{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "is_executing": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n",
      "active_global_batch_result_suffix: 2023-08-08_Apogee\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Optional, Dict\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun, BatchResultDataframeAccessor, run_diba_batch, BatchComputationProcessOptions, BatchSessionCompletionHandler, SessionBatchProgress, main\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "\n",
    "BATCH_DATE_TO_USE = '2023-08-08' # used for filenames throught the notebook\n",
    "active_global_batch_result_suffix:str = f\"{BATCH_DATE_TO_USE}_Apogee\"\n",
    "print(f'active_global_batch_result_suffix: {active_global_batch_result_suffix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab824348",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Batch Executions/Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "019afbbd-70d2-4e75-9548-b6f22d2e31ca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\runBatch.py:688: UserWarning: registration of accessor <class 'pyphoplacecellanalysis.General.Batch.runBatch.BatchResultDataframeAccessor'> under name 'batch_results' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  class BatchResultDataframeAccessor():\n"
     ]
    }
   ],
   "source": [
    "# Hardcoded included_session_contexts:\n",
    "\n",
    "\n",
    "\n",
    "included_session_contexts: Optional[List[IdentifyingContext]] = [\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54')]\n",
    "\n",
    "## Included Session Contexts:\n",
    "# included_session_contexts = batch_progress_df[np.logical_and(batch_progress_df['has_user_replay_annotations'], batch_progress_df['is_ready'])]['context'].to_numpy().tolist()\n",
    "\n",
    "# Only require sessions to have replay annotations:\n",
    "# included_session_contexts = batch_progress_df[batch_progress_df['has_user_replay_annotations']]['context'].to_numpy().tolist()\n",
    "\n",
    "# included_session_contexts = batch_progress_df['context'].to_numpy().tolist()[:4] # Only get the first 6\n",
    "## Limit the contexts to run to the last N:\n",
    "# included_session_contexts = included_session_contexts[:2]\n",
    "\n",
    "# ## No filtering the sessions:\n",
    "# included_session_contexts = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d382a65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting runBatch.main(active_result_suffix: \"2023-08-08_Apogee\", ...) ...\n",
      "finalized_loaded_global_batch_result_pickle_path: W:\\Data\\global_batch_result_2023-08-08_Apogee.pkl\n",
      "finalized_loaded_global_batch_result_pickle_path: W:\\Data\\global_batch_result_2023-08-08_Apogee.pkl\n",
      "Loading loaded session pickle file results : W:\\Data\\global_batch_result_2023-08-08_Apogee.pkl... encountered exception 'BatchRun' object is not iterable while printing. Turning into a warning and continuing.\n",
      "done.\n",
      "no difference between provided and internal paths.\n",
      "len(included_session_contexts): 12\n",
      "forced reloading...\n",
      "Beginning processing with len(included_session_contexts): 12\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\2006-6-07_16-40-19.epochs_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\2006-6-07_16-40-19.position_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\2006-6-07_16-40-19.spikes.mat... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\session\\Formats\\SessionSpecifications.py:122: UserWarning: WARNING: Optional File: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\2006-6-08_14-26-15.eeg does not exist. Continuing without it.\n",
      "  warnings.warn(f'WARNING: Optional File: {an_optional_filepath} does not exist. Continuing without it.')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\session\\Formats\\SessionSpecifications.py:122: UserWarning: WARNING: Optional File: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\2006-6-08_14-26-15.dat does not exist. Continuing without it.\n",
      "  warnings.warn(f'WARNING: Optional File: {an_optional_filepath} does not exist. Continuing without it.')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\session\\Formats\\SessionSpecifications.py:122: UserWarning: WARNING: Optional File: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\2006-6-07_16-40-19.dat does not exist. Continuing without it.\n",
      "  warnings.warn(f'WARNING: Optional File: {an_optional_filepath} does not exist. Continuing without it.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\sklearn\\manifold\\_isomap.py:359: UserWarning: The number of connected components of the neighbors graph is 2 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\scipy\\sparse\\_index.py:100: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving updated position results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\2006-6-07_16-40-19.position.npy... 2006-6-07_16-40-19.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\2006-6-07_16-40-19.interpolated_spike_positions.npy... 2006-6-07_16-40-19.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\2006-6-07_16-40-19.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\2006-6-07_16-40-19.replay_info.mat... done.\n",
      "session.replays loaded successfully!\n",
      "Loading success: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\2006-6-07_16-40-19.mua.npy... 2006-6-07_16-40-19.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\2006-6-07_16-40-19.pbe.npy... 2006-6-07_16-40-19.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 545\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1236.2662453636294)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\laps.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['lap_id']] = laps_df[['lap_id']].astype('int')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\laps.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['start_spike_index', 'end_spike_index']] = laps_df[['start_spike_index', 'end_spike_index']].astype('int')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\laps.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['num_spikes'] = laps_df['end_spike_index'] - laps_df['start_spike_index']\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\laps.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['lap_dir'] = laps_df['lap_dir'].astype('int')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\laps.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['label'] = laps_df['lap_id'].astype('str') # add the string \"label\" column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 1236.2662453636294, end: 2587.801681999932)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\laps.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['lap_id']] = laps_df[['lap_id']].astype('int')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\laps.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['start_spike_index', 'end_spike_index']] = laps_df[['start_spike_index', 'end_spike_index']].astype('int')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\laps.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['num_spikes'] = laps_df['end_spike_index'] - laps_df['start_spike_index']\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\laps.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['lap_dir'] = laps_df['lap_dir'].astype('int')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\laps.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['label'] = laps_df['lap_id'].astype('str') # add the string \"label\" column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 2587.801681999932)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18768,) should be less than time_window_edges: (35780,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18768,) should be less than time_window_edges: (35780,)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (36136,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (38641,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (34226,) should be less than time_window_edges: (76568,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (34226,) should be less than time_window_edges: (76568,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (77332,)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-07_16-40-19, curr_session_basedir: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19, ...)\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\n",
      "using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18768,) should be less than time_window_edges: (35780,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18768,) should be less than time_window_edges: (35780,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 15, 55, 11, 764864)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 15, 55, 52, 63517)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18768,) should be less than time_window_edges: (35780,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18768,) should be less than time_window_edges: (35780,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 15, 56, 31, 446636)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 15, 57, 9, 942966)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15458,) should be less than time_window_edges: (38260,)!\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 41, n_all_epoch_timebins = 1067)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 41, n_all_epoch_timebins = 1067)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding']. Saving global results...\n",
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\output\\global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "\t time since last computation: 0:02:02.691100\n",
      "pipeline hdf5_output_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\output\\pipeline_results.h5\n",
      "ERROR: encountered exception Cannot serialize the column [cell_type]\n",
      "because its data contents are not [string] but [mixed] object dtype while trying to build the session HDF output for kdiba_gor01_two_2006-6-07_16-40-19\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-07_16-40-19...\n",
      "\t\t Now have 1 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\2006-6-08_21-16-25.epochs_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\2006-6-08_21-16-25.position_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\2006-6-08_21-16-25.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\2006-6-08_21-16-25.position.npy... 2006-6-08_21-16-25.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\2006-6-08_21-16-25.interpolated_spike_positions.npy... 2006-6-08_21-16-25.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\2006-6-08_21-16-25.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\2006-6-08_21-16-25.replay_info.mat... done.\n",
      "session.replays loaded successfully!\n",
      "Loading success: W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\2006-6-08_21-16-25.mua.npy... 2006-6-08_21-16-25.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\2006-6-08_21-16-25.pbe.npy... 2006-6-08_21-16-25.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 108\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 722.653951405664)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 722.653951405664, end: 1201.0839364149142)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1201.0839364149142)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\n",
      "\t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (20270,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\n",
      "\t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (12894,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\n",
      "\t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (34680,)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-08_21-16-25, curr_session_basedir: W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25, ...)\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\n",
      "using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 2, 49, 301921)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 3, 4, 704571)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 3, 34, 347829)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 3, 50, 217134)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 64, n_all_epoch_timebins = 286)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 64, n_all_epoch_timebins = 286)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding']. Saving global results...\n",
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\output\\global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "\t time since last computation: 0:01:11.542198\n",
      "pipeline hdf5_output_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\output\\pipeline_results.h5\n",
      "ERROR: encountered exception Cannot serialize the column [cell_type]\n",
      "because its data contents are not [string] but [mixed] object dtype while trying to build the session HDF output for kdiba_gor01_two_2006-6-08_21-16-25\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-08_21-16-25...\n",
      "\t\t Now have 2 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\2006-6-09_22-24-40.epochs_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\2006-6-09_22-24-40.position_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\2006-6-09_22-24-40.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\2006-6-09_22-24-40.position.npy... 2006-6-09_22-24-40.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\2006-6-09_22-24-40.interpolated_spike_positions.npy... 2006-6-09_22-24-40.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\2006-6-09_22-24-40.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\2006-6-09_22-24-40.replay_info.mat... done.\n",
      "session.replays loaded successfully!\n",
      "Loading success: W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\2006-6-09_22-24-40.mua.npy... 2006-6-09_22-24-40.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\2006-6-09_22-24-40.pbe.npy... 2006-6-09_22-24-40.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 512\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 911.6011600069469)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 911.6011600069469, end: 2573.457162000006)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 2573.457162000006)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\n",
      "\t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (27155,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (49904,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (47040,) should be less than time_window_edges: (76857,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (47040,) should be less than time_window_edges: (76857,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (77624,)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-09_22-24-40, curr_session_basedir: W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40, ...)\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\n",
      "using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 11, 7, 188458)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 11, 58, 433154)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 12, 35, 168065)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 13, 25, 31502)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (14699,) should be less than time_window_edges: (49412,)!\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 58, n_all_epoch_timebins = 1410)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 58, n_all_epoch_timebins = 1410)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding']. Saving global results...\n",
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\output\\global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "\t time since last computation: 0:03:50.298895\n",
      "pipeline hdf5_output_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\output\\pipeline_results.h5\n",
      "ERROR: encountered exception Cannot serialize the column [cell_type]\n",
      "because its data contents are not [string] but [mixed] object dtype while trying to build the session HDF output for kdiba_gor01_two_2006-6-09_22-24-40\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-09_22-24-40...\n",
      "\t\t Now have 3 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\2006-6-12_16-53-46.epochs_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\2006-6-12_16-53-46.position_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\2006-6-12_16-53-46.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\2006-6-12_16-53-46.position.npy... 2006-6-12_16-53-46.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\2006-6-12_16-53-46.interpolated_spike_positions.npy... 2006-6-12_16-53-46.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\2006-6-12_16-53-46.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\2006-6-12_16-53-46.replay_info.mat... done.\n",
      "session.replays loaded successfully!\n",
      "Loading success: W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\2006-6-12_16-53-46.mua.npy... 2006-6-12_16-53-46.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\2006-6-12_16-53-46.pbe.npy... 2006-6-12_16-53-46.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 109\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 471.0674003356835)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 471.0674003356835, end: 785.4513262689579)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 785.4513262689579)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\n",
      "\t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (13127,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\n",
      "\t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (9198,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\n",
      "\t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (22940,)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-12_16-53-46, curr_session_basedir: W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46, ...)\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\n",
      "using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 19, 17, 815973)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 19, 26, 440094)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 19, 39, 675739)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 19, 48, 382499)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 38, n_all_epoch_timebins = 187)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 38, n_all_epoch_timebins = 187)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding']. Saving global results...\n",
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\output\\global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "\t time since last computation: 0:00:24.876517\n",
      "pipeline hdf5_output_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\output\\pipeline_results.h5\n",
      "ERROR: encountered exception Cannot serialize the column [cell_type]\n",
      "because its data contents are not [string] but [mixed] object dtype while trying to build the session HDF output for kdiba_gor01_two_2006-6-12_16-53-46\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-12_16-53-46...\n",
      "\t\t Now have 4 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "basedir: W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\2006-4-09_17-29-30.epochs_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\2006-4-09_17-29-30.position_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\2006-4-09_17-29-30.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\2006-4-09_17-29-30.position.npy... 2006-4-09_17-29-30.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\2006-4-09_17-29-30.interpolated_spike_positions.npy... 2006-4-09_17-29-30.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\2006-4-09_17-29-30.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\2006-4-09_17-29-30.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "Loading success: W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\2006-4-09_17-29-30.mua.npy... 2006-4-09_17-29-30.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\2006-4-09_17-29-30.pbe.npy... 2006-4-09_17-29-30.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 137\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 873.6244981772179)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 873.6244981772179, end: 1391.655627853339)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1391.655627853339)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11886,) should be less than time_window_edges: (24782,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11886,) should be less than time_window_edges: (24782,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (25027,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (14069,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20635,) should be less than time_window_edges: (40477,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20635,) should be less than time_window_edges: (40477,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (40880,)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_one_2006-4-09_17-29-30, curr_session_basedir: W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30, ...)\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\n",
      "using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11712,) should be less than time_window_edges: (23152,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11712,) should be less than time_window_edges: (23152,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 24, 22, 123287)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 24, 39, 372454)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11712,) should be less than time_window_edges: (23152,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11712,) should be less than time_window_edges: (23152,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 25, 8, 604077)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 25, 26, 282866)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8749,) should be less than time_window_edges: (13932,)!\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 27, n_all_epoch_timebins = 233)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 27, n_all_epoch_timebins = 233)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding']. Saving global results...\n",
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\output\\global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "\t time since last computation: 0:00:30.823442\n",
      "pipeline hdf5_output_path: W:\\Data\\KDIBA\\vvp01\\one\\2006-4-09_17-29-30\\output\\pipeline_results.h5\n",
      "ERROR: encountered exception Cannot serialize the column [cell_type]\n",
      "because its data contents are not [string] but [mixed] object dtype while trying to build the session HDF output for kdiba_vvp01_one_2006-4-09_17-29-30\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_one_2006-4-09_17-29-30...\n",
      "\t\t Now have 5 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "basedir: W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\2006-4-10_12-25-50.epochs_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\2006-4-10_12-25-50.position_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\2006-4-10_12-25-50.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\2006-4-10_12-25-50.position.npy... 2006-4-10_12-25-50.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\2006-4-10_12-25-50.interpolated_spike_positions.npy... 2006-4-10_12-25-50.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\2006-4-10_12-25-50.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\2006-4-10_12-25-50.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "Loading success: W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\2006-4-10_12-25-50.mua.npy... 2006-4-10_12-25-50.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\2006-4-10_12-25-50.pbe.npy... 2006-4-10_12-25-50.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 39\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 883.897131568141)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 883.897131568141, end: 1413.3991723447689)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1413.3991723447689)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11410,) should be less than time_window_edges: (26054,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11410,) should be less than time_window_edges: (26054,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (26312,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (13343,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20264,) should be less than time_window_edges: (41902,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20264,) should be less than time_window_edges: (41902,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (42319,)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_one_2006-4-10_12-25-50, curr_session_basedir: W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50, ...)\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\n",
      "using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11410,) should be less than time_window_edges: (26054,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11410,) should be less than time_window_edges: (26054,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 29, 49, 313814)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 30, 2, 785863)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11410,) should be less than time_window_edges: (26054,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11410,) should be less than time_window_edges: (26054,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 30, 34, 101449)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 30, 47, 785823)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8854,) should be less than time_window_edges: (13213,)!\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 26, n_all_epoch_timebins = 107)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 26, n_all_epoch_timebins = 107)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding']. Saving global results...\n",
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\output\\global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "\t time since last computation: 0:00:22.405616\n",
      "pipeline hdf5_output_path: W:\\Data\\KDIBA\\vvp01\\one\\2006-4-10_12-25-50\\output\\pipeline_results.h5\n",
      "ERROR: encountered exception Cannot serialize the column [cell_type]\n",
      "because its data contents are not [string] but [mixed] object dtype while trying to build the session HDF output for kdiba_vvp01_one_2006-4-10_12-25-50\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_one_2006-4-10_12-25-50...\n",
      "\t\t Now have 6 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "basedir: W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\2006-4-09_16-40-54.epochs_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\2006-4-09_16-40-54.position_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\2006-4-09_16-40-54.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\2006-4-09_16-40-54.position.npy... 2006-4-09_16-40-54.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\2006-4-09_16-40-54.interpolated_spike_positions.npy... 2006-4-09_16-40-54.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\2006-4-09_16-40-54.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\2006-4-09_16-40-54.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "Loading success: W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\2006-4-09_16-40-54.mua.npy... 2006-4-09_16-40-54.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\2006-4-09_16-40-54.pbe.npy... 2006-4-09_16-40-54.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 47\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1155.7064689620165)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 1155.7064689620165, end: 1724.0331400701689)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1724.0331400701689)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9650,) should be less than time_window_edges: (25913,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9650,) should be less than time_window_edges: (25913,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (26171,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (14863,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (16479,) should be less than time_window_edges: (42586,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (16479,) should be less than time_window_edges: (42586,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (43010,)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_two_2006-4-09_16-40-54, curr_session_basedir: W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54, ...)\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\n",
      "using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9650,) should be less than time_window_edges: (25913,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9650,) should be less than time_window_edges: (25913,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 34, 47, 949607)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 35, 0, 508870)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9650,) should be less than time_window_edges: (25913,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9650,) should be less than time_window_edges: (25913,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 35, 28, 77155)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 35, 40, 142052)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6829,) should be less than time_window_edges: (14718,)!\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 23, n_all_epoch_timebins = 86)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 23, n_all_epoch_timebins = 86)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding']. Saving global results...\n",
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\output\\global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "\t time since last computation: 0:00:19.705284\n",
      "pipeline hdf5_output_path: W:\\Data\\KDIBA\\vvp01\\two\\2006-4-09_16-40-54\\output\\pipeline_results.h5\n",
      "ERROR: encountered exception Cannot serialize the column [cell_type]\n",
      "because its data contents are not [string] but [mixed] object dtype while trying to build the session HDF output for kdiba_vvp01_two_2006-4-09_16-40-54\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_two_2006-4-09_16-40-54...\n",
      "\t\t Now have 7 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "basedir: W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\2006-4-10_12-58-3.epochs_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\2006-4-10_12-58-3.position_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\2006-4-10_12-58-3.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\2006-4-10_12-58-3.position.npy... 2006-4-10_12-58-3.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\2006-4-10_12-58-3.interpolated_spike_positions.npy... 2006-4-10_12-58-3.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\2006-4-10_12-58-3.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\2006-4-10_12-58-3.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "Loading success: W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\2006-4-10_12-58-3.mua.npy... 2006-4-10_12-58-3.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\2006-4-10_12-58-3.pbe.npy... 2006-4-10_12-58-3.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 64\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 932.8262060632987)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 932.8262060632987, end: 1458.5390641578997)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1458.5390641578997)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9325,) should be less than time_window_edges: (26752,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9325,) should be less than time_window_edges: (26752,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (27018,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (14198,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (17069,) should be less than time_window_edges: (42622,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (17069,) should be less than time_window_edges: (42622,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (43046,)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_two_2006-4-10_12-58-3, curr_session_basedir: W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3, ...)\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\n",
      "using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9325,) should be less than time_window_edges: (26752,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9325,) should be less than time_window_edges: (26752,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 40, 8, 421443)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 40, 26, 972692)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9325,) should be less than time_window_edges: (26752,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9325,) should be less than time_window_edges: (26752,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 41, 5, 175508)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 41, 21, 954645)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7744,) should be less than time_window_edges: (14059,)!\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 28, n_all_epoch_timebins = 148)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 28, n_all_epoch_timebins = 148)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding']. Saving global results...\n",
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\output\\global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "\t time since last computation: 0:00:26.282355\n",
      "pipeline hdf5_output_path: W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\output\\pipeline_results.h5\n",
      "ERROR: encountered exception Cannot serialize the column [cell_type]\n",
      "because its data contents are not [string] but [mixed] object dtype while trying to build the session HDF output for kdiba_vvp01_two_2006-4-10_12-58-3\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_two_2006-4-10_12-58-3...\n",
      "\t\t Now have 8 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "basedir: W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\11-02_17-46-44.epochs_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\11-02_17-46-44.position_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\11-02_17-46-44.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\11-02_17-46-44.position.npy... 11-02_17-46-44.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\11-02_17-46-44.interpolated_spike_positions.npy... 11-02_17-46-44.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\11-02_17-46-44.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\11-02_17-46-44.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "externally computed ripple_df.pkl not found. Falling back to .ripple.npy...\n",
      "Loading success: .ripple.npy.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\11-02_17-46-44.mua.npy... 11-02_17-46-44.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\11-02_17-46-44.pbe.npy... 11-02_17-46-44.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 126\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1144.228403621622)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 1144.228403621622, end: 1941.4332220000001)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1941.4332220000001)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7381,) should be less than time_window_edges: (29024,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7381,) should be less than time_window_edges: (29024,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (29312,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (22102,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15483,) should be less than time_window_edges: (56118,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15483,) should be less than time_window_edges: (56118,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (56677,)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_11-02_17-46-44, curr_session_basedir: W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44, ...)\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\n",
      "using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7381,) should be less than time_window_edges: (29024,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7381,) should be less than time_window_edges: (29024,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 45, 4, 165215)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 45, 18, 790508)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7381,) should be less than time_window_edges: (29024,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (7381,) should be less than time_window_edges: (29024,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 45, 41, 777671)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 45, 56, 804457)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (8102,) should be less than time_window_edges: (21885,)!\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 26, n_all_epoch_timebins = 446)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 26, n_all_epoch_timebins = 446)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding']. Saving global results...\n",
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\output\\global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "\t time since last computation: 0:00:35.047365\n",
      "pipeline hdf5_output_path: W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\output\\pipeline_results.h5\n",
      "ERROR: encountered exception Cannot serialize the column [cell_type]\n",
      "because its data contents are not [string] but [mixed] object dtype while trying to build the session HDF output for kdiba_pin01_one_11-02_17-46-44\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-02_17-46-44...\n",
      "\t\t Now have 9 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "basedir: W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\11-02_19-28-0.epochs_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\11-02_19-28-0.position_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\11-02_19-28-0.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\11-02_19-28-0.position.npy... 11-02_19-28-0.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\11-02_19-28-0.interpolated_spike_positions.npy... 11-02_19-28-0.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\11-02_19-28-0.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\11-02_19-28-0.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "externally computed ripple_df.pkl not found. Falling back to .ripple.npy...\n",
      "Loading success: .ripple.npy.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\11-02_19-28-0.mua.npy... 11-02_19-28-0.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\11-02_19-28-0.pbe.npy... 11-02_19-28-0.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 67\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 787.5080421553757)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 787.5080421553757, end: 1177.7605639999983)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1177.7605639999983)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11393,) should be less than time_window_edges: (22264,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11393,) should be less than time_window_edges: (22264,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (22485,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (11282,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (22186,) should be less than time_window_edges: (33911,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (22186,) should be less than time_window_edges: (33911,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (34248,)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_11-02_19-28-0, curr_session_basedir: W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0, ...)\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\n",
      "using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11393,) should be less than time_window_edges: (22264,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11393,) should be less than time_window_edges: (22264,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 48, 20, 551232)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 48, 26, 469451)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11393,) should be less than time_window_edges: (22264,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11393,) should be less than time_window_edges: (22264,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 48, 40, 535394)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 48, 46, 261437)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10793,) should be less than time_window_edges: (11173,)!\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 26, n_all_epoch_timebins = 189)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 26, n_all_epoch_timebins = 189)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding']. Saving global results...\n",
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\output\\global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "\t time since last computation: 0:00:18.726060\n",
      "pipeline hdf5_output_path: W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\output\\pipeline_results.h5\n",
      "ERROR: encountered exception Cannot serialize the column [cell_type]\n",
      "because its data contents are not [string] but [mixed] object dtype while trying to build the session HDF output for kdiba_pin01_one_11-02_19-28-0\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-02_19-28-0...\n",
      "ERROR: encountered exception The input must be a list of SpikeTrain while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_pin01_one_11-02_19-28-0]\n",
      "basedir: W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\11-03_12-3-25.epochs_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\11-03_12-3-25.position_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\11-03_12-3-25.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\11-03_12-3-25.position.npy... 11-03_12-3-25.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\11-03_12-3-25.interpolated_spike_positions.npy... 11-03_12-3-25.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\11-03_12-3-25.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\11-03_12-3-25.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "externally computed ripple_df.pkl not found. Falling back to .ripple.npy...\n",
      "Loading success: .ripple.npy.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\11-03_12-3-25.mua.npy... 11-03_12-3-25.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\11-03_12-3-25.pbe.npy... 11-03_12-3-25.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 16\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 669.0602578192211)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 669.0602578192211, end: 1005.4446971784892)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1005.4446971784892)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9259,) should be less than time_window_edges: (18736,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9259,) should be less than time_window_edges: (18736,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (18921,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (9200,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15445,) should be less than time_window_edges: (28139,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15445,) should be less than time_window_edges: (28139,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (28419,)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_11-03_12-3-25, curr_session_basedir: W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25, ...)\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\n",
      "using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9259,) should be less than time_window_edges: (18736,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9259,) should be less than time_window_edges: (18736,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 50, 24, 219127)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 50, 29, 64405)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9259,) should be less than time_window_edges: (18736,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (9259,) should be less than time_window_edges: (18736,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 50, 39, 1253)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 50, 43, 826686)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6186,) should be less than time_window_edges: (9111,)!\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 22, n_all_epoch_timebins = 57)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 22, n_all_epoch_timebins = 57)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding']. Saving global results...\n",
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\output\\global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "\t time since last computation: 0:00:10.177469\n",
      "pipeline hdf5_output_path: W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\output\\pipeline_results.h5\n",
      "ERROR: encountered exception Cannot serialize the column [cell_type]\n",
      "because its data contents are not [string] but [mixed] object dtype while trying to build the session HDF output for kdiba_pin01_one_11-03_12-3-25\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-03_12-3-25...\n",
      "ERROR: encountered exception The input must be a list of SpikeTrain while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_pin01_one_11-03_12-3-25]\n",
      "basedir: W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\n",
      "active_data_mode_name: kdiba\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\fet11-01_12-58-54.epochs_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\fet11-01_12-58-54.position_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\fet11-01_12-58-54.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\fet11-01_12-58-54.position.npy... fet11-01_12-58-54.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\fet11-01_12-58-54.interpolated_spike_positions.npy... fet11-01_12-58-54.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\fet11-01_12-58-54.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\fet11-01_12-58-54.replay_info.mat... done.\n",
      "session.replays could not be loaded from .replay_info.mat due to error Reader needs file name or open file-like object. Skipping (will be unavailable)\n",
      "externally computed ripple_df.pkl not found. Falling back to .ripple.npy...\n",
      "Loading success: .ripple.npy.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\fet11-01_12-58-54.mua.npy... fet11-01_12-58-54.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\fet11-01_12-58-54.pbe.npy... fet11-01_12-58-54.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "\t curr_replays: 469\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 2057.2259484970764)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 2057.2259484970764, end: 3031.7272470000007)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 3031.7272470000007)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11619,) should be less than time_window_edges: (52819,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11619,) should be less than time_window_edges: (52819,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (53345,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (28623,)\n",
      "due to includelist, including only 6 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\n",
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (17876,) should be less than time_window_edges: (89950,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (17876,) should be less than time_window_edges: (89950,)!\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (90848,)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\loadedSessPickle.pkl... done.\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_fet11-01_12-58-54, curr_session_basedir: W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54, ...)\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze2 != long_epoch_name: maze1\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\loadedSessPickle.pkl\n",
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "Time window 233 has no spikes.\n",
      "Time window 234 has no spikes.\n",
      "Time window 257 has no spikes.\n",
      "Time window 260 has no spikes.\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\n",
      "using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11619,) should be less than time_window_edges: (52819,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11619,) should be less than time_window_edges: (52819,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 55, 23, 68939)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 55, 40, 77275)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11619,) should be less than time_window_edges: (52819,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11619,) should be less than time_window_edges: (52819,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 56, 13, 393119)}\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "\tcomputation_times: {<function DefaultComputationFunctions._perform_position_decoding_computation at 0x0000022976F01E50>: datetime.datetime(2023, 8, 8, 16, 56, 28, 861900)}\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (6257,) should be less than time_window_edges: (28341,)!\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 25, n_all_epoch_timebins = 1202)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 25, n_all_epoch_timebins = 1202)\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses', 'long_short_post_decoding']. Saving global results...\n",
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\output\\global_computation_results.pkl... done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "\t time since last computation: 0:01:11.424279\n",
      "pipeline hdf5_output_path: W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\output\\pipeline_results.h5\n",
      "ERROR: encountered exception Cannot serialize the column [cell_type]\n",
      "because its data contents are not [string] but [mixed] object dtype while trying to build the session HDF output for kdiba_pin01_one_fet11-01_12-58-54\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_fet11-01_12-58-54...\n",
      "\t\t Now have 10 entries in self.across_sessions_instantaneous_fr_dict!\n",
      "\t\t done (success).\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\global_batch_result_2023-08-08_Apogee.pkl... done.\n",
      "encountered error HDF5 error back trace\n",
      "\n",
      "  File \"C:\\ci\\hdf5_1655191106204\\work\\src\\H5F.c\", line 532, in H5Fcreate\n",
      "    unable to create file\n",
      "  File \"C:\\ci\\hdf5_1655191106204\\work\\src\\H5VLcallback.c\", line 3282, in H5VL_file_create\n",
      "    file create failed\n",
      "  File \"C:\\ci\\hdf5_1655191106204\\work\\src\\H5VLcallback.c\", line 3248, in H5VL__file_create\n",
      "    file create failed\n",
      "  File \"C:\\ci\\hdf5_1655191106204\\work\\src\\H5VLnative_file.c\", line 63, in H5VL__native_file_create\n",
      "    unable to create file\n",
      "  File \"C:\\ci\\hdf5_1655191106204\\work\\src\\H5Fint.c\", line 1898, in H5F_open\n",
      "    unable to lock the file\n",
      "  File \"C:\\ci\\hdf5_1655191106204\\work\\src\\H5FD.c\", line 1625, in H5FD_lock\n",
      "    driver lock request failed\n",
      "  File \"C:\\ci\\hdf5_1655191106204\\work\\src\\H5FDsec2.c\", line 1002, in H5FD__sec2_lock\n",
      "    unable to lock file, errno = 0, error message = 'No error', Win32 GetLastError() = 33\n",
      "\n",
      "End of HDF5 error back trace\n",
      "\n",
      "Unable to open/create file 'W:\\Data\\global_batch_output_2023-08-08_Apogee.h5' saving HDF5 to W:\\Data\\global_batch_output_2023-08-08_Apogee.h5. Skipping.\n",
      "num_sessions: 10\n",
      "global_batch_result_inst_fr_file_path: W:\\Data\\across_session_result_long_short_inst_firing_rate_2023-08-08_Apogee.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\across_session_result_long_short_inst_firing_rate_2023-08-08_Apogee.pkl... done.\n"
     ]
    }
   ],
   "source": [
    "global_batch_run, result_handler, across_sessions_instantaneous_fr_dict, output_filenames_tuple = main(active_result_suffix=active_global_batch_result_suffix, included_session_contexts=included_session_contexts,\n",
    "                                                                                                       num_processes=1, should_force_reload_all=True, should_perform_figure_generation_to_file=False, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9ced46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun\n",
    "\n",
    "\n",
    "batch_slurm_scripts_directory = global_batch_run.global_data_root_parent_path.joinpath('slurm_scripts')\n",
    "batch_slurm_scripts_directory.mkdir(mode=755, parents=False, exist_ok=True)\n",
    "print(f'batch_slurm_scripts_directory: {batch_slurm_scripts_directory}')\n",
    "included_session_contexts, output_python_scripts, output_slurm_scripts = global_batch_run.generate_batch_slurm_jobs(included_session_contexts, batch_slurm_scripts_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f9ca2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_gor01_two_2006-6-07_16-40-19.py',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_gor01_two_2006-6-08_21-16-25.py',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_gor01_two_2006-6-09_22-24-40.py',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_gor01_two_2006-6-12_16-53-46.py',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_vvp01_one_2006-4-09_17-29-30.py',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_vvp01_one_2006-4-10_12-25-50.py',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_vvp01_two_2006-4-09_16-40-54.py',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_vvp01_two_2006-4-10_12-58-3.py',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_pin01_one_11-02_17-46-44.py',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_pin01_one_11-02_19-28-0.py',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_pin01_one_11-03_12-3-25.py',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_pin01_one_fet11-01_12-58-54.py']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_python_scripts\n",
    "# output_slurm_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8ce66c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_gor01_two_2006-6-07_16-40-19.sh',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_gor01_two_2006-6-08_21-16-25.sh',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_gor01_two_2006-6-09_22-24-40.sh',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_gor01_two_2006-6-12_16-53-46.sh',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_vvp01_one_2006-4-09_17-29-30.sh',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_vvp01_one_2006-4-10_12-25-50.sh',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_vvp01_two_2006-4-09_16-40-54.sh',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_vvp01_two_2006-4-10_12-58-3.sh',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_pin01_one_11-02_17-46-44.sh',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_pin01_one_11-02_19-28-0.sh',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_pin01_one_11-03_12-3-25.sh',\n",
       " 'W:\\\\Data\\\\slurm_scripts\\\\run_kdiba_pin01_one_fet11-01_12-58-54.sh']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_slurm_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9078b9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>context</th>\n",
       "      <th>basedirs</th>\n",
       "      <th>status</th>\n",
       "      <th>errors</th>\n",
       "      <th>n_long_laps</th>\n",
       "      <th>n_long_replays</th>\n",
       "      <th>n_short_laps</th>\n",
       "      <th>n_short_replays</th>\n",
       "      <th>is_ready</th>\n",
       "      <th>global_computation_result_file</th>\n",
       "      <th>loaded_session_pickle_file</th>\n",
       "      <th>ripple_result_file</th>\n",
       "      <th>has_user_replay_annotations</th>\n",
       "      <th>has_user_grid_bin_bounds_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-07_11-26-53</td>\n",
       "      <td>kdiba_gor01_one_2006-6-07_11-26-53</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\out...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\loa...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\rip...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>kdiba_gor01_one_2006-6-08_14-26-15</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15</td>\n",
       "      <td>SessionBatchProgress.FAILED</td>\n",
       "      <td>'kdiba'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\out...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loa...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\rip...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>kdiba_gor01_one_2006-6-09_1-22-43</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43</td>\n",
       "      <td>SessionBatchProgress.FAILED</td>\n",
       "      <td>'kdiba'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\outp...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\load...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\ripp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_3-23-37</td>\n",
       "      <td>kdiba_gor01_one_2006-6-09_3-23-37</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_3-23-37</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_3-23-37\\ripp...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-12_15-55-31</td>\n",
       "      <td>kdiba_gor01_one_2006-6-12_15-55-31</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31</td>\n",
       "      <td>SessionBatchProgress.FAILED</td>\n",
       "      <td>'kdiba'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\out...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\loa...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\rip...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-04_21-20-3</td>\n",
       "      <td>kdiba_pin01_one_fet11-04_21-20-3</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\fet11-04_21-20-3</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\fet11-04_21-20-3\\loade...</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\fet11-04_21-20-3\\fet11...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>redundant</td>\n",
       "      <td>kdiba_pin01_one_redundant</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\redundant</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>showclus</td>\n",
       "      <td>kdiba_pin01_one_showclus</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\showclus</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>sleep</td>\n",
       "      <td>kdiba_pin01_one_sleep</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\sleep</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>tmaze</td>\n",
       "      <td>kdiba_pin01_one_tmaze</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\tmaze</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   format_name animal exper_name        session_name  \\\n",
       "0        kdiba  gor01        one  2006-6-07_11-26-53   \n",
       "1        kdiba  gor01        one  2006-6-08_14-26-15   \n",
       "2        kdiba  gor01        one   2006-6-09_1-22-43   \n",
       "3        kdiba  gor01        one   2006-6-09_3-23-37   \n",
       "4        kdiba  gor01        one  2006-6-12_15-55-31   \n",
       "..         ...    ...        ...                 ...   \n",
       "67       kdiba  pin01        one    fet11-04_21-20-3   \n",
       "68       kdiba  pin01        one           redundant   \n",
       "69       kdiba  pin01        one            showclus   \n",
       "70       kdiba  pin01        one               sleep   \n",
       "71       kdiba  pin01        one               tmaze   \n",
       "\n",
       "                               context  \\\n",
       "0   kdiba_gor01_one_2006-6-07_11-26-53   \n",
       "1   kdiba_gor01_one_2006-6-08_14-26-15   \n",
       "2    kdiba_gor01_one_2006-6-09_1-22-43   \n",
       "3    kdiba_gor01_one_2006-6-09_3-23-37   \n",
       "4   kdiba_gor01_one_2006-6-12_15-55-31   \n",
       "..                                 ...   \n",
       "67    kdiba_pin01_one_fet11-04_21-20-3   \n",
       "68           kdiba_pin01_one_redundant   \n",
       "69            kdiba_pin01_one_showclus   \n",
       "70               kdiba_pin01_one_sleep   \n",
       "71               kdiba_pin01_one_tmaze   \n",
       "\n",
       "                                      basedirs  \\\n",
       "0   W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53   \n",
       "1   W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15   \n",
       "2    W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43   \n",
       "3    W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_3-23-37   \n",
       "4   W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31   \n",
       "..                                         ...   \n",
       "67    W:\\Data\\KDIBA\\pin01\\one\\fet11-04_21-20-3   \n",
       "68           W:\\Data\\KDIBA\\pin01\\one\\redundant   \n",
       "69            W:\\Data\\KDIBA\\pin01\\one\\showclus   \n",
       "70               W:\\Data\\KDIBA\\pin01\\one\\sleep   \n",
       "71               W:\\Data\\KDIBA\\pin01\\one\\tmaze   \n",
       "\n",
       "                              status   errors  n_long_laps  n_long_replays  \\\n",
       "0   SessionBatchProgress.NOT_STARTED     None            0               0   \n",
       "1        SessionBatchProgress.FAILED  'kdiba'            0               0   \n",
       "2        SessionBatchProgress.FAILED  'kdiba'            0               0   \n",
       "3   SessionBatchProgress.NOT_STARTED     None            0               0   \n",
       "4        SessionBatchProgress.FAILED  'kdiba'            0               0   \n",
       "..                               ...      ...          ...             ...   \n",
       "67  SessionBatchProgress.NOT_STARTED     None            0               0   \n",
       "68  SessionBatchProgress.NOT_STARTED     None            0               0   \n",
       "69  SessionBatchProgress.NOT_STARTED     None            0               0   \n",
       "70  SessionBatchProgress.NOT_STARTED     None            0               0   \n",
       "71  SessionBatchProgress.NOT_STARTED     None            0               0   \n",
       "\n",
       "    n_short_laps  n_short_replays  is_ready  \\\n",
       "0              0                0     False   \n",
       "1              0                0     False   \n",
       "2              0                0     False   \n",
       "3              0                0     False   \n",
       "4              0                0     False   \n",
       "..           ...              ...       ...   \n",
       "67             0                0     False   \n",
       "68             0                0     False   \n",
       "69             0                0     False   \n",
       "70             0                0     False   \n",
       "71             0                0     False   \n",
       "\n",
       "                       global_computation_result_file  \\\n",
       "0   W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\out...   \n",
       "1   W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\out...   \n",
       "2   W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\outp...   \n",
       "3                                                       \n",
       "4   W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\out...   \n",
       "..                                                ...   \n",
       "67                                                      \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "                           loaded_session_pickle_file  \\\n",
       "0   W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\loa...   \n",
       "1   W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loa...   \n",
       "2   W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\load...   \n",
       "3                                                       \n",
       "4   W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\loa...   \n",
       "..                                                ...   \n",
       "67  W:\\Data\\KDIBA\\pin01\\one\\fet11-04_21-20-3\\loade...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "                                   ripple_result_file  \\\n",
       "0   W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\rip...   \n",
       "1   W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\rip...   \n",
       "2   W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\ripp...   \n",
       "3   W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_3-23-37\\ripp...   \n",
       "4   W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\rip...   \n",
       "..                                                ...   \n",
       "67  W:\\Data\\KDIBA\\pin01\\one\\fet11-04_21-20-3\\fet11...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "    has_user_replay_annotations  has_user_grid_bin_bounds_annotations  \n",
       "0                         False                                  True  \n",
       "1                          True                                  True  \n",
       "2                          True                                  True  \n",
       "3                         False                                  True  \n",
       "4                          True                                  True  \n",
       "..                          ...                                   ...  \n",
       "67                        False                                  True  \n",
       "68                        False                                 False  \n",
       "69                        False                                 False  \n",
       "70                        False                                 False  \n",
       "71                        False                                 False  \n",
       "\n",
       "[72 rows x 18 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "# good_only_batch_progress_df\n",
    "batch_progress_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dddddb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Old (pre 2023-08-08) Run Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try to load an existing batch result:\n",
    "# # with set_posix_windows():\n",
    "# global_batch_run = BatchRun.try_init_from_file(global_data_root_parent_path, active_global_batch_result_filename=active_global_batch_result_filename,\n",
    "# \t\t\t\t\t\tskip_root_path_conversion=False, debug_print=debug_print) # on_needs_create_callback_fn=run_diba_batch\n",
    "\n",
    "# # batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "# # good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "# # batch_progress_df.batch_results.build_all_columns()\n",
    "# # good_only_batch_progress_df.batch_results.build_all_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd22042-113c-486f-8264-8ddfa6bb9474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# multiprocessing_kwargs = dict(use_multiprocessing=False, num_processes=1)\n",
    "multiprocessing_kwargs = dict(use_multiprocessing=True, num_processes=8)\n",
    "\n",
    "# Whether to output figures:\n",
    "# should_perform_figure_generation_to_file=False\n",
    "should_perform_figure_generation_to_file=True\n",
    "\n",
    "## Included Session Contexts:\n",
    "# included_session_contexts = batch_progress_df[np.logical_and(batch_progress_df['has_user_replay_annotations'], batch_progress_df['is_ready'])]['context'].to_numpy().tolist()\n",
    "\n",
    "# Only require sessions to have replay annotations:\n",
    "# included_session_contexts = batch_progress_df[batch_progress_df['has_user_replay_annotations']]['context'].to_numpy().tolist()\n",
    "\n",
    "# included_session_contexts = batch_progress_df['context'].to_numpy().tolist()[:4] # Only get the first 6\n",
    "## Limit the contexts to run to the last N:\n",
    "# included_session_contexts = included_session_contexts[:2]\n",
    "\n",
    "# ## No filtering the sessions:\n",
    "# included_session_contexts = None\n",
    "\n",
    "if included_session_contexts is not None:\n",
    "    print(f'len(included_session_contexts): {len(included_session_contexts)}')\n",
    "else:\n",
    "    print(f'included_session_contexts is None so all session contexts will be included.')\n",
    "\n",
    "# included_session_contexts\n",
    "\n",
    "\n",
    "# No Reloading\n",
    "result_handler = BatchSessionCompletionHandler(force_reload_all=False,\n",
    "                                                session_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=False, should_save=False),\n",
    "                                                global_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=False, should_save=False),\n",
    "                                                should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_global_recompute=False,\n",
    "                                                **multiprocessing_kwargs)\n",
    "\n",
    "# # Forced Reloading:\n",
    "# result_handler = BatchSessionCompletionHandler(force_reload_all=True,\n",
    "#                                                 session_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=True),\n",
    "#                                                 global_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=True),\n",
    "#                                                 should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE, force_global_recompute=True,\n",
    "#                                                 **multiprocessing_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "## Execute with the custom arguments.\n",
    "active_computation_functions_name_includelist=['_perform_baseline_placefield_computation',\n",
    "                                        # '_perform_time_dependent_placefield_computation',\n",
    "                                        '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        # '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding'\n",
    "                                    ]\n",
    "# active_computation_functions_name_includelist=['_perform_baseline_placefield_computation']\n",
    "global_batch_run.execute_all(force_reload=result_handler.force_reload_all, saving_mode=result_handler.saving_mode, skip_extended_batch_computations=True, post_run_callback_fn=result_handler.on_complete_success_execution_session,\n",
    "                             fail_on_exception=False, included_session_contexts=included_session_contexts,\n",
    "                                                                                        **{'computation_functions_name_includelist': active_computation_functions_name_includelist,\n",
    "                                                                                            'active_session_computation_configs': None,\n",
    "                                                                                            'allow_processing_previously_completed': True}, **multiprocessing_kwargs) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 4m 39.8s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f23326ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(format_name: 'kdiba'\n",
       "         animal: 'gor01'\n",
       "         exper_name: 'two'\n",
       "         session_name: '2006-6-07_16-40-19'),\n",
       " Context(format_name: 'kdiba'\n",
       "         animal: 'gor01'\n",
       "         exper_name: 'two'\n",
       "         session_name: '2006-6-08_21-16-25'),\n",
       " Context(format_name: 'kdiba'\n",
       "         animal: 'gor01'\n",
       "         exper_name: 'two'\n",
       "         session_name: '2006-6-09_22-24-40'),\n",
       " Context(format_name: 'kdiba'\n",
       "         animal: 'gor01'\n",
       "         exper_name: 'two'\n",
       "         session_name: '2006-6-12_16-53-46'),\n",
       " Context(format_name: 'kdiba'\n",
       "         animal: 'vvp01'\n",
       "         exper_name: 'one'\n",
       "         session_name: '2006-4-09_17-29-30'),\n",
       " Context(format_name: 'kdiba'\n",
       "         animal: 'vvp01'\n",
       "         exper_name: 'one'\n",
       "         session_name: '2006-4-10_12-25-50'),\n",
       " Context(format_name: 'kdiba'\n",
       "         animal: 'vvp01'\n",
       "         exper_name: 'two'\n",
       "         session_name: '2006-4-09_16-40-54'),\n",
       " Context(format_name: 'kdiba'\n",
       "         animal: 'vvp01'\n",
       "         exper_name: 'two'\n",
       "         session_name: '2006-4-10_12-58-3'),\n",
       " Context(format_name: 'kdiba'\n",
       "         animal: 'pin01'\n",
       "         exper_name: 'one'\n",
       "         session_name: '11-02_17-46-44'),\n",
       " Context(format_name: 'kdiba'\n",
       "         animal: 'pin01'\n",
       "         exper_name: 'one'\n",
       "         session_name: '11-02_19-28-0'),\n",
       " Context(format_name: 'kdiba'\n",
       "         animal: 'pin01'\n",
       "         exper_name: 'one'\n",
       "         session_name: '11-03_12-3-25'),\n",
       " Context(format_name: 'kdiba'\n",
       "         animal: 'pin01'\n",
       "         exper_name: 'one'\n",
       "         session_name: 'fet11-01_12-58-54')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get only the sessions with non-None results\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "sessions_with_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6cc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('W:/Data')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_data_root_parent_path = global_batch_run.global_data_root_parent_path.resolve()\n",
    "global_data_root_parent_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acae798c-78db-4cd4-8eb5-276447dce1fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\global_batch_run_test_2023-08-08_Apogee... done.\n"
     ]
    }
   ],
   "source": [
    "# Save to pickle:\n",
    "global_batch_result_file_path = global_data_root_parent_path.joinpath(f'global_batch_run_test_{active_global_batch_result_suffix}')\n",
    "saveData(global_batch_result_file_path, global_batch_run) # Update the global batch run dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70b42a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_output_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c21482b-23ac-44e6-bfb2-8e3d480d74bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine across .h5 files:\n",
    "import tables as tb\n",
    "import h5py\n",
    "\n",
    "# f'/kdiba/gor01/one/2006-6-12_15-55-31/neuron_identities/table'\n",
    "\n",
    "session_identifiers, pkl_output_paths, hdf5_output_paths\n",
    "\n",
    "file_path = f'output/test_external_links.h5'\n",
    "a_global_computations_group_key: str = f\"{session_group_key}/global_computations\"\n",
    "with tb.open_file(file_path, mode='w') as f: # this mode='w' is correct because it should overwrite the previous file and not append to it.\n",
    "    a_global_computations_group = f.create_group(session_group_key, 'global_computations', title='the result of computations that operate over many or all of the filters in the session.', createparents=True)\n",
    "    an_external_link = f.create_external_link(f'', n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb43f9-214a-401b-8ae9-7dbe9af40180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from typing import List\n",
    "from attrs import define, field, Factory\n",
    "import pandas as pd\n",
    "import tables as tb\n",
    "\n",
    "@define(slots=False)\n",
    "class H5Loader:\n",
    "    \"\"\"\n",
    "    H5Loader class for loading and consolidating .h5 files\n",
    "    Usage:\n",
    "        loader = H5Loader(file_list)\n",
    "        master_table = loader.load_and_consolidate()\n",
    "    \"\"\"\n",
    "    file_list: List[str] = field(default=Factory(list))\n",
    "    table_key_list: List[str] = field(default=Factory(list))\n",
    "    \n",
    "    def load_and_consolidate(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Loads .h5 files and consolidates into a master table\n",
    "        \"\"\"\n",
    "        data_frames = []\n",
    "        for file, table_key in zip(self.file_list, self.table_key_list):\n",
    "            with tb.open_file(file) as h5_file:\n",
    "                a_table = h5_file.get_node(table_key)\n",
    "                print(f'a_table: {a_table}')\n",
    "                # for a_record in a_table\n",
    "                \n",
    "                # data_frames.append(a_table)\n",
    "#                 for table in h5_file.get_node(table_key):\n",
    "#                 # for table in h5_file.root:\n",
    "                # df = pd.DataFrame.from_records(a_table[:]) # .read()\n",
    "                df = pd.DataFrame.from_records(a_table.read()) \n",
    "                data_frames.append(df)\n",
    "\n",
    "        master_table = pd.concat(data_frames, ignore_index=True)\n",
    "        return master_table\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "session_group_keys: List[str] = [(\"/\" + a_ctxt.get_description(separator=\"/\", include_property_names=False)) for a_ctxt in session_identifiers] # 'kdiba/gor01/one/2006-6-08_14-26-15'\n",
    "# session_uid: str = session_context.get_description(separator=\"|\", include_property_names=False)\n",
    "neuron_identities_table_keys = [f\"{session_group_key}/neuron_identities/table\" for session_group_key in session_group_keys]\n",
    "\n",
    "\n",
    "a_loader = H5Loader(file_list=hdf5_output_paths, table_key_list=neuron_identities_table_keys)\n",
    "a_loader\n",
    "\n",
    "_out_table = a_loader.load_and_consolidate()\n",
    "_out_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc1ac7-5771-4cd5-94c6-7a6244eb8217",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extract output files from all completed sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7749849c-9f57-4d2c-aab8-5ee9353f6cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5'\n",
    "\n",
    "# kdiba_vvp01_two_2006-4-10_12-58-3\n",
    "# \toutputs_local ={'pkl': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl')}\n",
    "# \toutputs_global ={'pkl': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl'), 'hdf5': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5')}\n",
    "\n",
    "session_identifiers, pkl_output_paths, hdf5_output_paths = global_batch_run.build_output_files_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361385b-385d-4e12-997b-e2a68404858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want .values from SingleBarResult \n",
    "session_identifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f3d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8288dee-a41a-4640-a139-cb0a64f01814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_output_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "626e4980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl'),\n",
       " WindowsPath('W:/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_output_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb0cd9-3e60-4425-9351-dfc903f3f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output filelist:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import save_filelist_to_text_file, convert_filelist_to_new_parent\n",
    "\n",
    "h5_filelist_path = global_data_root_parent_path.joinpath(f'fileList_Greatlakes_HDF5_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, src_filelist_HDF5_savepath = save_filelist_to_text_file(hdf5_output_paths, h5_filelist_path)\n",
    "\n",
    "pkls_filelist_path = global_data_root_parent_path.joinpath(f'fileList_Greatlakes_pkls_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, src_filelist_pkls_savepath = save_filelist_to_text_file(pkl_output_paths, pkls_filelist_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d5ab67a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_filelist_to_text_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m filelist_dest_paths\n\u001b[0;32m     12\u001b[0m dest_Apogee_h5_filelist_path \u001b[39m=\u001b[39m global_data_root_parent_path\u001b[39m.\u001b[39mjoinpath(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdest_fileList_Apogee_\u001b[39m\u001b[39m{\u001b[39;00mBATCH_DATE_TO_USE\u001b[39m}\u001b[39;00m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mresolve()\n\u001b[1;32m---> 13\u001b[0m _out_string, dest_filelist_savepath \u001b[39m=\u001b[39m save_filelist_to_text_file(filelist_dest_paths, dest_Apogee_h5_filelist_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'save_filelist_to_text_file' is not defined"
     ]
    }
   ],
   "source": [
    "from pyphocorehelpers.Filesystem.path_helpers import convert_filelist_to_new_parent\n",
    "# source_parent_path = Path(r'/media/MAX/cloud/turbo/Data')\n",
    "source_parent_path = Path(r'/nfs/turbo/umms-kdiba/Data')\n",
    "dest_parent_path = Path(r'/~/W/Data/')\n",
    "\n",
    "\n",
    "# # Build the destination filelist from the source_filelist and the two paths:\n",
    "filelist_source = hdf5_output_paths\n",
    "filelist_dest_paths = convert_filelist_to_new_parent(filelist_source, original_parent_path=source_parent_path, dest_parent_path=dest_parent_path)\n",
    "filelist_dest_paths\n",
    "\n",
    "dest_Apogee_h5_filelist_path = global_data_root_parent_path.joinpath(f'dest_fileList_Apogee_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, dest_filelist_savepath = save_filelist_to_text_file(filelist_dest_paths, dest_Apogee_h5_filelist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412260ec-ddbd-4727-8795-438717dd9db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_filelist_savepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a8e69a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('W:/Data/global_batch_output_2023-08-08.h5')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult\n",
    "from neuropy.core.epoch import Epoch\n",
    "\n",
    "# Save to HDF5\n",
    "suffix = f'{BATCH_DATE_TO_USE}'\n",
    "## Build Pickle Path:\n",
    "file_path = global_data_root_parent_path.joinpath(f'global_batch_output_{suffix}.h5').resolve()\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10b0d19b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: W:\\Data\\global_batch_output_2023-08-08.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: W:\\Data\\global_batch_output_2023-08-08.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: W:\\Data\\global_batch_output_2023-08-08.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: W:\\Data\\global_batch_output_2023-08-08.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: W:\\Data\\global_batch_output_2023-08-08.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: W:\\Data\\global_batch_output_2023-08-08.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: W:\\Data\\global_batch_output_2023-08-08.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: W:\\Data\\global_batch_output_2023-08-08.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: W:\\Data\\global_batch_output_2023-08-08.h5, with key: /kdiba/pin01/one/11-02_17-46-44/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: W:\\Data\\global_batch_output_2023-08-08.h5, with key: /kdiba/pin01/one/11-02_19-28-0/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: W:\\Data\\global_batch_output_2023-08-08.h5, with key: /kdiba/pin01/one/11-03_12-3-25/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: W:\\Data\\global_batch_output_2023-08-08.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "done outputting HDF file.\n"
     ]
    }
   ],
   "source": [
    "global_batch_run.to_hdf(file_path,'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "282ce774-98fb-4e69-a7e2-e94cbff1b0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_sessions: 10\n",
      "global_batch_result_inst_fr_file_path: W:\\Data\\across_session_result_long_short_inst_firing_rate_2023-08-08.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\across_session_result_long_short_inst_firing_rate_2023-08-08.pkl... done.\n"
     ]
    }
   ],
   "source": [
    "# Get only the sessions with non-None results\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "\n",
    "# list(global_batch_run.session_batch_outputs.keys())\n",
    "\n",
    "# Somewhere in there there are `InstantaneousSpikeRateGroupsComputation` results to extract\n",
    "across_sessions_instantaneous_fr_dict = {} # InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "# good_session_batch_outputs = global_batch_run.session_batch_outputs\n",
    "\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "good_session_batch_outputs = {a_ctxt:a_result for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None}\n",
    "\n",
    "for a_ctxt, a_result in good_session_batch_outputs.items():\n",
    "    if a_result is not None:\n",
    "        # a_good_result = a_result.__dict__.get('across_sessions_batch_results', {}).get('inst_fr_comps', None)\n",
    "        a_good_result = a_result.across_session_results.get('inst_fr_comps', None)\n",
    "        if a_good_result is not None:\n",
    "            across_sessions_instantaneous_fr_dict[a_ctxt] = a_good_result\n",
    "            # print(a_result['across_sessions_batch_results']['inst_fr_comps'])\n",
    "            \n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "\n",
    "# When done, `result_handler.across_sessions_instantaneous_fr_dict` is now equivalent to what it would have been before. It can be saved using the normal `.save_across_sessions_data(...)`\n",
    "\n",
    "## Save the instantaneous firing rate results dict: (# Dict[IdentifyingContext] = InstantaneousSpikeRateGroupsComputation)\n",
    "AcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_instantaneous_fr_dict, global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl')\n",
    "\n",
    "# ## Save pickle:\n",
    "# inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "# global_batch_result_inst_fr_file_path = Path(global_data_root_parent_path).joinpath(inst_fr_output_filename).resolve() # Use Default\n",
    "# print(f'global_batch_result_inst_fr_file_path: {global_batch_result_inst_fr_file_path}')\n",
    "# # Save the all sessions instantaneous firing rate dict to the path:\n",
    "# saveData(global_batch_result_inst_fr_file_path, across_sessions_instantaneous_fr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d19a7-5a89-43f1-aa33-3a7450d1f965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "across_sessions_instantaneous_fr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e178426c-54df-47ac-8103-a66f114c77e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[a_ctxt.get_initialization_code_string() for a_ctxt in sessions_with_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd124683-bfc2-49bf-9531-583e19db5a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "included_contexts = [IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'),\n",
    "IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'),\n",
    "IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'),\n",
    "IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'),\n",
    "IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'),\n",
    "IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be651cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2023-07-14 - Load Saved across-sessions-data and testing Batch-computed inst_firing_rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import list_of_dicts_to_dict_of_lists\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "## Load the saved across-session results:\n",
    "# inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "# inst_fr_output_filename = 'across_session_result_long_short_inst_firing_rate.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-07-21.pkl'\n",
    "inst_fr_output_filename=f'across_session_result_handler_{BATCH_DATE_TO_USE}.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hacks the `PaperFigureTwo` and `InstantaneousSpikeRateGroupsComputation` \n",
    "global_multi_session_context, _out_aggregate_fig_2 = AcrossSessionsVisualizations.across_sessions_bar_graphs(across_session_inst_fr_computation, num_sessions, enable_tiny_point_labels=False, enable_hover_labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381fcf5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "across_session_inst_fr_computation.LxC_scatter_props\n",
    "across_session_inst_fr_computation.SxC_scatter_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db1ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45d728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the unique scatter plot dictionaries:\n",
    "across_session_contexts = list(across_sessions_instantaneous_fr_dict.keys())\n",
    "unique_animals = IdentifyingContext.find_unique_values(across_session_contexts)['animal'] # {'gor01', 'pin01', 'vvp01'}\n",
    "# Get number of animals to plot\n",
    "marker_list = [(5, i) for i in np.arange(len(unique_animals))] # [(5, 0), (5, 1), (5, 2)]\n",
    "scatter_props = [{'marker': mkr} for mkr in marker_list]  # Example, you should provide your own scatter properties\n",
    "scatter_props_dict = dict(zip(unique_animals, scatter_props))\n",
    "# {'pin01': {'marker': (5, 0)},\n",
    "#  'gor01': {'marker': (5, 1)},\n",
    "#  'vvp01': {'marker': (5, 2)}}\n",
    "scatter_props_dict\n",
    "\n",
    "# Pass a function that will return a set of kwargs for a given context\n",
    "def _return_scatter_props_fn(ctxt: IdentifyingContext):\n",
    "\t\"\"\" captures `scatter_props_dict` \"\"\"\n",
    "\tanimal_id = str(ctxt.animal)\n",
    "\treturn scatter_props_dict[animal_id]\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63258151",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=num_sessions) # some global context across all of the sessions, not sure what to put here.\n",
    "\n",
    "# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\n",
    "\n",
    "## Display the aggregate across sessions:\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn't save this info\n",
    "_out_fig_2.computation_result = across_session_inst_fr_computation # the result loaded from the file\n",
    "_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\n",
    "# Set callback, the only self-specific property\n",
    "# _out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)\n",
    "_out_fig_2.scatter_props_fn = _return_scatter_props_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LxC_aclus = _out_fig_2.computation_result.LxC_aclus\n",
    "SxC_aclus = _out_fig_2.computation_result.SxC_aclus\n",
    "\n",
    "LxC_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c498f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureOutputManager, FigureOutputLocation, ContextToPathMode\n",
    "\n",
    "registered_output_files = {}\n",
    "\n",
    "def output_figure(final_context: IdentifyingContext, fig, write_vector_format:bool=False, write_png:bool=True, debug_print=True):\n",
    "    \"\"\" outputs the figure using the provided context. \"\"\"\n",
    "    from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_and_write_to_file\n",
    "    def register_output_file(output_path, output_metadata=None):\n",
    "        \"\"\" registers a new output file for the pipeline \"\"\"\n",
    "        print(f'register_output_file(output_path: {output_path}, ...)')\n",
    "        registered_output_files[output_path] = output_metadata or {}\n",
    "\n",
    "    fig_out_man = FigureOutputManager(figure_output_location=FigureOutputLocation.DAILY_PROGRAMMATIC_OUTPUT_FOLDER, context_to_path_mode=ContextToPathMode.HIERARCHY_UNIQUE)\n",
    "    active_out_figure_paths = build_and_write_to_file(fig, final_context, fig_out_man, write_vector_format=write_vector_format, write_png=write_png, register_output_file_fn=register_output_file)\n",
    "    return active_out_figure_paths, final_context\n",
    "\n",
    "\n",
    "# Set callback, the only self-specific property\n",
    "_out_fig_2._pipeline_file_callback_fn = output_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17b920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\n",
    "\t\n",
    "_out_fig_2.perform_save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32781c8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Single Session testing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_out = global_batch_run.execute_session(session_context=curr_sess_context, force_reload=True, skip_extended_batch_computations=True, computation_functions_name_includelist =['_perform_baseline_placefield_computation'], active_session_computation_configs=None) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "_test_out\n",
    "\n",
    "# global_batch_run.execute_session(session_context=curr_sess_context, force_reload=True, skip_extended_batch_computations=True, **{'computation_functions_name_includelist': ['_perform_baseline_placefield_computation'], 'active_session_computation_configs': None}) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 23.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf2bb67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "full_good_dirs = [k for k, v in global_batch_run.session_batch_errors.items() if v is None]\n",
    "bad_dirs = [k for k, v in global_batch_run.session_batch_errors.items() if v is not None]\n",
    "full_good_dirs\n",
    "bad_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f73f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_batch_run.session_batch_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcad70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_run.session_batch_status\n",
    "global_batch_run.session_batch_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15faf2bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Get good sessions for use in the specific session processing notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed516134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf02efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get the list of sessions that are completely ready to process:\n",
    "full_good_ready_to_process_sessions = list(good_only_batch_progress_df['context'].to_numpy())\n",
    "full_good_ready_to_process_sessions\n",
    "# Get good sessions for use in the specific session processing notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ad809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run[\"good_sessions_list\"].extend(full_good_ready_to_process_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636e3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.stop()\n",
    "project.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf1322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\",\\n\".join([ctx.get_initialization_code_string() for ctx in full_good_ready_to_process_sessions])) # List definitions\n",
    "\n",
    "# [IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a4bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\ncurr_context = \".join([ctx.get_initialization_code_string() for ctx in full_good_ready_to_process_sessions])) # Line definitions\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5689d1d-6400-4f87-be0e-a184a1d5bee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82aedf-b024-4f07-b1a9-350730b4db8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "save_time = datetime.now()\n",
    " \n",
    "print(\"save_time =\", save_time)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = save_time.strftime(\"%Y-%m-%d_%I-%M%p\")\n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7bc6bd-5b34-41d0-b906-b0ad9927b08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get output file paths:\n",
    "completed_pipeline_filename = 'loadedSessPickle.pkl'\n",
    "completed_global_computations_filename = 'outputs/global_computation_results.pkl'\n",
    "\n",
    "full_good_ready_to_process_session_paths = list(good_only_batch_progress_df['basedirs'].to_numpy())\n",
    "session_paths_output_folders = [sess_path.joinpath('outputs').resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "\n",
    "completed_pipeline_file_paths = [sess_path.joinpath(completed_pipeline_filename).resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "completed_global_computations_file_paths = [sess_path.joinpath(completed_global_computations_filename).resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "completed_global_computations_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab75122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countable Additivity \n",
    "# Any countable collections of points is size 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af06e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
