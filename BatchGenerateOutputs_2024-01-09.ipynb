{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from typing import List, Dict, Optional, Union, Callable\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "from attrs import define, field, Factory\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import CapturedException\n",
    "\n",
    "# Jupyter interactivity:\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.gui.Jupyter.JupyterButtonRowWidget import JupyterButtonRowWidget\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core import Epoch\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "import pyphoplacecellanalysis.General.Batch.runBatch\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun, BatchResultDataframeAccessor, run_diba_batch, BatchComputationProcessOptions, BatchSessionCompletionHandler, SavingOptions\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import SessionBatchProgress\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults, AcrossSessionTables, AcrossSessionsVisualizations\n",
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "\n",
    "from pyphocorehelpers.print_helpers import CapturedException\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult, BatchSessionCompletionHandler\n",
    "\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_file_metadata\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file, save_copydict_to_text_file, read_copydict_from_text_file, invert_filedict\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import get_file_str_if_file_exists\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import check_output_h5_files, copy_files_in_filelist_to_dest\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import ConcreteSessionFolder, BackupMethods\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots, BatchPhoJonathanFiguresHelper\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "\n",
    "from neuropy.core.neuron_identities import NeuronIdentityDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import build_merged_neuron_firing_rate_indicies\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsHelpers\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalLapsHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses, RankOrderResult, ShuffleHelper, Zscorer, LongShortStatsTuple, DirectionalRankOrderLikelihoods, DirectionalRankOrderResult, RankOrderComputationsContainer\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalMergedDecodersResult\n",
    "\n",
    "# BATCH_DATE_TO_USE = '2023-10-20' # used for filenames throught the notebook\n",
    "# BATCH_DATE_TO_USE = '2023-12-23_Apogee' # used for filenames throught the notebook\n",
    "BATCH_DATE_TO_USE = '2024-01-09_Apogee' # used for filenames throught the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef5938c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading loaded session pickle file results : W:\\Data\\global_batch_result_2024-01-09_Apogee.pkl... done.\n",
      "Failure loading W:\\Data\\global_batch_result_2024-01-09_Apogee.pkl.\n",
      "creating new batch_run\n",
      "Saving (file mode 'None') saved session pickle file results : None... done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>context</th>\n",
       "      <th>basedirs</th>\n",
       "      <th>status</th>\n",
       "      <th>errors</th>\n",
       "      <th>session_datetime</th>\n",
       "      <th>n_long_laps</th>\n",
       "      <th>n_long_replays</th>\n",
       "      <th>n_short_laps</th>\n",
       "      <th>n_short_replays</th>\n",
       "      <th>is_ready</th>\n",
       "      <th>global_computation_result_file</th>\n",
       "      <th>loaded_session_pickle_file</th>\n",
       "      <th>ripple_result_file</th>\n",
       "      <th>has_user_replay_annotations</th>\n",
       "      <th>has_user_grid_bin_bounds_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-07_11-26-53</td>\n",
       "      <td>kdiba_gor01_one_2006-6-07_11-26-53</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-07 11:26:53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\out...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\loa...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\rip...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>kdiba_gor01_one_2006-6-08_14-26-15</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\out...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loa...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\rip...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>kdiba_gor01_one_2006-6-09_1-22-43</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-09 01:22:43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\outp...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\load...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\ripp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_3-23-37</td>\n",
       "      <td>kdiba_gor01_one_2006-6-09_3-23-37</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_3-23-37</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-09 03:23:37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_3-23-37\\ripp...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-12_15-55-31</td>\n",
       "      <td>kdiba_gor01_one_2006-6-12_15-55-31</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-12 15:55:31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\out...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\loa...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\rip...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-04_21-20-3</td>\n",
       "      <td>kdiba_pin01_one_fet11-04_21-20-3</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\fet11-04_21-20-3</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-04 21:20:03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\fet11-04_21-20-3\\loade...</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\fet11-04_21-20-3\\fet11...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>redundant</td>\n",
       "      <td>kdiba_pin01_one_redundant</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\redundant</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>showclus</td>\n",
       "      <td>kdiba_pin01_one_showclus</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\showclus</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>sleep</td>\n",
       "      <td>kdiba_pin01_one_sleep</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\sleep</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>tmaze</td>\n",
       "      <td>kdiba_pin01_one_tmaze</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\tmaze</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   format_name animal exper_name        session_name  \\\n",
       "0        kdiba  gor01        one  2006-6-07_11-26-53   \n",
       "1        kdiba  gor01        one  2006-6-08_14-26-15   \n",
       "2        kdiba  gor01        one   2006-6-09_1-22-43   \n",
       "3        kdiba  gor01        one   2006-6-09_3-23-37   \n",
       "4        kdiba  gor01        one  2006-6-12_15-55-31   \n",
       "..         ...    ...        ...                 ...   \n",
       "67       kdiba  pin01        one    fet11-04_21-20-3   \n",
       "68       kdiba  pin01        one           redundant   \n",
       "69       kdiba  pin01        one            showclus   \n",
       "70       kdiba  pin01        one               sleep   \n",
       "71       kdiba  pin01        one               tmaze   \n",
       "\n",
       "                               context  \\\n",
       "0   kdiba_gor01_one_2006-6-07_11-26-53   \n",
       "1   kdiba_gor01_one_2006-6-08_14-26-15   \n",
       "2    kdiba_gor01_one_2006-6-09_1-22-43   \n",
       "3    kdiba_gor01_one_2006-6-09_3-23-37   \n",
       "4   kdiba_gor01_one_2006-6-12_15-55-31   \n",
       "..                                 ...   \n",
       "67    kdiba_pin01_one_fet11-04_21-20-3   \n",
       "68           kdiba_pin01_one_redundant   \n",
       "69            kdiba_pin01_one_showclus   \n",
       "70               kdiba_pin01_one_sleep   \n",
       "71               kdiba_pin01_one_tmaze   \n",
       "\n",
       "                                      basedirs  \\\n",
       "0   W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53   \n",
       "1   W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15   \n",
       "2    W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43   \n",
       "3    W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_3-23-37   \n",
       "4   W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31   \n",
       "..                                         ...   \n",
       "67    W:\\Data\\KDIBA\\pin01\\one\\fet11-04_21-20-3   \n",
       "68           W:\\Data\\KDIBA\\pin01\\one\\redundant   \n",
       "69            W:\\Data\\KDIBA\\pin01\\one\\showclus   \n",
       "70               W:\\Data\\KDIBA\\pin01\\one\\sleep   \n",
       "71               W:\\Data\\KDIBA\\pin01\\one\\tmaze   \n",
       "\n",
       "                              status errors    session_datetime  n_long_laps  \\\n",
       "0   SessionBatchProgress.NOT_STARTED   None 2006-06-07 11:26:53            0   \n",
       "1   SessionBatchProgress.NOT_STARTED   None 2006-06-08 14:26:15            0   \n",
       "2   SessionBatchProgress.NOT_STARTED   None 2006-06-09 01:22:43            0   \n",
       "3   SessionBatchProgress.NOT_STARTED   None 2006-06-09 03:23:37            0   \n",
       "4   SessionBatchProgress.NOT_STARTED   None 2006-06-12 15:55:31            0   \n",
       "..                               ...    ...                 ...          ...   \n",
       "67  SessionBatchProgress.NOT_STARTED   None 2009-11-04 21:20:03            0   \n",
       "68  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "69  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "70  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "71  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "\n",
       "    n_long_replays  n_short_laps  n_short_replays  is_ready  \\\n",
       "0                0             0                0     False   \n",
       "1                0             0                0     False   \n",
       "2                0             0                0     False   \n",
       "3                0             0                0     False   \n",
       "4                0             0                0     False   \n",
       "..             ...           ...              ...       ...   \n",
       "67               0             0                0     False   \n",
       "68               0             0                0     False   \n",
       "69               0             0                0     False   \n",
       "70               0             0                0     False   \n",
       "71               0             0                0     False   \n",
       "\n",
       "                       global_computation_result_file  \\\n",
       "0   W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\out...   \n",
       "1   W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\out...   \n",
       "2   W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\outp...   \n",
       "3                                                       \n",
       "4   W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\out...   \n",
       "..                                                ...   \n",
       "67                                                      \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "                           loaded_session_pickle_file  \\\n",
       "0   W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\loa...   \n",
       "1   W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loa...   \n",
       "2   W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\load...   \n",
       "3                                                       \n",
       "4   W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\loa...   \n",
       "..                                                ...   \n",
       "67  W:\\Data\\KDIBA\\pin01\\one\\fet11-04_21-20-3\\loade...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "                                   ripple_result_file  \\\n",
       "0   W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\rip...   \n",
       "1   W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\rip...   \n",
       "2   W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\ripp...   \n",
       "3   W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_3-23-37\\ripp...   \n",
       "4   W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\rip...   \n",
       "..                                                ...   \n",
       "67  W:\\Data\\KDIBA\\pin01\\one\\fet11-04_21-20-3\\fet11...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "    has_user_replay_annotations  has_user_grid_bin_bounds_annotations  \n",
       "0                         False                                  True  \n",
       "1                          True                                  True  \n",
       "2                          True                                  True  \n",
       "3                         False                                  True  \n",
       "4                          True                                  True  \n",
       "..                          ...                                   ...  \n",
       "67                        False                                  True  \n",
       "68                        False                                 False  \n",
       "69                        False                                 False  \n",
       "70                        False                                 False  \n",
       "71                        False                                 False  \n",
       "\n",
       "[72 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_global_batch_result_filename=f'global_batch_result_{BATCH_DATE_TO_USE}.pkl'\n",
    "\n",
    "debug_print = False\n",
    "known_global_data_root_parent_paths = [Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/home/halechr/FastData')] # , Path(r'/Volumes/MoverNew/data', Path(r'/home/halechr/FastData'), Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'/home/halechr/turbo/Data'), Path(r'W:\\Data')\n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "## Build Pickle Path:\n",
    "global_batch_result_file_path = Path(global_data_root_parent_path).joinpath(active_global_batch_result_filename).resolve() # Use Default\n",
    "\n",
    "# try to load an existing batch result:\n",
    "global_batch_run = BatchRun.try_init_from_file(global_data_root_parent_path, active_global_batch_result_filename=active_global_batch_result_filename,\n",
    "\t\t\t\t\t\tskip_root_path_conversion=False, debug_print=debug_print) # on_needs_create_callback_fn=run_diba_batch\n",
    "\n",
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "batch_progress_df.batch_results.build_all_columns()\n",
    "good_only_batch_progress_df.batch_results.build_all_columns()\n",
    "batch_progress_df\n",
    "with pd.option_context('display.max_rows', 10, 'display.max_columns', None):  # more options can be specified also\n",
    "    # display(batch_progress_df)\n",
    "    # display(good_only_batch_progress_df)\n",
    "    display(batch_progress_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab824348",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Batch Executions/Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019afbbd-70d2-4e75-9548-b6f22d2e31ca",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>context</th>\n",
       "      <th>basedirs</th>\n",
       "      <th>status</th>\n",
       "      <th>errors</th>\n",
       "      <th>session_datetime</th>\n",
       "      <th>n_long_laps</th>\n",
       "      <th>n_long_replays</th>\n",
       "      <th>n_short_laps</th>\n",
       "      <th>n_short_replays</th>\n",
       "      <th>is_ready</th>\n",
       "      <th>global_computation_result_file</th>\n",
       "      <th>loaded_session_pickle_file</th>\n",
       "      <th>ripple_result_file</th>\n",
       "      <th>has_user_replay_annotations</th>\n",
       "      <th>has_user_grid_bin_bounds_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-12_15-55-31</td>\n",
       "      <td>kdiba_gor01_one_2006-6-12_15-55-31</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-12 15:55:31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\out...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\loa...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\rip...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-07_16-40-19</td>\n",
       "      <td>kdiba_gor01_two_2006-6-07_16-40-19</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-07 16:40:19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\out...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loa...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\rip...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-08_21-16-25</td>\n",
       "      <td>kdiba_gor01_two_2006-6-08_21-16-25</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-08 21:16:25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\out...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\loa...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\rip...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-09_22-24-40</td>\n",
       "      <td>kdiba_gor01_two_2006-6-09_22-24-40</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-09 22:24:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\out...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\loa...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\rip...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-12_16-53-46</td>\n",
       "      <td>kdiba_gor01_two_2006-6-12_16-53-46</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-12 16:53:46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\out...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\loa...</td>\n",
       "      <td>W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\rip...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-4-10_12-58-3</td>\n",
       "      <td>kdiba_vvp01_two_2006-4-10_12-58-3</td>\n",
       "      <td>W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-04-10 12:58:03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\outp...</td>\n",
       "      <td>W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\load...</td>\n",
       "      <td>W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\ripp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-02_17-46-44</td>\n",
       "      <td>kdiba_pin01_one_11-02_17-46-44</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-02 17:46:44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\output\\...</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\loadedS...</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\11-02_1...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-02_19-28-0</td>\n",
       "      <td>kdiba_pin01_one_11-02_19-28-0</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-02 19:28:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\output\\g...</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\loadedSe...</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\11-02_19...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-03_12-3-25</td>\n",
       "      <td>kdiba_pin01_one_11-03_12-3-25</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-03 12:03:25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\output\\g...</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\loadedSe...</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\11-03_12...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>kdiba_pin01_one_fet11-01_12-58-54</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\outp...</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\load...</td>\n",
       "      <td>W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\fet1...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   format_name animal exper_name        session_name  \\\n",
       "4        kdiba  gor01        one  2006-6-12_15-55-31   \n",
       "6        kdiba  gor01        two  2006-6-07_16-40-19   \n",
       "8        kdiba  gor01        two  2006-6-08_21-16-25   \n",
       "9        kdiba  gor01        two  2006-6-09_22-24-40   \n",
       "10       kdiba  gor01        two  2006-6-12_16-53-46   \n",
       "..         ...    ...        ...                 ...   \n",
       "32       kdiba  vvp01        two   2006-4-10_12-58-3   \n",
       "52       kdiba  pin01        one      11-02_17-46-44   \n",
       "53       kdiba  pin01        one       11-02_19-28-0   \n",
       "54       kdiba  pin01        one       11-03_12-3-25   \n",
       "64       kdiba  pin01        one   fet11-01_12-58-54   \n",
       "\n",
       "                               context  \\\n",
       "4   kdiba_gor01_one_2006-6-12_15-55-31   \n",
       "6   kdiba_gor01_two_2006-6-07_16-40-19   \n",
       "8   kdiba_gor01_two_2006-6-08_21-16-25   \n",
       "9   kdiba_gor01_two_2006-6-09_22-24-40   \n",
       "10  kdiba_gor01_two_2006-6-12_16-53-46   \n",
       "..                                 ...   \n",
       "32   kdiba_vvp01_two_2006-4-10_12-58-3   \n",
       "52      kdiba_pin01_one_11-02_17-46-44   \n",
       "53       kdiba_pin01_one_11-02_19-28-0   \n",
       "54       kdiba_pin01_one_11-03_12-3-25   \n",
       "64   kdiba_pin01_one_fet11-01_12-58-54   \n",
       "\n",
       "                                      basedirs  \\\n",
       "4   W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31   \n",
       "6   W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19   \n",
       "8   W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25   \n",
       "9   W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40   \n",
       "10  W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46   \n",
       "..                                         ...   \n",
       "32   W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3   \n",
       "52      W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44   \n",
       "53       W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0   \n",
       "54       W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25   \n",
       "64   W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54   \n",
       "\n",
       "                              status errors    session_datetime  n_long_laps  \\\n",
       "4   SessionBatchProgress.NOT_STARTED   None 2006-06-12 15:55:31            0   \n",
       "6   SessionBatchProgress.NOT_STARTED   None 2006-06-07 16:40:19            0   \n",
       "8   SessionBatchProgress.NOT_STARTED   None 2006-06-08 21:16:25            0   \n",
       "9   SessionBatchProgress.NOT_STARTED   None 2006-06-09 22:24:40            0   \n",
       "10  SessionBatchProgress.NOT_STARTED   None 2006-06-12 16:53:46            0   \n",
       "..                               ...    ...                 ...          ...   \n",
       "32  SessionBatchProgress.NOT_STARTED   None 2006-04-10 12:58:03            0   \n",
       "52  SessionBatchProgress.NOT_STARTED   None 2009-11-02 17:46:44            0   \n",
       "53  SessionBatchProgress.NOT_STARTED   None 2009-11-02 19:28:00            0   \n",
       "54  SessionBatchProgress.NOT_STARTED   None 2009-11-03 12:03:25            0   \n",
       "64  SessionBatchProgress.NOT_STARTED   None 2009-11-01 12:58:54            0   \n",
       "\n",
       "    n_long_replays  n_short_laps  n_short_replays  is_ready  \\\n",
       "4                0             0                0     False   \n",
       "6                0             0                0     False   \n",
       "8                0             0                0     False   \n",
       "9                0             0                0     False   \n",
       "10               0             0                0     False   \n",
       "..             ...           ...              ...       ...   \n",
       "32               0             0                0     False   \n",
       "52               0             0                0     False   \n",
       "53               0             0                0     False   \n",
       "54               0             0                0     False   \n",
       "64               0             0                0     False   \n",
       "\n",
       "                       global_computation_result_file  \\\n",
       "4   W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\out...   \n",
       "6   W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\out...   \n",
       "8   W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\out...   \n",
       "9   W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\out...   \n",
       "10  W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\out...   \n",
       "..                                                ...   \n",
       "32  W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\outp...   \n",
       "52  W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\output\\...   \n",
       "53  W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\output\\g...   \n",
       "54  W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\output\\g...   \n",
       "64  W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\outp...   \n",
       "\n",
       "                           loaded_session_pickle_file  \\\n",
       "4   W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\loa...   \n",
       "6   W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loa...   \n",
       "8   W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\loa...   \n",
       "9   W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\loa...   \n",
       "10  W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\loa...   \n",
       "..                                                ...   \n",
       "32  W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\load...   \n",
       "52  W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\loadedS...   \n",
       "53  W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\loadedSe...   \n",
       "54  W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\loadedSe...   \n",
       "64  W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\load...   \n",
       "\n",
       "                                   ripple_result_file  \\\n",
       "4   W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\rip...   \n",
       "6   W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\rip...   \n",
       "8   W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\rip...   \n",
       "9   W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\rip...   \n",
       "10  W:\\Data\\KDIBA\\gor01\\two\\2006-6-12_16-53-46\\rip...   \n",
       "..                                                ...   \n",
       "32  W:\\Data\\KDIBA\\vvp01\\two\\2006-4-10_12-58-3\\ripp...   \n",
       "52  W:\\Data\\KDIBA\\pin01\\one\\11-02_17-46-44\\11-02_1...   \n",
       "53  W:\\Data\\KDIBA\\pin01\\one\\11-02_19-28-0\\11-02_19...   \n",
       "54  W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25\\11-03_12...   \n",
       "64  W:\\Data\\KDIBA\\pin01\\one\\fet11-01_12-58-54\\fet1...   \n",
       "\n",
       "    has_user_replay_annotations  has_user_grid_bin_bounds_annotations  \n",
       "4                          True                                  True  \n",
       "6                          True                                  True  \n",
       "8                          True                                  True  \n",
       "9                          True                                  True  \n",
       "10                         True                                  True  \n",
       "..                          ...                                   ...  \n",
       "32                         True                                  True  \n",
       "52                         True                                  True  \n",
       "53                         True                                  True  \n",
       "54                         True                                  True  \n",
       "64                         True                                  True  \n",
       "\n",
       "[13 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hardcoded included_session_contexts:\n",
    "included_session_contexts = [\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'), # prev completed\n",
    "]\n",
    "\n",
    "good_session_concrete_folders = ConcreteSessionFolder.build_concrete_session_folders(global_data_root_parent_path, included_session_contexts)\n",
    "good_session_concrete_folders\n",
    "\n",
    "# from pyphoplacecellanalysis.General.Batch.pythonScriptTemplating import generate_batch_single_session_scripts\n",
    "\n",
    "# ## Build Slurm Scripts:\n",
    "# session_basedirs_dict: Dict[IdentifyingContext, Path] = {a_session_folder.context:a_session_folder.path for a_session_folder in good_session_concrete_folders}\n",
    "# included_session_contexts, output_python_scripts, output_slurm_scripts = generate_batch_single_session_scripts(global_data_root_parent_path, session_batch_basedirs=session_basedirs_dict, included_session_contexts=included_session_contexts, output_directory=Path('output/generated_slurm_scripts/').resolve(), use_separate_run_directories=True, should_perform_figure_generation_to_file=True)\n",
    "# display(output_python_scripts)\n",
    "\n",
    "included_session_batch_progress_df = batch_progress_df[np.isin(batch_progress_df['context'].values, included_session_contexts)]\n",
    "with pd.option_context('display.max_rows', 10, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(included_session_batch_progress_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71584edc",
   "metadata": {},
   "source": [
    "# Execute Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab6ae279",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(included_session_contexts): 13\n",
      "Beginning processing with len(included_session_contexts): 13\n",
      "build_batch_task_logger(module_name=\"Apogee.kdiba.gor01.one.2006-6-12_15-55-31\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.Apogee.kdiba.gor01.one.2006-6-12_15-55-31 has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.Apogee.kdiba.gor01.one.2006-6-12_15-55-31.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: W:\\Data\n",
      "\tsession_context: kdiba_gor01_one_2006-6-12_15-55-31\n",
      "\tsession_basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\n",
      "__________________________________________________________________\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\\loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "Applying session filter named \"maze1_odd\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 656.0648088779999)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2_odd\"...\n",
      "Constraining to epoch with times (start: 656.0648088779999, end: 1122.1864874939201)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to includelist, including only 4 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (204660,) should be less than time_window_edges: (1314,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (5338,) should be less than time_window_edges: (1168,)!\n",
      "due to includelist, including only 4 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (141254,) should be less than time_window_edges: (934,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (4980,) should be less than time_window_edges: (759,)!\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "Applying session filter named \"maze1_even\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 656.0648088779999)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2_even\"...\n",
      "Constraining to epoch with times (start: 656.0648088779999, end: 1122.1864874939201)\n",
      "computing neurons mua for session...\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "due to includelist, including only 4 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (204660,) should be less than time_window_edges: (1314,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (5825,) should be less than time_window_edges: (1201,)!\n",
      "due to includelist, including only 4 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\BatchGenerateOutputs_2024-01-09.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/BatchGenerateOutputs_2024-01-09.ipynb#W5sZmlsZQ%3D%3D?line=209'>210</a>\u001b[0m result_handler\u001b[39m.\u001b[39moverride_existing_frs_index_values \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/BatchGenerateOutputs_2024-01-09.ipynb#W5sZmlsZQ%3D%3D?line=212'>213</a>\u001b[0m \u001b[39m## Execute with the custom arguments.\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/BatchGenerateOutputs_2024-01-09.ipynb#W5sZmlsZQ%3D%3D?line=213'>214</a>\u001b[0m global_batch_run\u001b[39m.\u001b[39mexecute_all(force_reload\u001b[39m=\u001b[39mresult_handler\u001b[39m.\u001b[39mforce_reload_all, saving_mode\u001b[39m=\u001b[39mresult_handler\u001b[39m.\u001b[39msaving_mode, skip_extended_batch_computations\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, post_run_callback_fn\u001b[39m=\u001b[39mactive_post_run_callback_fn,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/BatchGenerateOutputs_2024-01-09.ipynb#W5sZmlsZQ%3D%3D?line=214'>215</a>\u001b[0m                              fail_on_exception\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, included_session_contexts\u001b[39m=\u001b[39mincluded_session_contexts,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/BatchGenerateOutputs_2024-01-09.ipynb#W5sZmlsZQ%3D%3D?line=215'>216</a>\u001b[0m                                                                                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mcomputation_functions_name_includelist\u001b[39m\u001b[39m'\u001b[39m: basic_local_computations,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/BatchGenerateOutputs_2024-01-09.ipynb#W5sZmlsZQ%3D%3D?line=216'>217</a>\u001b[0m                                                                                             \u001b[39m'\u001b[39m\u001b[39mactive_session_computation_configs\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/BatchGenerateOutputs_2024-01-09.ipynb#W5sZmlsZQ%3D%3D?line=217'>218</a>\u001b[0m                                                                                             \u001b[39m'\u001b[39m\u001b[39mallow_processing_previously_completed\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m}, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmultiprocessing_kwargs) \u001b[39m# can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/BatchGenerateOutputs_2024-01-09.ipynb#W5sZmlsZQ%3D%3D?line=219'>220</a>\u001b[0m \u001b[39m# 4m 39.8s\u001b[39;00m\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\runBatch.py:415\u001b[0m, in \u001b[0;36mBatchRun.execute_all\u001b[1;34m(self, use_multiprocessing, num_processes, included_session_contexts, session_inclusion_filter, **kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m curr_session_status \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_batch_status[curr_session_context]\n\u001b[0;32m    414\u001b[0m curr_session_basedir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_batch_basedirs[curr_session_context]\n\u001b[1;32m--> 415\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_batch_status[curr_session_context], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_batch_errors[curr_session_context], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_batch_outputs[curr_session_context] \u001b[39m=\u001b[39m run_specific_batch(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_data_root_parent_path, curr_session_context, curr_session_basedir, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\runBatch.py:1155\u001b[0m, in \u001b[0;36mrun_specific_batch\u001b[1;34m(global_data_root_parent_path, curr_session_context, curr_session_basedir, force_reload, post_run_callback_fn, saving_mode, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m debug_print \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mdebug_print\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1154\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1155\u001b[0m     curr_active_pipeline \u001b[39m=\u001b[39m batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist\u001b[39m=\u001b[39mepoch_name_includelist,\n\u001b[0;32m   1156\u001b[0m                                     computation_functions_name_includelist\u001b[39m=\u001b[39mactive_computation_functions_name_includelist,\n\u001b[0;32m   1157\u001b[0m                                     saving_mode\u001b[39m=\u001b[39msaving_mode, force_reload\u001b[39m=\u001b[39mforce_reload, skip_extended_batch_computations\u001b[39m=\u001b[39mskip_extended_batch_computations, debug_print\u001b[39m=\u001b[39mdebug_print, fail_on_exception\u001b[39m=\u001b[39mfail_on_exception, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1159\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1160\u001b[0m     \u001b[39m## can fail here before callback function is even called.\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m     exception_info \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\NonInteractiveProcessing.py:239\u001b[0m, in \u001b[0;36mbatch_load_session\u001b[1;34m(global_data_root_parent_path, active_data_mode_name, basedir, force_reload, saving_mode, fail_on_exception, skip_extended_batch_computations, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m     curr_active_pipeline\u001b[39m.\u001b[39mfilter_sessions(updated_active_session_pseudo_filter_configs, changed_filters_ignore_list\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmaze1\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmaze2\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmaze\u001b[39m\u001b[39m'\u001b[39m], debug_print\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    236\u001b[0m     \u001b[39m## TODO 2023-01-15 - perform_computations for all configs!!\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[39m#TODO 2023-10-31 14:58: - [ ] This is where the computations are being done multiple times!\u001b[39;00m\n\u001b[0;32m    238\u001b[0m     \u001b[39m#TODO 2023-11-13 14:23: - [ ] With this approach, we can't actually properly filter the computation_configs for the relevant sessions ahead of time because they are calculated for a single computation config but across all sessions at once.\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     curr_active_pipeline\u001b[39m.\u001b[39;49mperform_computations(a_computation_config, computation_functions_name_includelist\u001b[39m=\u001b[39;49mcomputation_functions_name_includelist, computation_functions_name_excludelist\u001b[39m=\u001b[39;49mcomputation_functions_name_excludelist, fail_on_exception\u001b[39m=\u001b[39;49mfail_on_exception, debug_print\u001b[39m=\u001b[39;49mdebug_print) \u001b[39m#, overwrite_extant_results=False  ], fail_on_exception=True, debug_print=False)\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_extended_batch_computations:\n\u001b[0;32m    243\u001b[0m     batch_extended_computations(curr_active_pipeline, include_global_functions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, fail_on_exception\u001b[39m=\u001b[39mfail_on_exception, progress_print\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, debug_print\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1047\u001b[0m, in \u001b[0;36mPipelineWithComputedPipelineStageMixin.perform_computations\u001b[1;34m(self, active_computation_params, enabled_filter_names, overwrite_extant_results, computation_functions_name_includelist, computation_functions_name_excludelist, fail_on_exception, debug_print)\u001b[0m\n\u001b[0;32m   1042\u001b[0m progress_logger_callback\u001b[39m=\u001b[39m(\u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(x))\n\u001b[0;32m   1043\u001b[0m \u001b[39m# self.stage.perform_action_for_all_contexts(EvaluationActions.EVALUATE_COMPUTATIONS, enabled_filter_names=enabled_filter_names, active_computation_params=active_computation_params, overwrite_extant_results=overwrite_extant_results,\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[39m#     computation_functions_name_includelist=computation_functions_name_includelist, computation_functions_name_excludelist=computation_functions_name_excludelist, fail_on_exception=fail_on_exception, progress_logger_callback=progress_logger_callback, debug_print=debug_print)\u001b[39;00m\n\u001b[0;32m   1045\u001b[0m \n\u001b[0;32m   1046\u001b[0m \u001b[39m# Calls self.stage's version:\u001b[39;00m\n\u001b[1;32m-> 1047\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstage\u001b[39m.\u001b[39;49mperform_computations(enabled_filter_names\u001b[39m=\u001b[39;49menabled_filter_names, active_computation_params\u001b[39m=\u001b[39;49mactive_computation_params, overwrite_extant_results\u001b[39m=\u001b[39;49moverwrite_extant_results,\n\u001b[0;32m   1048\u001b[0m     computation_functions_name_includelist\u001b[39m=\u001b[39;49mcomputation_functions_name_includelist, computation_functions_name_excludelist\u001b[39m=\u001b[39;49mcomputation_functions_name_excludelist, fail_on_exception\u001b[39m=\u001b[39;49mfail_on_exception, progress_logger_callback\u001b[39m=\u001b[39;49mprogress_logger_callback, debug_print\u001b[39m=\u001b[39;49mdebug_print)\n\u001b[0;32m   1050\u001b[0m \u001b[39m# Global MultiContext computations will be done here:\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m \u001b[39mif\u001b[39;00m progress_logger_callback \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:711\u001b[0m, in \u001b[0;36mComputedPipelineStage.perform_computations\u001b[1;34m(self, active_computation_params, enabled_filter_names, overwrite_extant_results, computation_functions_name_includelist, computation_functions_name_excludelist, fail_on_exception, debug_print, progress_logger_callback)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"The main computation function for the pipeline.\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \n\u001b[0;32m    692\u001b[0m \u001b[39mWraps `perform_action_for_all_contexts`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[39m    factored out of `NeuropyPipeline` for use in GlobalComputationFunctions\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \u001b[39massert\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcan_compute), \u001b[39m\"\u001b[39m\u001b[39mCurrent stage must already be a ComputedPipelineStage. Call self.filter_sessions with filter configs to reach this step.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 711\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mperform_action_for_all_contexts(EvaluationActions\u001b[39m.\u001b[39;49mEVALUATE_COMPUTATIONS, enabled_filter_names\u001b[39m=\u001b[39;49menabled_filter_names, active_computation_params\u001b[39m=\u001b[39;49mactive_computation_params, overwrite_extant_results\u001b[39m=\u001b[39;49moverwrite_extant_results,\n\u001b[0;32m    712\u001b[0m     computation_functions_name_includelist\u001b[39m=\u001b[39;49mcomputation_functions_name_includelist, computation_functions_name_excludelist\u001b[39m=\u001b[39;49mcomputation_functions_name_excludelist, fail_on_exception\u001b[39m=\u001b[39;49mfail_on_exception, progress_logger_callback\u001b[39m=\u001b[39;49mprogress_logger_callback, debug_print\u001b[39m=\u001b[39;49mdebug_print)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:568\u001b[0m, in \u001b[0;36mComputedPipelineStage.perform_action_for_all_contexts\u001b[1;34m(self, action, enabled_filter_names, active_computation_params, overwrite_extant_results, computation_functions_name_includelist, computation_functions_name_excludelist, fail_on_exception, progress_logger_callback, are_global, debug_print)\u001b[0m\n\u001b[0;32m    564\u001b[0m         skip_computations_for_this_result \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    566\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_computations_for_this_result:\n\u001b[0;32m    567\u001b[0m         \u001b[39m# call to perform any registered computations:\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m         active_computation_results[a_select_config_name] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mperform_registered_computations_single_context(active_computation_results[a_select_config_name],\n\u001b[0;32m    569\u001b[0m             computation_functions_name_includelist\u001b[39m=\u001b[39;49mcomputation_functions_name_includelist, computation_functions_name_excludelist\u001b[39m=\u001b[39;49mcomputation_functions_name_excludelist, fail_on_exception\u001b[39m=\u001b[39;49mfail_on_exception, progress_logger_callback\u001b[39m=\u001b[39;49mprogress_logger_callback, are_global\u001b[39m=\u001b[39;49mare_global, debug_print\u001b[39m=\u001b[39;49mdebug_print)\n\u001b[0;32m    571\u001b[0m \u001b[39melif\u001b[39;00m action\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m EvaluationActions\u001b[39m.\u001b[39mRUN_SPECIFIC\u001b[39m.\u001b[39mname:\n\u001b[0;32m    572\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPerforming run_specific_computations_single_context on filtered_session with filter named \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00ma_select_config_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m...\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:311\u001b[0m, in \u001b[0;36mComputedPipelineStage.perform_registered_computations_single_context\u001b[1;34m(self, previous_computation_result, computation_functions_name_includelist, computation_functions_name_excludelist, fail_on_exception, progress_logger_callback, are_global, debug_print)\u001b[0m\n\u001b[0;32m    308\u001b[0m         active_computation_functions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregistered_computation_functions\n\u001b[0;32m    310\u001b[0m \u001b[39m# Perform the computations:\u001b[39;00m\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m ComputedPipelineStage\u001b[39m.\u001b[39;49m_execute_computation_functions(active_computation_functions, previous_computation_result\u001b[39m=\u001b[39;49mprevious_computation_result, fail_on_exception\u001b[39m=\u001b[39;49mfail_on_exception, progress_logger_callback\u001b[39m=\u001b[39;49mprogress_logger_callback, are_global\u001b[39m=\u001b[39;49mare_global, debug_print\u001b[39m=\u001b[39;49mdebug_print)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:791\u001b[0m, in \u001b[0;36mComputedPipelineStage._execute_computation_functions\u001b[1;34m(active_computation_functions, previous_computation_result, computation_kwargs_list, fail_on_exception, progress_logger_callback, are_global, debug_print)\u001b[0m\n\u001b[0;32m    788\u001b[0m     progress_logger_callback(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mExecuting [\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mtotal_num_funcs\u001b[39m}\u001b[39;00m\u001b[39m]: \u001b[39m\u001b[39m{\u001b[39;00mf\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    790\u001b[0m     \u001b[39m# evaluate the function 'f' using the result provided from the previous output or the initial input\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m     temp_result \u001b[39m=\u001b[39m f(previous_computation_result, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcomputation_kwargs_list[i]) \n\u001b[0;32m    792\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m, \u001b[39mNameError\u001b[39;00m, \u001b[39mAttributeError\u001b[39;00m, \u001b[39mKeyError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    793\u001b[0m     exception_info \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldComputations.py:43\u001b[0m, in \u001b[0;36mPlacefieldComputations._perform_baseline_placefield_computation\u001b[1;34m(computation_result, debug_print)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m prev_output_result\n\u001b[0;32m     32\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" \u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39mAccess via:\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m['pf1D']\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39m    active_pf_2D\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m \u001b[39mreturn\u001b[39;00m _initial_placefield_computation(computation_result\u001b[39m.\u001b[39;49msess, computation_result\u001b[39m.\u001b[39;49mcomputation_config\u001b[39m.\u001b[39;49mpf_params, computation_result)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldComputations.py:29\u001b[0m, in \u001b[0;36mPlacefieldComputations._perform_baseline_placefield_computation.<locals>._initial_placefield_computation\u001b[1;34m(active_session, pf_computation_config, prev_output_result)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_initial_placefield_computation\u001b[39m(active_session, pf_computation_config, prev_output_result: ComputationResult):\n\u001b[1;32m---> 29\u001b[0m     prev_output_result\u001b[39m.\u001b[39mcomputed_data[\u001b[39m'\u001b[39m\u001b[39mpf1D\u001b[39m\u001b[39m'\u001b[39m], prev_output_result\u001b[39m.\u001b[39mcomputed_data[\u001b[39m'\u001b[39m\u001b[39mpf2D\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m perform_compute_placefields(active_session\u001b[39m.\u001b[39;49mspikes_df, active_session\u001b[39m.\u001b[39;49mposition, pf_computation_config, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, included_epochs\u001b[39m=\u001b[39;49mpf_computation_config\u001b[39m.\u001b[39;49mcomputation_epochs, should_force_recompute_placefields\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m prev_output_result\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\placefields.py:1686\u001b[0m, in \u001b[0;36mperform_compute_placefields\u001b[1;34m(active_session_spikes_df, active_pos, computation_config, active_epoch_placefields1D, active_epoch_placefields2D, included_epochs, should_force_recompute_placefields, progress_logger)\u001b[0m\n\u001b[0;32m   1684\u001b[0m \u001b[39mif\u001b[39;00m ((active_epoch_placefields1D \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m should_force_recompute_placefields):\n\u001b[0;32m   1685\u001b[0m     progress_logger(\u001b[39m'\u001b[39m\u001b[39mRecomputing active_epoch_placefields...\u001b[39m\u001b[39m'\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1686\u001b[0m     spikes_df \u001b[39m=\u001b[39m deepcopy(active_session_spikes_df)\u001b[39m.\u001b[39;49mspikes\u001b[39m.\u001b[39;49msliced_by_neuron_type(\u001b[39m'\u001b[39;49m\u001b[39mPYRAMIDAL\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m# Only use PYRAMIDAL neurons\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     active_epoch_placefields1D \u001b[39m=\u001b[39m PfND\u001b[39m.\u001b[39mfrom_config_values(spikes_df, deepcopy(active_pos\u001b[39m.\u001b[39mlinear_pos_obj), epochs\u001b[39m=\u001b[39mincluded_epochs,\n\u001b[0;32m   1688\u001b[0m                                       speed_thresh\u001b[39m=\u001b[39mcomputation_config\u001b[39m.\u001b[39mspeed_thresh, frate_thresh\u001b[39m=\u001b[39mcomputation_config\u001b[39m.\u001b[39mfrate_thresh,\n\u001b[0;32m   1689\u001b[0m                                       grid_bin\u001b[39m=\u001b[39mcomputation_config\u001b[39m.\u001b[39mgrid_bin, grid_bin_bounds\u001b[39m=\u001b[39mcomputation_config\u001b[39m.\u001b[39mgrid_bin_bounds, smooth\u001b[39m=\u001b[39mcomputation_config\u001b[39m.\u001b[39msmooth)\n\u001b[0;32m   1691\u001b[0m     progress_logger(\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m done.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\flattened_spiketrains.py:133\u001b[0m, in \u001b[0;36mSpikesAccessor.sliced_by_neuron_type\u001b[1;34m(self, query_neuron_type)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    132\u001b[0m \u001b[39m# Compare via .shortClassName for both query_neuron_type and self._obj.neuron_type\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m inclusion_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misin(np\u001b[39m.\u001b[39marray([a_type\u001b[39m.\u001b[39mshortClassName \u001b[39mfor\u001b[39;00m a_type \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj\u001b[39m.\u001b[39mneuron_type]), [query_neuron_type\u001b[39m.\u001b[39mshortClassName])\n\u001b[0;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj\u001b[39m.\u001b[39mloc[inclusion_mask, :]\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\flattened_spiketrains.py:133\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    132\u001b[0m \u001b[39m# Compare via .shortClassName for both query_neuron_type and self._obj.neuron_type\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m inclusion_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misin(np\u001b[39m.\u001b[39marray([a_type\u001b[39m.\u001b[39;49mshortClassName \u001b[39mfor\u001b[39;00m a_type \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj\u001b[39m.\u001b[39mneuron_type]), [query_neuron_type\u001b[39m.\u001b[39mshortClassName])\n\u001b[0;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj\u001b[39m.\u001b[39mloc[inclusion_mask, :]\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\neuron_identities.py:536\u001b[0m, in \u001b[0;36mNeuronType.shortClassName\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshortClassName\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 536\u001b[0m     \u001b[39mreturn\u001b[39;00m NeuronType\u001b[39m.\u001b[39;49mshortClassNames()[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %pdb on\n",
    "multiprocessing_kwargs = dict(use_multiprocessing=False, num_processes=1)\n",
    "# multiprocessing_kwargs = dict(use_multiprocessing=True, num_processes=5)\n",
    "\n",
    "# Whether to output figures:\n",
    "# should_perform_figure_generation_to_file=False\n",
    "should_perform_figure_generation_to_file=True\n",
    "\n",
    "## Included Session Contexts:\n",
    "# included_session_contexts = batch_progress_df[np.logical_and(batch_progress_df['has_user_replay_annotations'], batch_progress_df['is_ready'])]['context'].to_numpy().tolist()\n",
    "\n",
    "# Only require sessions to have replay annotations:\n",
    "# included_session_contexts = batch_progress_df[batch_progress_df['has_user_replay_annotations']]['context'].to_numpy().tolist()\n",
    "\n",
    "# included_session_contexts = batch_progress_df['context'].to_numpy().tolist()[:4] # Only get the first 6\n",
    "# Limit the contexts to run to the last N:\n",
    "# included_session_contexts = included_session_contexts[3:5]\n",
    "\n",
    "# included_session_contexts = [included_session_contexts[3]]\n",
    "\n",
    "# ALL\n",
    "included_session_contexts = included_session_contexts\n",
    "\n",
    "# ## No filtering the sessions:\n",
    "# included_session_contexts = None\n",
    "\n",
    "if included_session_contexts is not None:\n",
    "    print(f'len(included_session_contexts): {len(included_session_contexts)}')\n",
    "else:\n",
    "    print(f'included_session_contexts is None so all session contexts will be included.')\n",
    "\n",
    "# included_session_contexts\n",
    "\n",
    "# # No recomputing at all:\n",
    "# result_handler = BatchSessionCompletionHandler(force_reload_all=False,\n",
    "#                                                 session_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=False, should_save=SavingOptions.NEVER), # , override_file=\n",
    "#                                                 global_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=False, should_save=SavingOptions.NEVER),\n",
    "#                                                 should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, should_generate_all_plots=True, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_global_recompute=False,\n",
    "#                                                 **multiprocessing_kwargs)\n",
    "\n",
    "# No Reloading\n",
    "result_handler = BatchSessionCompletionHandler(force_reload_all=False,\n",
    "                                                session_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=True, should_save=SavingOptions.IF_CHANGED),\n",
    "                                                global_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=True, should_save=SavingOptions.IF_CHANGED),\n",
    "                                                should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, should_generate_all_plots=True, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_global_recompute=False,\n",
    "                                                force_recompute_override_computations_includelist=['split_to_directional_laps', 'rank_order_shuffle_analysis'],\n",
    "                                                **multiprocessing_kwargs)\n",
    "\n",
    "\n",
    "# # Forced Reloading:\n",
    "# result_handler = BatchSessionCompletionHandler(force_reload_all=True,\n",
    "#                                                 session_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=SavingOptions.ALWAYS),\n",
    "#                                                 global_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=SavingOptions.ALWAYS),\n",
    "#                                                 should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE, force_global_recompute=True,\n",
    "#                                                 **multiprocessing_kwargs)\n",
    "\n",
    "\n",
    "active_post_run_callback_fn = result_handler.on_complete_success_execution_session\n",
    "# active_post_run_callback_fn = _temp_on_complete_success_execution_session\n",
    "\n",
    "def a_test_completion_function(self, global_data_root_parent_path, curr_session_context, curr_session_basedir, curr_active_pipeline, across_session_results_extended_dict: dict) -> dict:\n",
    "    # print(f'>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "    print(f'<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "    print(f'a_test_completion_function(curr_session_context: {curr_session_context}, curr_session_basedir: {str(curr_session_basedir)}, ...,across_session_results_extended_dict: {across_session_results_extended_dict})')\n",
    "    long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalMergedDecodersResult\n",
    "\n",
    "    # curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "    # ## clear the old values to prepare for the new ones:\n",
    "    # curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'] = None\n",
    "    # curr_active_pipeline.global_computation_results.computed_data['RankOrder'] = None\n",
    "    # del curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "    # del curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "\n",
    "    # print(f'\\t trying to compute directional laps')\n",
    "    # curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'] = DirectionalLapsHelpers.build_global_directional_result_from_natural_epochs(curr_active_pipeline, progress_print=True) # repalce the directional laps object\n",
    "    # directional_laps_results = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "\n",
    "    # minimum_inclusion_fr_Hz = 5.0\n",
    "    # included_qclu_values = [1,2]\n",
    "\n",
    "    # # minimum_inclusion_fr_Hz = 1.0\n",
    "    # # included_qclu_values = [1,2,4,9]\n",
    "\n",
    "    # print(f'\\t trying to compute perform_rank_order_shuffle_analysis laps')\n",
    "    # # perform_rank_order_shuffle_analysis\n",
    "    # # with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-perform_rank_order_shuffle_analysis_{curr_active_pipeline.session_name}.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    # RankOrderGlobalComputationFunctions.perform_rank_order_shuffle_analysis(curr_active_pipeline, curr_active_pipeline.global_computation_results, None, None, include_includelist=None, debug_print=True,\n",
    "    #                                                                         num_shuffles=1000, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values, skip_laps=False)\n",
    "\n",
    "    # newly_computed_values = [('maze_all', 'perform_rank_order_shuffle_analysis')]\n",
    "    # print(f'\\tperform_rank_order_shuffle_analysis done.')\n",
    "    \n",
    "    # 2023-11-27 - I'd like to be able to save/load single results a time, (meaning specific to their parameters):\n",
    "    # Unpacking:\n",
    "    directional_laps_results = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "    directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "    \n",
    "    # extract properties:\n",
    "    all_directional_decoder_dict_value = directional_merged_decoders_result.all_directional_decoder_dict\n",
    "    all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "    long_directional_pf1D_Decoder_value = directional_merged_decoders_result.long_directional_pf1D_Decoder\n",
    "    long_directional_decoder_dict_value = directional_merged_decoders_result.long_directional_decoder_dict\n",
    "    short_directional_pf1D_Decoder_value = directional_merged_decoders_result.short_directional_pf1D_Decoder\n",
    "    short_directional_decoder_dict_value = directional_merged_decoders_result.short_directional_decoder_dict\n",
    "\n",
    "    all_directional_laps_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "    all_directional_ripple_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\n",
    "\n",
    "    laps_marginals = DirectionalMergedDecodersResult.determine_directional_likelihoods(directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result)\n",
    "    laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = laps_marginals\n",
    "\n",
    "    # Validate Laps:\n",
    "    # ground_truth_lap_dirs = global_any_laps_epochs_obj.to_dataframe()['lap_dir'].to_numpy()\n",
    "    # n_laps = global_any_laps_epochs_obj.n_epochs\n",
    "    # assert len(laps_most_likely_direction_from_decoder) == n_laps\n",
    "    # percent_laps_estimated_correctly = (np.sum(ground_truth_lap_dirs == laps_most_likely_direction_from_decoder) / n_laps)\n",
    "    # print(f'percent_laps_estimated_correctly: {percent_laps_estimated_correctly}')\n",
    "\n",
    "    long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "    # Unwrap the naturally produced directional placefields:\n",
    "    long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "    # Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "    (long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "    long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "\n",
    "    global_session = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name])\n",
    "    percent_laps_estimated_correctly = DirectionalMergedDecodersResult.validate_lap_dir_estimations(global_session, active_global_laps_df=global_any_laps_epochs_obj.to_dataframe(), laps_is_most_likely_direction_LR_dir=laps_is_most_likely_direction_LR_dir)\n",
    "    print(f'!!!!!!!!! percent_laps_estimated_correctly: {percent_laps_estimated_correctly}\\n\\n')\n",
    "\n",
    "    ## 2023-12-21 - Export to CSV:\n",
    "    spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "    rank_order_results = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "    ripple_result_tuple, laps_result_tuple = rank_order_results.ripple_most_likely_result_tuple, rank_order_results.laps_most_likely_result_tuple\n",
    "    directional_laps_results = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "    track_templates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "    print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "    print(f'included_qclu_values: {included_qclu_values}')\n",
    "\n",
    "    print(f'\\t try saving to CSV...')\n",
    "    merged_complete_epoch_stats_df = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "    \n",
    "    merged_complete_ripple_epoch_stats_df_output_path = curr_active_pipeline.get_output_path().joinpath(f'{BATCH_DATE_TO_USE}_merged_complete_epoch_stats_df.csv').resolve()\n",
    "    merged_complete_epoch_stats_df.to_csv(merged_complete_ripple_epoch_stats_df_output_path)\n",
    "    print(f'\\t saving to CSV: {merged_complete_ripple_epoch_stats_df_output_path} done.')\n",
    "    \n",
    "    # across_session_results_extended_dict['merged_complete_epoch_stats_df'] = merged_complete_ripple_epoch_stats_df_output_path\n",
    "    \n",
    "    ## Saving via pickle:\n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData\n",
    "\n",
    "    print(f'\\t try saving.')\n",
    "    # list = ['2Hz', '12Hz']\n",
    "    directional_laps_output_path = curr_active_pipeline.get_output_path().joinpath(f'DirectionalLaps_5Hz_{BATCH_DATE_TO_USE}.pkl').resolve()\n",
    "    saveData(directional_laps_output_path, (curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'], curr_active_pipeline.global_computation_results.computed_data['RankOrder']))\n",
    "    print(f'\\t saving to {directional_laps_output_path} done.')\n",
    "    \n",
    "    \n",
    "    print(f'>>\\t done with {curr_session_context}')\n",
    "    print(f'>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "    print(f'>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "\n",
    "    # return True\n",
    "    return across_session_results_extended_dict\n",
    "\n",
    "\n",
    "result_handler.completion_functions.append(a_test_completion_function)\n",
    "\n",
    "## Specific Setup for 2023-09-28 Changes to LxC/SxC \"refinements\"\n",
    "result_handler.extended_computations_include_includelist = ['pf_computation', \n",
    "                                                            'pfdt_computation',\n",
    "                                                            'firing_rate_trends',\n",
    "                                                # # 'pf_dt_sequential_surprise',\n",
    "                                                # # 'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                # # 'position_decoding_two_step',\n",
    "                                                'extended_stats',\n",
    "                                                'long_short_decoding_analyses',\n",
    "                                                'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', #, 'long_short_rate_remapping',\n",
    "                                                # 'long_short_inst_spike_rate_groups',\n",
    "                                                # 'long_short_endcap_analysis',\n",
    "                                                # 'spike_burst_detection',\n",
    "                                                'split_to_directional_laps',\n",
    "                                                'merged_directional_placefields',\n",
    "                                                'rank_order_shuffle_analysis'\n",
    "                                                ]\n",
    "\n",
    "\n",
    "basic_local_computations = ['pf_computation', 'pfdt_computation', 'firing_rate_trends',\n",
    "#                                                 'pf_dt_sequential_surprise',\n",
    "                                                # 'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                #'position_decoding_two_step', \n",
    "                                                ]\n",
    " \n",
    "\n",
    "# basic_local_computations = [] # set to empty so we don't overwrite these computations\n",
    "# result_handler.extended_computations_include_includelist = ['split_to_directional_laps', 'rank_order_shuffle_analysis'] # OVERRIDE with specific computations to do\n",
    "\n",
    "\n",
    "# result_handler.enable_hdf5_output = True # output the HDF5 when done.\n",
    "# result_handler.override_existing_frs_index_values = True\n",
    "# result_handler.frs_index_inclusion_magnitude = 0.1\n",
    "\n",
    "result_handler.enable_hdf5_output = False\n",
    "result_handler.override_existing_frs_index_values = False\n",
    "\n",
    "\n",
    "## Execute with the custom arguments.\n",
    "global_batch_run.execute_all(force_reload=result_handler.force_reload_all, saving_mode=result_handler.saving_mode, skip_extended_batch_computations=True, post_run_callback_fn=active_post_run_callback_fn,\n",
    "                             fail_on_exception=False, included_session_contexts=included_session_contexts,\n",
    "                                                                                        **{'computation_functions_name_includelist': basic_local_computations,\n",
    "                                                                                            'active_session_computation_configs': None,\n",
    "                                                                                            'allow_processing_previously_completed': True}, **multiprocessing_kwargs) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 4m 39.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f130e5c9",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Save to pickle:\n",
    "saveData(global_batch_result_file_path, global_batch_run) # Update the global batch run dictionary\n",
    "\n",
    "# Save to HDF5\n",
    "suffix = f'{BATCH_DATE_TO_USE}'\n",
    "## Build Pickle Path:\n",
    "file_path = global_data_root_parent_path.joinpath(f'global_batch_output_{suffix}.h5').resolve()\n",
    "global_batch_run.to_hdf(file_path,'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0981cde1",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "batch_progress_df.batch_results.build_all_columns()\n",
    "good_only_batch_progress_df.batch_results.build_all_columns()\n",
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f140f",
   "metadata": {},
   "source": [
    "# Across Sessions After Batching Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dce885b-5b99-4a7a-9f72-2eed2e45ae18",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_batch_progress_df = included_session_batch_progress_df.copy()\n",
    "\n",
    "good_session_concrete_folders = [ConcreteSessionFolder(a_context, a_basedir) for a_context, a_basedir in zip(list(a_batch_progress_df.context.values), list(a_batch_progress_df.basedirs.values))]\n",
    "\n",
    "# good_only_batch_progress_df.batch_results\n",
    "# included_h5_paths = [get_file_str_if_file_exists(v.joinpath('output','pipeline_results.h5').resolve()) for v in list(good_only_batch_progress_df.basedirs.values)]\n",
    "# included_h5_paths = [a_dir.joinpath('output','pipeline_results.h5').resolve() for a_dir in included_session_batch_progress_df['basedirs']]\n",
    "included_h5_paths = [get_file_str_if_file_exists(v.pipeline_results_h5) for v in good_session_concrete_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39738fa-f8f3-46d2-a937-0fb08c0ccb43",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# target_dir = Path('output/across_session_results/2023-09-29').resolve()\n",
    "# target_dir = Path('/home/halechr/cloud/turbo/Pho/Output/across_session_results/2023-09-29').resolve()\n",
    "# target_dir = Path('/home/halechr/cloud/turbo/Pho/Output/across_session_results/2023-10-03').resolve()\n",
    "# copy_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, target_dir=target_dir)\n",
    "# copy_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, backup_mode=BackupMethods.RenameInSourceDirectory, rename_backup_suffix='2023-10-05', only_include_file_types=['local_pkl', 'global_pkl','h5'])\n",
    "copy_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, backup_mode=BackupMethods.RenameInSourceDirectory, rename_backup_suffix=BATCH_DATE_TO_USE, only_include_file_types=['local_pkl', 'global_pkl'])\n",
    "# copy_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, backup_mode=BackupMethods.RenameInSourceDirectory, rename_backup_suffix='2023-10-07', only_include_file_types=['local_pkl', 'global_pkl','h5'])\n",
    "copy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135cb2d8-65b3-405b-a41b-22b2fa7cb28e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "moved_files_dict_h5_files = copy_movedict(copy_dict)\n",
    "moved_files_dict_h5_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e3954-15a4-449c-b927-56d5d79153c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "moved_files_copydict_output_filename=f'backed_up_files_copydict_{BATCH_DATE_TO_USE}.csv'\n",
    "moved_files_copydict_file_path = Path(global_data_root_parent_path).joinpath(moved_files_copydict_output_filename).resolve() # Use Default\n",
    "print(f'moved_files_copydict_file_path: {moved_files_copydict_file_path}')\n",
    "\n",
    "_out_string, filedict_out_path = save_copydict_to_text_file(moved_files_dict_h5_files, moved_files_copydict_file_path, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab869730",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_moved_files_dict_files = read_copydict_from_text_file(moved_files_copydict_file_path, debug_print=False)\n",
    "read_moved_files_dict_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4671e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_moved_files_dict_files\n",
    "restore_moved_files_dict_files = invert_filedict(read_moved_files_dict_files)\n",
    "restore_moved_files_dict_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d067d8f2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "check_output_h5_files(included_h5_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb0953",
   "metadata": {},
   "source": [
    "## Extract `across_sessions_instantaneous_fr_dict` from the computation outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39691fe2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Somewhere in there there are `InstantaneousSpikeRateGroupsComputation` results to extract\n",
    "across_sessions_instantaneous_fr_dict = {} # InstantaneousSpikeRateGroupsComputation\n",
    "across_sessions_recomputed_instantaneous_fr_dict = {}\n",
    "\n",
    "# Get only the sessions with non-None results\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "good_session_batch_outputs = {a_ctxt:a_result for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None}\n",
    "\n",
    "for a_ctxt, a_result in good_session_batch_outputs.items():\n",
    "    if a_result is not None:\n",
    "        # a_good_result = a_result.__dict__.get('across_sessions_batch_results', {}).get('inst_fr_comps', None)\n",
    "        a_good_result = a_result.across_session_results.get('inst_fr_comps', None)\n",
    "        if a_good_result is not None:\n",
    "            across_sessions_instantaneous_fr_dict[a_ctxt] = a_good_result\n",
    "            # print(a_result['across_sessions_batch_results']['inst_fr_comps'])\n",
    "        a_good_recomp_result = a_result.across_session_results.get('recomputed_inst_fr_comps', None)\n",
    "        if a_good_recomp_result is not None:\n",
    "            across_sessions_recomputed_instantaneous_fr_dict[a_ctxt] = a_good_recomp_result\n",
    "            \n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "\n",
    "\n",
    "## Outputs: across_sessions_instantaneous_fr_dict, across_sessions_recomputed_instantaneous_fr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb9efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "across_sessions_recomputed_instantaneous_fr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09136799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When done, `result_handler.across_sessions_instantaneous_fr_dict` is now equivalent to what it would have been before. It can be saved using the normal `.save_across_sessions_data(...)`\n",
    "\n",
    "## Save the instantaneous firing rate results dict: (# Dict[IdentifyingContext] = InstantaneousSpikeRateGroupsComputation)\n",
    "# AcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_instantaneous_fr_dict, global_data_root_parent_path=global_data_root_parent_path,\n",
    "#                                                  inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl')\n",
    "\n",
    "across_session_result_long_short_recomputed_inst_firing_rate_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "\n",
    "AcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_recomputed_instantaneous_fr_dict, global_data_root_parent_path=global_data_root_parent_path,\n",
    "                                                 inst_fr_output_filename=across_session_result_long_short_recomputed_inst_firing_rate_filename)\n",
    "\n",
    "\n",
    "\n",
    "# ## Save pickle:\n",
    "# inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "# global_batch_result_inst_fr_file_path = Path(global_data_root_parent_path).joinpath(inst_fr_output_filename).resolve() # Use Default\n",
    "# print(f'global_batch_result_inst_fr_file_path: {global_batch_result_inst_fr_file_path}')\n",
    "# # Save the all sessions instantaneous firing rate dict to the path:\n",
    "# saveData(global_batch_result_inst_fr_file_path, across_sessions_instantaneous_fr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c123baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    "\n",
    "# neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_all_known_tables(included_session_contexts, included_h5_paths, should_restore_native_column_types=True, )\n",
    "\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_and_save_all_combined_tables(included_session_contexts, included_h5_paths, override_output_parent_path=global_data_root_parent_path, output_path_suffix=f'{BATCH_DATE_TO_USE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a859bff-8cdb-4281-a64f-251d24db7cb9",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    "\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_all_known_tables(included_session_contexts, included_h5_paths, should_restore_native_column_types=True)\n",
    "# neuron_replay_stats_table['is_refined_LxC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b2430-c9ec-4adb-81a8-1ffbf8a0cb3c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "long_short_fr_indicies_analysis_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95013ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_identities_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ced5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(neuron_replay_stats_table['is_refined_LxC'])\n",
    "# np.isnan(neuron_replay_stats_table['is_refined_LxC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8615ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "session_identifier_key: str = 'session_name'\n",
    "# session_identifier_key: str = 'session_datetime'\n",
    "\n",
    "## !IMPORTANT! Count of the fields of interest using .value_counts(...) and converting to an explicit pd.DataFrame:\n",
    "# _out_value_counts_df: pd.DataFrame = neuron_replay_stats_table.value_counts(subset=['format_name', 'animal', 'session_name', 'session_datetime','track_membership'], normalize=False, sort=False, ascending=True, dropna=True).reset_index()\n",
    "# _out_value_counts_df.columns = ['format_name', 'animal', 'session_name', 'session_datetime', 'track_membership', 'count']\n",
    "_out_value_counts_df: pd.DataFrame = neuron_replay_stats_table.value_counts(subset=['format_name', 'animal', 'session_name', 'session_datetime','track_membership','is_refined_LxC', 'is_refined_SxC'], normalize=False, sort=False, ascending=True, dropna=True).reset_index()\n",
    "_out_value_counts_df.columns = ['format_name', 'animal', 'session_name', 'session_datetime', 'track_membership', 'is_refined_LxC', 'is_refined_SxC', 'count']\n",
    "_out_value_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af57298",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the time of the first session for each animal:\n",
    "first_session_time  = _out_value_counts_df.groupby(['animal']).agg(session_datetime_first=('session_datetime', 'first')).reset_index()\n",
    "\n",
    "## Subtract this initial time from all of the 'session_datetime' entries for each animal:\n",
    "# Merge the first session time back into the original DataFrame\n",
    "merged_df = pd.merge(_out_value_counts_df, first_session_time, on='animal')\n",
    "\n",
    "# Subtract this initial time from all of the 'session_datetime' entries for each animal\n",
    "merged_df['time_since_first_session'] = merged_df['session_datetime'] - merged_df['session_datetime_first']\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25bb1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "point_size = 8\n",
    "df = _out_value_counts_df.copy()\n",
    "animals = df['animal'].unique()\n",
    "track_memberships = df['track_membership'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(animals), figsize=(15, 5))\n",
    "\n",
    "for i, animal in enumerate(animals):\n",
    "\tax = axes[i]\n",
    "\tsubset_df = df[df['animal'] == animal]\n",
    "\t\n",
    "\tfor track_membership in track_memberships:\n",
    "\t\ttrack_subset_df = subset_df[subset_df['track_membership'] == track_membership]\n",
    "\t\tax.plot(track_subset_df['session_datetime'], track_subset_df['count'], label=f'Track: {track_membership}')\n",
    "\t\tax.scatter(track_subset_df['session_datetime'], track_subset_df['count'], s=point_size)\n",
    "\t\t\n",
    "\tax.set_title(f'Animal: {animal}')\n",
    "\tax.set_xlabel('Session Datetime')\n",
    "\tax.set_ylabel('Count')\n",
    "\tax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94408ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_value_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784fcc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## See if the number of cells decreases over re-exposures to the track\n",
    "df = _out_value_counts_df[_out_value_counts_df['animal'] == 'gor01']\n",
    "# df = _out_value_counts_df[_out_value_counts_df['animal'] == 'pin01']\n",
    "# df = _out_value_counts_df[_out_value_counts_df['animal'] == 'vvp01']\n",
    "\n",
    "# Sort by column: 'session_datetime' (ascending)\n",
    "df = df.sort_values(['session_datetime'])\n",
    "\n",
    "'LEFT_ONLY'\n",
    "\n",
    "# df.to_clipboard(index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a502f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the number of cells in each session of the animal:\n",
    "num_LxCs = df[df['track_membership'] == 'LEFT_ONLY']['count'].to_numpy()\n",
    "num_Shared = df[df['track_membership'] == 'SHARED']['count'].to_numpy()\n",
    "num_SxCs = df[df['track_membership'] == 'RIGHT_ONLY']['count'].to_numpy()\n",
    "\n",
    "num_TotalCs = num_LxCs + num_Shared + num_SxCs\n",
    "num_TotalCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The only safe point to align each session to is the switchpoint (the delta):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046bbce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each session can be expressed in terms of time from the start of the first session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f99ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "\n",
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=num_sessions, save_figure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc1ac7-5771-4cd5-94c6-7a6244eb8217",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "source": [
    "## Extract output files from all completed sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb0cd9-3e60-4425-9351-dfc903f3f067",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphocorehelpers.Filesystem.path_helpers import convert_filelist_to_new_parent\n",
    "\n",
    "def save_filelist_to_text_file(hdf5_output_paths, filelist_path: Path):\n",
    "    _out_string = '\\n'.join([str(a_file) for a_file in hdf5_output_paths])\n",
    "    print(f'{_out_string}')\n",
    "    print(f'saving out to \"{filelist_path}\"...')\n",
    "    with open(filelist_path, 'w') as f:\n",
    "        f.write(_out_string)\n",
    "    return _out_string, filelist_path\n",
    "\n",
    "# Save output filelist:\n",
    "\n",
    "# '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5'\n",
    "\n",
    "# kdiba_vvp01_two_2006-4-10_12-58-3\n",
    "# \toutputs_local ={'pkl': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl')}\n",
    "# \toutputs_global ={'pkl': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl'), 'hdf5': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5')}\n",
    "session_identifiers, pkl_output_paths, hdf5_output_paths = global_batch_run.build_output_files_lists()\n",
    "\n",
    "h5_filelist_path = global_data_root_parent_path.joinpath(f'fileList_Greatlakes_HDF5_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, src_filelist_HDF5_savepath = save_filelist_to_text_file(hdf5_output_paths, h5_filelist_path)\n",
    "\n",
    "pkls_filelist_path = global_data_root_parent_path.joinpath(f'fileList_Greatlakes_pkls_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, src_filelist_pkls_savepath = save_filelist_to_text_file(pkl_output_paths, pkls_filelist_path)\n",
    "\n",
    "# source_parent_path = Path(r'/media/MAX/cloud/turbo/Data')\n",
    "source_parent_path = Path(r'/nfs/turbo/umms-kdiba/Data')\n",
    "dest_parent_path = Path(r'/~/W/Data/')\n",
    "# # Build the destination filelist from the source_filelist and the two paths:\n",
    "filelist_source = hdf5_output_paths\n",
    "filelist_dest_paths = convert_filelist_to_new_parent(filelist_source, original_parent_path=source_parent_path, dest_parent_path=dest_parent_path)\n",
    "filelist_dest_paths\n",
    "\n",
    "dest_Apogee_h5_filelist_path = global_data_root_parent_path.joinpath(f'dest_fileList_Apogee_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, dest_filelist_savepath = save_filelist_to_text_file(filelist_dest_paths, dest_Apogee_h5_filelist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e69a3",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult\n",
    "from neuropy.core.epoch import Epoch\n",
    "\n",
    "# Save to HDF5\n",
    "suffix = f'{BATCH_DATE_TO_USE}'\n",
    "## Build Pickle Path:\n",
    "file_path = global_data_root_parent_path.joinpath(f'global_batch_output_{suffix}.h5').resolve()\n",
    "file_path\n",
    "global_batch_run.to_hdf(file_path,'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ce774-98fb-4e69-a7e2-e94cbff1b0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get only the sessions with non-None results\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "\n",
    "# list(global_batch_run.session_batch_outputs.keys())\n",
    "\n",
    "# Somewhere in there there are `InstantaneousSpikeRateGroupsComputation` results to extract\n",
    "across_sessions_instantaneous_fr_dict = {} # InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "# good_session_batch_outputs = global_batch_run.session_batch_outputs\n",
    "\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "good_session_batch_outputs = {a_ctxt:a_result for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None}\n",
    "\n",
    "for a_ctxt, a_result in good_session_batch_outputs.items():\n",
    "    if a_result is not None:\n",
    "        # a_good_result = a_result.__dict__.get('across_sessions_batch_results', {}).get('inst_fr_comps', None)\n",
    "        a_good_result = a_result.across_session_results.get('inst_fr_comps', None)\n",
    "        if a_good_result is not None:\n",
    "            across_sessions_instantaneous_fr_dict[a_ctxt] = a_good_result\n",
    "            # print(a_result['across_sessions_batch_results']['inst_fr_comps'])\n",
    "            \n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "\n",
    "# When done, `result_handler.across_sessions_instantaneous_fr_dict` is now equivalent to what it would have been before. It can be saved using the normal `.save_across_sessions_data(...)`\n",
    "\n",
    "## Save the instantaneous firing rate results dict: (# Dict[IdentifyingContext] = InstantaneousSpikeRateGroupsComputation)\n",
    "AcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_instantaneous_fr_dict, global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl')\n",
    "\n",
    "# ## Save pickle:\n",
    "# inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "# global_batch_result_inst_fr_file_path = Path(global_data_root_parent_path).joinpath(inst_fr_output_filename).resolve() # Use Default\n",
    "# print(f'global_batch_result_inst_fr_file_path: {global_batch_result_inst_fr_file_path}')\n",
    "# # Save the all sessions instantaneous firing rate dict to the path:\n",
    "# saveData(global_batch_result_inst_fr_file_path, across_sessions_instantaneous_fr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d19a7-5a89-43f1-aa33-3a7450d1f965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "across_sessions_instantaneous_fr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e178426c-54df-47ac-8103-a66f114c77e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[a_ctxt.get_initialization_code_string() for a_ctxt in sessions_with_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28828512",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056d9a7",
   "metadata": {},
   "source": [
    "# 2023-10-06 - `joined_neruon_fri_df` loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_DATE_TO_USE = '2023-10-05_NewParameters'\n",
    "BATCH_DATE_TO_USE = '2023-10-07'\n",
    "all_sessions_joined_neruon_fri_df, out_path = build_and_merge_all_sessions_joined_neruon_fri_df(global_data_root_parent_path, BATCH_DATE_TO_USE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb893bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joined_neruon_fri_df_basename = f'{BATCH_DATE_TO_USE}_{output_file_prefix}_joined_neruon_fri_df'\n",
    "AcrossSessionTables.write_table_to_files(joined_neruon_fri_df, global_data_root_parent_path=global_data_root_parent_path, output_basename=joined_neruon_fri_df_basename, include_csv=False)\n",
    "print(f'>>\\t done with {output_file_prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c4c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be651cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2023-10-04 - Load Saved across-sessions-data and testing Batch-computed inst_firing_rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "# from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "# from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import list_of_dicts_to_dict_of_lists\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34549c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the saved across-session results:\n",
    "# inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "# inst_fr_output_filename = 'across_session_result_long_short_inst_firing_rate.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-07-21.pkl'\n",
    "# inst_fr_output_filename=f'across_session_result_handler_{BATCH_DATE_TO_USE}.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-08-09_Test.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-10-04-GL.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_recomputed_inst_firing_rate_2023-10-04-GL-Recomp.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_recomputed_inst_firing_rate_2023-10-07.pkl'\n",
    "inst_fr_output_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abea5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    " \n",
    "## Load all across-session tables from the pickles:\n",
    "# output_path_suffix: str = f'2023-10-07'\n",
    "output_path_suffix: str = f'{BATCH_DATE_TO_USE}'\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.load_all_combined_tables(override_output_parent_path=global_data_root_parent_path, output_path_suffix=output_path_suffix) # output_path_suffix=f'2023-10-04-GL-Recomp'\n",
    "num_sessions = len(neuron_replay_stats_table.session_uid.unique().to_numpy())\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ef2a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ac006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager, SessionCellExclusivityRecord\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "\n",
    "annotation_man = UserAnnotationsManager()\n",
    "\n",
    "LxC_uids = []\n",
    "SxC_uids = []\n",
    "\n",
    "for a_ctxt in included_session_contexts:\n",
    "\tsession_uid = a_ctxt.get_description(separator=\"|\", include_property_names=False)\n",
    "\tsession_uid\n",
    "\tsession_cell_exclusivity: SessionCellExclusivityRecord = annotation_man.annotations[a_ctxt].get('session_cell_exclusivity', None)\n",
    "\tLxC_uids.extend([f\"{session_uid}|{aclu}\" for aclu in session_cell_exclusivity.LxC])\n",
    "\tSxC_uids.extend([f\"{session_uid}|{aclu}\" for aclu in session_cell_exclusivity.SxC])\n",
    "\t\n",
    "# [a_ctxt.get_description(separator=\"|\", include_property_names=False) for a_ctxt in included_session_contexts]\n",
    "\n",
    "long_short_fr_indicies_analysis_table['XxC_status'] = 'Shared'\n",
    "long_short_fr_indicies_analysis_table.loc[np.isin(long_short_fr_indicies_analysis_table.neuron_uid, LxC_uids), 'XxC_status'] = 'LxC'\n",
    "long_short_fr_indicies_analysis_table.loc[np.isin(long_short_fr_indicies_analysis_table.neuron_uid, SxC_uids), 'XxC_status'] = 'SxC'\n",
    "\n",
    "long_short_fr_indicies_analysis_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df97ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-10-11 - Get the long peak location\n",
    "\n",
    "long_short_fr_indicies_analysis_table['long_pf_peak_x'] = neuron_replay_stats_table['long_pf_peak_x']\n",
    "long_short_fr_indicies_analysis_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1641aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "long_short_fr_indicies_analysis_table.plot.scatter(x='long_pf_peak_x', y='x_frs_index', title='Pf Peak position vs. LapsFRI', ylabel='Lap FRI')\n",
    "\n",
    "long_short_fr_indicies_analysis_table.plot.scatter(x='long_pf_peak_x', y='y_frs_index', title='Pf Peak position vs. ReplayFRI', ylabel='Replay FRI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9987dc",
   "metadata": {},
   "source": [
    " #TODO 2023-10-05 11:40: - [ ] Extract the \"contrarian cells\", the ones that have a strong exclusivity on the laps but the opposite tendency on the replays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_short_fr_indicies_analysis_table_filename = 'output/2023-10-07_long_short_fr_indicies_analysis_table.csv'\n",
    "long_short_fr_indicies_analysis_table_filename: str = 'output/{BATCH_DATE_TO_USE}_long_short_fr_indicies_analysis_table.csv'\n",
    "long_short_fr_indicies_analysis_table.to_csv(long_short_fr_indicies_analysis_table_filename)\n",
    "print(f'saved: {long_short_fr_indicies_analysis_table_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1427597f",
   "metadata": {},
   "source": [
    "# 2023-10-10 - Statistics for `across_sessions_bar_graphs`, analysing `across_session_inst_fr_computation` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33422d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import pho_stats_perform_diagonal_line_binomial_test, pho_stats_bar_graph_t_tests\n",
    "\n",
    "binom_test_chance_result = pho_stats_perform_diagonal_line_binomial_test(long_short_fr_indicies_analysis_table)\n",
    "print(f'binom_test_chance_result: {binom_test_chance_result}')\n",
    "\n",
    "LxC_Laps_T_result, SxC_Laps_T_result, LxC_Replay_T_result, SxC_Replay_T_result = pho_stats_bar_graph_t_tests(across_session_inst_fr_computation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24ea5a5",
   "metadata": {},
   "source": [
    "## 2023-10-04 - Run `AcrossSessionsVisualizations` corresponding to the PhoDibaPaper2023 figures for all sessions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1152c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Hacks the `PaperFigureTwo` and `InstantaneousSpikeRateGroupsComputation` \n",
    "global_multi_session_context, _out_aggregate_fig_2 = AcrossSessionsVisualizations.across_sessions_bar_graphs(across_session_inst_fr_computation, num_sessions, enable_tiny_point_labels=False, enable_hover_labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c437e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "\n",
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=num_sessions, save_figure=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_long_and_short_firing_rate_replays_v_laps_figure(neuron_replay_stats_table=neuron_replay_stats_table, num_sessions=num_sessions, save_figure=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_man = UserAnnotationsManager()\n",
    "included_annotations = {ctxt:ann_man.annotations[ctxt].get('session_cell_exclusivity', None) for ctxt in included_session_contexts}\n",
    "\n",
    "all_LxCs = []\n",
    "all_SxCs = []\n",
    "\n",
    "for ctxt, an_ann in included_annotations.items():\n",
    "\tsession_ctxt_key:str = ctxt.get_description(separator='|', subset_includelist=IdentifyingContext._get_session_context_keys())\n",
    "\tall_LxCs.extend([f\"{session_ctxt_key}|{aclu}\" for aclu in an_ann.LxC])\n",
    "\tall_SxCs.extend([f\"{session_ctxt_key}|{aclu}\" for aclu in an_ann.SxC])\n",
    "\t\n",
    "all_LxCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1222a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_SxCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381fcf5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "across_session_inst_fr_computation.LxC_scatter_props\n",
    "across_session_inst_fr_computation.SxC_scatter_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63258151",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=num_sessions) # some global context across all of the sessions, not sure what to put here.\n",
    "\n",
    "# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\n",
    "\n",
    "## Display the aggregate across sessions:\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn't save this info\n",
    "_out_fig_2.computation_result = across_session_inst_fr_computation # the result loaded from the file\n",
    "_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\n",
    "# Set callback, the only self-specific property\n",
    "# _out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)\n",
    "_out_fig_2.scatter_props_fn = _return_scatter_props_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LxC_aclus = _out_fig_2.computation_result.LxC_aclus\n",
    "SxC_aclus = _out_fig_2.computation_result.SxC_aclus\n",
    "\n",
    "LxC_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c498f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureOutputManager, FigureOutputLocation, ContextToPathMode\n",
    "\n",
    "registered_output_files = {}\n",
    "\n",
    "def output_figure(final_context: IdentifyingContext, fig, write_vector_format:bool=False, write_png:bool=True, debug_print=True):\n",
    "    \"\"\" outputs the figure using the provided context. \"\"\"\n",
    "    from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_and_write_to_file\n",
    "    def register_output_file(output_path, output_metadata=None):\n",
    "        \"\"\" registers a new output file for the pipeline \"\"\"\n",
    "        print(f'register_output_file(output_path: {output_path}, ...)')\n",
    "        registered_output_files[output_path] = output_metadata or {}\n",
    "\n",
    "    fig_out_man = FigureOutputManager(figure_output_location=FigureOutputLocation.DAILY_PROGRAMMATIC_OUTPUT_FOLDER, context_to_path_mode=ContextToPathMode.HIERARCHY_UNIQUE)\n",
    "    active_out_figure_paths = build_and_write_to_file(fig, final_context, fig_out_man, write_vector_format=write_vector_format, write_png=write_png, register_output_file_fn=register_output_file)\n",
    "    return active_out_figure_paths, final_context\n",
    "\n",
    "\n",
    "# Set callback, the only self-specific property\n",
    "_out_fig_2._pipeline_file_callback_fn = output_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\n",
    "\t\n",
    "_out_fig_2.perform_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96ed659",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-10-11 - Surprise Shuffling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d829b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a87449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike3d-poetry",
   "language": "python",
   "name": "spike3d-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
