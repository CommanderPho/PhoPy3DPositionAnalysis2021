{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import neptune # for logging progress and results\n",
    "from pyphoplacecellanalysis.General.Batch.NeptuneAiHelpers import set_environment_variables, neptune_output_figures\n",
    "neptune_kwargs = {'project':\"commander.pho/PhoDibaLongShort2023\",\n",
    "'api_token':\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGIxODU2My1lZTNhLTQ2ZWMtOTkzNS02ZTRmNzM5YmNjNjIifQ==\"}\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from attrs import define, field, fields, Factory\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "\n",
    "from pyphocorehelpers.print_helpers import generate_html_string\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "\n",
    "# Plotting\n",
    "import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: /media/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43\n",
      "Loading loaded session pickle file results : /media/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl... done.\n",
      "Failure loading /media/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl, the file is corrupted and incomplete (REACHED END OF FILE).\n",
      "\t deleting it and continuing. \n",
      "\t /media/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl deleted.\n",
      "Loading matlab import file results : /media/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.epochs_info.mat... done.\n",
      "Loading matlab import file results : /media/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat... done.\n",
      "Loading matlab import file results : /media/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.spikes.mat... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repo/NeuroPy/neuropy/core/session/Formats/SessionSpecifications.py:140: UserWarning: WARNING: Optional File: /media/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.dat does not exist. Continuing without it.\n",
      "  warnings.warn(f'WARNING: Optional File: {an_optional_filepath} does not exist. Continuing without it.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : /media/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position.npy... 2006-6-09_1-22-43.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : /media/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.interpolated_spike_positions.npy... 2006-6-09_1-22-43.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : /media/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : /media/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.replay_info.mat... done.\n",
      "session.replays loaded successfully!\n",
      "Loading success: /media/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/ripple_df.pkl.\n",
      "Failure loading .mua.npy. Must recompute.\n",
      "\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : /media/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.mua.npy... 2006-6-09_1-22-43.mua.npy saved\n",
      "done.\n",
      "Failure loading .pbe.npy. Must recompute.\n",
      "\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : /media/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.pbe.npy... 2006-6-09_1-22-43.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "sane_midpoint_x: 140.4096393106238, hardcoded_track_midpoint_x: None, track_min_max_x: (20.53900014070859, 260.280278480539)\n",
      "hardcoded_track_midpoint_x is None, falling back to sane_midpoint_x... 140.4096393106238\n",
      "desc_crossings_x: (43,), asc_crossings_x: (43,)\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 75\u001b[0m\n\u001b[1;32m     62\u001b[0m active_computation_functions_name_includelist\u001b[39m=\u001b[39m[\u001b[39m#'_perform_estimated_epochs_computation',  # AL:WAYS OFF\u001b[39;00m\n\u001b[1;32m     63\u001b[0m                                             \u001b[39m'\u001b[39m\u001b[39m_perform_baseline_placefield_computation\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     64\u001b[0m                                         \u001b[39m# '_perform_time_dependent_placefield_computation', # AL:WAYS OFF\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m                                         \u001b[39m# '_perform_recursive_latent_placefield_decoding' # AL:WAYS OFF\u001b[39;00m\n\u001b[1;32m     72\u001b[0m                                     ]\n\u001b[1;32m     73\u001b[0m \u001b[39m# active_computation_functions_name_includelist=['_perform_baseline_placefield_computation']\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m curr_active_pipeline \u001b[39m=\u001b[39m batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist\u001b[39m=\u001b[39;49mepoch_name_includelist,\n\u001b[1;32m     76\u001b[0m                                         computation_functions_name_includelist\u001b[39m=\u001b[39;49mactive_computation_functions_name_includelist,\n\u001b[1;32m     77\u001b[0m                                         saving_mode\u001b[39m=\u001b[39;49msaving_mode, force_reload\u001b[39m=\u001b[39;49mforce_reload,\n\u001b[1;32m     78\u001b[0m                                         skip_extended_batch_computations\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, debug_print\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, fail_on_exception\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \u001b[39m# , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m force_reload: \u001b[39m# not just force_reload, needs to recompute whenever the computation fails.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/repo/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/NonInteractiveProcessing.py:186\u001b[0m, in \u001b[0;36mbatch_load_session\u001b[0;34m(global_data_root_parent_path, active_data_mode_name, basedir, force_reload, saving_mode, fail_on_exception, skip_extended_batch_computations, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m active_data_mode_type_properties \u001b[39m=\u001b[39m known_data_session_type_properties_dict[active_data_mode_name]\n\u001b[1;32m    185\u001b[0m \u001b[39m## Begin main run of the pipeline (load or execute):\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m curr_active_pipeline \u001b[39m=\u001b[39m NeuropyPipeline\u001b[39m.\u001b[39;49mtry_init_from_saved_pickle_or_reload_if_needed(active_data_mode_name, active_data_mode_type_properties,\n\u001b[1;32m    187\u001b[0m     override_basepath\u001b[39m=\u001b[39;49mPath(basedir), force_reload\u001b[39m=\u001b[39;49mforce_reload, active_pickle_filename\u001b[39m=\u001b[39;49mactive_pickle_filename, skip_save_on_initial_load\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    189\u001b[0m was_loaded_from_file: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m  curr_active_pipeline\u001b[39m.\u001b[39mhas_associated_pickle \u001b[39m# True if pipeline was loaded from an existing file, False if it was created fresh\u001b[39;00m\n\u001b[1;32m    192\u001b[0m active_session_filter_configurations \u001b[39m=\u001b[39m active_data_mode_registered_class\u001b[39m.\u001b[39mbuild_default_filter_functions(sess\u001b[39m=\u001b[39mcurr_active_pipeline\u001b[39m.\u001b[39msess, epoch_name_includelist\u001b[39m=\u001b[39mepoch_name_includelist) \u001b[39m# build_filters_pyramidal_epochs(sess=curr_kdiba_pipeline.sess)\u001b[39;00m\n",
      "File \u001b[0;32m~/repo/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/NeuropyPipeline.py:281\u001b[0m, in \u001b[0;36mNeuropyPipeline.try_init_from_saved_pickle_or_reload_if_needed\u001b[0;34m(cls, type_name, known_type_properties, override_basepath, override_post_load_functions, force_reload, active_pickle_filename, skip_save_on_initial_load, progress_print, debug_print)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m debug_print:\n\u001b[1;32m    280\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMust reload/rebuild.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 281\u001b[0m curr_active_pipeline \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49minit_from_known_data_session_type(type_name, known_type_properties, override_basepath\u001b[39m=\u001b[39;49mPath(basepath), override_post_load_functions\u001b[39m=\u001b[39;49mpost_load_functions)\n\u001b[1;32m    282\u001b[0m \u001b[39m# Save reloaded pipeline out to pickle for future loading\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_save_on_initial_load:\n",
      "File \u001b[0;32m~/repo/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/NeuropyPipeline.py:152\u001b[0m, in \u001b[0;36mNeuropyPipeline.init_from_known_data_session_type\u001b[0;34m(cls, type_name, known_type_properties, override_basepath, override_post_load_functions)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     post_load_functions \u001b[39m=\u001b[39m known_type_properties\u001b[39m.\u001b[39mpost_load_functions\n\u001b[0;32m--> 152\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(name\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mtype_name\u001b[39m}\u001b[39;49;00m\u001b[39m_pipeline\u001b[39;49m\u001b[39m'\u001b[39;49m, session_data_type\u001b[39m=\u001b[39;49mtype_name, basedir\u001b[39m=\u001b[39;49mbasepath,\n\u001b[1;32m    153\u001b[0m     load_function\u001b[39m=\u001b[39;49mknown_type_properties\u001b[39m.\u001b[39;49mload_function, post_load_functions\u001b[39m=\u001b[39;49mpost_load_functions)\n",
      "File \u001b[0;32m~/repo/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/NeuropyPipeline.py:133\u001b[0m, in \u001b[0;36mNeuropyPipeline.__init__\u001b[0;34m(self, name, session_data_type, basedir, load_function, post_load_functions, parent, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_registered_output_files \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m# for RegisteredOutputsMixin\u001b[39;00m\n\u001b[1;32m    132\u001b[0m _stage_changed_connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigStageChanged\u001b[39m.\u001b[39mconnect(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_stage_changed)\n\u001b[0;32m--> 133\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_input(name\u001b[39m=\u001b[39;49mname, session_data_type\u001b[39m=\u001b[39;49msession_data_type, basedir\u001b[39m=\u001b[39;49mbasedir, load_function\u001b[39m=\u001b[39;49mload_function, post_load_functions\u001b[39m=\u001b[39;49mpost_load_functions)\n",
      "File \u001b[0;32m~/repo/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Loading.py:226\u001b[0m, in \u001b[0;36mPipelineWithInputStage.set_input\u001b[0;34m(self, session_data_type, basedir, load_function, post_load_functions, auto_load, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstage \u001b[39m=\u001b[39m InputPipelineStage(\n\u001b[1;32m    220\u001b[0m     stage_name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline_name\u001b[39m}\u001b[39;00m\u001b[39m_input\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m     basedir\u001b[39m=\u001b[39mactive_basedir,\n\u001b[1;32m    222\u001b[0m     load_function\u001b[39m=\u001b[39mload_function,\n\u001b[1;32m    223\u001b[0m     post_load_functions\u001b[39m=\u001b[39mpost_load_functions\n\u001b[1;32m    224\u001b[0m )\n\u001b[1;32m    225\u001b[0m \u001b[39mif\u001b[39;00m auto_load:\n\u001b[0;32m--> 226\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n",
      "File \u001b[0;32m~/repo/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Loading.py:339\u001b[0m, in \u001b[0;36mPipelineWithLoadableStage.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstage\u001b[39m.\u001b[39mload()  \u001b[39m# perform the load operation:\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstage \u001b[39m=\u001b[39m LoadedPipelineStage(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstage)  \u001b[39m# build the loaded stage\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstage\u001b[39m.\u001b[39;49mpost_load(progress_logger\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogger)\n",
      "File \u001b[0;32m~/repo/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Loading.py:283\u001b[0m, in \u001b[0;36mLoadedPipelineStage.post_load\u001b[0;34m(self, progress_logger, debug_print)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[39m# self.sess = compose_functions(self.post_load_functions, self.sess)\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     composed_post_load_function \u001b[39m=\u001b[39m compose_functions(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_load_functions) \u001b[39m# functions are composed left-to-right\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msess \u001b[39m=\u001b[39m composed_post_load_function(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msess)\n\u001b[1;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[39mif\u001b[39;00m debug_print:\n",
      "File \u001b[0;32m~/repo/pyPhoCoreHelpers/src/pyphocorehelpers/function_helpers.py:30\u001b[0m, in \u001b[0;36mcompose_functions.<locals>._\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[39mif\u001b[39;00m progress_logger \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         progress_logger(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mExecuting [\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mtotal_num_funcs\u001b[39m}\u001b[39;00m\u001b[39m]: \u001b[39m\u001b[39m{\u001b[39;00mf\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m     result \u001b[39m=\u001b[39m f(result)\n\u001b[1;32m     31\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/repo/NeuroPy/neuropy/core/session/Formats/Specific/KDibaOldDataSessionFormat.py:183\u001b[0m, in \u001b[0;36mKDibaOldDataSessionFormatRegisteredClass.get_known_data_session_type_properties.<locals>.<lambda>\u001b[0;34m(a_loaded_sess)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     basepath \u001b[39m=\u001b[39m Path(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_session_default_basedir)\n\u001b[1;32m    182\u001b[0m \u001b[39mreturn\u001b[39;00m KnownDataSessionTypeProperties(load_function\u001b[39m=\u001b[39m(\u001b[39mlambda\u001b[39;00m a_base_dir: \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_session(basedir\u001b[39m=\u001b[39ma_base_dir)), \n\u001b[0;32m--> 183\u001b[0m                         basedir\u001b[39m=\u001b[39mbasepath, post_load_functions\u001b[39m=\u001b[39m[\u001b[39mlambda\u001b[39;00m a_loaded_sess: \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mPOSTLOAD_estimate_laps_and_replays(a_loaded_sess)])\n",
      "File \u001b[0;32m~/repo/NeuroPy/neuropy/core/session/Formats/Specific/KDibaOldDataSessionFormat.py:215\u001b[0m, in \u001b[0;36mKDibaOldDataSessionFormatRegisteredClass.POSTLOAD_estimate_laps_and_replays\u001b[0;34m(cls, sess)\u001b[0m\n\u001b[1;32m    212\u001b[0m replay_estimation_parameters \u001b[39m=\u001b[39m DynamicContainer(require_intersecting_epoch\u001b[39m=\u001b[39mnon_running_periods, min_epoch_included_duration\u001b[39m=\u001b[39m\u001b[39m0.06\u001b[39m, max_epoch_included_duration\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, maximum_speed_thresh\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, min_inclusion_fr_active_thresh\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m, min_num_unique_aclu_inclusions\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m    214\u001b[0m \u001b[39m# num_pre = session.replay.\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m sess\u001b[39m.\u001b[39;49mreplace_session_replays_with_estimates(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mreplay_estimation_parameters)\n\u001b[1;32m    217\u001b[0m \u001b[39m# ### Get both laps and existing replays as PortionIntervals to check for overlaps:\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m# replays = sess.replay.epochs.to_PortionInterval()\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# laps = sess.laps.as_epoch_obj().to_PortionInterval() #.epochs.to_PortionInterval()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[39m# TODO 2023-05-22: Write the parameters somewhere:\u001b[39;00m\n\u001b[1;32m    227\u001b[0m replays \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39mreplay\u001b[39m.\u001b[39mepochs\u001b[39m.\u001b[39mto_PortionInterval()\n",
      "File \u001b[0;32m~/repo/NeuroPy/neuropy/core/session/dataSession.py:295\u001b[0m, in \u001b[0;36mDataSession.replace_session_replays_with_estimates\u001b[0;34m(self, debug_print, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreplace_session_replays_with_estimates\u001b[39m(\u001b[39mself\u001b[39m, debug_print\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    294\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" 2023-04-20 - Backup the loaded replays if they exist for the session to `.replay_backup`, and then estimate them fresh and assign them to the `a_session.replay` \"\"\"\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m     \u001b[39mreturn\u001b[39;00m DataSession\u001b[39m.\u001b[39;49mperform_replace_session_replays_with_estimates(\u001b[39mself\u001b[39;49m, debug_print\u001b[39m=\u001b[39;49mdebug_print, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/repo/NeuroPy/neuropy/core/session/dataSession.py:526\u001b[0m, in \u001b[0;36mDataSession.perform_replace_session_replays_with_estimates\u001b[0;34m(cls, a_session, debug_print, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m default_replay_estimation_parameters \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mrequire_intersecting_epoch\u001b[39m\u001b[39m'\u001b[39m:a_session\u001b[39m.\u001b[39mripple, \u001b[39m'\u001b[39m\u001b[39mmin_epoch_included_duration\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.06\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmax_epoch_included_duration\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mmaximum_speed_thresh\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mmin_inclusion_fr_active_thresh\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.05\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmin_num_unique_aclu_inclusions\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m5\u001b[39m}\n\u001b[1;32m    525\u001b[0m \u001b[39m# compute estimates and assign them as the session's .replay value\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m a_session\u001b[39m.\u001b[39mreplay \u001b[39m=\u001b[39m a_session\u001b[39m.\u001b[39;49mestimate_replay_epochs(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(default_replay_estimation_parameters \u001b[39m|\u001b[39;49m kwargs))\u001b[39m.\u001b[39mto_dataframe()\n\u001b[1;32m    527\u001b[0m \u001b[39mreturn\u001b[39;00m a_session\u001b[39m.\u001b[39mreplay\n",
      "File \u001b[0;32m~/repo/NeuroPy/neuropy/core/session/dataSession.py:423\u001b[0m, in \u001b[0;36mDataSession.estimate_replay_epochs\u001b[0;34m(self, require_intersecting_epoch, min_epoch_included_duration, max_epoch_included_duration, maximum_speed_thresh, min_inclusion_fr_active_thresh, min_num_unique_aclu_inclusions, save_on_compute, debug_print)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mestimate_replay_epochs\u001b[39m(\u001b[39mself\u001b[39m, require_intersecting_epoch\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, min_epoch_included_duration\u001b[39m=\u001b[39m\u001b[39m0.06\u001b[39m, max_epoch_included_duration\u001b[39m=\u001b[39m\u001b[39m0.6\u001b[39m, maximum_speed_thresh\u001b[39m=\u001b[39m\u001b[39m2.0\u001b[39m, min_inclusion_fr_active_thresh\u001b[39m=\u001b[39m\u001b[39m2.0\u001b[39m, min_num_unique_aclu_inclusions\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, save_on_compute\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, debug_print\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    411\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"estimates replay epochs from PBE and Position data.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \n\u001b[1;32m    413\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[39m        _type_: _description_\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 423\u001b[0m     \u001b[39mreturn\u001b[39;00m DataSession\u001b[39m.\u001b[39;49mperform_compute_estimated_replay_epochs(\u001b[39mself\u001b[39;49m, require_intersecting_epoch\u001b[39m=\u001b[39;49mrequire_intersecting_epoch, min_epoch_included_duration\u001b[39m=\u001b[39;49mmin_epoch_included_duration, max_epoch_included_duration\u001b[39m=\u001b[39;49mmax_epoch_included_duration, maximum_speed_thresh\u001b[39m=\u001b[39;49mmaximum_speed_thresh, min_inclusion_fr_active_thresh\u001b[39m=\u001b[39;49mmin_inclusion_fr_active_thresh, min_num_unique_aclu_inclusions\u001b[39m=\u001b[39;49mmin_num_unique_aclu_inclusions, save_on_compute\u001b[39m=\u001b[39;49msave_on_compute, debug_print\u001b[39m=\u001b[39;49mdebug_print)\n",
      "File \u001b[0;32m~/repo/NeuroPy/neuropy/core/session/dataSession.py:465\u001b[0m, in \u001b[0;36mDataSession.perform_compute_estimated_replay_epochs\u001b[0;34m(cls, a_session, require_intersecting_epoch, min_epoch_included_duration, max_epoch_included_duration, maximum_speed_thresh, min_inclusion_fr_active_thresh, min_num_unique_aclu_inclusions, save_on_compute, debug_print)\u001b[0m\n\u001b[1;32m    460\u001b[0m curr_replays \u001b[39m=\u001b[39m KnownFilterEpochs\u001b[39m.\u001b[39mperform_get_filter_epochs_df(sess\u001b[39m=\u001b[39ma_session, filter_epochs\u001b[39m=\u001b[39mfilter_epochs, min_epoch_included_duration\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m# returns Epoch object, don't use min_epoch_included_duration here, we'll do it in the next step.\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[39m# require_intersecting_epoch = a_session.ripple # previously was\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \n\u001b[1;32m    464\u001b[0m \u001b[39m# Filter by the constraints specified\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m curr_replays \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfilter_replay_epochs(curr_replays, pos_df\u001b[39m=\u001b[39;49ma_session\u001b[39m.\u001b[39;49mposition\u001b[39m.\u001b[39;49mto_dataframe(), spikes_df\u001b[39m=\u001b[39;49ma_session\u001b[39m.\u001b[39;49mspikes_df\u001b[39m.\u001b[39;49mcopy(), require_intersecting_epoch\u001b[39m=\u001b[39;49mrequire_intersecting_epoch,\n\u001b[1;32m    466\u001b[0m     min_epoch_included_duration\u001b[39m=\u001b[39;49mmin_epoch_included_duration, max_epoch_included_duration\u001b[39m=\u001b[39;49mmax_epoch_included_duration, maximum_speed_thresh\u001b[39m=\u001b[39;49mmaximum_speed_thresh, min_inclusion_fr_active_thresh\u001b[39m=\u001b[39;49mmin_inclusion_fr_active_thresh, min_num_unique_aclu_inclusions\u001b[39m=\u001b[39;49mmin_num_unique_aclu_inclusions, debug_print\u001b[39m=\u001b[39;49mdebug_print)\n\u001b[1;32m    468\u001b[0m \u001b[39m## TODO: 2023-05-16 - Debug print the number of replays before/after\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m curr_replays: \u001b[39m\u001b[39m{\u001b[39;00mcurr_replays\u001b[39m.\u001b[39mn_epochs\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/repo/NeuroPy/neuropy/core/session/dataSession.py:495\u001b[0m, in \u001b[0;36mDataSession.filter_replay_epochs\u001b[0;34m(cls, curr_replays, pos_df, spikes_df, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"filters the provided replay epochs by specified constraints.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \n\u001b[1;32m    478\u001b[0m \u001b[39m# require_intersecting_epoch:Epoch=None, min_epoch_included_duration=0.06, max_epoch_included_duration=0.6, maximum_speed_thresh=2.0, min_inclusion_fr_active_thresh=2.0, min_num_unique_aclu_inclusions=3, save_on_compute=False, debug_print=False\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m \n\u001b[1;32m    493\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mneuropy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mepoch\u001b[39;00m \u001b[39mimport\u001b[39;00m Epoch\n\u001b[0;32m--> 495\u001b[0m \u001b[39mreturn\u001b[39;00m Epoch\u001b[39m.\u001b[39;49mfilter_epochs(curr_epochs\u001b[39m=\u001b[39;49mcurr_replays, pos_df\u001b[39m=\u001b[39;49mpos_df, spikes_df\u001b[39m=\u001b[39;49mspikes_df, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/repo/NeuroPy/neuropy/core/epoch.py:412\u001b[0m, in \u001b[0;36mEpoch.filter_epochs\u001b[0;34m(cls, curr_epochs, pos_df, spikes_df, require_intersecting_epoch, min_epoch_included_duration, max_epoch_included_duration, maximum_speed_thresh, min_inclusion_fr_active_thresh, min_num_unique_aclu_inclusions, debug_print)\u001b[0m\n\u001b[1;32m    410\u001b[0m active_spikes_df \u001b[39m=\u001b[39m spikes_df\u001b[39m.\u001b[39mspikes\u001b[39m.\u001b[39msliced_by_neuron_type(\u001b[39m'\u001b[39m\u001b[39mpyr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# trim based on pyramidal cell activity only\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39mif\u001b[39;00m curr_epochs\u001b[39m.\u001b[39mn_epochs \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 412\u001b[0m     curr_epochs, _extra_outputs \u001b[39m=\u001b[39m filter_epochs_by_num_active_units(active_spikes_df, curr_epochs, min_inclusion_fr_active_thresh\u001b[39m=\u001b[39;49mmin_inclusion_fr_active_thresh, min_num_unique_aclu_inclusions\u001b[39m=\u001b[39;49mmin_num_unique_aclu_inclusions, include_intermediate_computations\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \u001b[39m# TODO: seems wasteful considering we compute all these spikes_df metrics and refinements and then don't return them.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m     warn(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcurr_epochs already empty prior to filtering by firing rate or minimum active units\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/repo/NeuroPy/neuropy/utils/efficient_interval_search.py:590\u001b[0m, in \u001b[0;36mfilter_epochs_by_num_active_units\u001b[0;34m(active_spikes_df, active_epochs, min_inclusion_fr_active_thresh, min_num_unique_aclu_inclusions, include_intermediate_computations)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Filter active_epochs by requiring them to have at least `min_num_unique_aclu_inclusions` active units as determined by filtering active_spikes_df.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39mInputs:\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[39m    active_spikes_df: a spike_df with only active units\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[1;32m    588\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    589\u001b[0m all_aclus \u001b[39m=\u001b[39m active_spikes_df\u001b[39m.\u001b[39mspikes\u001b[39m.\u001b[39mneuron_ids\n\u001b[0;32m--> 590\u001b[0m spike_trimmed_active_epochs, epoch_split_spike_dfs \u001b[39m=\u001b[39m trim_epochs_to_first_last_spikes(active_spikes_df, active_epochs) \u001b[39m# TODO 2023-05-24 - should this be: , min_num_unique_aclu_inclusions=min_num_unique_aclu_inclusions\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[39m## Firing Rate and Number of Active Aclus Filtering:\u001b[39;00m\n\u001b[1;32m    593\u001b[0m epoch_split_spike_dfs_aclu_spikecounts \u001b[39m=\u001b[39m [a_spike_df[\u001b[39m'\u001b[39m\u001b[39maclu\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalue_counts()\u001b[39m.\u001b[39mto_dict() \u001b[39mfor\u001b[39;00m a_spike_df \u001b[39min\u001b[39;00m epoch_split_spike_dfs] \u001b[39m# This code takes the column 'aclu' from the Pandas DataFrame df, counts the number of occurrences of each unique value, and converts the resulting Pandas Series object to a dictionary using to_dict(). The keys in the dictionary correspond to each unique aclu value and their count.\u001b[39;00m\n",
      "File \u001b[0;32m~/repo/NeuroPy/neuropy/utils/efficient_interval_search.py:523\u001b[0m, in \u001b[0;36mtrim_epochs_to_first_last_spikes\u001b[0;34m(active_spikes_df, active_epochs, min_num_unique_aclu_inclusions)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[39m# Get the first and last spike times for each epoch:\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[39m# Valid epochs should be pruned to this interval (when the first/last pyramidal spike happened):\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mneuropy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mepoch\u001b[39;00m \u001b[39mimport\u001b[39;00m Epoch \u001b[39m# `filter_epochs_by_num_active_units` used to rebuild the spike-constrained epochs:\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m epoch_split_spike_dfs \u001b[39m=\u001b[39m [active_spikes_df\u001b[39m.\u001b[39mspikes\u001b[39m.\u001b[39mtime_sliced(t_start, t_stop) \u001b[39mfor\u001b[39;00m t_start, t_stop \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(active_epochs\u001b[39m.\u001b[39mstarts, active_epochs\u001b[39m.\u001b[39mstops)] \u001b[39m# oh, very fast actually!\u001b[39;00m\n\u001b[1;32m    524\u001b[0m is_epoch_non_empty_spikes_df \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlogical_not([\u001b[39mlen\u001b[39m(v)\u001b[39m<\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m epoch_split_spike_dfs]) \u001b[39m# the epochs have no active cells (no spikes at all)\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[39m# Drop empty epochs:\u001b[39;00m\n",
      "File \u001b[0;32m~/repo/NeuroPy/neuropy/utils/efficient_interval_search.py:523\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[39m# Get the first and last spike times for each epoch:\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[39m# Valid epochs should be pruned to this interval (when the first/last pyramidal spike happened):\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mneuropy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mepoch\u001b[39;00m \u001b[39mimport\u001b[39;00m Epoch \u001b[39m# `filter_epochs_by_num_active_units` used to rebuild the spike-constrained epochs:\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m epoch_split_spike_dfs \u001b[39m=\u001b[39m [active_spikes_df\u001b[39m.\u001b[39;49mspikes\u001b[39m.\u001b[39;49mtime_sliced(t_start, t_stop) \u001b[39mfor\u001b[39;00m t_start, t_stop \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(active_epochs\u001b[39m.\u001b[39mstarts, active_epochs\u001b[39m.\u001b[39mstops)] \u001b[39m# oh, very fast actually!\u001b[39;00m\n\u001b[1;32m    524\u001b[0m is_epoch_non_empty_spikes_df \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlogical_not([\u001b[39mlen\u001b[39m(v)\u001b[39m<\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m epoch_split_spike_dfs]) \u001b[39m# the epochs have no active cells (no spikes at all)\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[39m# Drop empty epochs:\u001b[39;00m\n",
      "File \u001b[0;32m~/repo/NeuroPy/neuropy/utils/mixins/time_slicing.py:56\u001b[0m, in \u001b[0;36mTimeSlicedMixin.time_sliced\u001b[0;34m(self, t_start, t_stop)\u001b[0m\n\u001b[1;32m     53\u001b[0m start_stop_times_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhstack((np\u001b[39m.\u001b[39matleast_2d(starts)\u001b[39m.\u001b[39mT, np\u001b[39m.\u001b[39matleast_2d(stops)\u001b[39m.\u001b[39mT)) \u001b[39m# atleast_2d ensures that each array is represented as a column, so start_stop_times_arr is at least of shape (1, 2)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m# print(f'time_sliced(...): np.shape(start_stop_times_arr): {np.shape(start_stop_times_arr)}')\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m# print(f'np.shape(start_stop_times_arr): {np.shape(start_stop_times_arr)}')\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m inclusion_mask \u001b[39m=\u001b[39m determine_event_interval_is_included(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_obj[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtime_variable_name]\u001b[39m.\u001b[39;49mto_numpy(), start_stop_times_arr)\n\u001b[1;32m     57\u001b[0m \u001b[39m# once all slices have been computed and the inclusion_mask is complete, use it to mask the output dataframe\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj\u001b[39m.\u001b[39mloc[inclusion_mask, :]\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/repo/NeuroPy/neuropy/utils/efficient_interval_search.py:326\u001b[0m, in \u001b[0;36mdetermine_event_interval_is_included\u001b[0;34m(times_arr, start_stop_times_arr)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetermine_event_interval_is_included\u001b[39m(times_arr, start_stop_times_arr):\n\u001b[1;32m    325\u001b[0m     \u001b[39massert\u001b[39;00m verify_non_overlapping(start_stop_times_arr\u001b[39m=\u001b[39mstart_stop_times_arr), \u001b[39m'\u001b[39m\u001b[39mIntervals in start_stop_times_arr must be non-overlapping\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mreturn\u001b[39;00m _compiled_searchsorted_event_interval_is_included(times_arr, start_stop_times_arr)\n",
      "File \u001b[0;32m~/repo/Spike3D/.venv/lib/python3.9/site-packages/numba/core/serialize.py:29\u001b[0m, in \u001b[0;36m_numba_unpickle\u001b[0;34m(address, bytedata, hashed)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m# Keep unpickled object via `numba_unpickle` alive.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m _unpickled_memo \u001b[39m=\u001b[39m {}\n\u001b[0;32m---> 29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numba_unpickle\u001b[39m(address, bytedata, hashed):\n\u001b[1;32m     30\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Used by `numba_unpickle` from _helperlib.c\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39m        unpickled object\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     key \u001b[39m=\u001b[39m (address, hashed)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # DONE. Very good. Many good Pfs, many good replays.\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # DONE, might be the BEST SESSION, good example session with lots of place cells, clean replays, and clear bar graphs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD, 2023-07-14, unsure why still.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays!\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE, Added replay selections. Very \"jumpy\" between the starts and ends of the track.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # DONE, Added replay selections. A TON of putative replays in general, most bad, but some good.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # DONE, added replay selections. Very few (like 12) replays each.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3') # DONE, Good Pfs, no good epochs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') # DONE, okay replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # DONE, very few replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # DONE, one replay each (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # BAD, Good Pfs strangely despite horrible map, no good epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # DONE, good. Many good pfs, many good replays.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE, good?, replays selected, few\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE, very few replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # DONE, replays selected, quite a few replays but few are very good.\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "# saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "# force_reload = False\n",
    "\n",
    "# Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "force_reload = True\n",
    "\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=[#'_perform_estimated_epochs_computation',  # AL:WAYS OFF\n",
    "                                            '_perform_baseline_placefield_computation',\n",
    "                                        # '_perform_time_dependent_placefield_computation', # AL:WAYS OFF\n",
    "                                        '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        # '_perform_time_dependent_pf_sequential_surprise_computation' # AL:WAYS OFF\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding' # AL:WAYS OFF\n",
    "                                    ]\n",
    "# active_computation_functions_name_includelist=['_perform_baseline_placefield_computation']\n",
    "\n",
    "curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=False) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        curr_active_pipeline.load_pickled_global_computation_results()\n",
    "    except Exception as e:\n",
    "        print(f'cannot load global results: {e}')\n",
    "\n",
    "# 6m 1.1s\n",
    "# 12m 15.6s\n",
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated\n",
    "if was_updated:\n",
    "\ttry:\n",
    "\t\tcurr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "\texcept Exception as e:\n",
    "\t\t## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "\t\tprint(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "extended_computations_include_includelist=['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'] # do only specifiedl , 'long_short_rate_remapping'\n",
    "force_recompute_global = force_reload\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=force_recompute_global, debug_print=False)\n",
    "if (len(newly_computed_values) > 0) and (saving_mode.value != 'skip_saving'):\n",
    "\tprint(f'newly_computed_values: {newly_computed_values}. Saving global results...')\n",
    "\ttry:\n",
    "\t\t# curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "\t\t# Try to write out the global computation function results:\n",
    "\t\tcurr_active_pipeline.save_global_computation_results()\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "\t\tprint(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "\tprint(f'no changes in global results.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c850782f",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc7ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "## Extract variables from results object:\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global\n",
    "\n",
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result['Flat_epoch_time_bins_mean'], expected_v_observed_result['Flat_decoder_time_bin_centers'], expected_v_observed_result['num_neurons'], expected_v_observed_result['num_timebins_in_epoch'], expected_v_observed_result['num_total_flat_timebins'], expected_v_observed_result['is_short_track_epoch'], expected_v_observed_result['is_long_track_epoch'], expected_v_observed_result['short_short_diff'], expected_v_observed_result['long_long_diff']\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc30a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To file only:\n",
    "with matplotlib_file_only():\n",
    "\t# Perform non-interactive Matplotlib operations with 'AGG' backend\n",
    "\tmain_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=False, save_figures_only=True, save_figure=True)\n",
    "\n",
    "## Clear the Programmatically open figures:\n",
    "plt.close('all') # this takes care of the matplotlib-backed figures.\n",
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44783dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_out_figures = main_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=False, save_figures_only=False, save_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ff237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interactive Selection of User Annotations:\n",
    "from pyphoplacecellanalysis.General.Model.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.GUI.Qt.Mixins.PaginationMixins import SelectionsObject\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "\n",
    "user_annotation_man = UserAnnotationsManager()\n",
    "user_annotations = user_annotation_man.get_user_annotations()\n",
    "\n",
    "final_context_L = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj')\n",
    "final_context_S = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj')\n",
    "# _out_pagination_controller.params.active_identifying_figure_ctx.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_L = final_context_L.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_S = final_context_S.adding_context(None,  user_annotation=\"selections\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8cbb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover it from the last_added_display_output\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.last_added_display_output\n",
    "pagination_controller_L, pagination_controller_S = example_stacked_epoch_graphics.plot_data['controllers']\n",
    "ax_L, ax_S = example_stacked_epoch_graphics.axes\n",
    "figure_context_L, figure_context_S = example_stacked_epoch_graphics.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeba529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_annotations = UserAnnotationsManager.get_user_annotations()\n",
    "# user_annotations = self.get_user_annotations()\n",
    "\n",
    "## Capture current user selection\n",
    "\n",
    "# def _update_user_annotations_from_selections():\n",
    "# \t\"\"\" captures:\n",
    "# \t\tuser_annotations\n",
    "# \t\tpagination_controller_L, pagination_controller_S\n",
    "# \t\"\"\"\n",
    "saved_selection_L: SelectionsObject = pagination_controller_L.save_selection()\n",
    "saved_selection_S: SelectionsObject = pagination_controller_S.save_selection()\n",
    "user_annotations_L_context: IdentifyingContext = saved_selection_L.figure_ctx.adding_context_if_missing(user_annotation='selections')\n",
    "user_annotations_S_context: IdentifyingContext = saved_selection_S.figure_ctx.adding_context_if_missing(user_annotation='selections')\n",
    "print(f'{user_annotations_L_context}\\n\\t{saved_selection_L.flat_all_data_indicies[saved_selection_L.is_selected]}')\n",
    "print(f'{user_annotations_S_context}\\n\\t{saved_selection_S.flat_all_data_indicies[saved_selection_S.is_selected]}')\n",
    "user_annotations[user_annotations_L_context] = saved_selection_L.flat_all_data_indicies[saved_selection_L.is_selected]\n",
    "user_annotations[user_annotations_S_context] = saved_selection_S.flat_all_data_indicies[saved_selection_S.is_selected]\n",
    "\n",
    "## Generate code to insert int user_annotations:\n",
    "print('Add the following code to `pyphoplacecellanalysis.General.Model.user_annotations.UserAnnotationsManager.get_user_annotations()` function body:')\n",
    "print(f\"user_annotations[{user_annotations_L_context.get_initialization_code_string()}] = np.array({list(saved_selection_L.flat_all_data_indicies[saved_selection_L.is_selected])})\")\n",
    "print(f\"user_annotations[{user_annotations_S_context.get_initialization_code_string()}] = np.array({list(saved_selection_S.flat_all_data_indicies[saved_selection_S.is_selected])})\")\n",
    "\n",
    "# Stopping at (128, 89)\n",
    "\n",
    "# Updates the context. Needs to generate the code.\n",
    "# _update_user_annotations_from_selections()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386935cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## try to get the user annotations for this session:\n",
    "try:\n",
    "\tselection_idxs_L = user_annotations[selections_context_L]\n",
    "\tselection_idxs_S = user_annotations[selections_context_S]\n",
    "except KeyError as e:\n",
    "\tprint(f'user annotations <good replay selections> are not found. Creating them interactively...')\n",
    "\t# user_annotation_man.interactive_good_epoch_selections(curr_active_pipeline=curr_active_pipeline) # perform interactive selection. Should block here.\n",
    "\n",
    "\n",
    "\t## Stacked Epoch Plot\n",
    "\texample_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=False)\n",
    "\tpagination_controller_L, pagination_controller_S = example_stacked_epoch_graphics.plot_data['controllers']\n",
    "\tax_L, ax_S = example_stacked_epoch_graphics.axes\n",
    "\tfigure_context_L, figure_context_S = example_stacked_epoch_graphics.context\n",
    "\n",
    "except Exception as e:\n",
    "\tprint('Unhandled exception: {e}')\n",
    "\traise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_annotations_L_context.get_initialization_code_string(subset_includelist=['format_name','animal','exper_name', 'session_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b094ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "\n",
    "IdentifyingContext._get_session_context_keys()\n",
    "\n",
    "# user_annotations_L_context.get_subset(subset_includelist=[IdentifyingContext._get_session_context_keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fb55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_idxs_L = user_annotations[selections_context_L]\n",
    "selection_idxs_S = user_annotations[selections_context_S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591ede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_figures\n",
    "curr_active_pipeline.registered_output_files_list\n",
    "# [WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_display_short_long_pf1D_comparison_long.png'),\n",
    "#  WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_display_short_long_pf1D_comparison_short.png'),\n",
    "#  WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_plot_multiple_raster_plot_1_long_example_replays_plot_multiple_raster_plot.png'),\n",
    "#  WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_plot_multiple_raster_plot_1_short_example_replays_plot_multiple_raster_plot.png'),\n",
    "#  WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_DecodedEpochSlices_replays_long_results_obj.png'),\n",
    "#  WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_DecodedEpochSlices_replays_short_results_obj.png'),\n",
    "#  WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_2_inst_FR_bar_graphs_Laps.png'),\n",
    "#  WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_2_inst_FR_bar_graphs_Replay.png'),\n",
    "#  WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_long_short_firing_rate_indicies_display_long_short_laps.png'),\n",
    "#  WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_maze1_plot_single_track_firing_rate_compare.png'),\n",
    "#  WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_maze2_plot_single_track_firing_rate_compare.png')]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1985e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylustrator\n",
    "\n",
    "fig_1_paths = curr_active_pipeline.registered_output_files_list[:2]\n",
    "# [WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_display_short_long_pf1D_comparison_long.png'),\n",
    "#  WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_display_short_long_pf1D_comparison_short.png')]\n",
    "print(f\"{fig_1_paths =}\")\n",
    "fig = plt.figure() # new figure to hold the result\n",
    "pylustrator.load(fig_1_paths[0], figure=fig)\n",
    "pylustrator.load(fig_1_paths[1], offset=[1, 0], figure=fig)\n",
    "# pylustrator.load(\"plot3.jpg\", offset=[0, 1])\n",
    "# pylustrator.load(\"plot4.svg\", offset=[0.5, 0.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad2295",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_3_paths = curr_active_pipeline.registered_output_files_list[-3:]\n",
    "# [WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_long_short_firing_rate_indicies_display_long_short_laps.png'),\n",
    "#  WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_maze1_plot_single_track_firing_rate_compare.png'),\n",
    "#  WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-13/kdiba_gor01_two_2006-6-07_16-40-19_maze2_plot_single_track_firing_rate_compare.png')]\n",
    "print(f\"{fig_3_paths =}\")\n",
    "fig = plt.figure() # new figure to hold the result\n",
    "pylustrator.load(fig_3_paths[0], figure=fig)\n",
    "pylustrator.load(fig_3_paths[1], offset=[0, 1], figure=fig)\n",
    "pylustrator.load(fig_3_paths[2], offset=[1, 0.5], figure=fig)\n",
    "\n",
    "# #% start: automatic generated code from pylustrator\n",
    "# plt.figure(8).ax_dict = {ax.get_label(): ax for ax in plt.figure(8).axes}\n",
    "# import matplotlib as mpl\n",
    "# getattr(plt.figure(8), '_pylustrator_init', lambda: ...)()\n",
    "# plt.figure(8).set_size_inches(60.960000/2.54, 30.480000/2.54, forward=True)\n",
    "# plt.figure(8).ax_dict[\"C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\EXTERNAL\\\\Screenshots\\\\ProgrammaticDisplayFunctionTesting\\\\2023-07-13\\\\kdiba_gor01_two_2006-6-07_16-40-19_long_short_firing_rate_indicies_display_long_short_laps.png\"].set(position=[0., 0., 0.6209, 1.001])\n",
    "# plt.figure(8).ax_dict[\"C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\EXTERNAL\\\\Screenshots\\\\ProgrammaticDisplayFunctionTesting\\\\2023-07-13\\\\kdiba_gor01_two_2006-6-07_16-40-19_long_short_firing_rate_indicies_display_long_short_laps.png\"].spines[['right', 'top']].set_visible(True)\n",
    "# plt.figure(8).ax_dict[\"C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\EXTERNAL\\\\Screenshots\\\\ProgrammaticDisplayFunctionTesting\\\\2023-07-13\\\\kdiba_gor01_two_2006-6-07_16-40-19_maze1_plot_single_track_firing_rate_compare.png\"].set(position=[0.6067, 0.5008, 0.293, 0.5])\n",
    "# plt.figure(8).ax_dict[\"C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\EXTERNAL\\\\Screenshots\\\\ProgrammaticDisplayFunctionTesting\\\\2023-07-13\\\\kdiba_gor01_two_2006-6-07_16-40-19_maze2_plot_single_track_firing_rate_compare.png\"].set(position=[0.6067, 0.002521, 0.293, 0.5])\n",
    "# #% end: automatic generated code from pylustrator\n",
    "\n",
    "# pylustrator.load(\"plot3.jpg\", offset=[0, 1])\n",
    "# pylustrator.load(\"plot4.svg\", offset=[0.5, 0.5])\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f5ffa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be2921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pylustrator.start()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976793fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pylustrator\n",
    "# pylustrator.load(\"plot1.py\")\n",
    "# pylustrator.load(\"plot2.png\", offset=[1, 0])\n",
    "# pylustrator.load(\"plot3.jpg\", offset=[0, 1])\n",
    "# pylustrator.load(\"plot4.svg\", offset=[0.5, 0.5])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a53cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.figure_management import PhoActiveFigureManager2D, capture_new_figures_decorator\n",
    "fig_man = PhoActiveFigureManager2D(name=f'fig_man') # Initialize a new figure manager\n",
    "fig_man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c91d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_man.figures_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4bf510",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_man.figure_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d93de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84666437",
   "metadata": {},
   "outputs": [],
   "source": [
    "pylustrator.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49710f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10171ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the core desire is actually to be able to suppress figure display and interaction for batch saving to file only ('AGG' mode)\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import AssigningEpochs, TrackAssignmentDecision, TrackAssignmentState\n",
    "\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "fig, axs = AssigningEpochs.main_plot_iterative_epoch_track_assignments(curr_active_pipeline=curr_active_pipeline, defer_render=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64444d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the manual user selections for the replays:\n",
    "\n",
    "# [13 23 41 46]\n",
    "IdentifyingContext<('kdiba', 'pin01', 'one', '11-02_17-46-44', 'DecodedEpochSlices', 'replays', 'long_results_obj', 'selections')>\n",
    "# [ 4  7 10 15 21 23 41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7386d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interactively get the user selections for the good replays and generate the two entries to add to the UserAnnotations class:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9185a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.active_config_names\n",
    "curr_active_pipeline.active_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.active_config_names\n",
    "\n",
    "# ['maze1_odd', 'maze2_odd',  'maze_odd',\n",
    "#  'maze1_even','maze2_even', 'maze_even',\n",
    "#  'maze1_any', 'maze2_any', 'maze_any']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf44ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f2ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd09a9",
   "metadata": {
    "tags": [
     "interactive"
    ]
   },
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# HELPERS: Interactive Components                                                                                      #\n",
    "# ==================================================================================================================== #\n",
    "from neuropy.utils.matplotlib_helpers import interactive_select_grid_bin_bounds_2D\n",
    "# fig, ax, rect_selector, set_extents = interactive_select_grid_bin_bounds_2D(curr_active_pipeline, epoch_name='maze', should_block_for_input=True)\n",
    "# required to enable non-blocking interaction:\n",
    "# %gui qt5\n",
    "\n",
    "# %lsmagic\n",
    "\n",
    "# with plt.ion():\n",
    "grid_bin_bounds = interactive_select_grid_bin_bounds_2D(curr_active_pipeline, epoch_name='maze', should_block_for_input=True, should_apply_updates_to_pipeline=False)\n",
    "print(f'grid_bin_bounds: {grid_bin_bounds}')\n",
    "print(f\"Add this to `specific_session_override_dict`:\\n\\n{curr_active_pipeline.get_session_context().get_initialization_code_string()}:dict(grid_bin_bounds=({(grid_bin_bounds[0], grid_bin_bounds[1]), (grid_bin_bounds[2], grid_bin_bounds[3])})),\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6767f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Common matplotlib figure needs:\n",
    "\n",
    "# - [ ] Rendering to PyQt5-backed window (for display or potentially interaction)\n",
    "\n",
    "# - [ ] Saving to file\n",
    "\n",
    "# - [ ] Blocking for input (for interaction), only occasionally.\n",
    "\n",
    "from neuropy.utils.result_context import overwriting_display_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f8808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Helpers:\n",
    "\n",
    "# [ ] Changing the Window Title\n",
    "\n",
    "# [ ] Changing the Save File Path/Name\n",
    "\n",
    "# [ ] Changing the various suptitle/titles/axes-titles displayed on the graph in various places\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f18ee7c5",
   "metadata": {},
   "source": [
    "# 2023-07-03 - Looking at directional placefields\n",
    "The purpose of looking at this was to see if the bimodality actually should have belonged to directional placecells, and if splitting on direction would result in cleaner time spike rasters during replays instead of the strange bimodal setup I see now.\n",
    "- [ ] I realized why my replay rasters don't look as clean and simple as yours despite the replays looking good. I think your unidirectional filter results in less bimodal placefields. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Show 1D Placefields for both Short and Long (top half of the figure)                                                 #\n",
    "# ==================================================================================================================== #\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "long_single_cell_pfmap_processing_fn = None\n",
    "short_single_cell_pfmap_processing_fn = None\n",
    "# sort_idx = None\n",
    "# sort_idx = sort_ind\n",
    "# sort_idx = sort_indicies\n",
    "# sort_idx = new_all_aclus_sort_indicies\n",
    "sort_idx = 'peak_long'\n",
    "# sort_idx = 'bad'\n",
    "\n",
    "# include_includelist = ['maze1_odd', 'maze2_odd', 'maze_odd'] # Odd Only\n",
    "# include_includelist = ['maze1_even','maze2_even', 'maze_even'] # Even laps only\n",
    "# include_includelist = ['maze1_any','maze2_any', 'maze_any']\n",
    "\n",
    "# active_identifying_session_ctx\n",
    "\n",
    "# with plt.ion():\n",
    "with plt.ioff():\n",
    "\tpf1d_compare_graphics = curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_identifying_session_ctx.overwriting_context(laps='all'), include_includelist=['maze1_any','maze2_any', 'maze_any'], single_figure=False, debug_print=False, fignum='Short v Long pf1D Comparison - all laps',\n",
    "\t\t\t\t\t\t\t\t\tlong_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': long_single_cell_pfmap_processing_fn},\n",
    "\t\t\t\t\t\t\t\t\tshort_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': short_single_cell_pfmap_processing_fn, 'curve_hatch_style': {'hatch':'///', 'edgecolor':'k'}},\n",
    "\t\t\t\t\t\t\t\t\tsave_figure=True,\n",
    "\t\t\t\t\t\t\t\t\tdefer_render=False\n",
    "\t\t\t\t\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f6a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.ion():\n",
    "\tpf1d_compare_graphics = curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_identifying_session_ctx.overwriting_context(laps='even'), include_includelist=['maze1_even','maze2_even', 'maze_even'], single_figure=False, debug_print=False, fignum='Short v Long pf1D Comparison - EVEN laps only',\n",
    "\t\t\t\t\t\t\t\t\tlong_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': long_single_cell_pfmap_processing_fn},\n",
    "\t\t\t\t\t\t\t\t\tshort_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': short_single_cell_pfmap_processing_fn, 'curve_hatch_style': {'hatch':'///', 'edgecolor':'k'}},\n",
    "\t\t\t\t\t\t\t\t\tsave_figure=True,\n",
    "\t\t\t\t\t\t\t\t\tdefer_render=False\n",
    "\t\t\t\t\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4f75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.ion():\n",
    "\tpf1d_compare_graphics = curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_identifying_session_ctx.overwriting_context(laps='odd'), include_includelist=['maze1_odd', 'maze2_odd', 'maze_odd'], single_figure=False, debug_print=False, fignum='Short v Long pf1D Comparison - ODD laps only',\n",
    "\t\t\t\t\t\t\t\t\tlong_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': long_single_cell_pfmap_processing_fn},\n",
    "\t\t\t\t\t\t\t\t\tshort_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': short_single_cell_pfmap_processing_fn, 'curve_hatch_style': {'hatch':'///', 'edgecolor':'k'}},\n",
    "\t\t\t\t\t\t\t\t\tsave_figure=True,\n",
    "\t\t\t\t\t\t\t\t\tdefer_render=False\n",
    "\t\t\t\t\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdbe714",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "print(long_epoch_name, short_epoch_name, global_epoch_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "943b8f18",
   "metadata": {},
   "source": [
    "# Common Display Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef70fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# configure backend here\n",
    "matplotlib.use('Qt5Agg')\n",
    "# backend_qt5agg\n",
    "# %matplotlib qt5\n",
    "# %matplotlib qt\n",
    "# matplotlib.use('AGG') # non-interactive backend ## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# mpl.rcParams['toolbar'] = 'None' # disable toolbars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9e59bdb",
   "metadata": {},
   "source": [
    "# Figure 1) pf1D Ratemaps, Active set, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77377ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_1_add_replay_epoch_rasters\n",
    "\n",
    "pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics = PAPER_FIGURE_figure_1_full(curr_active_pipeline) # did not display the pf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3877d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1d_compare_fig_L, pf1d_compare_fig_S = pf1d_compare_graphics.figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46626313",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1d_compare_fig_L.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999442a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ffa57",
   "metadata": {
    "tags": [
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import build_shared_sorted_neuronIDs\n",
    "\n",
    "ratemap = long_pf1D.ratemap\n",
    "included_unit_neuron_IDs = EITHER_subset.track_exclusive_aclus\n",
    "rediculous_final_sorted_all_included_neuron_ID, rediculous_final_sorted_all_included_pfmap = build_shared_sorted_neuronIDs(ratemap, included_unit_neuron_IDs, sort_ind=new_all_aclus_sort_indicies.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(rediculous_final_sorted_all_included_pfmap, show_yticks=False, title=f\"pf1D Sorted Visualization\", defer_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66369f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_curves_sorted = long_pf1D.ratemap.normalized_tuning_curves[is_included][included_new_all_aclus_sort_indicies]\n",
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(active_curves_sorted, show_yticks=False, title=f\"pf1D Sorted Visualization\", defer_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01ff9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f0066",
   "metadata": {
    "tags": [
     "unwrap_figure_output",
     "interactive"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "## Stacked Epoch Plot\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=True)\n",
    "pagination_controller_L, pagination_controller_S = example_stacked_epoch_graphics.plot_data['controllers']\n",
    "ax_L, ax_S = example_stacked_epoch_graphics.axes\n",
    "final_figure_context_L, final_context_S = example_stacked_epoch_graphics.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b8b4b",
   "metadata": {
    "tags": [
     "selections",
     "user_annotations"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Mixins.PaginationMixins import SelectionsObject\n",
    "from pyphoplacecellanalysis.General.Model.user_annotations import UserAnnotationsManager\n",
    "\n",
    "user_annotations = UserAnnotationsManager.get_user_annotations()\n",
    "user_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Capture current user selection\n",
    "saved_selection_L: SelectionsObject = pagination_controller_L.save_selection()\n",
    "saved_selection_S: SelectionsObject = pagination_controller_S.save_selection()\n",
    "user_annotations_L_context = saved_selection_L.figure_ctx.adding_context_if_missing(user_annotation='selections')\n",
    "user_annotations_S_context = saved_selection_S.figure_ctx.adding_context_if_missing(user_annotation='selections')\n",
    "user_annotations[user_annotations_L_context] = saved_selection_L.flat_all_data_indicies[saved_selection_L.is_selected]\n",
    "user_annotations[user_annotations_S_context] = saved_selection_S.flat_all_data_indicies[saved_selection_S.is_selected]\n",
    "# Updates the context. Needs to generate the code.\n",
    "\n",
    "## Generate code to insert int user_annotations:\n",
    "print('Add the following code to UserAnnotationsManager.get_user_annotations() function body:')\n",
    "print(f\"\\t\\tuser_annotations[{user_annotations_L_context.get_initialization_code_string()}] = np.array({list(saved_selection_L.flat_all_data_indicies[saved_selection_L.is_selected])})\")\n",
    "print(f\"\\t\\tuser_annotations[{user_annotations_S_context.get_initialization_code_string()}] = np.array({list(saved_selection_S.flat_all_data_indicies[saved_selection_S.is_selected])})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e130b",
   "metadata": {
    "tags": [
     "selections",
     "user_annotations"
    ]
   },
   "outputs": [],
   "source": [
    "## Update the currently displayed selections with the user annotations:\n",
    "\n",
    "\n",
    "## Capture current user selection\n",
    "saved_selection_L = pagination_controller_L.save_selection()\n",
    "saved_selection_S = pagination_controller_S.save_selection()\n",
    "\n",
    "saved_selection_L = UserAnnotationsManager.update_selections_from_annotations(saved_selection_L, user_annotations)\n",
    "saved_selection_S = UserAnnotationsManager.update_selections_from_annotations(saved_selection_S, user_annotations)\n",
    "## re-apply the selections:\n",
    "pagination_controller_L.restore_selections(saved_selection_L)\n",
    "pagination_controller_S.restore_selections(saved_selection_S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8858abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit_colors_list = None # default rainbow of colors for the raster plots\n",
    "neuron_qcolors_list = [pg.mkColor('black') for aclu in EITHER_subset.track_exclusive_aclus] # solid green for all\n",
    "unit_colors_list = DataSeriesColorHelpers.qColorsList_to_NDarray(neuron_qcolors_list, is_255_array=True)\n",
    "\n",
    "# Copy and modify the colors for the cells that are long/short exclusive:\n",
    "unit_colors_list_L = deepcopy(unit_colors_list)\n",
    "is_L_exclusive = np.isin(EITHER_subset.track_exclusive_aclus, long_exclusive.track_exclusive_aclus) # get long exclusive\n",
    "unit_colors_list_L[0, is_L_exclusive] = 255 # [1.0, 0.0, 0.0, 1.0]\n",
    "unit_colors_list_L[1, is_L_exclusive] = 0.0\n",
    "unit_colors_list_L[2, is_L_exclusive] = 0.0\n",
    "\n",
    "unit_colors_list_S = deepcopy(unit_colors_list)\n",
    "is_S_exclusive = np.isin(EITHER_subset.track_exclusive_aclus, short_exclusive.track_exclusive_aclus) # get short exclusive\n",
    "unit_colors_list_S[0, is_S_exclusive] = 0.0 # [1.0, 0.0, 0.0, 1.0]\n",
    "unit_colors_list_S[1, is_S_exclusive] = 0.0\n",
    "unit_colors_list_S[2, is_S_exclusive] = 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spikes_df = an_epoch_spikes_df.copy()\n",
    "scatterplot_tooltips_kwargs = Render2DScrollWindowPlotMixin._build_spike_data_tuples_from_spikes_df(spikes_df)\n",
    "override_scatter_plot_kwargs = {**scatterplot_tooltips_kwargs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e594d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "override_scatter_plot_kwargs = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vtick = _build_default_tick(tick_width=1.0)\n",
    "\n",
    "# pxMode: If True, spots are always the same size regardless of scaling, and size is given in px. Otherwise, size is in scene coordinates and the spots scale with the view. To ensure effective caching, QPen and QBrush objects should be reused as much as possible. Default is True\n",
    "\n",
    "# size: The size (or list of sizes) of spots. If pxMode is True, this value is in pixels. Otherwise, it is in the item’s local coordinate system.\n",
    "\n",
    "override_scatter_plot_kwargs = dict(pxMode=True, symbol=vtick, size=10, pen={'color': 'w', 'width': 1.0})\n",
    "\n",
    "# override_scatter_plot_kwargs = dict(pxMode=False, symbol=vtick, size=1, pen={'color': 'w', 'width': 1.0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the symbol properties\n",
    "# symbol = pg.mkPen('w', width=1)  # Pen for the lines\n",
    "size = 1.0  # Fixed x-width\n",
    "symbol_brush = None  # No brush for the symbol (transparent fill)\n",
    "\n",
    "# override_scatter_plot_kwargs = dict(pxMode=False, symbol='|', size=size, pen={'color': 'w', 'width': 1.0}) # , brush=symbol_brush\n",
    "\n",
    "override_scatter_plot_kwargs = dict(pxMode=False, symbol='arrow_up', size=1.0, pen={'color': 'w', 'width': 1.0}, hoverable=True) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bb530",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epoch_spikes_df_L.spikes.rebuild_fragile_linear_neuron_IDXs();\n",
    "filter_epoch_spikes_df_S.spikes.rebuild_fragile_linear_neuron_IDXs();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_L, win_L, plots_L, plots_data_L = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "\t\t\t\t\t\t\t\t\t\tepoch_id_key_name='replay_epoch_id', scatter_app_name=\"Long Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee132b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_S, win_S, plots_S, plots_data_S = plot_multiple_raster_plot(epochs_df_S, filter_epoch_spikes_df_S, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                 epoch_id_key_name='replay_epoch_id', scatter_app_name=\"Short Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26dd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single `plot_raster_plot` calls\n",
    "an_epoch = list(epochs_df_L.itertuples())[0]\n",
    "an_epoch_spikes_df = filter_epoch_spikes_df_L[filter_epoch_spikes_df_L['replay_epoch_id'] == an_epoch.Index]\n",
    "\n",
    "_out_single_raster_plot = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test1\")\n",
    "_out_single_raster_plot2 = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6071c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_alt, win_alt, plots_alt, plots_data_alt = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                         epoch_id_key_name='replay_epoch_id', scatter_app_name=\"ALT Long Decoded Example Replays\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d20407c",
   "metadata": {},
   "source": [
    "### Testing `plot_kourosh_activity_style_figure` for debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69512447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import plot_kourosh_activity_style_figure\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.helpers import _helper_make_scatterplot_clickable\n",
    "\n",
    "plot_aclus = EITHER_subset.track_exclusive_aclus.copy()\n",
    "# plot_aclus = EITHER_subset.track_exclusive_aclus[new_all_aclus_sort_indicies].copy()\n",
    "_out_A = plot_kourosh_activity_style_figure(long_results_obj, long_session, plot_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_idx=13, callout_epoch_IDXs=None, skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, plots, plots_data = _out_A\n",
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d4092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 2023-06-27 10:42: - [ ] Desperitely need a class that \"explodes\" the important variables and their types out of a DynamicParameters (dict-like) or other object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_n = plot_kourosh_activity_style_figure(long_results_obj, long_session, EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_idx=49, callout_epoch_IDXs=np.arange(6), skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af748f5c",
   "metadata": {},
   "source": [
    "# 2023-07-14 - LxC and SxC PhoJonathanSession plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis['neuron_replay_stats_df'], curr_jonathan_firing_rate_analysis['rdf']['rdf'], curr_jonathan_firing_rate_analysis['rdf']['aclu_to_idx'], curr_jonathan_firing_rate_analysis['irdf']['irdf']\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_display_BatchPhoJonathanFiguresHelper_PlusPDF_20.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\n",
    "print(f'active_out_figures_dict: {active_out_figures_dict}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d12ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() # new figure to hold the result\n",
    "# can show the figures by looping through and calling\n",
    "for a_ctxt, a_fig in active_out_figures_dict.items():\n",
    "    print(f'showing: {a_ctxt}')\n",
    "    a_fig.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9694b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pylustrator.load(...) aparently only works with files (.py scripts that draw the figure or saved figures)\n",
    "# fig_1c_parts = list(active_out_figures_dict.values())\n",
    "# assert len(fig_1c_parts) == 2\n",
    "# print(f\"{fig_1c_parts =}\")\n",
    "# fig = plt.figure() # new figure to hold the result\n",
    "# pylustrator.load(fig_1c_parts[0], figure=fig)\n",
    "# pylustrator.load(fig_1c_parts[1], offset=[1, 0], figure=fig)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea9f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_active_pipeline.registered_output_files_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a7c05d1",
   "metadata": {},
   "source": [
    "# Figure 2) Firing Rate Bar Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cf1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantaneous versions:\n",
    "from pyphocorehelpers.mixins.serialized import SerializedAttributesAllowBlockSpecifyingClass\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # 10ms\n",
    "_out_fig_2.compute(curr_active_pipeline=curr_active_pipeline, active_context=curr_active_pipeline.sess.get_context())\n",
    "\n",
    "_out_fig_2_figs = {}\n",
    "\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_out_fig_2_figs = _out_fig_2.display(defer_show=True, save_figure=True, active_context=curr_active_pipeline.sess.get_context())\n",
    "\n",
    "## Extract for debugging/checking:\n",
    "_out_inst_fr_comps = _out_fig_2.computation_result\n",
    "LxC_ReplayDeltaMinus, LxC_ReplayDeltaPlus, SxC_ReplayDeltaMinus, SxC_ReplayDeltaPlus = _out_inst_fr_comps.LxC_ReplayDeltaMinus, _out_inst_fr_comps.LxC_ReplayDeltaPlus, _out_inst_fr_comps.SxC_ReplayDeltaMinus, _out_inst_fr_comps.SxC_ReplayDeltaPlus\n",
    "LxC_ThetaDeltaMinus, LxC_ThetaDeltaPlus, SxC_ThetaDeltaMinus, SxC_ThetaDeltaPlus = _out_inst_fr_comps.LxC_ThetaDeltaMinus, _out_inst_fr_comps.LxC_ThetaDeltaPlus, _out_inst_fr_comps.SxC_ThetaDeltaMinus, _out_inst_fr_comps.SxC_ThetaDeltaPlus\n",
    "# LxC_ThetaDeltaMinus # cell_agg_inst_fr_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c06a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for a_fig_container in _out_fig_2_figs:\n",
    "\tax = a_fig_container.axes[0]\n",
    "\t# Hide the right and top spines\n",
    "\tax.spines[['right', 'top']].set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_inst_fr_comps = InstantaneousSpikeRateGroupsComputation(instantaneous_time_bin_size_seconds=0.01) # 10ms\n",
    "_out_inst_fr_comps.compute(curr_active_pipeline=curr_active_pipeline, active_context=curr_active_pipeline.sess.get_context())\n",
    "LxC_ReplayDeltaMinus, LxC_ReplayDeltaPlus, SxC_ReplayDeltaMinus, SxC_ReplayDeltaPlus = _out_inst_fr_comps.LxC_ReplayDeltaMinus, _out_inst_fr_comps.LxC_ReplayDeltaPlus, _out_inst_fr_comps.SxC_ReplayDeltaMinus, _out_inst_fr_comps.SxC_ReplayDeltaPlus\n",
    "LxC_ThetaDeltaMinus, LxC_ThetaDeltaPlus, SxC_ThetaDeltaMinus, SxC_ThetaDeltaPlus = _out_inst_fr_comps.LxC_ThetaDeltaMinus, _out_inst_fr_comps.LxC_ThetaDeltaPlus, _out_inst_fr_comps.SxC_ThetaDeltaMinus, _out_inst_fr_comps.SxC_ThetaDeltaPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f34b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_fr_output_filename = 'long_short_inst_firing_rates.pkl'\n",
    "inst_fr_output_path = curr_active_pipeline.get_output_path().joinpath(inst_fr_output_filename).resolve()\n",
    "inst_fr_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ed1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "\n",
    "# saveData(inst_fr_output_path, _out_fig_2)\n",
    "saveData(inst_fr_output_path, _out_fig_2.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e0139",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# saveData(inst_fr_output_path, (LxC_ReplayDeltaMinus, LxC_ReplayDeltaPlus, SxC_ReplayDeltaMinus, SxC_ReplayDeltaPlus, LxC_ThetaDeltaMinus, LxC_ThetaDeltaPlus, SxC_ThetaDeltaMinus, SxC_ThetaDeltaPlus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e77486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import print_filesystem_file_size, print_object_memory_usage\n",
    "\n",
    "\n",
    "print_object_memory_usage(_out_fig_2) #  2743.397699 MB\n",
    "# print_object_memory_usage(_out_fig_2.to_dict()) #  2743.397699 MB\n",
    "# print_object_memory_usage(_out_fig_2._pipeline_file_callback_fn) #  2737.983306 MB\n",
    "print(print_object_memory_usage(_out_inst_fr_comps)) #  5.489502 MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2adc047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_object_memory_usage((LxC_ReplayDeltaMinus, LxC_ReplayDeltaPlus, SxC_ReplayDeltaMinus, SxC_ReplayDeltaPlus, LxC_ThetaDeltaMinus, LxC_ThetaDeltaPlus, SxC_ThetaDeltaMinus, SxC_ThetaDeltaPlus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de48d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "\n",
    "srt1 = PaperFigureTwo(**loadData(inst_fr_output_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61bee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "srt2 = loadData(inst_fr_output_path)\n",
    "\n",
    "# When combining two `SpikeRateTrends` objects, they may differ in any/all (n_timebins, n_epochs, n_cells) making it difficult to safely concatenate them. \n",
    "# `LxC_ThetaDeltaMinus`\n",
    "# srt1: SpikeRateTrends = deepcopy(LxC_ThetaDeltaMinus) # SpikeRateTrends(...)\n",
    "# srt2: SpikeRateTrends = deepcopy(LxC_ThetaDeltaMinus) # SpikeRateTrends(...)\n",
    "# concatenated = srt1 + srt2\n",
    "# concatenated = srt1.concatenate(srt2)\n",
    "concatenated = SpikeRateTrends.concatenate(srt1, srt2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc507cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edea79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]] # only uses global_session\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d085cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ab296",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exclusive.track_exclusive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exclusive.track_exclusive_df['lap_delta_minus_inst_fr'] = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n",
    "long_exclusive.track_exclusive_df['lap_delta_plus_inst_fr'] = LxC_ThetaDeltaPlus.cell_agg_inst_fr_list # (n_cells, )\n",
    "long_exclusive.track_exclusive_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3077438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = LxC_ThetaDeltaMinus.epoch_agg_inst_fr_list # (n_epochs, n_cells)\n",
    "# d = d[:,1]\n",
    "d = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n",
    "d\n",
    "long_exclusive.track_exclusive_df['lap_delta_minus_inst_fr'] = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop out the very low (inactive) Epochs... I guess? But we want it to be influenced by the inactive epochs.\n",
    "curr_active_pipeline.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(LxC_ThetaDeltaMinus.inst_fr_signals_list) # n_epochs\n",
    "d = LxC_ThetaDeltaMinus.inst_fr_df_list\n",
    "d[0]\n",
    "# (n_epochs, n_cells)\n",
    "# print(f'{d.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e9b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "# https://seaborn.pydata.org/generated/seaborn.violinplot.html#seaborn.violinplot\n",
    "# Show each distribution with both violins and points\n",
    "sns.violinplot(data=d, palette=\"light:g\", inner=\"point\", orient=\"h\") # , split=True\n",
    "\n",
    "# sns.violinplot(data=LxC_ThetaDeltaMinus.inst_fr_df_list, x=\"deck\", y=\"age\", hue=\"alive\", split=True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfd716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LxC_ThetaDeltaPlus\n",
    "# Look at percent change\n",
    "(LxC_ThetaDeltaPlus.cell_agg_inst_fr_list - LxC_ThetaDeltaMinus.cell_agg_inst_fr_list) / LxC_ThetaDeltaMinus.cell_agg_inst_fr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b2901",
   "metadata": {},
   "source": [
    "## NOW: 2023-07-11 - Testing Batch-computed inst_firing_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "## Load the saved across-session results:\n",
    "inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = BatchSessionCompletionHandler.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=num_sessions) # some global context across all of the sessions, not sure what to put here.\n",
    "\n",
    "# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\n",
    "\n",
    "## Display the aggregate across sessions:\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn't save this info\n",
    "_out_fig_2.computation_result = across_session_inst_fr_computation\n",
    "_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\n",
    "# Set callback, the only self-specific property\n",
    "_out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f71cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\n",
    "\t\n",
    "_out_fig_2.perform_save()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d7b230c",
   "metadata": {},
   "source": [
    "# Figure 3) `PAPER_FIGURE_figure_3`: Firing Rate Index and Long/Short Firing Rate Replays v. Laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6008da8",
   "metadata": {
    "tags": [
     "figure_3",
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.matplotlib.AdvancedMatplotlibText import FormattedFigureText\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _plot_long_short_firing_rate_indicies\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out, _out2 = PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd3546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out2.figures\n",
    "_out.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c49f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0-0.090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd17dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = _out.figures\n",
    "fig\n",
    "# Computed long ($L$)|short($S$) firing rate indicies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14388eec",
   "metadata": {},
   "source": [
    "# 2023-07-07 - `batch_extended_programmatic_figures` Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "neptuner = batch_perform_all_plots(curr_active_pipeline, enable_neptune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126028b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_extended_programmatic_figures(curr_active_pipeline, write_vector_format=False, write_png=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb4dcda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
