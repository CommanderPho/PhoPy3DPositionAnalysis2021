{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6088dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: pho\n",
    "\"\"\"\n",
    "import sys\n",
    "from threading import Thread\n",
    "import time # for time.sleep\n",
    "from ipygany import PolyMesh, Scene, IsoColor, WarpByScalar\n",
    "import pyvista as pv\n",
    "import pyvistaqt as pvqt\n",
    "import colorcet as cc # Colormaps:\n",
    "import numpy as np\n",
    "import h5py\n",
    "import hdf5storage # conda install hdf5storage\n",
    "from pathlib import Path\n",
    "import bqplot.scales\n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "# import mplcursors\n",
    "import math # For color map generation\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.cm import hsv\n",
    "\n",
    "import ipywidgets as widgets\n",
    "# from PyQt5 import QtWidgets, uic\n",
    "from pyvistaqt import QtInteractor, MainWindow\n",
    "# from pyqt6 import QApplication\n",
    "from IPython.external.qt_for_kernel import QtGui\n",
    "from PyQt5.QtWidgets import QApplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313eba69-5c27-4e2d-8563-2220af614aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PhoPositionalData as pdp\n",
    "# from PhoPositionalData import load_exported, process_data\n",
    "from PhoPositionalData.load_exported import *\n",
    "# from PhoPositionalData.process_data import process_positionalAnalysis_data, gen_2d_histrogram, get_heatmap_color_vectors, process_chunk_equal_poritions_data, extract_spike_timeseries\n",
    "from PhoPositionalData.process_data import *\n",
    "from PhoPositionalData.plot_data import *\n",
    "from PhoPositionalData.plotting.animations import * # make_mp4_from_plotter, apply_close_overhead_zoomed_camera_view\n",
    "from PhoPositionalData.import_data import * # build_spike_positions_list, build_cellID_reverse_lookup_map\n",
    "from PhoPositionalData.analysis.interactive_placeCell_config import InteractivePlaceCellConfig, VideoOutputModeConfig, PlottingConfig  # VideoOutputModeConfig, InteractivePlaceCellConfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f94e40-c8dc-467a-9b67-7d2dcbbb277c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuropy module not found, adding directory to sys.path. \n",
      " >> Updated sys.path.\n",
      "Issue with pickled POSIX_PATH on windows for path R:\\data\\Bapun\\Day5TwoNovel\\RatS-Day5TwoNovel-2020-12-04_07-55-09.probegroup.npy, falling back to non-pickled version...\n",
      "linearized position loaded from file.\n",
      "Loading success: .ripple.npy.\n",
      "Loading success: .mua.npy.\n",
      "Loading success: .pbe.npy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataSession(RatS-Day5TwoNovel-2020-12-04_07-55-09.xml)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "try:\n",
    "    from neuropy import core\n",
    "except ImportError:\n",
    "    sys.path.append(r'C:\\Users\\Pho\\repos\\NeuroPy') # Windows\n",
    "    # sys.path.append('/home/pho/repo/BapunAnalysis2021/NeuroPy') # Linux\n",
    "    # sys.path.append(r'/Users/pho/repo/Python Projects/NeuroPy') # MacOS\n",
    "    print('neuropy module not found, adding directory to sys.path. \\n >> Updated sys.path.')\n",
    "    from neuropy import core\n",
    "# from neuropy.core.dataSession import DataSession, processDataSession\n",
    "\n",
    "from neuropy.core.dataSession import DataSessionLoader, DataSession, processDataSession\n",
    "\n",
    "# basedir = '/media/share/data/Bapun/Day5TwoNovel' # Linux\n",
    "basedir = 'R:\\data\\Bapun\\Day5TwoNovel' # Windows\n",
    "# basedir = '/Volumes/iNeo/Data/Bapun/Day5TwoNovel' # MacOS\n",
    "sess = core.processDataSession(basedir)\n",
    "# curr_args_dict = dict()\n",
    "# curr_args_dict['basepath'] = basepath\n",
    "# curr_args_dict['session'] = DataSession()\n",
    "# sess = DataSessionLoader.default_load_bapun_npy_session_folder(curr_args_dict)\n",
    "sess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e63481c-9325-4477-8ec0-929888f85871",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: The only place that I need to be careful with indexing is with sess.position properties, as these appear to be represented in terms of the number of 60Hz samples instead of in seconds like the Neurons and other classes.\n",
    "# active_epoch_name = 'maze1'\n",
    "active_epoch_name = 'maze2'\n",
    "active_subplots_shape = (1,1) # Single subplot\n",
    "# active_subplots_shape = '1|2' # 1 subplot on left, two on right\n",
    "active_config = InteractivePlaceCellConfig(active_epoch_name,\n",
    "                    VideoOutputModeConfig(active_frame_range=np.arange(11070.0, 13970.0), video_output_parent_dir=Path('output', active_epoch_name), active_is_video_output_mode=False),\n",
    "                    PlottingConfig(output_subplots_shape=active_subplots_shape, output_parent_dir=Path('output', active_epoch_name), use_age_proportional_spike_scale=True)) # '3|1\n",
    "active_epoch_times = sess.epochs[active_config.active_epochs] \n",
    "# active_epoch_times = sess.epochs['maze2']  # np.arange(15200.0, 18000.0)\n",
    "# active_epoch_times = sess.epochs['maze1']  # array([11070, 13970], dtype=int64)\n",
    "print('Constraining to epoch with times (start: {}, end: {})'.format(active_epoch_times[0], active_epoch_times[1]))\n",
    "\n",
    "active_epoch_session_Neurons = sess.neurons.get_neuron_type('pyr').time_slice(active_epoch_times[0], active_epoch_times[1]) # Filter by pyramidal cells only, returns a core.Neurons object with its spiketrains filtered for the provided start/end times\n",
    "active_epoch_position_times_index_mask = sess.position.time_slice_indicies(active_epoch_times[0], active_epoch_times[1]) # a Boolean selection mask\n",
    "active_epoch_position_times = sess.position.time[active_epoch_position_times_index_mask] # The actual times\n",
    "active_epoch_relative_position_times = active_epoch_position_times - active_epoch_position_times[0] # Subtract off the first index, so that it becomes zero\n",
    "active_epoch_pos = sess.position.time_slice(active_epoch_times[0], active_epoch_times[1]) # active_epoch_pos's .time and start/end are all valid\n",
    "# have active_epoch_position_times: the actual times each position sample occured in seconds, active_epoch_relative_position_times: the same as active_epoch_position_times but starting at zero. Finally, have a complete active_epoch_pos object\n",
    "\n",
    "## Compute Placefields if needed:\n",
    "from neuropy.analyses import Pf1D, Pf2D\n",
    "from neuropy.plotting.spikes import get_neuron_colors\n",
    "\n",
    "should_force_recompute_placefields = True\n",
    "\n",
    "try: active_epoch_placefields\n",
    "except NameError: active_epoch_placefields = None # Checks variable active_epoch_placefields's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "if ((active_epoch_placefields is None) or should_force_recompute_placefields):\n",
    "    print('Recomputing active_epoch_placefields...')\n",
    "    active_epoch_placefields1D = Pf1D(neurons=active_epoch_session_Neurons, position=active_epoch_pos.linear_pos_obj, speed_thresh=4, grid_bin=4)\n",
    "    ax_pf_1D = active_epoch_placefields1D.plot_ratemaps()\n",
    "    active_pf_1D_identifier_string = '1D Placefields - {}'.format(active_epoch_name)\n",
    "    plt.title(active_pf_1D_identifier_string)\n",
    "    active_pf_1D_output_filename = '{}.pdf'.format(active_pf_1D_identifier_string)\n",
    "    active_pf_1D_output_filepath = active_config.plotting_config.active_output_parent_dir.joinpath(active_pf_1D_output_filename)\n",
    "    print('Saving 1D Placefield image out to \"{}\"...'.format(active_pf_1D_output_filepath))\n",
    "    plt.savefig(active_pf_1D_output_filepath)          \n",
    "    # active_epoch_placefields = active_epoch_placefields1D\n",
    "    print('done.')\n",
    "else:\n",
    "    print('active_epoch_placefields already exists, reusing it')\n",
    "    \n",
    "try: active_epoch_placefields2D\n",
    "except NameError: active_epoch_placefields2D = None # Checks variable active_epoch_placefields's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "if ((active_epoch_placefields2D is None) or should_force_recompute_placefields):\n",
    "    print('Recomputing active_epoch_placefields2D...')\n",
    "    active_epoch_placefields2D = Pf2D(neurons=active_epoch_session_Neurons, position=active_epoch_pos, speed_thresh=4, grid_bin=4)\n",
    "    # active_epoch_placefields2D.plotMap(subplots=(1, 1),figsize=(10,10))\n",
    "    # active_pf_2D_figures, active_pf_2D_gs = active_epoch_placefields2D.plotMap(subplots=(4, 4),figsize=(10, 10))\n",
    "    # active_epoch_placefields2D.occupancy # (37, 38) = (len(active_epoch_placefields2D.ratemap.xbin_centers), len(active_epoch_placefields2D.ratemap.ybin_centers))\n",
    "    active_pf_occupancy_2D_identifier_string = '2D Occupancy - {}'.format(active_epoch_name)\n",
    "    occupancy_fig = plt.figure()\n",
    "    occupancy_ax = occupancy_fig.gca()\n",
    "    im = occupancy_ax.pcolorfast(\n",
    "        active_epoch_placefields2D.ratemap.xbin_centers,\n",
    "        active_epoch_placefields2D.ratemap.ybin_centers,\n",
    "        np.rot90(np.fliplr(active_epoch_placefields2D.occupancy)) / np.max(active_epoch_placefields2D.occupancy),\n",
    "        cmap=\"jet\",\n",
    "        vmin=0,\n",
    "    )  # rot90(flipud... is necessary to match plotRaw configuration.\n",
    "    plt.title(active_pf_occupancy_2D_identifier_string)\n",
    "    plt.show()\n",
    "    # Save ocupancy figure out to disk:\n",
    "    active_pf_occupancy_2D_output_filename = '{}.pdf'.format(active_pf_occupancy_2D_identifier_string)\n",
    "    active_pf_occupancy_2D_output_filepath = active_config.plotting_config.active_output_parent_dir.joinpath(active_pf_occupancy_2D_output_filename)\n",
    "    print('Saving 2D Placefield image out to \"{}\"...'.format(active_pf_occupancy_2D_output_filepath))\n",
    "    occupancy_fig.savefig(active_pf_occupancy_2D_output_filepath)\n",
    "    print('done.')\n",
    "    ## 2D Tuning Curves Figure:\n",
    "    active_pf_2D_figures, active_pf_2D_gs = active_epoch_placefields2D.plotMap(subplots=(7, 7),figsize=(10, 10))\n",
    "    # active_epoch_placefields2D.plotRaw()\n",
    "    active_pf_2D_identifier_string = '2D Placefields - {}'.format(active_epoch_name)\n",
    "    # plt.title(active_pf_2D_identifier_string)\n",
    "    active_pf_2D_output_filename = '{}.pdf'.format(active_pf_2D_identifier_string)\n",
    "    active_pf_2D_output_filepath = active_config.plotting_config.active_output_parent_dir.joinpath(active_pf_2D_output_filename)\n",
    "    print('Saving 2D Placefield image out to \"{}\"...'.format(active_pf_2D_output_filepath))\n",
    "    for aFig in active_pf_2D_figures:\n",
    "        aFig.savefig(active_pf_2D_output_filepath)\n",
    "    print('done.')\n",
    "else:\n",
    "    print('active_epoch_placefields already exists, reusing it')\n",
    "    \n",
    "active_epoch_placefields = active_epoch_placefields2D\n",
    "\n",
    "# Get the cell IDs that have a good place field mapping:\n",
    "good_placefield_neuronIDs = np.array(active_epoch_placefields.ratemap.neuron_ids) # in order of ascending ID\n",
    "good_placefield_neuronIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1935ae0c-d838-455f-a14d-2fbd246453d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11066</td>\n",
       "      <td>pre</td>\n",
       "      <td>11066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11070</td>\n",
       "      <td>13970</td>\n",
       "      <td>maze1</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13972</td>\n",
       "      <td>20754</td>\n",
       "      <td>post1</td>\n",
       "      <td>6782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20756</td>\n",
       "      <td>24004</td>\n",
       "      <td>maze2</td>\n",
       "      <td>3248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24006</td>\n",
       "      <td>42305</td>\n",
       "      <td>post2</td>\n",
       "      <td>18299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start   stop  label  duration\n",
       "0      0  11066    pre     11066\n",
       "1  11070  13970  maze1      2900\n",
       "3  13972  20754  post1      6782\n",
       "2  20756  24004  maze2      3248\n",
       "4  24006  42305  post2     18299"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.epochs.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17552211-da15-4494-8b67-145e707691cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.position.time: [0.00000000e+00 1.66666732e-02 3.33333465e-02 ... 4.23057500e+04\n",
      " 4.23057667e+04 4.23057833e+04]\n",
      " sess.position.duration: 42305.78333333333\n",
      " sess.position.time[-1]: 42305.78333333333\n",
      " sess.position.time[0]: 0.0\n",
      " sess.position.sampling_rate: 60\n",
      " sess.position.t_start: 0\n",
      " sess.position.t_stop: 42305.78333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess.position.time # 0.00000000e+00, ..., 4.23057833e+04\n",
    "\n",
    "sess.position.time[-1] # 42305.78333333333\n",
    "sess.position.time[0] # 0.0\n",
    "sess.position.sampling_rate # 60\n",
    "sess.position.t_start # 0\n",
    "sess.position.t_stop # 42305.78333333333\n",
    "\n",
    "\n",
    "# sess.position.time\n",
    "# sess.position.time[-1]\n",
    "# sess.position.time[0]\n",
    "# sess.position.sampling_rate\n",
    "# sess.position.t_start\n",
    "# sess.position.t_stop\n",
    "\n",
    "print('sess.position.time: {}\\n sess.position.duration: {}\\n sess.position.time[-1]: {}\\n sess.position.time[0]: {}\\n sess.position.sampling_rate: {}\\n sess.position.t_start: {}\\n sess.position.t_stop: {}\\n'.format(\n",
    "    sess.position.time,\n",
    "    sess.position.duration,\n",
    "    sess.position.time[-1],\n",
    "    sess.position.time[0],\n",
    "    sess.position.sampling_rate,\n",
    "    sess.position.t_start,\n",
    "    sess.position.t_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5658e0b-4de2-481d-8c5a-2faa5024052c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_data_min_val: 0.0; curr_data_max_val: 20.999999893781823\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plots the tuning curves one at a time, and also can plot them without very low probabilitiy entries (by setting these entries to np.nan)\n",
    "curr_tuning_curves = active_epoch_placefields.ratemap.tuning_curves\n",
    "# curr_tuning_curves = active_epoch_placefields.ratemap.normalized_tuning_curves\n",
    "curr_index = 5\n",
    "curr_unitID = active_epoch_placefields2D.cell_ids[curr_index]\n",
    "curr_identifier_string = '2D Placemap - {} - Unit[{}] (ID {})'.format(active_epoch_name, curr_index, curr_unitID)\n",
    "curr_data = curr_tuning_curves[curr_index]\n",
    "curr_data_min_val = np.min(curr_data)\n",
    "curr_data_max_val = np.max(curr_data)\n",
    "curr_data[curr_data < 0.01] = np.nan\n",
    "print('curr_data_min_val: {}; curr_data_max_val: {}'.format(curr_data_min_val, curr_data_max_val))\n",
    "curr_fig = plt.figure()\n",
    "curr_ax = curr_fig.gca()\n",
    "im = curr_ax.pcolorfast(\n",
    "    active_epoch_placefields2D.ratemap.xbin_centers,\n",
    "    active_epoch_placefields2D.ratemap.ybin_centers,\n",
    "    np.rot90(np.fliplr(curr_data)),\n",
    "    cmap=\"jet\",\n",
    "    vmin=0,\n",
    ")  # rot90(flipud... is necessary to match plotRaw configuration.\n",
    "plt.title(curr_identifier_string)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2611563-244e-4c04-823f-25d9013458bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cells: 35\n",
      "cell_ids: [ 1  3  8 11 13 20 27 37 38 42 43 44 47 48 49 53 54 55 56 57 58 61 62 63\n",
      " 64 65 68 70 75 77 80 87 91 93 95]\n",
      "num_flattened_spikes: 104159\n",
      "flattened_spike_positions_list: (2, 104159)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pho\\repos\\NeuroPy\\neuropy\\utils\\mathutil.py:23: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (x - np.min(x, axis=axis, keepdims=True)) / np.ptp(\n"
     ]
    }
   ],
   "source": [
    "# pf_ax, pf_sort_ind, pf_colors = active_epoch_placefields.plot_ratemaps()\n",
    "# from neuropy.utils import mathutil\n",
    "# curr_tuning_curves = mathutil.min_max_scaler(active_epoch_placefields.ratemap.tuning_curves) # 37x25x27 ndarray\n",
    "# curr_tuning_curves = active_epoch_placefields.ratemap.tuning_curves\n",
    "curr_tuning_curves = active_epoch_placefields.ratemap.normalized_tuning_curves\n",
    "# sort_ind = np.argsort(np.argmax(curr_tuning_curves, axis=1))\n",
    "# ind = np.unravel_index(np.argsort(curr_tuning_curves, axis=None), curr_tuning_curves.shape)\n",
    "num_curr_tuning_curves = len(curr_tuning_curves)\n",
    "pf_sort_ind = np.arange(num_curr_tuning_curves)\n",
    "pf_colors = get_neuron_colors(pf_sort_ind)\n",
    "pf_sort_ind = np.array([int(pf_sort_ind[i]) for i in np.arange(len(pf_sort_ind))]) # convert to integer scalar array\n",
    "pf_sorted_good_placefield_neuronIDs = good_placefield_neuronIDs[pf_sort_ind]\n",
    "reverse_color_sort_indices = np.argsort(pf_sort_ind)\n",
    "pf_colors = pf_colors[:, reverse_color_sort_indices] # pf_colors shape is still (4, 31)\n",
    "active_epoch_session_Neurons = active_epoch_session_Neurons.get_by_id(good_placefield_neuronIDs) # Filter by good placefields only\n",
    "\n",
    "# Unpacking final values into separate variables:\n",
    "# Spike variables:\n",
    "num_cells = active_epoch_session_Neurons.n_neurons\n",
    "spike_list = active_epoch_session_Neurons.spiketrains\n",
    "cell_ids = active_epoch_session_Neurons.neuron_ids\n",
    "flattened_spikes = active_epoch_session_Neurons.get_flattened_spikes() # get_flattened_spikes(..) returns a FlattenedSpiketrains object\n",
    "# Position variables: t, x, y\n",
    "t = active_epoch_pos.time\n",
    "x = active_epoch_pos.x\n",
    "y = active_epoch_pos.y\n",
    "linear_pos = active_epoch_pos.linear_pos\n",
    "# speeds = active_epoch_pos.speed # note this has 1 less element than active_epoch_pos.x\n",
    "# Determine the x and y positions each spike occured for each cell\n",
    "spike_positions_list = build_spike_positions_list(spike_list, t, x, y)\n",
    "reverse_cellID_idx_lookup_map = build_cellID_reverse_lookup_map(cell_ids)\n",
    "print('num_cells: {}'.format(num_cells))\n",
    "print('cell_ids: {}'.format(cell_ids)) # cell_ids is now a regular python list with 57 elements\n",
    "\n",
    "active_cells_colormap = pf_colors.T # Make the colormap from the listed colors\n",
    "active_cells_listed_colormap = ListedColormap(active_cells_colormap)\n",
    "\n",
    "# Gets the flattened spikes, sorted in ascending timestamp for all cells.\n",
    "num_flattened_spikes = np.size(flattened_spikes.flattened_spike_times)\n",
    "print('num_flattened_spikes: {}'.format(num_flattened_spikes))\n",
    "# Build the Active UnitIDs\n",
    "flattened_spike_active_unitIdentities = np.array([int(reverse_cellID_idx_lookup_map[original_cellID]) for original_cellID in flattened_spikes.flattened_spike_identities]) # since flattened_spikes.flattened_spike_identities is already sorted, don't double sort\n",
    "## Build the flattened spike positions list\n",
    "flattened_spike_positions_list = np.concatenate(tuple(spike_positions_list), axis=1) # needs tuple(...) to conver the list into a tuple, which is the format it expects\n",
    "flattened_spike_positions_list = flattened_spike_positions_list[:, flattened_spikes.flattened_sort_indicies] # ensure the positions are ordered the same as the other flattened items so they line up\n",
    "print('flattened_spike_positions_list: {}'.format(np.shape(flattened_spike_positions_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e64b3d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_epoch_pos.sampling_rate (Hz): 60\n",
      "longer_spikes_window - curr_view_window_length_samples - 61440\n",
      "recent_spikes_window - curr_view_window_length_samples - 60\n"
     ]
    }
   ],
   "source": [
    "# have active_epoch_position_times: the actual times each position sample occured in seconds, active_epoch_relative_position_times: the same as active_epoch_position_times but starting at zero\n",
    "# describe the movement\n",
    "\n",
    "from PhoPositionalData.plotting.visualization_window import VisualizationWindow # Used to build \"Windows\" into the data points such as the window defining the fixed time period preceeding the current time where spikes had recently fired, etc.\n",
    "\n",
    "# Split the position data into equal sized chunks to be displayed at a single time. These will look like portions of the trajectory and be used to animate. # Chunk the data to create the animation.\n",
    "curr_plot_update_step = 1 # Update every frame\n",
    "curr_plot_update_frequency = curr_plot_update_step * active_epoch_pos.sampling_rate # number of updates per second (Hz)\n",
    "num_time_points = active_epoch_pos.n_frames / curr_plot_update_step\n",
    "print('active_epoch_pos.sampling_rate (Hz): {}'.format(active_epoch_pos.sampling_rate))\n",
    "\n",
    "# curr_window_duration = 2.5 # in seconds\n",
    "# curr_view_window_length_samples = int(np.floor(curr_window_duration * active_epoch_pos.sampling_rate)) # number of samples the window should last\n",
    "# recent_spikes_window = VisualizationWindow(duration_seconds=curr_window_duration, duration_num_frames=curr_view_window_length_samples)\n",
    "\n",
    "# curr_recently_window_duration = 0.5 # in seconds\n",
    "# curr_view_window_length_samples = int(np.floor(curr_window_duration * active_epoch_pos.sampling_rate)) # number of samples the window should last\n",
    "\n",
    "## Simplified with just two windows:\n",
    "longer_spikes_window = VisualizationWindow(duration_seconds=1024.0, sampling_rate=active_epoch_pos.sampling_rate) # have it start clearing spikes more than 30 seconds old\n",
    "curr_view_window_length_samples = longer_spikes_window.duration_num_frames # number of samples the window should last\n",
    "print('longer_spikes_window - curr_view_window_length_samples - {}'.format(curr_view_window_length_samples))\n",
    "\n",
    "recent_spikes_window = VisualizationWindow(duration_seconds=1.0, sampling_rate=active_epoch_pos.sampling_rate)\n",
    "curr_view_window_length_samples = recent_spikes_window.duration_num_frames # number of samples the window should last\n",
    "print('recent_spikes_window - curr_view_window_length_samples - {}'.format(curr_view_window_length_samples))\n",
    "\n",
    "## Build the sliding windows:\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "# build a sliding window to be able to retreive the correct flattened indicies for any given timestep\n",
    "active_epoch_position_linear_indicies = np.arange(np.size(active_epoch_position_times))\n",
    "pre_computed_window_sample_indicies = recent_spikes_window.build_sliding_windows(active_epoch_position_linear_indicies)\n",
    "# print('pre_computed_window_sample_indicies: {}\\n shape: {}'.format(pre_computed_window_sample_indicies, np.shape(pre_computed_window_sample_indicies)))\n",
    "\n",
    "## New Pre Computed Indicies Way:\n",
    "z_fixed = np.full((recent_spikes_window.duration_num_frames,), 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "242a014c-ae46-4e43-8095-91dbc11d3ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on frate_thresh, excluded neuron_ids: [ 8 37 49 80]\n"
     ]
    }
   ],
   "source": [
    "## ICA and PCA Analysis\n",
    "should_show_2D_ICA_plots = False\n",
    "from PhoPositionalData.analysis.neuronal_dimensionality_reduction import runAnalysis_PCAandICA\n",
    "active_session_ensembles, template, zsc_template, pca_data = runAnalysis_PCAandICA(active_epoch_session_Neurons, bin_size=0.250, frate_thresh=0.1, should_plot=should_show_2D_ICA_plots, active_cells_colormap=active_cells_colormap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bca1e4-77d4-4a42-9883-57f0ff6431d4",
   "metadata": {},
   "source": [
    "## Main Spike/Placemap plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d92bd2e-138f-4df6-8731-12fbdd3c950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PhoPositionalData.plotting.gui import customize_default_pyvista_theme, print_controls_helper_text\n",
    "customize_default_pyvista_theme() # Sets the default theme values to those specified in my imported file\n",
    "# This defines the position of the vertical/horizontal splitting, in this case 40% of the vertical/horizontal dimension of the window\n",
    "# pv.global_theme.multi_rendering_splitting_position = 0.40\n",
    "pv.global_theme.multi_rendering_splitting_position = 0.80\n",
    "\n",
    "from PhoPositionalData.plotting.spikeAndPositions import build_active_spikes_plot_pointdata, build_active_spikes_plot_data, build_flat_map_plot_data, build_spike_spawn_effect_light_actor, spike_geom_circle, spike_geom_box, spike_geom_cone, animal_location_circle, animal_location_trail_circle\n",
    "from PhoPositionalData.plotting.spikeAndPositions import InteractiveSliderWrapper # for wrapping the slider\n",
    "num_time_points = active_epoch_pos.n_frames / curr_plot_update_step\n",
    "# print('num_time_points: {}\\n'.format(num_time_points))\n",
    "\n",
    "## Opacity Helpers:\n",
    "last_only_opacity_values = np.zeros([curr_view_window_length_samples,])\n",
    "last_only_opacity_values[-1] = 1.0\n",
    "# gradually_fading_opacity_values = np.arange(curr_view_window_length_samples)\n",
    "gradually_fading_opacity_values = np.linspace(0.0, 1.0, curr_view_window_length_samples)\n",
    "long_gradually_fading_opacity_values = np.linspace(0.0, 1.0, longer_spikes_window.duration_num_frames)\n",
    "sharply_fading_opacity_values = np.linspace(0.0, 0.6, curr_view_window_length_samples)\n",
    "# sharply_fading_opacity_values[-1] = 0.1 # last element (corresponding to current position) is set to 1.0\n",
    "\n",
    "# active_trail_opacity_values = last_only_opacity_values.copy()\n",
    "# active_trail_opacity_values = gradually_fading_opacity_values.copy()\n",
    "active_trail_opacity_values = sharply_fading_opacity_values.copy()\n",
    "# print('active_trail_opacity_values: {}\\n'.format(np.shape(active_trail_opacity_values)))\n",
    "# active_trail_size_values = np.full([curr_view_window_length_samples,], 0.6) # all have a scale of 0.6\n",
    "active_trail_size_values = np.linspace(0.2, 0.6, curr_view_window_length_samples) # fade from a scale of 0.2 to 0.6\n",
    "# active_trail_size_values[-1] = 6.0 # except for the end (current) point, which has a scale of 1.0\n",
    "# active_trail_size_values = sharply_fading_opacity_values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce9fd90-e85c-470c-be21-a258d16c8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PhoPositionalData.plotting.spikeAndPositions import plot_placefields2D, update_plotVisiblePlacefields2D\n",
    "pActiveTuningCurvesPlotter = pvqt.BackgroundPlotter(window_size=(1920, 1080), shape=(1,1), off_screen=False) # Use just like you would a pv.Plotter() instance\n",
    "pActiveTuningCurvesPlotter.clear()\n",
    "# Plot the flat arena\n",
    "pdata_maze, pc_maze = build_flat_map_plot_data(x, y)\n",
    "pActiveTuningCurvesPlotter.add_mesh(pc_maze, name='maze_bg', label='maze', color=\"black\", render=True)\n",
    "pActiveTuningCurvesPlotter, tuningCurvePlotActors, tuningCurvePlotLegendActor = plot_placefields2D(pActiveTuningCurvesPlotter, active_epoch_placefields, pf_colors, zScalingFactor=10.0)\n",
    "\n",
    "# tuningCurvePlotActors[1].VisibilityOn()\n",
    "# legendActor = pTuningCurves.add_legend(name='tuningCurvesLegend', origin=[0.9, 0.0], size=[0.1, 1.0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d00ce8-56fc-447a-9826-aff66e7b215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_legendNumberOfEntries = tuningCurvePlotLegendActor.GetNumberOfEntries()\n",
    "# print('tuningCurvePlotLegendActor.GetPosition(): {}; tuningCurvePlotLegendActor.GetPosition2(): {};'.format(tuningCurvePlotLegendActor.GetPosition(), tuningCurvePlotLegendActor.GetPosition2()))\n",
    "# # print('tuningCurvePlotLegendActor.GetPositionCoordinate(): {}; tuningCurvePlotLegendActor.GetPosition2Coordinate(): {}'.format(tuningCurvePlotLegendActor.GetPositionCoordinate(), tuningCurvePlotLegendActor.GetPosition2Coordinate()))\n",
    "# print('tuningCurvePlotLegendActor.GetHeight(): {}; tuningCurvePlotLegendActor.GetWidth(): {};'.format(tuningCurvePlotLegendActor.GetHeight(), tuningCurvePlotLegendActor.GetWidth()))\n",
    "# print('temp_legendNumberOfEntries: {}'.format(temp_legendNumberOfEntries))\n",
    "# # tuningCurvePlotLegendActor.GetPropertyKeys()\n",
    "# for i in np.arange(temp_legendNumberOfEntries):    \n",
    "#     temp_legendEntryString = tuningCurvePlotLegendActor.GetEntryString(i)\n",
    "#     temp_legendEntrySymbol = tuningCurvePlotLegendActor.GetEntrySymbol(i)\n",
    "    \n",
    "#     # temp_legendActors = tuningCurvePlotLegendActor.GetActors(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6826c-5d97-45af-b35d-cbbf81b5dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Interactively Adjusting Visibility:\n",
    "curr_is_visible = np.full([len(tuningCurvePlotActors), 1], False)\n",
    "curr_is_visible[12] = True\n",
    "update_plotVisiblePlacefields2D(tuningCurvePlotActors, curr_is_visible)\n",
    "# pActiveTuningCurvesPlotter.disable_depth_peeling()\n",
    "pActiveTuningCurvesPlotter.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab61be64-3491-48d0-8e9e-35cd6017a631",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Slider with Callback Function Example:\n",
    "\n",
    "######################\n",
    "# General Plotting Method:    \n",
    "def on_slider_update_mesh(value):\n",
    "    curr_i = int(value)    \n",
    "    active_window_sample_indicies = np.squeeze(pre_computed_window_sample_indicies[curr_i,:]) # Get the current precomputed indicies for this curr_i\n",
    "    \n",
    "    ## Spike Plotting:\n",
    "    # Get the times that fall within the current plot window:\n",
    "    curr_time_fixedSegments = t[active_window_sample_indicies] # New Way\n",
    "    t_start = curr_time_fixedSegments[0]\n",
    "    t_stop = curr_time_fixedSegments[-1]\n",
    "    # print('Constraining to curr_time_fixedSegments with times (start: {}, end: {})'.format(t_start, t_stop))\n",
    "    # print('curr_time_fixedSegments: {}'.format(curr_time_fixedSegments))\n",
    "    curr_text_rendering_string = 'curr_i: {:d}; (t_start: {:.2f}, t_stop: {:.2f})'.format(curr_i, t_start, t_stop) # :.3f\n",
    "    p.add_text(curr_text_rendering_string, name='lblCurrent_spike_range', position='lower_right', color='white', shadow=True, font_size=10)\n",
    "\n",
    "    ## Historical Spikes:\n",
    "    # active_included_all_historical_indicies = (flattened_spikes.flattened_spike_times < t_stop) # Accumulate Spikes mode. All spikes occuring prior to the end of the frame (meaning the current time) are plotted\n",
    "    historical_t_start = (t_stop - longer_spikes_window.duration_seconds) # Get the earliest time that will be included in the search\n",
    "    active_included_all_historical_indicies = ((flattened_spikes.flattened_spike_times > historical_t_start) & (flattened_spikes.flattened_spike_times < t_stop)) # Two Sided Range Mode\n",
    "    historical_spikes_pdata, historical_spikes_pc = build_active_spikes_plot_data(flattened_spikes.flattened_spike_times[active_included_all_historical_indicies],\n",
    "                                                                                  flattened_spike_active_unitIdentities[active_included_all_historical_indicies],\n",
    "                                                                                  flattened_spike_positions_list[:, active_included_all_historical_indicies],\n",
    "                                                                                  spike_geom=spike_geom_box.copy())\n",
    "    if historical_spikes_pc.n_points >= 1:\n",
    "        historical_main_spikes_mesh = p.add_mesh(historical_spikes_pc, name='historical_spikes_main', scalars='cellID', cmap=active_cells_listed_colormap, show_scalar_bar=False, lighting=True, render=False)\n",
    "\n",
    "    ## Actively Firing Spikes:\n",
    "    recent_spikes_t_start = (t_stop - recent_spikes_window.duration_seconds) # Get the earliest time that will be included in the recent spikes\n",
    "    # print('recent_spikes_t_start: {}; t_start: {}'.format(recent_spikes_t_start, t_start))\n",
    "    active_included_recent_only_indicies = ((flattened_spikes.flattened_spike_times > recent_spikes_t_start) & (flattened_spikes.flattened_spike_times < t_stop)) # Two Sided Range Mode\n",
    "    if active_config.plotting_config.use_age_proportional_spike_scale:\n",
    "        ## Allows more control of the output spike glyphs (like custom scales with age)\n",
    "        recent_only_spikes_pdata = build_active_spikes_plot_pointdata(flattened_spikes.flattened_spike_times[active_included_recent_only_indicies],\n",
    "                                                                                        flattened_spike_active_unitIdentities[active_included_recent_only_indicies],\n",
    "                                                                                        flattened_spike_positions_list[:, active_included_recent_only_indicies])\n",
    "        recent_only_spikes_pdata['age'] = np.flip((t_stop - flattened_spikes.flattened_spike_times[active_included_recent_only_indicies]))\n",
    "        recent_only_spikes_pc = recent_only_spikes_pdata.glyph(scale='age', geom=spike_geom_cone.copy())\n",
    "\n",
    "    else:\n",
    "        recent_only_spikes_pdata, recent_only_spikes_pc = build_active_spikes_plot_data(flattened_spikes.flattened_spike_times[active_included_recent_only_indicies],\n",
    "                                                                                    flattened_spike_active_unitIdentities[active_included_recent_only_indicies],\n",
    "                                                                                    flattened_spike_positions_list[:, active_included_recent_only_indicies],\n",
    "                                                                                    spike_geom=spike_geom_cone.copy())\n",
    "    if recent_only_spikes_pc.n_points >= 1:\n",
    "        recent_only_main_spikes_mesh = p.add_mesh(recent_only_spikes_pc, name='recent_only_spikes_main', scalars='cellID', cmap=active_cells_listed_colormap, show_scalar_bar=False, lighting=False, render=False) # color='white'\n",
    "            \n",
    "    ## Animal Position and Location Trail Plotting:\n",
    "    point_cloud_fixedSegements_positionTrail = np.column_stack((x[active_window_sample_indicies], y[active_window_sample_indicies], z_fixed))\n",
    "    pdata_positionTrail = pv.PolyData(point_cloud_fixedSegements_positionTrail.copy()) # a mesh\n",
    "    pdata_positionTrail.point_data['pho_fade_values'] = active_trail_opacity_values\n",
    "    pdata_positionTrail.point_data['pho_size_values'] = active_trail_size_values\n",
    "    # create many spheres from the point cloud\n",
    "    pc_positionTrail = pdata_positionTrail.glyph(scale='pho_size_values', geom=animal_location_trail_circle)\n",
    "    animal_location_trail_mesh = p.add_mesh(pc_positionTrail, name='animal_location_trail', ambient=0.6, opacity='linear_r', scalars='pho_fade_values', nan_opacity=0.0,\n",
    "                                            show_edges=False, render_lines_as_tubes=True, show_scalar_bar=False, use_transparency=True, render=False) # works to render a heat colored (most recent==hotter) position\n",
    "\n",
    "    ## Animal Current Position:\n",
    "    curr_animal_point = point_cloud_fixedSegements_positionTrail[-1,:].copy() # Get the last point\n",
    "    pdata_current_point = pv.PolyData(curr_animal_point) # a mesh\n",
    "    pc_current_point = pdata_current_point.glyph(scale=False, geom=animal_location_circle)\n",
    "    animal_current_location_point_mesh = p.add_mesh(pc_current_point, name='animal_location', color='green', ambient=0.6, opacity=0.5,\n",
    "                                                    show_edges=True, edge_color=[0.05, 0.8, 0.08], line_width=3.0, nan_opacity=0.0, render_lines_as_tubes=True,\n",
    "                                                    show_scalar_bar=False, use_transparency=True, render=False) # works to render a heat colored (most recent==hotter) position\n",
    "    \n",
    "    p.render() # renders to ensure it's updated after changing the ScalarVisibility above\n",
    "    # p.update()\n",
    "    # p.app.processEvents() # not needed probably\n",
    "    return\n",
    "\n",
    "\n",
    "################################################\n",
    "### Build Appropriate Plotter and set it up:\n",
    "#####################\n",
    "# Only Create a new BackgroundPlotter if it's needed:\n",
    "if (active_config.video_output_config.active_is_video_output_mode):\n",
    "    ## Video mode should use a regular plotter object\n",
    "    p = pv.Plotter(notebook=False, shape=active_config.plotting_config.subplots_shape, window_size=([1280, 720]), off_screen=True) # , line_smoothing=True, polygon_smoothing=True, multi_samples=8\n",
    "else:\n",
    "    try: p\n",
    "    except NameError: p = None # Checks variable p's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "    if (p is not None):\n",
    "        if isinstance(p, pvqt.BackgroundPlotter):\n",
    "            if p.app_window.isHidden():\n",
    "                print('No open BackgroundPlotter')\n",
    "                p.close() # Close it to start over fresh\n",
    "                p = None\n",
    "                needs_create_new_backgroundPlotter = True\n",
    "            else:\n",
    "                print('BackgroundPlotter already open, reusing it.. NOT Forcing creation of a new one!')\n",
    "                # p.app_window.window().show()\n",
    "                # p.clear()\n",
    "                # needs_create_new_backgroundPlotter = False                \n",
    "                p.close() # Close it to start over fresh\n",
    "                p = None\n",
    "                needs_create_new_backgroundPlotter = True\n",
    "                \n",
    "        else:\n",
    "            print('No open BackgroundPlotter, p is a Plotter object')\n",
    "            p.close()\n",
    "            p = None\n",
    "            needs_create_new_backgroundPlotter = True\n",
    "    else:\n",
    "        print('No extant BackgroundPlotter')\n",
    "        needs_create_new_backgroundPlotter = True\n",
    "    if needs_create_new_backgroundPlotter:\n",
    "        print('Creating a new BackgroundPlotter')\n",
    "        p = pvqt.BackgroundPlotter(window_size=(1920, 1080), shape=active_config.plotting_config.subplots_shape, off_screen=False) # Use just like you would a pv.Plotter() instance\n",
    "        print('done.')\n",
    "\n",
    "# p.background_color = 'black'\n",
    "\n",
    "if (not active_config.video_output_config.active_is_video_output_mode):\n",
    "    #Interactive Mode: Enable interactive controls:\n",
    "    interactive_timestamp_slider_actor = p.add_slider_widget(on_slider_update_mesh, [0, (num_time_points-1)], title='Trajectory Timestep', event_type='always', style='modern', pointa=(0.025, 0.1), pointb=(0.98, 0.1), fmt='%0.2f') # fmt=\"%0.2f\"\n",
    "    interactive_timestamp_slider_wrapper = InteractiveSliderWrapper(interactive_timestamp_slider_actor)    \n",
    "    # interactive_checkbox_actor = p.add_checkbox_button_widget(toggle_animation, value=False, color_on='green')\n",
    "    helper_controls_text = print_controls_helper_text()\n",
    "    p.add_text(helper_controls_text, position='upper_left', name='lblControlsHelperText', color='grey', font_size=8.0)\n",
    "    \n",
    "    \n",
    "# Plot the flat arena\n",
    "pdata_maze, pc_maze = build_flat_map_plot_data(x, y)\n",
    "p.add_mesh(pc_maze, name='maze_bg', color=\"black\", render=False)\n",
    "# p.show_grid()\n",
    "# p.add_axes(line_width=5, labels_off=True)\n",
    "p.enable_depth_peeling(number_of_peels=4, occlusion_ratio=0) # Supposedly helps with translucency\n",
    "p.hide_axes()\n",
    "# p.camera_position = 'xy' # Overhead (top) view\n",
    "# apply_close_overhead_zoomed_camera_view(p)\n",
    "apply_close_perspective_camera_view(p)\n",
    "\n",
    "p.render() # manually render when needed\n",
    "\n",
    "if active_config.video_output_config.active_is_video_output_mode:\n",
    "    print('Writing video to {}...'.format(active_config.video_output_config.active_video_output_fullpath))\n",
    "    p.show(auto_close=False)\n",
    "    make_mp4_from_plotter(p, active_config.video_output_config.active_frame_range, on_slider_update_mesh, filename=active_config.video_output_config.active_video_output_fullpath, framerate=60) # 60fps\n",
    "    p.close()\n",
    "    p = None\n",
    "\n",
    "# p.show()\n",
    "                  \n",
    "print('all done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b037df-4a74-4130-9884-b592f81ab6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Playback animation:\n",
    "\n",
    "from PhoPositionalData.plotting.animations import InterfaceProperties\n",
    "        \n",
    "animate = InterfaceProperties(interactive_timestamp_slider_wrapper)\n",
    "# define the animation switch\n",
    "def toggle_animation(state):\n",
    "    animate.animation_state = state # updates the animation state to the new value\n",
    "\n",
    "# An unused constant-time callback that calls back every so often to perform updates\n",
    "p.add_callback(animate, interval=16)  # to be smooth on 60Hz\n",
    "\n",
    "# A checkbox that decides whether we're playing back at a constant rate or not.\n",
    "interactive_checkbox_actor = p.add_checkbox_button_widget(toggle_animation, value=False, color_on='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146823c5-21dd-4d1c-b183-e39b4bf4f450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "fde6e68fa8f5f4f0920a88ee99edd8d4121f14a57a7800ceb19ed197f25c05dc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
