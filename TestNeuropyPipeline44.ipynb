{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b911237-bf80-4a81-936c-b3f3891f9481",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\miniconda3\\envs\\phoviz_ultimate\\lib\\site-packages\\outdated\\utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.0, the latest is 0.5.1.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: pho\n",
    "\"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import time\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "# %gui qt\n",
    "# $env:QT_API=\"pyqt6\"\n",
    "%gui qt5\n",
    "# from PyQt5.Qt import QApplication\n",
    "# # start qt event loop\n",
    "# _instance = QApplication.instance()\n",
    "# if not _instance:\n",
    "#     _instance = QApplication([])\n",
    "# app = _instance\n",
    "import pyqtgraph as pg\n",
    "from pyqtgraph.Qt import QtCore, QtGui\n",
    "import pyqtgraph.opengl as gl # for 3D raster plot\n",
    "\n",
    "# ## Panel:\n",
    "# import param\n",
    "# import panel as pn\n",
    "# from panel.interact import interact, interactive, fixed, interact_manual\n",
    "# from panel.viewable import Viewer\n",
    "# pn.extension()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import get_arguments_as_optional_dict, inspect_callable_arguments\n",
    "from pyphocorehelpers.function_helpers import compose_functions\n",
    "from pyphocorehelpers.indexing_helpers import partition, build_spanning_bins, compute_spanning_bins, compute_position_grid_size, compute_paginated_grid_config\n",
    "from pyphocorehelpers.print_helpers import PrettyPrintable, WrappingMessagePrinter\n",
    "from pyphocorehelpers.geometry_helpers import compute_data_extent, compute_data_aspect_ratio, corner_points_from_extents\n",
    "from pyphocorehelpers.DataStructure.dynamic_parameters import DynamicParameters\n",
    "from pyphocorehelpers.performance_timing_helpers import WrappingPerformanceTimer\n",
    "from pyphocorehelpers.gui.interaction_helpers import CallbackWrapper\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.SessionSelectionAndFiltering import batch_filter_session, build_custom_epochs_filters\n",
    "from pyphoplacecellanalysis.General.ComputationResults import ComputationResult\n",
    "from pyphoplacecellanalysis.General.KnownDataSessionTypeProperties import KnownDataSessionTypeProperties\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Display import DefaultDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.Ratemaps import DefaultRatemapDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import DefaultDecoderDisplayFunctions\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Spike3DRaster import Spike3DRaster\n",
    "\n",
    "# from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_RasterPlot import plot_raster_plot, _display_pyqtgraph_raster_plot, plot_3d_raster_plot\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "try:\n",
    "    from neuropy import core\n",
    "\n",
    "    importlib.reload(core)\n",
    "except ImportError:\n",
    "    sys.path.append(r\"C:\\Users\\Pho\\repos\\NeuroPy\")  # Windows\n",
    "    # sys.path.append('/home/pho/repo/BapunAnalysis2021/NeuroPy') # Linux\n",
    "    # sys.path.append(r'/Users/pho/repo/Python Projects/NeuroPy') # MacOS\n",
    "    print(\"neuropy module not found, adding directory to sys.path. \\n >> Updated sys.path.\")\n",
    "    from neuropy import core\n",
    "\n",
    "# Neuropy:\n",
    "from neuropy.core.session.data_session_loader import DataSessionLoader\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.core.laps import Laps\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters, perform_compute_placefields\n",
    "from neuropy.analyses.laps import estimation_session_laps\n",
    "from neuropy.core.epoch import NamedTimerange\n",
    "\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters, perform_compute_placefields\n",
    "from neuropy.core.neuron_identities import NeuronIdentity, build_units_colormap, PlotStringBrevityModeEnum\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_spike_counts, debug_print_subsession_neuron_differences\n",
    "from neuropy.plotting.ratemaps import enumTuningMap2DPlotVariables\n",
    "# from neuropy.utils.mixins.time_slicing import verify_non_overlapping, add_PBE_identity\n",
    "from neuropy.utils.efficient_interval_search import get_non_overlapping_epochs, drop_overlapping\n",
    "\n",
    "known_data_session_type_dict = {'kdiba':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: DataSessionLoader.kdiba_old_format_session(a_base_dir)),\n",
    "                               basedir=Path(r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53')),\n",
    "                'bapun':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: DataSessionLoader.bapun_data_session(a_base_dir)),\n",
    "                               basedir=Path('R:\\data\\Bapun\\Day5TwoNovel'))\n",
    "               }\n",
    "known_data_session_type_dict['kdiba'].post_load_functions = [lambda a_loaded_sess: estimation_session_laps(a_loaded_sess)]\n",
    "\n",
    "# known_data_session_type_dict['kdiba'].name\n",
    "# from matplotlib.figure import Figure\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib qt\n",
    "# from matplotlib.transforms import IdentityTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28884090-444c-4c0a-a0a1-c7d5d09bf195",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "enable_saving_to_disk = False\n",
    "# common_parent_foldername = Path(r'R:\\Dropbox (Personal)\\Active\\Kamran Diba Lib\\Pho-Kamran-Meetings\\Final Placemaps 2021-01-14')\n",
    "common_parent_foldername = Path(r'R:\\Dropbox (Personal)\\Active\\Kamran Diba Lib\\Pho-Kamran-Meetings\\2022-01-16')\n",
    "\n",
    "def compute_position_grid_bin_size(x, y, num_bins=(64,64), debug_print=False):\n",
    "    \"\"\" Compute Required Bin size given a desired number of bins in each dimension\n",
    "    Usage:\n",
    "        active_grid_bin = compute_position_grid_bin_size(curr_kdiba_pipeline.sess.position.x, curr_kdiba_pipeline.sess.position.y, num_bins=(64, 64)\n",
    "    \"\"\"\n",
    "    out_grid_bin_size, out_bins, out_bins_infos = compute_position_grid_size(x, y, num_bins=num_bins)\n",
    "    active_grid_bin = tuple(out_grid_bin_size)\n",
    "    if debug_print:\n",
    "        print(f'active_grid_bin: {active_grid_bin}') # (3.776841861770752, 1.043326930905373)\n",
    "    return active_grid_bin\n",
    "\n",
    "# WARNING! TODO: Changing the smooth values from (1.5, 1.5) to (0.5, 0.5) was the difference between successful running and a syntax error!\n",
    "# try:\n",
    "#     active_grid_bin\n",
    "# except NameError as e:\n",
    "#     print('setting active_grid_bin = None')\n",
    "#     active_grid_bin = None\n",
    "# finally:\n",
    "#     # active_session_computation_config = PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=active_grid_bin, smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5) # if active_grid_bin is missing, figure out the name\n",
    "#     active_session_computation_config = PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=active_grid_bin, smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5) # if active_grid_bin is missing, figure out the name\n",
    "\n",
    "## Dynamic mode:\n",
    "def _build_active_computation_configs(sess):\n",
    "    \"\"\" _get_computation_configs(curr_kdiba_pipeline.sess)\n",
    "        # From Diba:\n",
    "        # (3.777, 1.043) # for (64, 64) bins\n",
    "        # (1.874, 0.518) # for (128, 128) bins\n",
    "\n",
    "    \"\"\"\n",
    "    # active_grid_bin = compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64))\n",
    "    # active_session_computation_config.computation_epochs = None # set the placefield computation epochs to None, using all epochs.\n",
    "    # return [PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64)), smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None)]\n",
    "    # return [PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(128, 128)), smooth=(2.0, 2.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None)]\n",
    "    return [PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64)), smooth=(2.0, 2.0), frate_thresh=0.2, time_bin_size=1.0, computation_epochs = None)]\n",
    "    # return [PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=(3.777, 1.043), smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None)]\n",
    "\n",
    "    # return [PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(32, 32)), smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None),\n",
    "    #         PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64)), smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None),\n",
    "    #         PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(128, 128)), smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None),\n",
    "    #        ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eceb354-7fa7-4064-ba26-4e989b9f3354",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bapun Format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20843de4-9a94-42f7-80a9-f2c8d5704b62",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# curr_bapun_pipeline = NeuropyPipeline(name='bapun_pipeline', session_data_type='bapun', basedir=known_data_session_type_dict['bapun'].basedir, load_function=known_data_session_type_dict['bapun'].load_function)\n",
    "curr_bapun_pipeline = NeuropyPipeline.init_from_known_data_session_type('bapun', known_data_session_type_dict['bapun'])\n",
    "active_session_computation_configs = _build_active_computation_configs(curr_bapun_pipeline.sess)\n",
    "# active_session_computation_config.grid_bin = compute_position_grid_bin_size(curr_bapun_pipeline.sess.position.x, curr_bapun_pipeline.sess.position.y, num_bins=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e0cc6c-4c19-4670-b685-bba16553e82c",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bapun/DataFrame style session filter functions:\n",
    "def build_bapun_any_epochs_filters(sess):\n",
    "    return build_custom_epochs_filters(sess)\n",
    "    \n",
    "def build_bapun_any_maze_epochs_filters(sess):\n",
    "    # all_filters = build_custom_epochs_filters(sess)\n",
    "    # # print(f'all_filters: {all_filters}')\n",
    "    # maze_only_filters = dict()\n",
    "    # for (name, filter_fcn) in all_filters.items():\n",
    "    #     if 'maze' in name:\n",
    "    #         maze_only_filters[name] = filter_fcn\n",
    "    # maze_only_filters = build_custom_epochs_filters(sess, included_epoch_labels=['maze1','maze2'])\n",
    "    # { key:value for (key,value) in dictOfNames.items() if key % 2 == 0}\n",
    "    # dict(filter(lambda elem: len(elem[1]) == 6,dictOfNames.items()))\n",
    "    # maze_only_name_filter_fn = lambda dict: dict(filter(lambda elem: 'maze' in elem[0], dict.items()))\n",
    "    maze_only_name_filter_fn = lambda names: list(filter(lambda elem: elem.startswith('maze'), names))\n",
    "    # print(f'callable(maze_only_name_filter_fn): {callable(maze_only_name_filter_fn)}')\n",
    "    # print(maze_only_name_filter_fn(['pre', 'maze1', 'post1', 'maze2', 'post2']))\n",
    "    # lambda elem: elem[0] % 2 == 0\n",
    "    maze_only_filters = build_custom_epochs_filters(sess, included_epoch_labels=maze_only_name_filter_fn)\n",
    "    # print(f'maze_only_filters: {maze_only_filters}')\n",
    "    return maze_only_filters\n",
    "\n",
    "# active_session_filter_configurations = build_bapun_any_epochs_filters(curr_bapun_pipeline.sess)\n",
    "active_session_filter_configurations = build_bapun_any_maze_epochs_filters(curr_bapun_pipeline.sess)\n",
    "# print(f'active_session_filter_configurations: {active_session_filter_configurations}')\n",
    "curr_bapun_pipeline.filter_sessions(active_session_filter_configurations)\n",
    "for i in np.arange(len(active_session_computation_configs)):\n",
    "    active_session_computation_configs[i].computation_epochs = None  # set the placefield computation epochs to None, using all epochs.\n",
    "curr_bapun_pipeline.perform_computations(active_session_computation_configs[0])\n",
    "curr_bapun_pipeline.prepare_for_display() # TODO: pass a display config\n",
    "# Set curr_active_pipeline for testing:\n",
    "curr_active_pipeline = curr_bapun_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4940269-23e4-46dc-a4ae-61d512ac5e41",
   "metadata": {
    "tags": []
   },
   "source": [
    "## KDiba Format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "506398f3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir is already Path object.\n",
      "\t basepath: R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\n",
      "\t session_name: 2006-6-07_11-26-53\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.epochs_info.mat... done.\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position_info.mat... done.\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Computing linear positions for all active epochs for session... Saving updated position results results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position.npy... 2006-6-07_11-26-53.position.npy saved\n",
      "done.\n",
      "\t Failure loading .interpolated_spike_positions.npy. Must recompute.\n",
      "\n",
      "\t Saving updated interpolated spike position results results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.interpolated_spike_positions.npy... 2006-6-07_11-26-53.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading success: .ripple.npy.\n",
      "Loading success: .mua.npy.\n",
      "Loading success: .pbe.npy.\n",
      "desc_crossings_x: (24,), asc_crossings_x: (24,)\n"
     ]
    }
   ],
   "source": [
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "# R:\\data\\KDIBA\\gor01\\one\\IIDataMat_Export_ToPython_2021_11_23.m\n",
    "# From pre-computed .mat files:\n",
    "## 07: \n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53'\n",
    "# # ## 08:\n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15'\n",
    "# curr_kdiba_pipeline = NeuropyPipeline(name='kdiba_pipeline', session_data_type='kdiba', basedir=known_data_session_type_dict['kdiba'].basedir, load_function=known_data_session_type_dict['kdiba'].load_function)\n",
    "curr_kdiba_pipeline = NeuropyPipeline.init_from_known_data_session_type('kdiba', known_data_session_type_dict['kdiba'])\n",
    "# active_grid_bin = compute_position_grid_bin_size(curr_kdiba_pipeline.sess.position.x, curr_kdiba_pipeline.sess.position.y, num_bins=(64, 64))\n",
    "# active_session_computation_config.grid_bin = active_grid_bin\n",
    "active_session_computation_configs = _build_active_computation_configs(curr_kdiba_pipeline.sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f03a92-1685-41a6-b10c-88ea7dc55ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_any_maze_epochs_filters(sess):\n",
    "    sess.epochs.t_start = 22.26 # exclude the first short period where the animal isn't on the maze yet\n",
    "    active_session_filter_configurations = {'maze1': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')) } # just maze 1\n",
    "    # active_session_filter_configurations = {'maze1': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')),\n",
    "    #                                     'maze2': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze2')), x.epochs.get_named_timerange('maze2')),\n",
    "    #                                     'maze': lambda x: (x.filtered_by_epoch(NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]])), NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]]))\n",
    "    #                                    }\n",
    "    return active_session_filter_configurations\n",
    "\n",
    "active_session_filter_configurations = build_any_maze_epochs_filters(curr_kdiba_pipeline.sess)\n",
    "curr_kdiba_pipeline.filter_sessions(active_session_filter_configurations)\n",
    "for i in np.arange(len(active_session_computation_configs)):\n",
    "    active_session_computation_configs[i].computation_epochs = None # add the laps epochs to all of the computation configs.\n",
    "\n",
    "curr_kdiba_pipeline.perform_computations(active_session_computation_configs[0])\n",
    "curr_kdiba_pipeline.prepare_for_display() # TODO: pass a display config\n",
    "# set curr_active_pipeline for testing:\n",
    "curr_active_pipeline = curr_kdiba_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee23920e-5d46-4258-8a99-bb40056913f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['lap_id']] = laps_df[['lap_id']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['start_spike_index', 'end_spike_index']] = laps_df[['start_spike_index', 'end_spike_index']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['num_spikes'] = laps_df['end_spike_index'] - laps_df['start_spike_index']\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['lap_dir'] = laps_df['lap_dir'].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['label'] = laps_df['lap_id'].astype('str') # add the string \"label\" column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze1\"...\n",
      "Constraining to units with type: pyramidal\n",
      "Constraining to epoch with times (start: 22.26, end: 1739.1533641185379)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['lap_id']] = laps_df[['lap_id']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['start_spike_index', 'end_spike_index']] = laps_df[['start_spike_index', 'end_spike_index']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['num_spikes'] = laps_df['end_spike_index'] - laps_df['start_spike_index']\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['lap_dir'] = laps_df['lap_dir'].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['label'] = laps_df['lap_id'].astype('str') # add the string \"label\" column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze2\"...\n",
      "Constraining to units with type: pyramidal\n",
      "Constraining to epoch with times (start: 1739.1533641185379, end: 1932.4200048116618)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to units with type: pyramidal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['lap_id']] = laps_df[['lap_id']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['start_spike_index', 'end_spike_index']] = laps_df[['start_spike_index', 'end_spike_index']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['num_spikes'] = laps_df['end_spike_index'] - laps_df['start_spike_index']\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['lap_dir'] = laps_df['lap_dir'].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['label'] = laps_df['lap_id'].astype('str') # add the string \"label\" column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraining to epoch with times (start: 22.26, end: 1932.4200048116618)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['lap_id']] = laps_df[['lap_id']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['start_spike_index', 'end_spike_index']] = laps_df[['start_spike_index', 'end_spike_index']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['num_spikes'] = laps_df['end_spike_index'] - laps_df['start_spike_index']\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['lap_dir'] = laps_df['lap_dir'].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['label'] = laps_df['lap_id'].astype('str') # add the string \"label\" column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing single_computation on filtered_session with filter named \"maze1\"...\n",
      "Recomputing active_epoch_placefields... pre speed filtering: 20202 spikes.\n",
      "post speed filtering: 13268 spikes.\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... pre speed filtering: 20202 spikes.\n",
      "post speed filtering: 13529 spikes.\n",
      "\t done.\n",
      "Performing perform_registered_computations(...) with 5 registered_computation_functions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:217: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing single_computation on filtered_session with filter named \"maze2\"...\n",
      "Recomputing active_epoch_placefields... pre speed filtering: 545 spikes.\n",
      "post speed filtering: 314 spikes.\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... pre speed filtering: 545 spikes.\n",
      "post speed filtering: 329 spikes.\n",
      "\t done.\n",
      "Performing perform_registered_computations(...) with 5 registered_computation_functions...\n",
      "Performing single_computation on filtered_session with filter named \"maze\"...\n",
      "Recomputing active_epoch_placefields... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:177: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  C_tau_n = 1.0 / np.sum(un_normalized_result) # normalize the result\n",
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:178: RuntimeWarning: invalid value encountered in multiply\n",
      "  result = C_tau_n * un_normalized_result\n",
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:217: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre speed filtering: 20747 spikes.\n",
      "post speed filtering: 13582 spikes.\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... pre speed filtering: 20747 spikes.\n",
      "post speed filtering: 13858 spikes.\n",
      "\t done.\n",
      "Performing perform_registered_computations(...) with 5 registered_computation_functions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:217: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    }
   ],
   "source": [
    "def build_pyramidal_epochs_filters(sess):\n",
    "    sess.epochs.t_start = 22.26 # exclude the first short period where the animal isn't on the maze yet\n",
    "    active_session_filter_configurations = {'maze1': lambda x: (x.filtered_by_neuron_type('pyramidal').filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')),\n",
    "                                        'maze2': lambda x: (x.filtered_by_neuron_type('pyramidal').filtered_by_epoch(x.epochs.get_named_timerange('maze2')), x.epochs.get_named_timerange('maze2')),\n",
    "                                        'maze': lambda x: (x.filtered_by_neuron_type('pyramidal').filtered_by_epoch(NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]])), NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]]))\n",
    "                                       }\n",
    "    return active_session_filter_configurations\n",
    "\n",
    "active_session_filter_configurations = build_pyramidal_epochs_filters(curr_kdiba_pipeline.sess)\n",
    "\n",
    "\n",
    "is_non_overlapping_lap = get_non_overlapping_epochs(curr_kdiba_pipeline.sess.laps.to_dataframe()[['start','stop']].to_numpy())\n",
    "only_good_laps_df = curr_kdiba_pipeline.sess.laps.to_dataframe()[is_non_overlapping_lap]\n",
    "curr_kdiba_pipeline.sess.laps = Laps(only_good_laps_df) # replace the laps object with the filtered one\n",
    "\n",
    "\n",
    "lap_specific_epochs = curr_kdiba_pipeline.sess.laps.as_epoch_obj()\n",
    "any_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(len(curr_kdiba_pipeline.sess.laps.lap_id))])\n",
    "even_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(0, len(curr_kdiba_pipeline.sess.laps.lap_id), 2)])\n",
    "odd_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(1, len(curr_kdiba_pipeline.sess.laps.lap_id), 2)])\n",
    "\n",
    "\n",
    "# Copy the active session_computation_config:\n",
    "for i in np.arange(len(active_session_computation_configs)):\n",
    "    active_session_computation_configs[i].computation_epochs = any_lap_specific_epochs # add the laps epochs to all of the computation configs.\n",
    "\n",
    "curr_kdiba_pipeline.filter_sessions(active_session_filter_configurations)\n",
    "curr_kdiba_pipeline.perform_computations(active_session_computation_configs[0]) # Causes \"IndexError: index 59 is out of bounds for axis 0 with size 59\"\n",
    "curr_kdiba_pipeline.prepare_for_display() # TODO: pass a display config\n",
    "# set curr_active_pipeline for testing:\n",
    "curr_active_pipeline = curr_kdiba_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3136f4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Common: Optional Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd6649",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_epoch_labels = list(curr_active_pipeline.sess.epochs.labels) # ['pre', 'maze1', 'post1', 'maze2', 'post2']\n",
    "curr_named_timeranges = [curr_active_pipeline.sess.epochs.get_named_timerange(a_label) for a_label in curr_epoch_labels]\n",
    "\n",
    "curr_named_timeranges\n",
    "\n",
    "all_filters_list = list(curr_active_pipeline.filtered_sessions.keys())\n",
    "all_filters_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d57f5d",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze PBEs by looping through the filtered epochs:\n",
    "\n",
    "\n",
    "# curr_kdiba_pipeline.sess.spikes_df.spikes.time_variable_name # 't_rel_seconds' \n",
    "# active_timestamps = curr_kdiba_pipeline.sess.spikes_df[curr_kdiba_pipeline.sess.spikes_df.spikes.time_variable_name].copy().to_numpy() # get the timestamps column using the time_variable_name property. It's 't_rel_seconds' for kdiba-format data for example\n",
    "# active_timestamps\n",
    "\n",
    "curr_kdiba_pipeline.sess.spikes_df[curr_kdiba_pipeline.sess.spikes_df['PBE_id'] > -1]\n",
    "\n",
    "# curr_epoch_duration\n",
    "# determine_event_interval_is_included(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b44895",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Works, but need to convert into the computation function format or find a new place to put it. It operates on the entire pipeline while currently computation functions are limited to operating on one stage at a time.\n",
    "def _perform_PBE_stats(active_pipeline, debug_print = False):\n",
    "    \"\"\" # Analyze PBEs by looping through the filtered epochs:\n",
    "        This whole implementation seems silly and inefficient        \n",
    "        Can't I use .agg(['count', 'mean']) or something? \n",
    "    \"\"\"\n",
    "    all_epochs_labels = []\n",
    "    all_epochs_total_durations = []\n",
    "    all_epochs_n_pbes = []\n",
    "    all_epochs_pbe_duration_lists = []\n",
    "    all_epochs_cummulative_pbe_durations = []\n",
    "    all_epochs_mean_pbe_durations = []\n",
    "    all_epochs_full_pbe_spiketrain_lists = []\n",
    "    all_epochs_pbe_num_spikes_lists = []\n",
    "    all_epochs_intra_pbe_interval_lists = []\n",
    "    \n",
    "    for (name, filtered_sess) in active_pipeline.filtered_sessions.items():\n",
    "        # interested in analyzing both the filtered_sess.pbe and the filtered_sess.spikes_df (as they relate to the PBEs)\n",
    "        all_epochs_labels.append(name)\n",
    "        curr_named_time_range = active_pipeline.sess.epochs.get_named_timerange(name) # for 'maze' key, the total duration is being set to array([], dtype=float64) for some reason. all_epochs_total_durations: [1716.8933641185379, 193.26664069312392, array([], dtype=float64)]\n",
    "        \n",
    "        if not np.isscalar(curr_named_time_range.duration):\n",
    "            # for 'maze' key, the total duration is being set to array([], dtype=float64) for some reason. all_epochs_total_durations: [1716.8933641185379, 193.26664069312392, array([], dtype=float64)]\n",
    "            curr_named_time_range = NamedTimerange(name='maze', start_end_times=[active_pipeline.sess.epochs['maze1'][0], active_pipeline.sess.epochs['maze2'][1]])\n",
    "        \n",
    "        curr_epoch_duration = curr_named_time_range.duration\n",
    "        all_epochs_total_durations.append(curr_epoch_duration) # TODO: this should be in seconds (or at least the same units as the PBE durations)... actually this might be right.\n",
    "        # Computes the intervals between each PBE:\n",
    "        curr_intra_pbe_intervals = filtered_sess.pbe.starts[1:] - filtered_sess.pbe.stops[:-1]\n",
    "        all_epochs_intra_pbe_interval_lists.append(curr_intra_pbe_intervals)\n",
    "        all_epochs_n_pbes.append(filtered_sess.pbe.n_epochs)\n",
    "        all_epochs_pbe_duration_lists.append(filtered_sess.pbe.durations)\n",
    "        all_epochs_cummulative_pbe_durations.append(np.sum(filtered_sess.pbe.durations))\n",
    "        all_epochs_mean_pbe_durations.append(np.nanmean(filtered_sess.pbe.durations))\n",
    "        # filtered_sess.spikes_df.PBE_id\n",
    "        curr_pbe_only_spikes_df = filtered_sess.spikes_df[filtered_sess.spikes_df.PBE_id > -1].copy()\n",
    "        unique_PBE_ids = np.unique(curr_pbe_only_spikes_df['PBE_id'])\n",
    "        flat_PBE_ids = [int(id) for id in unique_PBE_ids]\n",
    "        num_unique_PBE_ids = len(flat_PBE_ids)\n",
    "        # groups the spikes_df by PBEs:\n",
    "        curr_pbe_grouped_spikes_df = curr_pbe_only_spikes_df.groupby(['PBE_id'])\n",
    "        curr_spiketrains = list()\n",
    "        curr_PBE_spiketrain_num_spikes = list()\n",
    "        for i in np.arange(num_unique_PBE_ids):\n",
    "            curr_PBE_id = flat_PBE_ids[i] # actual cell ID\n",
    "            #curr_flat_cell_indicies = (flat_spikes_out_dict['aclu'] == curr_cell_id) # the indicies where the cell_id matches the current one\n",
    "            curr_PBE_dataframe = curr_pbe_grouped_spikes_df.get_group(curr_PBE_id)\n",
    "            curr_PBE_num_spikes = np.shape(curr_PBE_dataframe)[0] # the number of spikes in this PBE\n",
    "            curr_PBE_spiketrain_num_spikes.append(curr_PBE_num_spikes)\n",
    "            curr_spiketrains.append(curr_PBE_dataframe['t'].to_numpy())\n",
    "\n",
    "        curr_PBE_spiketrain_num_spikes = np.array(curr_PBE_spiketrain_num_spikes)\n",
    "        all_epochs_pbe_num_spikes_lists.append(curr_PBE_spiketrain_num_spikes)\n",
    "        curr_spiketrains = np.array(curr_spiketrains, dtype='object')\n",
    "        all_epochs_full_pbe_spiketrain_lists.append(curr_spiketrains)\n",
    "        if debug_print:\n",
    "            print(f'name: {name}, filtered_sess.pbe: {filtered_sess.pbe}')\n",
    "\n",
    "    if debug_print:\n",
    "        print(f'all_epochs_n_pbes: {all_epochs_n_pbes}, all_epochs_mean_pbe_durations: {all_epochs_mean_pbe_durations}, all_epochs_cummulative_pbe_durations: {all_epochs_cummulative_pbe_durations}, all_epochs_total_durations: {all_epochs_total_durations}')\n",
    "        # all_epochs_n_pbes: [3152, 561, 1847, 832, 4566], all_epochs_mean_pbe_durations: [0.19560881979695527, 0.22129233511594312, 0.19185056848946497, 0.2333112980769119, 0.1987152869032212]\n",
    "\n",
    "    all_epochs_pbe_occurance_rate = [(float(all_epochs_total_durations[i]) / float(all_epochs_n_pbes[i])) for i in np.arange(len(all_epochs_n_pbes))]\n",
    "    all_epochs_pbe_percent_duration = [(float(all_epochs_total_durations[i]) / float(all_epochs_cummulative_pbe_durations[i])) for i in np.arange(len(all_epochs_n_pbes))]    \n",
    "    all_epoch_mean_num_pbe_spikes = [np.nanmean(pbe_spike_counts) for pbe_spike_counts in all_epochs_pbe_num_spikes_lists] # [3151, 561, 1847, 831, 4563]\n",
    "    all_epoch_std_num_pbe_spikes = [np.nanstd(pbe_spike_counts) for pbe_spike_counts in all_epochs_pbe_num_spikes_lists] # [11.638970035733648, 15.013817202645336, 15.5123897729991, 15.113395025612247, 11.473087401691878]\n",
    "    # [20.429704855601397, 27.338680926916222, 23.748781808337846, 25.673886883273166, 20.38614946307254]\n",
    "    # Build the final output result dataframe:\n",
    "    pbe_analyses_result_df = pd.DataFrame({'n_pbes':all_epochs_n_pbes, 'mean_pbe_durations': all_epochs_mean_pbe_durations, 'cummulative_pbe_durations':all_epochs_cummulative_pbe_durations, 'epoch_total_duration':all_epochs_total_durations,\n",
    "                'pbe_occurance_rate':all_epochs_pbe_occurance_rate, 'pbe_percent_duration':all_epochs_pbe_percent_duration,\n",
    "                'mean_num_pbe_spikes':all_epoch_mean_num_pbe_spikes, 'stddev_num_pbe_spikes':all_epoch_std_num_pbe_spikes}, index=all_epochs_labels)\n",
    "    # temporary: this isn't how the returns work for other computation functions:\n",
    "    all_epochs_info = [all_epochs_full_pbe_spiketrain_lists, all_epochs_pbe_num_spikes_lists, all_epochs_intra_pbe_interval_lists] # list version\n",
    "    # all_epochs_info = {'all_epochs_full_pbe_spiketrain_lists':all_epochs_full_pbe_spiketrain_lists, 'all_epochs_pbe_num_spikes_lists':all_epochs_pbe_num_spikes_lists, 'all_epochs_intra_pbe_interval_lists':all_epochs_intra_pbe_interval_lists} # dict version\n",
    "    return pbe_analyses_result_df, all_epochs_info\n",
    "\n",
    "pbe_analyses_result_df, [all_epochs_full_pbe_spiketrain_lists, all_epochs_pbe_num_spikes_lists, all_epochs_intra_pbe_interval_lists] = _perform_PBE_stats(curr_active_pipeline, debug_print=False) # all_epochs_n_pbes: [206, 31, 237], all_epochs_mean_pbe_durations: [0.2209951456310722, 0.23900000000001073, 0.22335021097046923], all_epochs_cummulative_pbe_durations: [45.52500000000087, 7.409000000000333, 52.934000000001205], all_epochs_total_durations: [1716.8933641185379, 193.26664069312392, 1910.1600048116618]\n",
    "\n",
    "pbe_analyses_result_df\n",
    "# pbe_analyses_result_df.to_clipboard(sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee40f53-70cd-4b54-8fa1-71117a9a200c",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_SimplePlot import plot_simple_graph\n",
    "\n",
    "[p1], win, app = plot_simple_graph(all_epochs_intra_pbe_interval_lists[0])\n",
    "\n",
    "for (idx, named_range) in enumerate(curr_named_timeranges):\n",
    "    # interested in analyzing both the filtered_sess.pbe and the filtered_sess.spikes_df (as they relate to the PBEs)\n",
    "    p1.plot(all_epochs_intra_pbe_interval_lists[idx] + (300 * idx), pen=(255,0,0), name=named_range.name)\n",
    "\n",
    "# p1.plot(np.random.normal(size=100), pen=(255,0,0), name=\"Red curve\")\n",
    "# p1.plot(np.random.normal(size=110)+5, pen=(0,255,0), name=\"Green curve\")\n",
    "# p1.plot(np.random.normal(size=120)+10, pen=(0,0,255), name=\"Blue curve\")\n",
    "\n",
    "# def plot_simple_graph(y=np.random.normal(size=100))\n",
    "#     app = pg.mkQApp(\"Plotting Example\")\n",
    "#     #mw = QtGui.QMainWindow()\n",
    "#     #mw.resize(800,800)\n",
    "#     \n",
    "#     win = pg.GraphicsLayoutWidget(show=True, title=\"Basic plotting examples\")\n",
    "#     win.resize(1000,600)\n",
    "#     win.setWindowTitle('pyqtgraph example: Plotting')\n",
    "#     \n",
    "#     # Enable antialiasing for prettier plots\n",
    "#     pg.setConfigOptions(antialias=True)\n",
    "#     \n",
    "#     p1 = win.addPlot(title=\"Basic array plotting\", y=y)\n",
    "#     \n",
    "#     return app, win, [p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9795cd4-6968-4458-9442-3e38701ad1e8",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Find all spikes that occur during both a PBE & a lap on the track:\n",
    "\n",
    "# curr_active_pipeline.sess.spikes_df[(curr_active_pipeline.sess.spikes_df['PBE_id'] > -1)] # & (curr_active_pipeline.sess.spikes_df['lap'] != -1)\n",
    "during_lap_and_PBE_spikes_df = curr_active_pipeline.sess.spikes_df[(curr_active_pipeline.sess.spikes_df['PBE_id'] > -1) & (curr_active_pipeline.sess.spikes_df['lap'] != -1)]\n",
    "# curr_active_pipeline.sess.spikes_df[(curr_active_pipeline.sess.spikes_df['lap'] > -1)]\n",
    "during_lap_and_PBE_spikes_df\n",
    "\n",
    "# updated_spikes_df = curr_active_pipeline.sess.compute_PBEs_spikes_df(curr_active_pipeline.sess.spikes_df, curr_active_pipeline.sess.pbe.to_dataframe())\n",
    "# updated_spikes_df[(updated_spikes_df['PBE_id'] > -1)]\n",
    "# curr_active_pipeline.sess.spikes_df[(curr_active_pipeline.sess.spikes_df['PBE_id'] > -1)]\n",
    "# curr_active_pipeline.sess.spikes_df\n",
    "\n",
    "# group by Team, get mean, min, and max value of Age for each value of Team.\n",
    "grouped_single = during_lap_and_PBE_spikes_df.groupby('lap').agg({'PBE_id': ['mean', 'min', 'max']})\n",
    "grouped_single = grouped_single.reset_index()\n",
    "print(grouped_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d8670b-8cae-458e-9a39-de7a223a55d2",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## 3D Spike Train Visualization\n",
    "# import pyqtgraph.opengl as gl # for 3D raster plot\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Spike3DRaster import Spike3DRaster\n",
    "\n",
    "# importlib.reload(pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_RasterPlot)\n",
    "\n",
    "curr_epoch_name = 'maze1'\n",
    "curr_epoch = curr_active_pipeline.filtered_epochs[curr_epoch_name] # <NamedTimerange: {'name': 'maze1', 'start_end_times': array([  22.26      , 1739.15336412])};>\n",
    "curr_sess = curr_active_pipeline.filtered_sessions[curr_epoch_name]\n",
    "curr_spikes_df = curr_sess.spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d08b8a-75e4-4878-b1dd-0bf2c1c68ce1",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spike_raster_plt = Spike3DRaster(curr_spikes_df, window_duration=4.0, window_start_time=30.0, neuron_colors=None)\n",
    "# spike_raster_plt = Spike3DRaster(curr_spikes_df, window_duration=0.2, window_start_time=30.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4059b-42e7-4155-88b9-4a10d19d8f71",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spike_raster_plt.animation()\n",
    "# spike_raster_plt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb56ab4-2574-46f4-839a-a163bf9c282c",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'spike_raster_plt.spikes_window.active_time_window: {spike_raster_plt.spikes_window.active_time_window}')\n",
    "# spike_raster_plt.spikes_window.active_window_start_time = 50.0\n",
    "spike_raster_plt.spikes_window.update_window_start(90.0)\n",
    "print(f'spike_raster_plt.spikes_window.active_time_window: {spike_raster_plt.spikes_window.active_time_window}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ccfbc",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_computation_function_names\n",
    "# ['_perform_placefield_overlap_computation',\n",
    "#  '_perform_firing_rate_trends_computation',\n",
    "#  '_perform_extended_statistics_computation',\n",
    "#  '_perform_two_step_position_decoding_computation',\n",
    "#  '_perform_position_decoding_computation']\n",
    "\n",
    "\n",
    "curr_active_pipeline.registered_display_function_names\n",
    "# ['_display_1d_placefield_validations',\n",
    "#  '_display_2d_placefield_result_plot_ratemaps_2D',\n",
    "#  '_display_2d_placefield_result_plot_raw',\n",
    "#  '_display_3d_image_plotter',\n",
    "#  '_display_3d_interactive_custom_data_explorer',\n",
    "#  '_display_3d_interactive_spike_and_behavior_browser',\n",
    "#  '_display_3d_interactive_tuning_curves_plotter',\n",
    "#  '_display_normal',\n",
    "#  '_display_placemaps_pyqtplot_2D',\n",
    "#  '_display_decoder_result',\n",
    "#  '_display_plot_most_likely_position_comparisons',\n",
    "#  '_display_two_step_decoder_prediction_error_2D',\n",
    "#  '_display_two_step_decoder_prediction_error_animated_2D']\n",
    "\n",
    "\n",
    "# all_fcn_tuples[0]\n",
    "# [a_name for (a_name, a_fn) in all_fcn_tuples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cbbfa0",
   "metadata": {},
   "source": [
    "# Common: Display\n",
    "Common visualization and display functions for both forms of data/pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28864994-db95-4b51-8c68-092828a42ce9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maze1', 'maze2', 'maze']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(curr_active_pipeline.computation_results.keys()) # ['maze1', 'maze2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4917da1-a0b3-4b77-a34e-73f87c41a1ef",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "active_config_name = 'maze1'\n",
    "# active_config_name = 'maze'\n",
    "\n",
    "# Get relevant variables:\n",
    "# curr_active_pipeline is set above, and usable here\n",
    "sess: DataSession = curr_active_pipeline.filtered_sessions[active_config_name]\n",
    "pf = curr_active_pipeline.computation_results[active_config_name].computed_data['pf1D']\n",
    "active_one_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data['pf2D_Decoder']\n",
    "active_two_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_TwoStepDecoder', None)\n",
    "active_measured_positions = curr_active_pipeline.computation_results[active_config_name].sess.position.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd23e683-c624-4726-8d09-bdd92331e0bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compare curr_active_pipeline.filtered_sessions[active_config_name] and \n",
    "# from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_DataTreeWidget import plot_dataTreeWidget\n",
    "#\n",
    "# print(f'curr_active_pipeline.filtered_sessions[active_config_name]: {curr_active_pipeline.filtered_sessions[active_config_name]}')\n",
    "# print(f'curr_active_pipeline.computation_results[active_config_name].sess: {curr_active_pipeline.computation_results[active_config_name].sess}')\n",
    "#\n",
    "# filtered_sessions_tree, filtered_sessions_app = plot_dataTreeWidget(data={'filtered_sessions[active_config_name]':curr_active_pipeline.filtered_sessions[active_config_name].to_dict()}, title='PhoOutputDataTreeApp - filtered_sessions[active_config_name]')\n",
    "# tree, app = plot_dataTreeWidget(data={'computation_results[active_config_name].sess':curr_active_pipeline.computation_results[active_config_name].sess.to_dict()}, title='PhoOutputDataTreeApp- curr_active_pipeline.computation_results[active_config_name].sess')\n",
    "\n",
    "# pg.exec()\n",
    "\n",
    "# sess.ripple\n",
    "# sess.mua\n",
    "if sess.pbe is None:\n",
    "    sess.pbe = DataSession.compute_pbe_epochs(sess, save_on_compute=False)\n",
    "    \n",
    "sess.pbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a3b3c-999e-486c-8e48-0e16096a0419",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if curr_active_pipeline.filtered_sessions['maze2'].pbe is None:\n",
    "    curr_active_pipeline.filtered_sessions['maze2'].pbe = DataSession.compute_pbe_epochs(curr_active_pipeline.filtered_sessions['maze2'], save_on_compute=False)\n",
    "    \n",
    "curr_active_pipeline.filtered_sessions['maze2'].pbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3df1291",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_output = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1535f17-a388-4bd3-aece-bd5e7ca856c9",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying custom Pyvista theme.\n",
      "done.\n",
      "BackgroundPlotter already open, reusing it.. NOT Forcing creation of a new one!\n",
      "Creating a new BackgroundPlotter\n",
      "num_curr_tuning_curves: 39\n",
      "successfully set custom rgb key from separate R, G, B columns in dataframe.\n",
      "self.params.debug_disable_all_gui_controls is True, so no gui controls will be built.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PhoGui.InteractivePlotter.InteractivePlaceCellTuningCurvesDataExplorer.InteractivePlaceCellTuningCurvesDataExplorer at 0x29442608280>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pActiveTuningCurvesPlotter = None\n",
    "display_output = curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_tuning_curves_plotter, active_config_name, extant_plotter=display_output.get('plotter', None)) # Works now!\n",
    "# display_output = curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_tuning_curves_plotter, active_config_name, extant_plotter=pActiveTuningCurvesPlotter) # Works now!\n",
    "# pActiveTuningCurvesPlotter = display_output['plotter']\n",
    "# display_output['pane'] # doesn't seem to work to control the output anymore!\n",
    "display_output['ipcDataExplorer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4b3d24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFD190>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFD2E0>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFD3C0>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFD4A0>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFD580>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFD660>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFD740>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFD820>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFD900>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFD9E0>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDAC0>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDBA0>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDC80>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDD60>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDE40>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDF20>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDF20>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDF20>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDF20>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDF20>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDF20>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDF20>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDF20>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDF20>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFD190>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFD3C0>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFD580>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFD740>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFD900>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDAC0>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDC80>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDE40>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDE40>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDE40>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDE40>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDE40>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDE40>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDE40>\n",
      "done <PyQt5.QtGui.QColor object at 0x0000029470EFDE40>\n",
      "change <PyQt5.QtGui.QColor object at 0x0000029470EFD900>\n",
      "change <PyQt5.QtGui.QColor object at 0x0000029470EFD740>\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.qt_placefield import build_all_placefield_output_panels\n",
    "# display_output = curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_tuning_curves_plotter, active_config_name, extant_plotter=display_output.get('pActiveTuningCurvesPlotter', None)) # Works now!\n",
    "\n",
    "# pActiveTuningCurvesPlotter\n",
    "# display_output['ipcDataExplorer'].active_tuning_curve_render_configs # array of SingleNeuronPlottingExtended objects\n",
    "\n",
    "# build the output panels\n",
    "placefieldControlsContainerWidget, pf_widgets = build_all_placefield_output_panels(display_output['ipcDataExplorer'])\n",
    "placefieldControlsContainerWidget.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40404570",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_spike_and_behavior_browser, active_config_name) # this works now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0073ab-9e27-45e8-b3a0-ff5e34b4cd11",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_custom_data_explorer, active_config_name) # does not work, missing color info?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6497b-f442-4096-afe0-12ce9b41612b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plots = curr_active_pipeline.display(DefaultDisplayFunctions._display_1d_placefield_validations, active_config_name) # works, but generates a TON of plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fab03e-809e-441c-a235-7469147604cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(plots) # 39\n",
    "type(plots[0]) # matplotlib.figure.Figure\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(10, 4))\n",
    "subfigs = fig.subfigures(1, 2, wspace=0.07)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb4c7d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb39bbd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here we look at the population burst events for each epoch ('maze1' vs. 'maze2')\n",
    "# curr_active_pipeline.sess.\n",
    "\n",
    "# get only the spikes that occur during PBEs:\n",
    "pbe_only_spikes_df = sess.spikes_df[(sess.spikes_df.PBE_id > -1)]\n",
    "pbe_only_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e889d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.pbe #[10960 rows x 4 columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b1549-6a5f-493f-98f2-3b3f367cc43b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDecoderDisplayFunctions._display_two_step_decoder_prediction_error_2D, active_config_name, variable_name='p_x_given_n') # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d1ff7-73fa-44b3-a351-6ce01510320b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDecoderDisplayFunctions._display_two_step_decoder_prediction_error_2D, active_config_name, variable_name='p_x_given_n_and_x_prev') # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c49ccf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDecoderDisplayFunctions._display_two_step_decoder_prediction_error_animated_2D, active_config_name, variable_name='p_x_given_n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de2901-e7ea-40fe-8807-d5bfb57b01bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "app, win, w = curr_active_pipeline.display(DefaultRatemapDisplayFunctions._display_placemaps_pyqtplot_2D, active_config_name)\n",
    "win.show(); pg.exec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abc004f-a5d9-4979-8cde-f202597ba1ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "### Old Individual Plotting Functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5422763d-b961-4dab-810d-8e27b091dffe",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "filter_name = 'maze1'\n",
    "# curr_bapun_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, subplots=(20, 8), max_screen_figure_size=(2256, 2048), enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=0) # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, subplots=(20, 8), max_screen_figure_size=(2256, 2048), enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=10) # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca71727-a5cc-48df-88e7-782bbccdef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_name = 'maze2'\n",
    "# curr_bapun_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, subplots=(20, 8), max_screen_figure_size=(2256, 2048), enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=0) # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, subplots=(20, 8), max_screen_figure_size=(2256, 2048), enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=11) # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c4f39-412d-42e7-9b3d-8417993ee562",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_result(curr_active_pipeline.computation_results['maze1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c4907-c242-4908-80dd-0c7d49e89b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_result(curr_active_pipeline.computation_results['maze2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c3eb8a-d963-4d60-ab39-721de81a34fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_name = 'maze1'\n",
    "# curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=0, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=1, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ad5c3-328d-41a9-b7c2-2bc6f7aaf2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_name = 'maze2'\n",
    "# curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=0, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=1, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c849eb9-e7c4-476d-b17c-d197d2f80983",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_name = 'maze'\n",
    "# curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=0, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=1, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c4ecf-15c2-4197-927f-8f1a63c7ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_custom_data_explorer, 'maze1') # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_tuning_curves_plotter, 'maze1') # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2f3bb-49a9-4053-9fd4-03c8796e7bf2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_1d_placefield_validations, 'maze1') # works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c4171-ea23-4f0f-bcc0-a7ab3544dfbe",
   "metadata": {},
   "source": [
    "\n",
    "# Testing: Position Decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b04bc40",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# win.close()\n",
    "app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37445b3-c614-4b68-b6ab-ee7a26c29af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stock Decoder:\n",
    "from neuropy.analyses.decoders import Decode1d\n",
    "\n",
    "def stock_1d_decoder(sess, pf, curr_result_label):\n",
    "    maze1 = sess.paradigm[curr_result_label]\n",
    "    # rpls = sess.ripple.time_slice(maze1[0], maze1[1])\n",
    "    rpls = None\n",
    "    pf_neurons = sess.neurons.get_by_id(pf.ratemap.neuron_ids)\n",
    "    decode = Decode1d(neurons=pf_neurons, ratemap = pf.ratemap, epochs=rpls, bin_size=0.02)\n",
    "    return decode\n",
    "\n",
    "def validate_stock_1d_decoder(sess, decode):\n",
    "    # Plot to validate decoder:\n",
    "    np.shape(decode.decoded_position) # (85845,)\n",
    "    plt.plot(decode.decoded_position)\n",
    "    ax = plt.gca()\n",
    "    # ax.xlim() # (-4292.2, 90136.2)\n",
    "    ax.set_xlim(10000, 12000)\n",
    "\n",
    "np.shape(decode.posterior) # (48, 85845)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c545afc1-63d6-4f45-a186-5acae5b2dab3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- % $$\\int_{a}^b f(x)dx$$ -->\n",
    "<!-- Euler's identity: $ e^{i \\pi} + 1 = 0 $ -->\n",
    "\n",
    "## One-step Bayesian Decoder:\n",
    "$$P(\\overrightarrow{x}_{t}|\\overrightarrow{n}_{t})$$\n",
    "\n",
    "$$P(\\overrightarrow{n}|\\overrightarrow{x})$$ : probability for the numbers of spikes $\\overrightarrow{n}$ to occur given we know the animal is at location $\\overrightarrow{x}$\n",
    "\n",
    "## Two-step Bayesian Decoder:\n",
    "$$P(\\overrightarrow{x}_{t}|\\overrightarrow{n}_{t}, \\overrightarrow{x}_{t-1}) = k P(\\overrightarrow{x}_{t}|\\overrightarrow{n}_{t}) P(\\overrightarrow{x}_{t-1}|\\overrightarrow{x}_{t})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b8e04-3f5d-49e9-af1b-786326567330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# active_two_step_decoder['most_likely_positions'].shape # (2, 1717)\n",
    "\n",
    "active_two_step_decoder['most_likely_position_indicies'].shape # (2, 1717)\n",
    "np.max(active_two_step_decoder['most_likely_position_indicies'], axis=1) # array([0, 1])\n",
    "active_two_step_decoder['most_likely_position_indicies']\n",
    "# active_two_step_decoder['p_x_given_n_and_x_prev'].shape # (59, 21, 1717)\n",
    "\n",
    "# np.nanmax(active_two_step_decoder['p_x_given_n_and_x_prev'], axis=(1, 2)) # (59,)\n",
    "# np.nanmax(active_two_step_decoder['p_x_given_n_and_x_prev'], axis=-1).shape # (59, 21)\n",
    "\n",
    "# np.nanmax(active_two_step_decoder['p_x_given_n_and_x_prev'], axis=-1)\n",
    "# np.max(active_two_step_decoder['most_likely_positions'], axis=1) # array([ 36.30101033, 128.49991842])\n",
    "\n",
    "\n",
    "# np.max(active_one_step_decoder.most_likely_positions, axis=0) # array([244.02731273, 148.3231301 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be34e2-9062-4e08-bedb-0d7ec4ceca9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PyQtPlot Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d4e875-52e9-4bf4-b742-db1bfaab77d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array, pyqtplot_plot_image\n",
    "\n",
    "# test single image plot:\n",
    "curr_im = np.squeeze(active_one_step_decoder.ratemap.normalized_tuning_curves[0,:,:]) # (43, 63, 63)\n",
    "app, win, imv = pyqtplot_plot_image(active_one_step_decoder.xbin, active_one_step_decoder.ybin, curr_im)\n",
    "win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1263931-3967-4eff-a766-2be9b275566d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataTree Widget that displays a nested hierarchy of data:\n",
    "d = {\n",
    "    'active_sess_config':curr_active_pipeline.active_sess_config.__dict__,\n",
    "    'active_configs':curr_active_pipeline.active_configs,\n",
    "    'active_session_computation_configs':active_session_computation_configs[0].__dict__\n",
    "}\n",
    "# d = {\n",
    "#     'active_two_step_decoder': active_two_step_decoder,\n",
    "#     'active_extended_stats': active_extended_stats\n",
    "# }\n",
    "# d = {\n",
    "#     'active_session_computation_configs':active_session_computation_configs,\n",
    "#     'active_two_step_decoder': active_two_step_decoder,\n",
    "#     'active_extended_stats': active_extended_stats\n",
    "# }\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_DataTreeWidget import plot_dataTreeWidget\n",
    "tree, app = plot_dataTreeWidget(data=d, title='PhoOutputDataTreeApp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6943e136",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Params.pyqtplot_ParamTreeWidget import plot_paramTreeWidget\n",
    "param_tree, param_tree_app = plot_paramTreeWidget(title='PhoMainParamTreeApp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ddf63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Flowchart.pyqtplot_Flowchart import plot_flowchartWidget\n",
    "pipeline_flowchart_window, pipeline_flowchart_app = plot_flowchartWidget(title='PhoMainPipelineFlowchartApp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8f405-a15b-4e58-a281-c56fc6cb9c93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pg.mkQApp()\n",
    "# Create ScatterPlotWidget and configure its fields\n",
    "spw = pg.ScatterPlotWidget()\n",
    "# spw.setFields([\n",
    "    # ('x_pos', {'units': 'm'}),\n",
    "#     ('y_pos', {'units': 'm'}),\n",
    "#     ('count', {}),\n",
    "#     ('amplitude', {'units': 'V'}),\n",
    "#     ('decay', {'units': 's'}),    \n",
    "#     ('type', {'mode': 'enum', 'values': strings}),\n",
    "#     ])\n",
    "\n",
    "spw.setFields([\n",
    "    ('x', {'units': 'm'}),\n",
    "    ('y', {'units': 'm'}),\n",
    "    ('lin_pos', {'units': 'm'}),\n",
    "    ('speed', {'units': 'm/s'}),\n",
    "    ('binned_x', {}),\n",
    "    ('binned_y', {}),\n",
    "    # ('type', {'mode': 'enum', 'values': strings}),\n",
    "])\n",
    "    \n",
    "spw.setData(time_binned_pos_df)\n",
    "spw.show()\n",
    "\n",
    "\n",
    "# ## Multiple Line Plots:\n",
    "# plotWidget = pg.plot(title='PhoTest PyQtPlot Widget')\n",
    "# for i in range(3):\n",
    "#     plotWidget.plot(x, y[i], pen=(i,3))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6710ea4d-d80b-4e39-ba21-a3f9a3466ee2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check Placefield Normalizations:\n",
    "Conclusion: neither the normalized_tuning_curves nor tuning_curves are normalized in any way! They give different firing rates across time.\n",
    "NOTE: For the pyramidal-only and lap-epoch filtered Diba data, the np.nanmax of normalized_tuning_curves actually does appear to be scaled to a maximum of 1.0 across all units, meaning only the relative difference between units in firing rate is preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0938f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad417c9-8b38-4a08-a8f1-6ca254064f55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sum(active_one_step_decoder.pf.ratemap.normalized_tuning_curves, axis=(1,2)) # ERROR: the normalized_tuning_curves are NOT normalized in any way!\n",
    "np.nanmax(active_one_step_decoder.pf.ratemap.normalized_tuning_curves, axis=(1,2)) # Not even by having their maximum value scaled to one!\n",
    "\n",
    "# np.sum(active_one_step_decoder.pf.ratemap.tuning_curves, axis=(1,2))\n",
    "# np.nanmax(active_one_step_decoder.pf.ratemap.tuning_curves, axis=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb1fd1f-9bff-42b3-a3c5-5dfbd56ede80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Placefield Firing Rate Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18873548-010d-44fd-808f-f6c5dabdd545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# debug_dump_object_member_shapes(active_one_step_decoder)\n",
    "# computation_result.computed_data['pf2D_Decoder']\n",
    "# active_one_step_decoder.time_window_edges\n",
    "\n",
    "def _display_firing_rate_trends(cell_firing_rate_samples):    \n",
    "    # Incoming data is (C,N): where C is the number of cells and N is the number of datapoints.\n",
    "    num_cells = np.shape(cell_firing_rate_samples)[0]\n",
    "    num_samples = np.shape(cell_firing_rate_samples)[1]\n",
    "    assert (num_samples >= num_cells), f'num_samples should be greater than num_cells, but num_samples: {num_samples} and num_cells: {num_cells}! You probably meant the transpose of the data you passed in.'\n",
    "    \n",
    "    win = pg.plot()\n",
    "    win.setWindowTitle('pyqtgraph beeswarm: Firing Rate Trends')\n",
    "\n",
    "    print(f'np.shape(cell_firing_rate_samples): {np.shape(cell_firing_rate_samples)}, num_cells: {num_cells}, num_samples: {num_samples}')\n",
    "    # data = np.random.normal(size=(4,20))\n",
    "    # data[0] += 5\n",
    "    # data[1] += 7\n",
    "    # data[2] += 5\n",
    "    # data[3] = 10 + data[3] * 2\n",
    "\n",
    "    ## Make bar graph\n",
    "    #bar = pg.BarGraphItem(x=range(4), height=data.mean(axis=1), width=0.5, brush=0.4)\n",
    "    #win.addItem(bar)\n",
    "\n",
    "    ## add scatter plots on top\n",
    "    for i in np.arange(num_cells):\n",
    "        curr_cell_samples = cell_firing_rate_samples.loc[i,:].to_numpy()\n",
    "        print(f'i: {i} - np.shape(curr_cell_samples): {np.shape(curr_cell_samples)}')\n",
    "        xvals = pg.pseudoScatter(curr_cell_samples, spacing=0.4, bidir=True) * 0.2\n",
    "        win.plot(x=xvals+i, y=curr_cell_samples, pen=None, symbol='o', symbolBrush=pg.intColor(i,6,maxValue=128))\n",
    "\n",
    "    ## Make error bars\n",
    "    err = pg.ErrorBarItem(x=np.arange(num_cells), y=cell_firing_rate_samples.mean(axis=1), height=cell_firing_rate_samples.std(axis=1), beam=0.5, pen={'color':'w', 'width':2})\n",
    "    win.addItem(err)\n",
    "    return err, win\n",
    "\n",
    "\n",
    "# active_one_step_decoder.time_window_center_binning_info\n",
    "# position_time_delta = pd.to_timedelta(active_pos_df[active_pos_df.position.time_variable_name], unit=\"sec\")\n",
    "# active_pos_df['time_delta_sec'] = position_time_delta\n",
    "# active_pos_df = active_pos_df.set_index('time_delta_sec')\n",
    "# window_resampled_pos_df = active_pos_df.resample(f'{time_bin_size}S', base=0)#.nearest() # '0.02S' 0.02 second bins\n",
    "\n",
    "# np.shape(active_one_step_decoder.active_time_windows) # (2892, 2)\n",
    "\n",
    "active_firing_rate_trends = curr_active_pipeline.computation_results[active_config_name].computed_data['firing_rate_trends']\n",
    "\n",
    "active_rolling_window_times = active_firing_rate_trends['active_rolling_window_times']\n",
    "mean_firing_rates = active_firing_rate_trends['mean_firing_rates']\n",
    "moving_mean_firing_rates_df = active_firing_rate_trends['moving_mean_firing_rates_df']\n",
    "moving_mean_firing_rates_df # 3969 rows x 43 columns\n",
    "\n",
    "# mean_firing_rates\n",
    "# pg.plot(mean_firing_rates)\n",
    "\n",
    "np.shape(moving_mean_firing_rates_df) # (3969, 43)\n",
    "good_only_moving_mean_firing_rates_df = moving_mean_firing_rates_df.dropna() # 3910 rows x 43 columns\n",
    "good_only_moving_mean_firing_rates_df.T\n",
    "err, win = _display_firing_rate_trends(good_only_moving_mean_firing_rates_df.T)\n",
    "win.show()\n",
    "\n",
    "# active_rolling_window_times # dtype='timedelta64[ns]', name='time_delta_sec', length=2900, freq='S'\n",
    "# pg.plot(moving_mean_firing_rates_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ac6af-9c53-4d2d-9b3e-32a939acb346",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Placefield Overlap Detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9150b-f478-4a56-b645-73eaa9c9def0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Placefield Overlap Detection:\n",
    "def compute_placefield_overlap(pf):\n",
    "    return np.squeeze(np.prod(pf, axis=0))\n",
    "\n",
    "\n",
    "active_pf_overlap_results = curr_active_pipeline.computation_results[active_config_name].computed_data['placefield_overlap']\n",
    "all_pairwise_neuron_IDs_combinations = active_pf_overlap_results['all_pairwise_neuron_IDs_combinations']\n",
    "total_pairwise_overlaps = active_pf_overlap_results['total_pairwise_overlaps']\n",
    "all_pairwise_overlaps = active_pf_overlap_results['all_pairwise_overlaps']\n",
    "\n",
    "active_placefield_overlap\n",
    "total_pairwise_overlaps\n",
    "all_pairwise_overlaps\n",
    "\n",
    "\n",
    "# top_pairwise_overlaps = all_pairwise_overlaps[0:9,:,:]\n",
    "\n",
    "top_pairwise_overlaps = np.squeeze(all_pairwise_overlaps[2,:,:])\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_Matrix import MatrixRenderingWindow\n",
    "print(f'np.shape(top_pairwise_overlaps): {np.shape(top_pairwise_overlaps)}')\n",
    "pg.mkQApp(\"Correlation matrix display\")\n",
    "main_window = MatrixRenderingWindow(matrix=top_pairwise_overlaps, columns=[f'{i}' for i in np.arange(np.shape(top_pairwise_overlaps)[-1])])\n",
    "\n",
    "# compute_placefield_overlap(active_one_step_decoder.pf.ratemap.normalized_tuning_curves)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7357706-f14c-413b-9020-496db9ed63cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Position Dataframe Binning in Time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e39c8-6842-4ac4-8711-3fff06436690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aligned_active_pos_df = active_pos_df.copy()\n",
    "\n",
    "time_window_edges_time_delta = pd.to_timedelta(active_one_step_decoder.time_window_edges, unit=\"sec\") # convert the windows to timedeltas as well to allow efficient comparison\n",
    "time_window_edges_time_delta # length=1718\n",
    "\n",
    "# aligned_active_pos_df.between_time\n",
    "\n",
    "# aligned_active_pos_df.at_time(pho_custom_decoder.time_window_edges)\n",
    "\n",
    "# pho_custom_decoder.time_window_edges\n",
    "# aligned_active_pos_df.align(time_window_edges_time_delta, fill_value=np.nan)\n",
    "\n",
    "# build_position_df_time_window_idx(active_pos_df, pho_custom_decoder.active_time_window_centers)\n",
    "\n",
    "# pho_custom_decoder.active_time_window_centers\n",
    "# pho_custom_decoder.time_window_edges\n",
    "\n",
    "# s21, s22 = ts_2.align(ts_1, fill_value=0)\n",
    "\n",
    "# active_sess.position.df\n",
    "# aligned_active_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d0c686-f861-4f42-9897-d4344ed691c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pho_custom_decoder = curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D_Decoder']\n",
    "enable_plots = True\n",
    "\n",
    "print(f'most_likely_positions: {np.shape(pho_custom_decoder.most_likely_positions)}') # most_likely_positions: (3434, 2)\n",
    "\n",
    "\n",
    "def spike_count_and_firing_rate_normalizations(pho_custom_decoder, enable_plots=True):\n",
    "    \"\"\" Computes several different normalizations of binned firing rate and spike counts, optionally plotting them. \n",
    "    \n",
    "    Usage:\n",
    "        pho_custom_decoder = curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D_Decoder']\n",
    "        enable_plots = True\n",
    "        unit_specific_time_binned_outputs = spike_count_and_firing_rate_normalizations(pho_custom_decoder, enable_plots=enable_plots)\n",
    "        spike_proportion_global_fr_normalized, firing_rate, firing_rate_global_fr_normalized = unit_specific_time_binned_outputs # unwrap the output tuple:\n",
    "    \"\"\"\n",
    "    # produces a fraction which indicates which proportion of the window's firing belonged to each unit (accounts for global changes in firing rate (each window is scaled by the toial spikes of all cells in that window)\n",
    "    unit_specific_time_binned_spike_proportion_global_fr_normalized = pho_custom_decoder.unit_specific_time_binned_spike_counts / pho_custom_decoder.total_spike_counts_per_window\n",
    "    if enable_plots:\n",
    "        plt.figure(num=5)\n",
    "        plt.imshow(unit_specific_time_binned_spike_proportion_global_fr_normalized, cmap='turbo', aspect='auto')\n",
    "        plt.title('Unit Specific Proportion of Window Spikes')\n",
    "        plt.xlabel('Binned Time Window')\n",
    "        plt.ylabel('Neuron Proportion Activity')\n",
    "\n",
    "    # print(pho_custom_decoder.time_window_edges_binning_info.step)\n",
    "    # print(f'pho_custom_decoder: {pho_custom_decoder}')\n",
    "    # np.shape(pho_custom_decoder.F) # (1856, 64)\n",
    "\n",
    "    unit_specific_time_binned_firing_rate = pho_custom_decoder.unit_specific_time_binned_spike_counts / pho_custom_decoder.time_window_edges_binning_info.step\n",
    "    # print(unit_specific_time_binned_firing_rate)\n",
    "    if enable_plots:\n",
    "        plt.figure(num=6)\n",
    "        plt.imshow(unit_specific_time_binned_firing_rate, cmap='turbo', aspect='auto')\n",
    "        plt.title('Unit Specific Binned Firing Rates')\n",
    "        plt.xlabel('Binned Time Window')\n",
    "        plt.ylabel('Neuron Firing Rate')\n",
    "\n",
    "\n",
    "    # produces a unit firing rate for each window that accounts for global changes in firing rate (each window is scaled by the firing rate of all cells in that window\n",
    "    unit_specific_time_binned_firing_rate_global_fr_normalized = unit_specific_time_binned_spike_proportion_global_fr_normalized / pho_custom_decoder.time_window_edges_binning_info.step\n",
    "    if enable_plots:\n",
    "        plt.figure(num=7)\n",
    "        plt.imshow(unit_specific_time_binned_firing_rate_global_fr_normalized, cmap='turbo', aspect='auto')\n",
    "        plt.title('Unit Specific Binned Firing Rates (Global Normalized)')\n",
    "        plt.xlabel('Binned Time Window')\n",
    "        plt.ylabel('Neuron Proportion Firing Rate')\n",
    "        \n",
    "        \n",
    "    # Special:\n",
    "    # pho_custom_decoder.unit_specific_time_binned_spike_counts\n",
    "    # unit_specific_binned_spike_count_mean = np.nanmean(pho_custom_decoder.unit_specific_time_binned_spike_counts, axis=1)\n",
    "    \n",
    "\n",
    "    # Return the computed values, leaving the original data unchanged.\n",
    "    return unit_specific_time_binned_spike_proportion_global_fr_normalized, unit_specific_time_binned_firing_rate, unit_specific_time_binned_firing_rate_global_fr_normalized\n",
    "\n",
    "\n",
    "unit_specific_time_binned_outputs = spike_count_and_firing_rate_normalizations(pho_custom_decoder, enable_plots=enable_plots)\n",
    "spike_proportion_global_fr_normalized, firing_rate, firing_rate_global_fr_normalized = unit_specific_time_binned_outputs # unwrap the output tuple:\n",
    "\n",
    "# pho_custom_decoder.unit_specific_time_binned_spike_counts.shape # (64, 1717)\n",
    "unit_specific_binned_spike_count_mean = np.nanmean(pho_custom_decoder.unit_specific_time_binned_spike_counts, axis=1)\n",
    "unit_specific_binned_spike_count_var = np.nanvar(pho_custom_decoder.unit_specific_time_binned_spike_counts, axis=1)\n",
    "unit_specific_binned_spike_count_median = np.nanmedian(pho_custom_decoder.unit_specific_time_binned_spike_counts, axis=1)\n",
    "\n",
    "unit_specific_binned_spike_count_mean\n",
    "unit_specific_binned_spike_count_median\n",
    "# unit_specific_binned_spike_count_mean.shape # (64, )\n",
    "\n",
    "\n",
    "# pho_custom_decoder.unit_specific_time_binned_spike_counts\n",
    "# pho_custom_decoder.time_window_edges\n",
    "# pho_custom_decoder.time_window_edges_binning_info\n",
    "# pho_custom_decoder.total_spike_counts_per_window\n",
    "# curr_kdiba_pipeline.pf.xbin\n",
    "\n",
    "\n",
    "# active_pos_df = curr_kdiba_pipeline.filtered_sessions['maze1'].position.to_dataframe()\n",
    "# time_window_edges, time_window_edges_binning_info = compute_spanning_bins(active_pos_df['x'].to_numpy(), bin_size=max_time_bin_size) # np.shape(out_digitized_variable_bins)[0] == np.shape(spikes_df)[0]\n",
    "# assert np.shape(time_window_edges)[0] < np.shape(spikes_df)[0], f'spikes_df[time_variable_name]: {np.shape(spikes_df[time_variable_name])} should be less than time_window_edges: {np.shape(time_window_edges)}!'\n",
    "\n",
    "# active_sess.position.df\n",
    "\n",
    "# active_aligned_pos_df = align_data(pho_custom_decoder.active_time_window_centers, active_pos_df['t'].to_numpy(), active_pos_df[['x','y']].to_numpy())\n",
    "# active_aligned_pos_df = align_data(pho_custom_decoder.active_time_window_centers, active_pos_df.index, active_pos_df['x'])\n",
    "# active_aligned_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fa335-d725-41ba-a8cd-2921eb85de71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.General.Decoder.decoder_result import DecoderResultDisplayingPlot2D\n",
    "# def _display_decoder_result():\n",
    "#     renderer = DecoderResultDisplayingPlot2D(pho_custom_decoder, active_pos_df)\n",
    "#     def animate(i):\n",
    "#         # print(f'animate({i})')\n",
    "#         return renderer.display(i)\n",
    "#     interact(animate, i=(0, pho_custom_decoder.num_time_windows, 10))\n",
    "\n",
    "curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_decoder_result, 'maze1', show_posterior=True) # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b6e96-0231-4829-a895-bfd14249b4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @pn.interact(i=(0,pho_custom_decoder.num_time_windows,1,0))\n",
    "# @interact(i=pn.widgets.IntSlider(start=0,end=pho_custom_decoder.num_time_windows,step=1,value=0))\n",
    "\n",
    "# ani = FuncAnimation(renderer.fig, animate, interval=300)\n",
    "# interact(animate, i=(0, pho_custom_decoder.num_time_windows, 10))\n",
    "\n",
    "# pn.Column('**A custom interact layout**', pn.Row(layout[0], layout[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c981e-7259-4a8e-acfd-5d9146e6b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_kdiba_pipeline.computation_results['maze2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc9a4b0-0474-4f57-a5bb-e76a1fdee8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_result(curr_kdiba_pipeline.computation_results['maze1'])\n",
    "_display_result(curr_kdiba_pipeline.computation_results['maze2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58555225-e9c9-45b2-afb5-d303cabb9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from neuropy.utils.misc import is_iterable\n",
    "from neuropy.plotting.figure import pretty_plot\n",
    "from scipy.ndimage import gaussian_filter, gaussian_filter1d, interpolation\n",
    "\n",
    "from pyphoplacecellanalysis.Analysis.reliability import compute_lap_to_lap_reliability\n",
    "\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "\n",
    "\n",
    "def _test_plotRaw_v_time(active_pf, cellind, speed_thresh=False, alpha=0.5, ax=None):\n",
    "        \"\"\" Builds one subplot for each dimension of the position data\n",
    "        \n",
    "        Updated to work with both 1D and 2D Placefields \"\"\"   \n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(active_pf.ndim, 1, sharex=True)\n",
    "            fig.set_size_inches([23, 9.7])\n",
    "        \n",
    "        if not is_iterable(ax):\n",
    "            ax = [ax]\n",
    "            \n",
    "        # plot trajectories\n",
    "        if active_pf.ndim < 2:\n",
    "            variable_array = [active_pf.x]\n",
    "            label_array = [\"X position (cm)\"]\n",
    "        else:\n",
    "            variable_array = [active_pf.x, active_pf.y]\n",
    "            label_array = [\"X position (cm)\", \"Y position (cm)\"]\n",
    "            \n",
    "        for a, pos, ylabel in zip(ax, variable_array, label_array):\n",
    "            a.plot(active_pf.t, pos)\n",
    "            a.set_xlabel(\"Time (seconds)\")\n",
    "            a.set_ylabel(ylabel)\n",
    "            pretty_plot(a)\n",
    "\n",
    "        # Grab correct spike times/positions\n",
    "        if speed_thresh:\n",
    "            spk_pos_, spk_t_ = active_pf.run_spk_pos, active_pf.run_spk_t\n",
    "        else:\n",
    "            spk_pos_, spk_t_ = active_pf.spk_pos, active_pf.spk_t\n",
    "\n",
    "        # plot spikes on trajectory\n",
    "        for a, pos in zip(ax, spk_pos_[cellind]):\n",
    "            a.plot(spk_t_[cellind], pos, \".\", color=[0, 0, 0.8, alpha])\n",
    "\n",
    "        # Put info on title\n",
    "        ax[0].set_title(\n",
    "            \"Cell \"\n",
    "            + str(active_pf.cell_ids[cellind])\n",
    "            + \":, speed_thresh=\"\n",
    "            + str(active_pf.speed_thresh)\n",
    "        )\n",
    "        return ax\n",
    "\n",
    "\n",
    "def compute_reliability_metrics(out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap, debug_print=False, plot_results=False):\n",
    "    \"\"\" Takes input from compute_lap_to_lap_reliability(...) to build the actual reliability metrics \"\"\"\n",
    "    # Actual Computations of Reliability:\n",
    "    out_pairwise_pair_results = np.zeros_like(out_within_lap_spikes_overlap)\n",
    "    \n",
    "    # do simple diff:\n",
    "    laps_spikes_overlap_diff = np.diff(out_within_lap_spikes_overlap, axis=1) # the element-wise diff of the overlap. Shows changes.\n",
    "    out_pairwise_pair_results[:, 1:] = laps_spikes_overlap_diff\n",
    "    # out_pairwise_pair_results[:, -1] = np.zeros_like(out_within_lap_spikes_overlap[:,0])\n",
    "    \n",
    "    # do custom pairwise operation:\n",
    "#     for first_item_lap_idx, next_item_lap_idx in list(out_pairwise_flat_lap_indicies):\n",
    "#         first_item = out_within_lap_spikes_overlap[:, first_item_lap_idx]\n",
    "#         next_item = out_within_lap_spikes_overlap[:, next_item_lap_idx]\n",
    "#         out_pairwise_pair_results[:, next_item_lap_idx] = (first_item * next_item) # the result should be stored in the index of the second item, if we're doing the typical backwards style differences.\n",
    "#         # print(f'np.max(out_pairwise_pair_results[:, next_item_lap_idx]): {np.max(out_pairwise_pair_results[:, next_item_lap_idx])}')\n",
    "\n",
    "    if debug_print: \n",
    "        print(f'max out: {np.max(out_pairwise_pair_results)}')\n",
    "        \n",
    "    lap_ids \n",
    "    flat_lap_idxs = np.arange(len(lap_ids))\n",
    "    \n",
    "    \n",
    "    # add to the extant plot as a new color:\n",
    "    if plot_results:\n",
    "        for lap_idx, lap_ID in zip(flat_lap_idxs, lap_ids):\n",
    "            # curr_lap_alt_ax = axs[lap_idx]\n",
    "            if plot_horizontal:\n",
    "                curr_lap_alt_ax = axs[lap_idx].twiny()\n",
    "                curr_lap_alt_ax.plot(out_pairwise_pair_results[:, lap_idx], out_digitized_position_bins, '--r')\n",
    "            else:\n",
    "                # vertical\n",
    "                curr_lap_alt_ax = axs[lap_idx].twinx()\n",
    "                curr_lap_alt_ax.plot(out_digitized_position_bins, out_pairwise_pair_results[:, lap_idx], '--r')\n",
    "            \n",
    "    cum_laps_reliability = np.cumprod(out_within_lap_spikes_overlap, axis=1)\n",
    "    all_laps_reliability = np.prod(out_within_lap_spikes_overlap, axis=1, keepdims=True)\n",
    "    \n",
    "    if plot_results:\n",
    "        fig_result, axs_result = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(24, 40))\n",
    "        axs_result[0].plot(out_digitized_position_bins, all_laps_reliability, 'r')\n",
    "        axs_result[1].plot(out_digitized_position_bins, cum_laps_reliability, 'r')\n",
    "\n",
    "curr_result_label = 'maze1'\n",
    "sess = curr_kdiba_pipeline.filtered_sessions[curr_result_label]\n",
    "sess = curr_kdiba_pipeline.sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340e1ae-1165-4a55-b35a-73de562df226",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_laps_df = sess.laps.to_dataframe()\n",
    "curr_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00bc5e4-11cc-456f-994e-d4ae3ece2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "position_obj = sess.position\n",
    "position_obj.compute_higher_order_derivatives()\n",
    "pos_df = position_obj.compute_smoothed_position_info(N=20) ## Smooth the velocity curve to apply meaningful logic to it\n",
    "pos_df = position_obj.to_dataframe()\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58644ddd-6efe-40b7-a9c5-5971a1bc1bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, out_axes_list = plot_laps_2d(sess, legacy_plotting_mode=True)\n",
    "fig, out_axes_list = plot_laps_2d(sess, legacy_plotting_mode=False)\n",
    "out_axes_list[0].set_title('New Pho Position Thresholding Estimated Laps')\n",
    "\n",
    "curr_cell_idx = 2 \n",
    "# curr_cell_idx = 3 # good for end platform analysis\n",
    "curr_cell_ID = sess.spikes_df.spikes.neuron_ids[curr_cell_idx]\n",
    "print(f'curr_cell_idx: {curr_cell_idx}, curr_cell_ID: {curr_cell_ID}')\n",
    "\n",
    "# pre-filter by spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "filtered_spikes_df = sess.spikes_df.copy()\n",
    "time_variable_name = filtered_spikes_df.spikes.time_variable_name # 't_rel_seconds'\n",
    "\n",
    "lap_ids = sess.laps.lap_id\n",
    "# lap_flat_idxs = sess.laps.get_lap_flat_indicies(lap_ids)\n",
    "\n",
    "out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap = compute_lap_to_lap_reliability(curr_kdiba_pipeline.computation_results[curr_result_label].computed_data['pf2D'], filtered_spikes_df, lap_ids, curr_cell_idx, debug_print=False, plot_results=True);\n",
    "\n",
    "# compute_reliability_metrics(out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap, debug_print=False, plot_results=False)\n",
    "\n",
    "# # curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D'].plotRaw_v_time(curr_cell_idx)\n",
    "# _test_plotRaw_v_time(curr_kdiba_pipeline.computation_results[curr_result_label].computed_data['pf2D'], curr_cell_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e8e317-9b3c-4895-ac55-13600e8ccc47",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3D Lap Plotting Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752016f-67d4-4351-a61d-defc8a1bff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice # for Pagination class\n",
    "import pyvista as pv\n",
    "import pyvistaqt as pvqt\n",
    "from PhoGui.InteractivePlotter.LapsVisualizationMixin import LapsVisualizationMixin\n",
    "from PhoGui.PhoCustomVtkWidgets import PhoWidgetHelper\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.spikeAndPositions import perform_plot_flat_arena, _build_flat_arena_data\n",
    "\n",
    "\"\"\" Test Drawing Spike Lines \"\"\"\n",
    "# from pyphoplacecellanalysis.Pho3D.spikes import draw_line_spike, lines_from_points\n",
    "from pyphoplacecellanalysis.Pho3D.points import interlieve_points\n",
    "\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.spikeAndPositions import build_active_spikes_plot_pointdata_df\n",
    "\n",
    "def _plot_all_lap_spikes(p, sess, included_cell_IDXs, included_lap_IDXs, debug_print=True, lap_start_z=0.0, lap_id_dependent_z_offset=10.0):\n",
    "    should_reinterpolate_spike_positions = False\n",
    "        \n",
    "    def _plot_single_spikes(p, cell_specific_spikes_dfs, placefield_cell_index):\n",
    "        curr_cell_spike_df = cell_specific_spikes_dfs[placefield_cell_index]\n",
    "        # curr_cell_spike_df['z_fixed'] = np.full_like(active_flat_df['x'].values, 1.1)\n",
    "        pdata = build_active_spikes_plot_pointdata_df(curr_cell_spike_df)\n",
    "\n",
    "        # curr_cell_spike_times = curr_cell_spike_df[curr_cell_spike_df.spikes.time_variable_name].to_numpy()  # (271,)\n",
    "        # curr_cell_spike_positions = curr_cell_spike_df['x','y'].to_numpy()  # (271,)\n",
    "\n",
    "        # lines_from_points(\n",
    "        # p[0,0].add_points(pdata, name='plot_single_spikes_points', render_points_as_spheres=True, point_size=5.0)\n",
    "\n",
    "        # Build offset points and spike data:\n",
    "        spike_height = max((lap_id_dependent_z_offset * 0.6), 0.5) # half the line height\n",
    "\n",
    "        # start_points = pdata.points.copy()\n",
    "        # end_points = start_points.copy()\n",
    "        # # end_points[:,2] # get z values\n",
    "        # end_points[:,2] = end_points[:,2] + spike_height\n",
    "        # all_points = interlieve_points(start_points, end_points)\n",
    "        # lines_poly_data = pv.PolyData()\n",
    "        # lines_poly_data.points = all_points\n",
    "        # # cells = np.hstack(([2, 0, 1],[2, 1, 2]))\n",
    "        # num_lines = np.shape(start_points)[0]\n",
    "        # cells = [[2, 2*i, 2*i+1] for i in np.arange(num_lines)]\n",
    "        # lines_poly_data.lines = cells\n",
    "        \n",
    "        p[0,0].add_mesh(pdata, name=f'plot_single_spikes_points[{placefield_cell_index}]', render_points_as_spheres=True, point_size=5.0, color='white')        \n",
    "        \n",
    "        # p[0,0].add_points(pdata, name=f'plot_single_spikes_points[{placefield_cell_index}]', render_points_as_spheres=True, point_size=5.0)\n",
    "        # p[0,0].add_mesh(lines_poly_data, name=f'plot_single_spikes_lines[{placefield_cell_index}]', render_points_as_spheres=False, point_size=5.0)\n",
    "        # return {'pdata':pdata, 'lines_poly_data':lines_poly_data}\n",
    "        \n",
    "        return {'pdata':pdata}\n",
    "    \n",
    "    time_variable_name = sess.spikes_df.spikes.time_variable_name # 't_rel_seconds'\n",
    "    # sets the 'z_fixed' value for all spikes in sess.spikes_df, which will be used to plot them as points\n",
    "    sess.spikes_df['z'] = lap_start_z + (lap_id_dependent_z_offset * sess.spikes_df.lap.to_numpy())\n",
    "\n",
    "    if debug_print:\n",
    "        print(f'sess.laps.lap_id: {sess.laps.lap_id}')\n",
    "        \n",
    "    included_cell_IDXs = np.array(included_cell_IDXs)\n",
    "    included_lap_IDXs = np.array(included_lap_IDXs)\n",
    "    \n",
    "    # ensure that only lap_ids included in this session are used:\n",
    "    included_lap_ids = sess.laps.lap_id[included_lap_IDXs]\n",
    "    possible_included_lap_ids = np.unique(sess.spikes_df.lap.values)\n",
    "    if debug_print:\n",
    "        print(f'np.unique(sess.spikes_df.lap.values): {np.unique(sess.spikes_df.lap.values)}')\n",
    "    included_lap_ids = included_lap_ids[np.isin(included_lap_ids, possible_included_lap_ids)]\n",
    "    if debug_print:\n",
    "        print(f'included_lap_ids: {included_lap_ids}')\n",
    "    \n",
    "    # get the included cell IDs\n",
    "    included_cell_IDs = np.array(sess.spikes_df.spikes.neuron_ids)[included_cell_IDXs]\n",
    "        \n",
    "    # print(np.isin(['R','G','B','render_opacity'], sess.spikes_df.columns).all())\n",
    "\n",
    "    # POSITIONS:\n",
    "    curr_position_df, lap_specific_position_dfs, lap_specific_time_ranges, lap_specific_position_traces = LapsVisualizationMixin._compute_laps_position_data(sess)\n",
    "    \n",
    "    # SPIKES:\n",
    "    # # grouped by lap\n",
    "    # lap_grouped_spikes_df = sess.spikes_df.groupby('lap')\n",
    "    # lap_specific_spikes_dfs = [lap_grouped_spikes_df.get_group(i)[[time_variable_name,'aclu','lap','flat_spike_idx','cell_type','x','y','lin_pos','z']] for i in included_lap_ids] # dataframes split for each ID:\n",
    "\n",
    "    # grouped by cell:\n",
    "    # pre-filter by spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "    filtered_spikes_df = sess.spikes_df.copy()\n",
    "    filtered_spikes_df = filtered_spikes_df[np.isin(filtered_spikes_df['lap'], included_lap_ids)] # get only the spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "    \n",
    "    \n",
    "    # Interpolate the spikes positions again:\n",
    "    if should_reinterpolate_spike_positions:\n",
    "        print('Re-interpolating spike positions...')\n",
    "        filtered_spikes_df = filtered_spikes_df.spikes.interpolate_spike_positions(curr_position_df['t'].to_numpy(), curr_position_df['x'].to_numpy(), curr_position_df['y'].to_numpy())\n",
    "        # filtered_spikes_df = FlattenedSpiketrains.interpolate_spike_positions(filtered_spikes_df, session.position.time, session.position.x, session.position.y, spike_timestamp_column_name=time_variable_name)\n",
    "    \n",
    "    cell_grouped_spikes_df = filtered_spikes_df.groupby('aclu')\n",
    "    cell_specific_spikes_dfs = [cell_grouped_spikes_df.get_group(i)[[time_variable_name,'aclu','lap','flat_spike_idx','cell_type','x','y','lin_pos','z']] for i in included_cell_IDs] # dataframes split for each ID:\n",
    "\n",
    "    # lap_specific_position_dfs = _compute_laps_position_data(sess)\n",
    "\n",
    "    # # Positions:\n",
    "    # curr_position_df = sess.compute_position_laps()\n",
    "    # included_pos_lap_ids = np.unique(curr_position_df.lap.values)\n",
    "    # print(f'np.unique(curr_position_df.lap.values): {np.unique(curr_position_df.lap.values)}')\n",
    "    # included_pos_lap_ids = included_pos_lap_ids[np.isin(included_pos_lap_ids, sess.laps.lap_id)]\n",
    "    # included_pos_lap_ids\n",
    "\n",
    "    # print(f'included_pos_lap_ids: {included_pos_lap_ids}')\n",
    "\n",
    "    # lap_grouped_position_df = curr_position_df.groupby('lap')\n",
    "    # lap_specific_position_dfs = [lap_grouped_position_df.get_group(i)[['t','aclu','x','y','lin_pos']] for i in included_lap_ids] # dataframes split for each ID:\n",
    "\n",
    "    for i, curr_cell_ID in enumerate(included_cell_IDs):\n",
    "        plot_data_dict = _plot_single_spikes(p, cell_specific_spikes_dfs, i)\n",
    "\n",
    "\n",
    "# sess = curr_kdiba_pipeline.filtered_sessions['maze']\n",
    "# included_cell_IDXs = [6]\n",
    "# included_lap_IDXs = [2, 3]\n",
    "# _plot_all_lap_spikes(pActiveInteractiveLapsPlotter, sess, included_cell_IDXs, included_lap_IDXs)\n",
    "\n",
    "from PhoGui.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer\n",
    "\n",
    "lap_start_z = 0.0\n",
    "# lap_id_dependent_z_offset = 0.0\n",
    "lap_id_dependent_z_offset = 3.0\n",
    "# curr_kdiba_pipeline.active_configs['maze1'].lap_id_dependent_z_offset = 3.0\n",
    "\n",
    "def _display_testing(sess, computation_result, active_config, extant_plotter=None):\n",
    "    \"\"\" Testing of plot_lap_trajectories_2d \"\"\"\n",
    "    print(f'active_config.plotting_config: {active_config.plotting_config}')\n",
    "    single_combined_plot=True\n",
    "    if single_combined_plot:\n",
    "        default_plotting = True\n",
    "    else:\n",
    "        default_plotting = False\n",
    "    active_config.plotting_config.plotter_type = 'MultiPlotter'\n",
    "    print(f'active_config.plotting_config: {active_config.plotting_config}')\n",
    "    iplapsDataExplorer = InteractiveCustomDataExplorer(active_config, sess, extant_plotter=extant_plotter)\n",
    "    pActiveInteractiveLapsPlotter = iplapsDataExplorer.plot(pActivePlotter=extant_plotter, default_plotting=default_plotting)\n",
    "    # included_cell_idxs = None\n",
    "    included_cell_idxs = [0, 1]\n",
    "    # included_lap_idxs = [2, 5, 9, 12]\n",
    "    included_lap_idxs = [2]\n",
    "    # All\n",
    "    # included_cell_idxs = np.arange(len(sess.spikes_df.spikes.neuron_ids))\n",
    "    # included_lap_idxs = np.arange(len(sess.laps.lap_id))\n",
    "    from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_3d\n",
    "    pActiveInteractiveLapsPlotter, laps_pages = plot_lap_trajectories_3d(sess, curr_num_subplots=5, active_page_index=0, included_lap_idxs=included_lap_idxs, single_combined_plot=single_combined_plot, \n",
    "                                                                         lap_start_z = lap_start_z, lap_id_dependent_z_offset = lap_id_dependent_z_offset,\n",
    "                                                                         existing_plotter=pActiveInteractiveLapsPlotter)\n",
    "\n",
    "    # add the spikes for the curves:\n",
    "    _plot_all_lap_spikes(pActiveInteractiveLapsPlotter, sess, included_cell_idxs, included_lap_idxs, lap_start_z=lap_start_z, lap_id_dependent_z_offset=lap_id_dependent_z_offset)\n",
    "    return iplapsDataExplorer, pActiveInteractiveLapsPlotter\n",
    "\n",
    "\n",
    "# curr_kdiba_pipeline.computation_results['maze1'].computation_config\n",
    "# curr_kdiba_pipeline.computation_results['maze1'].sess.config\n",
    "# curr_kdiba_pipeline.active_configs['maze1']\n",
    "\n",
    "curr_result_label = 'maze1'\n",
    "sess = curr_active_pipeline.filtered_sessions[curr_result_label]\n",
    "sess = curr_active_pipeline.sess\n",
    "\n",
    "pActiveInteractiveLapsPlotter = None\n",
    "try: pActiveInteractiveLapsPlotter\n",
    "except NameError: pActiveInteractiveLapsPlotter = None # Checks variable p's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "iplapsDataExplorer, pActiveInteractiveLapsPlotter = _display_testing(sess, curr_active_pipeline.computation_results[curr_result_label], curr_active_pipeline.active_configs[curr_result_label],\n",
    "                                                                     extant_plotter=pActiveInteractiveLapsPlotter)\n",
    "pActiveInteractiveLapsPlotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e5881e-3e37-4d8b-b5c3-0c8837cbd1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines_from_points(pdata.points)\n",
    "\n",
    "np.shape(all_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580c6e6-38b1-4d6e-bf09-6b60842a922a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a0d93-16ac-4240-a373-7bd9f337f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, laps_pages = _plot_lap_trajectories_combined_plot_3d(curr_kdiba_pipeline.sess, curr_num_subplots=5, single_combined_plot=False)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86802581-69ea-4aca-a673-e4e306d6e17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phoviz_ultimate]",
   "language": "python",
   "name": "conda-env-phoviz_ultimate-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
