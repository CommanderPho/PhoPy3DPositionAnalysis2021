{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b61d95b0-92dc-49ad-a4f6-9a3626ad363a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      \n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.0.min.js\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/widgets.css\"];\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\");\\n      max-height: 400px;\\n    }\\n    \");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, js_modules, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      \n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.0.min.js\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/widgets.css\"];\n  var inline_js = [\n    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\");\\n      max-height: 400px;\\n    }\\n    \");\n    },\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuropy module not found, adding directory to sys.path. \n",
      " >> Updated sys.path.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: pho\n",
    "\"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## Panel:\n",
    "import param\n",
    "import panel as pn\n",
    "from panel.interact import interact, interactive, fixed, interact_manual\n",
    "from panel.viewable import Viewer\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import get_arguments_as_optional_dict, inspect_callable_arguments\n",
    "from pyphocorehelpers.function_helpers import compose_functions\n",
    "from pyphocorehelpers.indexing_helpers import partition, build_spanning_bins, compute_spanning_bins, compute_position_grid_size\n",
    "from pyphocorehelpers.print_helpers import PrettyPrintable, WrappingMessagePrinter\n",
    "from pyphocorehelpers.geometry_helpers import compute_data_extent, compute_data_aspect_ratio, corner_points_from_extents\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import * # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.SessionSelectionAndFiltering import batch_filter_session\n",
    "from pyphoplacecellanalysis.General.ComputationResults import ComputationResult\n",
    "# from PendingNotebookCode import estimation_session_laps\n",
    "\n",
    "\n",
    "from neuropy.analyses.laps import estimation_session_laps\n",
    "from neuropy.core.epoch import NamedTimerange\n",
    "\n",
    "# Neuropy:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters, perform_compute_placefields\n",
    "from neuropy.core.neuron_identities import NeuronIdentity, build_units_colormap, PlotStringBrevityModeEnum\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_spike_counts, debug_print_subsession_neuron_differences\n",
    "from neuropy.plotting.ratemaps import enumTuningMap2DPlotVariables\n",
    "\n",
    "\n",
    "# def estimate_session_laps_load_function(regular_load_function, a_base_dir):\n",
    "#     session = regular_load_function(a_base_dir)\n",
    "#     ## Estimate the Session's Laps data using my algorithm from the loaded position data.\n",
    "#     session = estimation_session_laps(session)\n",
    "#     return session\n",
    "\n",
    "known_data_session_type_dict = {'kdiba':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: DataSessionLoader.kdiba_old_format_session(a_base_dir)),\n",
    "                               basedir=Path(r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53')),\n",
    "                'bapun':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: DataSessionLoader.bapun_data_session(a_base_dir)),\n",
    "                               basedir=Path('R:\\data\\Bapun\\Day5TwoNovel'))\n",
    "               }\n",
    "\n",
    "known_data_session_type_dict['kdiba'].post_load_functions = [lambda a_loaded_sess: estimation_session_laps(a_loaded_sess)]\n",
    "# known_data_session_type_dict = {'kdiba':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: estimation_session_laps(DataSessionLoader.kdiba_old_format_session(a_base_dir))),\n",
    "#                                basedir=Path(r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53')),\n",
    "#                 'bapun':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: DataSessionLoader.bapun_data_session(a_base_dir)),\n",
    "#                                basedir=Path('R:\\data\\Bapun\\Day5TwoNovel'))\n",
    "#                }\n",
    "\n",
    "# known_data_session_type_dict['kdiba'].name\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "from matplotlib.transforms import IdentityTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff2b27e-8b58-4e47-8efd-b634d70034ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Common Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad2d8f96-9823-4b26-b8fb-874fa091a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING! TODO: Changing the smooth values from (1.5, 1.5) to (0.5, 0.5) was the difference between successful running and a syntax error!\n",
    "active_session_computation_config = PlacefieldComputationParameters(speed_thresh=15.0, grid_bin=None, smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3e2f6e-f8c5-495e-b1ab-081e85bd4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_position_grid_bin_size(x, y, num_bins=(64,64), debug_print=False):\n",
    "    \"\"\" Compute Required Bin size given a desired number of bins in each dimension\n",
    "    Usage:\n",
    "        active_grid_bin = compute_position_grid_bin_size(curr_kdiba_pipeline.sess.position.x, curr_kdiba_pipeline.sess.position.y, num_bins=(64, 64)\n",
    "    \"\"\"\n",
    "    out_grid_bin_size, out_bins, out_bins_infos = compute_position_grid_size(x, y, num_bins=num_bins)\n",
    "    active_grid_bin = tuple(out_grid_bin_size)\n",
    "    if debug_print:\n",
    "        print(f'active_grid_bin: {active_grid_bin}') # (3.776841861770752, 1.043326930905373)\n",
    "    return active_grid_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29f42d28-1451-412f-b743-20b1e9d5e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.background_helpers import build_image_from_text\n",
    "from pyphocorehelpers.plotting.figure_management import PhoActiveFigureManager2D, FigureFormatter2D\n",
    "\n",
    "def _display_add_computation_param_text_box(fig, computation_config):\n",
    "    \"\"\" Adds the computation parmaters to the matplotlib figure. \n",
    "    Usage:\n",
    "        _display_add_computation_param_text_box(plt.gcf(), active_session_computation_config)\n",
    "    \"\"\"\n",
    "    if fig is None:\n",
    "        fig = plt.gcf()\n",
    "    render_text = computation_config.str_for_attributes_list_display(key_val_sep_char=':')\n",
    "    # This configures the background box that wraps the text content. these are matplotlib.patch.Patch properties\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    # place a text box in upper left in axes coords\n",
    "    # ax.text(0.05, 0.95, render_text, transform=ax.transAxes, fontsize=12, verticalalignment='top', bbox=props)\n",
    "    active_properties_box_text = fig.text(20, 20, render_text, color=\"k\", fontsize=12, transform=IdentityTransform(), bbox=props)\n",
    "    return active_properties_box_text\n",
    "\n",
    "activeFigureMan = PhoActiveFigureManager2D('2D Firing Maps') # Used to adjust displayed figure window sizes\n",
    "\n",
    "# fig = plt.figure()\n",
    "# render_text = active_session_computation_config.str_for_attributes_list_display(key_val_sep_char=':')\n",
    "# fig.text(0, 250, render_text, color=\"k\", fontsize=12, transform=IdentityTransform(), wrap=True)\n",
    "\n",
    "# # rgba1 = build_image_from_text(r\"IQ: $\\sigma_i=15$\", color=\"blue\", fontsize=20, dpi=200)\n",
    "# # rgba2 = build_image_from_text(r\"some other string\", color=\"red\", fontsize=20, dpi=200)\n",
    "# # # One can then draw such text images to a Figure using `.Figure.figimage`.\n",
    "# # fig.figimage(rgba1, 100, 50)\n",
    "# # fig.figimage(rgba2, 100, 150)\n",
    "\n",
    "# # # One can also directly draw texts to a figure with positioning\n",
    "# # # in pixel coordinates by using `.Figure.text` together with\n",
    "# # # `.transforms.IdentityTransform`.\n",
    "# # fig.text(100, 250, r\"IQ: $\\sigma_i=15$\", color=\"blue\", fontsize=20,\n",
    "# #         transform=IdentityTransform())\n",
    "# # fig.text(100, 350, r\"some other string\", color=\"red\", fontsize=20,\n",
    "# #         transform=IdentityTransform())\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c20a2-aacf-4db5-b6d7-782bab58d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import multivariate_normal\n",
    "\n",
    "# multivariate_normal.pdf()\n",
    "\n",
    "\n",
    "# from sklearn.neighbors import KernelDensity\n",
    "\n",
    "# kde = KernelDensity(kernel='gaussian', bandwidth=1.0).fix(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eceb354-7fa7-4064-ba26-4e989b9f3354",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Bapun Format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20843de4-9a94-42f7-80a9-f2c8d5704b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_bapun_pipeline = NeuropyPipeline(name='bapun_pipeline', session_data_type='bapun', basedir=known_data_session_type_dict['bapun'].basedir, load_function=known_data_session_type_dict['bapun'].load_function)\n",
    "curr_bapun_pipeline = NeuropyPipeline.init_from_known_data_session_type('bapun', known_data_session_type_dict['bapun'])\n",
    "curr_bapun_pipeline.is_loaded\n",
    "size_bytes = curr_bapun_pipeline.sess.__sizeof__() # 1753723032\n",
    "f'object size: {size_bytes/(1024*1024)} MB'\n",
    "active_session_computation_config.grid_bin = compute_position_grid_bin_size(curr_bapun_pipeline.sess.position.x, curr_bapun_pipeline.sess.position.y, num_bins=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06847783-f934-43d9-bd7d-4206629ff737",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_bapun_pipeline.sess.spikes_df.spikes.time_variable_name # 't_rel_seconds'\n",
    "curr_bapun_pipeline.sess.position.to_dataframe().position.time_variable_name # t\n",
    "# .spikes.time_variable_name # 't_rel_seconds'\n",
    "# spk_df.spikes.time_variable_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c855eb33-31b0-4e01-8721-6d10c75d8a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bapun/DataFrame style session filter functions:\n",
    "def build_bapun_any_maze_epochs_filters(sess):\n",
    "    def _temp_filter_session_by_epoch1(sess):\n",
    "        \"\"\" \n",
    "        Usage:\n",
    "            active_session, active_epoch = _temp_filter_session(curr_bapun_pipeline.sess)\n",
    "        \"\"\"\n",
    "        active_epoch = sess.epochs.get_named_timerange('maze1')\n",
    "        ## All Spikes:\n",
    "        # active_epoch_session = sess.filtered_by_epoch(active_epoch) # old\n",
    "        active_session = batch_filter_session(sess, sess.position, sess.spikes_df, active_epoch.to_Epoch())\n",
    "        return active_session, active_epoch\n",
    "\n",
    "    def _temp_filter_session_by_epoch2(sess):\n",
    "        \"\"\" \n",
    "        Usage:\n",
    "            active_session, active_epoch = _temp_filter_session(curr_bapun_pipeline.sess)\n",
    "        \"\"\"\n",
    "        active_epoch = sess.epochs.get_named_timerange('maze2')\n",
    "        ## All Spikes:\n",
    "        # active_epoch_session = sess.filtered_by_epoch(active_epoch) # old\n",
    "        active_session = batch_filter_session(sess, sess.position, sess.spikes_df, active_epoch.to_Epoch())\n",
    "        return active_session, active_epoch\n",
    "\n",
    "    # return {'maze1':_temp_filter_session_by_epoch1}\n",
    "    return {'maze1':_temp_filter_session_by_epoch1,\n",
    "            'maze2':_temp_filter_session_by_epoch2\n",
    "           }\n",
    "\n",
    "    # return {'maze1': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')),\n",
    "    #         'maze2': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze2')), x.epochs.get_named_timerange('maze2'))\n",
    "    #        }\n",
    "\n",
    "active_session_filter_configurations = build_bapun_any_maze_epochs_filters(curr_bapun_pipeline.sess)\n",
    "curr_bapun_pipeline.filter_sessions(active_session_filter_configurations)\n",
    "curr_bapun_pipeline.perform_computations(active_session_computation_config)\n",
    "curr_bapun_pipeline.prepare_for_display() # TODO: pass a display config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba74076-14cb-4aab-9462-650b0e566570",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_bapun_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, 'maze1', subplots=(20, 8), enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=1) # works!\n",
    "activeFigureMan.set_geometries(x=0, y=35, width=2048, height=2048) # Ensure it fits on the screen vertically.\n",
    "_display_add_computation_param_text_box(plt.gcf(), active_session_computation_config) # 60, 35, 2547, 2049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa867d-b6f3-4b11-a4dd-1da4bca7fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_bapun_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, 'maze1', subplots=(20, 8), enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=1) # works!\n",
    "activeFigureMan.set_geometries(x=0, y=35, width=2256, height=2048) # Ensure it fits on the screen vertically.\n",
    "_display_add_computation_param_text_box(plt.gcf(), active_session_computation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c4f39-412d-42e7-9b3d-8417993ee562",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_result(curr_bapun_pipeline.computation_results['maze1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c4907-c242-4908-80dd-0c7d49e89b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_result(curr_bapun_pipeline.computation_results['maze2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4940269-23e4-46dc-a4ae-61d512ac5e41",
   "metadata": {
    "tags": []
   },
   "source": [
    "# KDiba Format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69a69581-2f38-4d64-bc21-d38041e2b068",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir is already Path object.\n",
      "\t basepath: R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\n",
      "\t session_name: 2006-6-07_11-26-53\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.epochs_info.mat... done.\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position_info.mat... done.\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Computing linear positions for all active epochs for session... Saving updated position results results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position.npy... 2006-6-07_11-26-53.position.npy saved\n",
      "done.\n",
      "\t Failure loading .interpolated_spike_positions.npy. Must recompute.\n",
      "\n",
      "\t Saving updated interpolated spike position results results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.interpolated_spike_positions.npy... 2006-6-07_11-26-53.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "desc_crossings_x: (24,), asc_crossings_x: (24,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'object size: 144.8962745666504 MB'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "# R:\\data\\KDIBA\\gor01\\one\\IIDataMat_Export_ToPython_2021_11_23.m\n",
    "# From pre-computed .mat files:\n",
    "## 07: \n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53'\n",
    "# # ## 08:\n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15'\n",
    "# curr_kdiba_pipeline = NeuropyPipeline(name='kdiba_pipeline', session_data_type='kdiba', basedir=known_data_session_type_dict['kdiba'].basedir, load_function=known_data_session_type_dict['kdiba'].load_function)\n",
    "curr_kdiba_pipeline = NeuropyPipeline.init_from_known_data_session_type('kdiba', known_data_session_type_dict['kdiba'])\n",
    "active_session_computation_config.grid_bin = compute_position_grid_bin_size(curr_kdiba_pipeline.sess.position.x, curr_kdiba_pipeline.sess.position.y, num_bins=(64, 64))\n",
    "\n",
    "# curr_bapun_pipeline\n",
    "curr_kdiba_pipeline.is_loaded\n",
    "size_bytes = curr_kdiba_pipeline.sess.__sizeof__() # 1753723032\n",
    "f'object size: {size_bytes/(1024*1024)} MB'\n",
    "# ## Estimate the Session's Laps data using my algorithm from the loaded position data.\n",
    "# curr_kdiba_pipeline.sess = estimation_session_laps(curr_kdiba_pipeline.sess)\n",
    "# curr_kdiba_pipeline.sess.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd21e72-a207-4fdd-8bc0-be9313b408e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 22.26, end: 1739.1533641185379)\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 1739.1533641185379, end: 1932.4200048116618)\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 22.26, end: 1932.4200048116618)\n",
      "Performing single_computation on filtered_session with filter named \"maze1\"...\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Performing perform_registered_computations(...) with 1 registered_computation_functions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:175: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  C_tau_n = 1.0 / np.sum(un_normalized_result) # normalize the result\n",
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:176: RuntimeWarning: invalid value encountered in multiply\n",
      "  result = C_tau_n * un_normalized_result\n",
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:175: RuntimeWarning: overflow encountered in double_scalars\n",
      "  C_tau_n = 1.0 / np.sum(un_normalized_result) # normalize the result\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing single_computation on filtered_session with filter named \"maze2\"...\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Performing perform_registered_computations(...) with 1 registered_computation_functions...\n",
      "Performing single_computation on filtered_session with filter named \"maze\"...\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Performing perform_registered_computations(...) with 1 registered_computation_functions...\n",
      "The specified cmap supports less colors than n_neurons (supports 7, n_neurons: 64). An extended colormap will be built.\n",
      "The specified cmap supports less colors than n_neurons (supports 7, n_neurons: 64). An extended colormap will be built.\n",
      "The specified cmap supports less colors than n_neurons (supports 7, n_neurons: 64). An extended colormap will be built.\n"
     ]
    }
   ],
   "source": [
    "def build_any_maze_epochs_filters(sess):\n",
    "    ## All Spikes:\n",
    "    sess.epochs.t_start = 22.26 # exclude the first short period where the animal isn't on the maze yet\n",
    "    active_session_filter_configurations = {'maze1': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')),\n",
    "                                        'maze2': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze2')), x.epochs.get_named_timerange('maze2')),\n",
    "                                        'maze': lambda x: (x.filtered_by_epoch(NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]])), NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]]))\n",
    "                                       }\n",
    "    return active_session_filter_configurations\n",
    "\n",
    "active_session_filter_configurations = build_any_maze_epochs_filters(curr_kdiba_pipeline.sess)\n",
    "curr_kdiba_pipeline.filter_sessions(active_session_filter_configurations)\n",
    "curr_kdiba_pipeline.perform_computations(active_session_computation_config)\n",
    "curr_kdiba_pipeline.prepare_for_display() # TODO: pass a display config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d2b141-433e-41a7-8722-8b1cdc5da776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lap_epochs_filters(sess):\n",
    "    lap_specific_epochs = sess.laps.as_epoch_obj()\n",
    "    any_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(len(sess.laps.lap_id))])\n",
    "    even_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(0, len(sess.laps.lap_id), 2)])\n",
    "    odd_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(1, len(sess.laps.lap_id), 2)])\n",
    "    ## All Spikes:\n",
    "    sess.epochs.t_start = 22.26 # exclude the first short period where the animal isn't on the maze yet\n",
    "    active_session_filter_configurations = {'maze1': lambda x: (x.filtered_by_neuron_type('pyramidal').filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')),\n",
    "                                        'maze2': lambda x: (x.filtered_by_neuron_type('pyramidal').filtered_by_epoch(x.epochs.get_named_timerange('maze2')), x.epochs.get_named_timerange('maze2')),\n",
    "                                        'maze': lambda x: (x.filtered_by_neuron_type('pyramidal').filtered_by_epoch(NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]])), NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]]))\n",
    "                                       }\n",
    "    return active_session_filter_configurations\n",
    "\n",
    "active_session_filter_configurations = build_lap_epochs_filters(curr_kdiba_pipeline.sess)\n",
    "curr_kdiba_pipeline.filter_sessions(active_session_filter_configurations)\n",
    "curr_kdiba_pipeline.perform_computations(active_session_computation_config)\n",
    "curr_kdiba_pipeline.prepare_for_display() # TODO: pass a display config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e009f713-62ba-49fe-80f4-6fc47e6c4516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _display_placemaps_2D(filter_name: str, plot_variable: enumTuningMap2DPlotVariables=enumTuningMap2DPlotVariables.FIRING_MAPS, variant_identifier_label:str = None, should_save_to_disk=True, common_parent_foldername=None):\n",
    "    # relies on curr_kdiba_pipeline, activeFigureMan, active_session_computation_config\n",
    "    if plot_variable.name == enumTuningMap2DPlotVariables.FIRING_MAPS.name:\n",
    "        fignum=1\n",
    "        active_pf_2D_filename_prefix_string = f'FiringMaps-{filter_name}'\n",
    "    elif plot_variable.name == enumTuningMap2DPlotVariables.TUNING_MAPS.name:\n",
    "        fignum=2\n",
    "        active_pf_2D_filename_prefix_string = f'Placefields-{filter_name}'\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    height=1868 # for diba data:\n",
    "    \n",
    "    active_config = curr_kdiba_pipeline.active_configs[filter_name] \n",
    "    \n",
    "    # Main display\n",
    "    curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=plot_variable, fignum=fignum) # works!\n",
    "    activeFigureMan.set_geometries(height=height) # Ensure it fits on the screen vertically.\n",
    "    active_figure = plt.gcf()\n",
    "    _display_add_computation_param_text_box(active_figure, active_session_computation_config) # Adds the parameters text.\n",
    "    active_pf_2D_figures = [active_figure]\n",
    "\n",
    "    if should_save_to_disk:\n",
    "        if variant_identifier_label is not None:\n",
    "            active_pf_2D_filename_prefix_string = '-'.join([active_pf_2D_filename_prefix_string, variant_identifier_label])\n",
    "        active_pf_2D_filename_prefix_string = f'{active_pf_2D_filename_prefix_string}-' # it always ends with a '-' character\n",
    "        common_basename = curr_kdiba_pipeline.computation_results[filter_name].computed_data['pf2D'].str_for_filename(prefix_string=active_pf_2D_filename_prefix_string)\n",
    "        active_pf_2D_output_filepath = active_config.plotting_config.get_figure_save_path(common_parent_foldername, common_basename).with_suffix('.png')\n",
    "        with WrappingMessagePrinter('Saving 2D Placefield image out to \"{}\"...'.format(active_pf_2D_output_filepath), begin_line_ending='...', finished_message='done.')\n",
    "            for aFig in active_pf_2D_figures:\n",
    "                aFig.savefig(active_pf_2D_output_filepath)\n",
    "        \n",
    "    return active_pf_2D_figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "476f85d8-8427-4fe0-aacf-478295faa19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_saving_to_disk = True\n",
    "common_parent_foldername = Path(r'R:\\Dropbox (Personal)\\Active\\Kamran Diba Lib\\Pho-Kamran-Meetings\\Final Placemaps 2021-01-13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74c3eb8a-d963-4d60-ab39-721de81a34fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_aspect_ratio: (7.988962073389786, Width_Height_Tuple(width=241.7178791533281, height=30.256480996256016))\n",
      "Pagination is disabled because one of the subplots values is None. Output will be in a single figure/page.\n",
      "page_grid_sizes: [RowColTuple(num_rows=22, num_columns=3)]\n",
      "resolution_multiplier: 1.0, required_figure_size: (24.0, 22.0)\n",
      "page_idx: 0\n",
      "geom: PyQt5.QtCore.QRect(8, 31, 2400, 1868)\n",
      "Saving 2D Placefield image out to \"R:\\Dropbox (Personal)\\Active\\Kamran Diba Lib\\Pho-Kamran-Meetings\\Final Placemaps 2021-01-13\\pf2D-FiringMaps-maze1-speedThresh_15.00-gridBin_3.78_1.04-smooth_1.00_1.00-frateThresh_0.png\"...\t done.\n",
      "data_aspect_ratio: (7.988962073389786, Width_Height_Tuple(width=241.7178791533281, height=30.256480996256016))\n",
      "Pagination is disabled because one of the subplots values is None. Output will be in a single figure/page.\n",
      "page_grid_sizes: [RowColTuple(num_rows=22, num_columns=3)]\n",
      "resolution_multiplier: 1.0, required_figure_size: (24.0, 22.0)\n",
      "page_idx: 0\n",
      "geom: PyQt5.QtCore.QRect(8, 31, 2400, 2234)\n",
      "Saving 2D Placefield image out to \"R:\\Dropbox (Personal)\\Active\\Kamran Diba Lib\\Pho-Kamran-Meetings\\Final Placemaps 2021-01-13\\pf2D-Placefields-maze1-speedThresh_15.00-gridBin_3.78_1.04-smooth_1.00_1.00-frateThresh_0.png\"...\t done.\n"
     ]
    }
   ],
   "source": [
    "filter_name = 'maze1'\n",
    "_display_placemaps_2D(filter_name, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, common_parent_foldername=common_parent_foldername, should_save_to_disk=enable_saving_to_disk);\n",
    "_display_placemaps_2D(filter_name, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, common_parent_foldername=common_parent_foldername, should_save_to_disk=enable_saving_to_disk);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "794ad5c3-328d-41a9-b7c2-2bc6f7aaf2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_name = 'maze2'\n",
    "_display_placemaps_2D(filter_name, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, common_parent_foldername=common_parent_foldername, should_save_to_disk=enable_saving_to_disk);\n",
    "_display_placemaps_2D(filter_name, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, common_parent_foldername=common_parent_foldername, should_save_to_disk=enable_saving_to_disk);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c849eb9-e7c4-476d-b17c-d197d2f80983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_aspect_ratio: (7.988962073389786, Width_Height_Tuple(width=241.7178791533281, height=30.256480996256016))\n",
      "Pagination is disabled because one of the subplots values is None. Output will be in a single figure/page.\n",
      "page_grid_sizes: [RowColTuple(num_rows=22, num_columns=3)]\n",
      "resolution_multiplier: 1.0, required_figure_size: (24.0, 22.0)\n",
      "page_idx: 0\n",
      "geom: PyQt5.QtCore.QRect(8, 31, 2400, 1868)\n",
      "Saving 2D Placefield image out to \"R:\\Dropbox (Personal)\\Active\\Kamran Diba Lib\\Pho-Kamran-Meetings\\Final Placemaps 2021-01-13\\pf2D-FiringMaps-maze-speedThresh_15.00-gridBin_3.78_1.04-smooth_1.00_1.00-frateThresh_0.png\"...\t done.\n",
      "data_aspect_ratio: (7.988962073389786, Width_Height_Tuple(width=241.7178791533281, height=30.256480996256016))\n",
      "Pagination is disabled because one of the subplots values is None. Output will be in a single figure/page.\n",
      "page_grid_sizes: [RowColTuple(num_rows=22, num_columns=3)]\n",
      "resolution_multiplier: 1.0, required_figure_size: (24.0, 22.0)\n",
      "page_idx: 0\n",
      "geom: PyQt5.QtCore.QRect(8, 31, 2400, 1868)\n",
      "Saving 2D Placefield image out to \"R:\\Dropbox (Personal)\\Active\\Kamran Diba Lib\\Pho-Kamran-Meetings\\Final Placemaps 2021-01-13\\pf2D-Placefields-maze-speedThresh_15.00-gridBin_3.78_1.04-smooth_1.00_1.00-frateThresh_0.png\"...\t done.\n"
     ]
    }
   ],
   "source": [
    "filter_name = 'maze'\n",
    "_display_placemaps_2D(filter_name, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, common_parent_foldername=common_parent_foldername, should_save_to_disk=enable_saving_to_disk);\n",
    "_display_placemaps_2D(filter_name, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, common_parent_foldername=common_parent_foldername, should_save_to_disk=enable_saving_to_disk);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e373c4-1fe4-4b7a-ad69-9cccb7153eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_session_computation_config.str_for_display(True)\n",
    "\n",
    "# active_session_computation_config.variable_names\n",
    "\n",
    "# active_session_computation_config.__dict__.items()\n",
    "\n",
    "# :.2f\n",
    "\n",
    "# %precision %.6f\n",
    "\n",
    "# %precision\n",
    "# properties_key_val_list = [f'{name}_{str(val)}' for (name, val) in active_session_computation_config.__dict__.items()]\n",
    "# properties_key_val_list\n",
    "\n",
    "\n",
    "\n",
    "# Default for filename outputs: 'speed_thresh_2.0-grid_bin_[3.777 1.043]-smooth_[1.5 1.5]-frate_thresh_0.1-time_bin_size_0.5'\n",
    "param_sep_char='-'\n",
    "key_val_sep_char='_'\n",
    "\n",
    "# Default for attributes lists outputs:\n",
    "\"\"\" \n",
    "speed_thresh\t2.0\n",
    "grid_bin\t[3.777 1.043]\n",
    "smooth\t[1.5 1.5]\n",
    "frate_thresh\t0.1\n",
    "time_bin_size\t0.5\n",
    "\"\"\"\n",
    "param_sep_char='\\n'\n",
    "key_val_sep_char='\\t'\n",
    "\n",
    "# Default for figure title outputs: 'speed_thresh:2.0, grid_bin:[3.777 1.043], smooth:[1.5 1.5], frate_thresh:0.1, time_bin_size:0.5'\n",
    "param_sep_char=', '\n",
    "key_val_sep_char=':'\n",
    "\n",
    "# def _build_formatted_str_for_output(dict_items, param_sep_char, key_val_sep_char) -> str:\n",
    "#     with np.printoptions(precision=3, suppress=True, threshold=5):\n",
    "#         properties_key_val_list = [f'{name}{key_val_sep_char}{np.array(val)}' for (name, val) in dict_items.items()]\n",
    "#     return param_sep_char.join(properties_key_val_list)\n",
    "\n",
    "# out_str = _build_formatted_str_for_output(active_session_computation_config.__dict__, param_sep_char, key_val_sep_char)\n",
    "# print(out_str)\n",
    "\n",
    "\n",
    "print(active_session_computation_config.str_for_attributes_list_display(key_val_sep_char='\\N{MINUS SIGN}'))\n",
    "\n",
    "\n",
    "    \n",
    "# 3.776841861770752, 1.043326930905373\n",
    "\n",
    "# round(active_session_computation_config.grid_bin, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837df2fd-11c6-4552-9cc8-66c5874ed0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _display_add_computation_param_text_box(plt.gcf(), active_session_computation_config)\n",
    "\n",
    "\n",
    "\n",
    "# figFormatter = FigureFormatter2D()\n",
    "\n",
    "\n",
    "activeFigureMan.get_geometries()\n",
    "# \"\"\"\n",
    "# geom: PyQt5.QtCore.QRect(33, 189, 2359, 1868)\n",
    "# (PyQt5.QtCore.QRect(33, 189, 2359, 1868), (33, 189, 2359, 1868))\n",
    "# \"\"\"\n",
    "# activeFigureMan.set_geometries(height=1868) # Ensure it fits on the screen vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c4ecf-15c2-4197-927f-8f1a63c7ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_custom_data_explorer, 'maze1') # works!\n",
    "curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_tuning_curves_plotter, 'maze1') # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2988fc6a-007d-4145-8258-dc5449ccf8fc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_1d_placefield_validations, 'maze1') # works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c4171-ea23-4f0f-bcc0-a7ab3544dfbe",
   "metadata": {},
   "source": [
    "## Position Decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37445b3-c614-4b68-b6ab-ee7a26c29af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stock Decoder:\n",
    "from neuropy.analyses.decoders import Decode1d\n",
    "\n",
    "curr_result_label = 'maze1'\n",
    "sess = curr_kdiba_pipeline.filtered_sessions[curr_result_label]\n",
    "pf = curr_kdiba_pipeline.computation_results[curr_result_label].computed_data['pf1D']\n",
    "\n",
    "def stock_1d_decoder(sess, pf, curr_result_label):\n",
    "    maze1 = sess.paradigm[curr_result_label]\n",
    "    # rpls = sess.ripple.time_slice(maze1[0], maze1[1])\n",
    "    rpls = None\n",
    "    pf_neurons = sess.neurons.get_by_id(pf.ratemap.neuron_ids) \n",
    "    decode = Decode1d(neurons=pf_neurons, ratemap = pf.ratemap, epochs=rpls, bin_size=0.02)\n",
    "    return decode\n",
    "    \n",
    "def validate_stock_1d_decoder(sess, decode):\n",
    "    # Plot to validate decoder:\n",
    "    np.shape(decode.decoded_position) # (85845,)\n",
    "    plt.plot(decode.decoded_position)\n",
    "    ax = plt.gca()\n",
    "    # ax.xlim() # (-4292.2, 90136.2)\n",
    "    ax.set_xlim(10000, 12000)\n",
    "\n",
    "np.shape(decode.posterior) # (48, 85845)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be4111c-585c-4797-b028-245f80d1b2e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Zhang Velocity/Position For 2-step Bayesian Decoder:\n",
    "from neuropy.analyses.placefields import PfND\n",
    "from pyphoplacecellanalysis.General.Decoder.decoder_result import build_position_df_discretized_binned_positions\n",
    "\n",
    "##TODO: compute the average speed at each position x:\n",
    "active_sess = curr_kdiba_pipeline.filtered_sessions['maze1']\n",
    "active_position_df = active_sess.position.to_dataframe()\n",
    "active_computation_config = curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D'].config\n",
    "\n",
    "\n",
    "def _compute_avg_speed_at_each_position_bin(active_position_df, active_computation_config, show_plots=False, debug_print=False):\n",
    "    \"\"\" compute the average speed at each position x: \"\"\"\n",
    "    ## Non-working attempt to use edges instead of bins:\n",
    "    # xbin_edges = xbin + [(xbin[-1] + (xbin[1] - xbin[0]))] # add an additional (right) edge to the end of the xbin array for use with pd.cut\n",
    "    # ybin_edges = ybin + [(ybin[-1] + (ybin[1] - ybin[0]))] # add an additional (right) edge to the end of the ybin array for use with pd.cut\n",
    "    # print(f'xbin_edges: {np.shape(xbin_edges)}\\n ybin_edges: {np.shape(ybin_edges)}, np.shape(np.arange(len(xbin_edges))): {np.shape(np.arange(len(xbin_edges)))}')\n",
    "    # active_position_df['binned_x'] = pd.cut(active_position_df['x'].to_numpy(), bins=xbin_edges, include_lowest=True, labels=np.arange(start=1, stop=len(xbin_edges))) # same shape as the input data \n",
    "    # active_position_df['binned_y'] = pd.cut(active_position_df['y'].to_numpy(), bins=ybin_edges, include_lowest=True, labels=np.arange(start=1, stop=len(ybin_edges))) # same shape as the input data \n",
    "\n",
    "    def _compute_group_stats_for_var(active_position_df, variable_name:str = 'speed'):\n",
    "        # For each unique binned_x and binned_y value, what is the average velocity_x at that point?\n",
    "        position_bin_dependent_specific_average_velocities = active_position_df.groupby(['binned_x','binned_y'])[variable_name].agg([np.nansum, np.nanmean, np.nanmin, np.nanmax]).reset_index() #.apply(lambda g: g.mean(skipna=True)) #.agg((lambda x: x.mean(skipna=False)))\n",
    "        # position_bin_dependent_specific_average_velocities # 1856 rows\n",
    "        output = np.zeros((len(xbin), len(ybin))) # (65, 30)\n",
    "        # np.shape(output)\n",
    "        output[position_bin_dependent_specific_average_velocities['binned_x'].to_numpy()-1, position_bin_dependent_specific_average_velocities['binned_y'].to_numpy()-1] = position_bin_dependent_specific_average_velocities['nanmean'].to_numpy() # ValueError: shape mismatch: value array of shape (1856,) could not be broadcast to indexing result of shape (1856,2,30)\n",
    "        return output\n",
    "\n",
    "    outputs = dict()\n",
    "    outputs['speed'] = _compute_group_stats_for_var(active_position_df, 'speed')\n",
    "    if show_plots:\n",
    "        plt.figure(num=8)\n",
    "        plt.imshow(outputs['speed'])\n",
    "        plt.title('speed')\n",
    "\n",
    "    outputs['velocity_x'] = _compute_group_stats_for_var(active_position_df, 'velocity_x')\n",
    "    if show_plots:\n",
    "        plt.figure(num=9)\n",
    "        plt.imshow(outputs['velocity_x'])\n",
    "        plt.title('velocity_x')\n",
    "\n",
    "    outputs['acceleration_x'] = _compute_group_stats_for_var(active_position_df, 'acceleration_x')\n",
    "    if show_plots:\n",
    "        plt.figure(num=10)\n",
    "        plt.imshow(outputs['acceleration_x'])\n",
    "        plt.title('acceleration_x')\n",
    "\n",
    "    return outputs['speed']\n",
    "\n",
    "\n",
    "active_sess.position.df = build_position_df_discretized_binned_positions(active_sess.position.df, active_computation_config, debug_print=False) # update the session's position dataframe with the new columns.\n",
    "avg_speed_per_pos = _compute_avg_speed_at_each_position_bin(active_sess.position.to_dataframe(), active_computation_config)\n",
    "avg_speed_per_pos\n",
    "\n",
    "# non_empty_position_bin_dependent_specific_average_velocities = position_bin_dependent_specific_average_velocities[position_bin_dependent_specific_average_velocities['nansum'].to_numpy() > 0.001]\n",
    "# non_empty_position_bin_dependent_specific_average_velocities # 790 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7a38f-674f-4a4f-beac-269e1630c65a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_speed_per_pos # called U_x in the paper.\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "class Zhang_Two_Step:\n",
    "    @classfunc\n",
    "    def sigma_t(cls, v_t, K, V, d:float=1.0):\n",
    "        \"\"\" The standard deviation of the Gaussian prior for position. Once computed and normalized, can be used such that it only requires the current position (x_t) to return the correct std_dev at a given timestamp.\n",
    "        K, V are constants\n",
    "        d is 0.5 for random walks and 1.0 for linear movements. \n",
    "        \"\"\"\n",
    "        return K * np.power((v_t / V), d)\n",
    "    \n",
    "    @classfunc\n",
    "    def compute_conditional_probability_x_prev_given_x_t(cls, C, x_prev, t):\n",
    "        \"\"\" Should return a value for all possible current locations x_t. x_prev should be a concrete position, not a matrix of them. \"\"\"\n",
    "        # multivariate_normal.pdf()\n",
    "        \n",
    "        return C * np.exp(-np.square(np.norm(x - x_prev))/(2.0*np.square(sigma_t)))\n",
    "        \n",
    "        # output = multivariate_normal.pdf()\n",
    "        \n",
    "    @classfunc\n",
    "    def compute_bayesian_two_step_prob_single_timestep(cls, one_step_p_x_given_n, t, x_prev, C, k):\n",
    "        return k * one_step_p_x_given_n * cls.compute_conditional_probability_x_prev_given_x_t(C, x_prev, t)\n",
    "    \n",
    "\n",
    "def v_t(window_t):\n",
    "    # get position during that window step\n",
    "    \n",
    "    # use that position x_t to get the velocity during this window.\n",
    "    \n",
    "\n",
    "# .apply(lambda g: g.mean(skipna=False))\n",
    "# # --- occupancy map calculation -----------\n",
    "# if (position.ndim > 1):\n",
    "#     occupancy, xedges, yedges = Pf2D._compute_occupancy(self.x, self.y, xbin, ybin, self.position_srate, smooth)\n",
    "# else:\n",
    "#     occupancy, xedges = Pf1D._compute_occupancy(self.x, xbin, self.position_srate, smooth[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c545afc1-63d6-4f45-a186-5acae5b2dab3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- % $$\\int_{a}^b f(x)dx$$ -->\n",
    "<!-- Euler's identity: $ e^{i \\pi} + 1 = 0 $ -->\n",
    "\n",
    "## One-step Bayesian Decoder:\n",
    "$$P(\\overrightarrow{x}_{t}|\\overrightarrow{n}_{t})$$\n",
    "\n",
    "$$P(\\overrightarrow{n}|\\overrightarrow{x})$$ : probability for the numbers of spikes $\\overrightarrow{n}$ to occur given we know the animal is at location $\\overrightarrow{x}$\n",
    "\n",
    "## Two-step Bayesian Decoder:\n",
    "$$P(\\overrightarrow{x}_{t}|\\overrightarrow{n}_{t}, \\overrightarrow{x}_{t-1}) = k P(\\overrightarrow{x}_{t}|\\overrightarrow{n}_{t}) P(\\overrightarrow{x}_{t-1}|\\overrightarrow{x}_{t})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff8ed9-3363-48a8-ae20-a1a51443aec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_plot_most_likely_position_comparisons, 'maze1') # works!\n",
    "\n",
    "# fig, axs = plot_most_likely_position_comparsions(pho_custom_decoder, sess.position.to_dataframe())\n",
    "\n",
    "\n",
    "# axs[0].set_xlim(500, 550)\n",
    "# plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7357706-f14c-413b-9020-496db9ed63cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Position Dataframe Binning in Time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae0262-15cd-47e0-9202-d1b836cb5d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.align_util import align_data\n",
    "from pyphoplacecellanalysis.General.Decoder.decoder_result import build_position_df_resampled_to_time_windows, build_position_df_time_window_idx\n",
    "\n",
    "active_pos_df = build_position_df_resampled_to_time_windows(curr_kdiba_pipeline.filtered_sessions['maze1'].position.to_dataframe(), time_bin_size=active_session_computation_config.time_bin_size)\n",
    "\n",
    "def add_timedelta_column_to_pos_df(active_pos_df):\n",
    "    position_time_delta = pd.to_timedelta(active_pos_df[active_pos_df.position.time_variable_name], unit=\"sec\")\n",
    "    active_pos_df['time_delta_sec'] = position_time_delta\n",
    "    return active_pos_df\n",
    "\n",
    "# Update the position dataframe with a time_delta column\n",
    "curr_kdiba_pipeline.filtered_sessions['maze1'].position.df = add_timedelta_column_to_pos_df(curr_kdiba_pipeline.filtered_sessions['maze1'].position.df)\n",
    "\n",
    "active_pos_df = curr_kdiba_pipeline.filtered_sessions['maze1'].position.df.copy() # don't change the index of the actual position df, make a copy\n",
    "active_pos_df = active_pos_df.set_index('time_delta_sec')\n",
    "\n",
    "active_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e39c8-6842-4ac4-8711-3fff06436690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aligned_active_pos_df = active_pos_df.copy()\n",
    "\n",
    "time_window_edges_time_delta = pd.to_timedelta(pho_custom_decoder.time_window_edges, unit=\"sec\") # convert the windows to timedeltas as well to allow efficient comparison\n",
    "time_window_edges_time_delta\n",
    "# aligned_active_pos_df.between_time\n",
    "\n",
    "# aligned_active_pos_df.at_time(pho_custom_decoder.time_window_edges)\n",
    "\n",
    "# pho_custom_decoder.time_window_edges\n",
    "# aligned_active_pos_df.align(time_window_edges_time_delta, fill_value=np.nan)\n",
    "\n",
    "# build_position_df_time_window_idx(active_pos_df, pho_custom_decoder.active_time_window_centers)\n",
    "\n",
    "# pho_custom_decoder.active_time_window_centers\n",
    "# pho_custom_decoder.time_window_edges\n",
    "\n",
    "# s21, s22 = ts_2.align(ts_1, fill_value=0)\n",
    "\n",
    "# active_sess.position.df\n",
    "# aligned_active_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d0c686-f861-4f42-9897-d4344ed691c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pho_custom_decoder = curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D_Decoder']\n",
    "enable_plots = True\n",
    "\n",
    "print(f'most_likely_positions: {np.shape(pho_custom_decoder.most_likely_positions)}') # most_likely_positions: (3434, 2)\n",
    "\n",
    "\n",
    "def spike_count_and_firing_rate_normalizations(pho_custom_decoder, enable_plots=True):\n",
    "    \"\"\" Computes several different normalizations of binned firing rate and spike counts, optionally plotting them. \n",
    "    \n",
    "    Usage:\n",
    "        pho_custom_decoder = curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D_Decoder']\n",
    "        enable_plots = True\n",
    "        unit_specific_time_binned_outputs = spike_count_and_firing_rate_normalizations(pho_custom_decoder, enable_plots=enable_plots)\n",
    "        spike_proportion_global_fr_normalized, firing_rate, firing_rate_global_fr_normalized = unit_specific_time_binned_outputs # unwrap the output tuple:\n",
    "    \"\"\"\n",
    "    # produces a fraction which indicates which proportion of the window's firing belonged to each unit (accounts for global changes in firing rate (each window is scaled by the toial spikes of all cells in that window)\n",
    "    unit_specific_time_binned_spike_proportion_global_fr_normalized = pho_custom_decoder.unit_specific_time_binned_spike_counts / pho_custom_decoder.total_spike_counts_per_window\n",
    "    if enable_plots:\n",
    "        plt.figure(num=5)\n",
    "        plt.imshow(unit_specific_time_binned_spike_proportion_global_fr_normalized, cmap='turbo', aspect='auto')\n",
    "        plt.title('Unit Specific Proportion of Window Spikes')\n",
    "        plt.xlabel('Binned Time Window')\n",
    "        plt.ylabel('Neuron Proportion Activity')\n",
    "\n",
    "    # print(pho_custom_decoder.time_window_edges_binning_info.step)\n",
    "    # print(f'pho_custom_decoder: {pho_custom_decoder}')\n",
    "    # np.shape(pho_custom_decoder.F) # (1856, 64)\n",
    "\n",
    "    unit_specific_time_binned_firing_rate = pho_custom_decoder.unit_specific_time_binned_spike_counts / pho_custom_decoder.time_window_edges_binning_info.step\n",
    "    # print(unit_specific_time_binned_firing_rate)\n",
    "    if enable_plots:\n",
    "        plt.figure(num=6)\n",
    "        plt.imshow(unit_specific_time_binned_firing_rate, cmap='turbo', aspect='auto')\n",
    "        plt.title('Unit Specific Binned Firing Rates')\n",
    "        plt.xlabel('Binned Time Window')\n",
    "        plt.ylabel('Neuron Firing Rate')\n",
    "\n",
    "\n",
    "    # produces a unit firing rate for each window that accounts for global changes in firing rate (each window is scaled by the firing rate of all cells in that window\n",
    "    unit_specific_time_binned_firing_rate_global_fr_normalized = unit_specific_time_binned_spike_proportion_global_fr_normalized / pho_custom_decoder.time_window_edges_binning_info.step\n",
    "    if enable_plots:\n",
    "        plt.figure(num=7)\n",
    "        plt.imshow(unit_specific_time_binned_firing_rate_global_fr_normalized, cmap='turbo', aspect='auto')\n",
    "        plt.title('Unit Specific Binned Firing Rates (Global Normalized)')\n",
    "        plt.xlabel('Binned Time Window')\n",
    "        plt.ylabel('Neuron Proportion Firing Rate')\n",
    "\n",
    "    # Return the computed values, leaving the original data unchanged.\n",
    "    return unit_specific_time_binned_spike_proportion_global_fr_normalized, unit_specific_time_binned_firing_rate, unit_specific_time_binned_firing_rate_global_fr_normalized\n",
    "\n",
    "\n",
    "    unit_specific_time_binned_outputs = spike_count_and_firing_rate_normalizations(pho_custom_decoder, enable_plots=enable_plots)\n",
    "    spike_proportion_global_fr_normalized, firing_rate, firing_rate_global_fr_normalized = unit_specific_time_binned_outputs # unwrap the output tuple:\n",
    "\n",
    "    # pho_custom_decoder.unit_specific_time_binned_spike_counts\n",
    "    # pho_custom_decoder.time_window_edges\n",
    "    # pho_custom_decoder.time_window_edges_binning_info\n",
    "    # pho_custom_decoder.total_spike_counts_per_window\n",
    "    # curr_kdiba_pipeline.pf.xbin\n",
    "\n",
    "\n",
    "    # active_pos_df = curr_kdiba_pipeline.filtered_sessions['maze1'].position.to_dataframe()\n",
    "    # time_window_edges, time_window_edges_binning_info = compute_spanning_bins(active_pos_df['x'].to_numpy(), bin_size=max_time_bin_size) # np.shape(out_digitized_variable_bins)[0] == np.shape(spikes_df)[0]\n",
    "    # assert np.shape(time_window_edges)[0] < np.shape(spikes_df)[0], f'spikes_df[time_variable_name]: {np.shape(spikes_df[time_variable_name])} should be less than time_window_edges: {np.shape(time_window_edges)}!'\n",
    "\n",
    "    active_sess.position.df\n",
    "\n",
    "    # active_aligned_pos_df = align_data(pho_custom_decoder.active_time_window_centers, active_pos_df['t'].to_numpy(), active_pos_df[['x','y']].to_numpy())\n",
    "    # active_aligned_pos_df = align_data(pho_custom_decoder.active_time_window_centers, active_pos_df.index, active_pos_df['x'])\n",
    "    # active_aligned_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fa335-d725-41ba-a8cd-2921eb85de71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.General.Decoder.decoder_result import DecoderResultDisplayingPlot2D\n",
    "# def _display_decoder_result():\n",
    "#     renderer = DecoderResultDisplayingPlot2D(pho_custom_decoder, active_pos_df)\n",
    "#     def animate(i):\n",
    "#         # print(f'animate({i})')\n",
    "#         return renderer.display(i)\n",
    "#     interact(animate, i=(0, pho_custom_decoder.num_time_windows, 10))\n",
    "\n",
    "curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_decoder_result, 'maze1') # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b6e96-0231-4829-a895-bfd14249b4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @pn.interact(i=(0,pho_custom_decoder.num_time_windows,1,0))\n",
    "# @interact(i=pn.widgets.IntSlider(start=0,end=pho_custom_decoder.num_time_windows,step=1,value=0))\n",
    "\n",
    "# ani = FuncAnimation(renderer.fig, animate, interval=300)\n",
    "# interact(animate, i=(0, pho_custom_decoder.num_time_windows, 10))\n",
    "\n",
    "# pn.Column('**A custom interact layout**', pn.Row(layout[0], layout[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96637cdd-8aa7-4a83-9bab-eedcb5363dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_plot_filtered_subsession_neuron_differences(sess, filtered_sess):\n",
    "    print_subsession_neuron_differences(sess.neurons, active_epoch_session.neurons)\n",
    "\n",
    "[debug_plot_filtered_subsession_neuron_differences(curr_kdiba_pipeline.sess, a_filtered_sess) for a_filtered_sess in curr_kdiba_pipeline.filtered_sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c981e-7259-4a8e-acfd-5d9146e6b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_kdiba_pipeline.computation_results['maze2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cace13-54be-40a7-bb8c-05d6bb25ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_result(curr_kdiba_pipeline.computation_results['maze1'])\n",
    "_display_result(curr_kdiba_pipeline.computation_results['maze2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75820aec-6942-4a38-adc0-4f6da16212d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58555225-e9c9-45b2-afb5-d303cabb9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from neuropy.utils.misc import is_iterable\n",
    "from neuropy.plotting.figure import pretty_plot\n",
    "from scipy.ndimage import gaussian_filter, gaussian_filter1d, interpolation\n",
    "\n",
    "from pyphoplacecellanalysis.Analysis.reliability import compute_lap_to_lap_reliability\n",
    "\n",
    "from PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "\n",
    "\n",
    "def _test_plotRaw_v_time(active_pf, cellind, speed_thresh=False, alpha=0.5, ax=None):\n",
    "        \"\"\" Builds one subplot for each dimension of the position data\n",
    "        \n",
    "        Updated to work with both 1D and 2D Placefields \"\"\"   \n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(active_pf.ndim, 1, sharex=True)\n",
    "            fig.set_size_inches([23, 9.7])\n",
    "        \n",
    "        if not is_iterable(ax):\n",
    "            ax = [ax]\n",
    "            \n",
    "        # plot trajectories\n",
    "        if active_pf.ndim < 2:\n",
    "            variable_array = [active_pf.x]\n",
    "            label_array = [\"X position (cm)\"]\n",
    "        else:\n",
    "            variable_array = [active_pf.x, active_pf.y]\n",
    "            label_array = [\"X position (cm)\", \"Y position (cm)\"]\n",
    "            \n",
    "        for a, pos, ylabel in zip(ax, variable_array, label_array):\n",
    "            a.plot(active_pf.t, pos)\n",
    "            a.set_xlabel(\"Time (seconds)\")\n",
    "            a.set_ylabel(ylabel)\n",
    "            pretty_plot(a)\n",
    "\n",
    "        # Grab correct spike times/positions\n",
    "        if speed_thresh:\n",
    "            spk_pos_, spk_t_ = active_pf.run_spk_pos, active_pf.run_spk_t\n",
    "        else:\n",
    "            spk_pos_, spk_t_ = active_pf.spk_pos, active_pf.spk_t\n",
    "\n",
    "        # plot spikes on trajectory\n",
    "        for a, pos in zip(ax, spk_pos_[cellind]):\n",
    "            a.plot(spk_t_[cellind], pos, \".\", color=[0, 0, 0.8, alpha])\n",
    "\n",
    "        # Put info on title\n",
    "        ax[0].set_title(\n",
    "            \"Cell \"\n",
    "            + str(active_pf.cell_ids[cellind])\n",
    "            + \":, speed_thresh=\"\n",
    "            + str(active_pf.speed_thresh)\n",
    "        )\n",
    "        return ax\n",
    "\n",
    "\n",
    "def compute_reliability_metrics(out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap, debug_print=False, plot_results=False):\n",
    "    \"\"\" Takes input from compute_lap_to_lap_reliability(...) to build the actual reliability metrics \"\"\"\n",
    "    # Actual Computations of Reliability:\n",
    "    out_pairwise_pair_results = np.zeros_like(out_within_lap_spikes_overlap)\n",
    "    \n",
    "    # do simple diff:\n",
    "    laps_spikes_overlap_diff = np.diff(out_within_lap_spikes_overlap, axis=1) # the element-wise diff of the overlap. Shows changes.\n",
    "    out_pairwise_pair_results[:, 1:] = laps_spikes_overlap_diff\n",
    "    # out_pairwise_pair_results[:, -1] = np.zeros_like(out_within_lap_spikes_overlap[:,0])\n",
    "    \n",
    "    # do custom pairwise operation:\n",
    "#     for first_item_lap_idx, next_item_lap_idx in list(out_pairwise_flat_lap_indicies):\n",
    "#         first_item = out_within_lap_spikes_overlap[:, first_item_lap_idx]\n",
    "#         next_item = out_within_lap_spikes_overlap[:, next_item_lap_idx]\n",
    "#         out_pairwise_pair_results[:, next_item_lap_idx] = (first_item * next_item) # the result should be stored in the index of the second item, if we're doing the typical backwards style differences.\n",
    "#         # print(f'np.max(out_pairwise_pair_results[:, next_item_lap_idx]): {np.max(out_pairwise_pair_results[:, next_item_lap_idx])}')\n",
    "\n",
    "    if debug_print: \n",
    "        print(f'max out: {np.max(out_pairwise_pair_results)}')\n",
    "        \n",
    "    lap_ids \n",
    "    flat_lap_idxs = np.arange(len(lap_ids))\n",
    "    \n",
    "    \n",
    "    # add to the extant plot as a new color:\n",
    "    if plot_results:\n",
    "        for lap_idx, lap_ID in zip(flat_lap_idxs, lap_ids):\n",
    "            # curr_lap_alt_ax = axs[lap_idx]\n",
    "            if plot_horizontal:\n",
    "                curr_lap_alt_ax = axs[lap_idx].twiny()\n",
    "                curr_lap_alt_ax.plot(out_pairwise_pair_results[:, lap_idx], out_digitized_position_bins, '--r')\n",
    "            else:\n",
    "                # vertical\n",
    "                curr_lap_alt_ax = axs[lap_idx].twinx()\n",
    "                curr_lap_alt_ax.plot(out_digitized_position_bins, out_pairwise_pair_results[:, lap_idx], '--r')\n",
    "            \n",
    "    cum_laps_reliability = np.cumprod(out_within_lap_spikes_overlap, axis=1)\n",
    "    all_laps_reliability = np.prod(out_within_lap_spikes_overlap, axis=1, keepdims=True)\n",
    "    \n",
    "    if plot_results:\n",
    "        fig_result, axs_result = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(24, 40))\n",
    "        axs_result[0].plot(out_digitized_position_bins, all_laps_reliability, 'r')\n",
    "        axs_result[1].plot(out_digitized_position_bins, cum_laps_reliability, 'r')\n",
    "\n",
    "curr_result_label = 'maze1'\n",
    "sess = curr_kdiba_pipeline.filtered_sessions[curr_result_label]\n",
    "sess = curr_kdiba_pipeline.sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340e1ae-1165-4a55-b35a-73de562df226",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_laps_df = sess.laps.to_dataframe()\n",
    "curr_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00bc5e4-11cc-456f-994e-d4ae3ece2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "position_obj = sess.position\n",
    "position_obj.compute_higher_order_derivatives()\n",
    "pos_df = position_obj.compute_smoothed_position_info(N=20) ## Smooth the velocity curve to apply meaningful logic to it\n",
    "pos_df = position_obj.to_dataframe()\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58644ddd-6efe-40b7-a9c5-5971a1bc1bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, out_axes_list = plot_laps_2d(sess, legacy_plotting_mode=True)\n",
    "fig, out_axes_list = plot_laps_2d(sess, legacy_plotting_mode=False)\n",
    "out_axes_list[0].set_title('New Pho Position Thresholding Estimated Laps')\n",
    "\n",
    "curr_cell_idx = 2 \n",
    "# curr_cell_idx = 3 # good for end platform analysis\n",
    "curr_cell_ID = sess.spikes_df.spikes.neuron_ids[curr_cell_idx]\n",
    "print(f'curr_cell_idx: {curr_cell_idx}, curr_cell_ID: {curr_cell_ID}')\n",
    "\n",
    "# pre-filter by spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "filtered_spikes_df = sess.spikes_df.copy()\n",
    "time_variable_name = filtered_spikes_df.spikes.time_variable_name # 't_rel_seconds'\n",
    "\n",
    "lap_ids = sess.laps.lap_id\n",
    "# lap_flat_idxs = sess.laps.get_lap_flat_indicies(lap_ids)\n",
    "\n",
    "out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap = compute_lap_to_lap_reliability(curr_kdiba_pipeline.computation_results[curr_result_label].computed_data['pf2D'], filtered_spikes_df, lap_ids, curr_cell_idx, debug_print=False, plot_results=True);\n",
    "\n",
    "# compute_reliability_metrics(out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap, debug_print=False, plot_results=False)\n",
    "\n",
    "# # curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D'].plotRaw_v_time(curr_cell_idx)\n",
    "# _test_plotRaw_v_time(curr_kdiba_pipeline.computation_results[curr_result_label].computed_data['pf2D'], curr_cell_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e8e317-9b3c-4895-ac55-13600e8ccc47",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3D Lap Plotting Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752016f-67d4-4351-a61d-defc8a1bff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice # for Pagination class\n",
    "import pyvista as pv\n",
    "import pyvistaqt as pvqt\n",
    "from PhoGui.InteractivePlotter.LapsVisualizationMixin import LapsVisualizationMixin\n",
    "from PhoGui.PhoCustomVtkWidgets import PhoWidgetHelper\n",
    "from PhoPositionalData.plotting.spikeAndPositions import perform_plot_flat_arena, _build_flat_arena_data\n",
    "\n",
    "\"\"\" Test Drawing Spike Lines \"\"\"\n",
    "# from pyphoplacecellanalysis.Pho3D.spikes import draw_line_spike, lines_from_points\n",
    "from pyphoplacecellanalysis.Pho3D.points import interlieve_points\n",
    "\n",
    "from PhoPositionalData.plotting.spikeAndPositions import build_active_spikes_plot_pointdata_df\n",
    "\n",
    "def _plot_all_lap_spikes(p, sess, included_cell_IDXs, included_lap_IDXs, debug_print=True, lap_start_z=0.0, lap_id_dependent_z_offset=10.0):\n",
    "    should_reinterpolate_spike_positions = False\n",
    "        \n",
    "    def _plot_single_spikes(p, cell_specific_spikes_dfs, placefield_cell_index):\n",
    "        curr_cell_spike_df = cell_specific_spikes_dfs[placefield_cell_index]\n",
    "        # curr_cell_spike_df['z_fixed'] = np.full_like(active_flat_df['x'].values, 1.1)\n",
    "        pdata = build_active_spikes_plot_pointdata_df(curr_cell_spike_df)\n",
    "\n",
    "        # curr_cell_spike_times = curr_cell_spike_df[curr_cell_spike_df.spikes.time_variable_name].to_numpy()  # (271,)\n",
    "        # curr_cell_spike_positions = curr_cell_spike_df['x','y'].to_numpy()  # (271,)\n",
    "\n",
    "        # lines_from_points(\n",
    "        # p[0,0].add_points(pdata, name='plot_single_spikes_points', render_points_as_spheres=True, point_size=5.0)\n",
    "\n",
    "        # Build offset points and spike data:\n",
    "        spike_height = max((lap_id_dependent_z_offset * 0.6), 0.5) # half the line height\n",
    "\n",
    "        # start_points = pdata.points.copy()\n",
    "        # end_points = start_points.copy()\n",
    "        # # end_points[:,2] # get z values\n",
    "        # end_points[:,2] = end_points[:,2] + spike_height\n",
    "        # all_points = interlieve_points(start_points, end_points)\n",
    "        # lines_poly_data = pv.PolyData()\n",
    "        # lines_poly_data.points = all_points\n",
    "        # # cells = np.hstack(([2, 0, 1],[2, 1, 2]))\n",
    "        # num_lines = np.shape(start_points)[0]\n",
    "        # cells = [[2, 2*i, 2*i+1] for i in np.arange(num_lines)]\n",
    "        # lines_poly_data.lines = cells\n",
    "        \n",
    "        p[0,0].add_mesh(pdata, name=f'plot_single_spikes_points[{placefield_cell_index}]', render_points_as_spheres=True, point_size=5.0, color='white')        \n",
    "        \n",
    "        # p[0,0].add_points(pdata, name=f'plot_single_spikes_points[{placefield_cell_index}]', render_points_as_spheres=True, point_size=5.0)\n",
    "        # p[0,0].add_mesh(lines_poly_data, name=f'plot_single_spikes_lines[{placefield_cell_index}]', render_points_as_spheres=False, point_size=5.0)\n",
    "        # return {'pdata':pdata, 'lines_poly_data':lines_poly_data}\n",
    "        \n",
    "        return {'pdata':pdata}\n",
    "    \n",
    "    time_variable_name = sess.spikes_df.spikes.time_variable_name # 't_rel_seconds'\n",
    "    # sets the 'z_fixed' value for all spikes in sess.spikes_df, which will be used to plot them as points\n",
    "    sess.spikes_df['z'] = lap_start_z + (lap_id_dependent_z_offset * sess.spikes_df.lap.to_numpy())\n",
    "\n",
    "    if debug_print:\n",
    "        print(f'sess.laps.lap_id: {sess.laps.lap_id}')\n",
    "        \n",
    "    included_cell_IDXs = np.array(included_cell_IDXs)\n",
    "    included_lap_IDXs = np.array(included_lap_IDXs)\n",
    "    \n",
    "    # ensure that only lap_ids included in this session are used:\n",
    "    included_lap_ids = sess.laps.lap_id[included_lap_IDXs]\n",
    "    possible_included_lap_ids = np.unique(sess.spikes_df.lap.values)\n",
    "    if debug_print:\n",
    "        print(f'np.unique(sess.spikes_df.lap.values): {np.unique(sess.spikes_df.lap.values)}')\n",
    "    included_lap_ids = included_lap_ids[np.isin(included_lap_ids, possible_included_lap_ids)]\n",
    "    if debug_print:\n",
    "        print(f'included_lap_ids: {included_lap_ids}')\n",
    "    \n",
    "    # get the included cell IDs\n",
    "    included_cell_IDs = np.array(sess.spikes_df.spikes.neuron_ids)[included_cell_IDXs]\n",
    "        \n",
    "    # print(np.isin(['R','G','B','render_opacity'], sess.spikes_df.columns).all())\n",
    "\n",
    "    # POSITIONS:\n",
    "    curr_position_df, lap_specific_position_dfs, lap_specific_time_ranges, lap_specific_position_traces = LapsVisualizationMixin._compute_laps_position_data(sess)\n",
    "    \n",
    "    # SPIKES:\n",
    "    # # grouped by lap\n",
    "    # lap_grouped_spikes_df = sess.spikes_df.groupby('lap')\n",
    "    # lap_specific_spikes_dfs = [lap_grouped_spikes_df.get_group(i)[[time_variable_name,'aclu','lap','flat_spike_idx','cell_type','x','y','lin_pos','z']] for i in included_lap_ids] # dataframes split for each ID:\n",
    "\n",
    "    # grouped by cell:\n",
    "    # pre-filter by spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "    filtered_spikes_df = sess.spikes_df.copy()\n",
    "    filtered_spikes_df = filtered_spikes_df[np.isin(filtered_spikes_df['lap'], included_lap_ids)] # get only the spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "    \n",
    "    \n",
    "    # Interpolate the spikes positions again:\n",
    "    if should_reinterpolate_spike_positions:\n",
    "        print('Re-interpolating spike positions...')\n",
    "        filtered_spikes_df = filtered_spikes_df.spikes.interpolate_spike_positions(curr_position_df['t'].to_numpy(), curr_position_df['x'].to_numpy(), curr_position_df['y'].to_numpy())\n",
    "        # filtered_spikes_df = FlattenedSpiketrains.interpolate_spike_positions(filtered_spikes_df, session.position.time, session.position.x, session.position.y, spike_timestamp_column_name=time_variable_name)\n",
    "    \n",
    "    cell_grouped_spikes_df = filtered_spikes_df.groupby('aclu')\n",
    "    cell_specific_spikes_dfs = [cell_grouped_spikes_df.get_group(i)[[time_variable_name,'aclu','lap','flat_spike_idx','cell_type','x','y','lin_pos','z']] for i in included_cell_IDs] # dataframes split for each ID:\n",
    "\n",
    "    # lap_specific_position_dfs = _compute_laps_position_data(sess)\n",
    "\n",
    "    # # Positions:\n",
    "    # curr_position_df = sess.compute_position_laps()\n",
    "    # included_pos_lap_ids = np.unique(curr_position_df.lap.values)\n",
    "    # print(f'np.unique(curr_position_df.lap.values): {np.unique(curr_position_df.lap.values)}')\n",
    "    # included_pos_lap_ids = included_pos_lap_ids[np.isin(included_pos_lap_ids, sess.laps.lap_id)]\n",
    "    # included_pos_lap_ids\n",
    "\n",
    "    # print(f'included_pos_lap_ids: {included_pos_lap_ids}')\n",
    "\n",
    "    # lap_grouped_position_df = curr_position_df.groupby('lap')\n",
    "    # lap_specific_position_dfs = [lap_grouped_position_df.get_group(i)[['t','aclu','x','y','lin_pos']] for i in included_lap_ids] # dataframes split for each ID:\n",
    "\n",
    "    for i, curr_cell_ID in enumerate(included_cell_IDs):\n",
    "        plot_data_dict = _plot_single_spikes(p, cell_specific_spikes_dfs, i)\n",
    "\n",
    "\n",
    "# sess = curr_kdiba_pipeline.filtered_sessions['maze']\n",
    "# included_cell_IDXs = [6]\n",
    "# included_lap_IDXs = [2, 3]\n",
    "# _plot_all_lap_spikes(pActiveInteractiveLapsPlotter, sess, included_cell_IDXs, included_lap_IDXs)\n",
    "\n",
    "from PhoGui.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer\n",
    "\n",
    "lap_start_z = 0.0\n",
    "# lap_id_dependent_z_offset = 0.0\n",
    "lap_id_dependent_z_offset = 3.0\n",
    "# curr_kdiba_pipeline.active_configs['maze1'].lap_id_dependent_z_offset = 3.0\n",
    "\n",
    "def _display_testing(sess, computation_result, active_config, extant_plotter=None):\n",
    "    \"\"\" Testing of plot_lap_trajectories_2d \"\"\"\n",
    "    print(f'active_config.plotting_config: {active_config.plotting_config}')\n",
    "    single_combined_plot=True\n",
    "    if single_combined_plot:\n",
    "        default_plotting = True\n",
    "    else:\n",
    "        default_plotting = False\n",
    "    active_config.plotting_config.plotter_type = 'MultiPlotter'\n",
    "    print(f'active_config.plotting_config: {active_config.plotting_config}')\n",
    "    iplapsDataExplorer = InteractiveCustomDataExplorer(active_config, sess, extant_plotter=extant_plotter)\n",
    "    pActiveInteractiveLapsPlotter = iplapsDataExplorer.plot(pActivePlotter=extant_plotter, default_plotting=default_plotting)\n",
    "    # included_cell_idxs = None\n",
    "    included_cell_idxs = [0, 1]\n",
    "    # included_lap_idxs = [2, 5, 9, 12]\n",
    "    included_lap_idxs = [2]\n",
    "    # All\n",
    "    # included_cell_idxs = np.arange(len(sess.spikes_df.spikes.neuron_ids))\n",
    "    # included_lap_idxs = np.arange(len(sess.laps.lap_id))\n",
    "    from PhoPositionalData.plotting.laps import plot_lap_trajectories_3d\n",
    "    pActiveInteractiveLapsPlotter, laps_pages = plot_lap_trajectories_3d(sess, curr_num_subplots=5, active_page_index=0, included_lap_idxs=included_lap_idxs, single_combined_plot=single_combined_plot, \n",
    "                                                                         lap_start_z = lap_start_z, lap_id_dependent_z_offset = lap_id_dependent_z_offset,\n",
    "                                                                         existing_plotter=pActiveInteractiveLapsPlotter)\n",
    "\n",
    "    # add the spikes for the curves:\n",
    "    _plot_all_lap_spikes(pActiveInteractiveLapsPlotter, sess, included_cell_idxs, included_lap_idxs, lap_start_z=lap_start_z, lap_id_dependent_z_offset=lap_id_dependent_z_offset)\n",
    "    return iplapsDataExplorer, pActiveInteractiveLapsPlotter\n",
    "\n",
    "\n",
    "# curr_kdiba_pipeline.computation_results['maze1'].computation_config\n",
    "# curr_kdiba_pipeline.computation_results['maze1'].sess.config\n",
    "# curr_kdiba_pipeline.active_configs['maze1']\n",
    "\n",
    "curr_result_label = 'maze1'\n",
    "sess = curr_kdiba_pipeline.filtered_sessions[curr_result_label]\n",
    "sess = curr_kdiba_pipeline.sess\n",
    "\n",
    "pActiveInteractiveLapsPlotter = None\n",
    "try: pActiveInteractiveLapsPlotter\n",
    "except NameError: pActiveInteractiveLapsPlotter = None # Checks variable p's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "iplapsDataExplorer, pActiveInteractiveLapsPlotter = _display_testing(sess, curr_kdiba_pipeline.computation_results[curr_result_label], curr_kdiba_pipeline.active_configs[curr_result_label],\n",
    "                                                                     extant_plotter=pActiveInteractiveLapsPlotter)\n",
    "pActiveInteractiveLapsPlotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e5881e-3e37-4d8b-b5c3-0c8837cbd1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines_from_points(pdata.points)\n",
    "\n",
    "\n",
    "np.shape(all_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580c6e6-38b1-4d6e-bf09-6b60842a922a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a0d93-16ac-4240-a373-7bd9f337f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, laps_pages = _plot_lap_trajectories_combined_plot_3d(curr_kdiba_pipeline.sess, curr_num_subplots=5, single_combined_plot=False)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86802581-69ea-4aca-a673-e4e306d6e17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
