{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a832c382-7f3e-42e3-91db-828709729862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: pho\n",
    "\"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import importlib\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import PrettyPrintable, get_arguments_as_optional_dict\n",
    "from pyphoplacecellanalysis.General.NeuropyPipeline import *\n",
    "from pyphoplacecellanalysis.General.SessionSelectionAndFiltering import batch_filter_session\n",
    "\n",
    "\n",
    "known_data_session_type_dict = {'kdiba':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: DataSessionLoader.kdiba_old_format_session(a_base_dir)),\n",
    "                               basedir=Path(r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53')),\n",
    "                'bapun':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: DataSessionLoader.bapun_data_session(a_base_dir)),\n",
    "                               basedir=Path('R:\\data\\Bapun\\Day5TwoNovel'))\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b9b3945-eb6e-4887-9bba-35f591a41837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir is already Path object.\n",
      "\t basepath: R:\\data\\Bapun\\Day5TwoNovel\n",
      "\t session_name: RatS-Day5TwoNovel-2020-12-04_07-55-09\n",
      "converting neuron_type strings to core.neurons.NeuronType objects...\n",
      "\t done.\n",
      "Position falling back to legacy loading protocol...: dict_rep: {'traces': array([[-50.946354, -50.946354, -50.946354, ..., -45.350155, -45.350155,\n",
      "        -45.350155],\n",
      "       [-50.646282, -50.646282, -50.646282, ...,  64.150757,  64.150757,\n",
      "         64.150757],\n",
      "       [  7.124897,   7.124897,   7.124897, ...,   5.571329,   5.571329,\n",
      "          5.571329]]), 'computed_traces': array([[nan, nan, nan, ..., nan, nan, nan]]), 't_start': 0, 'sampling_rate': 60, 'metadata': None}\n",
      "linearized position loaded from file.\n",
      "Loading success: .flattened.spikes.npy.\n",
      "Loading success: .ripple.npy.\n",
      "Loading success: .mua.npy.\n",
      "Loading success: .pbe.npy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'object size: 1672.480613708496 MB'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_bapun_pipeline = NeuropyPipeline(name='bapun_pipeline', basedir=known_data_session_type_dict['bapun'].basedir, load_function=known_data_session_type_dict['bapun'].load_function)\n",
    "curr_bapun_pipeline.is_loaded\n",
    "size_bytes = curr_bapun_pipeline.sess.__sizeof__() # 1753723032\n",
    "f'object size: {size_bytes/(1024*1024)} MB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eacca06-254e-4c87-9afd-d1b7e4e9542e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir is already Path object.\n",
      "\t basepath: R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\n",
      "\t session_name: 2006-6-07_11-26-53\n",
      "Loading matlab import file: R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.epochs_info.mat...\n",
      "done.\n",
      "Loading matlab import file: R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position_info.mat...\n",
      "done.\n",
      "Loading matlab import file: R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.spikes.mat...\n",
      "done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Computing linear positions for all active epochs for session...\n",
      "curr_active_epoch_timeslice_indicies: Int64Index([   27,    28,    29,    30,    31,    32,    33,    34,    35,\n",
      "               36,\n",
      "            ...\n",
      "            52139, 52140, 52141, 52142, 52143, 52144, 52145, 52146, 52147,\n",
      "            52148],\n",
      "           dtype='int64', length=52122)\n",
      " \t np.shape(curr_active_epoch_timeslice_indicies): (52122,)\n",
      "curr_active_epoch_timeslice_indicies: Int64Index([52149, 52150, 52151, 52152, 52153, 52154, 52155, 52156, 52157,\n",
      "            52158,\n",
      "            ...\n",
      "            57931, 57932, 57933, 57934, 57935, 57936, 57937, 57938, 57939,\n",
      "            57940],\n",
      "           dtype='int64', length=5792)\n",
      " \t np.shape(curr_active_epoch_timeslice_indicies): (5792,)\n",
      "Saving updated position results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position.npy...2006-6-07_11-26-53.position.npy saved\n",
      "\t done.\n",
      "\n",
      "\t Failure loading .interpolated_spike_positions.npy. Must recompute.\n",
      "\n",
      "\t Saving updated interpolated spike position results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.interpolated_spike_positions.npy..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pho\\repos\\NeuroPy\\neuropy\\core\\position.py:142: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated infavour of `both` or `neither`.\n",
      "  included_indicies = self._data['t'].between(t_start, t_stop, inclusive=True) # returns a boolean array indicating inclusion in teh current lap\n",
      "C:\\Users\\Pho\\repos\\NeuroPy\\neuropy\\core\\position.py:142: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated infavour of `both` or `neither`.\n",
      "  included_indicies = self._data['t'].between(t_start, t_stop, inclusive=True) # returns a boolean array indicating inclusion in teh current lap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006-6-07_11-26-53.interpolated_spike_positions.npy saved\n",
      "\t done.\n",
      "\n",
      "Loading matlab import file: R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.laps_info.mat...\n",
      "done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'estimation_session_laps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8012/1746899565.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;34mf'object size: {size_bytes/(1024*1024)} MB'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m## Estimate the Session's Laps data using my algorithm from the loaded position data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mcurr_kdiba_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimation_session_laps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_kdiba_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'estimation_session_laps' is not defined"
     ]
    }
   ],
   "source": [
    "# KDiba Old Format:\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "# R:\\data\\KDIBA\\gor01\\one\\IIDataMat_Export_ToPython_2021_11_23.m\n",
    "# From pre-computed .mat files:\n",
    "## 07: \n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53'\n",
    "# # ## 08:\n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15'\n",
    "curr_kdiba_pipeline = NeuropyPipeline(name='kdiba_pipeline', basedir=known_data_session_type_dict['kdiba'].basedir, load_function=known_data_session_type_dict['kdiba'].load_function)\n",
    "# curr_bapun_pipeline\n",
    "curr_kdiba_pipeline.is_loaded\n",
    "size_bytes = curr_kdiba_pipeline.sess.__sizeof__() # 1753723032\n",
    "f'object size: {size_bytes/(1024*1024)} MB'\n",
    "## Estimate the Session's Laps data using my algorithm from the loaded position data.\n",
    "curr_kdiba_pipeline.sess = estimation_session_laps(curr_kdiba_pipeline.sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdfd440c-a6db-4743-a872-cb79180d8a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: SpikesAccessor.set_time_variable_name(new_time_variable_name: t_seconds) has been called. Be careful!\n",
      "\t time variable changed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pho\\repos\\NeuroPy\\neuropy\\utils\\mixins\\time_slicing.py:55: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated infavour of `both` or `neither`.\n",
      "  curr_lap_position_df_is_included = self._obj[self.time_variable_name].between(curr_slice_t_start, curr_slice_t_stop, inclusive=True) # returns a boolean array indicating inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spikes Dataframe: \n",
      "np.shape(sess.spikes_df): (16318817, 10)\n",
      "np.shape(filtered_spikes_df): (102139, 10)\n",
      "Position Dataframe: \n",
      "np.shape(sess.position.to_dataframe()): (2538347, 21)\n",
      "np.shape(filtered_pos_df):(174000, 22)\n",
      "dataframe shank column does not exist. Initializing it to 1s\n",
      "dataframe qclu column does not exist. Initializing it to the same as aclu\n",
      "dataframe cluster column does not exist. Initializing it to the same as aclu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataSession(RatS-Day5TwoNovel-2020-12-04_07-55-09.xml)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def temp_filter_session(sess):\n",
    "    # curr_kdiba_pipeline.sess.epochs['maze1']\n",
    "    active_epoch = sess.epochs.get_named_timerange('maze1')\n",
    "\n",
    "    ## All Spikes:\n",
    "    # active_epoch_session = sess.filtered_by_epoch(active_epoch) # old\n",
    "    active_session = batch_filter_session(sess, sess.position, sess.spikes_df, active_epoch.to_Epoch())\n",
    "    return active_session, active_epoch\n",
    "\n",
    "# temp_filter_session(curr_kdiba_pipeline.sess)\n",
    "active_session, active_epoch = temp_filter_session(curr_bapun_pipeline.sess)\n",
    "active_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "951b69c7-c2a6-44e5-9295-55944d5754cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         start         stop  label     duration\n",
       "0     0.000000  1739.153364  maze1  1739.153364\n",
       "1  1739.153364  1932.420005  maze2   193.266641"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Idea: Another set of computations will need to be done for each:\n",
    "\"\"\" \n",
    "active_epoch_session: DataSession\n",
    "computation_config: PlacefieldComputationParameters\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def _perform_single_computation(active_session, computation_config):\n",
    "    # only requires that active_session has the .spikes_df and .position  properties\n",
    "    # active_epoch_placefields1D, active_epoch_placefields2D = compute_placefields_masked_by_epochs(active_epoch_session, active_config, included_epochs=None, should_display_2D_plots=should_display_2D_plots) ## This is causing problems due to deepcopy of session.\n",
    "    active_epoch_placefields1D, active_epoch_placefields2D = perform_compute_placefields(active_session.spikes_df, active_session.position, computation_config, None, None, included_epochs=None, should_force_recompute_placefields=True)\n",
    "\n",
    "    # Compare the results\n",
    "\n",
    "    # debug_print_ratemap(active_epoch_placefields1D.ratemap)\n",
    "    # num_spikes_per_spiketrain = np.array([np.shape(a_spk_train)[0] for a_spk_train in active_epoch_placefields1D.spk_t])\n",
    "    # num_spikes_per_spiketrain\n",
    "    # print('placefield_neuronID_spikes: {}; ({} total spikes)'.format(num_spikes_per_spiketrain, np.sum(num_spikes_per_spiketrain)))\n",
    "    # debug_print_placefield(active_epoch_placefields1D) #49 good\n",
    "    debug_print_placefield(active_epoch_placefields2D) #51 good\n",
    "\n",
    "    # Get the cell IDs that have a good place field mapping:\n",
    "    active_placefields = deepcopy(active_epoch_placefields2D) # not changed this from the default placefields2D object\n",
    "    good_placefield_neuronIDs = np.array(active_placefields.ratemap.neuron_ids) # in order of ascending ID\n",
    "    good_placefield_tuple_neuronIDs = active_placefields.neuron_extended_ids\n",
    "\n",
    "    # good_placefields_neurons_obj = active_epoch_session.neurons.get_by_id(good_placefield_neuronIDs)\n",
    "    # good_placefields_neurons_obj\n",
    "    np.shape(good_placefield_neuronIDs) # returns 51, why does it say that 49 are good then?\n",
    "\n",
    "    ## Filter by neurons with good placefields only:\n",
    "\n",
    "    # throwing an error because active_epoch_session's .neurons property is None. I think the memory usage from deepcopy is actually a bug, not real use.\n",
    "\n",
    "    # good_placefields_flattened_spiketrains = active_epoch_session.flattened_spiketrains.get_by_id(good_placefield_neuronIDs) ## Working\n",
    "\n",
    "    # Could alternatively build from the whole dataframe again, but prob. not needed.\n",
    "    # filtered_spikes_df = active_epoch_session.spikes_df.query(\"`aclu` in @good_placefield_neuronIDs\")\n",
    "    # good_placefields_spk_df = good_placefields_flattened_spiketrains.to_dataframe() # .copy()\n",
    "    # good_placefields_neurons_obj = active_epoch_session.neurons.get_by_id(good_placefield_neuronIDs)\n",
    "    # good_placefields_neurons_obj = Neurons.from_dataframe(good_placefields_spk_df, active_epoch_session.recinfo.dat_sampling_rate, time_variable_name=good_placefields_spk_df.spikes.time_variable_name) # do we really want another neuron object? Should we throw out the old one?\n",
    "    good_placefields_session = active_epoch_session\n",
    "    good_placefields_session.neurons = active_epoch_session.neurons.get_by_id(good_placefield_neuronIDs)\n",
    "    good_placefields_session.flattened_spiketrains = active_epoch_session.flattened_spiketrains.get_by_id(good_placefield_neuronIDs) ## Working\n",
    "\n",
    "    # good_placefields_session = active_epoch_session.get_by_id(good_placefield_neuronIDs) # Filter by good placefields only, and this fetch also ensures they're returned in the order of sorted ascending index ([ 2  3  5  7  9 12 18 21 22 23 26 27 29 34 38 45 48 53 57])\n",
    "    # good_placefields_session\n",
    "\n",
    "    pf_sort_ind, pf_colors, pf_colormap, pf_listed_colormap = build_units_colormap(good_placefield_neuronIDs)\n",
    "    active_config.plotting_config.pf_sort_ind = pf_sort_ind\n",
    "    active_config.plotting_config.pf_colors = pf_colors\n",
    "    active_config.plotting_config.active_cells_colormap = pf_colormap\n",
    "    active_config.plotting_config.active_cells_listed_colormap = ListedColormap(active_config.plotting_config.active_cells_colormap)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
