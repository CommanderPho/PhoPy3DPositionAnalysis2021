{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from typing import List, Dict, Optional, Union, Callable\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables as tb\n",
    "from copy import deepcopy\n",
    "from datetime import datetime, timedelta\n",
    "from attrs import define, field, Factory\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import CapturedException\n",
    "\n",
    "# Jupyter interactivity:\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.gui.Jupyter.JupyterButtonRowWidget import JupyterButtonRowWidget\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core import Epoch\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "import pyphoplacecellanalysis.General.Batch.runBatch\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun, BatchResultDataframeAccessor, run_diba_batch, BatchComputationProcessOptions, BatchSessionCompletionHandler, SavingOptions\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import SessionBatchProgress\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "\n",
    "from pyphocorehelpers.print_helpers import CapturedException\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler\n",
    "\n",
    "BATCH_DATE_TO_USE = '2023-10-04-GL' # used for filenames throught the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef5938c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/global_batch_result_2023-10-04-GL.pkl... done.\n",
      "no difference between provided and internal paths.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>context</th>\n",
       "      <th>basedirs</th>\n",
       "      <th>status</th>\n",
       "      <th>errors</th>\n",
       "      <th>session_datetime</th>\n",
       "      <th>n_long_laps</th>\n",
       "      <th>n_long_replays</th>\n",
       "      <th>n_short_laps</th>\n",
       "      <th>n_short_replays</th>\n",
       "      <th>is_ready</th>\n",
       "      <th>global_computation_result_file</th>\n",
       "      <th>loaded_session_pickle_file</th>\n",
       "      <th>ripple_result_file</th>\n",
       "      <th>has_user_replay_annotations</th>\n",
       "      <th>has_user_grid_bin_bounds_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-07_11-26-53</td>\n",
       "      <td>kdiba_gor01_one_2006-6-07_11-26-53</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-07 11:26:53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>kdiba_gor01_one_2006-6-08_14-26-15</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "      <td>40</td>\n",
       "      <td>279</td>\n",
       "      <td>40</td>\n",
       "      <td>224</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>kdiba_gor01_one_2006-6-09_1-22-43</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-09 01:22:43</td>\n",
       "      <td>46</td>\n",
       "      <td>179</td>\n",
       "      <td>40</td>\n",
       "      <td>142</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_3-23-37</td>\n",
       "      <td>kdiba_gor01_one_2006-6-09_3-23-37</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-09 03:23:37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-12_15-55-31</td>\n",
       "      <td>kdiba_gor01_one_2006-6-12_15-55-31</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-12 15:55:31</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-04_21-20-3</td>\n",
       "      <td>kdiba_pin01_one_fet11-04_21-20-3</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-04 21:20:03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>redundant</td>\n",
       "      <td>kdiba_pin01_one_redundant</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/red...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>showclus</td>\n",
       "      <td>kdiba_pin01_one_showclus</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sho...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>sleep</td>\n",
       "      <td>kdiba_pin01_one_sleep</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sleep</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>tmaze</td>\n",
       "      <td>kdiba_pin01_one_tmaze</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/tmaze</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   format_name animal exper_name        session_name  \\\n",
       "0        kdiba  gor01        one  2006-6-07_11-26-53   \n",
       "1        kdiba  gor01        one  2006-6-08_14-26-15   \n",
       "2        kdiba  gor01        one   2006-6-09_1-22-43   \n",
       "3        kdiba  gor01        one   2006-6-09_3-23-37   \n",
       "4        kdiba  gor01        one  2006-6-12_15-55-31   \n",
       "..         ...    ...        ...                 ...   \n",
       "67       kdiba  pin01        one    fet11-04_21-20-3   \n",
       "68       kdiba  pin01        one           redundant   \n",
       "69       kdiba  pin01        one            showclus   \n",
       "70       kdiba  pin01        one               sleep   \n",
       "71       kdiba  pin01        one               tmaze   \n",
       "\n",
       "                               context  \\\n",
       "0   kdiba_gor01_one_2006-6-07_11-26-53   \n",
       "1   kdiba_gor01_one_2006-6-08_14-26-15   \n",
       "2    kdiba_gor01_one_2006-6-09_1-22-43   \n",
       "3    kdiba_gor01_one_2006-6-09_3-23-37   \n",
       "4   kdiba_gor01_one_2006-6-12_15-55-31   \n",
       "..                                 ...   \n",
       "67    kdiba_pin01_one_fet11-04_21-20-3   \n",
       "68           kdiba_pin01_one_redundant   \n",
       "69            kdiba_pin01_one_showclus   \n",
       "70               kdiba_pin01_one_sleep   \n",
       "71               kdiba_pin01_one_tmaze   \n",
       "\n",
       "                                             basedirs  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/red...   \n",
       "69  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sho...   \n",
       "70   /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sleep   \n",
       "71   /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/tmaze   \n",
       "\n",
       "                              status errors    session_datetime  n_long_laps  \\\n",
       "0   SessionBatchProgress.NOT_STARTED   None 2006-06-07 11:26:53            0   \n",
       "1     SessionBatchProgress.COMPLETED   None 2006-06-08 14:26:15           40   \n",
       "2     SessionBatchProgress.COMPLETED   None 2006-06-09 01:22:43           46   \n",
       "3   SessionBatchProgress.NOT_STARTED   None 2006-06-09 03:23:37            0   \n",
       "4     SessionBatchProgress.COMPLETED   None 2006-06-12 15:55:31           40   \n",
       "..                               ...    ...                 ...          ...   \n",
       "67  SessionBatchProgress.NOT_STARTED   None 2009-11-04 21:20:03            0   \n",
       "68  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "69  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "70  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "71  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "\n",
       "    n_long_replays  n_short_laps  n_short_replays  is_ready  \\\n",
       "0                0             0                0     False   \n",
       "1              279            40              224      True   \n",
       "2              179            40              142      True   \n",
       "3                0             0                0     False   \n",
       "4               37            34               55      True   \n",
       "..             ...           ...              ...       ...   \n",
       "67               0             0                0     False   \n",
       "68               0             0                0     False   \n",
       "69               0             0                0     False   \n",
       "70               0             0                0     False   \n",
       "71               0             0                0     False   \n",
       "\n",
       "                       global_computation_result_file  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3                                                       \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "                           loaded_session_pickle_file  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3                                                       \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "                                   ripple_result_file  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "    has_user_replay_annotations  has_user_grid_bin_bounds_annotations  \n",
       "0                         False                                  True  \n",
       "1                          True                                  True  \n",
       "2                          True                                  True  \n",
       "3                         False                                  True  \n",
       "4                          True                                  True  \n",
       "..                          ...                                   ...  \n",
       "67                        False                                  True  \n",
       "68                        False                                 False  \n",
       "69                        False                                 False  \n",
       "70                        False                                 False  \n",
       "71                        False                                 False  \n",
       "\n",
       "[72 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_global_batch_result_filename=f'global_batch_result_{BATCH_DATE_TO_USE}.pkl'\n",
    "\n",
    "debug_print = False\n",
    "known_global_data_root_parent_paths = [Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/nfs/turbo/umms-kdiba/Data')] # , Path(r'/home/halechr/FastData')\n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "## Build Pickle Path:\n",
    "global_batch_result_file_path = Path(global_data_root_parent_path).joinpath(active_global_batch_result_filename).resolve() # Use Default\n",
    "\n",
    "# try to load an existing batch result:\n",
    "global_batch_run = BatchRun.try_init_from_file(global_data_root_parent_path, active_global_batch_result_filename=active_global_batch_result_filename,\n",
    "\t\t\t\t\t\tskip_root_path_conversion=False, debug_print=debug_print) # on_needs_create_callback_fn=run_diba_batch\n",
    "\n",
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "batch_progress_df.batch_results.build_all_columns()\n",
    "good_only_batch_progress_df.batch_results.build_all_columns()\n",
    "batch_progress_df\n",
    "with pd.option_context('display.max_rows', 10, 'display.max_columns', None):  # more options can be specified also\n",
    "    # display(batch_progress_df)\n",
    "    # display(good_only_batch_progress_df)\n",
    "    display(batch_progress_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab824348",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Batch Executions/Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019afbbd-70d2-4e75-9548-b6f22d2e31ca",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>context</th>\n",
       "      <th>basedirs</th>\n",
       "      <th>status</th>\n",
       "      <th>errors</th>\n",
       "      <th>session_datetime</th>\n",
       "      <th>n_long_laps</th>\n",
       "      <th>n_long_replays</th>\n",
       "      <th>n_short_laps</th>\n",
       "      <th>n_short_replays</th>\n",
       "      <th>is_ready</th>\n",
       "      <th>global_computation_result_file</th>\n",
       "      <th>loaded_session_pickle_file</th>\n",
       "      <th>ripple_result_file</th>\n",
       "      <th>has_user_replay_annotations</th>\n",
       "      <th>has_user_grid_bin_bounds_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>kdiba_gor01_one_2006-6-08_14-26-15</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "      <td>40</td>\n",
       "      <td>279</td>\n",
       "      <td>40</td>\n",
       "      <td>224</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>kdiba_gor01_one_2006-6-09_1-22-43</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-09 01:22:43</td>\n",
       "      <td>46</td>\n",
       "      <td>179</td>\n",
       "      <td>40</td>\n",
       "      <td>142</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-12_15-55-31</td>\n",
       "      <td>kdiba_gor01_one_2006-6-12_15-55-31</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-12 15:55:31</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-07_16-40-19</td>\n",
       "      <td>kdiba_gor01_two_2006-6-07_16-40-19</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-07 16:40:19</td>\n",
       "      <td>42</td>\n",
       "      <td>212</td>\n",
       "      <td>40</td>\n",
       "      <td>333</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-08_21-16-25</td>\n",
       "      <td>kdiba_gor01_two_2006-6-08_21-16-25</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-08 21:16:25</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>62</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-4-10_12-58-3</td>\n",
       "      <td>kdiba_vvp01_two_2006-4-10_12-58-3</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-04-10 12:58:03</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-02_17-46-44</td>\n",
       "      <td>kdiba_pin01_one_11-02_17-46-44</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-02 17:46:44</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-02_19-28-0</td>\n",
       "      <td>kdiba_pin01_one_11-02_19-28-0</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-02 19:28:00</td>\n",
       "      <td>56</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-03_12-3-25</td>\n",
       "      <td>kdiba_pin01_one_11-03_12-3-25</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-03 12:03:25</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>kdiba_pin01_one_fet11-01_12-58-54</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "      <td>315</td>\n",
       "      <td>330</td>\n",
       "      <td>163</td>\n",
       "      <td>139</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   format_name animal exper_name        session_name  \\\n",
       "1        kdiba  gor01        one  2006-6-08_14-26-15   \n",
       "2        kdiba  gor01        one   2006-6-09_1-22-43   \n",
       "4        kdiba  gor01        one  2006-6-12_15-55-31   \n",
       "6        kdiba  gor01        two  2006-6-07_16-40-19   \n",
       "8        kdiba  gor01        two  2006-6-08_21-16-25   \n",
       "..         ...    ...        ...                 ...   \n",
       "32       kdiba  vvp01        two   2006-4-10_12-58-3   \n",
       "52       kdiba  pin01        one      11-02_17-46-44   \n",
       "53       kdiba  pin01        one       11-02_19-28-0   \n",
       "54       kdiba  pin01        one       11-03_12-3-25   \n",
       "64       kdiba  pin01        one   fet11-01_12-58-54   \n",
       "\n",
       "                               context  \\\n",
       "1   kdiba_gor01_one_2006-6-08_14-26-15   \n",
       "2    kdiba_gor01_one_2006-6-09_1-22-43   \n",
       "4   kdiba_gor01_one_2006-6-12_15-55-31   \n",
       "6   kdiba_gor01_two_2006-6-07_16-40-19   \n",
       "8   kdiba_gor01_two_2006-6-08_21-16-25   \n",
       "..                                 ...   \n",
       "32   kdiba_vvp01_two_2006-4-10_12-58-3   \n",
       "52      kdiba_pin01_one_11-02_17-46-44   \n",
       "53       kdiba_pin01_one_11-02_19-28-0   \n",
       "54       kdiba_pin01_one_11-03_12-3-25   \n",
       "64   kdiba_pin01_one_fet11-01_12-58-54   \n",
       "\n",
       "                                             basedirs  \\\n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "..                                                ...   \n",
       "32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "\n",
       "                            status errors    session_datetime  n_long_laps  \\\n",
       "1   SessionBatchProgress.COMPLETED   None 2006-06-08 14:26:15           40   \n",
       "2   SessionBatchProgress.COMPLETED   None 2006-06-09 01:22:43           46   \n",
       "4   SessionBatchProgress.COMPLETED   None 2006-06-12 15:55:31           40   \n",
       "6   SessionBatchProgress.COMPLETED   None 2006-06-07 16:40:19           42   \n",
       "8   SessionBatchProgress.COMPLETED   None 2006-06-08 21:16:25           40   \n",
       "..                             ...    ...                 ...          ...   \n",
       "32  SessionBatchProgress.COMPLETED   None 2006-04-10 12:58:03           40   \n",
       "52  SessionBatchProgress.COMPLETED   None 2009-11-02 17:46:44           54   \n",
       "53  SessionBatchProgress.COMPLETED   None 2009-11-02 19:28:00           56   \n",
       "54  SessionBatchProgress.COMPLETED   None 2009-11-03 12:03:25           50   \n",
       "64  SessionBatchProgress.COMPLETED   None 2009-11-01 12:58:54          315   \n",
       "\n",
       "    n_long_replays  n_short_laps  n_short_replays  is_ready  \\\n",
       "1              279            40              224      True   \n",
       "2              179            40              142      True   \n",
       "4               37            34               55      True   \n",
       "6              212            40              333      True   \n",
       "8               45            40               62      True   \n",
       "..             ...           ...              ...       ...   \n",
       "32              47            42               16      True   \n",
       "52              60            66               66      True   \n",
       "53              48            50               19      True   \n",
       "54              10            46                6      True   \n",
       "64             330           163              139      True   \n",
       "\n",
       "                       global_computation_result_file  \\\n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "..                                                ...   \n",
       "32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "\n",
       "                           loaded_session_pickle_file  \\\n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "..                                                ...   \n",
       "32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "\n",
       "                                   ripple_result_file  \\\n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "..                                                ...   \n",
       "32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "\n",
       "    has_user_replay_annotations  has_user_grid_bin_bounds_annotations  \n",
       "1                          True                                  True  \n",
       "2                          True                                  True  \n",
       "4                          True                                  True  \n",
       "6                          True                                  True  \n",
       "8                          True                                  True  \n",
       "..                          ...                                   ...  \n",
       "32                         True                                  True  \n",
       "52                         True                                  True  \n",
       "53                         True                                  True  \n",
       "54                         True                                  True  \n",
       "64                         True                                  True  \n",
       "\n",
       "[15 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hardcoded included_session_contexts:\n",
    "included_session_contexts = [\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'), # prev completed\n",
    "]\n",
    "\n",
    "included_session_batch_progress_df = batch_progress_df[np.isin(batch_progress_df['context'].values, included_session_contexts)]\n",
    "with pd.option_context('display.max_rows', 10, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(included_session_batch_progress_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71584edc",
   "metadata": {},
   "source": [
    "# Execute Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff419df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_included_session_contexts, output_python_scripts, output_slurm_scripts = global_batch_run.generate_batch_slurm_jobs(included_session_contexts, Path('output/generated_slurm_scripts/').resolve(), \n",
    "                                                                                                                        use_separate_run_directories=True, should_force_reload_all=False, should_perform_figure_generation_to_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab6ae279",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(included_session_contexts): 15\n",
      "Beginning processing with len(included_session_contexts): 15\n",
      "build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-09_1-22-43\"):build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-08_14-26-15\"):\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-12_15-55-31\"):\n",
      "build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-07_16-40-19\"):\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-12_15-55-31 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-12_15-55-31.logbuild_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-12_16-53-46\"):\n",
      "\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-08_14-26-15 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-08_14-26-15.log\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-09_1-22-43 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-09_1-22-43.log\n",
      "build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-08_21-16-25\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-12_16-53-46 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-12_16-53-46.log\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-07_16-40-19 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-07_16-40-19.logbuild_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-09_22-24-40\"):\n",
      "\n",
      "========================== runBatch STARTING ==================================================== runBatch STARTING ==========================\n",
      "\n",
      "========================== runBatch STARTING ==========================\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-08_21-16-25 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-08_21-16-25.log\n",
      "\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "========================== runBatch STARTING ==================================================== runBatch STARTING ==========================\n",
      "\n",
      "========================== runBatch STARTING ==========================\n",
      "\tsession_context: kdiba_gor01_one_2006-6-08_14-26-15\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15\n",
      "\n",
      "\tsession_context: kdiba_gor01_two_2006-6-08_21-16-25\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-09_22-24-40 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-09_22-24-40.log\n",
      "\tsession_context: kdiba_gor01_one_2006-6-09_1-22-43\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25__________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "__________________________________________________________________\n",
      "\n",
      "========================== runBatch STARTING ==========================\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15\tsession_context: kdiba_gor01_two_2006-6-07_16-40-19\tsession_context: kdiba_gor01_two_2006-6-12_16-53-46\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "active_data_mode_name: kdiba\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Dataactive_data_mode_name: kdiba\n",
      "\n",
      "\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19\n",
      "____________________________________________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43\tsession_context: kdiba_gor01_two_2006-6-09_22-24-40basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46\n",
      "__________________________________________________________________\n",
      "active_data_mode_name: kdiba\n",
      "\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Databasedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19active_data_mode_name: kdiba\n",
      "\n",
      "\n",
      "\tsession_context: kdiba_gor01_one_2006-6-12_15-55-31\n",
      "\n",
      "active_data_mode_name: kdiba\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl...Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl...\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl... __________________________________________________________________Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl... \n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl...\n",
      "active_data_mode_name: kdiba  __________________________________________________________________\n",
      " \n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl...Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl...  done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-12_16-53-46, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl... done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_one_2006-6-12_15-55-31, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl... done.\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "position_decoding, maze already computed.\n",
      "position_decoding_two_step missing.\n",
      "\t Recomputing position_decoding_two_step...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_one_2006-6-09_1-22-43, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl... done.\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "position_decoding, maze already computed.\n",
      "position_decoding_two_step missing.\n",
      "\t Recomputing position_decoding_two_step...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.done.\n",
      "\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl.WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_one_2006-6-08_14-26-15, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl... properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-09_22-24-40, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl... two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (13127,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (9198,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (18467,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-08_21-16-25, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl... done.\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "position_decoding, maze already computed.\n",
      "position_decoding_two_step missing.\n",
      "\t Recomputing position_decoding_two_step...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (12943,)\n",
      "done.\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "position_decoding, maze already computed.\n",
      "position_decoding_two_step missing.\n",
      "\t Recomputing position_decoding_two_step...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (22940,)\n",
      "\t done.\n",
      "ERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_gor01_two_2006-6-12_16-53-46. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x14b422bd2580>)\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis']. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl... done.\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "position_decoding, maze already computed.\n",
      "position_decoding_two_step missing.\n",
      "\t Recomputing position_decoding_two_step...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "position_decoding, maze already computed.\n",
      "position_decoding_two_step missing.\n",
      "\t Recomputing position_decoding_two_step...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-07_16-40-19, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl... two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (30745,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/20231004133655-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:08.431579\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (20270,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (18711,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-12_16-53-46'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:266: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:272: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b4234d4400>) while trying to build the session HDF output.\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b42349b640>) while trying to build the session HDF output for kdiba_gor01_two_2006-6-12_16-53-46\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-12_16-53-46...\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-09_17-29-30\"):\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-09_17-29-30 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-09_17-29-30.log\n",
      "\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_vvp01_one_2006-4-09_17-29-30\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl... two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (27155,)\n",
      "done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (12894,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "position_decoding, maze already computed.\n",
      "position_decoding_two_step missing.\n",
      "\t Recomputing position_decoding_two_step...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (36246,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (32287,)\n",
      "\t done.\n",
      "ERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_gor01_one_2006-6-12_15-55-31. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x14b422b34380>)\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis']. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl... done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_one_2006-4-09_17-29-30, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl... \tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/20231004133715-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:07.380528\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5\n",
      "done.\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "position_decoding, maze already computed.\n",
      "position_decoding_two_step missing.\n",
      "\t Recomputing position_decoding_two_step...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (34680,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (25095,)\n",
      "\t done.\n",
      "ERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_gor01_two_2006-6-08_21-16-25. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x14b42339b680>)\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis']. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl... Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (50132,)\n",
      "\t done.\n",
      "ERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_gor01_one_2006-6-09_1-22-43. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x14b42381dec0>)\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis']. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-12_15-55-31'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:266: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:272: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b422b53b80>) while trying to build the session HDF output.\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b42288bf80>) while trying to build the session HDF output for kdiba_gor01_one_2006-6-12_15-55-31\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-12_15-55-31...\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-10_12-25-50\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-10_12-25-50 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-10_12-25-50.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_vvp01_one_2006-4-10_12-25-50\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl... two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (49904,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (36136,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_one_2006-4-10_12-25-50, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl... done.\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "position_decoding, maze already computed.\n",
      "position_decoding_two_step missing.\n",
      "\t Recomputing position_decoding_two_step...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/20231004133727-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:22.557539\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (25027,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (38641,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (62479,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t done.\n",
      "ERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_gor01_one_2006-6-08_14-26-15. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x14b423dc6a00>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-08_21-16-25'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newly_computed_values: ['jonathan_firing_rate_analysis']. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:266: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:272: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b4236bf2c0>) while trying to build the session HDF output.\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b42364cec0>) while trying to build the session HDF output for kdiba_gor01_two_2006-6-08_21-16-25\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-08_21-16-25...\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-09_16-40-54\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-09_16-40-54 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-09_16-40-54.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_vvp01_two_2006-4-09_16-40-54\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl... \tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/20231004133728-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:35.476986\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (77624,)\n",
      "\t done.\n",
      "ERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_gor01_two_2006-6-09_22-24-40. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x14b42314dbc0>)\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis']. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl... two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (14069,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (26312,)\n",
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl.\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_two_2006-4-09_16-40-54, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "position_decoding, maze already computed.\n",
      "position_decoding_two_step missing.\n",
      "\t Recomputing position_decoding_two_step...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n",
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-09_1-22-43'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:266: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:272: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b2ec746cc0>) while trying to build the session HDF output.\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b424f61a80>) while trying to build the session HDF output for kdiba_gor01_one_2006-6-09_1-22-43\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-09_1-22-43...\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-10_12-58-3\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-10_12-58-3 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-10_12-58-3.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_vvp01_two_2006-4-10_12-58-3\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl... two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (13343,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_two_2006-4-10_12-58-3, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl... done.\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "position_decoding, maze already computed.\n",
      "position_decoding_two_step missing.\n",
      "\t Recomputing position_decoding_two_step...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/20231004133801-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl'\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (26171,)\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:41.748800\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (77332,)\n",
      "\t done.\n",
      "ERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_gor01_two_2006-6-07_16-40-19. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x14b2022833c0>)\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis']. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl... two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (40880,)\n",
      "\t done.\n",
      "ERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_vvp01_one_2006-4-09_17-29-30. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x14b4239bba40>)\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis']. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl... \tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/20231004133846-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:07.703385\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (14863,)\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (27018,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n",
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-08_14-26-15'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-09_17-29-30'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:266: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:272: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:266: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/20231004133804-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl'\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:272: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps:\n",
      "an_attribute_field: meana_field: LxC_aclus\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b4230fef00>) while trying to build the session HDF output.\n",
      "\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_aclusERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b4239e6140>) while trying to build the session HDF output for kdiba_gor01_one_2006-6-08_14-26-15\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-08_14-26-15...\n",
      "\t\t done (success).\n",
      "\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-02_17-46-44\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-02_17-46-44 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-02_17-46-44.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Dataa_field: SxC_aclus\n",
      "\n",
      "\tsession_context: kdiba_pin01_one_11-02_17-46-44\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_aclus__________________________________________________________________\n",
      "\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44\n",
      "\n",
      "active_data_mode_name: kdiba\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FRLoading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl... \n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.done.\n",
      "\n",
      "a_field: LxC_aclusskipping figure generation because should_perform_figure_generation_to_file == False\n",
      "\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclusDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:56.294583\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b4251e5e80>) while trying to build the session HDF output.\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b4bc586640>) while trying to build the session HDF output for kdiba_vvp01_one_2006-4-09_17-29-30\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_one_2006-4-09_17-29-30...\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-02_19-28-0\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-02_19-28-0 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-02_19-28-0.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_pin01_one_11-02_19-28-0\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_11-02_17-46-44, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl... two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (42319,)\n",
      "\t done.\n",
      "ERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_vvp01_one_2006-4-10_12-25-50. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x14b423e30880>)\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis']. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (14198,)\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl... Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/20231004133911-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:04.990059\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5\n",
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/20231004133845-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:31.905926\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5\n",
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_11-02_19-28-0, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl... done.\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "position_decoding, maze already computed.\n",
      "position_decoding_two_step missing.\n",
      "\t Recomputing position_decoding_two_step...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n",
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-09_22-24-40'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-10_12-25-50'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:266: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:272: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:266: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:272: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclusa_field: LxC_aclus\n",
      "\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.a_field: SxC_aclus\n",
      "\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_aclus\n",
      "an_attribute_field: mean\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.an_attribute_field: std\n",
      "\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus:\n",
      "a_field: Fig2_Replay_FRa_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2_Replay_FRWARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclusa_field: values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: meana_field: LxC_aclus\n",
      "\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "a_field: SxC_aclus\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/SxC_ReplayDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclusan_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "\n",
      "a_field: Fig2_Laps_FR\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2_Laps_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus\n",
      "\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclusan_attribute_field: mean\n",
      "\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b4244f7280>) while trying to build the session HDF output.\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b4249c7fc0>) while trying to build the session HDF output for kdiba_vvp01_one_2006-4-10_12-25-50\n",
      "an_attribute_field: mean\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_one_2006-4-10_12-25-50...an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus:\n",
      "\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-03_12-3-25\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-03_12-3-25 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-03_12-3-25.log\n",
      "a_field: SxC_aclus========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/LxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "\n",
      "\tsession_context: kdiba_pin01_one_11-03_12-3-25\n",
      "an_attribute_field: mean\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25\n",
      "\n",
      "an_attribute_field: std__________________________________________________________________\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus:\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25\n",
      "active_data_mode_name: kdiba\n",
      "\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl... a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/Fig2/Laps/inst_FR_Bars/SxC_ThetaDeltaPlus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "an_attribute_field: std\n",
      "a_field: LxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: included_neuron_ids\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/included_neuron_ids\n",
      "\t field not custom serializable! a_field_attr.type: typing.Optional[numpy.ndarray].\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/included_neuron_ids is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: filter_epochs_df\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/filter_epochs_df\n",
      "\t field not custom serializable! a_field_attr.type: <class 'pandas.core.frame.DataFrame'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaMinus/filter_epochs_df is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: kernel_width_ms\n",
      "a_field: LxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: included_neuron_ids\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/included_neuron_ids\n",
      "\t field not custom serializable! a_field_attr.type: typing.Optional[numpy.ndarray].\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/included_neuron_ids is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: filter_epochs_df\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/filter_epochs_df\n",
      "\t field not custom serializable! a_field_attr.type: <class 'pandas.core.frame.DataFrame'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ReplayDeltaPlus/filter_epochs_df is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: kernel_width_ms\n",
      "a_field: SxC_ReplayDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: included_neuron_ids\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/included_neuron_ids\n",
      "\t field not custom serializable! a_field_attr.type: typing.Optional[numpy.ndarray].\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/included_neuron_ids is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: filter_epochs_df\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/filter_epochs_df\n",
      "\t field not custom serializable! a_field_attr.type: <class 'pandas.core.frame.DataFrame'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaMinus/filter_epochs_df is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: kernel_width_ms\n",
      "a_field: SxC_ReplayDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_listdone.\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: included_neuron_ids\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/included_neuron_ids\n",
      "\t field not custom serializable! a_field_attr.type: typing.Optional[numpy.ndarray].\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/included_neuron_ids is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: filter_epochs_df\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/filter_epochs_df\n",
      "\t field not custom serializable! a_field_attr.type: <class 'pandas.core.frame.DataFrame'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ReplayDeltaPlus/filter_epochs_df is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"an_attribute_field: all_agg_inst_fr\n",
      "\n",
      "pf_computation, maze already computed.an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: kernel_width_ms\n",
      "\n",
      "pfdt_computation, maze already computed.a_field: LxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "\n",
      "position_decoding, maze already computed.\n",
      "position_decoding_two_step missing.\n",
      "\t Recomputing position_decoding_two_step...WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus:\n",
      "\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: included_neuron_ids\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/included_neuron_ids\n",
      "\t field not custom serializable! a_field_attr.type: typing.Optional[numpy.ndarray].\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/included_neuron_ids is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: filter_epochs_df\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/filter_epochs_df\n",
      "\t field not custom serializable! a_field_attr.type: <class 'pandas.core.frame.DataFrame'>.\n",
      "\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaMinus/filter_epochs_df is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: kernel_width_ms\n",
      "a_field: LxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: included_neuron_ids\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/included_neuron_ids\n",
      "\t field not custom serializable! a_field_attr.type: typing.Optional[numpy.ndarray].\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/included_neuron_ids is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: filter_epochs_df\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/filter_epochs_df\n",
      "\t field not custom serializable! a_field_attr.type: <class 'pandas.core.frame.DataFrame'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/LxC_ThetaDeltaPlus/filter_epochs_df is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: kernel_width_ms\n",
      "a_field: SxC_ThetaDeltaMinus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: included_neuron_ids\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/included_neuron_ids\n",
      "\t field not custom serializable! a_field_attr.type: typing.Optional[numpy.ndarray].\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/included_neuron_ids is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_field: filter_epochs_df\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/filter_epochs_df\n",
      "\t field not custom serializable! a_field_attr.type: <class 'pandas.core.frame.DataFrame'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaMinus/filter_epochs_df is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: kernel_width_ms\n",
      "a_field: SxC_ThetaDeltaPlus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis.SpikeRateTrends'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus:\n",
      "a_field: epoch_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/epoch_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: cell_agg_inst_fr_list\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/cell_agg_inst_fr_list is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: included_neuron_ids\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/included_neuron_ids\n",
      "\t field not custom serializable! a_field_attr.type: typing.Optional[numpy.ndarray].\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/included_neuron_ids is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: filter_epochs_df\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/filter_epochs_df\n",
      "\t field not custom serializable! a_field_attr.type: <class 'pandas.core.frame.DataFrame'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/inst_fr_comps/SxC_ThetaDeltaPlus/filter_epochs_df is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: all_agg_inst_fr\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: kernel_width_ms\n",
      "an_attribute_field: instantaneous_time_bin_size_seconds\n",
      "an_attribute_field: active_identifying_session_ctx\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_11-03_12-3-25, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl... done.\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "position_decoding, maze already computed.\n",
      "position_decoding_two_step missing.\n",
      "\t Recomputing position_decoding_two_step...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (29312,)\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (22485,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n",
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-07_16-40-19'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:266: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:272: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b423e58600>) while trying to build the session HDF output.\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b423154f40>) while trying to build the session HDF output for kdiba_gor01_two_2006-6-07_16-40-19\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-07_16-40-19...\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.pin01.one.fet11-01_12-58-54\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.fet11-01_12-58-54 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.fet11-01_12-58-54.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_pin01_one_fet11-01_12-58-54\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl... two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (18921,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (11282,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (43010,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t done.\n",
      "ERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_vvp01_two_2006-4-09_16-40-54. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x14b322a4e700>)\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis']. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl... two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (9200,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/20231004133942-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:03.939746\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5\n",
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_fet11-01_12-58-54, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl... two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (22102,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (43046,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-09_16-40-54'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t done.\n",
      "ERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_vvp01_two_2006-4-10_12-58-3. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x14b2ec959380>)\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis']. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl... DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:266: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:272: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b423a61fc0>) while trying to build the session HDF output.\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b322f9b340>) while trying to build the session HDF output for kdiba_vvp01_two_2006-4-09_16-40-54\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_two_2006-4-09_16-40-54...\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "done.\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "position_decoding, maze already computed.\n",
      "position_decoding_two_step missing.\n",
      "\t Recomputing position_decoding_two_step...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (28419,)\n",
      "\t done.\n",
      "ERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_pin01_one_11-03_12-3-25. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x14b423fbe5c0>)\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis']. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl... two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (34248,)\n",
      "\t done.\n",
      "ERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_pin01_one_11-02_19-28-0. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x14b422987240>)\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis']. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl... \tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/20231004133951-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:06.615937\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5\n",
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/20231004133955-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:02.894698\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '11-03_12-3-25'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:266: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:272: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-03_12-3-25/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-03_12-3-25/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-03_12-3-25/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-03_12-3-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-03_12-3-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-03_12-3-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-03_12-3-25/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b4249b8a00>) while trying to build the session HDF output.\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b4bc327440>) while trying to build the session HDF output for kdiba_pin01_one_11-03_12-3-25\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-03_12-3-25...\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-10_12-58-3'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:266: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:272: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b2ec930280>) while trying to build the session HDF output.\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b2ed32a780>) while trying to build the session HDF output for kdiba_vvp01_two_2006-4-10_12-58-3\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_two_2006-4-10_12-58-3...\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/20231004133957-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:06.000338\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '11-02_19-28-0'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:266: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:272: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_19-28-0/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_19-28-0/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_19-28-0/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_19-28-0/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_19-28-0/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_19-28-0/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_19-28-0/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b420b5bd40>) while trying to build the session HDF output.\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b420b5b340>) while trying to build the session HDF output for kdiba_pin01_one_11-02_19-28-0\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-02_19-28-0...\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (56677,)\n",
      "\t done.\n",
      "ERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_pin01_one_11-02_17-46-44. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x14b27e5eb940>)\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis']. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl... two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (53345,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/20231004134019-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:07.633935\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '11-02_17-46-44'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:266: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:272: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b27f039100>) while trying to build the session HDF output.\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b281e02900>) while trying to build the session HDF output for kdiba_pin01_one_11-02_17-46-44\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-02_17-46-44...\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (28623,)\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:366: RuntimeWarning: divide by zero encountered in divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-09_22-24-40...\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (90848,)\n",
      "\t done.\n",
      "ERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_pin01_one_fet11-01_12-58-54. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x14b20629ac00>)\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis']. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl... \tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/20231004134120-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:14.449819\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: 'fet11-01_12-58-54'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:266: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:272: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.InstantaneousSpikeRateGroupsComputation'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps:\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Fig2_Replay_FR\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2_Replay_FR\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.SingleBarResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus:\n",
      "a_field: values\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/values is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: LxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/LxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: SxC_aclus\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/inst_fr_comps/Fig2/Replay/inst_FR_Bars/LxC_ReplayDeltaMinus/SxC_aclus is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: mean\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b41a7e5240>) while trying to build the session HDF output.\n",
      "ERROR: encountered exception !! Object dtype dtype('O') has no native HDF5 equivalent ::::: (<class 'TypeError'>, TypeError(\"Object dtype dtype('O') has no native HDF5 equivalent\"), <traceback object at 0x14b4234828c0>) while trying to build the session HDF output for kdiba_pin01_one_fet11-01_12-58-54\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_fet11-01_12-58-54...\n",
      "\t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %pdb on\n",
    "\n",
    "# multiprocessing_kwargs = dict(use_multiprocessing=False, num_processes=1)\n",
    "multiprocessing_kwargs = dict(use_multiprocessing=True, num_processes=7)\n",
    "\n",
    "enable_full_pipeline_in_ram = False\n",
    "# enable_full_pipeline_in_ram = True\n",
    "## Error with enable_full_pipeline_in_ram=True:\n",
    " # delta_since_last_compute=datetime.timedelta(seconds=43, microseconds=466370), outputs_local={'pkl': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl')}, outputs_global={'pkl': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl'), 'hdf5': None}, across_session_results={'inst_fr_comps': None, 'curr_active_pipeline': <pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline.NeuropyPipeline object at 0x148e83474700>}))'. Reason: 'AttributeError(\"Can't pickle local object 'DataSessionFormatBaseRegisteredClass.build_default_filter_functions.<locals>.<dictcomp>.<lambda>'\")'\n",
    "    \n",
    "# Whether to output figures:\n",
    "should_perform_figure_generation_to_file=False\n",
    "# should_perform_figure_generation_to_file=True\n",
    "\n",
    "## Included Session Contexts:\n",
    "# included_session_contexts = batch_progress_df[np.logical_and(batch_progress_df['has_user_replay_annotations'], batch_progress_df['is_ready'])]['context'].to_numpy().tolist()\n",
    "\n",
    "# Only require sessions to have replay annotations:\n",
    "# included_session_contexts = batch_progress_df[batch_progress_df['has_user_replay_annotations']]['context'].to_numpy().tolist()\n",
    "\n",
    "# included_session_contexts = batch_progress_df['context'].to_numpy().tolist()[:4] # Only get the first 6\n",
    "## Limit the contexts to run to the last N:\n",
    "# included_session_contexts = included_session_contexts[3:6]\n",
    "\n",
    "# ALL\n",
    "included_session_contexts = included_session_contexts\n",
    "\n",
    "# ## No filtering the sessions:\n",
    "# included_session_contexts = None\n",
    "\n",
    "if included_session_contexts is not None:\n",
    "    print(f'len(included_session_contexts): {len(included_session_contexts)}')\n",
    "else:\n",
    "    print(f'included_session_contexts is None so all session contexts will be included.')\n",
    "\n",
    "# included_session_contexts\n",
    "\n",
    "# No recomputing at all:\n",
    "# result_handler = BatchSessionCompletionHandler(force_reload_all=False,\n",
    "#                                                 session_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=False, should_save=SavingOptions.NEVER),\n",
    "#                                                 global_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=True, should_save=SavingOptions.NEVER),\n",
    "#                                                 should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, should_generate_all_plots=True, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_global_recompute=False,\n",
    "#                                                 enable_full_pipeline_in_ram=enable_full_pipeline_in_ram,\n",
    "#                                                 **multiprocessing_kwargs)\n",
    "\n",
    "# No Reloading\n",
    "result_handler = BatchSessionCompletionHandler(force_reload_all=False,\n",
    "                                                session_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=True, should_save=SavingOptions.NEVER),\n",
    "                                                global_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=True, should_save=SavingOptions.IF_CHANGED),\n",
    "                                                should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, should_generate_all_plots=True, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_global_recompute=False,\n",
    "                                                enable_full_pipeline_in_ram=enable_full_pipeline_in_ram,\n",
    "                                                **multiprocessing_kwargs)\n",
    "\n",
    "\n",
    "# # Forced Reloading:\n",
    "# result_handler = BatchSessionCompletionHandler(force_reload_all=True,\n",
    "#                                                 session_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=SavingOptions.ALWAYS),\n",
    "#                                                 global_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=SavingOptions.ALWAYS),\n",
    "#                                                 should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE, force_global_recompute=True,\n",
    "#                                                 **multiprocessing_kwargs)\n",
    "\n",
    "\n",
    "active_post_run_callback_fn = result_handler.on_complete_success_execution_session\n",
    "# active_post_run_callback_fn = _temp_on_complete_success_execution_session\n",
    "\n",
    "\n",
    "## Specific Setup for 2023-09-28 Changes to LxC/SxC \"refinements\"\n",
    "result_handler.extended_computations_include_includelist = ['pf_computation', 'pfdt_computation', 'firing_rate_trends',\n",
    "                                                'pf_dt_sequential_surprise',\n",
    "                                                'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                'position_decoding_two_step', \n",
    "                                                'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                                'long_short_inst_spike_rate_groups',\n",
    "                                                'long_short_endcap_analysis',\n",
    "                                                ]\n",
    "\n",
    "\n",
    "basic_local_computations = ['pf_computation', 'pfdt_computation', 'firing_rate_trends',\n",
    "#                                                 'pf_dt_sequential_surprise',\n",
    "                                                # 'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                #'position_decoding_two_step', \n",
    "                                                ]\n",
    " \n",
    "# result_handler.extended_computations_include_includelist = ['long_short_inst_spike_rate_groups']\n",
    "\n",
    "\n",
    "# result_handler.enable_hdf5_output = True # output the HDF5 when done.\n",
    "# result_handler.override_existing_frs_index_values = True\n",
    "# result_handler.frs_index_inclusion_magnitude = 0.1\n",
    "\n",
    "result_handler.enable_hdf5_output = True\n",
    "result_handler.override_existing_frs_index_values = False\n",
    "\n",
    "\n",
    "## Execute with the custom arguments.\n",
    "global_batch_run.execute_all(force_reload=result_handler.force_reload_all, saving_mode=result_handler.saving_mode, skip_extended_batch_computations=True, post_run_callback_fn=active_post_run_callback_fn,\n",
    "                             fail_on_exception=False, included_session_contexts=included_session_contexts,\n",
    "                                                                                        **{'computation_functions_name_includelist': basic_local_computations,\n",
    "                                                                                            'active_session_computation_configs': None,\n",
    "                                                                                            'allow_processing_previously_completed': True}, **multiprocessing_kwargs) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 4m 39.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00a26903-ebf8-4b3d-b135-c83909074ed8",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/global_batch_result_2023-10-04-GL.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/global_batch_result_2023-10-04-GL.pkl... \tmoving new output at '/nfs/turbo/umms-kdiba/Data/20231004134512-global_batch_result_2023-10-04-GL.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/global_batch_result_2023-10-04-GL.pkl'\n",
      "done.\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: /nfs/turbo/umms-kdiba/Data/global_batch_output_2023-10-04-GL.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-08_14-26-15'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-09_1-22-43'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: /nfs/turbo/umms-kdiba/Data/global_batch_output_2023-10-04-GL.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: /nfs/turbo/umms-kdiba/Data/global_batch_output_2023-10-04-GL.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-12_15-55-31'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: /nfs/turbo/umms-kdiba/Data/global_batch_output_2023-10-04-GL.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-07_16-40-19'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-08_21-16-25'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: /nfs/turbo/umms-kdiba/Data/global_batch_output_2023-10-04-GL.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: /nfs/turbo/umms-kdiba/Data/global_batch_output_2023-10-04-GL.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-09_22-24-40'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-12_16-53-46'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: /nfs/turbo/umms-kdiba/Data/global_batch_output_2023-10-04-GL.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: /nfs/turbo/umms-kdiba/Data/global_batch_output_2023-10-04-GL.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-09_17-29-30'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-10_12-25-50'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: /nfs/turbo/umms-kdiba/Data/global_batch_output_2023-10-04-GL.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: /nfs/turbo/umms-kdiba/Data/global_batch_output_2023-10-04-GL.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-09_16-40-54'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-10_12-58-3'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: /nfs/turbo/umms-kdiba/Data/global_batch_output_2023-10-04-GL.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: /nfs/turbo/umms-kdiba/Data/global_batch_output_2023-10-04-GL.h5, with key: /kdiba/pin01/one/11-02_17-46-44/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '11-02_17-46-44'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '11-02_19-28-0'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: /nfs/turbo/umms-kdiba/Data/global_batch_output_2023-10-04-GL.h5, with key: /kdiba/pin01/one/11-02_19-28-0/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: /nfs/turbo/umms-kdiba/Data/global_batch_output_2023-10-04-GL.h5, with key: /kdiba/pin01/one/11-03_12-3-25/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '11-03_12-3-25'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Batch.runBatch.PipelineCompletionResult'> to file_path: /nfs/turbo/umms-kdiba/Data/global_batch_output_2023-10-04-GL.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/batch_result:\n",
      "a_field: long_laps\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/batch_result/long_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: long_replays\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/batch_result/long_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_laps\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/batch_result/short_laps\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "a_field: short_replays\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/batch_result/short_replays\n",
      "\t field is serializable! Calling a_value.to_hdf(...)...\n",
      "an_attribute_field: long_epoch_name\n",
      "an_attribute_field: short_epoch_name\n",
      "done outputting HDF file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: 'fet11-01_12-58-54'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    }
   ],
   "source": [
    "# Save to pickle:\n",
    "saveData(global_batch_result_file_path, global_batch_run) # Update the global batch run dictionary\n",
    "\n",
    "# Save to HDF5\n",
    "suffix = f'{BATCH_DATE_TO_USE}'\n",
    "## Build Pickle Path:\n",
    "file_path = global_data_root_parent_path.joinpath(f'global_batch_output_{suffix}.h5').resolve()\n",
    "global_batch_run.to_hdf(file_path,'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0981cde1",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>context</th>\n",
       "      <th>basedirs</th>\n",
       "      <th>status</th>\n",
       "      <th>errors</th>\n",
       "      <th>session_datetime</th>\n",
       "      <th>n_long_laps</th>\n",
       "      <th>n_long_replays</th>\n",
       "      <th>n_short_laps</th>\n",
       "      <th>n_short_replays</th>\n",
       "      <th>is_ready</th>\n",
       "      <th>global_computation_result_file</th>\n",
       "      <th>loaded_session_pickle_file</th>\n",
       "      <th>ripple_result_file</th>\n",
       "      <th>has_user_replay_annotations</th>\n",
       "      <th>has_user_grid_bin_bounds_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>kdiba_gor01_one_2006-6-08_14-26-15</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "      <td>40</td>\n",
       "      <td>279</td>\n",
       "      <td>40</td>\n",
       "      <td>224</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>kdiba_gor01_one_2006-6-09_1-22-43</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-09 01:22:43</td>\n",
       "      <td>46</td>\n",
       "      <td>179</td>\n",
       "      <td>40</td>\n",
       "      <td>142</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-12_15-55-31</td>\n",
       "      <td>kdiba_gor01_one_2006-6-12_15-55-31</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-12 15:55:31</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-07_16-40-19</td>\n",
       "      <td>kdiba_gor01_two_2006-6-07_16-40-19</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-07 16:40:19</td>\n",
       "      <td>42</td>\n",
       "      <td>212</td>\n",
       "      <td>40</td>\n",
       "      <td>333</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-08_21-16-25</td>\n",
       "      <td>kdiba_gor01_two_2006-6-08_21-16-25</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-08 21:16:25</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>62</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-09_22-24-40</td>\n",
       "      <td>kdiba_gor01_two_2006-6-09_22-24-40</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-09 22:24:40</td>\n",
       "      <td>51</td>\n",
       "      <td>106</td>\n",
       "      <td>43</td>\n",
       "      <td>406</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-12_16-53-46</td>\n",
       "      <td>kdiba_gor01_two_2006-6-12_16-53-46</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-12 16:53:46</td>\n",
       "      <td>41</td>\n",
       "      <td>59</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-4-09_17-29-30</td>\n",
       "      <td>kdiba_vvp01_one_2006-4-09_17-29-30</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-04-09 17:29:30</td>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>62</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-4-10_12-25-50</td>\n",
       "      <td>kdiba_vvp01_one_2006-4-10_12-25-50</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-04-10 12:25:50</td>\n",
       "      <td>50</td>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-4-09_16-40-54</td>\n",
       "      <td>kdiba_vvp01_two_2006-4-09_16-40-54</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-04-09 16:40:54</td>\n",
       "      <td>48</td>\n",
       "      <td>27</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-4-10_12-58-3</td>\n",
       "      <td>kdiba_vvp01_two_2006-4-10_12-58-3</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-04-10 12:58:03</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-02_17-46-44</td>\n",
       "      <td>kdiba_pin01_one_11-02_17-46-44</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-02 17:46:44</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-02_19-28-0</td>\n",
       "      <td>kdiba_pin01_one_11-02_19-28-0</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-02 19:28:00</td>\n",
       "      <td>56</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-03_12-3-25</td>\n",
       "      <td>kdiba_pin01_one_11-03_12-3-25</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-03 12:03:25</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>kdiba_pin01_one_fet11-01_12-58-54</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "      <td>315</td>\n",
       "      <td>330</td>\n",
       "      <td>163</td>\n",
       "      <td>139</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   format_name animal exper_name        session_name  \\\n",
       "1        kdiba  gor01        one  2006-6-08_14-26-15   \n",
       "2        kdiba  gor01        one   2006-6-09_1-22-43   \n",
       "4        kdiba  gor01        one  2006-6-12_15-55-31   \n",
       "6        kdiba  gor01        two  2006-6-07_16-40-19   \n",
       "8        kdiba  gor01        two  2006-6-08_21-16-25   \n",
       "9        kdiba  gor01        two  2006-6-09_22-24-40   \n",
       "10       kdiba  gor01        two  2006-6-12_16-53-46   \n",
       "12       kdiba  vvp01        one  2006-4-09_17-29-30   \n",
       "13       kdiba  vvp01        one  2006-4-10_12-25-50   \n",
       "31       kdiba  vvp01        two  2006-4-09_16-40-54   \n",
       "32       kdiba  vvp01        two   2006-4-10_12-58-3   \n",
       "52       kdiba  pin01        one      11-02_17-46-44   \n",
       "53       kdiba  pin01        one       11-02_19-28-0   \n",
       "54       kdiba  pin01        one       11-03_12-3-25   \n",
       "64       kdiba  pin01        one   fet11-01_12-58-54   \n",
       "\n",
       "                               context  \\\n",
       "1   kdiba_gor01_one_2006-6-08_14-26-15   \n",
       "2    kdiba_gor01_one_2006-6-09_1-22-43   \n",
       "4   kdiba_gor01_one_2006-6-12_15-55-31   \n",
       "6   kdiba_gor01_two_2006-6-07_16-40-19   \n",
       "8   kdiba_gor01_two_2006-6-08_21-16-25   \n",
       "9   kdiba_gor01_two_2006-6-09_22-24-40   \n",
       "10  kdiba_gor01_two_2006-6-12_16-53-46   \n",
       "12  kdiba_vvp01_one_2006-4-09_17-29-30   \n",
       "13  kdiba_vvp01_one_2006-4-10_12-25-50   \n",
       "31  kdiba_vvp01_two_2006-4-09_16-40-54   \n",
       "32   kdiba_vvp01_two_2006-4-10_12-58-3   \n",
       "52      kdiba_pin01_one_11-02_17-46-44   \n",
       "53       kdiba_pin01_one_11-02_19-28-0   \n",
       "54       kdiba_pin01_one_11-03_12-3-25   \n",
       "64   kdiba_pin01_one_fet11-01_12-58-54   \n",
       "\n",
       "                                             basedirs  \\\n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "9   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "10  /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "12  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "13  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "31  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "\n",
       "                            status errors    session_datetime  n_long_laps  \\\n",
       "1   SessionBatchProgress.COMPLETED   None 2006-06-08 14:26:15           40   \n",
       "2   SessionBatchProgress.COMPLETED   None 2006-06-09 01:22:43           46   \n",
       "4   SessionBatchProgress.COMPLETED   None 2006-06-12 15:55:31           40   \n",
       "6   SessionBatchProgress.COMPLETED   None 2006-06-07 16:40:19           42   \n",
       "8   SessionBatchProgress.COMPLETED   None 2006-06-08 21:16:25           40   \n",
       "9   SessionBatchProgress.COMPLETED   None 2006-06-09 22:24:40           51   \n",
       "10  SessionBatchProgress.COMPLETED   None 2006-06-12 16:53:46           41   \n",
       "12  SessionBatchProgress.COMPLETED   None 2006-04-09 17:29:30           51   \n",
       "13  SessionBatchProgress.COMPLETED   None 2006-04-10 12:25:50           50   \n",
       "31  SessionBatchProgress.COMPLETED   None 2006-04-09 16:40:54           48   \n",
       "32  SessionBatchProgress.COMPLETED   None 2006-04-10 12:58:03           40   \n",
       "52  SessionBatchProgress.COMPLETED   None 2009-11-02 17:46:44           54   \n",
       "53  SessionBatchProgress.COMPLETED   None 2009-11-02 19:28:00           56   \n",
       "54  SessionBatchProgress.COMPLETED   None 2009-11-03 12:03:25           50   \n",
       "64  SessionBatchProgress.COMPLETED   None 2009-11-01 12:58:54          315   \n",
       "\n",
       "    n_long_replays  n_short_laps  n_short_replays  is_ready  \\\n",
       "1              279            40              224      True   \n",
       "2              179            40              142      True   \n",
       "4               37            34               55      True   \n",
       "6              212            40              333      True   \n",
       "8               45            40               62      True   \n",
       "9              106            43              406      True   \n",
       "10              59            40               48      True   \n",
       "12              45            42               62      True   \n",
       "13              22            42               17      True   \n",
       "31              27            50               20      True   \n",
       "32              47            42               16      True   \n",
       "52              60            66               66      True   \n",
       "53              48            50               19      True   \n",
       "54              10            46                6      True   \n",
       "64             330           163              139      True   \n",
       "\n",
       "                       global_computation_result_file  \\\n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "9   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "10  /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "12  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "13  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "31  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "\n",
       "                           loaded_session_pickle_file  \\\n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "9   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "10  /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "12  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "13  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "31  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "\n",
       "                                   ripple_result_file  \\\n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "9   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "10  /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \n",
       "12  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "13  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \n",
       "31  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \n",
       "52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \n",
       "64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "\n",
       "    has_user_replay_annotations  has_user_grid_bin_bounds_annotations  \n",
       "1                          True                                  True  \n",
       "2                          True                                  True  \n",
       "4                          True                                  True  \n",
       "6                          True                                  True  \n",
       "8                          True                                  True  \n",
       "9                          True                                  True  \n",
       "10                         True                                  True  \n",
       "12                         True                                  True  \n",
       "13                         True                                  True  \n",
       "31                         True                                  True  \n",
       "32                         True                                  True  \n",
       "52                         True                                  True  \n",
       "53                         True                                  True  \n",
       "54                         True                                  True  \n",
       "64                         True                                  True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "batch_progress_df.batch_results.build_all_columns()\n",
    "good_only_batch_progress_df.batch_results.build_all_columns()\n",
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d62d4a",
   "metadata": {},
   "source": [
    "# Post-Hoc Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2fafe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "included_session_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab3e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "690f140f",
   "metadata": {},
   "source": [
    "# Across Sessions After Batching Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dce885b-5b99-4a7a-9f72-2eed2e45ae18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_file_metadata\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import get_file_str_if_file_exists\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import check_output_h5_files, copy_files_in_filelist_to_dest\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import ConcreteSessionFolder\n",
    "\n",
    "good_session_concrete_folders = [ConcreteSessionFolder(a_context, a_basedir) for a_context, a_basedir in zip(list(good_only_batch_progress_df.context.values), list(good_only_batch_progress_df.basedirs.values))]\n",
    "good_session_concrete_folders\n",
    "\n",
    "# good_only_batch_progress_df.batch_results\n",
    "# included_h5_paths = [get_file_str_if_file_exists(v.joinpath('output','pipeline_results.h5').resolve()) for v in list(good_only_batch_progress_df.basedirs.values)]\n",
    "# included_h5_paths = [a_dir.joinpath('output','pipeline_results.h5').resolve() for a_dir in included_session_batch_progress_df['basedirs']]\n",
    "included_h5_paths = [get_file_str_if_file_exists(v.pipeline_results_h5) for v in good_session_concrete_folders]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7261886",
   "metadata": {},
   "source": [
    "## Extract `across_sessions_instantaneous_fr_dict` from the computation outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3605b83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_sessions: 15\n",
      "global_batch_result_inst_fr_file_path: /nfs/turbo/umms-kdiba/Data/across_session_result_long_short_inst_firing_rate_2023-10-04-GL.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/across_session_result_long_short_inst_firing_rate_2023-10-04-GL.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/across_session_result_long_short_inst_firing_rate_2023-10-04-GL.pkl... \tmoving new output at '/nfs/turbo/umms-kdiba/Data/20231004134528-across_session_result_long_short_inst_firing_rate_2023-10-04-GL.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/across_session_result_long_short_inst_firing_rate_2023-10-04-GL.pkl'\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "# Get only the sessions with non-None results\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "\n",
    "# list(global_batch_run.session_batch_outputs.keys())\n",
    "\n",
    "# Somewhere in there there are `InstantaneousSpikeRateGroupsComputation` results to extract\n",
    "across_sessions_instantaneous_fr_dict = {} # InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "# good_session_batch_outputs = global_batch_run.session_batch_outputs\n",
    "\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "good_session_batch_outputs = {a_ctxt:a_result for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None}\n",
    "\n",
    "for a_ctxt, a_result in good_session_batch_outputs.items():\n",
    "    if a_result is not None:\n",
    "        # a_good_result = a_result.__dict__.get('across_sessions_batch_results', {}).get('inst_fr_comps', None)\n",
    "        a_good_result = a_result.across_session_results.get('inst_fr_comps', None)\n",
    "        if a_good_result is not None:\n",
    "            across_sessions_instantaneous_fr_dict[a_ctxt] = a_good_result\n",
    "            # print(a_result['across_sessions_batch_results']['inst_fr_comps'])\n",
    "            \n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "\n",
    "# When done, `result_handler.across_sessions_instantaneous_fr_dict` is now equivalent to what it would have been before. It can be saved using the normal `.save_across_sessions_data(...)`\n",
    "\n",
    "## Save the instantaneous firing rate results dict: (# Dict[IdentifyingContext] = InstantaneousSpikeRateGroupsComputation)\n",
    "AcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_instantaneous_fr_dict, global_data_root_parent_path=global_data_root_parent_path,\n",
    "                                                 inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl')\n",
    "\n",
    "# ## Save pickle:\n",
    "# inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "# global_batch_result_inst_fr_file_path = Path(global_data_root_parent_path).joinpath(inst_fr_output_filename).resolve() # Use Default\n",
    "# print(f'global_batch_result_inst_fr_file_path: {global_batch_result_inst_fr_file_path}')\n",
    "# # Save the all sessions instantaneous firing rate dict to the path:\n",
    "# saveData(global_batch_result_inst_fr_file_path, across_sessions_instantaneous_fr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a859bff-8cdb-4281-a64f-251d24db7cb9",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, table_key: /kdiba/gor01/one/2006-6-08_14-26-15/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/gor01/one/2006-6-08_14-26-15/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, table_key: /kdiba/gor01/one/2006-6-09_1-22-43/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/gor01/one/2006-6-09_1-22-43/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, table_key: /kdiba/gor01/one/2006-6-12_15-55-31/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/gor01/one/2006-6-12_15-55-31/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, table_key: /kdiba/gor01/two/2006-6-07_16-40-19/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/gor01/two/2006-6-07_16-40-19/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, table_key: /kdiba/gor01/two/2006-6-08_21-16-25/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/gor01/two/2006-6-08_21-16-25/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, table_key: /kdiba/gor01/two/2006-6-12_16-53-46/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/gor01/two/2006-6-12_16-53-46/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, table_key: /kdiba/vvp01/one/2006-4-09_17-29-30/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/vvp01/one/2006-4-09_17-29-30/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, table_key: /kdiba/vvp01/one/2006-4-10_12-25-50/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/vvp01/one/2006-4-10_12-25-50/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, table_key: /kdiba/vvp01/two/2006-4-09_16-40-54/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/vvp01/two/2006-4-09_16-40-54/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, table_key: /kdiba/vvp01/two/2006-4-10_12-58-3/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/vvp01/two/2006-4-10_12-58-3/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, table_key: /kdiba/pin01/one/11-02_17-46-44/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/pin01/one/11-02_17-46-44/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5, table_key: /kdiba/pin01/one/11-02_19-28-0/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/pin01/one/11-02_19-28-0/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5, table_key: /kdiba/pin01/one/11-03_12-3-25/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/pin01/one/11-03_12-3-25/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, table_key: /kdiba/pin01/one/fet11-01_12-58-54/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/pin01/one/fet11-01_12-58-54/neuron_identities/table``. Skipping.\n",
      "concatenating dataframes from 1 of 15 files\n",
      "concatenating dataframes from 15 of 15 files\n",
      "concatenating dataframes from 15 of 15 files\n",
      "a_name: neuron_identities_table\n",
      "writing /nfs/turbo/umms-kdiba/Data/2023-10-04-GL/neuron_identities_table.csv.\n",
      "writing /nfs/turbo/umms-kdiba/Data/2023-10-04-GL/neuron_identities_table.pkl.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/2023-10-04-GL/neuron_identities_table.pkl... done.\n",
      "a_name: long_short_fr_indicies_analysis_table\n",
      "writing /nfs/turbo/umms-kdiba/Data/2023-10-04-GL/long_short_fr_indicies_analysis_table.csv.\n",
      "writing /nfs/turbo/umms-kdiba/Data/2023-10-04-GL/long_short_fr_indicies_analysis_table.pkl.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/2023-10-04-GL/long_short_fr_indicies_analysis_table.pkl... done.\n",
      "a_name: neuron_replay_stats_table\n",
      "writing /nfs/turbo/umms-kdiba/Data/2023-10-04-GL/neuron_replay_stats_table.csv.\n",
      "writing /nfs/turbo/umms-kdiba/Data/2023-10-04-GL/neuron_replay_stats_table.pkl.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/2023-10-04-GL/neuron_replay_stats_table.pkl... done.\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionTables\n",
    "\n",
    "# neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_all_known_tables(included_session_contexts, included_h5_paths, should_restore_native_column_types=True, )\n",
    "\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_and_save_all_combined_tables(included_session_contexts, included_h5_paths, override_output_parent_path=global_data_root_parent_path, output_path_suffix=f'{BATCH_DATE_TO_USE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c3131ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>index</th>\n",
       "      <th>neuron_uid</th>\n",
       "      <th>session_uid</th>\n",
       "      <th>aclu</th>\n",
       "      <th>x_frs_index</th>\n",
       "      <th>y_frs_index</th>\n",
       "      <th>session_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>0</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|2</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.947513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>1</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|3</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.855006</td>\n",
       "      <td>-0.544194</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>2</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|4</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.972594</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>3</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|5</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.133418</td>\n",
       "      <td>-0.032454</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>4</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|6</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>6</td>\n",
       "      <td>0.433462</td>\n",
       "      <td>0.454120</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>26</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|28</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.567445</td>\n",
       "      <td>-0.172839</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>27</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|29</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.176580</td>\n",
       "      <td>0.089972</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>28</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|30</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.219618</td>\n",
       "      <td>-0.072261</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>29</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|31</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>31</td>\n",
       "      <td>0.314634</td>\n",
       "      <td>0.160301</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>30</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|32</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>32</td>\n",
       "      <td>0.467246</td>\n",
       "      <td>0.233702</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    format_name animal exper_name        session_name  index  \\\n",
       "0         kdiba  gor01        one  2006-6-08_14-26-15      0   \n",
       "1         kdiba  gor01        one  2006-6-08_14-26-15      1   \n",
       "2         kdiba  gor01        one  2006-6-08_14-26-15      2   \n",
       "3         kdiba  gor01        one  2006-6-08_14-26-15      3   \n",
       "4         kdiba  gor01        one  2006-6-08_14-26-15      4   \n",
       "..          ...    ...        ...                 ...    ...   \n",
       "882       kdiba  pin01        one   fet11-01_12-58-54     26   \n",
       "883       kdiba  pin01        one   fet11-01_12-58-54     27   \n",
       "884       kdiba  pin01        one   fet11-01_12-58-54     28   \n",
       "885       kdiba  pin01        one   fet11-01_12-58-54     29   \n",
       "886       kdiba  pin01        one   fet11-01_12-58-54     30   \n",
       "\n",
       "                               neuron_uid                         session_uid  \\\n",
       "0    kdiba|gor01|one|2006-6-08_14-26-15|2  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "1    kdiba|gor01|one|2006-6-08_14-26-15|3  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "2    kdiba|gor01|one|2006-6-08_14-26-15|4  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "3    kdiba|gor01|one|2006-6-08_14-26-15|5  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "4    kdiba|gor01|one|2006-6-08_14-26-15|6  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "..                                    ...                                 ...   \n",
       "882  kdiba|pin01|one|fet11-01_12-58-54|28   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "883  kdiba|pin01|one|fet11-01_12-58-54|29   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "884  kdiba|pin01|one|fet11-01_12-58-54|30   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "885  kdiba|pin01|one|fet11-01_12-58-54|31   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "886  kdiba|pin01|one|fet11-01_12-58-54|32   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "\n",
       "     aclu  x_frs_index  y_frs_index    session_datetime  \n",
       "0       2     0.947513     1.000000 2006-06-08 14:26:15  \n",
       "1       3    -0.855006    -0.544194 2006-06-08 14:26:15  \n",
       "2       4    -0.972594    -1.000000 2006-06-08 14:26:15  \n",
       "3       5     0.133418    -0.032454 2006-06-08 14:26:15  \n",
       "4       6     0.433462     0.454120 2006-06-08 14:26:15  \n",
       "..    ...          ...          ...                 ...  \n",
       "882    28    -0.567445    -0.172839 2009-11-01 12:58:54  \n",
       "883    29    -0.176580     0.089972 2009-11-01 12:58:54  \n",
       "884    30    -0.219618    -0.072261 2009-11-01 12:58:54  \n",
       "885    31     0.314634     0.160301 2009-11-01 12:58:54  \n",
       "886    32     0.467246     0.233702 2009-11-01 12:58:54  \n",
       "\n",
       "[887 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_short_fr_indicies_analysis_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "730e7f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>long_pf_peak_x</th>\n",
       "      <th>short_pf_peak_x</th>\n",
       "      <th>track_membership</th>\n",
       "      <th>long_non_replay_mean</th>\n",
       "      <th>short_non_replay_mean</th>\n",
       "      <th>non_replay_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>neuron_type</th>\n",
       "      <th>aclu</th>\n",
       "      <th>custom_frs_index</th>\n",
       "      <th>is_rate_extrema</th>\n",
       "      <th>is_refined_exclusive</th>\n",
       "      <th>is_refined_LxC</th>\n",
       "      <th>is_refined_SxC</th>\n",
       "      <th>session_uid</th>\n",
       "      <th>neuron_uid</th>\n",
       "      <th>session_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>212.160000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LEFT_ONLY</td>\n",
       "      <td>0.419960</td>\n",
       "      <td>0.114724</td>\n",
       "      <td>-0.305237</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>2</td>\n",
       "      <td>0.235886</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|2</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>136.160000</td>\n",
       "      <td>198.160000</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>0.275226</td>\n",
       "      <td>1.227759</td>\n",
       "      <td>0.952532</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.683602</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|3</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.160000</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.117397</td>\n",
       "      <td>0.834271</td>\n",
       "      <td>0.716874</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.981692</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|4</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>98.160000</td>\n",
       "      <td>202.160000</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>2.090985</td>\n",
       "      <td>1.844885</td>\n",
       "      <td>-0.246099</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.057305</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|5</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>26.129319</td>\n",
       "      <td>12.892497</td>\n",
       "      <td>-13.236821</td>\n",
       "      <td>...</td>\n",
       "      <td>intr</td>\n",
       "      <td>6</td>\n",
       "      <td>0.102215</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|6</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>179.403791</td>\n",
       "      <td>177.403791</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>0.892852</td>\n",
       "      <td>1.027642</td>\n",
       "      <td>0.134789</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.148122</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|28</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>59.403791</td>\n",
       "      <td>107.403791</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>0.837484</td>\n",
       "      <td>0.766268</td>\n",
       "      <td>-0.071216</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>29</td>\n",
       "      <td>0.041598</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|29</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>119.403791</td>\n",
       "      <td>127.403791</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>0.712330</td>\n",
       "      <td>0.577649</td>\n",
       "      <td>-0.134681</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.026850</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|30</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>217.403791</td>\n",
       "      <td>33.403791</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>0.902182</td>\n",
       "      <td>1.016473</td>\n",
       "      <td>0.114291</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>31</td>\n",
       "      <td>0.039185</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|31</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>63.403791</td>\n",
       "      <td>95.403791</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>0.946397</td>\n",
       "      <td>0.529446</td>\n",
       "      <td>-0.416951</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>32</td>\n",
       "      <td>0.141802</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|32</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    format_name animal exper_name        session_name  long_pf_peak_x  \\\n",
       "0         kdiba  gor01        one  2006-6-08_14-26-15      212.160000   \n",
       "1         kdiba  gor01        one  2006-6-08_14-26-15      136.160000   \n",
       "2         kdiba  gor01        one  2006-6-08_14-26-15             NaN   \n",
       "3         kdiba  gor01        one  2006-6-08_14-26-15       98.160000   \n",
       "4         kdiba  gor01        one  2006-6-08_14-26-15             NaN   \n",
       "..          ...    ...        ...                 ...             ...   \n",
       "882       kdiba  pin01        one   fet11-01_12-58-54      179.403791   \n",
       "883       kdiba  pin01        one   fet11-01_12-58-54       59.403791   \n",
       "884       kdiba  pin01        one   fet11-01_12-58-54      119.403791   \n",
       "885       kdiba  pin01        one   fet11-01_12-58-54      217.403791   \n",
       "886       kdiba  pin01        one   fet11-01_12-58-54       63.403791   \n",
       "\n",
       "     short_pf_peak_x track_membership  long_non_replay_mean  \\\n",
       "0                NaN        LEFT_ONLY              0.419960   \n",
       "1         198.160000           SHARED              0.275226   \n",
       "2         178.160000       RIGHT_ONLY              0.117397   \n",
       "3         202.160000           SHARED              2.090985   \n",
       "4                NaN           SHARED             26.129319   \n",
       "..               ...              ...                   ...   \n",
       "882       177.403791           SHARED              0.892852   \n",
       "883       107.403791           SHARED              0.837484   \n",
       "884       127.403791           SHARED              0.712330   \n",
       "885        33.403791           SHARED              0.902182   \n",
       "886        95.403791           SHARED              0.946397   \n",
       "\n",
       "     short_non_replay_mean  non_replay_diff  ...  neuron_type  aclu  \\\n",
       "0                 0.114724        -0.305237  ...          pyr     2   \n",
       "1                 1.227759         0.952532  ...          pyr     3   \n",
       "2                 0.834271         0.716874  ...          pyr     4   \n",
       "3                 1.844885        -0.246099  ...          pyr     5   \n",
       "4                12.892497       -13.236821  ...         intr     6   \n",
       "..                     ...              ...  ...          ...   ...   \n",
       "882               1.027642         0.134789  ...          pyr    28   \n",
       "883               0.766268        -0.071216  ...          pyr    29   \n",
       "884               0.577649        -0.134681  ...          pyr    30   \n",
       "885               1.016473         0.114291  ...          pyr    31   \n",
       "886               0.529446        -0.416951  ...          pyr    32   \n",
       "\n",
       "     custom_frs_index  is_rate_extrema  is_refined_exclusive  is_refined_LxC  \\\n",
       "0            0.235886            False                 False           False   \n",
       "1           -0.683602             True                 False           False   \n",
       "2           -0.981692             True                  True           False   \n",
       "3           -0.057305            False                 False           False   \n",
       "4            0.102215            False                 False           False   \n",
       "..                ...              ...                   ...             ...   \n",
       "882         -0.148122            False                 False           False   \n",
       "883          0.041598            False                 False           False   \n",
       "884         -0.026850            False                 False           False   \n",
       "885          0.039185            False                 False           False   \n",
       "886          0.141802            False                 False           False   \n",
       "\n",
       "     is_refined_SxC                         session_uid  \\\n",
       "0             False  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "1             False  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "2              True  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "3             False  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "4             False  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "..              ...                                 ...   \n",
       "882           False   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "883           False   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "884           False   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "885           False   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "886           False   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "\n",
       "                               neuron_uid    session_datetime  \n",
       "0    kdiba|gor01|one|2006-6-08_14-26-15|2 2006-06-08 14:26:15  \n",
       "1    kdiba|gor01|one|2006-6-08_14-26-15|3 2006-06-08 14:26:15  \n",
       "2    kdiba|gor01|one|2006-6-08_14-26-15|4 2006-06-08 14:26:15  \n",
       "3    kdiba|gor01|one|2006-6-08_14-26-15|5 2006-06-08 14:26:15  \n",
       "4    kdiba|gor01|one|2006-6-08_14-26-15|6 2006-06-08 14:26:15  \n",
       "..                                    ...                 ...  \n",
       "882  kdiba|pin01|one|fet11-01_12-58-54|28 2009-11-01 12:58:54  \n",
       "883  kdiba|pin01|one|fet11-01_12-58-54|29 2009-11-01 12:58:54  \n",
       "884  kdiba|pin01|one|fet11-01_12-58-54|30 2009-11-01 12:58:54  \n",
       "885  kdiba|pin01|one|fet11-01_12-58-54|31 2009-11-01 12:58:54  \n",
       "886  kdiba|pin01|one|fet11-01_12-58-54|32 2009-11-01 12:58:54  \n",
       "\n",
       "[887 rows x 29 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_replay_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c6d36e4-8358-4362-a381-4f6b08f2b72b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, table_key: /kdiba/gor01/one/2006-6-08_14-26-15/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/gor01/one/2006-6-08_14-26-15/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, table_key: /kdiba/gor01/one/2006-6-09_1-22-43/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/gor01/one/2006-6-09_1-22-43/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, table_key: /kdiba/gor01/one/2006-6-12_15-55-31/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/gor01/one/2006-6-12_15-55-31/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, table_key: /kdiba/gor01/two/2006-6-07_16-40-19/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/gor01/two/2006-6-07_16-40-19/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, table_key: /kdiba/gor01/two/2006-6-08_21-16-25/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/gor01/two/2006-6-08_21-16-25/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, table_key: /kdiba/gor01/two/2006-6-12_16-53-46/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/gor01/two/2006-6-12_16-53-46/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, table_key: /kdiba/vvp01/one/2006-4-09_17-29-30/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/vvp01/one/2006-4-09_17-29-30/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, table_key: /kdiba/vvp01/one/2006-4-10_12-25-50/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/vvp01/one/2006-4-10_12-25-50/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, table_key: /kdiba/vvp01/two/2006-4-09_16-40-54/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/vvp01/two/2006-4-09_16-40-54/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, table_key: /kdiba/vvp01/two/2006-4-10_12-58-3/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/vvp01/two/2006-4-10_12-58-3/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, table_key: /kdiba/pin01/one/11-02_17-46-44/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/pin01/one/11-02_17-46-44/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5, table_key: /kdiba/pin01/one/11-02_19-28-0/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/pin01/one/11-02_19-28-0/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5, table_key: /kdiba/pin01/one/11-03_12-3-25/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/pin01/one/11-03_12-3-25/neuron_identities/table``. Skipping.\n",
      "failed for file path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, table_key: /kdiba/pin01/one/fet11-01_12-58-54/neuron_identities/table. wth exception group ``/`` does not have a child named ``/kdiba/pin01/one/fet11-01_12-58-54/neuron_identities/table``. Skipping.\n",
      "concatenating dataframes from 1 of 15 files\n",
      "concatenating dataframes from 15 of 15 files\n",
      "concatenating dataframes from 15 of 15 files\n",
      "a_name: neuron_identities_table\n",
      "writing /home/halechr/repos/Spike3D/output/across_session_results/neuron_identities_table.csv.\n",
      "writing /home/halechr/repos/Spike3D/output/across_session_results/neuron_identities_table.pkl.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /home/halechr/repos/Spike3D/output/across_session_results/neuron_identities_table.pkl... done.\n",
      "a_name: long_short_fr_indicies_analysis_table\n",
      "writing /home/halechr/repos/Spike3D/output/across_session_results/long_short_fr_indicies_analysis_table.csv.\n",
      "writing /home/halechr/repos/Spike3D/output/across_session_results/long_short_fr_indicies_analysis_table.pkl.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /home/halechr/repos/Spike3D/output/across_session_results/long_short_fr_indicies_analysis_table.pkl... done.\n",
      "a_name: neuron_replay_stats_table\n",
      "writing /home/halechr/repos/Spike3D/output/across_session_results/neuron_replay_stats_table.csv.\n",
      "writing /home/halechr/repos/Spike3D/output/across_session_results/neuron_replay_stats_table.pkl.\n",
      "Saving (file mode 'w+b') saved session pickle file results : /home/halechr/repos/Spike3D/output/across_session_results/neuron_replay_stats_table.pkl... done.\n"
     ]
    }
   ],
   "source": [
    "AcrossSessionTables.save_out_to_combined_file(included_session_contexts, included_h5_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f39738fa-f8f3-46d2-a937-0fb08c0ccb43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-08_14-26-15_pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-08_14-26-15_loadedSessPickle.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-08_14-26-15_global_computation_results.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-09_1-22-43_pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-09_1-22-43_loadedSessPickle.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-09_1-22-43_global_computation_results.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-12_15-55-31_pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-12_15-55-31_loadedSessPickle.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-12_15-55-31_global_computation_results.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-07_16-40-19_pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-07_16-40-19_loadedSessPickle.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-07_16-40-19_global_computation_results.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-08_21-16-25_pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-08_21-16-25_loadedSessPickle.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-08_21-16-25_global_computation_results.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-09_22-24-40_pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-09_22-24-40_loadedSessPickle.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-09_22-24-40_global_computation_results.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-12_16-53-46_pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-12_16-53-46_loadedSessPickle.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-12_16-53-46_global_computation_results.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_one_2006-4-09_17-29-30_pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_one_2006-4-09_17-29-30_loadedSessPickle.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_one_2006-4-09_17-29-30_global_computation_results.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_one_2006-4-10_12-25-50_pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_one_2006-4-10_12-25-50_loadedSessPickle.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_one_2006-4-10_12-25-50_global_computation_results.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_two_2006-4-09_16-40-54_pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_two_2006-4-09_16-40-54_loadedSessPickle.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_two_2006-4-09_16-40-54_global_computation_results.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_two_2006-4-10_12-58-3_pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_two_2006-4-10_12-58-3_loadedSessPickle.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_two_2006-4-10_12-58-3_global_computation_results.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-02_17-46-44_pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-02_17-46-44_loadedSessPickle.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-02_17-46-44_global_computation_results.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-02_19-28-0_pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-02_19-28-0_loadedSessPickle.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-02_19-28-0_global_computation_results.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-03_12-3-25_pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-03_12-3-25_loadedSessPickle.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-03_12-3-25_global_computation_results.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_fet11-01_12-58-54_pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_fet11-01_12-58-54_loadedSessPickle.pkl'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl'): PosixPath('/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_fet11-01_12-58-54_global_computation_results.pkl')}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_dir = Path('output/across_session_results/2023-09-29').resolve()\n",
    "# target_dir = Path('/home/halechr/cloud/turbo/Pho/Output/across_session_results/2023-09-29').resolve()\n",
    "target_dir = Path('/home/halechr/cloud/turbo/Pho/Output/across_session_results/2023-10-04').resolve()\n",
    "copy_dict = ConcreteSessionFolder.backup_output_files(good_session_concrete_folders, target_dir=target_dir)\n",
    "copy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "135cb2d8-65b3-405b-a41b-22b2fa7cb28e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-08_14-26-15_pipeline_results.h5\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-08_14-26-15_loadedSessPickle.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-08_14-26-15_global_computation_results.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-09_1-22-43_pipeline_results.h5\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-09_1-22-43_loadedSessPickle.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-09_1-22-43_global_computation_results.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-12_15-55-31_pipeline_results.h5\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-12_15-55-31_loadedSessPickle.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_one_2006-6-12_15-55-31_global_computation_results.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-07_16-40-19_pipeline_results.h5\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-07_16-40-19_loadedSessPickle.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-07_16-40-19_global_computation_results.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-08_21-16-25_pipeline_results.h5\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-08_21-16-25_loadedSessPickle.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-08_21-16-25_global_computation_results.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-09_22-24-40_pipeline_results.h5\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-09_22-24-40_loadedSessPickle.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-09_22-24-40_global_computation_results.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-12_16-53-46_pipeline_results.h5\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-12_16-53-46_loadedSessPickle.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_gor01_two_2006-6-12_16-53-46_global_computation_results.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_one_2006-4-09_17-29-30_pipeline_results.h5\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_one_2006-4-09_17-29-30_loadedSessPickle.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_one_2006-4-09_17-29-30_global_computation_results.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_one_2006-4-10_12-25-50_pipeline_results.h5\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_one_2006-4-10_12-25-50_loadedSessPickle.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_one_2006-4-10_12-25-50_global_computation_results.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_two_2006-4-09_16-40-54_pipeline_results.h5\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_two_2006-4-09_16-40-54_loadedSessPickle.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_two_2006-4-09_16-40-54_global_computation_results.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_two_2006-4-10_12-58-3_pipeline_results.h5\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_two_2006-4-10_12-58-3_loadedSessPickle.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_vvp01_two_2006-4-10_12-58-3_global_computation_results.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-02_17-46-44_pipeline_results.h5\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-02_17-46-44_loadedSessPickle.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-02_17-46-44_global_computation_results.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-02_19-28-0_pipeline_results.h5\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-02_19-28-0_loadedSessPickle.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-02_19-28-0_global_computation_results.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-03_12-3-25_pipeline_results.h5\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-03_12-3-25_loadedSessPickle.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_11-03_12-3-25_global_computation_results.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_fet11-01_12-58-54_pipeline_results.h5\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_fet11-01_12-58-54_loadedSessPickle.pkl\"...\n",
      "done.\n",
      "copying \"/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl\"\n",
      "\t\t -> \"/nfs/turbo/umms-kdiba/Pho/Output/across_session_results/2023-10-04/kdiba_pin01_one_fet11-01_12-58-54_global_computation_results.pkl\"...\n",
      "done.\n",
      "done copying 45 of 45 files.\n"
     ]
    }
   ],
   "source": [
    "moved_files_dict_h5_files = copy_movedict(copy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e3954-15a4-449c-b927-56d5d79153c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_output_h5_files(included_h5_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34bd1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import copy_files_in_filelist_to_dest\n",
    "\n",
    "copy_files_in_filelist_to_dest(filelist_text_file=\"/nfs/turbo/umms-kdiba/Data/fileList_GreatLakes_HDF5_2023-09-29-GL.txt\", target_directory=Path('output/extracted_hdf5_files/').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import build_output_filelists\n",
    "\n",
    "included_session_basedirs = included_session_batch_progress_df['basedirs']\n",
    "output_filelist_transfer_dict = build_output_filelists(filelist_save_parent_path=global_data_root_parent_path, included_session_basedirs=included_session_basedirs, BATCH_DATE_TO_USE=BATCH_DATE_TO_USE, dest_computer_name='LabWorkstation')\n",
    "# output_filelist_transfer_dict = build_output_filelists(filelist_save_parent_path=global_data_root_parent_path, included_session_basedirs=included_session_basedirs, BATCH_DATE_TO_USE=BATCH_DATE_TO_USE, dest_computer_name='Apogee')\n",
    "output_filelist_transfer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ced5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(neuron_replay_stats_table['is_refined_LxC'])\n",
    "# np.isnan(neuron_replay_stats_table['is_refined_LxC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5dde09",
   "metadata": {},
   "source": [
    "## 2023-10-04 - Explore Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8615ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "session_identifier_key: str = 'session_name'\n",
    "# session_identifier_key: str = 'session_datetime'\n",
    "\n",
    "## !IMPORTANT! Count of the fields of interest using .value_counts(...) and converting to an explicit pd.DataFrame:\n",
    "# _out_value_counts_df: pd.DataFrame = neuron_replay_stats_table.value_counts(subset=['format_name', 'animal', 'session_name', 'session_datetime','track_membership'], normalize=False, sort=False, ascending=True, dropna=True).reset_index()\n",
    "# _out_value_counts_df.columns = ['format_name', 'animal', 'session_name', 'session_datetime', 'track_membership', 'count']\n",
    "_out_value_counts_df: pd.DataFrame = neuron_replay_stats_table.value_counts(subset=['format_name', 'animal', 'session_name', 'session_datetime','track_membership','is_refined_LxC', 'is_refined_SxC'], normalize=False, sort=False, ascending=True, dropna=True).reset_index()\n",
    "_out_value_counts_df.columns = ['format_name', 'animal', 'session_name', 'session_datetime', 'track_membership', 'is_refined_LxC', 'is_refined_SxC', 'count']\n",
    "_out_value_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af57298",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the time of the first session for each animal:\n",
    "first_session_time  = _out_value_counts_df.groupby(['animal']).agg(session_datetime_first=('session_datetime', 'first')).reset_index()\n",
    "\n",
    "## Subtract this initial time from all of the 'session_datetime' entries for each animal:\n",
    "# Merge the first session time back into the original DataFrame\n",
    "merged_df = pd.merge(_out_value_counts_df, first_session_time, on='animal')\n",
    "\n",
    "# Subtract this initial time from all of the 'session_datetime' entries for each animal\n",
    "merged_df['time_since_first_session'] = merged_df['session_datetime'] - merged_df['session_datetime_first']\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25bb1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "point_size = 8\n",
    "df = _out_value_counts_df.copy()\n",
    "animals = df['animal'].unique()\n",
    "track_memberships = df['track_membership'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(animals), figsize=(15, 5))\n",
    "\n",
    "for i, animal in enumerate(animals):\n",
    "\tax = axes[i]\n",
    "\tsubset_df = df[df['animal'] == animal]\n",
    "\t\n",
    "\tfor track_membership in track_memberships:\n",
    "\t\ttrack_subset_df = subset_df[subset_df['track_membership'] == track_membership]\n",
    "\t\tax.plot(track_subset_df['session_datetime'], track_subset_df['count'], label=f'Track: {track_membership}')\n",
    "\t\tax.scatter(track_subset_df['session_datetime'], track_subset_df['count'], s=point_size)\n",
    "\t\t\n",
    "\tax.set_title(f'Animal: {animal}')\n",
    "\tax.set_xlabel('Session Datetime')\n",
    "\tax.set_ylabel('Count')\n",
    "\tax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94408ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_value_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784fcc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## See if the number of cells decreases over re-exposures to the track\n",
    "df = _out_value_counts_df[_out_value_counts_df['animal'] == 'gor01']\n",
    "# df = _out_value_counts_df[_out_value_counts_df['animal'] == 'pin01']\n",
    "# df = _out_value_counts_df[_out_value_counts_df['animal'] == 'vvp01']\n",
    "\n",
    "# Sort by column: 'session_datetime' (ascending)\n",
    "df = df.sort_values(['session_datetime'])\n",
    "\n",
    "'LEFT_ONLY'\n",
    "\n",
    "# df.to_clipboard(index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a502f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the number of cells in each session of the animal:\n",
    "num_LxCs = df[df['track_membership'] == 'LEFT_ONLY']['count'].to_numpy()\n",
    "num_Shared = df[df['track_membership'] == 'SHARED']['count'].to_numpy()\n",
    "num_SxCs = df[df['track_membership'] == 'RIGHT_ONLY']['count'].to_numpy()\n",
    "\n",
    "num_TotalCs = num_LxCs + num_Shared + num_SxCs\n",
    "num_TotalCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The only safe point to align each session to is the switchpoint (the delta):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046bbce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each session can be expressed in terms of time from the start of the first session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f99ff8",
   "metadata": {},
   "source": [
    "# AcrossSessionsVisualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "\n",
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d92710",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "\n",
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de182953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "included_h5_paths = [a_dir.joinpath('output','pipeline_results.h5').resolve() for a_dir in included_session_batch_progress_df['basedirs']]\n",
    "included_global_computation_h5_paths = [a_dir.joinpath('output','global_computations.h5').resolve() for a_dir in included_session_batch_progress_df['basedirs']] \n",
    "included_h5_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc1ac7-5771-4cd5-94c6-7a6244eb8217",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "source": [
    "## Extract output files from all completed sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb0cd9-3e60-4425-9351-dfc903f3f067",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphocorehelpers.Filesystem.path_helpers import convert_filelist_to_new_parent\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import save_filelist_to_text_file\n",
    "\n",
    "\n",
    "# Save output filelist:\n",
    "\n",
    "# '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5'\n",
    "\n",
    "# kdiba_vvp01_two_2006-4-10_12-58-3\n",
    "# \toutputs_local ={'pkl': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl')}\n",
    "# \toutputs_global ={'pkl': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl'), 'hdf5': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5')}\n",
    "session_identifiers, pkl_output_paths, hdf5_output_paths = global_batch_run.build_output_files_lists()\n",
    "\n",
    "h5_filelist_path = global_data_root_parent_path.joinpath(f'fileList_Greatlakes_HDF5_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, src_filelist_HDF5_savepath = save_filelist_to_text_file(hdf5_output_paths, h5_filelist_path)\n",
    "\n",
    "pkls_filelist_path = global_data_root_parent_path.joinpath(f'fileList_Greatlakes_pkls_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, src_filelist_pkls_savepath = save_filelist_to_text_file(pkl_output_paths, pkls_filelist_path)\n",
    "\n",
    "# source_parent_path = Path(r'/media/MAX/cloud/turbo/Data')\n",
    "source_parent_path = Path(r'/nfs/turbo/umms-kdiba/Data')\n",
    "dest_parent_path = Path(r'/~/W/Data/')\n",
    "# # Build the destination filelist from the source_filelist and the two paths:\n",
    "filelist_source = hdf5_output_paths\n",
    "filelist_dest_paths = convert_filelist_to_new_parent(filelist_source, original_parent_path=source_parent_path, dest_parent_path=dest_parent_path)\n",
    "filelist_dest_paths\n",
    "\n",
    "dest_Apogee_h5_filelist_path = global_data_root_parent_path.joinpath(f'dest_fileList_Apogee_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, dest_filelist_savepath = save_filelist_to_text_file(filelist_dest_paths, dest_Apogee_h5_filelist_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28828512",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be651cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2023-07-14 - Load Saved across-sessions-data and testing Batch-computed inst_firing_rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28ad5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "# from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "# from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import list_of_dicts_to_dict_of_lists\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34549c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_batch_result_inst_fr_file_path: /nfs/turbo/umms-kdiba/Data/across_session_result_long_short_inst_firing_rate_2023-10-04-GL.pkl\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/across_session_result_long_short_inst_firing_rate_2023-10-04-GL.pkl... done.\n",
      "num_sessions: 15\n",
      "num_sessions: 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Load the saved across-session results:\n",
    "# inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "# inst_fr_output_filename = 'across_session_result_long_short_inst_firing_rate.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-07-21.pkl'\n",
    "# inst_fr_output_filename=f'across_session_result_handler_{BATCH_DATE_TO_USE}.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-08-09_Test.pkl'\n",
    "inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-10-04-GL.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a11886",
   "metadata": {},
   "outputs": [],
   "source": [
    "across_sessions_instantaneous_frs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cc1152c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_sessions: 15\n",
      "WARNING: missing 3 keys from context: ['animal', 'exper_name', 'session_name']. Building path anyway.\n",
      "register_output_file(output_path: /home/halechr/repos/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-10-04/kdiba/15_2_inst_FR_bar_graphs.png, ...)\n",
      "\t saved /home/halechr/repos/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-10-04/kdiba/15_2_inst_FR_bar_graphs.png\n",
      "WARNING: missing 3 keys from context: ['animal', 'exper_name', 'session_name']. Building path anyway.\n",
      "register_output_file(output_path: /home/halechr/repos/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-10-04/kdiba/15_2_inst_FR_bar_graphs.png, ...)\n",
      "\t saved /home/halechr/repos/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-10-04/kdiba/15_2_inst_FR_bar_graphs.png\n",
      "save_figure()!\n"
     ]
    }
   ],
   "source": [
    "## Hacks the `PaperFigureTwo` and `InstantaneousSpikeRateGroupsComputation` \n",
    "global_multi_session_context, _out_aggregate_fig_2 = AcrossSessionsVisualizations.across_sessions_bar_graphs(across_session_inst_fr_computation, num_sessions, enable_tiny_point_labels=False, enable_hover_labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bee4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_aggregate_fig_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381fcf5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "across_session_inst_fr_computation.LxC_scatter_props\n",
    "across_session_inst_fr_computation.SxC_scatter_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db1ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, InstantaneousFiringRatesDataframeAccessor, InstantaneousSpikeRateGroupsComputation, trackMembershipTypesEnum, trackExclusiveToMembershipTypeDict, trackExclusiveToMembershipTypeReverseDict\n",
    "\n",
    "## Specify the output file:\n",
    "common_file_path = Path('output/test_across_session_scatter_plot_new.h5')\n",
    "print(f'common_file_path: {common_file_path}')\n",
    "InstantaneousFiringRatesDataframeAccessor.add_results_to_inst_fr_results_table(curr_active_pipeline, common_file_path, file_mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45d728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the unique scatter plot dictionaries:\n",
    "across_session_contexts = list(across_sessions_instantaneous_fr_dict.keys())\n",
    "unique_animals = IdentifyingContext.find_unique_values(across_session_contexts)['animal'] # {'gor01', 'pin01', 'vvp01'}\n",
    "# Get number of animals to plot\n",
    "marker_list = [(5, i) for i in np.arange(len(unique_animals))] # [(5, 0), (5, 1), (5, 2)]\n",
    "scatter_props = [{'marker': mkr} for mkr in marker_list]  # Example, you should provide your own scatter properties\n",
    "scatter_props_dict = dict(zip(unique_animals, scatter_props))\n",
    "# {'pin01': {'marker': (5, 0)},\n",
    "#  'gor01': {'marker': (5, 1)},\n",
    "#  'vvp01': {'marker': (5, 2)}}\n",
    "scatter_props_dict\n",
    "\n",
    "# Pass a function that will return a set of kwargs for a given context\n",
    "def _return_scatter_props_fn(ctxt: IdentifyingContext):\n",
    "\t\"\"\" captures `scatter_props_dict` \"\"\"\n",
    "\tanimal_id = str(ctxt.animal)\n",
    "\treturn scatter_props_dict[animal_id]\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63258151",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=num_sessions) # some global context across all of the sessions, not sure what to put here.\n",
    "\n",
    "# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\n",
    "\n",
    "## Display the aggregate across sessions:\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn't save this info\n",
    "_out_fig_2.computation_result = across_session_inst_fr_computation # the result loaded from the file\n",
    "_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\n",
    "# Set callback, the only self-specific property\n",
    "# _out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)\n",
    "_out_fig_2.scatter_props_fn = _return_scatter_props_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LxC_aclus = _out_fig_2.computation_result.LxC_aclus\n",
    "SxC_aclus = _out_fig_2.computation_result.SxC_aclus\n",
    "\n",
    "LxC_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c498f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureOutputManager, FigureOutputLocation, ContextToPathMode\n",
    "\n",
    "registered_output_files = {}\n",
    "\n",
    "def output_figure(final_context: IdentifyingContext, fig, write_vector_format:bool=False, write_png:bool=True, debug_print=True):\n",
    "    \"\"\" outputs the figure using the provided context. \"\"\"\n",
    "    from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_and_write_to_file\n",
    "    def register_output_file(output_path, output_metadata=None):\n",
    "        \"\"\" registers a new output file for the pipeline \"\"\"\n",
    "        print(f'register_output_file(output_path: {output_path}, ...)')\n",
    "        registered_output_files[output_path] = output_metadata or {}\n",
    "\n",
    "    fig_out_man = FigureOutputManager(figure_output_location=FigureOutputLocation.DAILY_PROGRAMMATIC_OUTPUT_FOLDER, context_to_path_mode=ContextToPathMode.HIERARCHY_UNIQUE)\n",
    "    active_out_figure_paths = build_and_write_to_file(fig, final_context, fig_out_man, write_vector_format=write_vector_format, write_png=write_png, register_output_file_fn=register_output_file)\n",
    "    return active_out_figure_paths, final_context\n",
    "\n",
    "\n",
    "# Set callback, the only self-specific property\n",
    "_out_fig_2._pipeline_file_callback_fn = output_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17b920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\n",
    "\t\n",
    "_out_fig_2.perform_save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32781c8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Single Session testing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_out = global_batch_run.execute_session(session_context=curr_sess_context, force_reload=True, skip_extended_batch_computations=True, computation_functions_name_includelist =['_perform_baseline_placefield_computation'], active_session_computation_configs=None) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "_test_out\n",
    "\n",
    "# global_batch_run.execute_session(session_context=curr_sess_context, force_reload=True, skip_extended_batch_computations=True, **{'computation_functions_name_includelist': ['_perform_baseline_placefield_computation'], 'active_session_computation_configs': None}) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 23.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf2bb67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "full_good_dirs = [k for k, v in global_batch_run.session_batch_errors.items() if v is None]\n",
    "bad_dirs = [k for k, v in global_batch_run.session_batch_errors.items() if v is not None]\n",
    "full_good_dirs\n",
    "bad_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f73f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_batch_run.session_batch_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcad70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_run.session_batch_status\n",
    "global_batch_run.session_batch_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15faf2bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Get good sessions for use in the specific session processing notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed516134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf02efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get the list of sessions that are completely ready to process:\n",
    "full_good_ready_to_process_sessions = list(good_only_batch_progress_df['context'].to_numpy())\n",
    "full_good_ready_to_process_sessions\n",
    "# Get good sessions for use in the specific session processing notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ad809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run[\"good_sessions_list\"].extend(full_good_ready_to_process_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636e3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.stop()\n",
    "project.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf1322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\",\\n\".join([ctx.get_initialization_code_string() for ctx in full_good_ready_to_process_sessions])) # List definitions\n",
    "\n",
    "# [IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a4bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\ncurr_context = \".join([ctx.get_initialization_code_string() for ctx in full_good_ready_to_process_sessions])) # Line definitions\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5689d1d-6400-4f87-be0e-a184a1d5bee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82aedf-b024-4f07-b1a9-350730b4db8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "save_time = datetime.now()\n",
    " \n",
    "print(\"save_time =\", save_time)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = save_time.strftime(\"%Y-%m-%d_%I-%M%p\")\n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7bc6bd-5b34-41d0-b906-b0ad9927b08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get output file paths:\n",
    "completed_pipeline_filename = 'loadedSessPickle.pkl'\n",
    "completed_global_computations_filename = 'outputs/global_computation_results.pkl'\n",
    "\n",
    "full_good_ready_to_process_session_paths = list(good_only_batch_progress_df['basedirs'].to_numpy())\n",
    "session_paths_output_folders = [sess_path.joinpath('outputs').resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "\n",
    "completed_pipeline_file_paths = [sess_path.joinpath(completed_pipeline_filename).resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "completed_global_computations_file_paths = [sess_path.joinpath(completed_global_computations_filename).resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "completed_global_computations_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab75122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countable Additivity \n",
    "# Any countable collections of points is size 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af06e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
