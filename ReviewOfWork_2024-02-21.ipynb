{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:20.608442900Z",
     "start_time": "2023-11-16T23:21:20.217442100Z"
    },
    "collapsed": true,
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.3, the latest is 0.5.4.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_output_parent_folder: /home/halechr/repos/Spike3D/EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.Spike3D.pipeline.log\n",
      "DAY_DATE_STR: 2024-02-22, DAY_DATE_TO_USE: 2024-02-22\n",
      "NOW_DATETIME: 2024-02-22_0357PM, NOW_DATETIME_TO_USE: 2024-02-22_0357PM\n",
      "global_data_root_parent_path changed to /media/halechr/MAX/Data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4ab029f1954baab51c43971335877a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Data Root:', layout=Layout(width='auto'), options=(PosixPath('/media/halechr/MAX/Data'), PosixPath('/home/halechr/FastData'), PosixPath('/home/halechr/cloud/turbo/Data')), style=ToggleButtonsStyle(button_width='max-content'), tooltip='global_data_root_parent_path', value=PosixPath('/media/halechr/MAX/Data'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "# %xmode Verbose\n",
    "# %xmode context\n",
    "%pdb off\n",
    "%load_ext viztracer\n",
    "from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "from attrs import define, field, fields, Factory\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "import builtins\n",
    "\n",
    "import IPython\n",
    "from IPython.core.formatters import PlainTextFormatter\n",
    "from IPython import get_ipython\n",
    "\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "# Jupyter-lab enable printing for any line on its own (instead of just the last one in the cell)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# BEGIN PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "\n",
    "## IPython pprint\n",
    "from pyphocorehelpers.pprint import wide_pprint, wide_pprint_ipython, wide_pprint_jupyter, MAX_LINE_LENGTH\n",
    "\n",
    "# Override default pprint\n",
    "builtins.pprint = wide_pprint\n",
    "\n",
    "text_formatter: PlainTextFormatter = IPython.get_ipython().display_formatter.formatters['text/plain']\n",
    "text_formatter.max_width = MAX_LINE_LENGTH\n",
    "text_formatter.for_type(object, wide_pprint_jupyter)\n",
    "\n",
    "\n",
    "# END PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "from pyphocorehelpers.print_helpers import get_now_time_str, get_now_day_str\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path, file_uri_from_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field, custom_define\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin, HDF_Converter\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_subsession_neuron_differences, debug_print_ratemap, debug_print_spike_counts, debug_plot_2d_binning, print_aligned_columns\n",
    "from neuropy.utils.debug_helpers import parameter_sweeps, _plot_parameter_sweep, compare_placefields_info\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies, paired_incremental_sorting\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, CapturedException, document_active_variables\n",
    "\n",
    "## Pho Programming Helpers:\n",
    "import inspect\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter, TypePrintMode, print_keys_if_possible, debug_dump_object_member_shapes, print_value_overview_only, document_active_variables, CapturedException\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers, PythonDictionaryDefinitionFormat, MemoryManagement, inspect_callable_arguments, get_arguments_as_optional_dict, GeneratedClassDefinitionType, CodeConversion\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper, print_widget_hierarchy\n",
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative, dict_to_full_array\n",
    "doc_output_parent_folder: Path = Path('EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation').resolve() # ../.\n",
    "print(f\"doc_output_parent_folder: {doc_output_parent_folder}\")\n",
    "assert doc_output_parent_folder.exists()\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsResult, TrackTemplates, DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer, RankOrderResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses\n",
    "\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "# %matplotlib inline\n",
    "# %matplotlib auto\n",
    "\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget, render_colors\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "\n",
    "DAY_DATE_STR: str = date.today().strftime(\"%Y-%m-%d\")\n",
    "DAY_DATE_TO_USE = f'{DAY_DATE_STR}' # used for filenames throught the notebook\n",
    "print(f'DAY_DATE_STR: {DAY_DATE_STR}, DAY_DATE_TO_USE: {DAY_DATE_TO_USE}')\n",
    "\n",
    "NOW_DATETIME: str = get_now_rounded_time_str()\n",
    "NOW_DATETIME_TO_USE = f'{NOW_DATETIME}' # used for filenames throught the notebook\n",
    "print(f'NOW_DATETIME: {NOW_DATETIME}, NOW_DATETIME_TO_USE: {NOW_DATETIME_TO_USE}')\n",
    "\n",
    "\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import build_global_data_root_parent_path_selection_widget\n",
    "all_paths = [Path(r'/media/MAX/Data'), Path(r'/media/halechr/MAX/Data'), Path(r'/home/halechr/FastData'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')]\n",
    "global_data_root_parent_path = None\n",
    "def on_user_update_path_selection(new_path: Path):\n",
    "\tglobal global_data_root_parent_path\n",
    "\tnew_global_data_root_parent_path = new_path.resolve()\n",
    "\tglobal_data_root_parent_path = new_global_data_root_parent_path\n",
    "\tprint(f'global_data_root_parent_path changed to {global_data_root_parent_path}')\n",
    "\tassert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "\t\t\t\n",
    "global_data_root_parent_path_widget = build_global_data_root_parent_path_selection_widget(all_paths, on_user_update_path_selection)\n",
    "global_data_root_parent_path_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db844b",
   "metadata": {},
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f07773d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir: /media/halechr/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43\n",
      "Loading loaded session pickle file results : /media/halechr/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:NeuropyPipeline.__setstate__(state=\"{'pipeline_name': 'kdiba_pipeline', 'session_data_type': 'kdiba', '_stage': <pyphoplacecellanalysis.General.Pipeline.Stages.Display.DisplayPipelineStage object at 0x7f87015e25b0>}\")\n",
      "INFO:com.PhoHale.Spike3D.pipeline:select_filters(...) with: []\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Loading pickled pipeline success: /media/halechr/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "WARNING: No global_session or position passed, using old even/odd 'lap_dir' determination.\n",
      "using provided computation_functions_name_includelist: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing global computations...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:select_filters(...) with: []\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing global computations...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:select_filters(...) with: []\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing global computations...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:NeuropyPipeline.on_stage_changed(new_stage=\"PipelineStage.Displayed\")\n",
      "WARNING:com.PhoHale.Spike3D.pipeline:WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # DONE. Very good. Many good Pfs, many good replays.\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # DONE, might be the BEST SESSION, good example session with lots of place cells, clean replays, and clear bar graphs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays ---- VERY weird effect of the replays, a sharp drop to strongly negative values more than 3/4 through the experiment.\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD, 2023-07-14, unsure why still.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays! Interesting see-saw!\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE, Added replay selections. Very \"jumpy\" between the starts and ends of the track.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # 2024-01-10 new RANKORDER APOGEE | DONE, Added replay selections. A TON of putative replays in general, most bad, but some good. LOOKIN GOOD!\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='twolong_LR_pf1Dsession_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # DONE, good. Many good pfs, many good replays. Noticed very strange jumping off the track in the 3D behavior/spikes viewer. Is there something wrong with this session?\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE, good?, replays selected, few --- \"ZeroDivisionError: float division by zero\"\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE, very few replays\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3') ### KeyError: 'maze1_odd'\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5') ### \n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # DONE, replays selected, quite a few replays but few are very good.\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25')\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "# \n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination', 'pf_computation',\n",
    "                                            #    'pfdt_computation',\n",
    "                                                'firing_rate_trends',\n",
    "                                                # 'pf_dt_sequential_surprise', \n",
    "                                            #    'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                # 'position_decoding_two_step', \n",
    "                                            #    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                            #     'long_short_inst_spike_rate_groups',\n",
    "                                            #     'long_short_endcap_analysis',\n",
    "                                            # 'split_to_directional_laps',\n",
    "]\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "\n",
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "188ed6fa",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DirectionalLaps',\n",
       " 'DirectionalMergedDecoders',\n",
       " 'RankOrder',\n",
       " 'long_short_leave_one_out_decoding_analysis',\n",
       " 'short_long_pf_overlap_analyses',\n",
       " 'long_short_fr_indicies_analysis',\n",
       " 'jonathan_firing_rate_analysis',\n",
       " 'long_short_post_decoding',\n",
       " 'long_short_inst_spike_rate_groups',\n",
       " 'long_short_endcap',\n",
       " 'DirectionalDecodersDecoded']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(curr_active_pipeline.global_computation_results.computed_data.keys())\n",
    "\n",
    "\n",
    "# 2024-01-22 ERROR: when the pipeline is manually saved, its global_computations seem to be saved to the pickle too. After modifying how global computations are loaded from pickle, the following global computations code block no longer appropriately overwrites the existing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd94b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dropped_keys, local_dropped_keys = curr_active_pipeline.perform_drop_computed_result(computed_data_keys_to_drop=['DirectionalLaps', 'DirectionalMergedDecoders', 'RankOrder', 'DirectionalDecodersDecoded'], debug_print=True)\n",
    "# global_dropped_keys, local_dropped_keys = curr_active_pipeline.perform_drop_computed_result(computed_data_keys_to_drop=[k for k in list(curr_active_pipeline.global_computation_results.computed_data.keys())], debug_print=True) # drop all global keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_problem_result_names = ['directional_decoders_evaluate_epochs', 'directional_decoders_decode_continuous']\n",
    "pickle_problem_global_result_key_names = ['DirectionalDecodersDecoded', 'DirectionalDecodersEpochsEvaluations']\n",
    "global_dropped_keys, local_dropped_keys = curr_active_pipeline.perform_drop_computed_result(computed_data_keys_to_drop=pickle_problem_global_result_key_names, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acba46b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:40.574268400Z",
     "start_time": "2023-11-16T23:21:35.966373700Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading loaded session pickle file results : /media/halechr/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl... done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['DirectionalLaps',\n",
       "  'DirectionalMergedDecoders',\n",
       "  'RankOrder',\n",
       "  'long_short_leave_one_out_decoding_analysis',\n",
       "  'short_long_pf_overlap_analyses',\n",
       "  'long_short_fr_indicies_analysis',\n",
       "  'jonathan_firing_rate_analysis',\n",
       "  'long_short_post_decoding',\n",
       "  'long_short_inst_spike_rate_groups',\n",
       "  'long_short_endcap',\n",
       "  'DirectionalDecodersDecoded'],\n",
       " ['DirectionalLaps',\n",
       "  'DirectionalMergedDecoders',\n",
       "  'RankOrder',\n",
       "  'long_short_leave_one_out_decoding_analysis',\n",
       "  'short_long_pf_overlap_analyses',\n",
       "  'long_short_fr_indicies_analysis',\n",
       "  'jonathan_firing_rate_analysis',\n",
       "  'long_short_post_decoding',\n",
       "  'long_short_inst_spike_rate_groups',\n",
       "  'long_short_endcap',\n",
       "  'DirectionalDecodersDecoded'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included includelist is specified: ['lap_direction_determination', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze_any\"\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('lap_direction_determination', 'maze_any'), ('split_to_directional_laps', 'maze_any'), ('merged_directional_placefields', 'maze_any'), ('rank_order_shuffle_analysis', 'maze_any'), ('long_short_decoding_analyses', 'maze_any'), ('short_long_pf_overlap_analyses', 'maze_any'), ('long_short_fr_indicies_analyses', 'maze_any'), ('jonathan_firing_rate_analysis', 'maze_any'), ('long_short_post_decoding', 'maze_any'), ('long_short_inst_spike_rate_groups', 'maze_any'), ('long_short_endcap_analysis', 'maze_any')].\n",
      "\n",
      "\n",
      "!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"\n",
      "\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### GLOBAL COMPUTATIONS:\n",
    "extended_computations_include_includelist=['lap_direction_determination', #'pf_computation', 'firing_rate_trends',# 'pfdt_computation',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "    #  'ratemap_peaks_prominence2d',\n",
    "    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', \n",
    "    'long_short_post_decoding', # #TODO 2024-01-19 05:49: - [ ] `'long_short_post_decoding' is broken for some reason `AttributeError: 'NoneType' object has no attribute 'active_filter_epochs'``\n",
    "    'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    # 'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'merged_directional_placefields',\n",
    "    'rank_order_shuffle_analysis',\n",
    "    # 'directional_decoders_decode_continuous',\n",
    "    # 'directional_decoders_evaluate_epochs'\n",
    "] # do only specified\n",
    "\n",
    "force_recompute_override_computations_includelist = None\n",
    "# force_recompute_override_computations_includelist = ['merged_directional_placefields']\n",
    "# force_recompute_override_computations_includelist = ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis'] # , 'directional_decoders_decode_continuous'\n",
    "# force_recompute_override_computations_includelist = ['directional_decoders_decode_continuous'] # \n",
    "\n",
    "\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # curr_active_pipeline.load_pickled_global_computation_results()\n",
    "        curr_active_pipeline.load_pickled_global_computation_results(allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist) # is new\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# except Exception as e:\n",
    "#     exception_info = sys.exc_info()\n",
    "#     e = CapturedException(e, exception_info)\n",
    "#     print(f'second half threw: {e}')\n",
    "\n",
    "# 4m 5.2s for inst fr computations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d4f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47820977",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extended_computations_include_includelist=['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "    #  'ratemap_peaks_prominence2d',\n",
    "    'long_short_decoding_analyses',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    # 'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'merged_directional_placefields',\n",
    "    'rank_order_shuffle_analysis',\n",
    "    # 'directional_decoders_decode_continuous',\n",
    "    # 'directional_decoders_evaluate_epochs',\n",
    "] # do only specified\n",
    "\n",
    "# force_recompute_override_computations_includelist = ['split_to_directional_laps',\n",
    "#     # 'merged_directional_placefields',\n",
    "#     # 'directional_decoders_decode_continuous',\n",
    "# ]\n",
    "force_recompute_override_computations_includelist = None\n",
    "\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "newly_computed_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.reload_default_computation_functions()\n",
    "# force_recompute_override_computations_includelist = ['_decode_continuous_using_directional_decoders']\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_decode_continuous_using_directional_decoders'], force_recompute_override_computations_includelist=force_recompute_override_computations_includelist,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_decode_continuous_using_directional_decoders'], computation_kwargs_list=[{'time_bin_size': 0.025}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(extended_computations_include_includelist=['_decode_continuous_using_directional_decoders'], computation_kwargs_list=[{'time_bin_size': 0.02}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f372737e",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_bin_size: 3.8054171165052444\n",
      "laps_decoding_time_bin_size: 0.025, ripple_decoding_time_bin_size: 0.025, pos_bin_size: 3.8054171165052444\n",
      "pos_bin_size: 3.8054171165052444\n",
      "laps_decoding_time_bin_size: 0.025, ripple_decoding_time_bin_size: 0.025, pos_bin_size: 3.8054171165052444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:329: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:329: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:175: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:175: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:175: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:175: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 50/84\n",
      "\tagreeing_rows_ratio: 0.5952380952380952\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 145/412\n",
      "\tagreeing_rows_ratio: 0.35194174757281554\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 77/84\n",
      "\tagreeing_rows_ratio: 0.9166666666666666\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 121/412\n",
      "\tagreeing_rows_ratio: 0.2936893203883495\n"
     ]
    }
   ],
   "source": [
    "# curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_evaluate_epochs'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77a1538b",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "ripple_decoding_time_bin_size = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "# New items:\n",
    "decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "# Weighted correlations:\n",
    "laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "# Pearson's correlations:\n",
    "laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# laps_simple_pf_pearson_merged_df\n",
    "# ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "## Drop rows where all are missing\n",
    "corr_column_names = ['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr']\n",
    "# ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='all') # 350/412 rows\n",
    "filtered_laps_simple_pf_pearson_merged_df = laps_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "filtered_ripple_simple_pf_pearson_merged_df = ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "\n",
    "## Update the `decoder_ripple_filter_epochs_decoder_result_dict` with the included epochs:\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs\n",
    "decoder_ripple_filter_epochs_decoder_result_dict = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_ripple_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988097ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_laps_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a95450",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07575164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_csvs\n",
    "# collected_outputs_path = Path('/nfs/turbo/umms-kdiba/Data/Output/collected_outputs').resolve() # Linux\n",
    "# collected_outputs_path: Path = Path('/home/halechr/cloud/turbo/Data/Output/collected_outputs').resolve() # GreatLakes\n",
    "collected_outputs_path = Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\output\\collected_outputs').resolve() # Apogee\n",
    "assert collected_outputs_path.exists()\n",
    "\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_output_csv_paths = directional_decoders_epochs_decode_result.export_csvs(parent_output_path=collected_outputs_path.resolve(), active_context=active_context, session_name=curr_session_name, curr_session_t_delta=t_delta)\n",
    "_output_csv_paths\n",
    "\n",
    "# {'laps_weighted_corr_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(laps_weighted_corr_merged_df)_tbin-0.025.csv'),\n",
    "#  'ripple_weighted_corr_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(ripple_weighted_corr_merged_df)_tbin-0.025.csv'),\n",
    "#  'laps_simple_pf_pearson_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(laps_simple_pf_pearson_merged_df)_tbin-0.025.csv'),\n",
    "#  'ripple_simple_pf_pearson_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(ripple_simple_pf_pearson_merged_df)_tbin-0.025.csv')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ab89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalLapsResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results() # newly_computed_values: [('pfdt_computation', 'maze_any')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7af96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_save_folder, split_save_paths, split_save_output_types, failed_keys = curr_active_pipeline.save_split_global_computation_results(debug_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77babf98",
   "metadata": {},
   "source": [
    "## Continue Saving/Exporting stuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a869b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f06d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE) ## #TODO 2024-02-16 14:25: - [ ] PicklingError: Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x7fd35e66b700>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell\n",
    "# curr_active_pipeline.save_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693db067",
   "metadata": {},
   "source": [
    "# Pho Interactive Pipeline Jupyter Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e275e3bb",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4bff60da0e452e80ee4e837eb74a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Box(children=(Label(value='session path:', layout=Layout(width='auto')), Label(value='/media/halechr/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output', layout=Layout(flex='1 1 auto', margin='2px', width='auto')), Button(button_style='info', description='Copy', layout=Layout(flex='0 1 auto', margin='1px', width='auto'), style=ButtonStyle(), tooltip='Copy to Clipboard'), Button(button_style='info', description='Reveal', icon='folder-tree', layout=Layout(flex='0 1 auto', margin='1px', width='auto'), style=ButtonStyle(), tooltip='Reveal in System Explorer')), layout=Layout(align_items='stretch', display='flex', flex_flow='row', width='70%')), HBox(children=(Button(description='Output Folder', style=ButtonStyle()), Button(description='global pickle', style=ButtonStyle()), Button(description='pipeline pickle', style=ButtonStyle()), Button(description='.h5 export', style=ButtonStyle()), Button(description='TEST - Dialog', style=ButtonStyle()), Button(description='Save Pipeline', style=ButtonStyle()))), HBox(children=(Button(description='Reload display functions...', style=ButtonStyle()), Button(description='Reload computation functions...', style=ButtonStyle()))), ToggleButton(value=True, description='Figures Displaying')))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "\n",
    "_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\n",
    "# display(_pipeline_jupyter_widget)\n",
    "_pipeline_jupyter_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe54599",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a533ba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:40.700275900Z",
     "start_time": "2023-11-16T23:21:40.584273Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1029.316608761903, 1737.1968310000375)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "\n",
    "assert short_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "assert long_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "t_start, t_delta, t_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b35196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have several python variables I want to print: t_start, t_delta, t_end\n",
    "# I want to generate a print statement that explicitly lists the variable name prior to its value like `print(f't_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')`\n",
    "# Currently I have to t_start, t_delta, t_end\n",
    "curr_active_pipeline.get_session_context()\n",
    "\n",
    "print(f'{curr_active_pipeline.session_name}:\\tt_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9071e94f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:43.601382Z",
     "start_time": "2023-11-16T23:21:40.702275600Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "WARNING: PAPER_FIGURE_figure_1_add_replay_epoch_rasters(...): no user-assigned manually labeled replay epochs. Reeturning all epochs.\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n"
     ]
    }
   ],
   "source": [
    "## long_short_decoding_analyses:\n",
    "from attrs import astuple\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import LeaveOneOutDecodingAnalysis\n",
    "\n",
    "curr_long_short_decoding_analyses: LeaveOneOutDecodingAnalysis = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global \n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "## Get global `long_short_fr_indicies_analysis`:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n",
    "long_short_fr_indicies_df = long_short_fr_indicies_analysis_results['long_short_fr_indicies_df']\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result.Flat_epoch_time_bins_mean, expected_v_observed_result.Flat_decoder_time_bin_centers, expected_v_observed_result.num_neurons, expected_v_observed_result.num_timebins_in_epoch, expected_v_observed_result.num_total_flat_timebins, expected_v_observed_result.is_short_track_epoch, expected_v_observed_result.is_long_track_epoch, expected_v_observed_result.short_short_diff, expected_v_observed_result.long_long_diff\n",
    "\n",
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.05)\n",
    "\n",
    "## Update long_exclusive/short_exclusive properties with `long_short_fr_indicies_df`\n",
    "# long_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n",
    "# short_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c49f5d4f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Most popular\n",
    "# long_LR_name, short_LR_name, long_RL_name, short_RL_name, global_any_name\n",
    "\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7104fc37",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum_inclusion_fr_Hz: 5.0\n",
      "included_qclu_values: [1, 2]\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalMergedDecodersResult, DirectionalLapsResult, DirectionalDecodersDecodedResult\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "directional_merged_decoders_result: DirectionalMergedDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']   \n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "included_qclu_values: float = rank_order_results.included_qclu_values\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912656a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "\n",
    "## UNPACK HERE via direct property access:\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "ripple_decoding_time_bin_size = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "# New items:\n",
    "decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "# Weighted correlations:\n",
    "laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "# Pearson's correlations:\n",
    "laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "238f67cb",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previously_decoded time_bin_sizes: [0.025]\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersDecodedResult\n",
    "\n",
    "directional_decoders_decode_result: DirectionalDecodersDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "spikes_df = directional_decoders_decode_result.spikes_df\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "\n",
    "most_recent_time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# most_recent_time_bin_size\n",
    "most_recent_continuously_decoded_dict = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\n",
    "# most_recent_continuously_decoded_dict\n",
    "\n",
    "## Adds in the 'pseudo2D' decoder in:\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# time_bin_size: float = 0.01\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict = continuously_decoded_result_cache_dict[time_bin_size]\n",
    "pseudo2D_decoder_continuously_decoded_result = continuously_decoded_dict.get('pseudo2D', None)\n",
    "if pseudo2D_decoder_continuously_decoded_result is None:\n",
    "\t# compute here...\n",
    "\t## Currently used for both cases to decode:\n",
    "\tt_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\tsingle_global_epoch_df: pd.DataFrame = pd.DataFrame({'start': [t_start], 'stop': [t_end], 'label': [0]}) # Build an Epoch object containing a single epoch, corresponding to the global epoch for the entire session:\n",
    "\tsingle_global_epoch: Epoch = Epoch(single_global_epoch_df)\n",
    "\tspikes_df = directional_decoders_decode_result.spikes_df\n",
    "\tpseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = pseudo2D_decoder.decode_specific_epochs(spikes_df=deepcopy(spikes_df), filter_epochs=single_global_epoch, decoding_time_bin_size=time_bin_size, debug_print=False)\n",
    "\tcontinuously_decoded_dict['pseudo2D'] = pseudo2D_decoder_continuously_decoded_result\n",
    "\tcontinuously_decoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa2dc5fe",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# NEW 2023-11-22 method: Get the templates (which can be filtered by frate first) and the from those get the decoders):        \n",
    "# track_templates: TrackTemplates = directional_laps_results.get_shared_aclus_only_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # shared-only\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only\n",
    "long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = track_templates.get_decoders()\n",
    "\n",
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n",
    "\n",
    "# `LongShortStatsItem` form (2024-01-02):\n",
    "# LR_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "# RL_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n",
    "LR_results_long_short_z_diffs = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "RL_results_long_short_z_diff = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260739a4f36c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_burst_intervals = curr_active_pipeline.computation_results[global_epoch_name].computed_data['burst_detection']['burst_intervals']\n",
    "# active_burst_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a1c6006aba5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Entropy/Surprise Results:\n",
    "active_extended_stats = global_results['extended_stats']\n",
    "active_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise'] # DynamicParameters\n",
    "historical_snapshots = active_relative_entropy_results['historical_snapshots']\n",
    "post_update_times: np.ndarray = active_relative_entropy_results['post_update_times'] # (4152,) = (n_post_update_times,)\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals: np.ndarray = active_relative_entropy_results['time_intervals']\n",
    "surprise_time_bin_duration = (post_update_times[2]-post_update_times[1])\n",
    "long_short_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "flat_relative_entropy_results: np.ndarray = active_relative_entropy_results['flat_relative_entropy_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_results: np.ndarray = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_across_all_positions: np.ndarray = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "flat_surprise_across_all_positions: np.ndarray = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\n",
    "## Get the placefield dt matrix:\n",
    "if 'snapshot_occupancy_weighted_tuning_maps' not in active_relative_entropy_results:\n",
    "\t## Compute it if missing:\n",
    "\toccupancy_weighted_tuning_maps_over_time = np.stack([placefield_snapshot.occupancy_weighted_tuning_maps_matrix for placefield_snapshot in historical_snapshots.values()])\n",
    "\tactive_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] = occupancy_weighted_tuning_maps_over_time\n",
    "else:\n",
    "\toccupancy_weighted_tuning_maps_over_time = active_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] # (n_post_update_times, n_neurons, n_xbins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554d3bf5955d9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8624c62d5c18c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "## long_short_endcap_analysis: checks for cells localized to the endcaps that have their placefields truncated after shortening the track\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "# disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "# trivially_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "# significant_distant_remapping_endcap_aclus\n",
    "appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n",
    "# appearing_aclus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426c292d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Saving/Loading `DirectionalLaps_2Hz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed6c50e",
   "metadata": {
    "tags": [
     "save",
     "persistance"
    ]
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import save_rank_order_results\n",
    "\n",
    "# DAY_DATE_STR: str = date.today().strftime(\"%Y-%m-%d\")\n",
    "# DAY_DATE_TO_USE = f'{DAY_DATE_STR}' # used for filenames throught the notebook\n",
    "# print(f'DAY_DATE_STR: {DAY_DATE_STR}, DAY_DATE_TO_USE: {DAY_DATE_TO_USE}')\n",
    "\n",
    "# NOW_DATETIME: str = get_now_rounded_time_str()\n",
    "# NOW_DATETIME_TO_USE = f'{NOW_DATETIME}' # used for filenames throught the notebook\n",
    "# print(f'NOW_DATETIME: {NOW_DATETIME}, NOW_DATETIME_TO_USE: {NOW_DATETIME_TO_USE}')\n",
    "\n",
    "formatted_time = get_now_rounded_time_str()\n",
    "print(formatted_time)\n",
    "save_rank_order_results(curr_active_pipeline, day_date=f\"{formatted_time}\") # \"2024-01-02_301pm\" \"2024-01-02_322pm\" 322pm # \"2024-01-02_301pm\" \"2024-01-02_322pm\" 322pm\n",
    "# '2024-01-09_0125PM-minimum_inclusion_fr-5-included_qclu_values-[1, 2]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_path = Path('/media/MAX/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/').resolve()\n",
    "# /media/halechr/MAX/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/2024-02-16_0427PM-minimum_inclusion_fr-5-included_qclu_values-[1, 2]DirectionalMergedDecoders.pkl\n",
    "sorted(search_path.glob(f\"{DAY_DATE_TO_USE}*\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da8a7c",
   "metadata": {
    "tags": [
     "load"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import SaveStringGenerator\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import loadData\n",
    "\n",
    "# Load the data from a file into the pipeline:\n",
    "# out_filename_str: str = '2023-12-11-minimum_inclusion_fr_Hz_2_included_qclu_values_1-2_' # specific\n",
    "\n",
    "minimum_inclusion_fr_Hz: float = 5.0\n",
    "included_qclu_values: List[int] = [1,2]\n",
    "out_filename_str = SaveStringGenerator.generate_save_suffix(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values, day_date=f'{DAY_DATE_TO_USE}_11am') # '2023-12-21_349am'\n",
    "# out_filename_str = SaveStringGenerator.generate_save_suffix(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values, day_date='2023-12-22_312pm') # '2023-12-21_349am'\n",
    "print(f'out_filename_str: \"{out_filename_str}\"')\n",
    "# day_date_str: str = '2023-12-11_with_tuple_newer_'\n",
    "# day_date_str: str = ''\n",
    "directional_laps_output_path = curr_active_pipeline.get_output_path().joinpath(f'{out_filename_str}DirectionalLaps.pkl').resolve()\n",
    "assert directional_laps_output_path.exists()\n",
    "# loaded_directional_laps, loaded_rank_order = loadData(directional_laps_output_path)\n",
    "loaded_directional_laps = loadData(directional_laps_output_path)\n",
    "assert (loaded_directional_laps is not None)\n",
    "# assert (loaded_rank_order is not None)\n",
    "\n",
    "rank_order_output_path = curr_active_pipeline.get_output_path().joinpath(f'{out_filename_str}RankOrder.pkl').resolve()\n",
    "loaded_rank_order = loadData(rank_order_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a82b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the loaded data to the pipeline:\n",
    "curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'], curr_active_pipeline.global_computation_results.computed_data['RankOrder'] = loaded_directional_laps, loaded_rank_order\n",
    "curr_active_pipeline.global_computation_results.computed_data['RankOrder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd521ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_order_results.RL_ripple.selected_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_order_results.LR_ripple.selected_spikes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec24467335a760",
   "metadata": {},
   "source": [
    "# POST-Compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "728c46e6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    },
    "tags": [
     "unwrap"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum_inclusion_fr_Hz: 5.0\n",
      "included_qclu_values: [1, 2]\n",
      "laps_decoding_time_bin_size: 0.025, ripple_decoding_time_bin_size: 0.025\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multi_sort_raster_browser\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import paired_separately_sort_neurons, paired_incremental_sort_neurons # _display_directional_template_debugger\n",
    "from neuropy.utils.indexing_helpers import paired_incremental_sorting, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ScrollBarWithSpinBox.ScrollBarWithSpinBox import ScrollBarWithSpinBox\n",
    "\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_SerializationMixin\n",
    "from pyphoplacecellanalysis.General.Model.ComputationResults import ComputedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses, RankOrderResult, ShuffleHelper, Zscorer, LongShortStatsTuple, DirectionalRankOrderLikelihoods, DirectionalRankOrderResult, RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalMergedDecodersResult\n",
    "\n",
    "## Display Testing\n",
    "# from pyphoplacecellanalysis.External.pyqtgraph import QtGui\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import pyqtplot_build_image_bounds_extent, pyqtplot_plot_image\n",
    "\n",
    "spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "ripple_result_tuple, laps_result_tuple = rank_order_results.ripple_most_likely_result_tuple, rank_order_results.laps_most_likely_result_tuple\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')\n",
    "# ripple_result_tuple\n",
    "\n",
    "## Unpacks `rank_order_results`: \n",
    "# global_replays = Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# global_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# active_replay_epochs, active_epochs_df, active_selected_spikes_df = combine_rank_order_results(rank_order_results, global_replays, track_templates=track_templates)\n",
    "# active_epochs_df\n",
    "\n",
    "# ripple_result_tuple.directional_likelihoods_tuple.long_best_direction_indices\n",
    "dir_index_to_direction_name_map: Dict[int, str] = {0:'LR', 1:\"RL\"}\n",
    "\n",
    "\n",
    "## All three DataFrames are the same number of rows, each with one row corresponding to an Epoch:\n",
    "active_replay_epochs_df = deepcopy(rank_order_results.LR_ripple.epochs_df)\n",
    "# active_replay_epochs_df\n",
    "\n",
    "# Change column type to int8 for columns: 'long_best_direction_indices', 'short_best_direction_indices'\n",
    "# directional_likelihoods_df = pd.DataFrame.from_dict(ripple_result_tuple.directional_likelihoods_tuple._asdict()).astype({'long_best_direction_indices': 'int8', 'short_best_direction_indices': 'int8'})\n",
    "directional_likelihoods_df = ripple_result_tuple.directional_likelihoods_df\n",
    "# directional_likelihoods_df\n",
    "\n",
    "# 2023-12-15 - Newest method:\n",
    "# laps_combined_epoch_stats_df = rank_order_results.laps_combined_epoch_stats_df\n",
    "\n",
    "# ripple_combined_epoch_stats_df: pd.DataFrame  = rank_order_results.ripple_combined_epoch_stats_df\n",
    "# ripple_combined_epoch_stats_df\n",
    "\n",
    "\n",
    "# # Concatenate the three DataFrames along the columns axis:\n",
    "# # Assert that all DataFrames have the same number of rows:\n",
    "# assert len(active_replay_epochs_df) == len(directional_likelihoods_df) == len(ripple_combined_epoch_stats_df), \"DataFrames have different numbers of rows.\"\n",
    "# # Assert that all DataFrames have at least one row:\n",
    "# assert len(active_replay_epochs_df) > 0, \"active_replay_epochs_df is empty.\"\n",
    "# assert len(directional_likelihoods_df) > 0, \"directional_likelihoods_df is empty.\"\n",
    "# assert len(ripple_combined_epoch_stats_df) > 0, \"ripple_combined_epoch_stats_df is empty.\"\n",
    "# merged_complete_epoch_stats_df: pd.DataFrame = pd.concat([active_replay_epochs_df.reset_index(drop=True, inplace=False), directional_likelihoods_df.reset_index(drop=True, inplace=False), ripple_combined_epoch_stats_df.reset_index(drop=True, inplace=False)], axis=1)\n",
    "# merged_complete_epoch_stats_df = merged_complete_epoch_stats_df.set_index(active_replay_epochs_df.index, inplace=False)\n",
    "\n",
    "# merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "# merged_complete_epoch_stats_df.to_csv('output/2023-12-21_merged_complete_epoch_stats_df.csv')\n",
    "# merged_complete_epoch_stats_df\n",
    "\n",
    "laps_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.laps_merged_complete_epoch_stats_df ## New method\n",
    "ripple_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalMergedDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "all_directional_decoder_dict_value = directional_merged_decoders_result.all_directional_decoder_dict\n",
    "all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "# long_directional_pf1D_Decoder_value = directional_merged_decoders_result.long_directional_pf1D_Decoder\n",
    "# long_directional_decoder_dict_value = directional_merged_decoders_result.long_directional_decoder_dict\n",
    "# short_directional_pf1D_Decoder_value = directional_merged_decoders_result.short_directional_pf1D_Decoder\n",
    "# short_directional_decoder_dict_value = directional_merged_decoders_result.short_directional_decoder_dict\n",
    "\n",
    "all_directional_laps_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "all_directional_ripple_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\n",
    "\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = directional_merged_decoders_result.laps_track_identity_marginals_tuple\n",
    "ripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.ripple_directional_marginals_tuple\n",
    "ripple_track_identity_marginals, ripple_track_identity_all_epoch_bins_marginal, ripple_most_likely_track_identity_from_decoder, ripple_is_most_likely_track_identity_Long = directional_merged_decoders_result.ripple_track_identity_marginals_tuple\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "\n",
    "laps_all_epoch_bins_marginals_df = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "ripple_all_epoch_bins_marginals_df = directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca6b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_merged_decoders_result.all_directional_pf1D_Decoder.pf.spikes_df\n",
    "# all_directional_pf1D_Decoder_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b53c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ripple_merged_complete_epoch_stats_df\n",
    "laps_merged_complete_epoch_stats_df\n",
    "['long_best_direction_indices', 'short_best_direction_indices', 'combined_best_direction_indicies', 'long_relative_direction_likelihoods', 'short_relative_direction_likelihoods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the time series of Long-likely events\n",
    "# type(long_RL_results) # DynamicParameters\n",
    "long_LR_pf1D_Decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_directional_decoder_dict_value)\n",
    "list(all_directional_decoder_dict_value.keys()) # ['long_LR', 'long_RL', 'short_LR', 'short_RL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_all_epoch_bins_marginals_df\n",
    "laps_most_likely_direction_from_decoder\n",
    "long_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdabd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ripple_result_tuple) # pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations.DirectionalRankOrderResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "\n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f3f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps, partial\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def register_type_display(func_to_register, type_to_register):\n",
    "\t\"\"\" adds the display function (`func_to_register`) it decorates to the class (`type_to_register) as a method\n",
    "\n",
    "\n",
    "\t\"\"\"\n",
    "\t@wraps(func_to_register)\n",
    "\tdef wrapper(*args, **kwargs):\n",
    "\t\treturn func_to_register(*args, **kwargs)\n",
    "\n",
    "\tfunction_name: str = func_to_register.__name__ # get the name of the function to be added as the property\n",
    "\tsetattr(type_to_register, function_name, wrapper) # set the function as a method with the same name as the decorated function on objects of the class.\t\n",
    "\treturn wrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15629dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots \n",
    "\n",
    "# @register_type_display(DirectionalRankOrderResult)\n",
    "def plot_histograms(self: DirectionalRankOrderResult, **kwargs) -> \"MatplotlibRenderPlots\":\n",
    "\t\"\"\" \n",
    "\tnum='RipplesRankOrderZscore'\n",
    "\t\"\"\"\n",
    "\tprint(f'.plot_histograms(..., kwargs: {kwargs})')\n",
    "\tfig = plt.figure(layout=\"constrained\", **kwargs)\n",
    "\tax_dict = fig.subplot_mosaic(\n",
    "\t\t[\n",
    "\t\t\t[\"long_short_best_z_score_diff\", \"long_short_best_z_score_diff\"],\n",
    "\t\t\t[\"long_best_z_scores\", \"short_best_z_scores\"],\n",
    "\t\t],\n",
    "\t)\n",
    "\tplots = (pd.DataFrame({'long_best_z_scores': self.long_best_dir_z_score_values}).hist(ax=ax_dict['long_best_z_scores'], bins=21, alpha=0.8),\n",
    "\t\tpd.DataFrame({'short_best_z_scores': self.short_best_dir_z_score_values}).hist(ax=ax_dict['short_best_z_scores'], bins=21, alpha=0.8),\n",
    "\t\tpd.DataFrame({'long_short_best_z_score_diff': self.long_short_best_dir_z_score_diff_values}).hist(ax=ax_dict['long_short_best_z_score_diff'], bins=21, alpha=0.8),\n",
    "\t)\n",
    "\treturn MatplotlibRenderPlots(name='plot_histogram_figure', figures=[fig], axes=ax_dict)\n",
    "\n",
    "\n",
    "register_type_display(plot_histograms, DirectionalRankOrderResult)\n",
    "## Call the newly added `plot_histograms` function on the `ripple_result_tuple` object which is of type `DirectionalRankOrderResult`:\n",
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c291690",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_result_tuple.plot_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b30bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\t try saving to CSV...')\n",
    "merged_complete_epoch_stats_df = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "merged_complete_epoch_stats_df\n",
    "merged_complete_ripple_epoch_stats_df_output_path = curr_active_pipeline.get_output_path().joinpath(f'{DAY_DATE_TO_USE}_1247pm_merged_complete_epoch_stats_df.csv').resolve()\n",
    "merged_complete_epoch_stats_df.to_csv(merged_complete_ripple_epoch_stats_df_output_path)\n",
    "print(f'\\t saving to CSV: {merged_complete_ripple_epoch_stats_df_output_path} done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732743e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_combined_epoch_stats_df = deepcopy(merged_complete_epoch_stats_df)\n",
    "\n",
    "# Filter rows based on columns: 'Long_BestDir_quantile', 'Short_BestDir_quantile'\n",
    "quantile_significance_threshold: float = 0.95\n",
    "significant_BestDir_quantile_stats_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['Long_BestDir_quantile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['Short_BestDir_quantile'] > quantile_significance_threshold)]\n",
    "LR_likely_active_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['combined_best_direction_indicies']==0) & ((ripple_combined_epoch_stats_df['LR_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['LR_Short_rank_percentile'] > quantile_significance_threshold))]\n",
    "RL_likely_active_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['combined_best_direction_indicies']==1) & ((ripple_combined_epoch_stats_df['RL_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['RL_Short_rank_percentile'] > quantile_significance_threshold))]\n",
    "\n",
    "# significant_ripple_combined_epoch_stats_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['LR_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['LR_Short_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['RL_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['RL_Short_rank_percentile'] > quantile_significance_threshold)]\n",
    "# significant_ripple_combined_epoch_stats_df\n",
    "is_epoch_significant = np.isin(ripple_combined_epoch_stats_df.index, significant_BestDir_quantile_stats_df.index)\n",
    "active_replay_epochs_df = rank_order_results.LR_ripple.epochs_df\n",
    "significant_ripple_epochs: Epoch = Epoch(deepcopy(active_replay_epochs_df).epochs.get_valid_df()).boolean_indicies_slice(is_epoch_significant)\n",
    "epoch_identifiers = significant_ripple_epochs._df.label.astype({'label': RankOrderAnalyses._label_column_type}).values #.labels\n",
    "x_values = significant_ripple_epochs.midtimes\n",
    "x_axis_name_suffix = 'Mid-time (Sec)'\n",
    "\n",
    "# significant_ripple_epochs_df = significant_ripple_epochs.to_dataframe()\n",
    "# significant_ripple_epochs_df\n",
    "\n",
    "significant_BestDir_quantile_stats_df['midtimes'] = significant_ripple_epochs.midtimes\n",
    "significant_BestDir_quantile_stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee47f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import reorder_columns\n",
    "\n",
    "dict(zip(['Long_LR_evidence', 'Long_RL_evidence', 'Short_LR_evidence', 'Short_RL_evidence'], np.arange(4)+4))\n",
    "reorder_columns(merged_complete_epoch_stats_df, column_name_desired_index_dict=dict(zip(['Long_LR_evidence', 'Long_RL_evidence', 'Short_LR_evidence', 'Short_RL_evidence'], np.arange(4)+4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dceda30",
   "metadata": {},
   "source": [
    "## 2023-12-21 - Computing Spearman Percentiles as an alternative to the Z-score from shuffling, which does not seem to work for small numbers of active cells in an event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45aa7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_active_epoch_computed_values, shuffled_results_output_dict, combined_variable_names, valid_stacked_arrays, real_stacked_arrays, n_valid_shuffles = rank_order_results.ripple_new_output_tuple\n",
    "# shuffled_results_output_dict['short_LR_pearson_Z']\n",
    "print(list(shuffled_results_output_dict.keys())) # ['short_LR_pearson_Z', 'short_LR_spearman_Z', 'short_RL_pearson_Z', 'short_RL_spearman_Z', 'long_LR_pearson_Z', 'long_RL_pearson_Z', 'long_RL_spearman_Z', 'long_LR_spearman_Z']\n",
    "\n",
    "['long_LR_pearson_Z', 'long_RL_pearson_Z', 'short_LR_pearson_Z', 'short_RL_pearson_Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b40bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-12-22 - Add the LR-LR, RL-RL differences\n",
    "merged_complete_epoch_stats_df['LongShort_LR_quantile_diff'] = merged_complete_epoch_stats_df['LR_Long_rank_percentile'] - merged_complete_epoch_stats_df['LR_Short_rank_percentile']\n",
    "merged_complete_epoch_stats_df['LongShort_RL_quantile_diff'] = merged_complete_epoch_stats_df['RL_Long_rank_percentile'] - merged_complete_epoch_stats_df['RL_Short_rank_percentile']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73865dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_combined_epoch_stats_df = deepcopy(merged_complete_epoch_stats_df)\n",
    "\n",
    "# Filter rows based on columns: 'Long_BestDir_quantile', 'Short_BestDir_quantile'\n",
    "quantile_significance_threshold: float = 0.95\n",
    "significant_BestDir_quantile_stats_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['Long_BestDir_quantile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['Short_BestDir_quantile'] > quantile_significance_threshold)]\n",
    "LR_likely_active_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['combined_best_direction_indicies']==0) & ((ripple_combined_epoch_stats_df['LR_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['LR_Short_rank_percentile'] > quantile_significance_threshold))]\n",
    "RL_likely_active_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['combined_best_direction_indicies']==1) & ((ripple_combined_epoch_stats_df['RL_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['RL_Short_rank_percentile'] > quantile_significance_threshold))]\n",
    "\n",
    "# significant_ripple_combined_epoch_stats_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['LR_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['LR_Short_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['RL_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['RL_Short_rank_percentile'] > quantile_significance_threshold)]\n",
    "# significant_ripple_combined_epoch_stats_df\n",
    "is_epoch_significant = np.isin(ripple_combined_epoch_stats_df.index, significant_BestDir_quantile_stats_df.index)\n",
    "active_replay_epochs_df = rank_order_results.LR_ripple.epochs_df\n",
    "significant_ripple_epochs: Epoch = Epoch(deepcopy(active_replay_epochs_df).epochs.get_valid_df()).boolean_indicies_slice(is_epoch_significant)\n",
    "epoch_identifiers = significant_ripple_epochs._df.label.astype({'label': RankOrderAnalyses._label_column_type}).values #.labels\n",
    "x_values = significant_ripple_epochs.midtimes\n",
    "x_axis_name_suffix = 'Mid-time (Sec)'\n",
    "\n",
    "# significant_ripple_epochs_df = significant_ripple_epochs.to_dataframe()\n",
    "# significant_ripple_epochs_df\n",
    "\n",
    "significant_BestDir_quantile_stats_df['midtimes'] = significant_ripple_epochs.midtimes\n",
    "significant_BestDir_quantile_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb18612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import _plot_significant_event_quantile_fig\n",
    "\n",
    "# active_replay_epochs_df = rank_order_results.LR_ripple.epochs_df\n",
    "# if isinstance(global_events, pd.DataFrame):\n",
    "#     active_replay_epochs = Epoch(deepcopy(active_replay_epochs_df).epochs.get_valid_df())\n",
    "\n",
    "\n",
    "# _out = _plot_significant_event_quantile_fig(curr_active_pipeline, significant_ripple_combined_epoch_stats_df=significant_ripple_combined_epoch_stats_df)\n",
    "# _out\n",
    "\n",
    "marker_style = dict(linestyle='None', color='#ff7f0eff', markersize=6, markerfacecolor='#ff7f0eb4', markeredgecolor='#ff7f0eff')\n",
    "\n",
    "    # dict(facecolor='#ff7f0eb4', size=8.0)\n",
    "    # fignum='best_quantiles'\n",
    "\n",
    "# ripple_combined_epoch_stats_df['combined_best_direction_indicies']\n",
    "\n",
    "_out = significant_BestDir_quantile_stats_df[['midtimes', 'LongShort_BestDir_quantile_diff']].plot(x='midtimes', y='LongShort_BestDir_quantile_diff', title='Sig. (>0.95) Best Quantile Diff', **marker_style, marker='o')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import plot_quantile_diffs\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "global_epoch = curr_active_pipeline.filtered_epochs[global_epoch_name]\n",
    "short_epoch = curr_active_pipeline.filtered_epochs[short_epoch_name]\n",
    "split_time_t: float = short_epoch.t_start\n",
    "active_context = curr_active_pipeline.sess.get_context()\n",
    "\n",
    "collector = plot_quantile_diffs(ripple_merged_complete_epoch_stats_df, t_split=split_time_t, active_context=active_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd89199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from flexitext import flexitext ## flexitext for formatted matplotlib text\n",
    "from neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\n",
    "perform_update_title_subtitle(fig=fig_long_pf_1D, ax=ax_long_pf_1D, title_string=title_string, subtitle_string=subtitle_string, active_context=active_context, use_flexitext_titles=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e46ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, defer_render=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ecb4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(significant_BestDir_quantile_stats_df.columns))\n",
    "['LR_Long_rank_percentile', 'LR_Short_rank_percentile', 'RL_Long_rank_percentile', 'RL_Short_rank_percentile', 'Long_BestDir_quantile', 'Short_BestDir_quantile', 'LongShort_BestDir_quantile_diff']\n",
    "\n",
    "for a_name in ['LR_Long_rank_percentile', 'LR_Short_rank_percentile', 'RL_Long_rank_percentile', 'RL_Short_rank_percentile', 'Long_BestDir_quantile', 'Short_BestDir_quantile', 'LongShort_BestDir_quantile_diff']:\n",
    "\t_out = significant_BestDir_quantile_stats_df[['midtimes', 'LongShort_BestDir_quantile_diff']].plot(x='midtimes', y=a_name, title=f'Sig. (>0.95) {a_name}', **marker_style, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantile_results_df[['LR_Long_rank_percentile', 'RL_Long_rank_percentile', 'LR_Short_rank_percentile', 'RL_Short_rank_percentile']].plot.hist(bins=21)\n",
    "# quantile_results_df[['LR_Long_rank_percentile', 'RL_Long_rank_percentile', 'LR_Short_rank_percentile', 'RL_Short_rank_percentile']].plot.hist(bins=21)\n",
    "\n",
    "df = quantile_results_df[['LR_Long_rank_percentile', 'RL_Long_rank_percentile', 'LR_Short_rank_percentile', 'RL_Short_rank_percentile']].copy()\n",
    "# Create the subplots and loop through columns\n",
    "fig, axes = plt.subplots(4, 1, figsize=(10, 10))\n",
    "for i, col in enumerate(df.columns):\n",
    "    df[col].plot.hist(ax=axes[i], bins=21)\n",
    "    axes[i].set_title(col)\n",
    "\n",
    "# Adjust layout and display plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd61a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = pg.GraphicsLayoutWidget(show=True)\n",
    "win.resize(800,350)\n",
    "win.setWindowTitle('Z-Scorer: Histogram')\n",
    "plt1 = win.addPlot()\n",
    "vals = quantile_results_df.LR_Long_rank_percentile\n",
    "fisher_z_transformed_vals = np.arctanh(vals)\n",
    "\n",
    "## compute standard histogram\n",
    "y, x = np.histogram(vals) # , bins=np.linspace(-3, 8, 40)\n",
    "# fisher_z_transformed_y, x = np.histogram(fisher_z_transformed_vals, bins=x)\n",
    "\n",
    "## Using stepMode=\"center\" causes the plot to draw two lines for each sample.\n",
    "## notice that len(x) == len(y)+1\n",
    "plt1.plot(x, y, stepMode=\"center\", fillLevel=0, fillOutline=True, brush=(0,0,255,50), name='original_values')\n",
    "plt1.plot(x, y, stepMode=\"center\", fillLevel=0, fillOutline=True, brush=(0,0,255,50), name='original_values')\n",
    "# plt1.plot(x, fisher_z_transformed_y, stepMode=\"center\", fillLevel=0, fillOutline=True, brush=(0,255,100,50), name='fisher_z_values')\n",
    "\n",
    "# ## Now draw all points as a nicely-spaced scatter plot\n",
    "y = pg.pseudoScatter(vals, spacing=0.15)\n",
    "# #plt2.plot(vals, y, pen=None, symbol='o', symbolSize=5)\n",
    "plt2.plot(vals, y, pen=None, symbol='o', symbolSize=5, symbolPen=(255,255,255,200), symbolBrush=(0,0,255,150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30cb791",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.concat((ripple_combined_epoch_stats_df, ripple_p_values_epoch_stats_df), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d300a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_result_tuple.directional_likelihoods_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43327521",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logical_not(np.isnan(rank_order_results.ripple_combined_epoch_stats_df.index).any())\n",
    "# ripple_combined_epoch_stats_df.label.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_combined_epoch_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3cedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(ripple_combined_epoch_stats_df.label).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31224e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(ripple_combined_epoch_stats_df.index).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60749347",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tdone. building global result.\n"
     ]
    }
   ],
   "source": [
    "print(f'\\tdone. building global result.')\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "selected_spikes_df = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.selected_spikes_df)\n",
    "# active_epochs = global_computation_results.computed_data['RankOrder'].ripple_most_likely_result_tuple.active_epochs\n",
    "active_epochs = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.epochs_df)\n",
    "track_templates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ab4052",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_combined_epoch_stats_df, ripple_new_output_tuple = RankOrderAnalyses.pandas_df_based_correlation_computations(selected_spikes_df=selected_spikes_df, active_epochs_df=active_epochs, track_templates=track_templates, num_shuffles=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313886d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_output_tuple (output_active_epoch_computed_values, valid_stacked_arrays, real_stacked_arrays, n_valid_shuffles) = ripple_new_output_tuple\n",
    "curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_combined_epoch_stats_df, curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_new_output_tuple = ripple_combined_epoch_stats_df, ripple_new_output_tuple\n",
    "print(f'done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e95d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_aclu_peak_map_dict = track_templates.get_decoder_aclu_peak_map_dict()\n",
    "## Restrict to only the relevant columns, and Initialize the dataframe columns to np.nan:\n",
    "active_selected_spikes_df: pd.DataFrame = deepcopy(selected_spikes_df[['t_rel_seconds', 'aclu', 'Probe_Epoch_id']]).sort_values(['Probe_Epoch_id', 't_rel_seconds', 'aclu']).astype({'Probe_Epoch_id': RankOrderAnalyses._label_column_type}) # Sort by columns: 'Probe_Epoch_id' (ascending), 't_rel_seconds' (ascending), 'aclu' (ascending)\n",
    "\n",
    "# _pf_peak_x_column_names = ['LR_Long_pf_peak_x', 'RL_Long_pf_peak_x', 'LR_Short_pf_peak_x', 'RL_Short_pf_peak_x']\n",
    "_pf_peak_x_column_names = [f'{a_decoder_name}_pf_peak_x' for a_decoder_name in track_templates.get_decoder_names()]\n",
    "active_selected_spikes_df[_pf_peak_x_column_names] = pd.DataFrame([[RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type]], index=active_selected_spikes_df.index)\n",
    "\n",
    "unique_Probe_Epoch_IDs = active_selected_spikes_df['Probe_Epoch_id'].unique()\n",
    "unique_Probe_Epoch_IDs\n",
    "for a_probe_epoch_ID in unique_Probe_Epoch_IDs:\n",
    "\t# probe_epoch_df = active_selected_spikes_df[a_probe_epoch_ID == active_selected_spikes_df['Probe_Epoch_id']]\n",
    "\t# epoch_unique_aclus = probe_epoch_df.aclu.unique()\n",
    "\tmask = (a_probe_epoch_ID == active_selected_spikes_df['Probe_Epoch_id'])\n",
    "\t# epoch_unique_aclus = active_selected_spikes_df.loc[mask, 'aclu'].unique()\n",
    "\tfor a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items():\n",
    "\t\t# Shuffle aclus here:\n",
    "\t\tactive_selected_spikes_df.loc[mask, 'aclu'] = active_selected_spikes_df.loc[mask, 'aclu'].sample(frac=1).values\n",
    "\t\tactive_selected_spikes_df.loc[mask, f'{a_decoder_name}_pf_peak_x'] = active_selected_spikes_df.loc[mask, 'aclu'].map(a_aclu_peak_map)\n",
    "\n",
    "\t\t# ## Shuffle aclus here:\n",
    "\t\t# # probe_epoch_df.aclu.sample(1000)\n",
    "\t\t# # a_aclu_peak_map\n",
    "\t\t# # Assuming 'df' is your DataFrame and 'column_name' is the column you want to shuffle\n",
    "\t\t# probe_epoch_df['aclu'] = probe_epoch_df['aclu'].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\t\t# probe_epoch_df[f'{a_decoder_name}_pf_peak_x'] = probe_epoch_df.aclu.map(a_aclu_peak_map)\n",
    "\n",
    "\t\t# active_selected_spikes_df[f'{a_decoder_name}_pf_peak_x'] = active_selected_spikes_df.aclu.map(a_aclu_peak_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c306ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2024-01-09 - More Efficient\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "def _new_compute_single_rank_order_shuffle(track_templates, active_selected_spikes_df: pd.DataFrame):\n",
    "    \"\"\" 2024-01-09 - Candidate for moving into RankOrderComputations \n",
    "    captures: decoder_names\n",
    "    \n",
    "    Usage:\n",
    "    \n",
    "    shuffled_dfs = _perform_efficient_shuffle(active_selected_spikes_df, decoder_aclu_peak_map_dict, num_shuffles=5)\n",
    "    \n",
    "    \"\"\"\n",
    "    decoder_names = track_templates.get_decoder_names()\n",
    "    \n",
    "    ## Compute real values here:\n",
    "    epoch_id_grouped_selected_spikes_df = active_selected_spikes_df.groupby('Probe_Epoch_id') # I can even compute this outside the loop?\n",
    "\n",
    "    # spearman_correlations = epoch_id_grouped_selected_spikes_df.apply(lambda group: RankOrderAnalyses._subfn_calculate_correlations(group, method='spearman', decoder_names=decoder_names)).reset_index() # Reset index to make 'Probe_Epoch_id' a column\n",
    "    # pearson_correlations = epoch_id_grouped_selected_spikes_df.apply(lambda group: RankOrderAnalyses._subfn_calculate_correlations(group, method='pearson', decoder_names=decoder_names)).reset_index() # Reset index to make 'Probe_Epoch_id' a column\n",
    "\n",
    "    # real_stats_df = pd.concat((spearman_correlations, pearson_correlations), axis='columns')\n",
    "    # real_stats_df = real_stats_df.loc[:, ~real_stats_df.columns.duplicated()] # drop duplicated 'Probe_Epoch_id' column\n",
    "    # # Change column type to uint64 for column: 'Probe_Epoch_id'\n",
    "    # real_stats_df = real_stats_df.astype({'Probe_Epoch_id': 'uint64'})\n",
    "    # # Rename column 'Probe_Epoch_id' to 'label'\n",
    "    # real_stats_df = real_stats_df.rename(columns={'Probe_Epoch_id': 'label'})\n",
    "    \n",
    "    # Parallelize correlation computations if required\n",
    "    correlations = []\n",
    "    for method in ['spearman', 'pearson']:\n",
    "        correlations.append(\n",
    "            epoch_id_grouped_selected_spikes_df.apply(\n",
    "                lambda group: RankOrderAnalyses._subfn_calculate_correlations(\n",
    "                    group, method=method, decoder_names=decoder_names)\n",
    "            )\n",
    "        )\n",
    "  \n",
    "    # Adjust and join all calculated correlations\n",
    "    real_stats_df = pd.concat(correlations, axis='columns').reset_index()\n",
    "    real_stats_df = real_stats_df.loc[:, ~real_stats_df.columns.duplicated()]\n",
    "\n",
    "    real_stats_df.rename(columns={'Probe_Epoch_id': 'label'}, inplace=True)\n",
    "    real_stats_df['label'] = real_stats_df['label'].astype('uint64')  # in-place type casting\n",
    "    \n",
    "    return real_stats_df\n",
    "\n",
    "\n",
    "# Determine the number of shuffles you want to do\n",
    "def _new_perform_efficient_shuffle(track_templates, active_selected_spikes_df, decoder_aclu_peak_map_dict, num_shuffles:int=5):\n",
    "    \"\"\" 2024-01-09 - Performs the shuffles in a simple way\n",
    "    \n",
    "    \"\"\"\n",
    "    unique_Probe_Epoch_IDs = active_selected_spikes_df['Probe_Epoch_id'].unique()\n",
    "\n",
    "    # Create a list to hold the shuffled dataframes\n",
    "    shuffled_dfs = []\n",
    "    shuffled_stats_dfs = []\n",
    "\n",
    "    for i in range(num_shuffles):\n",
    "        # Working on a copy of the DataFrame\n",
    "        shuffled_df = active_selected_spikes_df.copy()\n",
    "\n",
    "        for a_probe_epoch_ID in unique_Probe_Epoch_IDs:\n",
    "            mask = (a_probe_epoch_ID == shuffled_df['Probe_Epoch_id'])\n",
    "            \n",
    "            # Shuffle 'aclu' values\n",
    "            shuffled_df.loc[mask, 'aclu'] = shuffled_df.loc[mask, 'aclu'].sample(frac=1).values\n",
    "            \n",
    "            # # Apply aclu peak map dictionary to 'aclu' column\n",
    "            # for a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items():\n",
    "            #     shuffled_df.loc[mask, f'{a_decoder_name}_pf_peak_x'] = shuffled_df.loc[mask, 'aclu'].map(a_aclu_peak_map)\n",
    "            \n",
    "\n",
    "        # end `for a_probe_epoch_ID`\n",
    "        # Once done, apply the aclu peak maps to shuffled_df's 'aclu' column:\n",
    "        for a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items():\n",
    "            shuffled_df[f'{a_decoder_name}_pf_peak_x'] = shuffled_df.aclu.map(a_aclu_peak_map)\n",
    "            \n",
    "        a_shuffle_stats_df = _new_compute_single_rank_order_shuffle(track_templates, active_selected_spikes_df=shuffled_df)\n",
    "        \n",
    "        # Adding the shuffled DataFrame to the list\n",
    "        shuffled_dfs.append(shuffled_df)\n",
    "        shuffled_stats_dfs.append(a_shuffle_stats_df)\n",
    "        \n",
    "    return shuffled_dfs, shuffled_stats_dfs\n",
    "\n",
    "\n",
    "\n",
    "def _suggested_perform_efficient_shuffle(track_templates, active_selected_spikes_df, decoder_aclu_peak_map_dict, num_shuffles: int = 5):\n",
    "    unique_Probe_Epoch_IDs = active_selected_spikes_df['Probe_Epoch_id'].unique()\n",
    "    shuffled_dfs = []\n",
    "    shuffled_stats_dfs = []\n",
    "\n",
    "    def map_dict_to_group(group, a_dict, column):\n",
    "        group[column] = group[column].map(a_dict)\n",
    "        return group\n",
    "\n",
    "    for i in range(num_shuffles):\n",
    "        shuffled_df = active_selected_spikes_df.copy()\n",
    "\n",
    "        for a_probe_epoch_ID in unique_Probe_Epoch_IDs:\n",
    "            shuffled_df.loc[shuffled_df['Probe_Epoch_id'] == a_probe_epoch_ID, 'aclu'] = shuffled_df.loc[shuffled_df['Probe_Epoch_id'] == a_probe_epoch_ID, 'aclu'].sample(frac=1).values\n",
    "\n",
    "        for a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items():\n",
    "            shuffled_df = shuffled_df.groupby('Probe_Epoch_id').apply(map_dict_to_group, a_dict=a_aclu_peak_map, column=f'{a_decoder_name}_pf_peak_x')\n",
    "\n",
    "        a_shuffle_stats_df = _new_compute_single_rank_order_shuffle(track_templates, active_selected_spikes_df=shuffled_df)\n",
    "\n",
    "        shuffled_dfs.append(shuffled_df)\n",
    "        shuffled_stats_dfs.append(a_shuffle_stats_df)\n",
    "\n",
    "    return shuffled_dfs, shuffled_stats_dfs\n",
    "\n",
    "\n",
    "\n",
    "## Compute:\n",
    "decoder_aclu_peak_map_dict = track_templates.get_decoder_aclu_peak_map_dict()\n",
    "## Restrict to only the relevant columns, and Initialize the dataframe columns to np.nan:\n",
    "active_selected_spikes_df: pd.DataFrame = deepcopy(selected_spikes_df[['t_rel_seconds', 'aclu', 'Probe_Epoch_id']]).sort_values(['Probe_Epoch_id', 't_rel_seconds', 'aclu']).astype({'Probe_Epoch_id': RankOrderAnalyses._label_column_type}) # Sort by columns: 'Probe_Epoch_id' (ascending), 't_rel_seconds' (ascending), 'aclu' (ascending)\n",
    "# _pf_peak_x_column_names = ['LR_Long_pf_peak_x', 'RL_Long_pf_peak_x', 'LR_Short_pf_peak_x', 'RL_Short_pf_peak_x']\n",
    "_pf_peak_x_column_names = [f'{a_decoder_name}_pf_peak_x' for a_decoder_name in track_templates.get_decoder_names()]\n",
    "active_selected_spikes_df[_pf_peak_x_column_names] = pd.DataFrame([[RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type]], index=active_selected_spikes_df.index)\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-suggested_perform_efficient_shuffle.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "shuffled_dfs, shuffled_stats_dfs = _suggested_perform_efficient_shuffle(track_templates, active_selected_spikes_df, decoder_aclu_peak_map_dict, num_shuffles=10) # 50, 1m 21.2s, 10, 16.1s\n",
    "# shuffled_dfs, shuffled_stats_dfs = _new_perform_efficient_shuffle(track_templates, active_selected_spikes_df, decoder_aclu_peak_map_dict, num_shuffles=10) # 10, 12.8s\n",
    "\n",
    "\n",
    "shuffled_dfs\n",
    "shuffled_stats_dfs\n",
    "# 5, 4.1 sec\n",
    "# 0.5s!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_active_epoch_computed_values = shuffled_stats_dfs\n",
    "# Build the output `stacked_arrays`: _________________________________________________________________________________ #\n",
    "\n",
    "stacked_arrays = np.stack([a_shuffle_real_stats_df[combined_variable_names].to_numpy() for a_shuffle_real_stats_df in output_active_epoch_computed_values], axis=0) # for compatibility: .shape (n_shuffles, n_epochs, n_columns)\n",
    "# stacked_df = pd.concat(output_active_epoch_computed_values, axis='index')\n",
    "\n",
    "## Drop any shuffle indicies where NaNs are returned for any of the stats values.\n",
    "is_valid_row = np.logical_not(np.isnan(stacked_arrays)).all(axis=(1,2)) # row [0, 66, :] is bad, ... so is [1, 66, :], ... [20, 66, :], ... they are repeated!!\n",
    "n_valid_shuffles = np.sum(is_valid_row)\n",
    "if debug_print:\n",
    "\tprint(f'n_valid_shuffles: {n_valid_shuffles}')\n",
    "valid_stacked_arrays = stacked_arrays[is_valid_row] ## Get only the rows where all elements along both axis (1, 2) are True\n",
    "\n",
    "# Need: valid_stacked_arrays, real_stacked_arrays, combined_variable_names\n",
    "combined_epoch_stats_df: pd.DataFrame = pd.DataFrame(real_stacked_arrays, columns=combined_variable_names)\n",
    "combined_variable_z_score_column_names = [f\"{a_name}_Z\" for a_name in combined_variable_names] # combined_variable_z_score_column_names: ['LR_Long_spearman_Z', 'RL_Long_spearman_Z', 'LR_Short_spearman_Z', 'RL_Short_spearman_Z', 'LR_Long_pearson_Z', 'RL_Long_pearson_Z', 'LR_Short_pearson_Z', 'RL_Short_pearson_Z']\n",
    "\n",
    "## Extract the stats values for each shuffle from `valid_stacked_arrays`:\n",
    "n_epochs = np.shape(real_stacked_arrays)[0]\n",
    "n_variables = np.shape(real_stacked_arrays)[1]\n",
    "\n",
    "# valid_stacked_arrays.shape: (n_shuffles, n_epochs, n_variables)\n",
    "assert n_epochs == np.shape(valid_stacked_arrays)[-2]\n",
    "assert n_variables == np.shape(valid_stacked_arrays)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Determine the number of shuffles you want to do\n",
    "num_shuffles = 5\n",
    "\n",
    "# Define the operation to be run in parallel for a shuffle iteration\n",
    "def shuffle_iteration(i):\n",
    "    # Working on a copy of the DataFrame\n",
    "    shuffled_df = active_selected_spikes_df.copy()\n",
    "\n",
    "    for a_probe_epoch_ID in unique_Probe_Epoch_IDs:\n",
    "        mask = (a_probe_epoch_ID == shuffled_df['Probe_Epoch_id'])\n",
    "\n",
    "        # Shuffle 'aclu' values\n",
    "        shuffled_df.loc[mask, 'aclu'] = shuffled_df.loc[mask, 'aclu'].sample(frac=1).values\n",
    "\n",
    "        # Apply aclu peak map dictionary to 'aclu' column\n",
    "        for a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items():\n",
    "            shuffled_df.loc[mask, f'{a_decoder_name}_pf_peak_x'] = shuffled_df.loc[mask, 'aclu'].map(a_aclu_peak_map)\n",
    "\n",
    "    # Return the shuffled DataFrame\n",
    "    return shuffled_df\n",
    "\n",
    "# Create a list to hold the shuffled dataframes\n",
    "shuffled_dfs = Parallel(n_jobs=-1)(delayed(shuffle_iteration)(i) for i in range(num_shuffles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['long_LR_pf_peak_x', 'long_RL_pf_peak_x', 'short_LR_pf_peak_x', 'short_RL_pf_peak_x']\n",
    "peak_column_names = [f'{a_decoder_name}_pf_peak_x' for a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items()]\n",
    "print(peak_column_names) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b42a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _perform_efficient_shuffle_pre_mapping(active_selected_spikes_df, decoder_aclu_peak_map_dict, num_shuffles:int=5):\n",
    "    # Apply aclu peak map dictionary to each decoder name\n",
    "    for a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items():\n",
    "        active_selected_spikes_df[f'{a_decoder_name}_pf_peak_x'] = active_selected_spikes_df['aclu'].map(a_aclu_peak_map)\n",
    "\n",
    "    unique_Probe_Epoch_IDs = active_selected_spikes_df['Probe_Epoch_id'].unique()\n",
    "    shuffles = {}\n",
    "    for i in range(num_shuffles):\n",
    "        shuffles[i] = active_selected_spikes_df.copy()\n",
    "        for a_probe_epoch_ID in unique_Probe_Epoch_IDs:\n",
    "            mask = (a_probe_epoch_ID == shuffles[i]['Probe_Epoch_id'])\n",
    "            # Shuffle multiple columns here:\n",
    "            for a_decoder_name in decoder_aclu_peak_map_dict.keys():\n",
    "                shuffles[i].loc[mask, f'{a_decoder_name}_pf_peak_x'] = shuffles[i].loc[mask, f'{a_decoder_name}_pf_peak_x'].sample(frac=1).values\n",
    "    return shuffles\n",
    "\n",
    "## Compute:\n",
    "decoder_aclu_peak_map_dict = track_templates.get_decoder_aclu_peak_map_dict()\n",
    "## Restrict to only the relevant columns, and Initialize the dataframe columns to np.nan:\n",
    "active_selected_spikes_df: pd.DataFrame = deepcopy(selected_spikes_df[['t_rel_seconds', 'aclu', 'Probe_Epoch_id']]).sort_values(['Probe_Epoch_id', 't_rel_seconds', 'aclu']).astype({'Probe_Epoch_id': RankOrderAnalyses._label_column_type}) # Sort by columns: 'Probe_Epoch_id' (ascending), 't_rel_seconds' (ascending), 'aclu' (ascending)\n",
    "# _pf_peak_x_column_names = ['LR_Long_pf_peak_x', 'RL_Long_pf_peak_x', 'LR_Short_pf_peak_x', 'RL_Short_pf_peak_x']\n",
    "_pf_peak_x_column_names = [f'{a_decoder_name}_pf_peak_x' for a_decoder_name in track_templates.get_decoder_names()]\n",
    "active_selected_spikes_df[_pf_peak_x_column_names] = pd.DataFrame([[RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type]], index=active_selected_spikes_df.index)\n",
    "shuffled_dfs = _perform_efficient_shuffle_pre_mapping(active_selected_spikes_df, decoder_aclu_peak_map_dict, num_shuffles=5)\n",
    "# shuffled_dfs\n",
    "# 5, 1.5 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548d3db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle 'aclu' values\n",
    "shuffled_df.loc[mask, 'aclu'] = shuffled_df.loc[mask, 'aclu'].sample(frac=1).values\n",
    "\n",
    "\n",
    "# Shuffle aclu and their corresponding peaks: ['aclu', 'long_LR_pf_peak_x', 'long_RL_pf_peak_x', 'short_LR_pf_peak_x', 'short_RL_pf_peak_x']\n",
    "peak_column_names = [f'{a_decoder_name}_pf_peak_x' for a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items()] # ['long_LR_pf_peak_x', 'long_RL_pf_peak_x', 'short_LR_pf_peak_x', 'short_RL_pf_peak_x']\n",
    "shuffled_df.loc[mask, ['aclu','long_LR_pf_peak_x', 'long_RL_pf_peak_x', 'short_LR_pf_peak_x', 'short_RL_pf_peak_x']] = shuffled_df.loc[mask, ['aclu','long_LR_pf_peak_x', 'long_RL_pf_peak_x', 'short_LR_pf_peak_x', 'short_RL_pf_peak_x']].sample(frac=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d641689",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_object_memory_usage(output_active_epoch_computed_values) # 0.946189 MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3d1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## #TODO 2023-12-13 02:07: - [ ] Figure out how 'Probe_Epoch_id' maps to `ripple_result_tuple.active_epochs`\n",
    "ripple_result_tuple.active_epochs\n",
    "rank_order_results.LR_ripple.ranked_aclus_stats_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f1bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the pf_x information for each aclu:\n",
    "## 2023-10-11 - Get the long/short peak locations\n",
    "# decoder_peak_coms_list = [a_decoder.pf.ratemap.peak_tuning_curve_center_of_masses[is_good_aclus] for a_decoder in decoder_args]\n",
    "decoder_aclu_peak_location_dict_list = [dict(zip(neuron_IDs, peak_locations)) for neuron_IDs, peak_locations in zip(track_templates.decoder_neuron_IDs_list, track_templates.decoder_peak_location_list)]\n",
    "decoder_aclu_peak_location_dict_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de234ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.long_LR_decoder.peak_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc4b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.long_LR_decoder.peak_tuning_curve_center_of_masses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1305ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.decoder_LR_pf_peak_ranks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b179f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replays:\n",
    "global_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "if isinstance(global_replays, pd.DataFrame):\n",
    "\tglobal_replays = Epoch(global_replays.epochs.get_valid_df())\n",
    "\n",
    "# get the aligned epochs and the z-scores aligned to them:\n",
    "active_replay_epochs, (active_LR_ripple_long_z_score, active_RL_ripple_long_z_score, active_LR_ripple_short_z_score, active_RL_ripple_short_z_score) = rank_order_results.get_aligned_events(global_replays.to_dataframe().copy(), is_laps=False)\n",
    "active_replay_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6384a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Laps:\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping()\n",
    "active_laps_epochs, (active_LR_ripple_long_z_score, active_RL_ripple_long_z_score, active_LR_ripple_short_z_score, active_RL_ripple_short_z_score) = rank_order_results.get_aligned_events(global_laps.to_dataframe(), is_laps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e8ff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_result_tuple.plot_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfbe341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find only the significant events (|z| > 1.96):\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses\n",
    "\n",
    "filtered_z_score_df, (n_events, n_significant_events, percent_significant_events) = RankOrderAnalyses.find_only_significant_events(rank_order_results, high_z_criteria=1.96)\n",
    "filtered_z_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_z_score_df.index.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86532662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-11-20 - Finding high-significance periods for Kamran:\n",
    "z_threshold = 1.96\n",
    "is_greater_than_z_threshold_long = (np.abs(ripple_result_tuple.long_best_dir_z_score_values) > z_threshold)\n",
    "is_greater_than_z_threshold_short = (np.abs(ripple_result_tuple.short_best_dir_z_score_values) > z_threshold)\n",
    "is_significant_either = np.logical_or(is_greater_than_z_threshold_long, is_greater_than_z_threshold_short)\n",
    "is_significant_either\n",
    "\n",
    "# is_greater_than_3std_long = (np.abs(ripple_result_tuple.long_best_dir_z_score_values) >= 3.0)\n",
    "# is_greater_than_3std_short = (np.abs(ripple_result_tuple.short_best_dir_z_score_values) >= 3.0)\n",
    "# is_significant_either = np.logical_or(is_greater_than_3std_long, is_greater_than_3std_short)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f925cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_ripple_epochs = deepcopy(Epoch(ripple_result_tuple.active_epochs)).boolean_indicies_slice(is_significant_either)\n",
    "# significant_ripple_epochs = deepcopy(global_replays).boolean_indicies_slice(is_significant_either)\n",
    "significant_ripple_epochs.to_dataframe()\n",
    "\n",
    "# significant_ripple_epochs.filename = Path(f'output/2023-11-27_SignificantReplayRipples').resolve()\n",
    "# significant_ripple_epochs.to_neuroscope()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8beece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_epochs = ripple_result_tuple.active_epochs\n",
    "active_epochs: Epoch = rank_order_results.RL_ripple.epochs_df # Epoch(rank_order_results.RL_ripple.epochs_df)\n",
    "# type(active_epochs)\n",
    "active_epochs.n_epochs\n",
    "# rank_order_results.RL_ripple.spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ffe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_order_results.LR_ripple.epochs_df\n",
    "rank_order_results.LR_ripple.spikes_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39525572",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_variable_names: ['LR_Long_spearman', 'RL_Long_spearman', 'LR_Short_spearman', 'RL_Short_spearman', 'LR_Long_pearson', 'RL_Long_pearson', 'LR_Short_pearson', 'RL_Short_pearson']\n",
    "combined_variable_z_score_column_names: ['LR_Long_spearman_Z', 'RL_Long_spearman_Z', 'LR_Short_spearman_Z', 'RL_Short_spearman_Z', 'LR_Long_pearson_Z', 'RL_Long_pearson_Z', 'LR_Short_pearson_Z', 'RL_Short_pearson_Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f47973",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.build_display_context_for_filtered_session(filtered_session_name='maze_any', display_fn_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b319650",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_order_results.LR_ripple.selected_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef5436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_order_results.RL_ripple.selected_spikes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ebf52",
   "metadata": {},
   "source": [
    "#### Iterates through the epochs (via the slider) and saves out the images:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f73ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = Path(r'C:\\Users\\pho\\Desktop\\2023-12-19 Exports').resolve()\n",
    "all_save_paths = _out_rank_order_event_raster_debugger.export_figure_all_slider_values(export_path=export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_rank_order_event_raster_debugger.active_epoch_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d7d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_rank_order_event_raster_debugger.active_epoch_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d5bd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "aclu_y_values_dict = {_active_plot_identifier:{int(aclu):new_sorted_raster.neuron_y_pos[aclu] for aclu in new_sorted_raster.neuron_IDs} for _active_plot_identifier, new_sorted_raster in _out_rank_order_event_raster_debugger.plots_data.seperate_new_sorted_rasters_dict.items()}\n",
    "aclu_max_y_values_dict = {_active_plot_identifier:np.max(list({int(aclu):new_sorted_raster.neuron_y_pos[aclu] for aclu in new_sorted_raster.neuron_IDs}.values())) for _active_plot_identifier, new_sorted_raster in _out_rank_order_event_raster_debugger.plots_data.seperate_new_sorted_rasters_dict.items()} # {'long_LR': 51.48039215686274, 'long_RL': 53.5, 'short_LR': 51.48039215686274, 'short_RL': 53.5}\n",
    "global_max_y_value = np.max(list(aclu_max_y_values_dict.values()))\n",
    "global_max_y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01518ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_neurons = np.max([len(v) for v in _out_rank_order_event_raster_debugger.plots_data.unsorted_original_neuron_IDs_lists])\n",
    "max_n_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_rank_order_event_raster_debugger.plots.all_separate_plots['long_LR']['root_plot']\n",
    "\n",
    "\n",
    "root_plots_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debcee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_alt_directional_merged_decoders_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d02ad",
   "metadata": {},
   "source": [
    "## 2024-01-17 - Updates the `a_directional_merged_decoders_result.laps_epochs_df` with both the ground-truth values and the decoded predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab95d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dabb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive-mode parameters:\n",
    "_interactive_mode_kwargs = dict(should_use_MatplotlibTimeSynchronizedWidget=True, scrollable_figure=True, defer_render=False)\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_curr_interaction_mode_kwargs = _interactive_mode_kwargs # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ca3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-interactive:\n",
    "_non_interactive_mode_kwargs = dict(should_use_MatplotlibTimeSynchronizedWidget=False, scrollable_figure=False, defer_render=True)\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=False, backend='AGG')\n",
    "_curr_interaction_mode_kwargs = _non_interactive_mode_kwargs # non-interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2727307e",
   "metadata": {},
   "source": [
    "### 2024-01-19 - Marginal Scatter Plots from `alt_directional_merged_decoders_result`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import plot_all_epoch_bins_marginal_predictions\n",
    "use_single_time_bin_per_epoch = False\n",
    "active_display_context = curr_active_pipeline.build_display_context_for_session('plot_all_epoch_bins_marginal_predictions', laps_t_bin=laps_decoding_time_bin_size, ripple_t_bin=ripple_decoding_time_bin_size) # \n",
    "if use_single_time_bin_per_epoch:\n",
    "\tactive_display_context = active_display_context.adding_context_if_missing(use_single_time_bin_per_epoch=use_single_time_bin_per_epoch)\n",
    "\n",
    "# 'directional_decoded_epochs_marginals'\n",
    "collector_decoded_epoch_marginals = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs_marginals', curr_active_pipeline.get_session_context(), \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tactive_context=active_display_context,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsave_figure=True, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdirectional_merged_decoders_result=alt_directional_merged_decoders_result, # Custom `directional_merged_decoders_result` to use instead of the computed one.\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae85fcb",
   "metadata": {},
   "source": [
    "### 2024-01-19 - Marginal Yellow-Blue Plots from `alt_directional_merged_decoders_result`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5876c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_context = owning_pipeline_reference.sess.get_context()\n",
    "# Build the active context directly:\n",
    "active_display_context: IdentifyingContext = curr_active_pipeline.build_display_context_for_session('directional_merged_pf_decoded_epochs', laps_t_bin=laps_decoding_time_bin_size, ripple_t_bin=ripple_decoding_time_bin_size)\n",
    "if use_single_time_bin_per_epoch:\n",
    "\tactive_display_context = active_display_context.adding_context_if_missing(use_single_time_bin_per_epoch=use_single_time_bin_per_epoch)\n",
    "active_display_context\n",
    "\n",
    "## Plot the decoded epoch bins of the custom result:\n",
    "_out_decoded_epochs = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs', curr_active_pipeline.get_session_context(), #active_display_context,\n",
    "\tmax_num_lap_epochs = 80, max_num_ripple_epochs = 100,\n",
    "\t# render_directional_marginal_laps=True, render_directional_marginal_ripples=True, render_track_identity_marginal_laps=True, render_track_identity_marginal_ripples=True,\n",
    "\trender_directional_marginal_laps=False, render_directional_marginal_ripples=False, render_track_identity_marginal_laps=False, render_track_identity_marginal_ripples=True,\n",
    "\t# constrained_layout=True, # layout='none',\n",
    "\t# build_fn='basic_view', constrained_layout=True, # 25.5s\n",
    "\tbuild_fn='insets_view', constrained_layout=True, #constrained_layout=None, layout='none', # , constrained_layout=False constrained_layout=None, layout='none', # , constrained_layout=None, layout='none' extrodinarily fast, 4.2s\n",
    "\t**_curr_interaction_mode_kwargs, # interactive mode\n",
    "\tskip_plotting_measured_positions=True, skip_plotting_most_likely_positions=True, save_figure=True, \n",
    "\tdirectional_merged_decoders_result=alt_directional_merged_decoders_result, # Custom `directional_merged_decoders_result` to use instead of the computed one.\n",
    "\t)\n",
    "collector_decoded_epochs = _out_decoded_epochs['collector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc6584",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_only_keys = [item for item in active_display_context.keys() if 'lap' in item] # items exclusive to laps: ['laps_t_bin']\n",
    "ripple_only_keys = [item for item in active_display_context.keys() if 'ripple' in item]\n",
    "laps_context = active_display_context.get_subset(subset_excludelist=ripple_only_keys) # laps specific context filtering out the ripple keys\n",
    "ripple_context = active_display_context.get_subset(subset_excludelist=laps_only_keys) # ripple specific context filtering out the laps keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4169a",
   "metadata": {},
   "source": [
    "### 2024-01-19 - Build General Marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d8817",
   "metadata": {},
   "outputs": [],
   "source": [
    "## `alt_directional_merged_decoders_result`\n",
    "from PendingNotebookCode import test_build_new_marginals_df\n",
    "\n",
    "# `alt_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result`\n",
    "\n",
    "# laps_time_bin_marginals_df = test_build_new_marginals_df(alt_directional_merged_decoders_result)\n",
    "laps_time_bin_marginals_df: pd.DataFrame = test_build_new_marginals_df(a_decoder_result=deepcopy(alt_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result),\n",
    "\t\t\t\t\t\t\t\t a_track_identity_marginals=alt_directional_merged_decoders_result.laps_directional_marginals_tuple[0]\n",
    "\t\t\t\t\t\t\t )\n",
    "laps_time_bin_marginals_df\n",
    "\n",
    "ripple_time_bin_marginals_df: pd.DataFrame = test_build_new_marginals_df(a_decoder_result=deepcopy(alt_directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result),\n",
    "\t\t\t\t\t\t\t\t\t\t\t a_track_identity_marginals=alt_directional_merged_decoders_result.ripple_directional_marginals_tuple[0]\n",
    "\t\t\t\t\t\t\t\t\t\t)\n",
    "ripple_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d88744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from flexitext import flexitext ## flexitext for formatted matplotlib text\n",
    "\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import FigureCollector\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import PlottingHelpers\n",
    "from neuropy.utils.matplotlib_helpers import FormattedFigureText\n",
    "\n",
    "\n",
    "perform_write_to_file_callback = None\n",
    "\n",
    "laps_all_epoch_bins_marginals_df = deepcopy(laps_time_bin_marginals_df)\n",
    "ripple_all_epoch_bins_marginals_df = deepcopy(ripple_time_bin_marginals_df)\n",
    "\n",
    "if active_context is not None:\n",
    "\tdisplay_context = active_context.adding_context('display_fn', display_fn_name='plot_all_epoch_bins_marginal_predictions')\n",
    "\t\n",
    "# These subset contexts are used to filter out lap/ripple only keys.\n",
    "# e.g. active_context=curr_active_pipeline.build_display_context_for_session('directional_merged_pf_decoded_epochs', laps_t_bin=laps_decoding_time_bin_size, ripple_t_bin=ripple_decoding_time_bin_size)\n",
    "\t# only want laps_t_bin on the laps plot and ripple_t_bin on the ripples plot\n",
    "laps_only_keys = [item for item in display_context.keys() if 'lap' in item] # items exclusive to laps: ['laps_t_bin']\n",
    "ripple_only_keys = [item for item in display_context.keys() if 'ripple' in item]\n",
    "laps_display_context = display_context.get_subset(subset_excludelist=ripple_only_keys) # laps specific context filtering out the ripple keys\n",
    "ripple_display_context = display_context.get_subset(subset_excludelist=laps_only_keys) # ripple specific context filtering out the laps keys\n",
    "\n",
    "\n",
    "with mpl.rc_context({'figure.figsize': (12.4, 4.8), 'figure.dpi': '220', 'savefig.transparent': True, 'ps.fonttype': 42,\n",
    "\t\t\t\t\t\t\"axes.spines.left\": False, \"axes.spines.right\": False, \"axes.spines.bottom\": False, \"axes.spines.top\": False,\n",
    "\t\t\t\t\t\t\"axes.edgecolor\": \"none\", \"xtick.bottom\": False, \"xtick.top\": False, \"ytick.left\": False, \"ytick.right\": False}):\n",
    "\t# Create a FigureCollector instance\n",
    "\twith FigureCollector(name='plot_all_epoch_bins_marginal_predictions', base_context=display_context) as collector:\n",
    "\n",
    "\t\t## Define common operations to do after making the figure:\n",
    "\t\tdef setup_common_after_creation(a_collector, fig, axes, sub_context, title=f'<size:22> Sig. (>0.95) <weight:bold>Best</> <weight:bold>Quantile Diff</></>'):\n",
    "\t\t\t\"\"\" Captures:\n",
    "\n",
    "\t\t\tt_split, t_start, t_end)\n",
    "\t\t\t\"\"\"\n",
    "\t\t\ta_collector.contexts.append(sub_context)\n",
    "\t\t\t\n",
    "\t\t\tfor ax in (axes if isinstance(axes, Iterable) else [axes]):\n",
    "\t\t\t\t# Update the xlimits with the new bounds\n",
    "\t\t\t\tax.set_ylim(0.0, 1.0)\n",
    "\t\t\t\t# Add epoch indicators\n",
    "\t\t\t\t_tmp_output_dict = PlottingHelpers.helper_matplotlib_add_long_short_epoch_indicator_regions(ax=ax, t_split=t_delta, t_start=t_start, t_end=t_end)\n",
    "\t\t\t\t# Update the xlimits with the new bounds\n",
    "\t\t\t\tax.set_xlim(t_start, t_end)\n",
    "\t\t\t\t# Draw a horizontal line at y=0.5\n",
    "\t\t\t\tax.axhline(y=0.5, color=(0,0,0,1)) # , linestyle='--'\n",
    "\t\t\t\t## This is figure level stuff and only needs to be done once:\n",
    "\t\t\t\t# `flexitext` version:\n",
    "\t\t\t\ttext_formatter = FormattedFigureText()\n",
    "\t\t\t\tax.set_title('')\n",
    "\t\t\t\tfig.suptitle('')\n",
    "\t\t\t\t# top=0.84, bottom=0.125, left=0.07, right=0.97,\n",
    "\t\t\t\t# text_formatter.setup_margins(fig, top_margin=1.0, left_margin=0.0, right_margin=1.0, bottom_margin=0.05)\n",
    "\t\t\t\ttext_formatter.setup_margins(fig, top_margin=0.84, left_margin=0.07, right_margin=0.97, bottom_margin=0.125)\n",
    "\t\t\t\t# fig.subplots_adjust(top=top_margin, left=left_margin, right=right_margin, bottom=bottom_margin)\n",
    "\t\t\t\t# title_text_obj = flexitext(text_formatter.left_margin, text_formatter.top_margin, title, va=\"bottom\", xycoords=\"figure fraction\")\n",
    "\t\t\t\ttitle_text_obj = flexitext(text_formatter.left_margin, 0.98, title, va=\"top\", xycoords=\"figure fraction\") # 0.98, va=\"top\" means the top edge of the title will be aligned to the fig_y=0.98 mark of the figure.\n",
    "\t\t\t\t# footer_text_obj = flexitext((text_formatter.left_margin * 0.1), (text_formatter.bottom_margin * 0.25),\n",
    "\t\t\t\t#                             text_formatter._build_footer_string(active_context=sub_context),\n",
    "\t\t\t\t#                             va=\"top\", xycoords=\"figure fraction\")\n",
    "\n",
    "\t\t\t\tfooter_text_obj = flexitext((text_formatter.left_margin * 0.1), (0.0025), ## (va=\"bottom\", (0.0025)) - this means that the bottom edge of the footer text is aligned with the fig_y=0.0025 in figure space\n",
    "\t\t\t\t\t\t\t\t\t\t\ttext_formatter._build_footer_string(active_context=sub_context),\n",
    "\t\t\t\t\t\t\t\t\t\t\tva=\"bottom\", xycoords=\"figure fraction\")\n",
    "\t\t\n",
    "\t\t\tif ((perform_write_to_file_callback is not None) and (sub_context is not None)):\n",
    "\t\t\t\tperform_write_to_file_callback(sub_context, fig)\n",
    "\t\t\t\n",
    "\t\t# Plot for BestDir\n",
    "\t\tfig, ax = collector.subplots(num='Laps_Marginal', clear=True)\n",
    "\t\t_out_Laps = sns.scatterplot(\n",
    "\t\t\tax=ax,\n",
    "\t\t\tdata=laps_all_epoch_bins_marginals_df,\n",
    "\t\t\tx='t_bin_center',\n",
    "\t\t\ty='P_Long',\n",
    "\t\t\t# size='LR_Long_rel_num_cells',  # Use the 'size' parameter for variable marker sizes\n",
    "\t\t)\n",
    "\t\tsetup_common_after_creation(collector, fig=fig, axes=ax, sub_context=laps_display_context.adding_context('subplot', subplot_name='Laps all_epoch_binned Marginals'), \n",
    "\t\t\t\t\t\t\t\t\ttitle=f'<size:22> Laps <weight:bold>all_epoch_binned</> Marginals</>')\n",
    "\t\t\n",
    "\t\tfig, ax = collector.subplots(num='Ripple_Marginal', clear=True)\n",
    "\t\t_out_Ripple = sns.scatterplot(\n",
    "\t\t\tax=ax,\n",
    "\t\t\tdata=ripple_all_epoch_bins_marginals_df,\n",
    "\t\t\tx='t_bin_center',\n",
    "\t\t\ty='P_Long',\n",
    "\t\t\t# size='LR_Long_rel_num_cells',  # Use the 'size' parameter for variable marker sizes\n",
    "\t\t)\n",
    "\t\tsetup_common_after_creation(collector, fig=fig, axes=ax, sub_context=ripple_display_context.adding_context('subplot', subplot_name='Ripple all_epoch_binned Marginals'), \n",
    "\t\t\t\t\t\ttitle=f'<size:22> Ripple <weight:bold>all_epoch_binned</> Marginals</>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d655560",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_time_bin_marginals_df['lap_idx'] = laps_time_bin_marginals_df.index.to_numpy()\n",
    "laps_time_bin_marginals_df['lap_start_t'] = laps_epochs_df['start'].to_numpy()\n",
    "laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3800d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024-01-19 - Can decode position from the pseudo2D posterior directly, or by using the pseudo2D decoder to determine the best direction and track_id and use the corresponding 1D decoder's predicted position.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f76dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024-01-19 - Export All Epoch Time bin marginals to CSV also\n",
    "## Laps:\n",
    "laps_epochs_df: pd.DataFrame = deepcopy(alt_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result.filter_epochs).to_dataframe()\n",
    "laps_directional_marginals_tuple = DirectionalMergedDecodersResult.determine_directional_likelihoods(alt_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result)\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals = DirectionalMergedDecodersResult.determine_long_short_likelihoods(alt_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result)\n",
    "track_identity_marginals, track_identity_all_epoch_bins_marginal, most_likely_track_identity_from_decoder, is_most_likely_track_identity_Long = laps_track_identity_marginals\n",
    "\n",
    "laps_marginals_df: pd.DataFrame = pd.DataFrame(np.hstack((laps_directional_all_epoch_bins_marginal, track_identity_all_epoch_bins_marginal)), columns=['P_LR', 'P_RL', 'P_Long', 'P_Short'])\n",
    "laps_marginals_df['lap_idx'] = laps_marginals_df.index.to_numpy()\n",
    "laps_marginals_df['lap_start_t'] = laps_epochs_df['start'].to_numpy()\n",
    "laps_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78fbcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(laps_marginals_df)\n",
    "laps_marginals_df.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73c79d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Local computation: check laps\n",
    "laps = curr_active_pipeline.sess.laps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(start=0.030, step=0.01, stop=0.10) # [0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc018065",
   "metadata": {},
   "source": [
    "# Call perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82c6522e",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function\n",
    "\n",
    "BATCH_DATE_TO_USE: str = '2024-02-16_Lab' # TODO: Change this as needed, templating isn't actually doing anything rn.\n",
    "collected_outputs_path = Path('/nfs/turbo/umms-kdiba/Data/Output/collected_outputs').resolve() # Linux\n",
    "# collected_outputs_path: Path = Path('/home/halechr/cloud/turbo/Data/Output/collected_outputs').resolve() # GreatLakes\n",
    "# collected_outputs_path = Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\output\\collected_outputs').resolve() # Apogee\n",
    "\n",
    "\n",
    "def perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(self, global_data_root_parent_path, curr_session_context, curr_session_basedir, curr_active_pipeline, across_session_results_extended_dict: dict, save_hdf=True, save_csvs=True) -> dict:\n",
    "    print(f'<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "    print(f'perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(curr_session_context: {curr_session_context}, curr_session_basedir: {str(curr_session_basedir)}, ...,across_session_results_extended_dict: {across_session_results_extended_dict})')\n",
    "    from copy import deepcopy\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from neuropy.utils.debug_helpers import parameter_sweeps\n",
    "    from neuropy.core.laps import Laps\n",
    "    from neuropy.utils.mixins.binning_helpers import find_minimum_time_bin_duration\n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _check_result_laps_epochs_df_performance\n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalMergedDecodersResult\n",
    "    from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "    # Export CSVs:\n",
    "    def export_marginals_df_csv(marginals_df: pd.DataFrame, data_identifier_str: str, parent_output_path: Path, active_context):\n",
    "        \"\"\" captures nothing\n",
    "        \"\"\"\n",
    "        # output_date_str: str = get_now_rounded_time_str()\n",
    "        output_date_str: str = get_now_day_str()\n",
    "        # parent_output_path: Path = Path('output').resolve()\n",
    "        # active_context = curr_active_pipeline.get_session_context()\n",
    "        session_identifier_str: str = active_context.get_description()\n",
    "        assert output_date_str is not None\n",
    "        out_basename = '-'.join([output_date_str, session_identifier_str, data_identifier_str]) # '2024-01-04|kdiba_gor01_one_2006-6-09_1-22-43|(laps_marginals_df).csv'\n",
    "        out_filename = f\"{out_basename}.csv\"\n",
    "        out_path = parent_output_path.joinpath(out_filename).resolve()\n",
    "        marginals_df.to_csv(out_path)\n",
    "        return out_path \n",
    "\n",
    "\n",
    "    def _subfn_process_time_bin_swept_results(curr_active_pipeline, output_extracted_result_tuples):\n",
    "        \"\"\" After the sweeps are complete and multiple (one for each time_bin_size swept) indepdnent dfs are had with the four results types this function concatenates each of the four into a single dataframe for all time_bin_size values with a column 'time_bin_size'. \n",
    "        It also saves them out to CSVs in a manner similar to what `compute_and_export_marginals_dfs_completion_function` did to be compatible with `2024-01-23 - Across Session Point and YellowBlue Marginal CSV Exports.ipynb`\n",
    "        Captures: save_csvs\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        several_time_bin_sizes_laps_time_bin_marginals_df_list = []\n",
    "        several_time_bin_sizes_laps_per_epoch_marginals_df_list = []\n",
    "\n",
    "        several_time_bin_sizes_ripple_time_bin_marginals_df_list = []\n",
    "        several_time_bin_sizes_ripple_per_epoch_marginals_df_list = []\n",
    "\n",
    "\n",
    "        # for a_sweep_tuple, (a_laps_time_bin_marginals_df, a_laps_all_epoch_bins_marginals_df) in output_extracted_result_tuples.items():\n",
    "        for a_sweep_tuple, (a_laps_time_bin_marginals_df, a_laps_all_epoch_bins_marginals_df, a_ripple_time_bin_marginals_df, a_ripple_all_epoch_bins_marginals_df) in output_extracted_result_tuples.items():\n",
    "            a_sweep_dict = dict(a_sweep_tuple)\n",
    "            \n",
    "            # Shared\n",
    "            desired_laps_decoding_time_bin_size = float(a_sweep_dict['desired_shared_decoding_time_bin_size'])\n",
    "            desired_ripple_decoding_time_bin_size = float(a_sweep_dict['desired_shared_decoding_time_bin_size'])\n",
    "            \n",
    "            # a_laps_time_bin_marginals_df.\n",
    "            df = a_laps_time_bin_marginals_df\n",
    "            df['time_bin_size'] = desired_laps_decoding_time_bin_size # desired_laps_decoding_time_bin_size\n",
    "            # df['session_name'] = session_name\n",
    "            df = a_laps_all_epoch_bins_marginals_df\n",
    "            df['time_bin_size'] = desired_laps_decoding_time_bin_size\n",
    "\n",
    "            df = a_ripple_time_bin_marginals_df\n",
    "            df['time_bin_size'] = desired_ripple_decoding_time_bin_size\n",
    "            df = a_ripple_all_epoch_bins_marginals_df\n",
    "            df['time_bin_size'] = desired_ripple_decoding_time_bin_size\n",
    "\n",
    "            several_time_bin_sizes_laps_time_bin_marginals_df_list.append(a_laps_time_bin_marginals_df)\n",
    "            several_time_bin_sizes_laps_per_epoch_marginals_df_list.append(a_laps_all_epoch_bins_marginals_df)\n",
    "            \n",
    "            several_time_bin_sizes_ripple_time_bin_marginals_df_list.append(a_ripple_time_bin_marginals_df)\n",
    "            several_time_bin_sizes_ripple_per_epoch_marginals_df_list.append(a_ripple_all_epoch_bins_marginals_df)\n",
    "\n",
    "\n",
    "        ## Build across_sessions join dataframes:\n",
    "        several_time_bin_sizes_time_bin_laps_df: pd.DataFrame = pd.concat(several_time_bin_sizes_laps_time_bin_marginals_df_list, axis='index', ignore_index=True)\n",
    "        several_time_bin_sizes_laps_df: pd.DataFrame = pd.concat(several_time_bin_sizes_laps_per_epoch_marginals_df_list, axis='index', ignore_index=True) # per epoch\n",
    "\n",
    "        several_time_bin_sizes_time_bin_ripple_df: pd.DataFrame = pd.concat(several_time_bin_sizes_ripple_time_bin_marginals_df_list, axis='index', ignore_index=True)\n",
    "        several_time_bin_sizes_ripple_df: pd.DataFrame = pd.concat(several_time_bin_sizes_ripple_per_epoch_marginals_df_list, axis='index', ignore_index=True) # per epoch\n",
    "\n",
    "        # Export time_bin_swept results to CSVs:\n",
    "        if save_csvs:\n",
    "            assert collected_outputs_path.exists()\n",
    "            active_context = curr_active_pipeline.get_session_context()\n",
    "            laps_time_bin_marginals_out_path = export_marginals_df_csv(several_time_bin_sizes_time_bin_laps_df, data_identifier_str=f'(laps_time_bin_marginals_df)', parent_output_path=collected_outputs_path, active_context=active_context)\n",
    "            laps_out_path = export_marginals_df_csv(several_time_bin_sizes_laps_df, data_identifier_str=f'(laps_marginals_df)', parent_output_path=collected_outputs_path, active_context=active_context)\n",
    "            ripple_time_bin_marginals_out_path = export_marginals_df_csv(several_time_bin_sizes_time_bin_ripple_df, data_identifier_str=f'(ripple_time_bin_marginals_df)', parent_output_path=collected_outputs_path, active_context=active_context)\n",
    "            ripple_out_path = export_marginals_df_csv(several_time_bin_sizes_ripple_df, data_identifier_str=f'(ripple_marginals_df)', parent_output_path=collected_outputs_path, active_context=active_context)\n",
    "        else:\n",
    "            laps_time_bin_marginals_out_path, laps_out_path, ripple_time_bin_marginals_out_path, ripple_out_path = None, None, None, None\n",
    "            \n",
    "        return (several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path)\n",
    "        # (several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path)\n",
    "        \n",
    "\n",
    "\n",
    "    def add_session_df_columns(df: pd.DataFrame, session_name: str, curr_session_t_delta: Optional[float], time_col: str) -> pd.DataFrame:\n",
    "        \"\"\" adds session-specific information to the marginal dataframes \"\"\"\n",
    "        df['session_name'] = session_name \n",
    "        if curr_session_t_delta is not None:\n",
    "            df['delta_aligned_start_t'] = df[time_col] - curr_session_t_delta\n",
    "        return df\n",
    "\n",
    "\n",
    "    ## Single decode:\n",
    "    def _try_single_decode(owning_pipeline_reference, directional_merged_decoders_result, use_single_time_bin_per_epoch: bool, desired_laps_decoding_time_bin_size: Optional[float]=None, desired_ripple_decoding_time_bin_size: Optional[float]=None, desired_shared_decoding_time_bin_size: Optional[float]=None, minimum_event_duration: Optional[float]=None):\n",
    "        \"\"\" decodes laps and ripples for a single bin size. \n",
    "        \n",
    "        minimum_event_duration: if provided, excludes all events shorter than minimum_event_duration\n",
    "        \"\"\"\n",
    "        if desired_shared_decoding_time_bin_size is not None:\n",
    "            assert desired_laps_decoding_time_bin_size is None\n",
    "            assert desired_ripple_decoding_time_bin_size is None\n",
    "            desired_laps_decoding_time_bin_size = desired_shared_decoding_time_bin_size\n",
    "            desired_ripple_decoding_time_bin_size = desired_shared_decoding_time_bin_size\n",
    "            \n",
    "\n",
    "        ## Decode Laps:\n",
    "        laps_epochs_df = deepcopy(directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result.filter_epochs)\n",
    "        if not isinstance(laps_epochs_df, pd.DataFrame):\n",
    "            laps_epochs_df = laps_epochs_df.to_dataframe()\n",
    "        # global_any_laps_epochs_obj = deepcopy(owning_pipeline_reference.computation_results[global_epoch_name].computation_config.pf_params.computation_epochs) # global_epoch_name='maze_any' (? same as global_epoch_name?)\n",
    "        min_possible_laps_time_bin_size: float = find_minimum_time_bin_duration(laps_epochs_df['duration'].to_numpy())\n",
    "        min_bounded_laps_decoding_time_bin_size: float = min(desired_laps_decoding_time_bin_size, min_possible_laps_time_bin_size) # 10ms # 0.002\n",
    "        if desired_laps_decoding_time_bin_size < min_bounded_laps_decoding_time_bin_size:\n",
    "            print(f'WARN: desired_laps_decoding_time_bin_size: {desired_laps_decoding_time_bin_size} < min_bounded_laps_decoding_time_bin_size: {min_bounded_laps_decoding_time_bin_size}... hopefully it works.')\n",
    "        laps_decoding_time_bin_size: float = desired_laps_decoding_time_bin_size # allow direct use\n",
    "        if use_single_time_bin_per_epoch:\n",
    "            laps_decoding_time_bin_size = None\n",
    "        directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result = directional_merged_decoders_result.all_directional_pf1D_Decoder.decode_specific_epochs(spikes_df=deepcopy(owning_pipeline_reference.sess.spikes_df), filter_epochs=laps_epochs_df,\n",
    "                                                                                                                                                        decoding_time_bin_size=laps_decoding_time_bin_size, use_single_time_bin_per_epoch=use_single_time_bin_per_epoch, debug_print=False)\n",
    "        \n",
    "\n",
    "        ## Decode Ripples:\n",
    "        if desired_ripple_decoding_time_bin_size is not None:\n",
    "            # global_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(owning_pipeline_reference.filtered_sessions[global_epoch_name].replay))\n",
    "            replay_epochs_df = deepcopy(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result.filter_epochs)\n",
    "            if not isinstance(replay_epochs_df, pd.DataFrame):\n",
    "                replay_epochs_df = replay_epochs_df.to_dataframe()\n",
    "            # min_possible_ripple_time_bin_size: float = find_minimum_time_bin_duration(replay_epochs_df['duration'].to_numpy())\n",
    "            # min_bounded_ripple_decoding_time_bin_size: float = min(desired_ripple_decoding_time_bin_size, min_possible_ripple_time_bin_size) # 10ms # 0.002\n",
    "            # if desired_ripple_decoding_time_bin_size < min_bounded_ripple_decoding_time_bin_size:\n",
    "            #     print(f'WARN: desired_ripple_decoding_time_bin_size: {desired_ripple_decoding_time_bin_size} < min_bounded_ripple_decoding_time_bin_size: {min_bounded_ripple_decoding_time_bin_size}... hopefully it works.')\n",
    "            ripple_decoding_time_bin_size: float = desired_ripple_decoding_time_bin_size # allow direct use            \n",
    "            ## Drop those less than the time bin duration\n",
    "            print(f'DropShorterMode:')\n",
    "            pre_drop_n_epochs = len(replay_epochs_df)\n",
    "            if minimum_event_duration is not None:                \n",
    "                replay_epochs_df = replay_epochs_df[replay_epochs_df['duration'] > minimum_event_duration]\n",
    "                post_drop_n_epochs = len(replay_epochs_df)\n",
    "                n_dropped_epochs = post_drop_n_epochs - pre_drop_n_epochs\n",
    "                print(f'\\tminimum_event_duration present (minimum_event_duration={minimum_event_duration}).\\n\\tdropping {n_dropped_epochs} that are shorter than our minimum_event_duration of {minimum_event_duration}.', end='\\t')\n",
    "            else:\n",
    "                replay_epochs_df = replay_epochs_df[replay_epochs_df['duration'] > desired_ripple_decoding_time_bin_size]\n",
    "                post_drop_n_epochs = len(replay_epochs_df)\n",
    "                n_dropped_epochs = post_drop_n_epochs - pre_drop_n_epochs\n",
    "                print(f'\\tdropping {n_dropped_epochs} that are shorter than our ripple decoding time bin size of {desired_ripple_decoding_time_bin_size}', end='\\t') \n",
    "\n",
    "            print(f'{post_drop_n_epochs} remain.')\n",
    "            directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result = directional_merged_decoders_result.all_directional_pf1D_Decoder.decode_specific_epochs(spikes_df=deepcopy(owning_pipeline_reference.sess.spikes_df), filter_epochs=replay_epochs_df,\n",
    "                                                                                                                                                                                            decoding_time_bin_size=ripple_decoding_time_bin_size, use_single_time_bin_per_epoch=use_single_time_bin_per_epoch, debug_print=False)\n",
    "\n",
    "        directional_merged_decoders_result.perform_compute_marginals()\n",
    "        return directional_merged_decoders_result\n",
    "        \n",
    "\n",
    "    def _update_result_laps(a_result: DecodedFilterEpochsResult, laps_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\" captures nothing. Can reusing the same laps_df as it makes no modifications to it. \n",
    "        \n",
    "        e.g. a_result=output_alt_directional_merged_decoders_result[a_sweep_tuple]\n",
    "        \"\"\"\n",
    "        result_laps_epochs_df: pd.DataFrame = a_result.laps_epochs_df\n",
    "        ## 2024-01-17 - Updates the `a_directional_merged_decoders_result.laps_epochs_df` with both the ground-truth values and the decoded predictions\n",
    "        result_laps_epochs_df['maze_id'] = laps_df['maze_id'].to_numpy()[np.isin(laps_df['lap_id'], result_laps_epochs_df['lap_id'])] # this works despite the different size because of the index matching\n",
    "        ## add the 'is_LR_dir' groud-truth column in:\n",
    "        result_laps_epochs_df['is_LR_dir'] = laps_df['is_LR_dir'].to_numpy()[np.isin(laps_df['lap_id'], result_laps_epochs_df['lap_id'])] # this works despite the different size because of the index matching\n",
    "        \n",
    "        laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir = a_result.laps_directional_marginals_tuple\n",
    "        laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = a_result.laps_track_identity_marginals_tuple\n",
    "        ## Add the decoded results to the laps df:\n",
    "        result_laps_epochs_df['is_most_likely_track_identity_Long'] = laps_is_most_likely_track_identity_Long\n",
    "        result_laps_epochs_df['is_most_likely_direction_LR'] = laps_is_most_likely_direction_LR_dir\n",
    "        return result_laps_epochs_df\n",
    "\n",
    "    # BEGIN FUNCTION BODY ________________________________________________________________________________________________ #\n",
    "    assert collected_outputs_path.exists()\n",
    "    curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "    CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "    print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "    active_context = curr_active_pipeline.get_session_context()\n",
    "    session_ctxt_key:str = active_context.get_description(separator='|', subset_includelist=IdentifyingContext._get_session_context_keys())\n",
    "    \n",
    "    ## INPUT PARAMETER: time_bin_size sweep paraemters\n",
    "    desired_shared_decoding_time_bin_size = np.linspace(start=0.030, stop=0.10, num=6)\n",
    "    \n",
    "    # Shared time bin sizes\n",
    "    # all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_sizes, use_single_time_bin_per_epoch=[False], desired_ripple_decoding_time_bin_size=[None])\n",
    "    all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_shared_decoding_time_bin_size=desired_shared_decoding_time_bin_size, use_single_time_bin_per_epoch=[False], minimum_event_duration=[desired_shared_decoding_time_bin_size[-1]]) # with Ripples\n",
    "    # len(all_param_sweep_options)\n",
    "    \n",
    "    ## Perfrom the computations:\n",
    "\n",
    "    # DirectionalMergedDecoders: Get the result after computation:\n",
    "    ## Copy the default result:\n",
    "    directional_merged_decoders_result: DirectionalMergedDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "    alt_directional_merged_decoders_result: DirectionalMergedDecodersResult = deepcopy(directional_merged_decoders_result)\n",
    "\n",
    "    # out_path_basename_str: str = f\"{now_day_str}_{active_context}_time_bin_size-{laps_decoding_time_bin_size}_{data_identifier_str}\"\n",
    "    # out_path_basename_str: str = f\"{now_day_str}_{active_context}_time_bin_size_sweep_results\"\n",
    "    out_path_basename_str: str = f\"{CURR_BATCH_OUTPUT_PREFIX}_time_bin_size_sweep_results\"\n",
    "    # out_path_filenname_str: str = f\"{out_path_basename_str}.csv\"\n",
    "\n",
    "    out_path_filenname_str: str = f\"{out_path_basename_str}.h5\"\n",
    "    out_path: Path = collected_outputs_path.resolve().joinpath(out_path_filenname_str).resolve()\n",
    "    print(f'\\out_path_str: \"{out_path_filenname_str}\"')\n",
    "    print(f'\\tout_path: \"{out_path}\"')\n",
    "    \n",
    "    # Ensure it has the 'lap_track' column\n",
    "    ## Compute the ground-truth information using the position information:\n",
    "    # adds columns: ['maze_id', 'is_LR_dir']\n",
    "    t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "    laps_obj: Laps = curr_active_pipeline.sess.laps\n",
    "    laps_obj.update_lap_dir_from_smoothed_velocity(pos_input=curr_active_pipeline.sess.position)\n",
    "    laps_obj.update_maze_id_if_needed(t_start=t_start, t_delta=t_delta, t_end=t_end)\n",
    "    laps_df = laps_obj.to_dataframe()\n",
    "    \n",
    "    # Uses: session_ctxt_key, all_param_sweep_options\n",
    "    output_alt_directional_merged_decoders_result = {} # empty dict\n",
    "    output_laps_decoding_accuracy_results_dict = {} # empty dict\n",
    "    output_extracted_result_tuples = {}\n",
    "\n",
    "    for a_sweep_dict in all_param_sweep_options:\n",
    "        a_sweep_tuple = frozenset(a_sweep_dict.items())\n",
    "        print(f'a_sweep_dict: {a_sweep_dict}')\n",
    "        # Convert parameters to string because Parquet supports metadata as string\n",
    "        a_sweep_str_params = {key: str(value) for key, value in a_sweep_dict.items() if value is not None}\n",
    "        \n",
    "        output_alt_directional_merged_decoders_result[a_sweep_tuple] = _try_single_decode(curr_active_pipeline, alt_directional_merged_decoders_result, **a_sweep_dict)\n",
    "\n",
    "        laps_time_bin_marginals_df: pd.DataFrame = output_alt_directional_merged_decoders_result[a_sweep_tuple].laps_time_bin_marginals_df.copy()\n",
    "        laps_all_epoch_bins_marginals_df: pd.DataFrame = output_alt_directional_merged_decoders_result[a_sweep_tuple].laps_all_epoch_bins_marginals_df.copy()\n",
    "        \n",
    "        ## Ripples:\n",
    "        ripple_time_bin_marginals_df: pd.DataFrame = output_alt_directional_merged_decoders_result[a_sweep_tuple].ripple_time_bin_marginals_df.copy()\n",
    "        ripple_all_epoch_bins_marginals_df: pd.DataFrame = output_alt_directional_merged_decoders_result[a_sweep_tuple].ripple_all_epoch_bins_marginals_df.copy()\n",
    "\n",
    "        session_name = curr_session_name\n",
    "        curr_session_t_delta = t_delta\n",
    "        \n",
    "        for a_df, a_time_bin_column_name in zip((laps_time_bin_marginals_df, laps_all_epoch_bins_marginals_df, ripple_time_bin_marginals_df, ripple_all_epoch_bins_marginals_df), ('t_bin_center', 'lap_start_t', 't_bin_center', 'ripple_start_t')):\n",
    "            ## Add the session-specific columns:\n",
    "            a_df = add_session_df_columns(a_df, session_name, curr_session_t_delta, a_time_bin_column_name)\n",
    "\n",
    "        ## Build the output tuple:\n",
    "        output_extracted_result_tuples[a_sweep_tuple] = (laps_time_bin_marginals_df, laps_all_epoch_bins_marginals_df, ripple_time_bin_marginals_df, ripple_all_epoch_bins_marginals_df)\n",
    "        \n",
    "        # desired_laps_decoding_time_bin_size_str: str = a_sweep_str_params.get('desired_laps_decoding_time_bin_size', None)\n",
    "        laps_decoding_time_bin_size: float = output_alt_directional_merged_decoders_result[a_sweep_tuple].laps_decoding_time_bin_size\n",
    "        # ripple_decoding_time_bin_size: float = output_alt_directional_merged_decoders_result[a_sweep_tuple].ripple_decoding_time_bin_size\n",
    "        actual_laps_decoding_time_bin_size_str: str = str(laps_decoding_time_bin_size)\n",
    "        if save_hdf and (actual_laps_decoding_time_bin_size_str is not None):\n",
    "            laps_time_bin_marginals_df.to_hdf(out_path, key=f'{session_ctxt_key}/{actual_laps_decoding_time_bin_size_str}/laps_time_bin_marginals_df', format='table', data_columns=True)\n",
    "            laps_all_epoch_bins_marginals_df.to_hdf(out_path, key=f'{session_ctxt_key}/{actual_laps_decoding_time_bin_size_str}/laps_all_epoch_bins_marginals_df', format='table', data_columns=True)\n",
    "\n",
    "        ## TODO: output ripple .h5 here if desired.\n",
    "            \n",
    "\n",
    "        # get the current lap object and determine the percentage correct:\n",
    "        result_laps_epochs_df: pd.DataFrame = _update_result_laps(a_result=output_alt_directional_merged_decoders_result[a_sweep_tuple], laps_df=laps_df)\n",
    "        (is_decoded_track_correct, is_decoded_dir_correct, are_both_decoded_properties_correct), (percent_laps_track_identity_estimated_correctly, percent_laps_direction_estimated_correctly, percent_laps_estimated_correctly) = _check_result_laps_epochs_df_performance(result_laps_epochs_df)\n",
    "        output_laps_decoding_accuracy_results_dict[laps_decoding_time_bin_size] = (percent_laps_track_identity_estimated_correctly, percent_laps_direction_estimated_correctly, percent_laps_estimated_correctly)\n",
    "        \n",
    "\n",
    "    ## Output the performance:\n",
    "    output_laps_decoding_accuracy_results_df: pd.DataFrame = pd.DataFrame(output_laps_decoding_accuracy_results_dict.values(), index=output_laps_decoding_accuracy_results_dict.keys(), \n",
    "                    columns=['percent_laps_track_identity_estimated_correctly',\n",
    "                            'percent_laps_direction_estimated_correctly',\n",
    "                            'percent_laps_estimated_correctly'])\n",
    "    output_laps_decoding_accuracy_results_df.index.name = 'laps_decoding_time_bin_size'\n",
    "    ## Save out the laps peformance result\n",
    "    if save_hdf:\n",
    "        output_laps_decoding_accuracy_results_df.to_hdf(out_path, key=f'{session_ctxt_key}/laps_decoding_accuracy_results', format='table', data_columns=True)\n",
    "\n",
    "    ## Call the subfunction to process the time_bin_size swept result and produce combined output dataframes:\n",
    "    combined_multi_timebin_outputs_tuple = _subfn_process_time_bin_swept_results(curr_active_pipeline, output_extracted_result_tuples)\n",
    "    # Unpacking:    \n",
    "    # (several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\n",
    "\n",
    "    # add to output dict\n",
    "    # across_session_results_extended_dict['compute_and_export_marginals_dfs_completion_function'] = _out\n",
    "    across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function'] = (out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple)\n",
    "    # can unpack like:\n",
    "    (several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\n",
    "\n",
    "    print(f'>>\\t done with {curr_session_context}')\n",
    "    print(f'>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "    print(f'>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "\n",
    "    return across_session_results_extended_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "773e9f51",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0f6b31",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "## Combine the output of `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(None, None,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tacross_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=False)\n",
    "out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "(several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a71abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_file_pat\n",
    "collected_outputs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_laps_decoding_accuracy_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd970d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_histograms( data_type: str, session_spec: str, data_results_df: pd.DataFrame, time_bin_duration_str: str ) -> None:\n",
    "#     # get the pre-delta epochs\n",
    "#     pre_delta_df = data_results_df[data_results_df['delta_aligned_start_t'] <= 0]\n",
    "#     post_delta_df = data_results_df[data_results_df['delta_aligned_start_t'] > 0]\n",
    "\n",
    "#     descriptor_str: str = '|'.join([data_type, session_spec, time_bin_duration_str])\n",
    "    \n",
    "#     # plot pre-delta histogram\n",
    "#     pre_delta_df.hist(column='P_Long')\n",
    "#     plt.title(f'{descriptor_str} - pre-$\\Delta$ time bins')\n",
    "#     plt.show()\n",
    "\n",
    "#     # plot post-delta histogram\n",
    "#     post_delta_df.hist(column='P_Long')\n",
    "#     plt.title(f'{descriptor_str} - post-$\\Delta$ time bins')\n",
    "#     plt.show()\n",
    "    \n",
    "\n",
    "def plot_histograms(data_type: str, session_spec: str, data_results_df: pd.DataFrame, time_bin_duration_str: str) -> None:\n",
    "    \"\"\" plots a stacked histogram of the many time-bin sizes \"\"\"\n",
    "    # get the pre-delta epochs\n",
    "    pre_delta_df = data_results_df[data_results_df['delta_aligned_start_t'] <= 0]\n",
    "    post_delta_df = data_results_df[data_results_df['delta_aligned_start_t'] > 0]\n",
    "\n",
    "    descriptor_str: str = '|'.join([data_type, session_spec, time_bin_duration_str])\n",
    "    \n",
    "    # plot pre-delta histogram\n",
    "    time_bin_sizes = pre_delta_df['time_bin_size'].unique()\n",
    "    \n",
    "    figure_identifier: str = f\"{descriptor_str}_preDelta\"\n",
    "    plt.figure(num=figure_identifier, clear=True, figsize=(6, 2))\n",
    "    for time_bin_size in time_bin_sizes:\n",
    "        df_tbs = pre_delta_df[pre_delta_df['time_bin_size']==time_bin_size]\n",
    "        df_tbs['P_Long'].hist(alpha=0.5, label=str(time_bin_size)) \n",
    "    \n",
    "    plt.title(f'{descriptor_str} - pre-$\\Delta$ time bins')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # plot post-delta histogram\n",
    "    time_bin_sizes = post_delta_df['time_bin_size'].unique()\n",
    "    figure_identifier: str = f\"{descriptor_str}_postDelta\"\n",
    "    plt.figure(num=figure_identifier, clear=True, figsize=(6, 2))\n",
    "    for time_bin_size in time_bin_sizes:\n",
    "        df_tbs = post_delta_df[post_delta_df['time_bin_size']==time_bin_size]\n",
    "        df_tbs['P_Long'].hist(alpha=0.5, label=str(time_bin_size)) \n",
    "    \n",
    "    plt.title(f'{descriptor_str} - post-$\\Delta$ time bins')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# # You can use it like this:\n",
    "# plot_histograms('Laps', 'All Sessions', all_sessions_laps_time_bin_df, \"75 ms\")\n",
    "# plot_histograms('Ripples', 'All Sessions', all_sessions_ripple_time_bin_df, \"75 ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd6f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from neuropy.utils.matplotlib_helpers import pho_jointplot\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# def pho_jointplot(*args, **kwargs):\n",
    "# \t\"\"\" wraps sns.jointplot to allow adding titles/axis labels/etc.\"\"\"\n",
    "# \ttitle = kwargs.pop('title', None)\n",
    "# \t_out = sns.jointplot(*args, **kwargs)\n",
    "# \tif title is not None:\n",
    "# \t\tplt.suptitle(title)\n",
    "# \treturn _out\n",
    "\n",
    "common_kwargs = dict(ylim=(0,1), hue='time_bin_size') # , marginal_kws=dict(bins=25, fill=True)\n",
    "# sns.jointplot(data=a_laps_all_epoch_bins_marginals_df, x='lap_start_t', y='P_Long', kind=\"scatter\", color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per epoch') #color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per epoch')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per time bin')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per time bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43311ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use it like this:\n",
    "plot_histograms('Laps', 'One Session', several_time_bin_sizes_time_bin_laps_df, \"several\")\n",
    "plot_histograms('Ripples', 'One Session', several_time_bin_sizes_time_bin_ripple_df, \"several\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "several_time_bin_sizes_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(\n",
    "#     several_time_bin_sizes_laps_df, x=\"P_Long\", col=\"species\", row=\"time_bin_size\",\n",
    "#     binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    "# )\n",
    "\n",
    "sns.displot(\n",
    "    several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', row=\"time_bin_size\",\n",
    "    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be351c18",
   "metadata": {},
   "source": [
    "# 2024-01-31 - Reinvestigation regarding remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "911d7495",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncationCheckingResults(_VersionedResultMixin_version='2024.01.10_0', disappearing_endcap_aclus=Int64Index([19, 34, 83], dtype='int64'), non_disappearing_endcap_aclus=Int64Index([13, 14, 15, 16, 18, 25, 26, 28, 32, 40, 43, 47, 51, 52, 56, 57, 59, 60, 61, 62, 67, 68, 70, 71, 77, 84, 85, 87, 89, 95, 101, 102], dtype='int64'), significant_distant_remapping_endcap_aclus=Int64Index([14, 15, 25, 40, 43, 47, 56, 57, 60, 61, 62, 68, 84, 89], dtype='int64'), minor_remapping_endcap_aclus=Int64Index([13, 16, 18, 26, 28, 32, 51, 52, 59, 67, 70, 71, 77, 85, 87, 95, 101, 102], dtype='int64'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## long_short_endcap_analysis:\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "truncation_checking_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d9b54",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "## From Jonathan Long/Short Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3641aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "neuron_replay_stats_df = deepcopy(jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "\n",
    "## try to add the 2D peak information to the cells in `neuron_replay_stats_df`:\n",
    "neuron_replay_stats_df['long_pf2D_peak_x'] = pd.NA\n",
    "neuron_replay_stats_df['short_pf2D_peak_x'] = pd.NA\n",
    "neuron_replay_stats_df['long_pf2D_peak_y'] = pd.NA\n",
    "neuron_replay_stats_df['short_pf2D_peak_y'] = pd.NA\n",
    "\n",
    "# flat_peaks_df: pd.DataFrame = deepcopy(active_peak_prominence_2d_results['flat_peaks_df']).reset_index(drop=True)\n",
    "long_filtered_flat_peaks_df: pd.DataFrame = deepcopy(curr_active_pipeline.computation_results[long_any_name].computed_data['RatemapPeaksAnalysis']['PeakProminence2D']['filtered_flat_peaks_df']).reset_index(drop=True)\n",
    "short_filtered_flat_peaks_df: pd.DataFrame = deepcopy(curr_active_pipeline.computation_results[short_any_name].computed_data['RatemapPeaksAnalysis']['PeakProminence2D']['filtered_flat_peaks_df']).reset_index(drop=True)\n",
    "\n",
    "neuron_replay_stats_df.loc[np.isin(neuron_replay_stats_df['aclu'].to_numpy(), long_filtered_flat_peaks_df.neuron_id.to_numpy()), ['long_pf2D_peak_x', 'long_pf2D_peak_y']] = long_filtered_flat_peaks_df[['peak_center_x', 'peak_center_y']].to_numpy()\n",
    "neuron_replay_stats_df.loc[np.isin(neuron_replay_stats_df['aclu'].to_numpy(), short_filtered_flat_peaks_df.neuron_id.to_numpy()), ['short_pf2D_peak_x', 'short_pf2D_peak_y']] = short_filtered_flat_peaks_df[['peak_center_x', 'peak_center_y']].to_numpy()\n",
    "\n",
    "both_included_neuron_stats_df = deepcopy(neuron_replay_stats_df[neuron_replay_stats_df['LS_pf_peak_x_diff'].notnull()]).drop(columns=['track_membership', 'neuron_type'])\n",
    "both_included_neuron_stats_df\n",
    "# both_included_neuron_stats_df['LS_pf_peak_x_diff'].plot()\n",
    "\n",
    "# both_included_neuron_stats_df['LS_pf_peak_x_diff'].plot()\n",
    "\n",
    "# _out_scatter = sns.scatterplot(both_included_neuron_stats_df, x='LS_pf_peak_x_diff', y='aclu') # , hue='aclu'\n",
    "# _out_scatter.show()\n",
    "# _out_hist = sns.histplot(both_included_neuron_stats_df, x='LS_pf_peak_x_diff', bins=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b50ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf_aclus = both_included_neuron_stats_df.aclu[both_included_neuron_stats_df.has_long_pf].to_numpy()\n",
    "short_pf_aclus = both_included_neuron_stats_df.aclu[both_included_neuron_stats_df.has_short_pf].to_numpy()\n",
    "\n",
    "long_pf_aclus, short_pf_aclus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d18cfba",
   "metadata": {},
   "source": [
    "## 2024-02-06 - `directional_compute_trial_by_trial_correlation_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c383e8ea",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   4,   5,   6,   8,   9,  11,  12,  14,  15,  16,  18,  19,  20,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  38,  39,  40,  43,  44,  47,  48,  51,  52,  53,  56,  57,  58,  59,  60,  61,  62,  63,  66,  67,  68,  70,  71,  72,  75,  77,  79,  80,  81,  82,  83,  84,  85,  86,  87,  89,  90,  91,  92,  93,  95,  98, 101, 102, 104])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent\n",
    "# from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import compute_spatial_binned_activity_via_pfdt, compute_trial_by_trial_correlation_matrix\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import TrialByTrialActivity\n",
    "\n",
    "any_decoder_neuron_IDs = deepcopy(track_templates.any_decoder_neuron_IDs)\n",
    "any_decoder_neuron_IDs\n",
    "\n",
    "# track_templates.shared_LR_aclus_only_neuron_IDs\n",
    "# track_templates.shared_RL_aclus_only_neuron_IDs\n",
    "\n",
    "\n",
    "## Directional Trial-by-Trial Activity:\n",
    "if 'pf1D_dt' not in curr_active_pipeline.computation_results[global_epoch_name].computed_data:\n",
    "\t# if `KeyError: 'pf1D_dt'` recompute\n",
    "\tcurr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['pfdt_computation'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "\n",
    "active_pf_1D_dt: PfND_TimeDependent = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf1D_dt'])\n",
    "active_pf_2D_dt: PfND_TimeDependent = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf2D_dt'])\n",
    "\n",
    "active_pf_dt: PfND_TimeDependent = deepcopy(active_pf_1D_dt)\n",
    "# active_pf_dt.res\n",
    "# Limit only to the placefield aclus:\n",
    "active_pf_dt = active_pf_dt.get_by_id(ids=any_decoder_neuron_IDs)\n",
    "\n",
    "# active_pf_dt: PfND_TimeDependent = deepcopy(active_pf_2D_dt) # 2D\n",
    "long_LR_name, long_RL_name, short_LR_name, short_RL_name = track_templates.get_decoder_names()\n",
    "\n",
    "directional_lap_epochs_dict = dict(zip((long_LR_name, long_RL_name, short_LR_name, short_RL_name), (long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj)))\n",
    "directional_active_lap_pf_results_dicts = TrialByTrialActivity.directional_compute_trial_by_trial_correlation_matrix(active_pf_dt=active_pf_dt, directional_lap_epochs_dict=directional_lap_epochs_dict, included_neuron_IDs=any_decoder_neuron_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3c34fd9",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aclu</th>\n",
       "      <th>subpeak_idx</th>\n",
       "      <th>long_LR_peak</th>\n",
       "      <th>long_RL_peak</th>\n",
       "      <th>short_LR_peak</th>\n",
       "      <th>short_RL_peak</th>\n",
       "      <th>long_LR_peak_height</th>\n",
       "      <th>long_RL_peak_height</th>\n",
       "      <th>short_LR_peak_height</th>\n",
       "      <th>short_RL_peak_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139.332466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.527049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.251209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.631616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>154.554135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.554135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204.024557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.298047</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.359552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146.943300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181.192054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.635391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.662477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.219140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207.829974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.608306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.667461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.613289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124.110798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.816431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.306938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.137883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.222445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>158.359552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.748717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aclu  subpeak_idx  long_LR_peak  long_RL_peak  short_LR_peak  short_RL_peak  long_LR_peak_height  long_RL_peak_height  short_LR_peak_height  short_RL_peak_height\n",
       "0       2            0           NaN    139.332466            NaN     135.527049                  NaN             1.000000                   NaN              1.000000\n",
       "1       2            1           NaN           NaN            NaN      82.251209                  NaN                  NaN                   NaN              0.631616\n",
       "2       4            0    154.554135           NaN     154.554135            NaN                  1.0                  NaN              1.000000                   NaN\n",
       "3       4            1           NaN           NaN     204.024557            NaN                  NaN                  NaN              0.298047                   NaN\n",
       "4       5            0           NaN    158.359552            NaN     146.943300                  NaN             1.000000                   NaN              1.000000\n",
       "5       6            0           NaN    181.192054            NaN     211.635391                  NaN             1.000000                   NaN              1.000000\n",
       "..    ...          ...           ...           ...            ...            ...                  ...                  ...                   ...                   ...\n",
       "176   102            0           NaN    230.662477            NaN     200.219140                  NaN             1.000000                   NaN              1.000000\n",
       "177   102            0           NaN           NaN     207.829974            NaN                  NaN                  NaN              1.000000                   NaN\n",
       "178   104            0           NaN    192.608306            NaN      93.667461                  NaN             1.000000                   NaN              1.000000\n",
       "179   104            1           NaN     55.613289            NaN     124.110798                  NaN             0.816431                   NaN              0.306938\n",
       "180   104            2           NaN           NaN            NaN     143.137883                  NaN                  NaN                   NaN              0.222445\n",
       "181   104            0    158.359552           NaN     150.748717            NaN                  1.0                  NaN              1.000000                   NaN\n",
       "\n",
       "[182 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "decoder_aclu_peak_location_df_merged = deepcopy(track_templates.get_decoders_aclu_peak_location_df(width=None)).drop(columns=['series_idx', 'LR_peak_diff', 'RL_peak_diff'])\n",
    "# decoder_aclu_peak_location_df_merged[np.isin(decoder_aclu_peak_location_df_merged['aclu'], both_included_neuron_stats_df.aclu.to_numpy())]\n",
    "decoder_aclu_peak_location_df_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b01804af",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aclu</th>\n",
       "      <th>long_LR_num_peaks</th>\n",
       "      <th>long_RL_num_peaks</th>\n",
       "      <th>short_LR_num_peaks</th>\n",
       "      <th>short_RL_num_peaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aclu  long_LR_num_peaks  long_RL_num_peaks  short_LR_num_peaks  short_RL_num_peaks\n",
       "0      2                  0                  1                   0                   2\n",
       "1      4                  1                  0                   2                   0\n",
       "2      5                  0                  1                   0                   1\n",
       "3      6                  0                  1                   0                   2\n",
       "4      8                  0                  1                   0                   2\n",
       "5      9                  1                  2                   2                   1\n",
       "..   ...                ...                ...                 ...                 ...\n",
       "65    93                  2                  1                   1                   1\n",
       "66    95                  1                  0                   1                   0\n",
       "67    98                  1                  1                   1                   1\n",
       "68   101                  1                  0                   1                   0\n",
       "69   102                  0                  1                   1                   1\n",
       "70   104                  1                  2                   1                   1\n",
       "\n",
       "[71 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_aclu_num_peaks_df: pd.DataFrame = track_templates.get_decoders_aclu_num_peaks_df()\n",
    "decoder_aclu_num_peaks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604b90dc",
   "metadata": {},
   "source": [
    "## 2024-02-08 - Filter to find only the clear remap examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import TrialByTrialActivity\n",
    "from pyphocorehelpers.indexing_helpers import dict_to_full_array\n",
    "\n",
    "any_decoder_neuron_IDs = deepcopy(track_templates.any_decoder_neuron_IDs)\n",
    "any_decoder_neuron_IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0cf56",
   "metadata": {},
   "source": [
    "### Get num peaks exclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c849dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_ids_dict = {k:v.neuron_ids for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "# neuron_ids_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec42a8d",
   "metadata": {},
   "source": [
    "### Get stability for each cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ec2d7",
   "metadata": {},
   "source": [
    "#### 2024-02-08 - 3pm - new stability dataframe to look at stability of each cell across decoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57869e27",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aclu</th>\n",
       "      <th>long_LR</th>\n",
       "      <th>long_RL</th>\n",
       "      <th>short_LR</th>\n",
       "      <th>short_RL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.361388</td>\n",
       "      <td>0.586789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.517590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198003</td>\n",
       "      <td>0.764841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.746013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.880603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747509</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>0.375737</td>\n",
       "      <td>0.606193</td>\n",
       "      <td>0.157363</td>\n",
       "      <td>0.832467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>93</td>\n",
       "      <td>0.048075</td>\n",
       "      <td>0.811061</td>\n",
       "      <td>0.083893</td>\n",
       "      <td>0.850389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>95</td>\n",
       "      <td>0.676762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.917072</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>98</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.903593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.956228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>101</td>\n",
       "      <td>0.807298</td>\n",
       "      <td>0.304563</td>\n",
       "      <td>0.234306</td>\n",
       "      <td>0.050491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.925724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.948715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>104</td>\n",
       "      <td>0.799041</td>\n",
       "      <td>0.815246</td>\n",
       "      <td>0.887061</td>\n",
       "      <td>0.585298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aclu   long_LR   long_RL  short_LR  short_RL\n",
       "0      2  0.361388  0.586789  0.000000  0.449112\n",
       "1      4  0.517590  0.000000  0.198003  0.764841\n",
       "2      5  0.000000  0.746013  0.000000  0.000000\n",
       "3      6  0.000000  0.000000  0.040900  0.880603\n",
       "4      8  0.000000  0.000000  0.747509  0.000000\n",
       "5      9  0.375737  0.606193  0.157363  0.832467\n",
       "..   ...       ...       ...       ...       ...\n",
       "65    93  0.048075  0.811061  0.083893  0.850389\n",
       "66    95  0.676762  0.000000  0.917072  0.000000\n",
       "67    98  0.000000  0.903593  0.000000  0.956228\n",
       "68   101  0.807298  0.304563  0.234306  0.050491\n",
       "69   102  0.000000  0.925724  0.000000  0.948715\n",
       "70   104  0.799041  0.815246  0.887061  0.585298\n",
       "\n",
       "[71 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for k,v in directional_active_lap_pf_results_dicts.items():\n",
    "# stability_dict = {k:v.aclu_to_stability_score_dict for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "# stability_dict = {k:dict_to_full_array(v.aclu_to_stability_score_dict, full_indicies=any_decoder_neuron_IDs, fill_value=0.0) for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "# stability_dict\n",
    "\n",
    "\n",
    "# list(stability_dict.values())\n",
    "\n",
    "stability_dict = {k:list(v.aclu_to_stability_score_dict.values()) for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "# stability_dict\n",
    "## all the same size hopefully!\n",
    "# [len(v) for v in list(stability_dict.values())]\n",
    "\n",
    "stability_df: pd.DataFrame = pd.DataFrame({'aclu': any_decoder_neuron_IDs, **stability_dict})\n",
    "# stability_df.rename(dict(zip([], [])))\n",
    "stability_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3308ff",
   "metadata": {},
   "source": [
    "### Ensure that we're only getting the location of the maximum peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d1dcd",
   "metadata": {
    "tags": [
     "df_method_bad",
     "bad"
    ]
   },
   "outputs": [],
   "source": [
    "decoder_aclu_MAX_peak_location_df_merged = decoder_aclu_peak_location_df_merged[decoder_aclu_peak_location_df_merged['subpeak_idx'] == 0]\n",
    "decoder_aclu_MAX_peak_location_df_merged\n",
    "# decoder_aclu_MAX_peak_location_df_merged.columns # ['aclu', 'subpeak_idx', 'long_LR_peak', 'long_RL_peak', 'short_LR_peak', 'short_RL_peak', 'long_LR_peak_height', 'long_RL_peak_height', 'short_LR_peak_height', 'short_RL_peak_height', 'LR_peak_diff', 'RL_peak_diff']\n",
    "\n",
    "common_drop_column_names = ['subpeak_idx', 'LR_peak_diff', 'RL_peak_diff']\n",
    "RL_column_names = [col for col in list(decoder_aclu_MAX_peak_location_df_merged.columns) if (str(col).find('RL_') != -1)] # ['long_RL_peak', 'short_RL_peak', 'long_RL_peak_height', 'short_RL_peak_height', 'RL_peak_diff']\n",
    "LR_column_names = [col for col in list(decoder_aclu_MAX_peak_location_df_merged.columns) if (str(col).find('LR_') != -1)] # ['long_LR_peak', 'short_LR_peak', 'long_LR_peak_height', 'short_LR_peak_height', 'LR_peak_diff']\n",
    "\n",
    "LR_only_decoder_aclu_MAX_peak_location_df_merged = decoder_aclu_MAX_peak_location_df_merged.drop(columns=(RL_column_names+common_drop_column_names), inplace=False).dropna(axis='index')\n",
    "LR_only_decoder_aclu_MAX_peak_location_df_merged\n",
    "\n",
    "\n",
    "## OUTPUTS: decoder_aclu_MAX_peak_location_df_merged, LR_only_decoder_aclu_MAX_peak_location_df_merged, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_aclu_peak_location_df_merged\n",
    "\n",
    "valid_aclus = deepcopy(decoder_aclu_peak_location_df_merged.aclu.unique())\n",
    "peaks_df_subset: pd.DataFrame = decoder_aclu_peak_location_df_merged.copy()\n",
    "\n",
    "# active_IDX = 1\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def integer_slider(update_func):\n",
    "    \"\"\" Captures: valid_aclus\n",
    "    \"\"\"\n",
    "    slider = widgets.IntSlider(description='cell_IDX:', min=0, max=len(valid_aclus)-1, value=0)\n",
    "    def on_slider_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            # Call the user-provided update function with the current slider index\n",
    "            update_func(change['new'])\n",
    "    slider.observe(on_slider_change)\n",
    "    display(slider)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def update_function(index):\n",
    "    \"\"\" Define an update function that will be called with the current slider index \n",
    "    Captures decoder_aclu_peak_location_df_merged, valid_aclus\n",
    "    \"\"\"\n",
    "    global peaks_df_subset\n",
    "    print(f'Slider index: {index}')\n",
    "    active_aclu = int(valid_aclus[int(index)])\n",
    "    peaks_df_subset = decoder_aclu_peak_location_df_merged[decoder_aclu_peak_location_df_merged.aclu == active_aclu].copy()\n",
    "    display(peaks_df_subset)\n",
    "\n",
    "\n",
    "# timebinned_neuron_info = long_results_obj.timebinned_neuron_info\n",
    "# active_fig_obj, update_function = DiagnosticDistanceMetricFigure.build_interactive_diagnostic_distance_metric_figure(long_results_obj, timebinned_neuron_info, result)\n",
    "\n",
    "\n",
    "# Call the integer_slider function with the update function\n",
    "integer_slider(update_function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539eb198",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_df_subset[['long_LR_peak', 'short_LR_peak']]\n",
    "peaks_df_subset[['long_LR_peak_height', 'short_LR_peak_height']]\n",
    "peaks_df_subset['LR_peak_diff']\n",
    "\n",
    "\n",
    "## #TODO 2024-02-16 06:50: - [ ] ERROR discovered in `decoder_aclu_peak_location_df_merged` - the columns 'LR_peak_diff', 'RL_peak_diff' are incorrect as they aren't comparing the maximum peak (supposed to be at `subpeak_idx == 0`, but better given by `height == 1.0`) of long decoder to maximum peak of short. The comparison logic is wrong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f287c",
   "metadata": {
    "tags": [
     "good",
     "active",
     "proper"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import NumpyHelpers\n",
    "from neuropy.utils.indexing_helpers import intersection_of_arrays, union_of_arrays\n",
    "\n",
    "def unwrap_single_item(lst):\n",
    "    return lst[0] if len(lst) == 1 else None\n",
    "\n",
    "# decoder_aclu_peak_maps_dict = {a_name:deepcopy(dict(zip(a_decoder.neuron_IDs, a_decoder.peak_locations))) for a_name, a_decoder in track_templates.get_decoders_dict().items()}\n",
    "decoder_aclu_peak_maps_dict = {a_name:deepcopy(dict(zip(a_decoder.neuron_IDs, a_decoder.get_tuning_curve_peak_positions(peak_mode='peaks')))) for a_name, a_decoder in track_templates.get_decoders_dict().items()}\n",
    "\n",
    "## Split into LR/RL groups to get proper peak differences:\n",
    "# ['long_LR', 'long_RL', 'short_LR', 'short_RL']\n",
    "LR_decoder_names = ['long_LR', 'short_LR']\n",
    "RL_decoder_names = ['long_RL', 'short_RL']\n",
    "\n",
    "## Only the maximums:\n",
    "decoder_aclu_MAX_peak_maps_dict = {a_name:{k:unwrap_single_item(v) for k, v in deepcopy(dict(zip(a_decoder.neuron_IDs, a_decoder.get_tuning_curve_peak_positions(peak_mode='peaks', height=1)))).items()} for a_name, a_decoder in track_templates.get_decoders_dict().items()}\n",
    "\n",
    "LR_only_decoder_aclu_MAX_peak_maps_df: pd.DataFrame = pd.DataFrame({k:v for k,v in decoder_aclu_MAX_peak_maps_dict.items() if k in LR_decoder_names})\n",
    "RL_only_decoder_aclu_MAX_peak_maps_df: pd.DataFrame = pd.DataFrame({k:v for k,v in decoder_aclu_MAX_peak_maps_dict.items() if k in RL_decoder_names})\n",
    "\n",
    "## Drop row if either long/short is missing a value:\n",
    "LR_only_decoder_aclu_MAX_peak_maps_df = LR_only_decoder_aclu_MAX_peak_maps_df.dropna(axis=0, how='any')\n",
    "RL_only_decoder_aclu_MAX_peak_maps_df = RL_only_decoder_aclu_MAX_peak_maps_df.dropna(axis=0, how='any')\n",
    "\n",
    "## Compute the difference between the Long/Short peaks:\n",
    "LR_only_decoder_aclu_MAX_peak_maps_df['peak_diff'] = LR_only_decoder_aclu_MAX_peak_maps_df.diff(axis='columns').to_numpy()[:, -1]\n",
    "RL_only_decoder_aclu_MAX_peak_maps_df['peak_diff'] = RL_only_decoder_aclu_MAX_peak_maps_df.diff(axis='columns').to_numpy()[:, -1]\n",
    "\n",
    "LR_only_decoder_aclu_MAX_peak_maps_df\n",
    "RL_only_decoder_aclu_MAX_peak_maps_df\n",
    "\n",
    "\n",
    "long_peak_x = LR_only_decoder_aclu_MAX_peak_maps_df['long_LR'].to_numpy()\n",
    "short_peak_x = LR_only_decoder_aclu_MAX_peak_maps_df['short_LR'].to_numpy()\n",
    "peak_x_diff = LR_only_decoder_aclu_MAX_peak_maps_df['peak_diff'].to_numpy()\n",
    "# decoder_aclu_peak_maps_dict\n",
    "\n",
    "\n",
    "## OUTPUTS: LR_only_decoder_aclu_MAX_peak_maps_df, long_peak_x, long_peak_x, peak_x_diff\n",
    "## OUTPUTS: RL_only_decoder_aclu_MAX_peak_maps_df, long_peak_x, long_peak_x, peak_x_diff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc77c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximal_peak_only_decoder_aclu_peak_location_df_merged = deepcopy(decoder_aclu_peak_location_df_merged)[decoder_aclu_peak_location_df_merged['long_LR_peak_height'] == 1.0]\n",
    "\n",
    "LR_height_column_names = ['long_LR_peak_height', 'short_LR_peak_height']\n",
    "\n",
    "# [decoder_aclu_peak_location_df_merged[a_name] == 1.0 for a_name in LR_height_column_names]\n",
    "\n",
    "LR_max_peak_dfs = [deepcopy(decoder_aclu_peak_location_df_merged)[decoder_aclu_peak_location_df_merged[a_name] == 1.0].drop(columns=['subpeak_idx', 'series_idx', 'LR_peak_diff', 'RL_peak_diff', a_name]) for a_name in LR_height_column_names]\n",
    "\n",
    "aclus_with_LR_peaks = intersection_of_arrays(*[a_df.aclu.unique() for a_df in LR_max_peak_dfs])\n",
    "aclus_with_LR_peaks\n",
    "\n",
    "\n",
    "## Align them now:\n",
    "LR_max_peak_dfs = [a_df[a_df.aclu.isin(aclus_with_LR_peaks)] for a_df in LR_max_peak_dfs]\n",
    "LR_max_peak_dfs\n",
    "\n",
    "# aclus_with_LR_peaks = aclu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096dda8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximal_peak_only_decoder_aclu_peak_location_df_merged = deepcopy(decoder_aclu_peak_location_df_merged)[decoder_aclu_peak_location_df_merged[LR_height_column_names] == 1.0]\n",
    "maximal_peak_only_decoder_aclu_peak_location_df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bbdbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_aclu_peak_location_df_merged[['LR_peak_diff', 'RL_peak_diff']].notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024-02-08 - Plot heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5de5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_single_heatmap_set_with_points\n",
    "\n",
    "# active_pf_dt: PfND_TimeDependent\n",
    "\n",
    "decoders_tuning_curves_dict = track_templates.decoder_normalized_tuning_curves_dict_dict.copy()\n",
    "\n",
    "extra_decoder_values_dict = {'tuning_curves': decoders_tuning_curves_dict, 'points': decoder_aclu_peak_location_df_merged}\n",
    "\n",
    "# decoders_tuning_curves_dict\n",
    "xbin_centers = deepcopy(active_pf_dt.xbin_centers)\n",
    "xbin = deepcopy(active_pf_dt.xbin)\n",
    "fig, ax_dict = plot_single_heatmap_set_with_points(directional_active_lap_pf_results_dicts, xbin_centers, xbin, extra_decoder_values_dict=extra_decoder_values_dict, aclu=4, \n",
    "                                                   decoders_tuning_curves_dict=decoders_tuning_curves_dict, decoder_aclu_peak_location_df_merged=decoder_aclu_peak_location_df_merged,\n",
    "                                                    active_context=curr_active_pipeline.build_display_context_for_session('single_heatmap_set_with_points'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a399108",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot a couple\n",
    "# long_pf_aclus, short_pf_aclus\n",
    "\n",
    "# plot_aclus = [4,  5,  8,  9]\n",
    "plot_aclus = [11, 18, 68]\n",
    "# plot_aclus = [68]\n",
    "\n",
    "for test_aclu in plot_aclus:\n",
    "\tfig, ax_dict = plot_single_heatmap_set_with_points(directional_active_lap_pf_results_dicts, xbin_centers, xbin, extra_decoder_values_dict=extra_decoder_values_dict, aclu=test_aclu, \n",
    "                                                   decoders_tuning_curves_dict=decoders_tuning_curves_dict, decoder_aclu_peak_location_df_merged=decoder_aclu_peak_location_df_merged,\n",
    "                                                    active_context=curr_active_pipeline.build_display_context_for_session('single_heatmap_set_with_points'))\n",
    "\t\n",
    "\tfig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_aclu_peak_location_df_merged.aclu.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f23ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b9a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: these layout changes don't seem to take effect until the window containing the figure is resized.\n",
    "# fig.set_layout_engine('compressed') # TAKEWAY: Use 'compressed' instead of 'constrained'\n",
    "fig.set_layout_engine('none') # disabling layout engine. Strangely still allows window to resize and the plots scale, so I'm not sure what the layout engine is doing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f1adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(directional_active_lap_pf_results_dicts.keys()) # ['maze1_odd', 'maze1_even', 'maze2_odd', 'maze2_even']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bbc9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.long_LR_decoder.pf.plot_ratemaps_1D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef13541",
   "metadata": {},
   "source": [
    "# 2024-02-02 - napari_plot_directional_trial_by_trial_activity_viz Trial-by-trial Correlation Matrix C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddd735e",
   "metadata": {},
   "source": [
    "### 🎨 Show Trial-by-trial Correlation Matrix C in `napari`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad72df59",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import napari\n",
    "# import afinder\n",
    "from pyphoplacecellanalysis.GUI.Napari.napari_helpers import napari_from_layers_dict\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import napari_trial_by_trial_activity_viz\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import napari_plot_directional_trial_by_trial_activity_viz\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import napari_export_image_sequence\n",
    "\n",
    "## Directional\n",
    "directional_viewer, directional_image_layer_dict, custom_direction_split_layers_dict = napari_plot_directional_trial_by_trial_activity_viz(directional_active_lap_pf_results_dicts, include_trial_by_trial_correlation_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9934d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Global:\n",
    "viewer, image_layer_dict = napari_trial_by_trial_activity_viz(z_scored_tuning_map_matrix, C_trial_by_trial_correlation_matrix, title='Trial-by-trial Correlation Matrix C', axis_labels=('aclu', 'lap', 'xbin')) # GLOBAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f61fa",
   "metadata": {},
   "source": [
    "# Napari Plotting Long/Short Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80146cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import test_LinearTrackDimensions_2D_pyqtgraph, LinearTrackDimensions, LinearTrackInstance\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions, LinearTrackDimensions3D\n",
    "\n",
    "long_track_dims = LinearTrackDimensions(track_length=170.0)\n",
    "short_track_dims = LinearTrackDimensions(track_length=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a001a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_LR_pf1D.config.grid_bin_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f26a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf2D.config.grid_bin_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d3065",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_LR_pf1D.position.has_linear_pos\n",
    "# long_LR_pf1D.position.compute_linearized_position()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get grid_bin_bounds:\n",
    "long_grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "short_grid_bin_bounds = deepcopy(short_pf2D.config.grid_bin_bounds)\n",
    "\n",
    "long_grid_bin_bounds\n",
    "short_grid_bin_bounds\n",
    "linear_track_instance = LinearTrackInstance.init_from_grid_bin_bounds(grid_bin_bounds=long_grid_bin_bounds, debug_print=True)\n",
    "linear_track_instance\n",
    "\n",
    "\n",
    "# a_track_dims, ideal_maze_pdata = LinearTrackDimensions.init_from_grid_bin_bounds(grid_bin_bounds, return_geoemtry=True)\n",
    "linear_track_instance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b4ec86",
   "metadata": {},
   "source": [
    "# 2023-09-07 - Track Graphics Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07993325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.placefields import compute_grid_bin_bounds\n",
    "from pyphocorehelpers.geometry_helpers import map_value\n",
    "\n",
    "pos_df = deepcopy(global_session.position).to_dataframe()\n",
    "# xlinear = deepcopy(global_session.position.linear_pos_obj.x)\n",
    "xlinear = deepcopy(global_session.position.to_dataframe()['lin_pos'].to_numpy())\n",
    "# xlinear = -1.0 * xlinear # flip over the y-axis first\n",
    "lin_pos_bounds = compute_grid_bin_bounds(xlinear)[0]\n",
    "x_bounds = compute_grid_bin_bounds(pos_df['x'].to_numpy())[0]\n",
    "print(f'lin_pos_bounds: {lin_pos_bounds}, x_bounds: {x_bounds}')\n",
    "xlinear = map_value(xlinear, lin_pos_bounds, x_bounds) # map xlinear from its current bounds range to the xbounds range\n",
    "\n",
    "## Confirmed they match: lin_pos_bounds: (20.53900014070859, 260.280278480539), x_bounds: (20.53900014070859, 260.280278480539)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c59b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, w, cw, (ax0, ax1), (long_track_dims, long_rect_items, long_rects), (short_track_dims, short_rect_items, short_rects) = test_LinearTrackDimensions_2D_pyqtgraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b53254",
   "metadata": {},
   "source": [
    "## 🔝🖼️🎨 2024-02-16 - NOW - Working Track Remapping Diagram Figure!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb92e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_track_remapping_diagram\n",
    "\n",
    "fig_LR, ax_LR, _outputs_tuple = _plot_track_remapping_diagram(LR_only_decoder_aclu_MAX_peak_maps_df, grid_bin_bounds=long_pf2D.config.grid_bin_bounds, long_column_name='long_LR', short_column_name='short_LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c426a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_RL, ax_RL, _outputs_tuple = _plot_track_remapping_diagram(RL_only_decoder_aclu_MAX_peak_maps_df, grid_bin_bounds=long_pf2D.config.grid_bin_bounds, long_column_name='long_RL', short_column_name='short_RL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfef4700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b343987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f75d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax1, ax2 = test_LinearTrackDimensions_2D_Matplotlib()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f981611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=ax1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aeb712",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Napari Shapes Layer Test:\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_napari_track_shapes_layer\n",
    "\n",
    "# add the image\n",
    "# viewer = napari.view_image(data.camera(), name='photographer')\n",
    "\n",
    "test_shapes_viewer = napari.Viewer() # name='Test Shapes Viewer'\n",
    "# add the tracks\n",
    "long_rectangles_poly_shapes_layer, short_rectangles_poly_shapes_layer = add_napari_track_shapes_layer(test_shapes_viewer, long_rect_items, short_rect_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_layer_info(long_rectangles_poly_shapes_layer)\n",
    "extract_layer_info(short_rectangles_poly_shapes_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8948d536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_rectangles_poly_shapes_layer.bounding_box\n",
    "# long_rectangles_poly_shapes_layer.interaction_box\n",
    "long_rectangles_poly_shapes_layer.corner_pixels # np.array([[ 44, 124], [376, 161]])\n",
    "# long_rectangles_poly_shapes_layer.frame\n",
    "\n",
    "\n",
    "# long_rectangles_poly_shapes_layer.rotate = 90\n",
    "# data_to_world, world_to_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d1eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_rectangles_poly_shapes_layer.rotate = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af347488",
   "metadata": {},
   "outputs": [],
   "source": [
    "## #TODO 2024-02-02 22:31: - [ ] These need to be update for global support\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import napari_add_aclu_slider\n",
    "\n",
    "def build_filename_from_viewer(viewer, desired_save_parent_path: Path, slider_axis_IDX: int = 0) -> Path:\n",
    "    \"\"\"\n",
    "    Captures: curr_active_pipeline, neuron_ids, global_any_name\n",
    "    \n",
    "     Usage:\n",
    "        file_out_path = build_filename_from_viewer(viewer)\n",
    "        viewer.screenshot(path=file_out_path, canvas_only=True, flash=False)\n",
    "\n",
    "    \"\"\"\n",
    "    # desired_save_parent_path = Path('/home/halechr/Desktop/test_napari_out').resolve()\n",
    "\n",
    "    matrix_aclu_IDX: int = int(viewer.dims.current_step[slider_axis_IDX])\n",
    "    # find the aclu value for this index:\n",
    "    aclu: int = int(neuron_ids[matrix_aclu_IDX])\n",
    "    curr_context = curr_active_pipeline.build_display_context_for_filtered_session(global_any_name, 'napari_trial_by_trial_activity_viz', aclu=str(aclu))\n",
    "    curr_context_string: str = curr_context.get_description() #.get_description(suffix_items=[f'aclu-{aclu}'])\n",
    "    filename_string: str = f\"{curr_context_string}.png\"\n",
    "\n",
    "    file_out_path = desired_save_parent_path.joinpath(filename_string).resolve()\n",
    "    return file_out_path\n",
    "\n",
    "\n",
    "# desired_save_parent_path = Path('/home/halechr/Desktop/test_napari_out').resolve()\n",
    "desired_save_parent_path = Path(r'C:\\Users\\pho\\Desktop\\test_napari_out').resolve()\n",
    "_connected_on_update_slider_event = napari_add_aclu_slider(viewer=directional_viewer, neuron_ids=neuron_ids)\n",
    "imageseries_output_directory = napari_export_image_sequence(viewer=viewer, imageseries_output_directory=desired_save_parent_path, slider_axis_IDX=0, build_filename_from_viewer_callback_fn=build_filename_from_viewer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_viewer.Config\n",
    "directional_viewer.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6fcb1",
   "metadata": {},
   "source": [
    "# 2024-02-06 - Other Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5623a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "\n",
    "curr_active_pipeline.prepare_for_display()\n",
    "# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "# active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\n",
    "\n",
    "_out_graphics_dict = curr_active_pipeline.display('_display_spike_rasters_pyqtplot_2D', 'maze_any') # 'maze_any'\n",
    "assert isinstance(_out_graphics_dict, dict)\n",
    "active_2d_plot, active_3d_plot, spike_raster_window = _out_graphics_dict['spike_raster_plt_2d'], _out_graphics_dict['spike_raster_plt_3d'], _out_graphics_dict['spike_raster_window']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8eceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_neuron_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "# graphics_output_dict = curr_active_pipeline.display('_display_long_short_pf1D_comparison', active_identifying_session_ctx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_LR_name, long_RL_name, short_LR_name, short_RL_name = track_templates.get_decoder_names()\n",
    "\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_long_short_pf1D_comparison', active_identifying_session_ctx,\n",
    "                                                     include_includelist=[long_LR_name, short_LR_name, global_LR_name], active_context=active_identifying_session_ctx.overwriting_context(dir='LR'), included_any_context_neuron_ids=LR_shift_df.aclu.unique())\n",
    "\n",
    "\n",
    "# fig, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['axs'], graphics_output_dict['plot_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51201e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "\n",
    "\n",
    "_out = TemplateDebugger.init_templates_debugger(track_templates) # , included_any_context_neuron_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feab852",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot.display_function_items\n",
    "\n",
    "# '_display_directional_template_debugger'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b67c4",
   "metadata": {},
   "source": [
    "# 🖼️🎨 Rasters Debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76b0f00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23816aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "\n",
    "RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "_out_laps_rasters = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, global_laps_epochs_df, track_templates, rank_order_results, RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict)\n",
    "_out_laps_rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaa1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "# global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "# global_laps_epochs_df = global_laps.to_dataframe()\n",
    "global_ripple_epochs_df = global_replays.to_dataframe()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "_out_ripple_rasters = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, global_ripple_epochs_df, track_templates, rank_order_results, RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict)\n",
    "_out_ripple_rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea652adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included_neuron_ids: [  2   4   5   6   8   9  11  12  14  15  16  18  19  20  24  25  26  27  28  29  30  31  32  33  34  35  38  39  40  43  44  47  48  51  52  53  56  57  58  59  60  61  62  63  66  67  68  70  71  72  75  77  79  80  81  82  83  84  85  86  87  89  90  91  92  93  95  98 101 102 104], n_neurons: 71\n",
      "WARNING: encountered numba TypingError: Failed in nopython mode pipeline (step: nopython frontend)\n",
      "\u001b[1m\u001b[1mnon-precise type array(pyobject, 1d, C)\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at /home/halechr/repos/NeuroPy/neuropy/utils/efficient_interval_search.py (277)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"../NeuroPy/neuropy/utils/efficient_interval_search.py\", line 277:\u001b[0m\n",
      "\u001b[1mdef _compiled_searchsorted_event_interval_identity(times_arr, start_stop_times_arr, period_identity_labels, no_interval_fill_value=np.nan): # Function is compiled by numba and runs in machine code\n",
      "    <source elided>\n",
      "    \"\"\"\n",
      "\u001b[1m    event_interval_identity_arr = np.full((times_arr.shape[0],), no_interval_fill_value) # fill with NaN for all entries initially\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      " on the period_identity_labels: type(period_identity_labels): <class 'numpy.ndarray'> passed.\n",
      "period_identity_labels: ['4' '8' '11' '14' '17' '28' '31' '38' '44' '49' '54' '57' '70' '72' '81' '86' '95' '102' '117' '127' '130' '138' '150' '158' '168' '169' '178' '183' '186' '207' '215' '219' '225' '226' '230' '234' '238' '248' '254' '255' '257' '262' '267' '271' '278' '305' '307' '308' '312' '313' '314' '315' '317' '320' '323' '326' '327' '329' '336' '337' '340' '341' '343' '355' '359' '364' '366' '371' '374' '376' '380' '389' '391' '396' '398' '400' '403' '411' '413' '414' '417' '420']. \n",
      "\tTrying to convert them to int and continue...\n",
      "unit_sort_order: [35 10  5 36 45 22 46 25 44 49  4 16 20  3 40 19 21 43 41  9 52 37 17  2 24  8 47 55 50 38  0 12 32 14 23 42  1 18 34 31  7 29 48 30 28 53 51 26 54 27  6 13 11 33 15 39]\n",
      "desired_sort_arr: [ 70  25  15  71  87  51  89  56  84  92  14  38  47  12  79  44  48  82  80  24  98  72  39  11  53  20  90 104  93  75   4  27  66  31  52  81   9  40  68  63  18  61  91  62  60 101  95  57 102  59  16  28  26  67  32  77]\n",
      "WARN: len(neuron_colors): 71 > n_cells: 56: restricting neuron_colors to the correct aclus, but if colors ever get off this is where it is happening!\n",
      "merged_kwargs: {'name': 'spikeRasterOverviewWindowScatterPlotItem', 'pxMode': True, 'symbol': <PyQt5.QtGui.QPainterPath object at 0x7f8505b434a0>, 'size': 2, 'pen': {'color': 'w', 'width': 1}, 'hoverable': True}\n",
      "unit_sort_order: [15  8 16 44 24 41 10  6 45 21 46 23 20 36 38 27 13 33 48 17 22  0  4  5 26 14 47 39 50 31 37  9  3 28 43  1 12  2 34  7 19 18 30 42 25 40 29 32 49 35 11]\n",
      "desired_sort_arr: [ 33  19  34  87  51  84  25  15  89  44  92  48  43  79  81  56  30  72  98  35  47   2   9  11  53  31  93  82 104  66  80  24   8  58  86   5  29   6  75  16  40  39  61  85  52  83  60  68 102  77  26]\n",
      "WARN: len(neuron_colors): 71 > n_cells: 51: restricting neuron_colors to the correct aclus, but if colors ever get off this is where it is happening!\n",
      "merged_kwargs: {'name': 'spikeRasterOverviewWindowScatterPlotItem', 'pxMode': True, 'symbol': <PyQt5.QtGui.QPainterPath object at 0x7f84a35d0e40>, 'size': 2, 'pen': {'color': 'w', 'width': 1}, 'hoverable': True}\n",
      "unit_sort_order: [35 36  5 45 10 20 49 16 25 22  4  3 40 19 34 21 41  9  8 52 43 46 44 50  2 17 32 55 42  1 12 24 47  0 48 14 29 30 23 31 37 26 51 18 38 27 13 53  7 33 11 28 15 39 54  6]\n",
      "desired_sort_arr: [ 70  71  15  87  25  47  92  38  56  51  14  12  79  44  68  48  80  24  20  98  82  89  84  93  11  39  66 104  81   9  27  53  90   4  91  31  61  62  52  63  72  57  95  40  75  59  28 101  18  67  26  60  32  77 102  16]\n",
      "WARN: len(neuron_colors): 71 > n_cells: 56: restricting neuron_colors to the correct aclus, but if colors ever get off this is where it is happening!\n",
      "merged_kwargs: {'name': 'spikeRasterOverviewWindowScatterPlotItem', 'pxMode': True, 'symbol': <PyQt5.QtGui.QPainterPath object at 0x7f848bd5ff90>, 'size': 2, 'pen': {'color': 'w', 'width': 1}, 'hoverable': True}\n",
      "unit_sort_order: [44 10 15  6 16  8  5 45 22 46  3 21 20 50 17 23 38 13 27 36 41  0 33  4  9 48 47 24 14  1 12 43 39 31 28 37 30 26  7 18 19 40 34 29 42  2 32 49 25 35 11]\n",
      "desired_sort_arr: [ 87  25  33  15  34  19  11  89  47  92   8  44  43 104  35  48  81  30  56  79  84   2  72   9  24  98  93  51  31   5  29  86  82  66  58  80  61  53  16  39  40  83  75  60  85   6  68 102  52  77  26]\n",
      "WARN: len(neuron_colors): 71 > n_cells: 51: restricting neuron_colors to the correct aclus, but if colors ever get off this is where it is happening!\n",
      "merged_kwargs: {'name': 'spikeRasterOverviewWindowScatterPlotItem', 'pxMode': True, 'symbol': <PyQt5.QtGui.QPainterPath object at 0x7f841994ff90>, 'size': 2, 'pen': {'color': 'w', 'width': 1}, 'hoverable': True}\n",
      "PhoDockAreaContainingWindow.GlobalConnectionManagerAccessingMixin_on_setup()\n",
      "PhoDockAreaContainingWindow.try_register_any_control_widgets()\n",
      "\tflat_widgets_list contains 0 items\n",
      "using overriden dock location.\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "emitChanged(): self.val: 10\n",
      "WARN: the selected spikes did not work properly, so none will be shown.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RankOrderRastersDebugger(plots=RenderPlots({'name': 'RankOrderRastersDebugger', 'context': None, 'root_dockAreaWindow': <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.DockAreaWrapper.PhoDockAreaContainingWindow object at 0x7f8446856940>, 'apps': {'long_LR': <PyQt5.QtWidgets.QApplication object at 0x7f87b40549d0>, 'long_RL': <PyQt5.QtWidgets.QApplication object at 0x7f87b40549d0>, 'short_LR': <PyQt5.QtWidgets.QApplication object at 0x7f87b40549d0>, 'short_RL': <PyQt5.QtWidgets.QApplication object at 0x7f87b40549d0>}, 'all_windows': {'long_LR': <pyphoplacecellanalysis.External.pyqtgraph.widgets.GraphicsLayoutWidget.GraphicsLayoutWidget object at 0x7f84a402e310>, 'long_RL': <pyphoplacecellanalysis.External.pyqtgraph.widgets.GraphicsLayoutWidget.GraphicsLayoutWidget object at 0x7f84177adb80>, 'short_LR': <pyphoplacecellanalysis.External.pyqtgraph.widgets.GraphicsLayoutWidget.GraphicsLayoutWidget object at 0x7f844921d5e0>, 'short_RL': <pyphoplacecellanalysis.External.pyqtgraph.widgets.GraphicsLayoutWidget.GraphicsLayoutWidget object at 0x7f844b3cfd30>}, 'all_separate_plots': {'long_LR': RenderPlots({'name': 'pho_directional_laps_rasters_long_LR', 'context': None, 'debug_header_label': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.LabelItem.LabelItem object at 0x7f84a402eb80>, 'root_plot': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotItem.PlotItem.PlotItem object at 0x7f84177ad040>, 'scatter_plot': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.ScatterPlotItem.ScatterPlotItem object at 0x7f844b46ce50>, 'grid': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.GridItem.GridItem object at 0x7f844b46cf70>}), 'long_RL': RenderPlots({'name': 'pho_directional_laps_rasters_long_RL', 'context': None, 'debug_header_label': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.LabelItem.LabelItem object at 0x7f8417ab44c0>, 'root_plot': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotItem.PlotItem.PlotItem object at 0x7f8417ab4670>, 'scatter_plot': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.ScatterPlotItem.ScatterPlotItem object at 0x7f844921d4c0>, 'grid': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.GridItem.GridItem object at 0x7f844921d550>}), 'short_LR': RenderPlots({'name': 'pho_directional_laps_rasters_short_LR', 'context': None, 'debug_header_label': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.LabelItem.LabelItem object at 0x7f844b46cee0>, 'root_plot': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotItem.PlotItem.PlotItem object at 0x7f844921df70>, 'scatter_plot': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.ScatterPlotItem.ScatterPlotItem object at 0x7f844b3cfb80>, 'grid': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.GridItem.GridItem object at 0x7f844b3cfaf0>}), 'short_RL': RenderPlots({'name': 'pho_directional_laps_rasters_short_RL', 'context': None, 'debug_header_label': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.LabelItem.LabelItem object at 0x7f844cf3e160>, 'root_plot': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotItem.PlotItem.PlotItem object at 0x7f844cf3e310>, 'scatter_plot': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.ScatterPlotItem.ScatterPlotItem object at 0x7f8446856160>, 'grid': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.GridItem.GridItem object at 0x7f8446856af0>})}, 'root_plots': {'long_LR': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotItem.PlotItem.PlotItem object at 0x7f84177ad040>, 'long_RL': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotItem.PlotItem.PlotItem object at 0x7f8417ab4670>, 'short_LR': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotItem.PlotItem.PlotItem object at 0x7f844921df70>, 'short_RL': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotItem.PlotItem.PlotItem object at 0x7f844cf3e310>}, 'grids': {'long_LR': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.GridItem.GridItem object at 0x7f844b46cf70>, 'long_RL': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.GridItem.GridItem object at 0x7f844921d550>, 'short_LR': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.GridItem.GridItem object at 0x7f844b3cfaf0>, 'short_RL': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.GridItem.GridItem object at 0x7f8446856af0>}, 'scatter_plots': {'long_LR': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.ScatterPlotItem.ScatterPlotItem object at 0x7f844b46ce50>, 'long_RL': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.ScatterPlotItem.ScatterPlotItem object at 0x7f844921d4c0>, 'short_LR': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.ScatterPlotItem.ScatterPlotItem object at 0x7f844b3cfb80>, 'short_RL': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.ScatterPlotItem.ScatterPlotItem object at 0x7f8446856160>}, 'debug_header_labels': {'long_LR': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.LabelItem.LabelItem object at 0x7f84a402eb80>, 'long_RL': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.LabelItem.LabelItem object at 0x7f8417ab44c0>, 'short_LR': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.LabelItem.LabelItem object at 0x7f844b46cee0>, 'short_RL': <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.LabelItem.LabelItem object at 0x7f844cf3e160>}, 'dock_widgets': {'long_LR': (<pyphoplacecellanalysis.External.pyqtgraph.widgets.GraphicsLayoutWidget.GraphicsLayoutWidget object at 0x7f84a402e310>, <Dock long_LR (300, 600)>), 'long_RL': (<pyphoplacecellanalysis.External.pyqtgraph.widgets.GraphicsLayoutWidget.GraphicsLayoutWidget object at 0x7f84177adb80>, <Dock long_RL (300, 600)>), 'short_LR': (<pyphoplacecellanalysis.External.pyqtgraph.widgets.GraphicsLayoutWidget.GraphicsLayoutWidget object at 0x7f844921d5e0>, <Dock short_LR (300, 600)>), 'short_RL': (<pyphoplacecellanalysis.External.pyqtgraph.widgets.GraphicsLayoutWidget.GraphicsLayoutWidget object at 0x7f844b3cfd30>, <Dock short_RL (300, 600)>), 'bottom_controls': (<pyphoplacecellanalysis.External.pyqtgraph.widgets.LayoutWidget.LayoutWidget object at 0x7f8449148550>, <Dock bottom_controls (600, 200)>), 'LongShortColumnsInfo_dock': (<pyphoplacecellanalysis.External.pyqtgraph.widgets.LayoutWidget.LayoutWidget object at 0x7f84e5834040>, <Dock LongShortColumnsInfo_dock (600, 60)>)}, 'text_items_dict': {<pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotItem.PlotItem.PlotItem object at 0x7f84177ad040>: {4: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5834a60>, 9: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5834b80>, 11: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5834ca0>, 12: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5834dc0>, 14: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5834ee0>, 15: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5838040>, 16: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5838160>, 18: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5838280>, 20: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e58383a0>, 24: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e58384c0>, 25: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e58385e0>, 26: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5838700>, 27: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5838820>, 28: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5838940>, 31: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5838a60>, 32: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5838b80>, 38: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5838ca0>, 39: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5838dc0>, 40: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5838ee0>, 44: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5815040>, 47: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5815160>, 48: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5815280>, 51: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e58153a0>, 52: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e58154c0>, 53: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e58155e0>, 56: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5815700>, 57: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5815820>, 59: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5815940>, 60: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5815a60>, 61: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5815b80>, 62: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5815d30>, 63: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e58349d0>, 66: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e58348b0>, 67: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5834700>, 68: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5815e50>, 70: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5815f70>, 71: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e583e0d0>, 72: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e583e1f0>, 75: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e583e310>, 77: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e583e430>, 79: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e583e550>, 80: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e583e670>, 81: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e583e790>, 82: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e583e8b0>, 84: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e583e9d0>, 87: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e583eaf0>, 89: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e583ec10>, 90: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e583ed30>, 91: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e583ee50>, 92: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e583ef70>, 93: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498e80d0>, 95: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498e81f0>, 98: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498e8310>, 101: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498e8430>, 102: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498e8550>, 104: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498e8670>}, <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotItem.PlotItem.PlotItem object at 0x7f8417ab4670>: {2: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498e8790>, 5: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498e88b0>, 6: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498e89d0>, 8: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498e8af0>, 9: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498e8c10>, 11: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498e8d30>, 15: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498e8e50>, 16: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498d3940>, 19: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498d3a60>, 24: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498d38b0>, 25: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498d3c10>, 26: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498d3d30>, 29: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498d3e50>, 30: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498d3f70>, 31: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498c70d0>, 33: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498c71f0>, 34: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498c7310>, 35: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498c7430>, 39: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498c7550>, 40: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498c7670>, 43: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498c7790>, 44: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498c78b0>, 47: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498c79d0>, 48: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498c7af0>, 51: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498c7c10>, 52: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498c7d30>, 53: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498c7e50>, 56: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498c7f70>, 58: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498d3700>, 60: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498d3820>, 61: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498d34c0>, 66: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498d35e0>, 68: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498d3280>, 72: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498d33a0>, 75: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498d3040>, 77: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498d3160>, 79: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498f40d0>, 80: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498f41f0>, 81: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498f4310>, 82: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498f4430>, 83: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498f4550>, 84: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498f4670>, 85: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498f4790>, 86: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498f48b0>, 87: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498f49d0>, 89: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498f4af0>, 92: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498f4c10>, 93: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498f4d30>, 98: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498f4e50>, 102: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84498f4f70>, 104: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e50520d0>}, <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotItem.PlotItem.PlotItem object at 0x7f844921df70>: {4: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e50521f0>, 9: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5052310>, 11: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5052430>, 12: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5052550>, 14: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5052670>, 15: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5052790>, 16: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e50528b0>, 18: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e50529d0>, 20: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5052af0>, 24: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5052c10>, 25: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5052d30>, 26: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5052e50>, 27: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5052f70>, 28: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e505b0d0>, 31: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e505b1f0>, 32: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e505b310>, 38: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e505b430>, 39: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e505b550>, 40: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e505b670>, 44: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e505b790>, 47: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e505b8b0>, 48: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e505b9d0>, 51: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e505baf0>, 52: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e505bc10>, 53: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e505bd30>, 56: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e505be50>, 57: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e505bf70>, 59: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e50620d0>, 60: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e50621f0>, 61: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5062310>, 62: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5062430>, 63: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5062550>, 66: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5062670>, 67: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5062790>, 68: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e50628b0>, 70: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e50629d0>, 71: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5062af0>, 72: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5062c10>, 75: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5062d30>, 77: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5062e50>, 79: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e5062f70>, 80: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e507d0d0>, 81: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e507d1f0>, 82: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e507d310>, 84: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e507d430>, 87: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e507d550>, 89: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e507d670>, 90: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e507d790>, 91: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e507d8b0>, 92: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e507d9d0>, 93: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e507daf0>, 95: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e507dc10>, 98: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e507dd30>, 101: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e507de50>, 102: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e507df70>, 104: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f70d0>}, <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotItem.PlotItem.PlotItem object at 0x7f844cf3e310>: {2: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f71f0>, 5: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f7310>, 6: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f7430>, 8: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f7550>, 9: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f7670>, 11: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f7790>, 15: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f78b0>, 16: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f79d0>, 19: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f7af0>, 24: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f7c10>, 25: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f7d30>, 26: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f7e50>, 29: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f7f70>, 30: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57c70d0>, 31: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57c71f0>, 33: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57c7310>, 34: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57c7430>, 35: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57c7550>, 39: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57c7670>, 40: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57c7790>, 43: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57c78b0>, 44: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57c79d0>, 47: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57c7af0>, 48: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57c7c10>, 51: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57c7d30>, 52: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57c7e50>, 53: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57c7f70>, 56: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57dc0d0>, 58: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57dc1f0>, 60: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57dc310>, 61: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57dc430>, 66: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57dc550>, 68: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57dc670>, 72: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57dc790>, 75: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57dc8b0>, 77: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57dc9d0>, 79: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57dcaf0>, 80: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57dcc10>, 81: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57dcd30>, 82: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57dce50>, 83: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57dcf70>, 84: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f30d0>, 85: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f31f0>, 86: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f3310>, 87: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f3430>, 89: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f3550>, 92: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f3670>, 93: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f3790>, 98: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f38b0>, 102: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f39d0>, 104: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.TextItem.TextItem object at 0x7f84e57f3af0>}}}), params=keys=['name', 'is_laps', 'enable_show_spearman', 'enable_show_pearson', 'enable_show_Z_values', 'use_plaintext_title'], active_epoch_IDX=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_tip_fn(...): data_string: t: 724.2848848461872|aclu: 92|neuron_IDX: 46|visualization_raster_y_location: nan\n",
      "_tip_fn(...): data_string: t: 315.6462102290243|aclu: 72|neuron_IDX: 33|visualization_raster_y_location: nan\n",
      "_tip_fn(...): data_string: t: 125.1625547966687|aclu: 2|neuron_IDX: 0|visualization_raster_y_location: nan\n",
      "_tip_fn(...): data_string: t: 105.42416618287098|aclu: 25|neuron_IDX: 10|visualization_raster_y_location: nan\n",
      "emitChanged(): self.val: 11\n",
      "valueChanged(new_val: 11)\n",
      "an_epoch: EpochTuple(Index=56, P_LR=0.6005112746655109, P_RL=0.39948872533448926, P_Long=0.43855079242985645, P_Short=0.5614492075701435, ripple_idx=56, ripple_start_t=212.30359946051612, P_Long_LR=0.263354695367623, P_Long_RL=0.17519609706223355, P_Short_LR=0.3371565792978879, P_Short_RL=0.2242926282722557, most_likely_decoder_index=2, start=212.30359946051612, stop=212.5447513370309, label='57', duration=0.24115187651477754, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=-0.382092343983857, long_RL_pf_peak_x_pearsonr=0.17579766041102016, short_LR_pf_peak_x_pearsonr=-0.3205615297787755, short_RL_pf_peak_x_pearsonr=0.26326022054198284)\n",
      "an_epoch: EpochTuple(Index=56, P_LR=0.6005112746655109, P_RL=0.39948872533448926, P_Long=0.43855079242985645, P_Short=0.5614492075701435, ripple_idx=56, ripple_start_t=212.30359946051612, P_Long_LR=0.263354695367623, P_Long_RL=0.17519609706223355, P_Short_LR=0.3371565792978879, P_Short_RL=0.2242926282722557, most_likely_decoder_index=2, start=212.30359946051612, stop=212.5447513370309, label='57', duration=0.24115187651477754, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=-0.382092343983857, long_RL_pf_peak_x_pearsonr=0.17579766041102016, short_LR_pf_peak_x_pearsonr=-0.3205615297787755, short_RL_pf_peak_x_pearsonr=0.26326022054198284)\n",
      "an_epoch: EpochTuple(Index=56, P_LR=0.6005112746655109, P_RL=0.39948872533448926, P_Long=0.43855079242985645, P_Short=0.5614492075701435, ripple_idx=56, ripple_start_t=212.30359946051612, P_Long_LR=0.263354695367623, P_Long_RL=0.17519609706223355, P_Short_LR=0.3371565792978879, P_Short_RL=0.2242926282722557, most_likely_decoder_index=2, start=212.30359946051612, stop=212.5447513370309, label='57', duration=0.24115187651477754, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=-0.382092343983857, long_RL_pf_peak_x_pearsonr=0.17579766041102016, short_LR_pf_peak_x_pearsonr=-0.3205615297787755, short_RL_pf_peak_x_pearsonr=0.26326022054198284)\n",
      "an_epoch: EpochTuple(Index=56, P_LR=0.6005112746655109, P_RL=0.39948872533448926, P_Long=0.43855079242985645, P_Short=0.5614492075701435, ripple_idx=56, ripple_start_t=212.30359946051612, P_Long_LR=0.263354695367623, P_Long_RL=0.17519609706223355, P_Short_LR=0.3371565792978879, P_Short_RL=0.2242926282722557, most_likely_decoder_index=2, start=212.30359946051612, stop=212.5447513370309, label='57', duration=0.24115187651477754, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=-0.382092343983857, long_RL_pf_peak_x_pearsonr=0.17579766041102016, short_LR_pf_peak_x_pearsonr=-0.3205615297787755, short_RL_pf_peak_x_pearsonr=0.26326022054198284)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 12\n",
      "valueChanged(new_val: 12)\n",
      "an_epoch: EpochTuple(Index=69, P_LR=0.9507828796720291, P_RL=0.04921712032797094, P_Long=0.9478871776869688, P_Short=0.052112822313031194, ripple_idx=69, ripple_start_t=307.07960469520185, P_Long_LR=0.9012349004054085, P_Long_RL=0.046652277281560316, P_Short_LR=0.04954797926662057, P_Short_RL=0.002564843046410625, most_likely_decoder_index=0, start=307.07960469520185, stop=307.1942823964637, label='70', duration=0.11467770126182586, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.05501424057239682, long_RL_pf_peak_x_pearsonr=-0.12086666081950946, short_LR_pf_peak_x_pearsonr=0.061984119526653725, short_RL_pf_peak_x_pearsonr=0.048537873322616554)\n",
      "an_epoch: EpochTuple(Index=69, P_LR=0.9507828796720291, P_RL=0.04921712032797094, P_Long=0.9478871776869688, P_Short=0.052112822313031194, ripple_idx=69, ripple_start_t=307.07960469520185, P_Long_LR=0.9012349004054085, P_Long_RL=0.046652277281560316, P_Short_LR=0.04954797926662057, P_Short_RL=0.002564843046410625, most_likely_decoder_index=0, start=307.07960469520185, stop=307.1942823964637, label='70', duration=0.11467770126182586, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.05501424057239682, long_RL_pf_peak_x_pearsonr=-0.12086666081950946, short_LR_pf_peak_x_pearsonr=0.061984119526653725, short_RL_pf_peak_x_pearsonr=0.048537873322616554)\n",
      "an_epoch: EpochTuple(Index=69, P_LR=0.9507828796720291, P_RL=0.04921712032797094, P_Long=0.9478871776869688, P_Short=0.052112822313031194, ripple_idx=69, ripple_start_t=307.07960469520185, P_Long_LR=0.9012349004054085, P_Long_RL=0.046652277281560316, P_Short_LR=0.04954797926662057, P_Short_RL=0.002564843046410625, most_likely_decoder_index=0, start=307.07960469520185, stop=307.1942823964637, label='70', duration=0.11467770126182586, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.05501424057239682, long_RL_pf_peak_x_pearsonr=-0.12086666081950946, short_LR_pf_peak_x_pearsonr=0.061984119526653725, short_RL_pf_peak_x_pearsonr=0.048537873322616554)\n",
      "an_epoch: EpochTuple(Index=69, P_LR=0.9507828796720291, P_RL=0.04921712032797094, P_Long=0.9478871776869688, P_Short=0.052112822313031194, ripple_idx=69, ripple_start_t=307.07960469520185, P_Long_LR=0.9012349004054085, P_Long_RL=0.046652277281560316, P_Short_LR=0.04954797926662057, P_Short_RL=0.002564843046410625, most_likely_decoder_index=0, start=307.07960469520185, stop=307.1942823964637, label='70', duration=0.11467770126182586, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.05501424057239682, long_RL_pf_peak_x_pearsonr=-0.12086666081950946, short_LR_pf_peak_x_pearsonr=0.061984119526653725, short_RL_pf_peak_x_pearsonr=0.048537873322616554)\n",
      "emitChanged(): self.val: 18\n",
      "valueChanged(new_val: 18)\n",
      "an_epoch: EpochTuple(Index=115, P_LR=6.23889594389891e-06, P_RL=0.9999937611040562, P_Long=0.9446936262994985, P_Short=0.05530637370050159, ripple_idx=115, ripple_start_t=607.3244122498436, P_Long_LR=5.893845233347094e-06, P_Long_RL=0.9446877324542653, P_Short_LR=3.4505071055181673e-07, P_Short_RL=0.05530602864979105, most_likely_decoder_index=1, start=607.3244122498436, stop=607.4178624419728, label='117', duration=0.09345019212923944, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=0.02747950045123243, long_RL_pf_peak_x_pearsonr=0.12152710445468137, short_LR_pf_peak_x_pearsonr=0.006598656709943025, short_RL_pf_peak_x_pearsonr=0.2968078849817229)\n",
      "an_epoch: EpochTuple(Index=115, P_LR=6.23889594389891e-06, P_RL=0.9999937611040562, P_Long=0.9446936262994985, P_Short=0.05530637370050159, ripple_idx=115, ripple_start_t=607.3244122498436, P_Long_LR=5.893845233347094e-06, P_Long_RL=0.9446877324542653, P_Short_LR=3.4505071055181673e-07, P_Short_RL=0.05530602864979105, most_likely_decoder_index=1, start=607.3244122498436, stop=607.4178624419728, label='117', duration=0.09345019212923944, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=0.02747950045123243, long_RL_pf_peak_x_pearsonr=0.12152710445468137, short_LR_pf_peak_x_pearsonr=0.006598656709943025, short_RL_pf_peak_x_pearsonr=0.2968078849817229)\n",
      "an_epoch: EpochTuple(Index=115, P_LR=6.23889594389891e-06, P_RL=0.9999937611040562, P_Long=0.9446936262994985, P_Short=0.05530637370050159, ripple_idx=115, ripple_start_t=607.3244122498436, P_Long_LR=5.893845233347094e-06, P_Long_RL=0.9446877324542653, P_Short_LR=3.4505071055181673e-07, P_Short_RL=0.05530602864979105, most_likely_decoder_index=1, start=607.3244122498436, stop=607.4178624419728, label='117', duration=0.09345019212923944, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=0.02747950045123243, long_RL_pf_peak_x_pearsonr=0.12152710445468137, short_LR_pf_peak_x_pearsonr=0.006598656709943025, short_RL_pf_peak_x_pearsonr=0.2968078849817229)\n",
      "an_epoch: EpochTuple(Index=115, P_LR=6.23889594389891e-06, P_RL=0.9999937611040562, P_Long=0.9446936262994985, P_Short=0.05530637370050159, ripple_idx=115, ripple_start_t=607.3244122498436, P_Long_LR=5.893845233347094e-06, P_Long_RL=0.9446877324542653, P_Short_LR=3.4505071055181673e-07, P_Short_RL=0.05530602864979105, most_likely_decoder_index=1, start=607.3244122498436, stop=607.4178624419728, label='117', duration=0.09345019212923944, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=0.02747950045123243, long_RL_pf_peak_x_pearsonr=0.12152710445468137, short_LR_pf_peak_x_pearsonr=0.006598656709943025, short_RL_pf_peak_x_pearsonr=0.2968078849817229)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 19\n",
      "valueChanged(new_val: 19)\n",
      "an_epoch: EpochTuple(Index=125, P_LR=0.00016044011368950218, P_RL=0.9998395598863106, P_Long=0.9911237066731315, P_Short=0.008876293326868403, ripple_idx=125, ripple_start_t=618.7250592127675, P_Long_LR=0.00015901600017899803, P_Long_RL=0.9909646906729526, P_Short_LR=1.424113510504136e-06, P_Short_RL=0.0088748692133579, most_likely_decoder_index=1, start=618.7250592127675, stop=618.7884652601788, label='127', duration=0.06340604741126299, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.05203243682159723, long_RL_pf_peak_x_pearsonr=-0.38619833711747986, short_LR_pf_peak_x_pearsonr=-0.1487132373479464, short_RL_pf_peak_x_pearsonr=-0.42058030753254344)\n",
      "an_epoch: EpochTuple(Index=125, P_LR=0.00016044011368950218, P_RL=0.9998395598863106, P_Long=0.9911237066731315, P_Short=0.008876293326868403, ripple_idx=125, ripple_start_t=618.7250592127675, P_Long_LR=0.00015901600017899803, P_Long_RL=0.9909646906729526, P_Short_LR=1.424113510504136e-06, P_Short_RL=0.0088748692133579, most_likely_decoder_index=1, start=618.7250592127675, stop=618.7884652601788, label='127', duration=0.06340604741126299, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.05203243682159723, long_RL_pf_peak_x_pearsonr=-0.38619833711747986, short_LR_pf_peak_x_pearsonr=-0.1487132373479464, short_RL_pf_peak_x_pearsonr=-0.42058030753254344)\n",
      "an_epoch: EpochTuple(Index=125, P_LR=0.00016044011368950218, P_RL=0.9998395598863106, P_Long=0.9911237066731315, P_Short=0.008876293326868403, ripple_idx=125, ripple_start_t=618.7250592127675, P_Long_LR=0.00015901600017899803, P_Long_RL=0.9909646906729526, P_Short_LR=1.424113510504136e-06, P_Short_RL=0.0088748692133579, most_likely_decoder_index=1, start=618.7250592127675, stop=618.7884652601788, label='127', duration=0.06340604741126299, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.05203243682159723, long_RL_pf_peak_x_pearsonr=-0.38619833711747986, short_LR_pf_peak_x_pearsonr=-0.1487132373479464, short_RL_pf_peak_x_pearsonr=-0.42058030753254344)\n",
      "an_epoch: EpochTuple(Index=125, P_LR=0.00016044011368950218, P_RL=0.9998395598863106, P_Long=0.9911237066731315, P_Short=0.008876293326868403, ripple_idx=125, ripple_start_t=618.7250592127675, P_Long_LR=0.00015901600017899803, P_Long_RL=0.9909646906729526, P_Short_LR=1.424113510504136e-06, P_Short_RL=0.0088748692133579, most_likely_decoder_index=1, start=618.7250592127675, stop=618.7884652601788, label='127', duration=0.06340604741126299, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.05203243682159723, long_RL_pf_peak_x_pearsonr=-0.38619833711747986, short_LR_pf_peak_x_pearsonr=-0.1487132373479464, short_RL_pf_peak_x_pearsonr=-0.42058030753254344)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 20\n",
      "valueChanged(new_val: 20)\n",
      "an_epoch: EpochTuple(Index=128, P_LR=0.7285706129234756, P_RL=0.27142938707652436, P_Long=0.6638513516604738, P_Short=0.33614864833952607, ripple_idx=128, ripple_start_t=626.9695964314742, P_Long_LR=0.48366258616934915, P_Long_RL=0.18018876549112464, P_Short_LR=0.24490802675412635, P_Short_RL=0.0912406215853997, most_likely_decoder_index=0, start=626.9695964314742, stop=627.0629237437388, label='130', duration=0.09332731226459146, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.5946005434620398, long_RL_pf_peak_x_pearsonr=-0.7410103329664154, short_LR_pf_peak_x_pearsonr=-0.4950071849631156, short_RL_pf_peak_x_pearsonr=-0.6712510055944466)\n",
      "an_epoch: EpochTuple(Index=128, P_LR=0.7285706129234756, P_RL=0.27142938707652436, P_Long=0.6638513516604738, P_Short=0.33614864833952607, ripple_idx=128, ripple_start_t=626.9695964314742, P_Long_LR=0.48366258616934915, P_Long_RL=0.18018876549112464, P_Short_LR=0.24490802675412635, P_Short_RL=0.0912406215853997, most_likely_decoder_index=0, start=626.9695964314742, stop=627.0629237437388, label='130', duration=0.09332731226459146, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.5946005434620398, long_RL_pf_peak_x_pearsonr=-0.7410103329664154, short_LR_pf_peak_x_pearsonr=-0.4950071849631156, short_RL_pf_peak_x_pearsonr=-0.6712510055944466)\n",
      "an_epoch: EpochTuple(Index=128, P_LR=0.7285706129234756, P_RL=0.27142938707652436, P_Long=0.6638513516604738, P_Short=0.33614864833952607, ripple_idx=128, ripple_start_t=626.9695964314742, P_Long_LR=0.48366258616934915, P_Long_RL=0.18018876549112464, P_Short_LR=0.24490802675412635, P_Short_RL=0.0912406215853997, most_likely_decoder_index=0, start=626.9695964314742, stop=627.0629237437388, label='130', duration=0.09332731226459146, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.5946005434620398, long_RL_pf_peak_x_pearsonr=-0.7410103329664154, short_LR_pf_peak_x_pearsonr=-0.4950071849631156, short_RL_pf_peak_x_pearsonr=-0.6712510055944466)\n",
      "an_epoch: EpochTuple(Index=128, P_LR=0.7285706129234756, P_RL=0.27142938707652436, P_Long=0.6638513516604738, P_Short=0.33614864833952607, ripple_idx=128, ripple_start_t=626.9695964314742, P_Long_LR=0.48366258616934915, P_Long_RL=0.18018876549112464, P_Short_LR=0.24490802675412635, P_Short_RL=0.0912406215853997, most_likely_decoder_index=0, start=626.9695964314742, stop=627.0629237437388, label='130', duration=0.09332731226459146, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.5946005434620398, long_RL_pf_peak_x_pearsonr=-0.7410103329664154, short_LR_pf_peak_x_pearsonr=-0.4950071849631156, short_RL_pf_peak_x_pearsonr=-0.6712510055944466)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 21\n",
      "valueChanged(new_val: 21)\n",
      "an_epoch: EpochTuple(Index=136, P_LR=0.48731025203087147, P_RL=0.5126897479691285, P_Long=0.45161777744667897, P_Short=0.5483822225533209, ripple_idx=136, ripple_start_t=641.0301025125664, P_Long_LR=0.22007797294916315, P_Long_RL=0.2315398044975158, P_Short_LR=0.26723227908170827, P_Short_RL=0.2811499434716126, most_likely_decoder_index=3, start=641.0301025125664, stop=641.1253037438728, label='138', duration=0.09520123130641878, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.7561163790960176, long_RL_pf_peak_x_pearsonr=-0.8054565402869578, short_LR_pf_peak_x_pearsonr=-0.6401268923891127, short_RL_pf_peak_x_pearsonr=-0.7504527360926422)\n",
      "an_epoch: EpochTuple(Index=136, P_LR=0.48731025203087147, P_RL=0.5126897479691285, P_Long=0.45161777744667897, P_Short=0.5483822225533209, ripple_idx=136, ripple_start_t=641.0301025125664, P_Long_LR=0.22007797294916315, P_Long_RL=0.2315398044975158, P_Short_LR=0.26723227908170827, P_Short_RL=0.2811499434716126, most_likely_decoder_index=3, start=641.0301025125664, stop=641.1253037438728, label='138', duration=0.09520123130641878, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.7561163790960176, long_RL_pf_peak_x_pearsonr=-0.8054565402869578, short_LR_pf_peak_x_pearsonr=-0.6401268923891127, short_RL_pf_peak_x_pearsonr=-0.7504527360926422)\n",
      "an_epoch: EpochTuple(Index=136, P_LR=0.48731025203087147, P_RL=0.5126897479691285, P_Long=0.45161777744667897, P_Short=0.5483822225533209, ripple_idx=136, ripple_start_t=641.0301025125664, P_Long_LR=0.22007797294916315, P_Long_RL=0.2315398044975158, P_Short_LR=0.26723227908170827, P_Short_RL=0.2811499434716126, most_likely_decoder_index=3, start=641.0301025125664, stop=641.1253037438728, label='138', duration=0.09520123130641878, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.7561163790960176, long_RL_pf_peak_x_pearsonr=-0.8054565402869578, short_LR_pf_peak_x_pearsonr=-0.6401268923891127, short_RL_pf_peak_x_pearsonr=-0.7504527360926422)\n",
      "an_epoch: EpochTuple(Index=136, P_LR=0.48731025203087147, P_RL=0.5126897479691285, P_Long=0.45161777744667897, P_Short=0.5483822225533209, ripple_idx=136, ripple_start_t=641.0301025125664, P_Long_LR=0.22007797294916315, P_Long_RL=0.2315398044975158, P_Short_LR=0.26723227908170827, P_Short_RL=0.2811499434716126, most_likely_decoder_index=3, start=641.0301025125664, stop=641.1253037438728, label='138', duration=0.09520123130641878, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.7561163790960176, long_RL_pf_peak_x_pearsonr=-0.8054565402869578, short_LR_pf_peak_x_pearsonr=-0.6401268923891127, short_RL_pf_peak_x_pearsonr=-0.7504527360926422)\n",
      "emitChanged(): self.val: 22\n",
      "valueChanged(new_val: 22)\n",
      "an_epoch: EpochTuple(Index=148, P_LR=0.19270695535898485, P_RL=0.8072930446410153, P_Long=0.7782787167943487, P_Short=0.22172128320565146, ripple_idx=148, ripple_start_t=678.4919252520194, P_Long_LR=0.14997972193413656, P_Long_RL=0.6282989948602122, P_Short_LR=0.04272723342484831, P_Short_RL=0.17899404978080316, most_likely_decoder_index=1, start=678.4919252520194, stop=678.5704455319792, label='150', duration=0.07852027995977551, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=0.737495075940467, long_RL_pf_peak_x_pearsonr=0.6591149668706959, short_LR_pf_peak_x_pearsonr=0.5530677084848934, short_RL_pf_peak_x_pearsonr=0.4293644309694613)\n",
      "an_epoch: EpochTuple(Index=148, P_LR=0.19270695535898485, P_RL=0.8072930446410153, P_Long=0.7782787167943487, P_Short=0.22172128320565146, ripple_idx=148, ripple_start_t=678.4919252520194, P_Long_LR=0.14997972193413656, P_Long_RL=0.6282989948602122, P_Short_LR=0.04272723342484831, P_Short_RL=0.17899404978080316, most_likely_decoder_index=1, start=678.4919252520194, stop=678.5704455319792, label='150', duration=0.07852027995977551, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=0.737495075940467, long_RL_pf_peak_x_pearsonr=0.6591149668706959, short_LR_pf_peak_x_pearsonr=0.5530677084848934, short_RL_pf_peak_x_pearsonr=0.4293644309694613)\n",
      "an_epoch: EpochTuple(Index=148, P_LR=0.19270695535898485, P_RL=0.8072930446410153, P_Long=0.7782787167943487, P_Short=0.22172128320565146, ripple_idx=148, ripple_start_t=678.4919252520194, P_Long_LR=0.14997972193413656, P_Long_RL=0.6282989948602122, P_Short_LR=0.04272723342484831, P_Short_RL=0.17899404978080316, most_likely_decoder_index=1, start=678.4919252520194, stop=678.5704455319792, label='150', duration=0.07852027995977551, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=0.737495075940467, long_RL_pf_peak_x_pearsonr=0.6591149668706959, short_LR_pf_peak_x_pearsonr=0.5530677084848934, short_RL_pf_peak_x_pearsonr=0.4293644309694613)\n",
      "an_epoch: EpochTuple(Index=148, P_LR=0.19270695535898485, P_RL=0.8072930446410153, P_Long=0.7782787167943487, P_Short=0.22172128320565146, ripple_idx=148, ripple_start_t=678.4919252520194, P_Long_LR=0.14997972193413656, P_Long_RL=0.6282989948602122, P_Short_LR=0.04272723342484831, P_Short_RL=0.17899404978080316, most_likely_decoder_index=1, start=678.4919252520194, stop=678.5704455319792, label='150', duration=0.07852027995977551, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=0.737495075940467, long_RL_pf_peak_x_pearsonr=0.6591149668706959, short_LR_pf_peak_x_pearsonr=0.5530677084848934, short_RL_pf_peak_x_pearsonr=0.4293644309694613)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 25\n",
      "valueChanged(new_val: 25)\n",
      "an_epoch: EpochTuple(Index=166, P_LR=0.05249634916830375, P_RL=0.9475036508316963, P_Long=0.9993909725108154, P_Short=0.0006090274891845023, ripple_idx=166, ripple_start_t=724.8915123754414, P_Long_LR=0.052464377448578424, P_Long_RL=0.9469265950622371, P_Short_LR=3.197171972532497e-05, P_Short_RL=0.0005770557694591774, most_likely_decoder_index=1, start=724.8915123754414, stop=724.9578368214425, label='169', duration=0.06632444600109011, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.09355177747807296, long_RL_pf_peak_x_pearsonr=-0.1927106961247687, short_LR_pf_peak_x_pearsonr=0.06551746769551252, short_RL_pf_peak_x_pearsonr=-0.07161423802345498)\n",
      "an_epoch: EpochTuple(Index=166, P_LR=0.05249634916830375, P_RL=0.9475036508316963, P_Long=0.9993909725108154, P_Short=0.0006090274891845023, ripple_idx=166, ripple_start_t=724.8915123754414, P_Long_LR=0.052464377448578424, P_Long_RL=0.9469265950622371, P_Short_LR=3.197171972532497e-05, P_Short_RL=0.0005770557694591774, most_likely_decoder_index=1, start=724.8915123754414, stop=724.9578368214425, label='169', duration=0.06632444600109011, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.09355177747807296, long_RL_pf_peak_x_pearsonr=-0.1927106961247687, short_LR_pf_peak_x_pearsonr=0.06551746769551252, short_RL_pf_peak_x_pearsonr=-0.07161423802345498)\n",
      "an_epoch: EpochTuple(Index=166, P_LR=0.05249634916830375, P_RL=0.9475036508316963, P_Long=0.9993909725108154, P_Short=0.0006090274891845023, ripple_idx=166, ripple_start_t=724.8915123754414, P_Long_LR=0.052464377448578424, P_Long_RL=0.9469265950622371, P_Short_LR=3.197171972532497e-05, P_Short_RL=0.0005770557694591774, most_likely_decoder_index=1, start=724.8915123754414, stop=724.9578368214425, label='169', duration=0.06632444600109011, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.09355177747807296, long_RL_pf_peak_x_pearsonr=-0.1927106961247687, short_LR_pf_peak_x_pearsonr=0.06551746769551252, short_RL_pf_peak_x_pearsonr=-0.07161423802345498)\n",
      "an_epoch: EpochTuple(Index=166, P_LR=0.05249634916830375, P_RL=0.9475036508316963, P_Long=0.9993909725108154, P_Short=0.0006090274891845023, ripple_idx=166, ripple_start_t=724.8915123754414, P_Long_LR=0.052464377448578424, P_Long_RL=0.9469265950622371, P_Short_LR=3.197171972532497e-05, P_Short_RL=0.0005770557694591774, most_likely_decoder_index=1, start=724.8915123754414, stop=724.9578368214425, label='169', duration=0.06632444600109011, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.09355177747807296, long_RL_pf_peak_x_pearsonr=-0.1927106961247687, short_LR_pf_peak_x_pearsonr=0.06551746769551252, short_RL_pf_peak_x_pearsonr=-0.07161423802345498)\n",
      "emitChanged(): self.val: 28\n",
      "valueChanged(new_val: 28)\n",
      "an_epoch: EpochTuple(Index=183, P_LR=0.6382324120745398, P_RL=0.36176758792546015, P_Long=0.6331733541645134, P_Short=0.36682664583548663, ripple_idx=183, ripple_start_t=764.1524509938899, P_Long_LR=0.4041117570897443, P_Long_RL=0.2290615970747691, P_Short_LR=0.2341206549847956, P_Short_RL=0.13270599085069104, most_likely_decoder_index=0, start=764.1524509938899, stop=764.2699242136441, label='186', duration=0.11747321975417435, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.1564402983423053, long_RL_pf_peak_x_pearsonr=0.32667618566151874, short_LR_pf_peak_x_pearsonr=-0.1094520032467258, short_RL_pf_peak_x_pearsonr=0.29471056349723923)\n",
      "an_epoch: EpochTuple(Index=183, P_LR=0.6382324120745398, P_RL=0.36176758792546015, P_Long=0.6331733541645134, P_Short=0.36682664583548663, ripple_idx=183, ripple_start_t=764.1524509938899, P_Long_LR=0.4041117570897443, P_Long_RL=0.2290615970747691, P_Short_LR=0.2341206549847956, P_Short_RL=0.13270599085069104, most_likely_decoder_index=0, start=764.1524509938899, stop=764.2699242136441, label='186', duration=0.11747321975417435, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.1564402983423053, long_RL_pf_peak_x_pearsonr=0.32667618566151874, short_LR_pf_peak_x_pearsonr=-0.1094520032467258, short_RL_pf_peak_x_pearsonr=0.29471056349723923)\n",
      "an_epoch: EpochTuple(Index=183, P_LR=0.6382324120745398, P_RL=0.36176758792546015, P_Long=0.6331733541645134, P_Short=0.36682664583548663, ripple_idx=183, ripple_start_t=764.1524509938899, P_Long_LR=0.4041117570897443, P_Long_RL=0.2290615970747691, P_Short_LR=0.2341206549847956, P_Short_RL=0.13270599085069104, most_likely_decoder_index=0, start=764.1524509938899, stop=764.2699242136441, label='186', duration=0.11747321975417435, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.1564402983423053, long_RL_pf_peak_x_pearsonr=0.32667618566151874, short_LR_pf_peak_x_pearsonr=-0.1094520032467258, short_RL_pf_peak_x_pearsonr=0.29471056349723923)\n",
      "an_epoch: EpochTuple(Index=183, P_LR=0.6382324120745398, P_RL=0.36176758792546015, P_Long=0.6331733541645134, P_Short=0.36682664583548663, ripple_idx=183, ripple_start_t=764.1524509938899, P_Long_LR=0.4041117570897443, P_Long_RL=0.2290615970747691, P_Short_LR=0.2341206549847956, P_Short_RL=0.13270599085069104, most_likely_decoder_index=0, start=764.1524509938899, stop=764.2699242136441, label='186', duration=0.11747321975417435, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.1564402983423053, long_RL_pf_peak_x_pearsonr=0.32667618566151874, short_LR_pf_peak_x_pearsonr=-0.1094520032467258, short_RL_pf_peak_x_pearsonr=0.29471056349723923)\n",
      "emitChanged(): self.val: 31\n",
      "valueChanged(new_val: 31)\n",
      "an_epoch: EpochTuple(Index=216, P_LR=0.5025218296599616, P_RL=0.4974781703400384, P_Long=0.5686364653722564, P_Short=0.43136353462774346, ripple_idx=216, ripple_start_t=896.8536284909351, P_Long_LR=0.2857522369902397, P_Long_RL=0.2828842283820167, P_Short_LR=0.21676959266972184, P_Short_RL=0.21459394195802162, most_likely_decoder_index=0, start=896.8536284909351, stop=897.0923227686435, label='219', duration=0.23869427770841867, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=0.26446909978844163, long_RL_pf_peak_x_pearsonr=0.01575715261163894, short_LR_pf_peak_x_pearsonr=0.3780041283917195, short_RL_pf_peak_x_pearsonr=0.18204645373799314)\n",
      "an_epoch: EpochTuple(Index=216, P_LR=0.5025218296599616, P_RL=0.4974781703400384, P_Long=0.5686364653722564, P_Short=0.43136353462774346, ripple_idx=216, ripple_start_t=896.8536284909351, P_Long_LR=0.2857522369902397, P_Long_RL=0.2828842283820167, P_Short_LR=0.21676959266972184, P_Short_RL=0.21459394195802162, most_likely_decoder_index=0, start=896.8536284909351, stop=897.0923227686435, label='219', duration=0.23869427770841867, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=0.26446909978844163, long_RL_pf_peak_x_pearsonr=0.01575715261163894, short_LR_pf_peak_x_pearsonr=0.3780041283917195, short_RL_pf_peak_x_pearsonr=0.18204645373799314)\n",
      "an_epoch: EpochTuple(Index=216, P_LR=0.5025218296599616, P_RL=0.4974781703400384, P_Long=0.5686364653722564, P_Short=0.43136353462774346, ripple_idx=216, ripple_start_t=896.8536284909351, P_Long_LR=0.2857522369902397, P_Long_RL=0.2828842283820167, P_Short_LR=0.21676959266972184, P_Short_RL=0.21459394195802162, most_likely_decoder_index=0, start=896.8536284909351, stop=897.0923227686435, label='219', duration=0.23869427770841867, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=0.26446909978844163, long_RL_pf_peak_x_pearsonr=0.01575715261163894, short_LR_pf_peak_x_pearsonr=0.3780041283917195, short_RL_pf_peak_x_pearsonr=0.18204645373799314)\n",
      "an_epoch: EpochTuple(Index=216, P_LR=0.5025218296599616, P_RL=0.4974781703400384, P_Long=0.5686364653722564, P_Short=0.43136353462774346, ripple_idx=216, ripple_start_t=896.8536284909351, P_Long_LR=0.2857522369902397, P_Long_RL=0.2828842283820167, P_Short_LR=0.21676959266972184, P_Short_RL=0.21459394195802162, most_likely_decoder_index=0, start=896.8536284909351, stop=897.0923227686435, label='219', duration=0.23869427770841867, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=0.26446909978844163, long_RL_pf_peak_x_pearsonr=0.01575715261163894, short_LR_pf_peak_x_pearsonr=0.3780041283917195, short_RL_pf_peak_x_pearsonr=0.18204645373799314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 32\n",
      "valueChanged(new_val: 32)\n",
      "an_epoch: EpochTuple(Index=222, P_LR=0.4329450981557645, P_RL=0.5670549018442356, P_Long=0.4459576977387561, P_Short=0.5540423022612438, ripple_idx=222, ripple_start_t=950.6775906931143, P_Long_LR=0.1930751992208245, P_Long_RL=0.2528824985179316, P_Short_LR=0.23986989893493996, P_Short_RL=0.3141724033263039, most_likely_decoder_index=3, start=950.6775906931143, stop=950.8714645137079, label='225', duration=0.1938738205935806, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=0.15039365176160635, long_RL_pf_peak_x_pearsonr=0.03599232506015984, short_LR_pf_peak_x_pearsonr=0.16268469222001714, short_RL_pf_peak_x_pearsonr=-0.037021548654727725)\n",
      "an_epoch: EpochTuple(Index=222, P_LR=0.4329450981557645, P_RL=0.5670549018442356, P_Long=0.4459576977387561, P_Short=0.5540423022612438, ripple_idx=222, ripple_start_t=950.6775906931143, P_Long_LR=0.1930751992208245, P_Long_RL=0.2528824985179316, P_Short_LR=0.23986989893493996, P_Short_RL=0.3141724033263039, most_likely_decoder_index=3, start=950.6775906931143, stop=950.8714645137079, label='225', duration=0.1938738205935806, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=0.15039365176160635, long_RL_pf_peak_x_pearsonr=0.03599232506015984, short_LR_pf_peak_x_pearsonr=0.16268469222001714, short_RL_pf_peak_x_pearsonr=-0.037021548654727725)\n",
      "an_epoch: EpochTuple(Index=222, P_LR=0.4329450981557645, P_RL=0.5670549018442356, P_Long=0.4459576977387561, P_Short=0.5540423022612438, ripple_idx=222, ripple_start_t=950.6775906931143, P_Long_LR=0.1930751992208245, P_Long_RL=0.2528824985179316, P_Short_LR=0.23986989893493996, P_Short_RL=0.3141724033263039, most_likely_decoder_index=3, start=950.6775906931143, stop=950.8714645137079, label='225', duration=0.1938738205935806, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=0.15039365176160635, long_RL_pf_peak_x_pearsonr=0.03599232506015984, short_LR_pf_peak_x_pearsonr=0.16268469222001714, short_RL_pf_peak_x_pearsonr=-0.037021548654727725)\n",
      "an_epoch: EpochTuple(Index=222, P_LR=0.4329450981557645, P_RL=0.5670549018442356, P_Long=0.4459576977387561, P_Short=0.5540423022612438, ripple_idx=222, ripple_start_t=950.6775906931143, P_Long_LR=0.1930751992208245, P_Long_RL=0.2528824985179316, P_Short_LR=0.23986989893493996, P_Short_RL=0.3141724033263039, most_likely_decoder_index=3, start=950.6775906931143, stop=950.8714645137079, label='225', duration=0.1938738205935806, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=0.15039365176160635, long_RL_pf_peak_x_pearsonr=0.03599232506015984, short_LR_pf_peak_x_pearsonr=0.16268469222001714, short_RL_pf_peak_x_pearsonr=-0.037021548654727725)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 33\n",
      "valueChanged(new_val: 33)\n",
      "an_epoch: EpochTuple(Index=223, P_LR=0.4908460955756552, P_RL=0.5091539044243449, P_Long=0.9465374144151584, P_Short=0.05346258558484159, ripple_idx=223, ripple_start_t=963.6543264489155, P_Long_LR=0.46460419418195636, P_Long_RL=0.4819332202332021, P_Short_LR=0.0262419013936988, P_Short_RL=0.027220684191142798, most_likely_decoder_index=1, start=963.6543264489155, stop=963.7602182347327, label='226', duration=0.10589178581722081, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.01552135706184863, long_RL_pf_peak_x_pearsonr=0.1952426884336755, short_LR_pf_peak_x_pearsonr=0.05600146159394303, short_RL_pf_peak_x_pearsonr=-0.018112390467330885)\n",
      "an_epoch: EpochTuple(Index=223, P_LR=0.4908460955756552, P_RL=0.5091539044243449, P_Long=0.9465374144151584, P_Short=0.05346258558484159, ripple_idx=223, ripple_start_t=963.6543264489155, P_Long_LR=0.46460419418195636, P_Long_RL=0.4819332202332021, P_Short_LR=0.0262419013936988, P_Short_RL=0.027220684191142798, most_likely_decoder_index=1, start=963.6543264489155, stop=963.7602182347327, label='226', duration=0.10589178581722081, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.01552135706184863, long_RL_pf_peak_x_pearsonr=0.1952426884336755, short_LR_pf_peak_x_pearsonr=0.05600146159394303, short_RL_pf_peak_x_pearsonr=-0.018112390467330885)\n",
      "an_epoch: EpochTuple(Index=223, P_LR=0.4908460955756552, P_RL=0.5091539044243449, P_Long=0.9465374144151584, P_Short=0.05346258558484159, ripple_idx=223, ripple_start_t=963.6543264489155, P_Long_LR=0.46460419418195636, P_Long_RL=0.4819332202332021, P_Short_LR=0.0262419013936988, P_Short_RL=0.027220684191142798, most_likely_decoder_index=1, start=963.6543264489155, stop=963.7602182347327, label='226', duration=0.10589178581722081, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.01552135706184863, long_RL_pf_peak_x_pearsonr=0.1952426884336755, short_LR_pf_peak_x_pearsonr=0.05600146159394303, short_RL_pf_peak_x_pearsonr=-0.018112390467330885)\n",
      "an_epoch: EpochTuple(Index=223, P_LR=0.4908460955756552, P_RL=0.5091539044243449, P_Long=0.9465374144151584, P_Short=0.05346258558484159, ripple_idx=223, ripple_start_t=963.6543264489155, P_Long_LR=0.46460419418195636, P_Long_RL=0.4819332202332021, P_Short_LR=0.0262419013936988, P_Short_RL=0.027220684191142798, most_likely_decoder_index=1, start=963.6543264489155, stop=963.7602182347327, label='226', duration=0.10589178581722081, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.01552135706184863, long_RL_pf_peak_x_pearsonr=0.1952426884336755, short_LR_pf_peak_x_pearsonr=0.05600146159394303, short_RL_pf_peak_x_pearsonr=-0.018112390467330885)\n",
      "emitChanged(): self.val: 35\n",
      "valueChanged(new_val: 35)\n",
      "an_epoch: EpochTuple(Index=231, P_LR=0.6417222399190146, P_RL=0.35827776008098505, P_Long=0.47610511762327345, P_Short=0.5238948823767268, ripple_idx=231, ripple_start_t=1018.4285499245161, P_Long_LR=0.3055272425181129, P_Long_RL=0.17057787510516034, P_Short_LR=0.33619499740090175, P_Short_RL=0.1876998849758248, most_likely_decoder_index=2, start=1018.4285499245161, stop=1018.6890553912381, label='234', duration=0.26050546672195196, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=0.4622540577940398, long_RL_pf_peak_x_pearsonr=0.6472576094221256, short_LR_pf_peak_x_pearsonr=0.45068356219520644, short_RL_pf_peak_x_pearsonr=0.6706934515425839)\n",
      "an_epoch: EpochTuple(Index=231, P_LR=0.6417222399190146, P_RL=0.35827776008098505, P_Long=0.47610511762327345, P_Short=0.5238948823767268, ripple_idx=231, ripple_start_t=1018.4285499245161, P_Long_LR=0.3055272425181129, P_Long_RL=0.17057787510516034, P_Short_LR=0.33619499740090175, P_Short_RL=0.1876998849758248, most_likely_decoder_index=2, start=1018.4285499245161, stop=1018.6890553912381, label='234', duration=0.26050546672195196, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=0.4622540577940398, long_RL_pf_peak_x_pearsonr=0.6472576094221256, short_LR_pf_peak_x_pearsonr=0.45068356219520644, short_RL_pf_peak_x_pearsonr=0.6706934515425839)\n",
      "an_epoch: EpochTuple(Index=231, P_LR=0.6417222399190146, P_RL=0.35827776008098505, P_Long=0.47610511762327345, P_Short=0.5238948823767268, ripple_idx=231, ripple_start_t=1018.4285499245161, P_Long_LR=0.3055272425181129, P_Long_RL=0.17057787510516034, P_Short_LR=0.33619499740090175, P_Short_RL=0.1876998849758248, most_likely_decoder_index=2, start=1018.4285499245161, stop=1018.6890553912381, label='234', duration=0.26050546672195196, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=0.4622540577940398, long_RL_pf_peak_x_pearsonr=0.6472576094221256, short_LR_pf_peak_x_pearsonr=0.45068356219520644, short_RL_pf_peak_x_pearsonr=0.6706934515425839)\n",
      "an_epoch: EpochTuple(Index=231, P_LR=0.6417222399190146, P_RL=0.35827776008098505, P_Long=0.47610511762327345, P_Short=0.5238948823767268, ripple_idx=231, ripple_start_t=1018.4285499245161, P_Long_LR=0.3055272425181129, P_Long_RL=0.17057787510516034, P_Short_LR=0.33619499740090175, P_Short_RL=0.1876998849758248, most_likely_decoder_index=2, start=1018.4285499245161, stop=1018.6890553912381, label='234', duration=0.26050546672195196, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=0.4622540577940398, long_RL_pf_peak_x_pearsonr=0.6472576094221256, short_LR_pf_peak_x_pearsonr=0.45068356219520644, short_RL_pf_peak_x_pearsonr=0.6706934515425839)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 37\n",
      "valueChanged(new_val: 37)\n",
      "an_epoch: EpochTuple(Index=244, P_LR=0.7809238440139437, P_RL=0.21907615598605637, P_Long=0.7366130314339568, P_Short=0.26338696856604316, ripple_idx=244, ripple_start_t=1116.4435781408101, P_Long_LR=0.5752386800581695, P_Long_RL=0.16137435137578737, P_Short_LR=0.20568516395577416, P_Short_RL=0.057701804610269, most_likely_decoder_index=0, start=1116.4435781408101, stop=1116.5642462391406, label='248', duration=0.12066809833049774, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.061238700166952854, long_RL_pf_peak_x_pearsonr=0.5195706263314096, short_LR_pf_peak_x_pearsonr=0.28443204400398164, short_RL_pf_peak_x_pearsonr=0.5877325380829294)\n",
      "an_epoch: EpochTuple(Index=244, P_LR=0.7809238440139437, P_RL=0.21907615598605637, P_Long=0.7366130314339568, P_Short=0.26338696856604316, ripple_idx=244, ripple_start_t=1116.4435781408101, P_Long_LR=0.5752386800581695, P_Long_RL=0.16137435137578737, P_Short_LR=0.20568516395577416, P_Short_RL=0.057701804610269, most_likely_decoder_index=0, start=1116.4435781408101, stop=1116.5642462391406, label='248', duration=0.12066809833049774, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.061238700166952854, long_RL_pf_peak_x_pearsonr=0.5195706263314096, short_LR_pf_peak_x_pearsonr=0.28443204400398164, short_RL_pf_peak_x_pearsonr=0.5877325380829294)\n",
      "an_epoch: EpochTuple(Index=244, P_LR=0.7809238440139437, P_RL=0.21907615598605637, P_Long=0.7366130314339568, P_Short=0.26338696856604316, ripple_idx=244, ripple_start_t=1116.4435781408101, P_Long_LR=0.5752386800581695, P_Long_RL=0.16137435137578737, P_Short_LR=0.20568516395577416, P_Short_RL=0.057701804610269, most_likely_decoder_index=0, start=1116.4435781408101, stop=1116.5642462391406, label='248', duration=0.12066809833049774, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.061238700166952854, long_RL_pf_peak_x_pearsonr=0.5195706263314096, short_LR_pf_peak_x_pearsonr=0.28443204400398164, short_RL_pf_peak_x_pearsonr=0.5877325380829294)\n",
      "an_epoch: EpochTuple(Index=244, P_LR=0.7809238440139437, P_RL=0.21907615598605637, P_Long=0.7366130314339568, P_Short=0.26338696856604316, ripple_idx=244, ripple_start_t=1116.4435781408101, P_Long_LR=0.5752386800581695, P_Long_RL=0.16137435137578737, P_Short_LR=0.20568516395577416, P_Short_RL=0.057701804610269, most_likely_decoder_index=0, start=1116.4435781408101, stop=1116.5642462391406, label='248', duration=0.12066809833049774, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.061238700166952854, long_RL_pf_peak_x_pearsonr=0.5195706263314096, short_LR_pf_peak_x_pearsonr=0.28443204400398164, short_RL_pf_peak_x_pearsonr=0.5877325380829294)\n",
      "emitChanged(): self.val: 38\n",
      "valueChanged(new_val: 38)\n",
      "an_epoch: EpochTuple(Index=250, P_LR=0.655167391220912, P_RL=0.34483260877908783, P_Long=0.5248718861479533, P_Short=0.4751281138520467, ripple_idx=250, ripple_start_t=1132.191594397882, P_Long_LR=0.3438789443727541, P_Long_RL=0.18099294177519912, P_Short_LR=0.31128844684815793, P_Short_RL=0.16383966700388872, most_likely_decoder_index=0, start=1132.191594397882, stop=1132.47652225208, label='254', duration=0.2849278541980311, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=-0.5790721879452186, long_RL_pf_peak_x_pearsonr=-0.024266698569849896, short_LR_pf_peak_x_pearsonr=-0.4611041615182043, short_RL_pf_peak_x_pearsonr=-0.1607596404545431)\n",
      "an_epoch: EpochTuple(Index=250, P_LR=0.655167391220912, P_RL=0.34483260877908783, P_Long=0.5248718861479533, P_Short=0.4751281138520467, ripple_idx=250, ripple_start_t=1132.191594397882, P_Long_LR=0.3438789443727541, P_Long_RL=0.18099294177519912, P_Short_LR=0.31128844684815793, P_Short_RL=0.16383966700388872, most_likely_decoder_index=0, start=1132.191594397882, stop=1132.47652225208, label='254', duration=0.2849278541980311, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=-0.5790721879452186, long_RL_pf_peak_x_pearsonr=-0.024266698569849896, short_LR_pf_peak_x_pearsonr=-0.4611041615182043, short_RL_pf_peak_x_pearsonr=-0.1607596404545431)\n",
      "an_epoch: EpochTuple(Index=250, P_LR=0.655167391220912, P_RL=0.34483260877908783, P_Long=0.5248718861479533, P_Short=0.4751281138520467, ripple_idx=250, ripple_start_t=1132.191594397882, P_Long_LR=0.3438789443727541, P_Long_RL=0.18099294177519912, P_Short_LR=0.31128844684815793, P_Short_RL=0.16383966700388872, most_likely_decoder_index=0, start=1132.191594397882, stop=1132.47652225208, label='254', duration=0.2849278541980311, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=-0.5790721879452186, long_RL_pf_peak_x_pearsonr=-0.024266698569849896, short_LR_pf_peak_x_pearsonr=-0.4611041615182043, short_RL_pf_peak_x_pearsonr=-0.1607596404545431)\n",
      "an_epoch: EpochTuple(Index=250, P_LR=0.655167391220912, P_RL=0.34483260877908783, P_Long=0.5248718861479533, P_Short=0.4751281138520467, ripple_idx=250, ripple_start_t=1132.191594397882, P_Long_LR=0.3438789443727541, P_Long_RL=0.18099294177519912, P_Short_LR=0.31128844684815793, P_Short_RL=0.16383966700388872, most_likely_decoder_index=0, start=1132.191594397882, stop=1132.47652225208, label='254', duration=0.2849278541980311, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=-0.5790721879452186, long_RL_pf_peak_x_pearsonr=-0.024266698569849896, short_LR_pf_peak_x_pearsonr=-0.4611041615182043, short_RL_pf_peak_x_pearsonr=-0.1607596404545431)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 39\n",
      "valueChanged(new_val: 39)\n",
      "an_epoch: EpochTuple(Index=251, P_LR=0.4424588844841814, P_RL=0.5575411155158186, P_Long=0.4659126722340696, P_Short=0.5340873277659304, ripple_idx=251, ripple_start_t=1132.878247486311, P_Long_LR=0.20614720122373048, P_Long_RL=0.25976547101033914, P_Short_LR=0.23631168326045093, P_Short_RL=0.2977756445054795, most_likely_decoder_index=3, start=1132.878247486311, stop=1133.0441046813503, label='255', duration=0.16585719503927976, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.029849380251629375, long_RL_pf_peak_x_pearsonr=0.3491689207223859, short_LR_pf_peak_x_pearsonr=0.10081016545576166, short_RL_pf_peak_x_pearsonr=0.332305762290717)\n",
      "an_epoch: EpochTuple(Index=251, P_LR=0.4424588844841814, P_RL=0.5575411155158186, P_Long=0.4659126722340696, P_Short=0.5340873277659304, ripple_idx=251, ripple_start_t=1132.878247486311, P_Long_LR=0.20614720122373048, P_Long_RL=0.25976547101033914, P_Short_LR=0.23631168326045093, P_Short_RL=0.2977756445054795, most_likely_decoder_index=3, start=1132.878247486311, stop=1133.0441046813503, label='255', duration=0.16585719503927976, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.029849380251629375, long_RL_pf_peak_x_pearsonr=0.3491689207223859, short_LR_pf_peak_x_pearsonr=0.10081016545576166, short_RL_pf_peak_x_pearsonr=0.332305762290717)\n",
      "an_epoch: EpochTuple(Index=251, P_LR=0.4424588844841814, P_RL=0.5575411155158186, P_Long=0.4659126722340696, P_Short=0.5340873277659304, ripple_idx=251, ripple_start_t=1132.878247486311, P_Long_LR=0.20614720122373048, P_Long_RL=0.25976547101033914, P_Short_LR=0.23631168326045093, P_Short_RL=0.2977756445054795, most_likely_decoder_index=3, start=1132.878247486311, stop=1133.0441046813503, label='255', duration=0.16585719503927976, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.029849380251629375, long_RL_pf_peak_x_pearsonr=0.3491689207223859, short_LR_pf_peak_x_pearsonr=0.10081016545576166, short_RL_pf_peak_x_pearsonr=0.332305762290717)\n",
      "an_epoch: EpochTuple(Index=251, P_LR=0.4424588844841814, P_RL=0.5575411155158186, P_Long=0.4659126722340696, P_Short=0.5340873277659304, ripple_idx=251, ripple_start_t=1132.878247486311, P_Long_LR=0.20614720122373048, P_Long_RL=0.25976547101033914, P_Short_LR=0.23631168326045093, P_Short_RL=0.2977756445054795, most_likely_decoder_index=3, start=1132.878247486311, stop=1133.0441046813503, label='255', duration=0.16585719503927976, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.029849380251629375, long_RL_pf_peak_x_pearsonr=0.3491689207223859, short_LR_pf_peak_x_pearsonr=0.10081016545576166, short_RL_pf_peak_x_pearsonr=0.332305762290717)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 40\n",
      "valueChanged(new_val: 40)\n",
      "an_epoch: EpochTuple(Index=253, P_LR=0.5435243400353612, P_RL=0.45647565996463885, P_Long=0.3477476243908583, P_Short=0.6522523756091416, ripple_idx=253, ripple_start_t=1135.513284857152, P_Long_LR=0.18900929804590594, P_Long_RL=0.15873832634495239, P_Short_LR=0.3545150419894552, P_Short_RL=0.2977373336196864, most_likely_decoder_index=2, start=1135.513284857152, stop=1135.6884194875602, label='257', duration=0.17513463040813804, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.04699016169837495, long_RL_pf_peak_x_pearsonr=0.07346711166074549, short_LR_pf_peak_x_pearsonr=-0.02728746427854276, short_RL_pf_peak_x_pearsonr=0.07868620823146513)\n",
      "an_epoch: EpochTuple(Index=253, P_LR=0.5435243400353612, P_RL=0.45647565996463885, P_Long=0.3477476243908583, P_Short=0.6522523756091416, ripple_idx=253, ripple_start_t=1135.513284857152, P_Long_LR=0.18900929804590594, P_Long_RL=0.15873832634495239, P_Short_LR=0.3545150419894552, P_Short_RL=0.2977373336196864, most_likely_decoder_index=2, start=1135.513284857152, stop=1135.6884194875602, label='257', duration=0.17513463040813804, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.04699016169837495, long_RL_pf_peak_x_pearsonr=0.07346711166074549, short_LR_pf_peak_x_pearsonr=-0.02728746427854276, short_RL_pf_peak_x_pearsonr=0.07868620823146513)\n",
      "an_epoch: EpochTuple(Index=253, P_LR=0.5435243400353612, P_RL=0.45647565996463885, P_Long=0.3477476243908583, P_Short=0.6522523756091416, ripple_idx=253, ripple_start_t=1135.513284857152, P_Long_LR=0.18900929804590594, P_Long_RL=0.15873832634495239, P_Short_LR=0.3545150419894552, P_Short_RL=0.2977373336196864, most_likely_decoder_index=2, start=1135.513284857152, stop=1135.6884194875602, label='257', duration=0.17513463040813804, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.04699016169837495, long_RL_pf_peak_x_pearsonr=0.07346711166074549, short_LR_pf_peak_x_pearsonr=-0.02728746427854276, short_RL_pf_peak_x_pearsonr=0.07868620823146513)\n",
      "an_epoch: EpochTuple(Index=253, P_LR=0.5435243400353612, P_RL=0.45647565996463885, P_Long=0.3477476243908583, P_Short=0.6522523756091416, ripple_idx=253, ripple_start_t=1135.513284857152, P_Long_LR=0.18900929804590594, P_Long_RL=0.15873832634495239, P_Short_LR=0.3545150419894552, P_Short_RL=0.2977373336196864, most_likely_decoder_index=2, start=1135.513284857152, stop=1135.6884194875602, label='257', duration=0.17513463040813804, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.04699016169837495, long_RL_pf_peak_x_pearsonr=0.07346711166074549, short_LR_pf_peak_x_pearsonr=-0.02728746427854276, short_RL_pf_peak_x_pearsonr=0.07868620823146513)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 41\n",
      "valueChanged(new_val: 41)\n",
      "an_epoch: EpochTuple(Index=258, P_LR=0.4190733778568115, P_RL=0.5809266221431885, P_Long=0.557583160835332, P_Short=0.44241683916466795, ripple_idx=258, ripple_start_t=1140.1954405398574, P_Long_LR=0.23366825864734037, P_Long_RL=0.32391490218799157, P_Short_LR=0.1854051192094711, P_Short_RL=0.25701171995519684, most_likely_decoder_index=1, start=1140.1954405398574, stop=1140.494929666631, label='262', duration=0.2994891267735511, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=-0.6851693877309913, long_RL_pf_peak_x_pearsonr=-0.3812310652021742, short_LR_pf_peak_x_pearsonr=-0.7380151688713461, short_RL_pf_peak_x_pearsonr=-0.41000487651300516)\n",
      "an_epoch: EpochTuple(Index=258, P_LR=0.4190733778568115, P_RL=0.5809266221431885, P_Long=0.557583160835332, P_Short=0.44241683916466795, ripple_idx=258, ripple_start_t=1140.1954405398574, P_Long_LR=0.23366825864734037, P_Long_RL=0.32391490218799157, P_Short_LR=0.1854051192094711, P_Short_RL=0.25701171995519684, most_likely_decoder_index=1, start=1140.1954405398574, stop=1140.494929666631, label='262', duration=0.2994891267735511, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=-0.6851693877309913, long_RL_pf_peak_x_pearsonr=-0.3812310652021742, short_LR_pf_peak_x_pearsonr=-0.7380151688713461, short_RL_pf_peak_x_pearsonr=-0.41000487651300516)\n",
      "an_epoch: EpochTuple(Index=258, P_LR=0.4190733778568115, P_RL=0.5809266221431885, P_Long=0.557583160835332, P_Short=0.44241683916466795, ripple_idx=258, ripple_start_t=1140.1954405398574, P_Long_LR=0.23366825864734037, P_Long_RL=0.32391490218799157, P_Short_LR=0.1854051192094711, P_Short_RL=0.25701171995519684, most_likely_decoder_index=1, start=1140.1954405398574, stop=1140.494929666631, label='262', duration=0.2994891267735511, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=-0.6851693877309913, long_RL_pf_peak_x_pearsonr=-0.3812310652021742, short_LR_pf_peak_x_pearsonr=-0.7380151688713461, short_RL_pf_peak_x_pearsonr=-0.41000487651300516)\n",
      "an_epoch: EpochTuple(Index=258, P_LR=0.4190733778568115, P_RL=0.5809266221431885, P_Long=0.557583160835332, P_Short=0.44241683916466795, ripple_idx=258, ripple_start_t=1140.1954405398574, P_Long_LR=0.23366825864734037, P_Long_RL=0.32391490218799157, P_Short_LR=0.1854051192094711, P_Short_RL=0.25701171995519684, most_likely_decoder_index=1, start=1140.1954405398574, stop=1140.494929666631, label='262', duration=0.2994891267735511, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=-0.6851693877309913, long_RL_pf_peak_x_pearsonr=-0.3812310652021742, short_LR_pf_peak_x_pearsonr=-0.7380151688713461, short_RL_pf_peak_x_pearsonr=-0.41000487651300516)\n",
      "emitChanged(): self.val: 42\n",
      "valueChanged(new_val: 42)\n",
      "an_epoch: EpochTuple(Index=263, P_LR=0.5757786494894341, P_RL=0.4242213505105658, P_Long=0.39698915420413683, P_Short=0.6030108457958632, ripple_idx=263, ripple_start_t=1166.5375812926795, P_Long_LR=0.2285778790696106, P_Long_RL=0.1684112751345262, P_Short_LR=0.3472007704198235, P_Short_RL=0.2558100753760396, most_likely_decoder_index=2, start=1166.5375812926795, stop=1166.6023697395576, label='267', duration=0.06478844687808305, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.2540451309759064, long_RL_pf_peak_x_pearsonr=0.5469299720564883, short_LR_pf_peak_x_pearsonr=-0.08769051167440378, short_RL_pf_peak_x_pearsonr=0.4460091830395171)\n",
      "an_epoch: EpochTuple(Index=263, P_LR=0.5757786494894341, P_RL=0.4242213505105658, P_Long=0.39698915420413683, P_Short=0.6030108457958632, ripple_idx=263, ripple_start_t=1166.5375812926795, P_Long_LR=0.2285778790696106, P_Long_RL=0.1684112751345262, P_Short_LR=0.3472007704198235, P_Short_RL=0.2558100753760396, most_likely_decoder_index=2, start=1166.5375812926795, stop=1166.6023697395576, label='267', duration=0.06478844687808305, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.2540451309759064, long_RL_pf_peak_x_pearsonr=0.5469299720564883, short_LR_pf_peak_x_pearsonr=-0.08769051167440378, short_RL_pf_peak_x_pearsonr=0.4460091830395171)\n",
      "an_epoch: EpochTuple(Index=263, P_LR=0.5757786494894341, P_RL=0.4242213505105658, P_Long=0.39698915420413683, P_Short=0.6030108457958632, ripple_idx=263, ripple_start_t=1166.5375812926795, P_Long_LR=0.2285778790696106, P_Long_RL=0.1684112751345262, P_Short_LR=0.3472007704198235, P_Short_RL=0.2558100753760396, most_likely_decoder_index=2, start=1166.5375812926795, stop=1166.6023697395576, label='267', duration=0.06478844687808305, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.2540451309759064, long_RL_pf_peak_x_pearsonr=0.5469299720564883, short_LR_pf_peak_x_pearsonr=-0.08769051167440378, short_RL_pf_peak_x_pearsonr=0.4460091830395171)\n",
      "an_epoch: EpochTuple(Index=263, P_LR=0.5757786494894341, P_RL=0.4242213505105658, P_Long=0.39698915420413683, P_Short=0.6030108457958632, ripple_idx=263, ripple_start_t=1166.5375812926795, P_Long_LR=0.2285778790696106, P_Long_RL=0.1684112751345262, P_Short_LR=0.3472007704198235, P_Short_RL=0.2558100753760396, most_likely_decoder_index=2, start=1166.5375812926795, stop=1166.6023697395576, label='267', duration=0.06478844687808305, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.2540451309759064, long_RL_pf_peak_x_pearsonr=0.5469299720564883, short_LR_pf_peak_x_pearsonr=-0.08769051167440378, short_RL_pf_peak_x_pearsonr=0.4460091830395171)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 43\n",
      "valueChanged(new_val: 43)\n",
      "an_epoch: EpochTuple(Index=266, P_LR=0.2215146749997331, P_RL=0.7784853250002669, P_Long=0.6602724321002438, P_Short=0.3397275678997561, ripple_idx=266, ripple_start_t=1186.899339827476, P_Long_LR=0.14626003320796885, P_Long_RL=0.5140123988922749, P_Short_LR=0.07525464179176423, P_Short_RL=0.2644729261079919, most_likely_decoder_index=1, start=1186.899339827476, stop=1186.9965685777133, label='271', duration=0.09722875023726374, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=0.8461521649771114, long_RL_pf_peak_x_pearsonr=0.8190304297123981, short_LR_pf_peak_x_pearsonr=0.8434188331229583, short_RL_pf_peak_x_pearsonr=0.7379180278368284)\n",
      "an_epoch: EpochTuple(Index=266, P_LR=0.2215146749997331, P_RL=0.7784853250002669, P_Long=0.6602724321002438, P_Short=0.3397275678997561, ripple_idx=266, ripple_start_t=1186.899339827476, P_Long_LR=0.14626003320796885, P_Long_RL=0.5140123988922749, P_Short_LR=0.07525464179176423, P_Short_RL=0.2644729261079919, most_likely_decoder_index=1, start=1186.899339827476, stop=1186.9965685777133, label='271', duration=0.09722875023726374, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=0.8461521649771114, long_RL_pf_peak_x_pearsonr=0.8190304297123981, short_LR_pf_peak_x_pearsonr=0.8434188331229583, short_RL_pf_peak_x_pearsonr=0.7379180278368284)\n",
      "an_epoch: EpochTuple(Index=266, P_LR=0.2215146749997331, P_RL=0.7784853250002669, P_Long=0.6602724321002438, P_Short=0.3397275678997561, ripple_idx=266, ripple_start_t=1186.899339827476, P_Long_LR=0.14626003320796885, P_Long_RL=0.5140123988922749, P_Short_LR=0.07525464179176423, P_Short_RL=0.2644729261079919, most_likely_decoder_index=1, start=1186.899339827476, stop=1186.9965685777133, label='271', duration=0.09722875023726374, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=0.8461521649771114, long_RL_pf_peak_x_pearsonr=0.8190304297123981, short_LR_pf_peak_x_pearsonr=0.8434188331229583, short_RL_pf_peak_x_pearsonr=0.7379180278368284)\n",
      "an_epoch: EpochTuple(Index=266, P_LR=0.2215146749997331, P_RL=0.7784853250002669, P_Long=0.6602724321002438, P_Short=0.3397275678997561, ripple_idx=266, ripple_start_t=1186.899339827476, P_Long_LR=0.14626003320796885, P_Long_RL=0.5140123988922749, P_Short_LR=0.07525464179176423, P_Short_RL=0.2644729261079919, most_likely_decoder_index=1, start=1186.899339827476, stop=1186.9965685777133, label='271', duration=0.09722875023726374, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=0.8461521649771114, long_RL_pf_peak_x_pearsonr=0.8190304297123981, short_LR_pf_peak_x_pearsonr=0.8434188331229583, short_RL_pf_peak_x_pearsonr=0.7379180278368284)\n",
      "emitChanged(): self.val: 44\n",
      "valueChanged(new_val: 44)\n",
      "an_epoch: EpochTuple(Index=273, P_LR=0.3872547745464171, P_RL=0.6127452254535829, P_Long=0.3721364193000392, P_Short=0.6278635806999608, ripple_idx=273, ripple_start_t=1211.5067230685381, P_Long_LR=0.14411160515654764, P_Long_RL=0.22802481414349157, P_Short_LR=0.2431431693898695, P_Short_RL=0.3847204113100913, most_likely_decoder_index=3, start=1211.5067230685381, stop=1211.6426897189813, label='278', duration=0.1359666504431516, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=0.4882590719219605, long_RL_pf_peak_x_pearsonr=0.3530458747399464, short_LR_pf_peak_x_pearsonr=0.5742651925463647, short_RL_pf_peak_x_pearsonr=0.4036960432226292)\n",
      "an_epoch: EpochTuple(Index=273, P_LR=0.3872547745464171, P_RL=0.6127452254535829, P_Long=0.3721364193000392, P_Short=0.6278635806999608, ripple_idx=273, ripple_start_t=1211.5067230685381, P_Long_LR=0.14411160515654764, P_Long_RL=0.22802481414349157, P_Short_LR=0.2431431693898695, P_Short_RL=0.3847204113100913, most_likely_decoder_index=3, start=1211.5067230685381, stop=1211.6426897189813, label='278', duration=0.1359666504431516, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=0.4882590719219605, long_RL_pf_peak_x_pearsonr=0.3530458747399464, short_LR_pf_peak_x_pearsonr=0.5742651925463647, short_RL_pf_peak_x_pearsonr=0.4036960432226292)\n",
      "an_epoch: EpochTuple(Index=273, P_LR=0.3872547745464171, P_RL=0.6127452254535829, P_Long=0.3721364193000392, P_Short=0.6278635806999608, ripple_idx=273, ripple_start_t=1211.5067230685381, P_Long_LR=0.14411160515654764, P_Long_RL=0.22802481414349157, P_Short_LR=0.2431431693898695, P_Short_RL=0.3847204113100913, most_likely_decoder_index=3, start=1211.5067230685381, stop=1211.6426897189813, label='278', duration=0.1359666504431516, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=0.4882590719219605, long_RL_pf_peak_x_pearsonr=0.3530458747399464, short_LR_pf_peak_x_pearsonr=0.5742651925463647, short_RL_pf_peak_x_pearsonr=0.4036960432226292)\n",
      "an_epoch: EpochTuple(Index=273, P_LR=0.3872547745464171, P_RL=0.6127452254535829, P_Long=0.3721364193000392, P_Short=0.6278635806999608, ripple_idx=273, ripple_start_t=1211.5067230685381, P_Long_LR=0.14411160515654764, P_Long_RL=0.22802481414349157, P_Short_LR=0.2431431693898695, P_Short_RL=0.3847204113100913, most_likely_decoder_index=3, start=1211.5067230685381, stop=1211.6426897189813, label='278', duration=0.1359666504431516, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=0.4882590719219605, long_RL_pf_peak_x_pearsonr=0.3530458747399464, short_LR_pf_peak_x_pearsonr=0.5742651925463647, short_RL_pf_peak_x_pearsonr=0.4036960432226292)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 45\n",
      "valueChanged(new_val: 45)\n",
      "an_epoch: EpochTuple(Index=299, P_LR=0.9948636681433772, P_RL=0.00513633185662293, P_Long=0.3320633515449175, P_Short=0.6679366484550823, ripple_idx=299, ripple_start_t=1262.0877915710444, P_Long_LR=0.33035776397396044, P_Long_RL=0.0017055875709571387, P_Short_LR=0.6645059041694166, P_Short_RL=0.00343074428566579, most_likely_decoder_index=2, start=1262.0877915710444, stop=1262.2197339034174, label='305', duration=0.13194233237300068, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.5584201534219628, long_RL_pf_peak_x_pearsonr=-0.7099539270462011, short_LR_pf_peak_x_pearsonr=-0.5682286772867837, short_RL_pf_peak_x_pearsonr=-0.753941062131517)\n",
      "an_epoch: EpochTuple(Index=299, P_LR=0.9948636681433772, P_RL=0.00513633185662293, P_Long=0.3320633515449175, P_Short=0.6679366484550823, ripple_idx=299, ripple_start_t=1262.0877915710444, P_Long_LR=0.33035776397396044, P_Long_RL=0.0017055875709571387, P_Short_LR=0.6645059041694166, P_Short_RL=0.00343074428566579, most_likely_decoder_index=2, start=1262.0877915710444, stop=1262.2197339034174, label='305', duration=0.13194233237300068, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.5584201534219628, long_RL_pf_peak_x_pearsonr=-0.7099539270462011, short_LR_pf_peak_x_pearsonr=-0.5682286772867837, short_RL_pf_peak_x_pearsonr=-0.753941062131517)\n",
      "an_epoch: EpochTuple(Index=299, P_LR=0.9948636681433772, P_RL=0.00513633185662293, P_Long=0.3320633515449175, P_Short=0.6679366484550823, ripple_idx=299, ripple_start_t=1262.0877915710444, P_Long_LR=0.33035776397396044, P_Long_RL=0.0017055875709571387, P_Short_LR=0.6645059041694166, P_Short_RL=0.00343074428566579, most_likely_decoder_index=2, start=1262.0877915710444, stop=1262.2197339034174, label='305', duration=0.13194233237300068, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.5584201534219628, long_RL_pf_peak_x_pearsonr=-0.7099539270462011, short_LR_pf_peak_x_pearsonr=-0.5682286772867837, short_RL_pf_peak_x_pearsonr=-0.753941062131517)\n",
      "an_epoch: EpochTuple(Index=299, P_LR=0.9948636681433772, P_RL=0.00513633185662293, P_Long=0.3320633515449175, P_Short=0.6679366484550823, ripple_idx=299, ripple_start_t=1262.0877915710444, P_Long_LR=0.33035776397396044, P_Long_RL=0.0017055875709571387, P_Short_LR=0.6645059041694166, P_Short_RL=0.00343074428566579, most_likely_decoder_index=2, start=1262.0877915710444, stop=1262.2197339034174, label='305', duration=0.13194233237300068, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.5584201534219628, long_RL_pf_peak_x_pearsonr=-0.7099539270462011, short_LR_pf_peak_x_pearsonr=-0.5682286772867837, short_RL_pf_peak_x_pearsonr=-0.753941062131517)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 46\n",
      "valueChanged(new_val: 46)\n",
      "an_epoch: EpochTuple(Index=301, P_LR=0.5958866210967353, P_RL=0.4041133789032648, P_Long=0.5463757237912772, P_Short=0.45362427620872275, ripple_idx=301, ripple_start_t=1264.4280706928112, P_Long_LR=0.3255779838992673, P_Long_RL=0.22079773989200996, P_Short_LR=0.27030863719746795, P_Short_RL=0.18331563901125483, most_likely_decoder_index=0, start=1264.4280706928112, stop=1264.6984372743173, label='307', duration=0.2703665815060958, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=-0.4815624979964841, long_RL_pf_peak_x_pearsonr=-0.5104507165902752, short_LR_pf_peak_x_pearsonr=-0.5374150452547625, short_RL_pf_peak_x_pearsonr=-0.309361817833352)\n",
      "an_epoch: EpochTuple(Index=301, P_LR=0.5958866210967353, P_RL=0.4041133789032648, P_Long=0.5463757237912772, P_Short=0.45362427620872275, ripple_idx=301, ripple_start_t=1264.4280706928112, P_Long_LR=0.3255779838992673, P_Long_RL=0.22079773989200996, P_Short_LR=0.27030863719746795, P_Short_RL=0.18331563901125483, most_likely_decoder_index=0, start=1264.4280706928112, stop=1264.6984372743173, label='307', duration=0.2703665815060958, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=-0.4815624979964841, long_RL_pf_peak_x_pearsonr=-0.5104507165902752, short_LR_pf_peak_x_pearsonr=-0.5374150452547625, short_RL_pf_peak_x_pearsonr=-0.309361817833352)\n",
      "an_epoch: EpochTuple(Index=301, P_LR=0.5958866210967353, P_RL=0.4041133789032648, P_Long=0.5463757237912772, P_Short=0.45362427620872275, ripple_idx=301, ripple_start_t=1264.4280706928112, P_Long_LR=0.3255779838992673, P_Long_RL=0.22079773989200996, P_Short_LR=0.27030863719746795, P_Short_RL=0.18331563901125483, most_likely_decoder_index=0, start=1264.4280706928112, stop=1264.6984372743173, label='307', duration=0.2703665815060958, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=-0.4815624979964841, long_RL_pf_peak_x_pearsonr=-0.5104507165902752, short_LR_pf_peak_x_pearsonr=-0.5374150452547625, short_RL_pf_peak_x_pearsonr=-0.309361817833352)\n",
      "an_epoch: EpochTuple(Index=301, P_LR=0.5958866210967353, P_RL=0.4041133789032648, P_Long=0.5463757237912772, P_Short=0.45362427620872275, ripple_idx=301, ripple_start_t=1264.4280706928112, P_Long_LR=0.3255779838992673, P_Long_RL=0.22079773989200996, P_Short_LR=0.27030863719746795, P_Short_RL=0.18331563901125483, most_likely_decoder_index=0, start=1264.4280706928112, stop=1264.6984372743173, label='307', duration=0.2703665815060958, best_decoder_index=2, long_LR_pf_peak_x_pearsonr=-0.4815624979964841, long_RL_pf_peak_x_pearsonr=-0.5104507165902752, short_LR_pf_peak_x_pearsonr=-0.5374150452547625, short_RL_pf_peak_x_pearsonr=-0.309361817833352)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 47\n",
      "valueChanged(new_val: 47)\n",
      "an_epoch: EpochTuple(Index=302, P_LR=0.30510230416494916, P_RL=0.6948976958350509, P_Long=0.4300217518661557, P_Short=0.5699782481338443, ripple_idx=302, ripple_start_t=1267.9177073061, P_Long_LR=0.13120062733541213, P_Long_RL=0.2988211245307436, P_Short_LR=0.17390167682953703, P_Short_RL=0.39607657130430735, most_likely_decoder_index=3, start=1267.9177073061, stop=1268.2349525836762, label='308', duration=0.3172452775761485, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.5943061853828203, long_RL_pf_peak_x_pearsonr=0.7882222061728881, short_LR_pf_peak_x_pearsonr=0.4516228987878735, short_RL_pf_peak_x_pearsonr=0.726952626248035)\n",
      "an_epoch: EpochTuple(Index=302, P_LR=0.30510230416494916, P_RL=0.6948976958350509, P_Long=0.4300217518661557, P_Short=0.5699782481338443, ripple_idx=302, ripple_start_t=1267.9177073061, P_Long_LR=0.13120062733541213, P_Long_RL=0.2988211245307436, P_Short_LR=0.17390167682953703, P_Short_RL=0.39607657130430735, most_likely_decoder_index=3, start=1267.9177073061, stop=1268.2349525836762, label='308', duration=0.3172452775761485, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.5943061853828203, long_RL_pf_peak_x_pearsonr=0.7882222061728881, short_LR_pf_peak_x_pearsonr=0.4516228987878735, short_RL_pf_peak_x_pearsonr=0.726952626248035)\n",
      "an_epoch: EpochTuple(Index=302, P_LR=0.30510230416494916, P_RL=0.6948976958350509, P_Long=0.4300217518661557, P_Short=0.5699782481338443, ripple_idx=302, ripple_start_t=1267.9177073061, P_Long_LR=0.13120062733541213, P_Long_RL=0.2988211245307436, P_Short_LR=0.17390167682953703, P_Short_RL=0.39607657130430735, most_likely_decoder_index=3, start=1267.9177073061, stop=1268.2349525836762, label='308', duration=0.3172452775761485, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.5943061853828203, long_RL_pf_peak_x_pearsonr=0.7882222061728881, short_LR_pf_peak_x_pearsonr=0.4516228987878735, short_RL_pf_peak_x_pearsonr=0.726952626248035)\n",
      "an_epoch: EpochTuple(Index=302, P_LR=0.30510230416494916, P_RL=0.6948976958350509, P_Long=0.4300217518661557, P_Short=0.5699782481338443, ripple_idx=302, ripple_start_t=1267.9177073061, P_Long_LR=0.13120062733541213, P_Long_RL=0.2988211245307436, P_Short_LR=0.17390167682953703, P_Short_RL=0.39607657130430735, most_likely_decoder_index=3, start=1267.9177073061, stop=1268.2349525836762, label='308', duration=0.3172452775761485, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.5943061853828203, long_RL_pf_peak_x_pearsonr=0.7882222061728881, short_LR_pf_peak_x_pearsonr=0.4516228987878735, short_RL_pf_peak_x_pearsonr=0.726952626248035)\n",
      "emitChanged(): self.val: 48\n",
      "valueChanged(new_val: 48)\n",
      "an_epoch: EpochTuple(Index=306, P_LR=0.1376727015427106, P_RL=0.8623272984572895, P_Long=0.3842408723156095, P_Short=0.6157591276843906, ripple_idx=306, ripple_start_t=1284.1807133795228, P_Long_LR=0.05289947893481768, P_Long_RL=0.3313413933807919, P_Short_LR=0.08477322260789294, P_Short_RL=0.5309859050764977, most_likely_decoder_index=3, start=1284.1807133795228, stop=1284.2872810048284, label='312', duration=0.10656762530561537, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.7550527271701002, long_RL_pf_peak_x_pearsonr=0.7808029691717446, short_LR_pf_peak_x_pearsonr=0.7068075810234561, short_RL_pf_peak_x_pearsonr=0.6501409108324907)\n",
      "an_epoch: EpochTuple(Index=306, P_LR=0.1376727015427106, P_RL=0.8623272984572895, P_Long=0.3842408723156095, P_Short=0.6157591276843906, ripple_idx=306, ripple_start_t=1284.1807133795228, P_Long_LR=0.05289947893481768, P_Long_RL=0.3313413933807919, P_Short_LR=0.08477322260789294, P_Short_RL=0.5309859050764977, most_likely_decoder_index=3, start=1284.1807133795228, stop=1284.2872810048284, label='312', duration=0.10656762530561537, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.7550527271701002, long_RL_pf_peak_x_pearsonr=0.7808029691717446, short_LR_pf_peak_x_pearsonr=0.7068075810234561, short_RL_pf_peak_x_pearsonr=0.6501409108324907)\n",
      "an_epoch: EpochTuple(Index=306, P_LR=0.1376727015427106, P_RL=0.8623272984572895, P_Long=0.3842408723156095, P_Short=0.6157591276843906, ripple_idx=306, ripple_start_t=1284.1807133795228, P_Long_LR=0.05289947893481768, P_Long_RL=0.3313413933807919, P_Short_LR=0.08477322260789294, P_Short_RL=0.5309859050764977, most_likely_decoder_index=3, start=1284.1807133795228, stop=1284.2872810048284, label='312', duration=0.10656762530561537, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.7550527271701002, long_RL_pf_peak_x_pearsonr=0.7808029691717446, short_LR_pf_peak_x_pearsonr=0.7068075810234561, short_RL_pf_peak_x_pearsonr=0.6501409108324907)\n",
      "an_epoch: EpochTuple(Index=306, P_LR=0.1376727015427106, P_RL=0.8623272984572895, P_Long=0.3842408723156095, P_Short=0.6157591276843906, ripple_idx=306, ripple_start_t=1284.1807133795228, P_Long_LR=0.05289947893481768, P_Long_RL=0.3313413933807919, P_Short_LR=0.08477322260789294, P_Short_RL=0.5309859050764977, most_likely_decoder_index=3, start=1284.1807133795228, stop=1284.2872810048284, label='312', duration=0.10656762530561537, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.7550527271701002, long_RL_pf_peak_x_pearsonr=0.7808029691717446, short_LR_pf_peak_x_pearsonr=0.7068075810234561, short_RL_pf_peak_x_pearsonr=0.6501409108324907)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 49\n",
      "valueChanged(new_val: 49)\n",
      "an_epoch: EpochTuple(Index=307, P_LR=0.9983187534026681, P_RL=0.0016812465973319152, P_Long=0.3898923802495796, P_Short=0.6101076197504203, ripple_idx=307, ripple_start_t=1284.9596800205763, P_Long_LR=0.38923687501195936, P_Long_RL=0.000655505237620247, P_Short_LR=0.6090818783907086, P_Short_RL=0.0010257413597116682, most_likely_decoder_index=2, start=1284.9596800205763, stop=1285.0243455874734, label='313', duration=0.06466556689701974, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.26893536883702457, long_RL_pf_peak_x_pearsonr=-0.4055300177558012, short_LR_pf_peak_x_pearsonr=-0.2996430698230911, short_RL_pf_peak_x_pearsonr=-0.5418778924294401)\n",
      "an_epoch: EpochTuple(Index=307, P_LR=0.9983187534026681, P_RL=0.0016812465973319152, P_Long=0.3898923802495796, P_Short=0.6101076197504203, ripple_idx=307, ripple_start_t=1284.9596800205763, P_Long_LR=0.38923687501195936, P_Long_RL=0.000655505237620247, P_Short_LR=0.6090818783907086, P_Short_RL=0.0010257413597116682, most_likely_decoder_index=2, start=1284.9596800205763, stop=1285.0243455874734, label='313', duration=0.06466556689701974, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.26893536883702457, long_RL_pf_peak_x_pearsonr=-0.4055300177558012, short_LR_pf_peak_x_pearsonr=-0.2996430698230911, short_RL_pf_peak_x_pearsonr=-0.5418778924294401)\n",
      "an_epoch: EpochTuple(Index=307, P_LR=0.9983187534026681, P_RL=0.0016812465973319152, P_Long=0.3898923802495796, P_Short=0.6101076197504203, ripple_idx=307, ripple_start_t=1284.9596800205763, P_Long_LR=0.38923687501195936, P_Long_RL=0.000655505237620247, P_Short_LR=0.6090818783907086, P_Short_RL=0.0010257413597116682, most_likely_decoder_index=2, start=1284.9596800205763, stop=1285.0243455874734, label='313', duration=0.06466556689701974, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.26893536883702457, long_RL_pf_peak_x_pearsonr=-0.4055300177558012, short_LR_pf_peak_x_pearsonr=-0.2996430698230911, short_RL_pf_peak_x_pearsonr=-0.5418778924294401)\n",
      "an_epoch: EpochTuple(Index=307, P_LR=0.9983187534026681, P_RL=0.0016812465973319152, P_Long=0.3898923802495796, P_Short=0.6101076197504203, ripple_idx=307, ripple_start_t=1284.9596800205763, P_Long_LR=0.38923687501195936, P_Long_RL=0.000655505237620247, P_Short_LR=0.6090818783907086, P_Short_RL=0.0010257413597116682, most_likely_decoder_index=2, start=1284.9596800205763, stop=1285.0243455874734, label='313', duration=0.06466556689701974, best_decoder_index=3, long_LR_pf_peak_x_pearsonr=-0.26893536883702457, long_RL_pf_peak_x_pearsonr=-0.4055300177558012, short_LR_pf_peak_x_pearsonr=-0.2996430698230911, short_RL_pf_peak_x_pearsonr=-0.5418778924294401)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 50\n",
      "valueChanged(new_val: 50)\n",
      "an_epoch: EpochTuple(Index=308, P_LR=0.38055387571093324, P_RL=0.6194461242890668, P_Long=0.5927681896819506, P_Short=0.40723181031804956, ripple_idx=308, ripple_start_t=1286.2167110570008, P_Long_LR=0.22558023198161992, P_Long_RL=0.36718795770033064, P_Short_LR=0.15497364372931338, P_Short_RL=0.2522581665887362, most_likely_decoder_index=1, start=1286.2167110570008, stop=1286.627744446625, label='314', duration=0.4110333896242082, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.06921819630278055, long_RL_pf_peak_x_pearsonr=-0.6249595654258626, short_LR_pf_peak_x_pearsonr=-0.24380700175916917, short_RL_pf_peak_x_pearsonr=-0.5871580268640465)\n",
      "an_epoch: EpochTuple(Index=308, P_LR=0.38055387571093324, P_RL=0.6194461242890668, P_Long=0.5927681896819506, P_Short=0.40723181031804956, ripple_idx=308, ripple_start_t=1286.2167110570008, P_Long_LR=0.22558023198161992, P_Long_RL=0.36718795770033064, P_Short_LR=0.15497364372931338, P_Short_RL=0.2522581665887362, most_likely_decoder_index=1, start=1286.2167110570008, stop=1286.627744446625, label='314', duration=0.4110333896242082, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.06921819630278055, long_RL_pf_peak_x_pearsonr=-0.6249595654258626, short_LR_pf_peak_x_pearsonr=-0.24380700175916917, short_RL_pf_peak_x_pearsonr=-0.5871580268640465)\n",
      "an_epoch: EpochTuple(Index=308, P_LR=0.38055387571093324, P_RL=0.6194461242890668, P_Long=0.5927681896819506, P_Short=0.40723181031804956, ripple_idx=308, ripple_start_t=1286.2167110570008, P_Long_LR=0.22558023198161992, P_Long_RL=0.36718795770033064, P_Short_LR=0.15497364372931338, P_Short_RL=0.2522581665887362, most_likely_decoder_index=1, start=1286.2167110570008, stop=1286.627744446625, label='314', duration=0.4110333896242082, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.06921819630278055, long_RL_pf_peak_x_pearsonr=-0.6249595654258626, short_LR_pf_peak_x_pearsonr=-0.24380700175916917, short_RL_pf_peak_x_pearsonr=-0.5871580268640465)\n",
      "an_epoch: EpochTuple(Index=308, P_LR=0.38055387571093324, P_RL=0.6194461242890668, P_Long=0.5927681896819506, P_Short=0.40723181031804956, ripple_idx=308, ripple_start_t=1286.2167110570008, P_Long_LR=0.22558023198161992, P_Long_RL=0.36718795770033064, P_Short_LR=0.15497364372931338, P_Short_RL=0.2522581665887362, most_likely_decoder_index=1, start=1286.2167110570008, stop=1286.627744446625, label='314', duration=0.4110333896242082, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.06921819630278055, long_RL_pf_peak_x_pearsonr=-0.6249595654258626, short_LR_pf_peak_x_pearsonr=-0.24380700175916917, short_RL_pf_peak_x_pearsonr=-0.5871580268640465)\n",
      "emitChanged(): self.val: 51\n",
      "valueChanged(new_val: 51)\n",
      "an_epoch: EpochTuple(Index=309, P_LR=0.5091668229831126, P_RL=0.4908331770168874, P_Long=0.5600921359986427, P_Short=0.43990786400135723, ripple_idx=309, ripple_start_t=1294.8132071355358, P_Long_LR=0.2851803334642543, P_Long_RL=0.27491180253438835, P_Short_LR=0.22398648951885822, P_Short_RL=0.21592137448249898, most_likely_decoder_index=0, start=1294.8132071355358, stop=1294.903738929308, label='315', duration=0.09053179377224296, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=0.1382768173494706, long_RL_pf_peak_x_pearsonr=-0.03815765736899933, short_LR_pf_peak_x_pearsonr=-0.08589805207278174, short_RL_pf_peak_x_pearsonr=0.008218141898958514)\n",
      "an_epoch: EpochTuple(Index=309, P_LR=0.5091668229831126, P_RL=0.4908331770168874, P_Long=0.5600921359986427, P_Short=0.43990786400135723, ripple_idx=309, ripple_start_t=1294.8132071355358, P_Long_LR=0.2851803334642543, P_Long_RL=0.27491180253438835, P_Short_LR=0.22398648951885822, P_Short_RL=0.21592137448249898, most_likely_decoder_index=0, start=1294.8132071355358, stop=1294.903738929308, label='315', duration=0.09053179377224296, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=0.1382768173494706, long_RL_pf_peak_x_pearsonr=-0.03815765736899933, short_LR_pf_peak_x_pearsonr=-0.08589805207278174, short_RL_pf_peak_x_pearsonr=0.008218141898958514)\n",
      "an_epoch: EpochTuple(Index=309, P_LR=0.5091668229831126, P_RL=0.4908331770168874, P_Long=0.5600921359986427, P_Short=0.43990786400135723, ripple_idx=309, ripple_start_t=1294.8132071355358, P_Long_LR=0.2851803334642543, P_Long_RL=0.27491180253438835, P_Short_LR=0.22398648951885822, P_Short_RL=0.21592137448249898, most_likely_decoder_index=0, start=1294.8132071355358, stop=1294.903738929308, label='315', duration=0.09053179377224296, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=0.1382768173494706, long_RL_pf_peak_x_pearsonr=-0.03815765736899933, short_LR_pf_peak_x_pearsonr=-0.08589805207278174, short_RL_pf_peak_x_pearsonr=0.008218141898958514)\n",
      "an_epoch: EpochTuple(Index=309, P_LR=0.5091668229831126, P_RL=0.4908331770168874, P_Long=0.5600921359986427, P_Short=0.43990786400135723, ripple_idx=309, ripple_start_t=1294.8132071355358, P_Long_LR=0.2851803334642543, P_Long_RL=0.27491180253438835, P_Short_LR=0.22398648951885822, P_Short_RL=0.21592137448249898, most_likely_decoder_index=0, start=1294.8132071355358, stop=1294.903738929308, label='315', duration=0.09053179377224296, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=0.1382768173494706, long_RL_pf_peak_x_pearsonr=-0.03815765736899933, short_LR_pf_peak_x_pearsonr=-0.08589805207278174, short_RL_pf_peak_x_pearsonr=0.008218141898958514)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 52\n",
      "valueChanged(new_val: 52)\n",
      "an_epoch: EpochTuple(Index=311, P_LR=0.9983093597526431, P_RL=0.0016906402473569162, P_Long=0.4371663393784382, P_Short=0.5628336606215616, ripple_idx=311, ripple_start_t=1302.650520242867, P_Long_LR=0.43642724837029534, P_Long_RL=0.0007390910081428803, P_Short_LR=0.5618821113823476, P_Short_RL=0.0009515492392140355, most_likely_decoder_index=2, start=1302.650520242867, stop=1302.8014475256205, label='317', duration=0.1509272827534005, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.4243201467838973, long_RL_pf_peak_x_pearsonr=0.8474354412724381, short_LR_pf_peak_x_pearsonr=0.39242926524179594, short_RL_pf_peak_x_pearsonr=0.7802012691692803)\n",
      "an_epoch: EpochTuple(Index=311, P_LR=0.9983093597526431, P_RL=0.0016906402473569162, P_Long=0.4371663393784382, P_Short=0.5628336606215616, ripple_idx=311, ripple_start_t=1302.650520242867, P_Long_LR=0.43642724837029534, P_Long_RL=0.0007390910081428803, P_Short_LR=0.5618821113823476, P_Short_RL=0.0009515492392140355, most_likely_decoder_index=2, start=1302.650520242867, stop=1302.8014475256205, label='317', duration=0.1509272827534005, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.4243201467838973, long_RL_pf_peak_x_pearsonr=0.8474354412724381, short_LR_pf_peak_x_pearsonr=0.39242926524179594, short_RL_pf_peak_x_pearsonr=0.7802012691692803)\n",
      "an_epoch: EpochTuple(Index=311, P_LR=0.9983093597526431, P_RL=0.0016906402473569162, P_Long=0.4371663393784382, P_Short=0.5628336606215616, ripple_idx=311, ripple_start_t=1302.650520242867, P_Long_LR=0.43642724837029534, P_Long_RL=0.0007390910081428803, P_Short_LR=0.5618821113823476, P_Short_RL=0.0009515492392140355, most_likely_decoder_index=2, start=1302.650520242867, stop=1302.8014475256205, label='317', duration=0.1509272827534005, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.4243201467838973, long_RL_pf_peak_x_pearsonr=0.8474354412724381, short_LR_pf_peak_x_pearsonr=0.39242926524179594, short_RL_pf_peak_x_pearsonr=0.7802012691692803)\n",
      "an_epoch: EpochTuple(Index=311, P_LR=0.9983093597526431, P_RL=0.0016906402473569162, P_Long=0.4371663393784382, P_Short=0.5628336606215616, ripple_idx=311, ripple_start_t=1302.650520242867, P_Long_LR=0.43642724837029534, P_Long_RL=0.0007390910081428803, P_Short_LR=0.5618821113823476, P_Short_RL=0.0009515492392140355, most_likely_decoder_index=2, start=1302.650520242867, stop=1302.8014475256205, label='317', duration=0.1509272827534005, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.4243201467838973, long_RL_pf_peak_x_pearsonr=0.8474354412724381, short_LR_pf_peak_x_pearsonr=0.39242926524179594, short_RL_pf_peak_x_pearsonr=0.7802012691692803)\n",
      "emitChanged(): self.val: 53\n",
      "valueChanged(new_val: 53)\n",
      "an_epoch: EpochTuple(Index=314, P_LR=0.08466142073547835, P_RL=0.9153385792645217, P_Long=0.26406228217719135, P_Short=0.7359377178228086, ripple_idx=314, ripple_start_t=1316.0564141790383, P_Long_LR=0.0223558879717738, P_Long_RL=0.24170639420541756, P_Short_LR=0.06230553276370454, P_Short_RL=0.673632185059104, most_likely_decoder_index=3, start=1316.0564141790383, stop=1316.2703788694926, label='320', duration=0.21396469045430422, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.002046069248603561, long_RL_pf_peak_x_pearsonr=-0.11852297310813223, short_LR_pf_peak_x_pearsonr=0.03012272104346813, short_RL_pf_peak_x_pearsonr=-0.08657365109232462)\n",
      "an_epoch: EpochTuple(Index=314, P_LR=0.08466142073547835, P_RL=0.9153385792645217, P_Long=0.26406228217719135, P_Short=0.7359377178228086, ripple_idx=314, ripple_start_t=1316.0564141790383, P_Long_LR=0.0223558879717738, P_Long_RL=0.24170639420541756, P_Short_LR=0.06230553276370454, P_Short_RL=0.673632185059104, most_likely_decoder_index=3, start=1316.0564141790383, stop=1316.2703788694926, label='320', duration=0.21396469045430422, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.002046069248603561, long_RL_pf_peak_x_pearsonr=-0.11852297310813223, short_LR_pf_peak_x_pearsonr=0.03012272104346813, short_RL_pf_peak_x_pearsonr=-0.08657365109232462)\n",
      "an_epoch: EpochTuple(Index=314, P_LR=0.08466142073547835, P_RL=0.9153385792645217, P_Long=0.26406228217719135, P_Short=0.7359377178228086, ripple_idx=314, ripple_start_t=1316.0564141790383, P_Long_LR=0.0223558879717738, P_Long_RL=0.24170639420541756, P_Short_LR=0.06230553276370454, P_Short_RL=0.673632185059104, most_likely_decoder_index=3, start=1316.0564141790383, stop=1316.2703788694926, label='320', duration=0.21396469045430422, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.002046069248603561, long_RL_pf_peak_x_pearsonr=-0.11852297310813223, short_LR_pf_peak_x_pearsonr=0.03012272104346813, short_RL_pf_peak_x_pearsonr=-0.08657365109232462)\n",
      "an_epoch: EpochTuple(Index=314, P_LR=0.08466142073547835, P_RL=0.9153385792645217, P_Long=0.26406228217719135, P_Short=0.7359377178228086, ripple_idx=314, ripple_start_t=1316.0564141790383, P_Long_LR=0.0223558879717738, P_Long_RL=0.24170639420541756, P_Short_LR=0.06230553276370454, P_Short_RL=0.673632185059104, most_likely_decoder_index=3, start=1316.0564141790383, stop=1316.2703788694926, label='320', duration=0.21396469045430422, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.002046069248603561, long_RL_pf_peak_x_pearsonr=-0.11852297310813223, short_LR_pf_peak_x_pearsonr=0.03012272104346813, short_RL_pf_peak_x_pearsonr=-0.08657365109232462)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 54\n",
      "valueChanged(new_val: 54)\n",
      "an_epoch: EpochTuple(Index=317, P_LR=0.2729503612141755, P_RL=0.7270496387858244, P_Long=0.4767270906151557, P_Short=0.5232729093848443, ripple_idx=317, ripple_start_t=1324.224673677003, P_Long_LR=0.1301228315839897, P_Long_RL=0.34660425903116593, P_Short_LR=0.14282752963018577, P_Short_RL=0.3804453797546585, most_likely_decoder_index=3, start=1324.224673677003, stop=1324.546557672089, label='323', duration=0.32188399508595467, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=-0.7809199575651562, long_RL_pf_peak_x_pearsonr=-0.4218515512566151, short_LR_pf_peak_x_pearsonr=-0.648342507268029, short_RL_pf_peak_x_pearsonr=-0.3981928595335473)\n",
      "an_epoch: EpochTuple(Index=317, P_LR=0.2729503612141755, P_RL=0.7270496387858244, P_Long=0.4767270906151557, P_Short=0.5232729093848443, ripple_idx=317, ripple_start_t=1324.224673677003, P_Long_LR=0.1301228315839897, P_Long_RL=0.34660425903116593, P_Short_LR=0.14282752963018577, P_Short_RL=0.3804453797546585, most_likely_decoder_index=3, start=1324.224673677003, stop=1324.546557672089, label='323', duration=0.32188399508595467, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=-0.7809199575651562, long_RL_pf_peak_x_pearsonr=-0.4218515512566151, short_LR_pf_peak_x_pearsonr=-0.648342507268029, short_RL_pf_peak_x_pearsonr=-0.3981928595335473)\n",
      "an_epoch: EpochTuple(Index=317, P_LR=0.2729503612141755, P_RL=0.7270496387858244, P_Long=0.4767270906151557, P_Short=0.5232729093848443, ripple_idx=317, ripple_start_t=1324.224673677003, P_Long_LR=0.1301228315839897, P_Long_RL=0.34660425903116593, P_Short_LR=0.14282752963018577, P_Short_RL=0.3804453797546585, most_likely_decoder_index=3, start=1324.224673677003, stop=1324.546557672089, label='323', duration=0.32188399508595467, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=-0.7809199575651562, long_RL_pf_peak_x_pearsonr=-0.4218515512566151, short_LR_pf_peak_x_pearsonr=-0.648342507268029, short_RL_pf_peak_x_pearsonr=-0.3981928595335473)\n",
      "an_epoch: EpochTuple(Index=317, P_LR=0.2729503612141755, P_RL=0.7270496387858244, P_Long=0.4767270906151557, P_Short=0.5232729093848443, ripple_idx=317, ripple_start_t=1324.224673677003, P_Long_LR=0.1301228315839897, P_Long_RL=0.34660425903116593, P_Short_LR=0.14282752963018577, P_Short_RL=0.3804453797546585, most_likely_decoder_index=3, start=1324.224673677003, stop=1324.546557672089, label='323', duration=0.32188399508595467, best_decoder_index=0, long_LR_pf_peak_x_pearsonr=-0.7809199575651562, long_RL_pf_peak_x_pearsonr=-0.4218515512566151, short_LR_pf_peak_x_pearsonr=-0.648342507268029, short_RL_pf_peak_x_pearsonr=-0.3981928595335473)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 53\n",
      "valueChanged(new_val: 53)\n",
      "an_epoch: EpochTuple(Index=314, P_LR=0.08466142073547835, P_RL=0.9153385792645217, P_Long=0.26406228217719135, P_Short=0.7359377178228086, ripple_idx=314, ripple_start_t=1316.0564141790383, P_Long_LR=0.0223558879717738, P_Long_RL=0.24170639420541756, P_Short_LR=0.06230553276370454, P_Short_RL=0.673632185059104, most_likely_decoder_index=3, start=1316.0564141790383, stop=1316.2703788694926, label='320', duration=0.21396469045430422, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.002046069248603561, long_RL_pf_peak_x_pearsonr=-0.11852297310813223, short_LR_pf_peak_x_pearsonr=0.03012272104346813, short_RL_pf_peak_x_pearsonr=-0.08657365109232462)\n",
      "an_epoch: EpochTuple(Index=314, P_LR=0.08466142073547835, P_RL=0.9153385792645217, P_Long=0.26406228217719135, P_Short=0.7359377178228086, ripple_idx=314, ripple_start_t=1316.0564141790383, P_Long_LR=0.0223558879717738, P_Long_RL=0.24170639420541756, P_Short_LR=0.06230553276370454, P_Short_RL=0.673632185059104, most_likely_decoder_index=3, start=1316.0564141790383, stop=1316.2703788694926, label='320', duration=0.21396469045430422, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.002046069248603561, long_RL_pf_peak_x_pearsonr=-0.11852297310813223, short_LR_pf_peak_x_pearsonr=0.03012272104346813, short_RL_pf_peak_x_pearsonr=-0.08657365109232462)\n",
      "an_epoch: EpochTuple(Index=314, P_LR=0.08466142073547835, P_RL=0.9153385792645217, P_Long=0.26406228217719135, P_Short=0.7359377178228086, ripple_idx=314, ripple_start_t=1316.0564141790383, P_Long_LR=0.0223558879717738, P_Long_RL=0.24170639420541756, P_Short_LR=0.06230553276370454, P_Short_RL=0.673632185059104, most_likely_decoder_index=3, start=1316.0564141790383, stop=1316.2703788694926, label='320', duration=0.21396469045430422, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.002046069248603561, long_RL_pf_peak_x_pearsonr=-0.11852297310813223, short_LR_pf_peak_x_pearsonr=0.03012272104346813, short_RL_pf_peak_x_pearsonr=-0.08657365109232462)\n",
      "an_epoch: EpochTuple(Index=314, P_LR=0.08466142073547835, P_RL=0.9153385792645217, P_Long=0.26406228217719135, P_Short=0.7359377178228086, ripple_idx=314, ripple_start_t=1316.0564141790383, P_Long_LR=0.0223558879717738, P_Long_RL=0.24170639420541756, P_Short_LR=0.06230553276370454, P_Short_RL=0.673632185059104, most_likely_decoder_index=3, start=1316.0564141790383, stop=1316.2703788694926, label='320', duration=0.21396469045430422, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=-0.002046069248603561, long_RL_pf_peak_x_pearsonr=-0.11852297310813223, short_LR_pf_peak_x_pearsonr=0.03012272104346813, short_RL_pf_peak_x_pearsonr=-0.08657365109232462)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emitChanged(): self.val: 52\n",
      "valueChanged(new_val: 52)\n",
      "an_epoch: EpochTuple(Index=311, P_LR=0.9983093597526431, P_RL=0.0016906402473569162, P_Long=0.4371663393784382, P_Short=0.5628336606215616, ripple_idx=311, ripple_start_t=1302.650520242867, P_Long_LR=0.43642724837029534, P_Long_RL=0.0007390910081428803, P_Short_LR=0.5618821113823476, P_Short_RL=0.0009515492392140355, most_likely_decoder_index=2, start=1302.650520242867, stop=1302.8014475256205, label='317', duration=0.1509272827534005, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.4243201467838973, long_RL_pf_peak_x_pearsonr=0.8474354412724381, short_LR_pf_peak_x_pearsonr=0.39242926524179594, short_RL_pf_peak_x_pearsonr=0.7802012691692803)\n",
      "an_epoch: EpochTuple(Index=311, P_LR=0.9983093597526431, P_RL=0.0016906402473569162, P_Long=0.4371663393784382, P_Short=0.5628336606215616, ripple_idx=311, ripple_start_t=1302.650520242867, P_Long_LR=0.43642724837029534, P_Long_RL=0.0007390910081428803, P_Short_LR=0.5618821113823476, P_Short_RL=0.0009515492392140355, most_likely_decoder_index=2, start=1302.650520242867, stop=1302.8014475256205, label='317', duration=0.1509272827534005, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.4243201467838973, long_RL_pf_peak_x_pearsonr=0.8474354412724381, short_LR_pf_peak_x_pearsonr=0.39242926524179594, short_RL_pf_peak_x_pearsonr=0.7802012691692803)\n",
      "an_epoch: EpochTuple(Index=311, P_LR=0.9983093597526431, P_RL=0.0016906402473569162, P_Long=0.4371663393784382, P_Short=0.5628336606215616, ripple_idx=311, ripple_start_t=1302.650520242867, P_Long_LR=0.43642724837029534, P_Long_RL=0.0007390910081428803, P_Short_LR=0.5618821113823476, P_Short_RL=0.0009515492392140355, most_likely_decoder_index=2, start=1302.650520242867, stop=1302.8014475256205, label='317', duration=0.1509272827534005, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.4243201467838973, long_RL_pf_peak_x_pearsonr=0.8474354412724381, short_LR_pf_peak_x_pearsonr=0.39242926524179594, short_RL_pf_peak_x_pearsonr=0.7802012691692803)\n",
      "an_epoch: EpochTuple(Index=311, P_LR=0.9983093597526431, P_RL=0.0016906402473569162, P_Long=0.4371663393784382, P_Short=0.5628336606215616, ripple_idx=311, ripple_start_t=1302.650520242867, P_Long_LR=0.43642724837029534, P_Long_RL=0.0007390910081428803, P_Short_LR=0.5618821113823476, P_Short_RL=0.0009515492392140355, most_likely_decoder_index=2, start=1302.650520242867, stop=1302.8014475256205, label='317', duration=0.1509272827534005, best_decoder_index=1, long_LR_pf_peak_x_pearsonr=0.4243201467838973, long_RL_pf_peak_x_pearsonr=0.8474354412724381, short_LR_pf_peak_x_pearsonr=0.39242926524179594, short_RL_pf_peak_x_pearsonr=0.7802012691692803)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 359, in valueChanged\n",
      "    _obj.on_update_epoch_IDX(int(new_val))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 554, in on_update_epoch_IDX\n",
      "    self.update_plot_titles_with_stats(an_epoch_idx)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 1217, in update_plot_titles_with_stats\n",
      "    curr_new_results_df = self.active_epoch_result_df\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/PyQtPlot/Widgets/ContainerBased/RankOrderRastersDebugger.py\", line 188, in active_epoch_result_df\n",
      "    assert np.shape(self.combined_epoch_stats_df)[0] == np.shape(self.active_epochs_df)[0], f\"np.shape(self.combined_epoch_stats_df)[0]: {np.shape(self.combined_epoch_stats_df)[0]} != np.shape(self.active_epochs_df)[0]: {np.shape(self.active_epochs_df)[0]}\"\n",
      "AssertionError: np.shape(self.combined_epoch_stats_df)[0]: 247 != np.shape(self.active_epochs_df)[0]: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecodedEpochSlicesPaginatedFigureController.on_selected_epochs_changed(...)\n",
      "could not find the clicked ax: None in the list of axes: [<Axes: ylabel='epoch[48]\\n1284.18'> <Axes: ylabel='epoch[49]\\n1284.96'> <Axes: ylabel='epoch[50]\\n1286.22'> <Axes: ylabel='epoch[51]\\n1294.81'> <Axes: ylabel='epoch[52]\\n1302.65'> <Axes: ylabel='epoch[53]\\n1316.06'> <Axes: ylabel='epoch[54]\\n1324.22'> <Axes: ylabel='epoch[55]\\n1331.71'>]\n",
      "\tselection_indicies: []\n"
     ]
    }
   ],
   "source": [
    "RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "_out_ripple_rasters = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, deepcopy(filtered_ripple_simple_pf_pearson_merged_df), track_templates, rank_order_results, RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict)\n",
    "_out_ripple_rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab99127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075a270c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd064d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_directional_template_debugger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba36573",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_template_debugger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880dce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_track_template_pf1Ds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c9542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6aafef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_display_directional_laps_overview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f5b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_display_directional_merged_pfs'\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pfs', plot_all_directions=False, plot_long_directional=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda2d180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4b6633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59dc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting on 2024-02-06 to display the LR/RL directions instead of the All/Long/Short pfs:\n",
    "def _display_directional_merged_pfs(owning_pipeline_reference, global_computation_results, computation_results, active_configs, include_includelist=None, save_figure=True, included_any_context_neuron_ids=None,\n",
    "\t\t\t\t\t\t\t\t\tplot_all_directions=True, plot_long_directional=False, plot_short_directional=False, **kwargs):\n",
    "\t\"\"\" Plots the merged pseduo-2D pfs/ratemaps. Plots: All-Directions, Long-Directional, Short-Directional in seperate windows. \n",
    "\t\n",
    "\tHistory: this is the Post 2022-10-22 display_all_pf_2D_pyqtgraph_binned_image_rendering-based method:\n",
    "\t\"\"\"\n",
    "\tfrom pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array, display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "\tfrom pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow \n",
    "\t\n",
    "\n",
    "\tdefer_render = kwargs.pop('defer_render', False)\n",
    "\tdirectional_merged_decoders_result: DirectionalMergedDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\tactive_merged_pf_plots_data_dict = {} #empty dict\n",
    "\t\n",
    "\tif plot_all_directions:\n",
    "\t\tactive_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='All-Directions', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.all_directional_pf1D_Decoder.pf # all-directions\n",
    "\tif plot_long_directional:\n",
    "\t\tactive_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Long-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.long_directional_pf1D_Decoder.pf # Long-only\n",
    "\tif plot_short_directional:\n",
    "\t\tactive_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Short-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.short_directional_pf1D_Decoder.pf # Short-only\n",
    "\n",
    "\tout_plots_dict = {}\n",
    "\t\n",
    "\tfor active_context, active_pf_2D in active_merged_pf_plots_data_dict.items():\n",
    "\t\t# figure_format_config = {} # empty dict for config\n",
    "\t\tfigure_format_config = {'scrollability_mode': LayoutScrollability.NON_SCROLLABLE} # kwargs # kwargs as default figure_format_config\n",
    "\t\tout_all_pf_2D_pyqtgraph_binned_image_fig: BasicBinnedImageRenderingWindow  = display_all_pf_2D_pyqtgraph_binned_image_rendering(active_pf_2D, figure_format_config) # output is BasicBinnedImageRenderingWindow\n",
    "\t\n",
    "\t\t# Set the window title from the context\n",
    "\t\tout_all_pf_2D_pyqtgraph_binned_image_fig.setWindowTitle(f'{active_context.get_description()}')\n",
    "\t\tout_plots_dict[active_context] = out_all_pf_2D_pyqtgraph_binned_image_fig\n",
    "\n",
    "\t\t# Tries to update the display of the item:\n",
    "\t\tnames_list = [v for v in list(out_all_pf_2D_pyqtgraph_binned_image_fig.plots.keys()) if v not in ('name', 'context')]\n",
    "\t\tfor a_name in names_list:\n",
    "\t\t\t# Adjust the size of the text for the item by passing formatted text\n",
    "\t\t\ta_plot: pg.PlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem # PlotItem \n",
    "\t\t\t# no clue why 2 is a good value for this...\n",
    "\t\t\ta_plot.titleLabel.setMaximumHeight(2)\n",
    "\t\t\ta_plot.layout.setRowFixedHeight(0, 2)\n",
    "\t\t\t\n",
    "\n",
    "\t\tif not defer_render:\n",
    "\t\t\tout_all_pf_2D_pyqtgraph_binned_image_fig.show()\n",
    "\n",
    "\treturn out_plots_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfcc19a",
   "metadata": {},
   "source": [
    "# 2023-12-18 - Simpily detect bimodal cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc55f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.peak_location_representing import ContinuousPeakLocationRepresentingMixin\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from scipy.signal import find_peaks\n",
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# curr_active_pipeline.display('_display_1d_placefields', 'maze1_any', sortby=None)\n",
    "\n",
    "# active_ratemap = deepcopy(long_pf1D.ratemap)\n",
    "active_ratemap: Ratemap = deepcopy(long_LR_pf1D.ratemap)\n",
    "peaks_dict, aclu_n_peaks_dict, peaks_results_df = active_ratemap.compute_tuning_curve_modes(height=0.2, width=None)\n",
    "\n",
    "\n",
    "included_columns = ['pos', 'peak_heights'] # the columns of interest that you want in the final dataframe.\n",
    "included_columns_renamed = dict(zip(included_columns, ['peak', 'peak_height']))\n",
    "decoder_peaks_results_dfs = [a_decoder.pf.ratemap.get_tuning_curve_peak_df(height=0.2, width=None) for a_decoder in (track_templates.long_LR_decoder, track_templates.long_RL_decoder, track_templates.short_LR_decoder, track_templates.short_RL_decoder)]\n",
    "prefix_names = [f'{a_decoder_name}_' for a_decoder_name in track_templates.get_decoder_names()]\n",
    "all_included_columns = ['aclu', 'series_idx', 'subpeak_idx'] + included_columns # Used to filter out the unwanted columns from the output\n",
    "\n",
    "# [['aclu', 'series_idx', 'subpeak_idx', 'pos']]\n",
    "\n",
    "# rename_list_fn = lambda a_prefix: {'pos': f\"{a_prefix}pos\"}\n",
    "rename_list_fn = lambda a_prefix: {a_col_name:f\"{a_prefix}{included_columns_renamed[a_col_name]}\" for a_col_name in included_columns}\n",
    "\n",
    "# column_names = [f'{a_decoder_name}_peak' for a_decoder_name in track_templates.get_decoder_names()]\n",
    "\n",
    "# dataFrames = decoder_peaks_results_dfs\n",
    "# names = self.get_decoder_names()\n",
    "\n",
    "# rename 'pos' column in each dataframe and then reduce to perform cumulative outer merge\n",
    "result_df = decoder_peaks_results_dfs[0][all_included_columns].rename(columns=rename_list_fn(prefix_names[0]))\n",
    "for df, a_prefix in zip(decoder_peaks_results_dfs[1:], prefix_names[1:]):\n",
    "    result_df = pd.merge(result_df, df[all_included_columns].rename(columns=rename_list_fn(a_prefix)), on=['aclu', 'series_idx', 'subpeak_idx'], how='outer')\n",
    "\n",
    "# result = reorder_columns(result, column_name_desired_index_dict=dict(zip(['Long_LR_evidence', 'Long_RL_evidence', 'Short_LR_evidence', 'Short_RL_evidence'], np.arange(4)+4)))\n",
    "\n",
    "## Move the \"height\" columns to the end\n",
    "# list(filter(lambda column: column.endswith('_peak_heights'), result.columns))\n",
    "# result_df = reorder_columns(result_df, column_name_desired_index_dict=dict(zip(list(filter(lambda column: column.endswith('_peak_heights'), result_df.columns)), np.arange(len(result_df.columns)-4, len(result_df.columns)))))\n",
    "# result_df\n",
    "\n",
    "# print(list(result.columns))\n",
    "\n",
    "## Move the \"height\" columns to the end\n",
    "result_df: pd.DataFrame = reorder_columns_relative(result_df, column_names=list(filter(lambda column: column.endswith('_peak_heights'), result_df.columns)), relative_mode='end').sort_values(['aclu', 'series_idx', 'subpeak_idx']).reset_index(drop=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d4af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually Excluded endcap aclus:\n",
    "IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43')\n",
    "excluded_endcap_aclus: NDArray = np.array(list(set([40, 60, 85, 102, 52, 6] + [83, 60, 52, 102, 40] + [59, 67, 95, 28, 101] + [14, 15, 87, 71] + [43, 84, 87, 19, 33, 51, 53])))\n",
    "excluded_endcap_aclus\n",
    "\n",
    "\n",
    "np.array([  6,  14,  15,  19,  28,  33,  40,  43,  51,  52,  53,  59,  60,  67,  71,  83,  84,  85,  87,  95, 101, 102])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ccd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_results_df = track_templates.get_decoders_aclu_peak_location_df().sort_values(['aclu', 'series_idx', 'subpeak_idx']).reset_index(drop=True) ## Does not seem to merge entries as I would expect via intution. It keeps LR/RL peaks distinct and leaves pd.NA values for the entries.\n",
    "peaks_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40377267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d377cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aclu_n_peaks_dict: Dict = peaks_results_df.groupby(['aclu']).agg(subpeak_idx_count=('subpeak_idx', 'count')).reset_index().set_index('aclu').to_dict()['subpeak_idx_count'] # number of peaks (\"models\" for each aclu)\n",
    "aclu_n_peaks_dict\n",
    "\n",
    "# peaks_results_df = peaks_results_df.groupby(['aclu']).agg(subpeak_idx_count=('subpeak_idx', 'count')).reset_index()\n",
    "\n",
    "# peaks_results_df[peaks_results_df.aclu == 5]\n",
    "# peaks_results_df.aclu.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeccfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_ratemap.n_neurons\n",
    "curr_active_pipeline.display('_display_1d_placefields', 'maze1_any', included_unit_neuron_IDs=active_ratemap.neuron_ids, sortby=np.arange(active_ratemap.n_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec60d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aclu_n_peaks_dict\n",
    "unimodal_only_aclus = np.array(list(unimodal_peaks_dict.keys()))\n",
    "unimodal_only_aclus\n",
    "curr_active_pipeline.display('_display_1d_placefields', 'maze1_any', included_unit_neuron_IDs=unimodal_only_aclus, sortby=np.arange(active_ratemap.n_neurons))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aebbf1",
   "metadata": {},
   "source": [
    "# 🟪 2024-02-08 Directional Marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_directional_ripple_filter_epochs_decoder_result_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da36235",
   "metadata": {},
   "source": [
    "### 2024-02-09 - Recover Radon Transform info to confirm the Pseudo2D decoder-based detection of long/short replay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d97b0fb",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "source": [
    "#### Main Custom Decoder Computation:\n",
    "2024-02-15 - Appears to be best to refactor to the TrackTemplates object. __________________________________________ #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6453cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_compute_custom_epoch_decoding\n",
    "\n",
    "decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict = _perform_compute_custom_epoch_decoding(curr_active_pipeline, directional_merged_decoders_result, track_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d06ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recompute the epoch scores/metrics such as radon transform and wcorr:\n",
    "(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict), merged_df_outputs_tuple, raw_dict_outputs_tuple = _compute_all_df_score_metrics(directional_merged_decoders_result, track_templates, decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict, spikes_df=deepcopy(curr_active_pipeline.sess.spikes_df),\n",
    "                                                                                                                                                                                     should_skip_radon_transform=True)\n",
    "laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df, laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df = merged_df_outputs_tuple\n",
    "decoder_laps_radon_transform_df_dict, decoder_ripple_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict, decoder_ripple_radon_transform_extras_dict, decoder_laps_weighted_corr_df_dict, decoder_ripple_weighted_corr_df_dict = raw_dict_outputs_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8399efd5",
   "metadata": {},
   "source": [
    "##  2024-02-13 - Saving manual decodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc95ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "\n",
    "## Needed for saving either way:\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "pos_bin_size = _recover_position_bin_size(track_templates.get_decoders()[0]) # 3.793023081021702\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "\n",
    "\n",
    "override_output_parent_path = None\n",
    "out_filename_str: str = '-'.join([DAY_DATE_TO_USE]) #SaveStringGenerator.generate_save_suffix(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values, day_date=DAY_DATE_TO_USE)\n",
    "output_parent_path: Path = (override_output_parent_path or curr_active_pipeline.get_output_path()).resolve()\n",
    "try:\n",
    "\toutput_path = output_parent_path.joinpath(f'{out_filename_str}_CustomDecodingResults.pkl').resolve()\n",
    "\tprint(f'saving to \"{output_path}\"...')\n",
    "\tsaveData(output_path, ({'pos_bin_size': pos_bin_size, 'ripple_decoding_time_bin_size':ripple_decoding_time_bin_size, 'laps_decoding_time_bin_size':laps_decoding_time_bin_size, 'decoder_laps_filter_epochs_decoder_result_dict':decoder_laps_filter_epochs_decoder_result_dict,\n",
    "\t\t\t\t\t\t  'decoder_ripple_filter_epochs_decoder_result_dict':decoder_ripple_filter_epochs_decoder_result_dict, 'decoder_laps_radon_transform_df_dict':decoder_laps_radon_transform_df_dict, 'decoder_ripple_radon_transform_df_dict':decoder_ripple_radon_transform_df_dict,\n",
    "\t\t\t\t\t\t  'decoder_laps_radon_transform_extras_dict': decoder_laps_radon_transform_extras_dict, 'decoder_ripple_radon_transform_extras_dict': decoder_ripple_radon_transform_extras_dict,\n",
    "\t\t\t\t\t\t  'laps_weighted_corr_merged_df': laps_weighted_corr_merged_df, 'ripple_weighted_corr_merged_df': ripple_weighted_corr_merged_df, 'decoder_laps_weighted_corr_df_dict': decoder_laps_weighted_corr_df_dict, 'decoder_ripple_weighted_corr_df_dict': decoder_ripple_weighted_corr_df_dict,\n",
    "                          'laps_simple_pf_pearson_merged_df': laps_simple_pf_pearson_merged_df, 'ripple_simple_pf_pearson_merged_df': ripple_simple_pf_pearson_merged_df,\n",
    "                          }))\n",
    "except BaseException as e:\n",
    "\tprint(f'issue saving \"{output_path}\": error: {e}')\n",
    "\tpass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cf4605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import loadData\n",
    "\n",
    "# load_path = Path(r\"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-02-13_CustomDecodingResults.pkl\").resolve()\n",
    "# load_path = Path(r\"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-02-13_9pm_CustomDecodingResults.pkl\").resolve()\n",
    "# load_path = Path(r\"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-02-14_CustomDecodingResults.pkl\").resolve()\n",
    "# load_path = Path(r\"W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\2024-02-15-8pm_CustomDecodingResults.pkl\").resolve()\n",
    "# load_path = Path(r\"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-02-16_CustomDecodingResults.pkl\").resolve()\n",
    "load_path = Path(\"/media/halechr/MAX/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-02-16_CustomDecodingResults.pkl\").resolve()\n",
    "\n",
    "assert load_path.exists()\n",
    "loaded_dict = loadData(load_path, debug_print=False)\n",
    "## UNPACK HERE:\n",
    "pos_bin_size: float = loaded_dict['pos_bin_size']\n",
    "ripple_decoding_time_bin_size = loaded_dict['ripple_decoding_time_bin_size']\n",
    "laps_decoding_time_bin_size = loaded_dict['laps_decoding_time_bin_size']\n",
    "decoder_laps_filter_epochs_decoder_result_dict = loaded_dict['decoder_laps_filter_epochs_decoder_result_dict']\n",
    "decoder_ripple_filter_epochs_decoder_result_dict = loaded_dict['decoder_ripple_filter_epochs_decoder_result_dict']\n",
    "decoder_laps_radon_transform_df_dict = loaded_dict['decoder_laps_radon_transform_df_dict']\n",
    "decoder_ripple_radon_transform_df_dict = loaded_dict['decoder_ripple_radon_transform_df_dict']\n",
    "## New 2024-02-14 - Noon:\n",
    "decoder_laps_radon_transform_extras_dict = loaded_dict['decoder_laps_radon_transform_extras_dict']\n",
    "decoder_ripple_radon_transform_extras_dict = loaded_dict['decoder_ripple_radon_transform_extras_dict']\n",
    "## New 2024-02-16 _ Weighted Corr\n",
    "laps_weighted_corr_merged_df = loaded_dict['laps_weighted_corr_merged_df']\n",
    "ripple_weighted_corr_merged_df = loaded_dict['ripple_weighted_corr_merged_df']\n",
    "decoder_laps_weighted_corr_df_dict = loaded_dict['decoder_laps_weighted_corr_df_dict']\n",
    "decoder_ripple_weighted_corr_df_dict = loaded_dict['decoder_ripple_weighted_corr_df_dict']\n",
    "\n",
    "laps_simple_pf_pearson_merged_df = loaded_dict['laps_simple_pf_pearson_merged_df']\n",
    "ripple_simple_pf_pearson_merged_df = loaded_dict['ripple_simple_pf_pearson_merged_df']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb8161a",
   "metadata": {},
   "source": [
    "# 🖼️🎨 2024-02-08 - `PhoPaginatedMultiDecoderDecodedEpochsWindow` - Plot Ripple Metrics like Radon Transforms, WCorr, Simple Pearson, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d9fda21",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhoDockAreaContainingWindow.GlobalConnectionManagerAccessingMixin_on_setup()\n",
      "PhoDockAreaContainingWindow.try_register_any_control_widgets()\n",
      "\tflat_widgets_list contains 0 items\n",
      "no radon transform columns present in the the active_filter_epochs_df. Skipping.\n",
      "no radon transform columns present in the the active_filter_epochs_df. Skipping.\n",
      "no radon transform columns present in the the active_filter_epochs_df. Skipping.\n",
      "no radon transform columns present in the the active_filter_epochs_df. Skipping.\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "# pagination_controller_dict =  PhoPaginatedMultiDecoderDecodedEpochsWindow._subfn_prepare_plot_multi_decoders_stacked_epoch_slices(curr_active_pipeline, track_templates, decoder_decoded_epochs_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epochs_name='laps', included_epoch_indicies=None, defer_render=False, save_figure=False)\n",
    "pagination_controller_dict =  PhoPaginatedMultiDecoderDecodedEpochsWindow._subfn_prepare_plot_multi_decoders_stacked_epoch_slices(curr_active_pipeline, track_templates, decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epochs_name='ripple', included_epoch_indicies=None, defer_render=False, save_figure=False)\n",
    "app, root_dockAreaWindow = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_pagination_controller_dict(pagination_controller_dict) # Combine to a single figure\n",
    "root_dockAreaWindow.add_data_overlays(track_templates, decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "# filtered_ripple_simple_pf_pearson_merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8889b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d86c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(decoder_laps_filter_epochs_decoder_result_dict.keys())\n",
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555deda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the figure from the axes:\n",
    "a_fig = ax.get_figure()\n",
    "a_fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0e35ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_controlling_pagination_controller = root_dockAreaWindow.contents.pagination_controllers['long_LR'] # DecodedEpochSlicesPaginatedFigureController\n",
    "a_pagination_controller_figure_widget = paginator_controller_widget = a_controlling_pagination_controller.ui.mw # MatplotlibTimeSynchronizedWidget\n",
    "paginator_controller_widget = a_controlling_pagination_controller.ui.mw.ui.paginator_controller_widget # PaginationControlWidget\n",
    "# paginator_controller_widget\n",
    "a_pagination_controller_figure_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4237afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r\"\"\"\n",
    "DecodedEpochSlicesPaginatedFigureController.on_selected_epochs_changed(...)\n",
    "current_page_idx = 0, found_data_index =array([[0, 1, 2, 3, 4, 5, 6, 7]])\n",
    "Traceback (most recent call last):\n",
    "  File \"k:\\FastSwap\\AppData\\VSCode\\yellow\\.venv_yellow\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
    "    func(*args, **kwargs)\n",
    "  File \"C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Pho2D\\stacked_epoch_slices.py\", line 642, in on_selected_epochs_changed\n",
    "    self.on_click(event=event)\n",
    "  File \"C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Pho2D\\stacked_epoch_slices.py\", line 803, in on_click\n",
    "    self.params.is_selected[found_data_index] = not self.params.is_selected.get(found_data_index, False) # if never set before, assume that it's not selected\n",
    "TypeError: unhashable type: 'numpy.ndarray'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def on_click(event):\n",
    "    \"\"\" called when an axis is clicked to toggle the selection.\n",
    "    Captures: a_controlling_pagination_controller\n",
    "    \"\"\"\n",
    "    if a_controlling_pagination_controller.params.debug_print:\n",
    "        print(f'DecodedEpochSlicesPaginatedFigureController.on_click(...) OVERRIDE:')\n",
    "    # Get the clicked Axes object\n",
    "    ax = event.inaxes\n",
    "    # Find the axes\n",
    "    found_index = safe_find_index_in_list(a_controlling_pagination_controller.plots.axs, ax) # find the index on the page of the ax that was clicked\n",
    "    # print(f'{found_index = }')\n",
    "    current_page_idx = a_controlling_pagination_controller.current_page_idx\n",
    "    curr_page_data_indicies = a_controlling_pagination_controller.paginator.get_page_data(page_idx=current_page_idx)[0] # the [0] returns only the indicies and not the data\n",
    "    found_data_index = curr_page_data_indicies[found_index]\n",
    "    print(f'{current_page_idx = }, {found_data_index =}') # array([[0, 1, 2, 3, 4, 5, 6, 7]])\n",
    "    # Toggle the selection status of the clicked Axes\n",
    "    a_controlling_pagination_controller.params.is_selected[found_data_index] = not a_controlling_pagination_controller.params.is_selected.get(found_data_index, False) # if never set before, assume that it's not selected\n",
    "    ## Update visual apperance of axis:\n",
    "    a_controlling_pagination_controller.perform_update_ax_selected_state(ax=ax, is_selected=a_controlling_pagination_controller.params.is_selected[found_data_index])\n",
    "\n",
    "\n",
    "# ax = event.inaxes\n",
    "# Find the axes\n",
    "# found_index = safe_find_index_in_list(a_controlling_pagination_controller.plots.axs, ax) # find the index on the page of the ax that was clicked\n",
    "\n",
    "current_page_idx = a_controlling_pagination_controller.current_page_idx\n",
    "# current_page_idx = 0\n",
    "print(f'current_page_idx: {current_page_idx}')\n",
    "curr_page_data_indicies, included_page_data_items = a_controlling_pagination_controller.paginator.get_page_data(page_idx=current_page_idx)\n",
    "curr_page_data_indicies\n",
    "\n",
    "# len(a_controlling_pagination_controller.plots.axs)\n",
    "ax = a_controlling_pagination_controller.plots.axs[3]\n",
    "found_index = safe_find_index_in_list(a_controlling_pagination_controller.plots.axs, ax) # find the index on the page of the ax that was clicked\n",
    "print(f'found_index: {found_index}')\n",
    "if found_index is not None:\n",
    "    found_data_index = curr_page_data_indicies[found_index]\n",
    "    print(f'{current_page_idx = }, {found_data_index =}') # array([[0, 1, 2, 3, 4, 5, 6, 7]])\n",
    "\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b08ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = a_controlling_pagination_controller.plots.axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73526ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "from neuropy.utils.matplotlib_helpers import add_selection_patch\n",
    "\n",
    "# current_page_idx = self.current_page_idx\n",
    "# curr_page_data_indicies = self.paginator.get_page_data(page_idx=current_page_idx)[0] # the [0] returns only the indicies and not the data\n",
    "\n",
    "if not a_controlling_pagination_controller.plots.has_attr('selection_rectangles_dict'):\n",
    "    ## Create the dict if needed and it doesn't exist:\n",
    "    a_controlling_pagination_controller.plots.selection_rectangles_dict = {} # empty dict to start\n",
    "\n",
    "## INPUTS: curr_page_data_indicies, axs\n",
    "assert len(axs) == len(curr_page_data_indicies), f\"len(plots.axs): {len(axs)}, len(curr_page_data_indicies): {len(curr_page_data_indicies)}\"\n",
    "for ax, found_data_idx in zip(axs, list(curr_page_data_indicies)): # TODO: might fail for the last page?\n",
    "    ## First get the ax\n",
    "    a_selection_rect = a_controlling_pagination_controller.plots.selection_rectangles_dict.get(ax, None)\n",
    "    if a_selection_rect is None:\n",
    "        # create a new one\n",
    "        print(f'need a new selection rect.')\n",
    "        a_selection_rect = add_selection_patch(ax, selection_color='green', alpha=0.6, zorder=-1, defer_draw=True)\n",
    "        a_controlling_pagination_controller.plots.selection_rectangles_dict[ax] = a_selection_rect ## add to dict\n",
    "\n",
    "    is_selected = a_controlling_pagination_controller.params.is_selected.get(found_data_idx, False)\n",
    "    a_selection_rect.set_visible(is_selected)\n",
    "\n",
    "    a_controlling_pagination_controller.perform_update_ax_selected_state(ax=ax, is_selected=is_selected)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550263ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_figure().canvas.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04143f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_rectangles_dict = a_controlling_pagination_controller.plots.get('selection_rectangles_dict', None)\n",
    "selection_rectangles_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ebee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_pos.x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rectangle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a2276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_controlling_pagination_controller.plots.fig.canvas.draw_idle()\n",
    "# a_controlling_pagination_controller.plots.fig.canvas.draw()\n",
    "# paginator_controller_widget.update()\n",
    "a_pagination_controller_figure_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eeedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_controlling_pagination_controller.params.is_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc424c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator_controller_widget.go_to_page(3)\n",
    "# paginator_controller_widget.jump_to_page(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f7aaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_controlling_pagination_controller.ui.mw.ui.paginator_controller_widget.jump_to_page\n",
    "\n",
    "new_obj.plots_data.paginator\n",
    "new_obj.params.active_identifying_figure_ctx\n",
    "new_obj.on_paginator_control_widget_jump_to_page(page_idx=0)\n",
    "new_obj.ui.connections['paginator_controller_widget_jump_to_page']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae4154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, extant_plots in a_plots['weighted_corr'].items():\n",
    "    extant_wcorr_text = extant_plots.get('wcorr_text', None)\n",
    "    # extant_wcorr_text = extant_plots.pop('wcorr_text', None)\n",
    "    print(f'extant_wcorr_text: {extant_wcorr_text}')\n",
    "    # plot the radon transform line on the epoch:\n",
    "    if (extant_wcorr_text is not None):\n",
    "        # already exists, clear the existing ones. \n",
    "        # Let's assume we want to remove the 'Quadratic' line (line2)\n",
    "        print(f'removing extant text object at index: {i}.')\n",
    "        # extant_wcorr_text.remove()\n",
    "        extant_wcorr_text.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b07f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_pagination_controller in pagination_controller_dict.items():\n",
    "    display_context = a_pagination_controller.params.get('active_identifying_figure_ctx', IdentifyingContext())\n",
    "\n",
    "    # Get context for current page of items:\n",
    "    current_page_idx: int = int(a_pagination_controller.current_page_idx)\n",
    "    a_paginator = a_pagination_controller.paginator\n",
    "    total_num_pages = int(a_paginator.num_pages)\n",
    "    page_context = display_context.overwriting_context(page=current_page_idx, num_pages=total_num_pages)\n",
    "    print(page_context)\n",
    "\n",
    "    ## Get the figure/axes:\n",
    "    a_plots = a_pagination_controller.plots # RenderPlots\n",
    "    a_plot_data = a_pagination_controller.plots_data\n",
    "\n",
    "    a_params = a_pagination_controller.params\n",
    "    a_params.skip_plotting_measured_positions\n",
    "\n",
    "    figs = a_plots.fig\n",
    "    axs = a_plots.axs\n",
    "\n",
    "    # # with mpl.rc_context({'figure.figsize': (8.4, 4.8), 'figure.dpi': '220', 'savefig.transparent': True, 'ps.fonttype': 42, }):\n",
    "    # with mpl.rc_context({'figure.figsize': (16.8, 4.8), 'figure.dpi': '420', 'savefig.transparent': True, 'ps.fonttype': 42, }):\n",
    "    #     curr_active_pipeline.output_figure(final_context=page_context, fig=figs, write_vector_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d7aca6",
   "metadata": {},
   "source": [
    "## Export Paginated Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64bac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_paginator = a_pagination_controller.paginator\n",
    "total_num_pages = int(a_paginator.num_pages)\n",
    "page_idx_sweep = np.arange(total_num_pages)\n",
    "page_num_sweep = page_idx_sweep + 1 # switch to 1-indexed\n",
    "# page_num_sweep\n",
    "\n",
    "for a_page_idx, a_page_num in zip(page_idx_sweep, page_num_sweep):\n",
    "    print(f'switching to page: a_page_idx: {a_page_idx}, a_page_num: {a_page_num} of total_num_pages: {total_num_pages}')\n",
    "    a_pagination_controller.on_paginator_control_widget_jump_to_page(page_idx=a_page_idx)\n",
    "    a_pagination_controller.ui.mw.draw()\n",
    "    export_decoder_pagination_controller_figure_page(pagination_controller_dict, curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190122f0",
   "metadata": {},
   "source": [
    "## Other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eed0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = _out_pagination_controller.plots['radon_transform'][7]\n",
    "extant_line = _out['line'] # matplotlib.lines.Line2D\n",
    "extant_line.linestyle = 'none'\n",
    "# extant_line.draw()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82687641",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(curr_active_pipeline.filtered_contexts.keys())) # ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "\n",
    "# long_any_name\n",
    "\n",
    "# long_LR_name\n",
    "\n",
    "# Converting between decoder names and filtered epoch names:\n",
    "{'long':'maze1', 'short':'maze2'}\n",
    "{'LR':'odd', 'RL':'even'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "decoder_name_to_session_context_name = dict(zip(track_templates.get_decoder_names(), (long_LR_name, long_RL_name, short_LR_name, short_RL_name)))\n",
    "decoder_name_to_session_context_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04abcb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_num_slices: int = _out_pagination_controller.params.active_num_slices\n",
    "single_plot_fixed_height: float = _out_pagination_controller.params.single_plot_fixed_height\n",
    "all_plots_height: float = _out_pagination_controller.params.all_plots_height\n",
    "print(f'all_plots_height: {all_plots_height}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35377e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcef848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PendingNotebookCode import _add_maze_id_to_epochs\n",
    "\n",
    "\n",
    "## Add new weighted correlation results as new columns in existing filter_epochs df:\n",
    "active_filter_epochs = long_results_obj.active_filter_epochs\n",
    "# Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "active_filter_epochs = _add_maze_id_to_epochs(active_filter_epochs, short_session.t_start)\n",
    "active_filter_epochs._df['weighted_corr_LONG'] = epoch_long_weighted_corr_results[:,0]\n",
    "active_filter_epochs._df['weighted_corr_SHORT'] = epoch_short_weighted_corr_results[:,0]\n",
    "active_filter_epochs._df['weighted_corr_spearman_LONG'] = epoch_long_weighted_corr_results[:,1]\n",
    "active_filter_epochs._df['weighted_corr_spearman_SHORT'] = epoch_short_weighted_corr_results[:,1]\n",
    "\n",
    "\n",
    "active_filter_epochs\n",
    "active_filter_epochs.to_dataframe()\n",
    "## plot the `weighted_corr_LONG` over time\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=active_num_rows, sharex=True, sharey=sharey, figsize=figsize)\n",
    "\n",
    "## Weighted Correlation during replay epochs:\n",
    "_out_ax = active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_LONG', title='weighted_corr during replay events', marker=\"s\",  s=5, label=f'Long', alpha=0.8)\n",
    "active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_SHORT', xlabel='Replay Epoch Time', ylabel='Weighted Correlation', ax=_out_ax, marker=\"s\", c='r', s=5, label=f'Short', alpha=0.8)\n",
    "_out_ax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line\n",
    "## Weighted Spearman Correlation during replay epochs:\n",
    "_out_ax = active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_spearman_LONG', title='weighted_spearman_corr during replay events', marker=\"s\",  s=5, label=f'Long', alpha=0.8)\n",
    "active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_spearman_SHORT', xlabel='Replay Epoch Time', ylabel='Weighted Spearman Correlation', ax=_out_ax, marker=\"s\", c='r', s=5, label=f'Short', alpha=0.8)\n",
    "_out_ax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line\n",
    "_out_ax = active_filter_epochs._df.plot.scatter(x='start', y='score_LONG', title='Radon Transform Score during replay events', marker=\"s\",  s=5, label=f'Long', alpha=0.8)\n",
    "active_filter_epochs._df.plot.scatter(x='start', y='score_SHORT', xlabel='Replay Epoch Time', ylabel='Replay Radon Transform Score', ax=_out_ax, marker=\"s\", c='r', s=5, label=f'Short', alpha=0.8)\n",
    "_out_ax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d56479",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a739e",
   "metadata": {},
   "source": [
    "# 2024-02-13 - Plot the correlation between the Radon score and the decoder certainty for each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e028231",
   "metadata": {},
   "source": [
    "### Decoder confidence is how far away the value is from 0.5. A value of 0.5 indicates no bias towards long or short, and should recieve a value of zero. Bias in either direction (towards 1.0 or 0.0) should recieve a increasing certainty value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549853f",
   "metadata": {},
   "source": [
    "This is most easily accomplished by shifting the values towards zero and applying an absolute value function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c080b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_is_most_likely_direction_LR_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eff559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laps_all_epoch_bins_marginals_df\n",
    "rescaled_P_Long = np.abs(((ripple_all_epoch_bins_marginals_df['P_Long'] - 0.5) * 2))\n",
    "rescaled_P_Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0565c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get radon scores:\n",
    "ripple_radon_transform_merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb1abb",
   "metadata": {
    "tags": [
     "writing"
    ]
   },
   "source": [
    "# 2024-02-15 - Do simple spike-t vs. template pf peak correlation like Kamran suggested this morning\n",
    "\n",
    "Replays can be of trajectories on either the current track configuration or on a temporally distant one (such as a trajectory on the long track after the track has been shortened). \n",
    "The goal of the decoder scoring methods are to evaluate how likely each decoder was. This means for each Epoch we obtain a score for all four decoders: Long_LR, Long_RL, Short_LR, Short_RL\n",
    "\n",
    "#### `posterior decoder likelihoods` - This scoring method produces a probability that the\n",
    "\n",
    "#### Radon Transform - TODO\n",
    "\n",
    "#### `compute_simple_spike_time_v_pf_peak_x_by_epoch` - This epoch scoring metric plots the placefield peak x position against the time in seconds of each spike relative to the start of the epoch. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21de4ac7",
   "metadata": {},
   "source": [
    "## TODO 2024-02-15 8pm - Add in to previous result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0ba47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df)\n",
    "# (laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df)\n",
    "laps_simple_pf_pearson_merged_df\n",
    "# laps_radon_transform_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_laps_df: pd.DataFrame = laps_weighted_corr_merged_df.rename(columns={'best_decoder_index':'wcorr_best_decoder_index'}).join(laps_simple_pf_pearson_merged_df.rename(columns={'best_decoder_index':'pearsonr_best_decoder_index'})) # , lsuffix='__L'\n",
    "_test_ripple_df: pd.DataFrame = ripple_weighted_corr_merged_df.rename(columns={'best_decoder_index':'wcorr_best_decoder_index'}).join(ripple_simple_pf_pearson_merged_df.rename(columns={'best_decoder_index':'pearsonr_best_decoder_index'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c31abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_df = _test_ripple_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332caab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _test_df.pearsonr_best_decoder_index.hist()\n",
    "\n",
    "_test_df.long_LR_pf_peak_x_pearsonr.hist()\n",
    "_test_df.long_RL_pf_peak_x_pearsonr.hist()\n",
    "_test_df.short_LR_pf_peak_x_pearsonr.hist()\n",
    "_test_df.short_RL_pf_peak_x_pearsonr.hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f502f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_df[corr_column_names].abs().mean(axis='rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2dd8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_radon_transform_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b694aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## count up the number that the RadonTransform and the most-likely direction agree\n",
    "# laps_simple_pf_pearson_stats = _compute_matching_best_indicies(_test_laps_df, index_column_name='most_likely_decoder_index', second_index_column_name='pearsonr_best_decoder_index', enable_print=True)\n",
    "# ripple_simple_pf_pearson_stats = _compute_matching_best_indicies(_test_ripple_df, index_column_name='most_likely_decoder_index', second_index_column_name='pearsonr_best_decoder_index', enable_print=True)\n",
    "\n",
    "laps_simple_pf_pearson_stats = _compute_matching_best_indicies(laps_simple_pf_pearson_merged_df.rename(columns={'best_decoder_index':'pearsonr_best_decoder_index'}), index_column_name='most_likely_decoder_index', second_index_column_name='pearsonr_best_decoder_index', enable_print=True)\n",
    "# ripple_simple_pf_pearson_stats = _compute_matching_best_indicies(_test_ripple_df, index_column_name='most_likely_decoder_index', second_index_column_name='pearsonr_best_decoder_index', enable_print=True)\n",
    "laps_simple_pf_pearson_stats\n",
    "\n",
    "# laps_simple_pf_pearson_stats = _compute_matching_best_indicies(laps_weighted_corr_merged_df.rename(columns={'best_decoder_index':'wcorr_best_decoder_index'}).join(laps_simple_pf_pearson_merged_df.rename(columns={'best_decoder_index':'pearsonr_best_decoder_index'})), index_column_name='most_likely_decoder_index', second_index_column_name='pearsonr_best_decoder_index', enable_print=True)\n",
    "# agreeing_rows_ratio, (agreeing_rows_count, num_total_epochs) = laps_radon_stats\n",
    "# ripple_wcorr_stats = _compute_matching_best_indicies(ripple_weighted_corr_merged_df, index_column_name='most_likely_decoder_index', second_index_column_name=best_decoder_index_col_name, enable_print=True)\n",
    "\n",
    "# agreeing_rows_count/num_total_epochs: 41/84\n",
    "# \tagreeing_rows_ratio: 0.4880952380952381\n",
    "\n",
    "\n",
    "## Not well-matching for ripples surprisingly:\n",
    "# agreeing_rows_count/num_total_epochs: 77/84\n",
    "# \tagreeing_rows_ratio: 0.9166666666666666\n",
    "# agreeing_rows_count/num_total_epochs: 115/412\n",
    "# \tagreeing_rows_ratio: 0.279126213592233\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f8139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS:laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df\n",
    "laps_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17625acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_lap_epochs_dict = dict(zip((long_LR_name, long_RL_name, short_LR_name, short_RL_name), (long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj)))\n",
    "directional_active_lap_pf_results_dicts = TrialByTrialActivity.directional_compute_trial_by_trial_correlation_matrix(active_pf_dt=active_pf_dt, directional_lap_epochs_dict=directional_lap_epochs_dict, included_neuron_IDs=any_decoder_neuron_IDs)\n",
    "\n",
    "decoder_aclu_peak_location_df_merged = deepcopy(track_templates.get_decoders_aclu_peak_location_df(width=None))\n",
    "# decoder_aclu_peak_location_df_merged[np.isin(decoder_aclu_peak_location_df_merged['aclu'], both_included_neuron_stats_df.aclu.to_numpy())]\n",
    "decoder_aclu_peak_location_df_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result: TrialByTrialActivity = directional_active_lap_pf_results_dicts['long_LR']\n",
    "# a_result.sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e43ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: ripple_radon_transform_merged_df, decoder_specific_Radon_transform_score_columns\n",
    "\n",
    "\n",
    "decoder_specific_probability_columns = ['P_Long_LR', 'P_Long_RL', 'P_Short_LR', 'P_Short_RL']\n",
    "decoder_specific_Radon_transform_score_columns = ['score_long_LR', 'score_long_RL', 'score_short_LR', 'score_short_RL']\n",
    "\n",
    "best_decoder_index = ripple_radon_transform_merged_df['best_decoder_index'].to_numpy()\n",
    "# best_decoder_index.shape # (611,)\n",
    "\n",
    "\n",
    "# ripple_radon_transform_merged_df['best_decoder_index']\n",
    "\n",
    "decoder_specific_probability_mat = ripple_radon_transform_merged_df[decoder_specific_probability_columns].to_numpy() # .shape (611, 4)\n",
    "decoder_specific_Radon_transform_score_mat = ripple_radon_transform_merged_df[decoder_specific_Radon_transform_score_columns].to_numpy() # .shape (611, 4)\n",
    "n_epochs = np.shape(decoder_specific_Radon_transform_score_mat)[0] # 611\n",
    "# n_epochs \n",
    "best_decoder_probability = np.array([decoder_specific_probability_mat[i, best_decoder_index[i]] for i in np.arange(n_epochs)])\n",
    "best_decoder_Radon_transform_score = np.array([decoder_specific_Radon_transform_score_mat[i, best_decoder_index[i]] for i in np.arange(n_epochs)])\n",
    "# best_decoder_Radon_transform_score.shape # (611,)\n",
    "# best_decoder_Radon_transform_score\n",
    "\n",
    "# best_decoder_probability.shape # (611,)\n",
    "\n",
    "\n",
    "# [best_decoder_index].shape\n",
    "\n",
    "\n",
    "# Assuming best_decoder_probability and best_decoder_Radon_transform_score have been computed successfully and have the same shape\n",
    "correlation_matrix = np.corrcoef(best_decoder_probability, best_decoder_Radon_transform_score)\n",
    "\n",
    "# Extract the correlation coefficient from the matrix\n",
    "point_wise_correlation = correlation_matrix[0, 1]  # This gets the correlation between the two arrays\n",
    "\n",
    "print(point_wise_correlation)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your previously calculated vectors\n",
    "# best_decoder_probability = np.array([...])\n",
    "# best_decoder_Radon_transform_score = np.array([...])\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(best_decoder_probability, best_decoder_Radon_transform_score)\n",
    "\n",
    "# Optional: Specify the labels for axes\n",
    "plt.xlabel('Best Decoder Probability')\n",
    "plt.ylabel('Best Decoder Radon Transform Score')\n",
    "\n",
    "# Optional: Specify the title of the graph\n",
    "plt.title('Scatter Plot of Best Decoder Probability vs. Radon Transform Score')\n",
    "\n",
    "# Show the scatter plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0f22b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdc9c8c5",
   "metadata": {},
   "source": [
    "## Checking each probability of decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec881f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_laps_results.all_directional_laps_filter_epochs_decoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d6da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.laps_merged_complete_epoch_stats_df ## New method\n",
    "ripple_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalMergedDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "all_directional_decoder_dict_value = directional_merged_decoders_result.all_directional_decoder_dict\n",
    "all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "# long_directional_pf1D_Decoder_value = directional_merged_decoders_result.long_directional_pf1D_Decoder\n",
    "# long_directional_decoder_dict_value = directional_merged_decoders_result.long_directional_decoder_dict\n",
    "# short_directional_pf1D_Decoder_value = directional_merged_decoders_result.short_directional_pf1D_Decoder\n",
    "# short_directional_decoder_dict_value = directional_merged_decoders_result.short_directional_decoder_dict\n",
    "\n",
    "all_directional_laps_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "all_directional_ripple_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\n",
    "\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = directional_merged_decoders_result.laps_track_identity_marginals_tuple\n",
    "ripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.ripple_directional_marginals_tuple\n",
    "ripple_track_identity_marginals, ripple_track_identity_all_epoch_bins_marginal, ripple_most_likely_track_identity_from_decoder, ripple_is_most_likely_track_identity_Long = directional_merged_decoders_result.ripple_track_identity_marginals_tuple\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "\n",
    "laps_all_epoch_bins_marginals_df = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "ripple_all_epoch_bins_marginals_df = directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_all_epoch_bins_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93608f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_directional_marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a0c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalMergedDecodersResult\n",
    "\n",
    "non_marginalized_raw_result_per_time_bin = [v['p_x_given_n'] for v in DirectionalMergedDecodersResult.build_non_marginalized_raw_posteriors(all_directional_ripple_filter_epochs_decoder_result_value)] #[0]['p_x_given_n']\n",
    "# non_marginalized_raw_result_per_time_bin\n",
    "\n",
    "## Collapse to one 4-element probability per epoch\n",
    "non_marginalized_raw_result_per_epoch = [np.nanmean(v, axis=1) for v in non_marginalized_raw_result_per_time_bin]\n",
    "len(non_marginalized_raw_result_per_epoch)\n",
    "\n",
    "# non_marginalized_raw_result_shapes = [np.shape(v) for v in non_marginalized_raw_result]\n",
    "# non_marginalized_raw_result_shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_marginalized_raw_result_per_epoch[265]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32581271",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_directional_ripple_filter_epochs_decoder_result_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac6e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try filtering out the endcap cells, maybe change the minimum number of cells inclusion for the ripples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86968ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0174187368f176085df53c2cec5d63d0b8400e63ae887d077931481ed3fab96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
