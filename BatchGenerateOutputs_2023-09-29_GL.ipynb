{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from typing import List, Dict, Optional, Union, Callable\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables as tb\n",
    "from copy import deepcopy\n",
    "from datetime import datetime, timedelta\n",
    "from attrs import define, field, Factory\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import CapturedException\n",
    "\n",
    "# Jupyter interactivity:\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.gui.Jupyter.JupyterButtonRowWidget import JupyterButtonRowWidget\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core import Epoch\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "import pyphoplacecellanalysis.General.Batch.runBatch\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun, BatchResultDataframeAccessor, run_diba_batch, BatchComputationProcessOptions, BatchSessionCompletionHandler, SavingOptions\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import SessionBatchProgress\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "\n",
    "from pyphocorehelpers.print_helpers import CapturedException\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler\n",
    "\n",
    "BATCH_DATE_TO_USE = '2023-09-29-GL' # used for filenames throught the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef5938c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/global_batch_result_2023-09-29-GL.pkl... done.\n",
      "no difference between provided and internal paths.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>context</th>\n",
       "      <th>basedirs</th>\n",
       "      <th>status</th>\n",
       "      <th>errors</th>\n",
       "      <th>session_datetime</th>\n",
       "      <th>n_long_laps</th>\n",
       "      <th>n_long_replays</th>\n",
       "      <th>n_short_laps</th>\n",
       "      <th>n_short_replays</th>\n",
       "      <th>is_ready</th>\n",
       "      <th>global_computation_result_file</th>\n",
       "      <th>loaded_session_pickle_file</th>\n",
       "      <th>ripple_result_file</th>\n",
       "      <th>has_user_replay_annotations</th>\n",
       "      <th>has_user_grid_bin_bounds_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-07_11-26-53</td>\n",
       "      <td>kdiba_gor01_one_2006-6-07_11-26-53</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-07 11:26:53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>kdiba_gor01_one_2006-6-08_14-26-15</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "      <td>40</td>\n",
       "      <td>279</td>\n",
       "      <td>40</td>\n",
       "      <td>224</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>kdiba_gor01_one_2006-6-09_1-22-43</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-09 01:22:43</td>\n",
       "      <td>46</td>\n",
       "      <td>179</td>\n",
       "      <td>40</td>\n",
       "      <td>142</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_3-23-37</td>\n",
       "      <td>kdiba_gor01_one_2006-6-09_3-23-37</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-09 03:23:37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-12_15-55-31</td>\n",
       "      <td>kdiba_gor01_one_2006-6-12_15-55-31</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-12 15:55:31</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-04_21-20-3</td>\n",
       "      <td>kdiba_pin01_one_fet11-04_21-20-3</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-04 21:20:03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>redundant</td>\n",
       "      <td>kdiba_pin01_one_redundant</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/red...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>showclus</td>\n",
       "      <td>kdiba_pin01_one_showclus</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sho...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>sleep</td>\n",
       "      <td>kdiba_pin01_one_sleep</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sleep</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>tmaze</td>\n",
       "      <td>kdiba_pin01_one_tmaze</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/tmaze</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   format_name animal exper_name        session_name  \\\n",
       "0        kdiba  gor01        one  2006-6-07_11-26-53   \n",
       "1        kdiba  gor01        one  2006-6-08_14-26-15   \n",
       "2        kdiba  gor01        one   2006-6-09_1-22-43   \n",
       "3        kdiba  gor01        one   2006-6-09_3-23-37   \n",
       "4        kdiba  gor01        one  2006-6-12_15-55-31   \n",
       "..         ...    ...        ...                 ...   \n",
       "67       kdiba  pin01        one    fet11-04_21-20-3   \n",
       "68       kdiba  pin01        one           redundant   \n",
       "69       kdiba  pin01        one            showclus   \n",
       "70       kdiba  pin01        one               sleep   \n",
       "71       kdiba  pin01        one               tmaze   \n",
       "\n",
       "                               context  \\\n",
       "0   kdiba_gor01_one_2006-6-07_11-26-53   \n",
       "1   kdiba_gor01_one_2006-6-08_14-26-15   \n",
       "2    kdiba_gor01_one_2006-6-09_1-22-43   \n",
       "3    kdiba_gor01_one_2006-6-09_3-23-37   \n",
       "4   kdiba_gor01_one_2006-6-12_15-55-31   \n",
       "..                                 ...   \n",
       "67    kdiba_pin01_one_fet11-04_21-20-3   \n",
       "68           kdiba_pin01_one_redundant   \n",
       "69            kdiba_pin01_one_showclus   \n",
       "70               kdiba_pin01_one_sleep   \n",
       "71               kdiba_pin01_one_tmaze   \n",
       "\n",
       "                                             basedirs  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/red...   \n",
       "69  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sho...   \n",
       "70   /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sleep   \n",
       "71   /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/tmaze   \n",
       "\n",
       "                              status errors    session_datetime  n_long_laps  \\\n",
       "0   SessionBatchProgress.NOT_STARTED   None 2006-06-07 11:26:53            0   \n",
       "1     SessionBatchProgress.COMPLETED   None 2006-06-08 14:26:15           40   \n",
       "2     SessionBatchProgress.COMPLETED   None 2006-06-09 01:22:43           46   \n",
       "3   SessionBatchProgress.NOT_STARTED   None 2006-06-09 03:23:37            0   \n",
       "4     SessionBatchProgress.COMPLETED   None 2006-06-12 15:55:31           40   \n",
       "..                               ...    ...                 ...          ...   \n",
       "67  SessionBatchProgress.NOT_STARTED   None 2009-11-04 21:20:03            0   \n",
       "68  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "69  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "70  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "71  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "\n",
       "    n_long_replays  n_short_laps  n_short_replays  is_ready  \\\n",
       "0                0             0                0     False   \n",
       "1              279            40              224      True   \n",
       "2              179            40              142      True   \n",
       "3                0             0                0     False   \n",
       "4               37            34               55      True   \n",
       "..             ...           ...              ...       ...   \n",
       "67               0             0                0     False   \n",
       "68               0             0                0     False   \n",
       "69               0             0                0     False   \n",
       "70               0             0                0     False   \n",
       "71               0             0                0     False   \n",
       "\n",
       "                       global_computation_result_file  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3                                                       \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "                           loaded_session_pickle_file  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3                                                       \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "                                   ripple_result_file  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "    has_user_replay_annotations  has_user_grid_bin_bounds_annotations  \n",
       "0                         False                                  True  \n",
       "1                          True                                  True  \n",
       "2                          True                                  True  \n",
       "3                         False                                  True  \n",
       "4                          True                                  True  \n",
       "..                          ...                                   ...  \n",
       "67                        False                                  True  \n",
       "68                        False                                 False  \n",
       "69                        False                                 False  \n",
       "70                        False                                 False  \n",
       "71                        False                                 False  \n",
       "\n",
       "[72 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_global_batch_result_filename=f'global_batch_result_{BATCH_DATE_TO_USE}.pkl'\n",
    "\n",
    "debug_print = False\n",
    "known_global_data_root_parent_paths = [Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/nfs/turbo/umms-kdiba/Data')] # , Path(r'/home/halechr/FastData')\n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "## Build Pickle Path:\n",
    "global_batch_result_file_path = Path(global_data_root_parent_path).joinpath(active_global_batch_result_filename).resolve() # Use Default\n",
    "\n",
    "# try to load an existing batch result:\n",
    "global_batch_run = BatchRun.try_init_from_file(global_data_root_parent_path, active_global_batch_result_filename=active_global_batch_result_filename,\n",
    "\t\t\t\t\t\tskip_root_path_conversion=False, debug_print=debug_print) # on_needs_create_callback_fn=run_diba_batch\n",
    "\n",
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "batch_progress_df.batch_results.build_all_columns()\n",
    "good_only_batch_progress_df.batch_results.build_all_columns()\n",
    "batch_progress_df\n",
    "with pd.option_context('display.max_rows', 10, 'display.max_columns', None):  # more options can be specified also\n",
    "    # display(batch_progress_df)\n",
    "    # display(good_only_batch_progress_df)\n",
    "    display(batch_progress_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab824348",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Batch Executions/Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019afbbd-70d2-4e75-9548-b6f22d2e31ca",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hardcoded included_session_contexts:\n",
    "included_session_contexts = [\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'), # prev completed\n",
    "]\n",
    "\n",
    "included_session_batch_progress_df = batch_progress_df[np.isin(batch_progress_df['context'].values, included_session_contexts)]\n",
    "with pd.option_context('display.max_rows', 10, 'display.max_columns', None):  # more options can be specified also\n",
    "    included_session_batch_progress_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71584edc",
   "metadata": {},
   "source": [
    "# Execute Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff419df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_included_session_contexts, output_python_scripts, output_slurm_scripts = global_batch_run.generate_batch_slurm_jobs(included_session_contexts, Path('output/generated_slurm_scripts/').resolve(), \n",
    "                                                                                                                        use_separate_run_directories=True, should_force_reload_all=False, should_perform_figure_generation_to_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab6ae279",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(included_session_contexts): 15\n",
      "Beginning processing with len(included_session_contexts): 15\n",
      "build_batch_task_logger(module_name=\"gl3065.arc-ts.umich.edu.kdiba.gor01.two.2006-6-07_16-40-19\"):build_batch_task_logger(module_name=\"gl3065.arc-ts.umich.edu.kdiba.gor01.one.2006-6-08_14-26-15\"):build_batch_task_logger(module_name=\"gl3065.arc-ts.umich.edu.kdiba.gor01.two.2006-6-08_21-16-25\"):\n",
      "\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.gor01.two.2006-6-07_16-40-19 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.gor01.two.2006-6-07_16-40-19.logbuild_batch_task_logger(module_name=\"gl3065.arc-ts.umich.edu.kdiba.gor01.one.2006-6-12_15-55-31\"):\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.gor01.one.2006-6-08_14-26-15 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.gor01.one.2006-6-08_14-26-15.log\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3065.arc-ts.umich.edu.kdiba.gor01.one.2006-6-09_1-22-43\"):\n",
      "\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.gor01.one.2006-6-12_15-55-31 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.gor01.one.2006-6-12_15-55-31.log\n",
      "========================== runBatch STARTING ==================================================== runBatch STARTING ==========================\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.gor01.one.2006-6-09_1-22-43 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.gor01.one.2006-6-09_1-22-43.log========================== runBatch STARTING ==========================\n",
      "\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.gor01.two.2006-6-08_21-16-25 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.gor01.two.2006-6-08_21-16-25.log\n",
      "\n",
      "\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\n",
      "\tsession_context: kdiba_gor01_two_2006-6-07_16-40-19\n",
      "\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19\tsession_context: kdiba_gor01_one_2006-6-12_15-55-31\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31\n",
      "__________________________________________________________________========================== runBatch STARTING ==========================\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31\tsession_context: kdiba_gor01_one_2006-6-08_14-26-15\n",
      "\n",
      "\n",
      "active_data_mode_name: kdiba\n",
      "__________________________________________________________________\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl... basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19\n",
      "\n",
      "========================== runBatch STARTING ==========================active_data_mode_name: kdiba\n",
      "\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_gor01_two_2006-6-08_21-16-25\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl...\n",
      "\n",
      " \tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data__________________________________________________________________\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25\n",
      "\n",
      "\n",
      "\tsession_context: kdiba_gor01_one_2006-6-09_1-22-43basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15__________________________________________________________________\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl... \n",
      "\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43\n",
      "\n",
      "active_data_mode_name: kdiba__________________________________________________________________\n",
      "\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl...Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl...  done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_one_2006-6-12_15-55-31, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl... done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_one_2006-6-09_1-22-43, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl... done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "extended_stats, maze already computed.\n",
      "pf_dt_sequential_surprise missing.\n",
      "\t Recomputing pf_dt_sequential_surprise...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_one_2006-6-08_14-26-15, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl... done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-08_21-16-25, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl... done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "extended_stats, maze already computed.\n",
      "pf_dt_sequential_surprise missing.\n",
      "\t Recomputing pf_dt_sequential_surprise...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "extended_stats, maze already computed.\n",
      "pf_dt_sequential_surprise missing.\n",
      "\t Recomputing pf_dt_sequential_surprise...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-07_16-40-19, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl... done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "extended_stats, maze already computed.\n",
      "pf_dt_sequential_surprise, maze already computed.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses, maze already computed.\n",
      "jonathan_firing_rate_analysis, maze already computed.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "no changes in global results.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 7:20:41.860103\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5\n",
      "done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "extended_stats, maze already computed.\n",
      "pf_dt_sequential_surprise, maze already computed.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses, maze already computed.\n",
      "jonathan_firing_rate_analysis, maze already computed.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "no changes in global results.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 7:26:36.939092\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-07_16-40-19'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:303: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:309: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_short_inst_spike_rate_groups is missing and will be skipped\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-07_16-40-19/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-08_21-16-25'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:303: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:309: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_short_inst_spike_rate_groups is missing and will be skipped\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-08_21-16-25/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-07_16-40-19...\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "ERROR: encountered exception !! Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "\tself.SxC_aclus: [ 3 19]\n",
      "\tself.LxC_aclus: []\n",
      " ::::: (<class 'AssertionError'>, AssertionError(\"Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\\n\\tself.SxC_aclus: [ 3 19]\\n\\tself.LxC_aclus: []\\n\"), <traceback object at 0x14990fb4b9c0>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_gor01_two_2006-6-07_16-40-19]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3065.arc-ts.umich.edu.kdiba.gor01.two.2006-6-09_22-24-40\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.gor01.two.2006-6-09_22-24-40 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.gor01.two.2006-6-09_22-24-40.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_gor01_two_2006-6-09_22-24-40\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl... Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-09_22-24-40, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl... \t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-08_21-16-25...\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "ERROR: encountered exception !! Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "\tself.SxC_aclus: [ 4  8 16]\n",
      "\tself.LxC_aclus: []\n",
      " ::::: (<class 'AssertionError'>, AssertionError(\"Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\\n\\tself.SxC_aclus: [ 4  8 16]\\n\\tself.LxC_aclus: []\\n\"), <traceback object at 0x14975873ad40>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_gor01_two_2006-6-08_21-16-25]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3065.arc-ts.umich.edu.kdiba.gor01.two.2006-6-12_16-53-46\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.gor01.two.2006-6-12_16-53-46 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.gor01.two.2006-6-12_16-53-46.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_gor01_two_2006-6-12_16-53-46\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-12_16-53-46, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl... done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "extended_stats, maze already computed.\n",
      "pf_dt_sequential_surprise missing.\n",
      "\t Recomputing pf_dt_sequential_surprise...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "extended_stats, maze already computed.\n",
      "pf_dt_sequential_surprise missing.\n",
      "\t Recomputing pf_dt_sequential_surprise...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "\t done.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses, maze already computed.\n",
      "jonathan_firing_rate_analysis, maze already computed.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('pf_dt_sequential_surprise', 'maze')]. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl... \tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/20230929075535-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:12.631103\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-12_15-55-31'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:303: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:309: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_short_inst_spike_rate_groups is missing and will be skipped\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-12_15-55-31/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-12_15-55-31...\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "ERROR: encountered exception !! Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "\tself.SxC_aclus: [30 33]\n",
      "\tself.LxC_aclus: []\n",
      " ::::: (<class 'AssertionError'>, AssertionError(\"Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\\n\\tself.SxC_aclus: [30 33]\\n\\tself.LxC_aclus: []\\n\"), <traceback object at 0x149892483640>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_gor01_one_2006-6-12_15-55-31]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3065.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-09_17-29-30\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-09_17-29-30 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-09_17-29-30.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_vvp01_one_2006-4-09_17-29-30\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_one_2006-4-09_17-29-30, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl... done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "extended_stats, maze already computed.\n",
      "pf_dt_sequential_surprise missing.\n",
      "\t Recomputing pf_dt_sequential_surprise...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "\t done.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': None})\n",
      "_generalized_compute_long_short_firing_rate_indicies(...): processing key: \"laps\"\n",
      "_generalized_compute_long_short_firing_rate_indicies(...): processing key: \"replays\"\n",
      "\t done.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses, maze already computed.\n",
      "jonathan_firing_rate_analysis, maze already computed.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('pf_dt_sequential_surprise', 'maze')]. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl... _generalized_compute_long_short_firing_rate_indicies(...): processing key: \"non_replays\"\n",
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/20230929080813-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:37.842897\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-12_16-53-46'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:303: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:309: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_short_inst_spike_rate_groups is missing and will be skipped\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-12_16-53-46/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses, maze already computed.\n",
      "jonathan_firing_rate_analysis, maze already computed.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('pf_dt_sequential_surprise', 'maze')]. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl... DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/20230929080949-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:07.715025\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5\n",
      "\t done.\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "\t done.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('pf_dt_sequential_surprise', 'maze'), ('long_short_fr_indicies_analyses', 'maze'), ('jonathan_firing_rate_analysis', 'maze')]. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-09_17-29-30'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:303: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:309: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_short_inst_spike_rate_groups is missing and will be skipped\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-09_17-29-30/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-12_16-53-46...\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "ERROR: encountered exception !! Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "\tself.SxC_aclus: []\n",
      "\tself.LxC_aclus: []\n",
      " ::::: (<class 'AssertionError'>, AssertionError(\"Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\\n\\tself.SxC_aclus: []\\n\\tself.LxC_aclus: []\\n\"), <traceback object at 0x1498bdee7200>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_gor01_two_2006-6-12_16-53-46]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3065.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-10_12-25-50\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-10_12-25-50 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-10_12-25-50.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_vvp01_one_2006-4-10_12-25-50\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl... DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses, maze already computed.\n",
      "jonathan_firing_rate_analysis, maze already computed.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('pf_dt_sequential_surprise', 'maze')]. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl... DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl.\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_one_2006-4-09_17-29-30...\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only aboveproperties already present in pickled version. No need to save.\n",
      "\n",
      "pipeline load success!Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "\n",
      "ERROR: encountered exception !! Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "\tself.SxC_aclus: [31 41]\n",
      "\tself.LxC_aclus: []\n",
      " ::::: (<class 'AssertionError'>, AssertionError(\"Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\\n\\tself.SxC_aclus: [31 41]\\n\\tself.LxC_aclus: []\\n\"), <traceback object at 0x1497b7d61200>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_vvp01_one_2006-4-09_17-29-30]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis']\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-Nonebuild_batch_task_logger(module_name=\"gl3065.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-09_16-40-54\"):\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-09_16-40-54 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-09_16-40-54.log\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "========================== runBatch STARTING ==========================\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_one_2006-4-10_12-25-50, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\tsession_context: kdiba_vvp01_two_2006-4-09_16-40-54DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl... __________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl... \tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/20230929080959-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:46.638454\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5\n",
      "done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "extended_stats, maze already computed.\n",
      "pf_dt_sequential_surprise missing.\n",
      "\t Recomputing pf_dt_sequential_surprise...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_two_2006-4-09_16-40-54, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl... done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "extended_stats, maze already computed.\n",
      "pf_dt_sequential_surprise missing.\n",
      "\t Recomputing pf_dt_sequential_surprise...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-09_1-22-43'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:303: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:309: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_short_inst_spike_rate_groups is missing and will be skipped\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-09_1-22-43/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/20230929081032-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:55.293803\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-08_14-26-15'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:303: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:309: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_short_inst_spike_rate_groups is missing and will be skipped\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5, with key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/one/2006-6-08_14-26-15/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-09_1-22-43...\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "ERROR: encountered exception !! Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "\tself.SxC_aclus: [55 69]\n",
      "\tself.LxC_aclus: []\n",
      " ::::: (<class 'AssertionError'>, AssertionError(\"Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\\n\\tself.SxC_aclus: [55 69]\\n\\tself.LxC_aclus: []\\n\"), <traceback object at 0x14989236e1c0>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_gor01_one_2006-6-09_1-22-43]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3065.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-10_12-58-3\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-10_12-58-3 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-10_12-58-3.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_vvp01_two_2006-4-10_12-58-3\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_vvp01_two_2006-4-10_12-58-3, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl... done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "extended_stats, maze already computed.\n",
      "pf_dt_sequential_surprise missing.\n",
      "\t Recomputing pf_dt_sequential_surprise...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-08_14-26-15...\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "ERROR: encountered exception !! Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "\tself.SxC_aclus: [ 4 13 58]\n",
      "\tself.LxC_aclus: []\n",
      " ::::: (<class 'AssertionError'>, AssertionError(\"Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\\n\\tself.SxC_aclus: [ 4 13 58]\\n\\tself.LxC_aclus: []\\n\"), <traceback object at 0x14989200d7c0>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_gor01_one_2006-6-08_14-26-15]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3065.arc-ts.umich.edu.kdiba.pin01.one.11-02_17-46-44\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.pin01.one.11-02_17-46-44 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.pin01.one.11-02_17-46-44.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_pin01_one_11-02_17-46-44\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_11-02_17-46-44, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl... done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "extended_stats, maze already computed.\n",
      "pf_dt_sequential_surprise missing.\n",
      "\t Recomputing pf_dt_sequential_surprise...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "\t done.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses, maze already computed.\n",
      "jonathan_firing_rate_analysis, maze already computed.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('pf_dt_sequential_surprise', 'maze')]. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl... Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/20230929081727-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:01:23.649242\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-09_22-24-40'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:303: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:309: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_short_inst_spike_rate_groups is missing and will be skipped\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5, with key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/gor01/two/2006-6-09_22-24-40/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-09_22-24-40...\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "\t done.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses, maze already computed.\n",
      "jonathan_firing_rate_analysis, maze already computed.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('pf_dt_sequential_surprise', 'maze')]. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl... Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/20230929082215-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:08.126839\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-09_16-40-54'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:303: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:309: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_short_inst_spike_rate_groups is missing and will be skipped\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-09_16-40-54/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_two_2006-4-09_16-40-54...\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "ERROR: encountered exception !! Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "\tself.SxC_aclus: []\n",
      "\tself.LxC_aclus: []\n",
      " ::::: (<class 'AssertionError'>, AssertionError(\"Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\\n\\tself.SxC_aclus: []\\n\\tself.LxC_aclus: []\\n\"), <traceback object at 0x1497b8495740>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_vvp01_two_2006-4-09_16-40-54]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3065.arc-ts.umich.edu.kdiba.pin01.one.11-02_19-28-0\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.pin01.one.11-02_19-28-0 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.pin01.one.11-02_19-28-0.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_pin01_one_11-02_19-28-0\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_11-02_19-28-0, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl... \t\t done (success).\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3065.arc-ts.umich.edu.kdiba.pin01.one.11-03_12-3-25\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.pin01.one.11-03_12-3-25 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.pin01.one.11-03_12-3-25.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_pin01_one_11-03_12-3-25\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl... done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "extended_stats, maze already computed.\n",
      "pf_dt_sequential_surprise missing.\n",
      "\t Recomputing pf_dt_sequential_surprise...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_11-03_12-3-25, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl... done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "extended_stats, maze already computed.\n",
      "pf_dt_sequential_surprise missing.\n",
      "\t Recomputing pf_dt_sequential_surprise...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "\t done.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses, maze already computed.\n",
      "jonathan_firing_rate_analysis, maze already computed.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('pf_dt_sequential_surprise', 'maze')]. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl... Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/20230929082712-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:10.129535\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-10_12-58-3'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:303: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:309: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_short_inst_spike_rate_groups is missing and will be skipped\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5, with key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/two/2006-4-10_12-58-3/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_two_2006-4-10_12-58-3...\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "ERROR: encountered exception !! Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "\tself.SxC_aclus: []\n",
      "\tself.LxC_aclus: []\n",
      " ::::: (<class 'AssertionError'>, AssertionError(\"Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\\n\\tself.SxC_aclus: []\\n\\tself.LxC_aclus: []\\n\"), <traceback object at 0x14970c455f00>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_vvp01_two_2006-4-10_12-58-3]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "build_batch_task_logger(module_name=\"gl3065.arc-ts.umich.edu.kdiba.pin01.one.fet11-01_12-58-54\"):\n",
      "\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.pin01.one.fet11-01_12-58-54 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl3065.arc-ts.umich.edu.kdiba.pin01.one.fet11-01_12-58-54.log\n",
      "========================== runBatch STARTING ==========================\n",
      "\tglobal_data_root_parent_path: /nfs/turbo/umms-kdiba/Data\n",
      "\tsession_context: kdiba_pin01_one_fet11-01_12-58-54\n",
      "\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54\n",
      "__________________________________________________________________\n",
      "basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54\n",
      "active_data_mode_name: kdiba\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding', 'position_decoding_two_step', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "on_complete_success_execution_session(curr_session_context: kdiba_pin01_one_fet11-01_12-58-54, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54, ...)\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl... Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "extended_stats, maze already computed.\n",
      "pf_dt_sequential_surprise missing.\n",
      "\t Recomputing pf_dt_sequential_surprise...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "\t done.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses, maze already computed.\n",
      "jonathan_firing_rate_analysis, maze already computed.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('pf_dt_sequential_surprise', 'maze')]. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl... \tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/20230929083156-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:13.635459\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '11-02_17-46-44'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:303: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:309: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_short_inst_spike_rate_groups is missing and will be skipped\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_17-46-44/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses, maze already computed.\n",
      "jonathan_firing_rate_analysis, maze already computed.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('pf_dt_sequential_surprise', 'maze')]. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl... DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/20230929083258-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:04.630679\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '11-03_12-3-25'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:303: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:309: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_short_inst_spike_rate_groups is missing and will be skipped\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-02_17-46-44...\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "\n",
      "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.WARNING: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "ERROR: encountered exception !! Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "\tself.SxC_aclus: [17 40]\n",
      "\tself.LxC_aclus: []\n",
      " ::::: (<class 'AssertionError'>, AssertionError(\"Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\\n\\tself.SxC_aclus: [17 40]\\n\\tself.LxC_aclus: []\\n\"), <traceback object at 0x149925064080>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_pin01_one_11-02_17-46-44]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-03_12-3-25/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-03_12-3-25...\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "ERROR: encountered exception !! Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "\tself.SxC_aclus: []\n",
      "\tself.LxC_aclus: []\n",
      " ::::: (<class 'AssertionError'>, AssertionError(\"Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\\n\\tself.SxC_aclus: []\\n\\tself.LxC_aclus: []\\n\"), <traceback object at 0x14988f4534c0>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_pin01_one_11-03_12-3-25]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "\t done.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses, maze already computed.\n",
      "jonathan_firing_rate_analysis, maze already computed.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('pf_dt_sequential_surprise', 'maze')]. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl... \t done.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses, maze already computed.\n",
      "jonathan_firing_rate_analysis, maze already computed.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('pf_dt_sequential_surprise', 'maze')]. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl... \tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/20230929083411-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:09.274090\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '11-02_19-28-0'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/20230929083417-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:10.384683\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:303: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:309: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_short_inst_spike_rate_groups is missing and will be skipped\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5, with key: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/11-02_19-28-0/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-10_12-25-50'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:303: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:309: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_short_inst_spike_rate_groups is missing and will be skipped\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5, with key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/vvp01/one/2006-4-10_12-25-50/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-02_19-28-0...\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "ERROR: encountered exception !! Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "\tself.SxC_aclus: []\n",
      "\tself.LxC_aclus: []\n",
      " ::::: (<class 'AssertionError'>, AssertionError(\"Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\\n\\tself.SxC_aclus: []\\n\\tself.LxC_aclus: []\\n\"), <traceback object at 0x149799e13300>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_pin01_one_11-02_19-28-0]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_one_2006-4-10_12-25-50...\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "ERROR: encountered exception !! Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "\tself.SxC_aclus: [29]\n",
      "\tself.LxC_aclus: []\n",
      " ::::: (<class 'AssertionError'>, AssertionError(\"Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\\n\\tself.SxC_aclus: [29]\\n\\tself.LxC_aclus: []\\n\"), <traceback object at 0x149892714ec0>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_vvp01_one_2006-4-10_12-25-50]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "\t done.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses, maze already computed.\n",
      "jonathan_firing_rate_analysis, maze already computed.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('pf_dt_sequential_surprise', 'maze')]. Saving global results...\n",
      "WARNING: supposed to skip_saving because of self.saving_mode: PipelineSavingScheme.SKIP_SAVING but supposedly has new global results! Figure out if these are actually new.\n",
      "global_computation_results_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl\n",
      "Saving (file mode '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl... \tmoving new output at '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/20230929083842-global_computation_results.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl'\n",
      "done.\n",
      "skipping figure generation because should_perform_figure_generation_to_file == False\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\n",
      "\t time since last computation: 0:00:17.842618\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5\n",
      "OVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5!\n",
      "pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: 'fet11-01_12-58-54'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:303: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['firing_rates', 'is_neuron_active', 'active_aclus'], dtype='object')]\n",
      "\n",
      "  self.rdf.rdf.to_hdf(file_path, key=f'{key}/rdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/LongShortTrackComputations.py:309: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['firing_rates'], dtype='object')]\n",
      "\n",
      "  self.irdf.irdf.to_hdf(file_path, key=f'{key}/irdf/df') # , format='table', data_columns=True Can't do 'table' format because `TypeError: Cannot serialize the column [firing_rates] because its data contents are not [string] but [mixed] object dtype`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_short_inst_spike_rate_groups is missing and will be skipped\n",
      "WARNING: experimental automatic `to_hdf` implementation for object of type <class 'pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.ExpectedVsObservedResult'> to file_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5, with key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result:\n",
      "a_field: Flat_epoch_time_bins_mean\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/Flat_epoch_time_bins_mean is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_LONG\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_LONG\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_LONG\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/observed_from_expected_diff_std_LONG is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/Flat_all_epochs_computed_expected_cell_num_spikes_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_ptp_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ma.core.MaskedArray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/observed_from_expected_diff_ptp_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_mean_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/observed_from_expected_diff_mean_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "a_field: observed_from_expected_diff_std_SHORT\n",
      "\ta_field_key: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT\n",
      "\t field not custom serializable! a_field_attr.type: <class 'numpy.ndarray'>.\n",
      "WARNING: /kdiba/pin01/one/fet11-01_12-58-54/global_computations/expected_v_observed_result/observed_from_expected_diff_std_SHORT is not custom serializable, but we will try HDF_Converter._try_default_to_hdf_conversion_fn(file_path=file_path, key=a_field_key, value=a_value) with the value. Will raise a NotImplementedException if this fails.\n",
      "an_attribute_field: num_neurons\n",
      "an_attribute_field: num_total_flat_timebins\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_fet11-01_12-58-54...\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "ERROR: encountered exception !! Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\n",
      "\tself.SxC_aclus: []\n",
      "\tself.LxC_aclus: []\n",
      " ::::: (<class 'AssertionError'>, AssertionError(\"Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\\n\\tself.SxC_aclus: []\\n\\tself.LxC_aclus: []\\n\"), <traceback object at 0x149710b29600>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_pin01_one_fet11-01_12-58-54]\n",
      "\"========================== END BATCH ==========================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %pdb on\n",
    "\n",
    "# multiprocessing_kwargs = dict(use_multiprocessing=False, num_processes=1)\n",
    "multiprocessing_kwargs = dict(use_multiprocessing=True, num_processes=5)\n",
    "\n",
    "enable_full_pipeline_in_ram = False\n",
    "# enable_full_pipeline_in_ram = True\n",
    "\n",
    "# Whether to output figures:\n",
    "should_perform_figure_generation_to_file=False\n",
    "# should_perform_figure_generation_to_file=True\n",
    "\n",
    "## Included Session Contexts:\n",
    "# included_session_contexts = batch_progress_df[np.logical_and(batch_progress_df['has_user_replay_annotations'], batch_progress_df['is_ready'])]['context'].to_numpy().tolist()\n",
    "\n",
    "# Only require sessions to have replay annotations:\n",
    "# included_session_contexts = batch_progress_df[batch_progress_df['has_user_replay_annotations']]['context'].to_numpy().tolist()\n",
    "\n",
    "# included_session_contexts = batch_progress_df['context'].to_numpy().tolist()[:4] # Only get the first 6\n",
    "## Limit the contexts to run to the last N:\n",
    "# included_session_contexts = included_session_contexts[3:6]\n",
    "\n",
    "# ALL\n",
    "included_session_contexts = included_session_contexts\n",
    "\n",
    "# ## No filtering the sessions:\n",
    "# included_session_contexts = None\n",
    "\n",
    "if included_session_contexts is not None:\n",
    "    print(f'len(included_session_contexts): {len(included_session_contexts)}')\n",
    "else:\n",
    "    print(f'included_session_contexts is None so all session contexts will be included.')\n",
    "\n",
    "# included_session_contexts\n",
    "\n",
    "\n",
    "# No Reloading\n",
    "result_handler = BatchSessionCompletionHandler(force_reload_all=False,\n",
    "                                                session_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=True, should_save=SavingOptions.IF_CHANGED),\n",
    "                                                global_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=True, should_save=SavingOptions.IF_CHANGED),\n",
    "                                                should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, should_generate_all_plots=True, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_global_recompute=False,\n",
    "                                                enable_full_pipeline_in_ram=enable_full_pipeline_in_ram,\n",
    "                                                **multiprocessing_kwargs)\n",
    "\n",
    "\n",
    "# # Forced Reloading:\n",
    "# result_handler = BatchSessionCompletionHandler(force_reload_all=True,\n",
    "#                                                 session_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=SavingOptions.ALWAYS),\n",
    "#                                                 global_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=SavingOptions.ALWAYS),\n",
    "#                                                 should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE, force_global_recompute=True,\n",
    "#                                                 **multiprocessing_kwargs)\n",
    "\n",
    "\n",
    "active_post_run_callback_fn = result_handler.on_complete_success_execution_session\n",
    "# active_post_run_callback_fn = _temp_on_complete_success_execution_session\n",
    "\n",
    "\n",
    "\n",
    "## Execute with the custom arguments.\n",
    "active_computation_functions_name_includelist=['pf_computation', 'pfdt_computation', 'firing_rate_trends',\n",
    "                                                # 'pf_dt_sequential_surprise',\n",
    "                                                # 'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', 'position_decoding_two_step', \n",
    "                                               'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                                # 'long_short_inst_spike_rate_groups',\n",
    "                                                'long_short_endcap_analysis']\n",
    "\n",
    "global_batch_run.execute_all(force_reload=result_handler.force_reload_all, saving_mode=result_handler.saving_mode, skip_extended_batch_computations=True, post_run_callback_fn=active_post_run_callback_fn,\n",
    "                             fail_on_exception=True, included_session_contexts=included_session_contexts,\n",
    "                                                                                        **{'computation_functions_name_includelist': active_computation_functions_name_includelist,\n",
    "                                                                                            'active_session_computation_configs': None,\n",
    "                                                                                            'allow_processing_previously_completed': True}, **multiprocessing_kwargs) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 4m 39.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db79885",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Save to pickle:\n",
    "saveData(global_batch_result_file_path, global_batch_run) # Update the global batch run dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0981cde1",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>context</th>\n",
       "      <th>basedirs</th>\n",
       "      <th>status</th>\n",
       "      <th>errors</th>\n",
       "      <th>session_datetime</th>\n",
       "      <th>n_long_laps</th>\n",
       "      <th>n_long_replays</th>\n",
       "      <th>n_short_laps</th>\n",
       "      <th>n_short_replays</th>\n",
       "      <th>is_ready</th>\n",
       "      <th>global_computation_result_file</th>\n",
       "      <th>loaded_session_pickle_file</th>\n",
       "      <th>ripple_result_file</th>\n",
       "      <th>has_user_replay_annotations</th>\n",
       "      <th>has_user_grid_bin_bounds_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-07_11-26-53</td>\n",
       "      <td>kdiba_gor01_one_2006-6-07_11-26-53</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-07 11:26:53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>kdiba_gor01_one_2006-6-08_14-26-15</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "      <td>40</td>\n",
       "      <td>279</td>\n",
       "      <td>40</td>\n",
       "      <td>224</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>kdiba_gor01_one_2006-6-09_1-22-43</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-09 01:22:43</td>\n",
       "      <td>46</td>\n",
       "      <td>179</td>\n",
       "      <td>40</td>\n",
       "      <td>142</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_3-23-37</td>\n",
       "      <td>kdiba_gor01_one_2006-6-09_3-23-37</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-09 03:23:37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-12_15-55-31</td>\n",
       "      <td>kdiba_gor01_one_2006-6-12_15-55-31</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>SessionBatchProgress.COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-06-12 15:55:31</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-04_21-20-3</td>\n",
       "      <td>kdiba_pin01_one_fet11-04_21-20-3</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-11-04 21:20:03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>redundant</td>\n",
       "      <td>kdiba_pin01_one_redundant</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/red...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>showclus</td>\n",
       "      <td>kdiba_pin01_one_showclus</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sho...</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>sleep</td>\n",
       "      <td>kdiba_pin01_one_sleep</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sleep</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>tmaze</td>\n",
       "      <td>kdiba_pin01_one_tmaze</td>\n",
       "      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/tmaze</td>\n",
       "      <td>SessionBatchProgress.NOT_STARTED</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   format_name animal exper_name        session_name  \\\n",
       "0        kdiba  gor01        one  2006-6-07_11-26-53   \n",
       "1        kdiba  gor01        one  2006-6-08_14-26-15   \n",
       "2        kdiba  gor01        one   2006-6-09_1-22-43   \n",
       "3        kdiba  gor01        one   2006-6-09_3-23-37   \n",
       "4        kdiba  gor01        one  2006-6-12_15-55-31   \n",
       "..         ...    ...        ...                 ...   \n",
       "67       kdiba  pin01        one    fet11-04_21-20-3   \n",
       "68       kdiba  pin01        one           redundant   \n",
       "69       kdiba  pin01        one            showclus   \n",
       "70       kdiba  pin01        one               sleep   \n",
       "71       kdiba  pin01        one               tmaze   \n",
       "\n",
       "                               context  \\\n",
       "0   kdiba_gor01_one_2006-6-07_11-26-53   \n",
       "1   kdiba_gor01_one_2006-6-08_14-26-15   \n",
       "2    kdiba_gor01_one_2006-6-09_1-22-43   \n",
       "3    kdiba_gor01_one_2006-6-09_3-23-37   \n",
       "4   kdiba_gor01_one_2006-6-12_15-55-31   \n",
       "..                                 ...   \n",
       "67    kdiba_pin01_one_fet11-04_21-20-3   \n",
       "68           kdiba_pin01_one_redundant   \n",
       "69            kdiba_pin01_one_showclus   \n",
       "70               kdiba_pin01_one_sleep   \n",
       "71               kdiba_pin01_one_tmaze   \n",
       "\n",
       "                                             basedirs  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/red...   \n",
       "69  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sho...   \n",
       "70   /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sleep   \n",
       "71   /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/tmaze   \n",
       "\n",
       "                              status errors    session_datetime  n_long_laps  \\\n",
       "0   SessionBatchProgress.NOT_STARTED   None 2006-06-07 11:26:53            0   \n",
       "1     SessionBatchProgress.COMPLETED   None 2006-06-08 14:26:15           40   \n",
       "2     SessionBatchProgress.COMPLETED   None 2006-06-09 01:22:43           46   \n",
       "3   SessionBatchProgress.NOT_STARTED   None 2006-06-09 03:23:37            0   \n",
       "4     SessionBatchProgress.COMPLETED   None 2006-06-12 15:55:31           40   \n",
       "..                               ...    ...                 ...          ...   \n",
       "67  SessionBatchProgress.NOT_STARTED   None 2009-11-04 21:20:03            0   \n",
       "68  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "69  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "70  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "71  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \n",
       "\n",
       "    n_long_replays  n_short_laps  n_short_replays  is_ready  \\\n",
       "0                0             0                0     False   \n",
       "1              279            40              224      True   \n",
       "2              179            40              142      True   \n",
       "3                0             0                0     False   \n",
       "4               37            34               55      True   \n",
       "..             ...           ...              ...       ...   \n",
       "67               0             0                0     False   \n",
       "68               0             0                0     False   \n",
       "69               0             0                0     False   \n",
       "70               0             0                0     False   \n",
       "71               0             0                0     False   \n",
       "\n",
       "                       global_computation_result_file  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3                                                       \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "                           loaded_session_pickle_file  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3                                                       \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "                                   ripple_result_file  \\\n",
       "0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "3   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \n",
       "..                                                ...   \n",
       "67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "\n",
       "    has_user_replay_annotations  has_user_grid_bin_bounds_annotations  \n",
       "0                         False                                  True  \n",
       "1                          True                                  True  \n",
       "2                          True                                  True  \n",
       "3                         False                                  True  \n",
       "4                          True                                  True  \n",
       "..                          ...                                   ...  \n",
       "67                        False                                  True  \n",
       "68                        False                                 False  \n",
       "69                        False                                 False  \n",
       "70                        False                                 False  \n",
       "71                        False                                 False  \n",
       "\n",
       "[72 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "batch_progress_df.batch_results.build_all_columns()\n",
    "good_only_batch_progress_df.batch_results.build_all_columns()\n",
    "batch_progress_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f140f",
   "metadata": {},
   "source": [
    "# Across Sessions After Batching Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d85e7111",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Undocumented: HDF5 files containing links to other external .h5 files. These work!\n",
    "\n",
    "included_h5_paths = [a_dir.joinpath('output','pipeline_results.h5').resolve() for a_dir in included_session_batch_progress_df['basedirs']]\n",
    "included_h5_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34bd1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def copy_files_in_filelist_to_dest(filelist_text_file='fileList_GreatLakes_HDF5_2023-09-29-GL.txt', target_directory='/path/to/target/directory'):\n",
    "\t# Read the file paths from the text file\n",
    "\twith open(filelist_text_file, 'r') as f:\n",
    "\t\tfile_paths = f.readlines()\n",
    "\n",
    "\t# Remove newline characters from each line\n",
    "\tfile_paths = [x.strip() for x in file_paths]\n",
    "\n",
    "\t# Target directory where files will be copied\n",
    "\n",
    "\t# Copy each file to the target directory\n",
    "\tfor file_path in file_paths:\n",
    "\t\tprint(f'copying {file_path} to {target_directory}...')\n",
    "\t\tshutil.copy(file_path, target_directory)\n",
    "\tprint(f'done.')\n",
    "\n",
    "# file_paths = [Path('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5'),\n",
    "#  Path('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5'),\n",
    "#  Path('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5'),\n",
    "#  Path('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5'),\n",
    "#  Path('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5'),\n",
    "#  Path('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5'),\n",
    "#  Path('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5'),\n",
    "#  Path('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5'),\n",
    "#  Path('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5'),\n",
    "#  Path('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5'),\n",
    "#  Path('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5'),\n",
    "#  Path('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5'),\n",
    "#  Path('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5'),\n",
    "#  Path('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5'),\n",
    "#  Path('/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5')]\n",
    "\n",
    "copy_files_in_filelist_to_dest(filelist_text_file=\"/nfs/turbo/umms-kdiba/Data/fileList_GreatLakes_HDF5_2023-09-29-GL.txt\", target_directory=Path('output/extracted_hdf5_files/').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fc7340d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl\n",
      "saving out to \"/nfs/turbo/umms-kdiba/Data/fileList_GreatLakes_pkls_2023-09-29-GL.txt\"...\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl\n",
      "saving out to \"/nfs/turbo/umms-kdiba/Data/dest_fileList_LabWorkstation_pkls_2023-09-29-GL.txt\"...\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl\n",
      "saving out to \"/nfs/turbo/umms-kdiba/Data/fileList_GreatLakes_global_pkls_2023-09-29-GL.txt\"...\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/global_computation_results.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/global_computation_results.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/global_computation_results.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/global_computation_results.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/global_computation_results.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/global_computation_results.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/pin01/one/11-02_17-46-44/output/global_computation_results.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/pin01/one/11-02_19-28-0/output/global_computation_results.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/pin01/one/11-03_12-3-25/output/global_computation_results.pkl\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/global_computation_results.pkl\n",
      "saving out to \"/nfs/turbo/umms-kdiba/Data/dest_fileList_LabWorkstation_global_pkls_2023-09-29-GL.txt\"...\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5\n",
      "/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5\n",
      "saving out to \"/nfs/turbo/umms-kdiba/Data/fileList_GreatLakes_HDF5_2023-09-29-GL.txt\"...\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5\n",
      "/media/MAX/cloud/turbo/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5\n",
      "saving out to \"/nfs/turbo/umms-kdiba/Data/dest_fileList_LabWorkstation_HDF5_2023-09-29-GL.txt\"...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{PosixPath('/nfs/turbo/umms-kdiba/Data/fileList_GreatLakes_pkls_2023-09-29-GL.txt'): PosixPath('/nfs/turbo/umms-kdiba/Data/dest_fileList_LabWorkstation_pkls_2023-09-29-GL.txt'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/fileList_GreatLakes_global_pkls_2023-09-29-GL.txt'): PosixPath('/nfs/turbo/umms-kdiba/Data/dest_fileList_LabWorkstation_global_pkls_2023-09-29-GL.txt'),\n",
       " PosixPath('/nfs/turbo/umms-kdiba/Data/fileList_GreatLakes_HDF5_2023-09-29-GL.txt'): PosixPath('/nfs/turbo/umms-kdiba/Data/dest_fileList_LabWorkstation_HDF5_2023-09-29-GL.txt')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import build_output_filelists\n",
    "\n",
    "included_session_basedirs = included_session_batch_progress_df['basedirs']\n",
    "output_filelist_transfer_dict = build_output_filelists(filelist_save_parent_path=global_data_root_parent_path, included_session_basedirs=included_session_basedirs, BATCH_DATE_TO_USE=BATCH_DATE_TO_USE, dest_computer_name='LabWorkstation')\n",
    "# output_filelist_transfer_dict = build_output_filelists(filelist_save_parent_path=global_data_root_parent_path, included_session_basedirs=included_session_basedirs, BATCH_DATE_TO_USE=BATCH_DATE_TO_USE, dest_computer_name='Apogee')\n",
    "output_filelist_transfer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9dfee55",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenating dataframes from 15 of 15 files\n",
      "concatenating dataframes from 15 of 15 files\n",
      "concatenating dataframes from 15 of 15 files\n",
      "a_name: neuron_identities_table\n",
      "writing /home/halechr/repos/Spike3D/output/across_session_results/neuron_identities_table.csv.\n",
      "a_name: long_short_fr_indicies_analysis_table\n",
      "writing /home/halechr/repos/Spike3D/output/across_session_results/long_short_fr_indicies_analysis_table.csv.\n",
      "a_name: neuron_replay_stats_table\n",
      "writing /home/halechr/repos/Spike3D/output/across_session_results/neuron_replay_stats_table.csv.\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionTables\n",
    "\n",
    "AcrossSessionTables.save_out_to_combined_file(included_session_contexts, included_h5_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c4e7b48",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenating dataframes from 15 of 15 files\n",
      "concatenating dataframes from 15 of 15 files\n",
      "concatenating dataframes from 15 of 15 files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_uid</th>\n",
       "      <th>session_uid</th>\n",
       "      <th>session_datetime</th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>neuron_id</th>\n",
       "      <th>neuron_type</th>\n",
       "      <th>cluster_index</th>\n",
       "      <th>qclu</th>\n",
       "      <th>shank_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|2</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>2</td>\n",
       "      <td>pyr</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|3</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>3</td>\n",
       "      <td>pyr</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|4</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>4</td>\n",
       "      <td>pyr</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|5</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>5</td>\n",
       "      <td>pyr</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|6</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>6</td>\n",
       "      <td>intr</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|28</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>28</td>\n",
       "      <td>pyr</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|29</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>29</td>\n",
       "      <td>pyr</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|30</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>30</td>\n",
       "      <td>pyr</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|31</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>31</td>\n",
       "      <td>pyr</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|32</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>32</td>\n",
       "      <td>pyr</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               global_uid                         session_uid  \\\n",
       "0    kdiba|gor01|one|2006-6-08_14-26-15|2  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "1    kdiba|gor01|one|2006-6-08_14-26-15|3  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "2    kdiba|gor01|one|2006-6-08_14-26-15|4  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "3    kdiba|gor01|one|2006-6-08_14-26-15|5  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "4    kdiba|gor01|one|2006-6-08_14-26-15|6  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "..                                    ...                                 ...   \n",
       "882  kdiba|pin01|one|fet11-01_12-58-54|28   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "883  kdiba|pin01|one|fet11-01_12-58-54|29   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "884  kdiba|pin01|one|fet11-01_12-58-54|30   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "885  kdiba|pin01|one|fet11-01_12-58-54|31   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "886  kdiba|pin01|one|fet11-01_12-58-54|32   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "\n",
       "       session_datetime format_name animal exper_name        session_name  \\\n",
       "0   2006-06-08 14:26:15       kdiba  gor01        one  2006-6-08_14-26-15   \n",
       "1   2006-06-08 14:26:15       kdiba  gor01        one  2006-6-08_14-26-15   \n",
       "2   2006-06-08 14:26:15       kdiba  gor01        one  2006-6-08_14-26-15   \n",
       "3   2006-06-08 14:26:15       kdiba  gor01        one  2006-6-08_14-26-15   \n",
       "4   2006-06-08 14:26:15       kdiba  gor01        one  2006-6-08_14-26-15   \n",
       "..                  ...         ...    ...        ...                 ...   \n",
       "882 2009-11-01 12:58:54       kdiba  pin01        one   fet11-01_12-58-54   \n",
       "883 2009-11-01 12:58:54       kdiba  pin01        one   fet11-01_12-58-54   \n",
       "884 2009-11-01 12:58:54       kdiba  pin01        one   fet11-01_12-58-54   \n",
       "885 2009-11-01 12:58:54       kdiba  pin01        one   fet11-01_12-58-54   \n",
       "886 2009-11-01 12:58:54       kdiba  pin01        one   fet11-01_12-58-54   \n",
       "\n",
       "     neuron_id neuron_type  cluster_index  qclu  shank_index  \n",
       "0            2         pyr              6     2            1  \n",
       "1            3         pyr              9     4            1  \n",
       "2            4         pyr             10     4            1  \n",
       "3            5         pyr             11     2            1  \n",
       "4            6        intr             12     5            1  \n",
       "..         ...         ...            ...   ...          ...  \n",
       "882         28         pyr             10     2            3  \n",
       "883         29         pyr             11     2            3  \n",
       "884         30         pyr             14     2            3  \n",
       "885         31         pyr              3     4            4  \n",
       "886         32         pyr              6     2            4  \n",
       "\n",
       "[887 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save tables out to .csv:\n",
    "neuron_replay_stats_table = AcrossSessionTables.build_neuron_replay_stats_table(included_session_contexts, included_h5_paths)\n",
    "neuron_replay_stats_table\n",
    "long_short_fr_indicies_analysis_table = AcrossSessionTables.build_long_short_fr_indicies_analysis_table(included_session_contexts, included_h5_paths)\n",
    "long_short_fr_indicies_analysis_table\n",
    "neuron_identities_table = AcrossSessionTables.build_neuron_identities_table(included_session_contexts, included_h5_paths)\n",
    "neuron_identities_table\n",
    "## Save converted back to .h5 file, .csv file, and several others\n",
    "\n",
    "# across_session_outputs = {f'output/across_session_results/neuron_identities_table_{BATCH_DATE_TO_USE}': neuron_identities_table,\n",
    "#  f'output/across_session_results/long_short_fr_indicies_analysis_table_{BATCH_DATE_TO_USE}': long_short_fr_indicies_analysis_table,\n",
    "# f'output/across_session_results/neuron_replay_stats_table_{BATCH_DATE_TO_USE}': neuron_replay_stats_table}\n",
    "\n",
    "# for k, v in across_session_outputs.items():\n",
    "#     k = Path(k)\n",
    "#     a_name = k.name\n",
    "#     print(f'a_name: {a_name}')\n",
    "#     v.to_csv(k.with_suffix(suffix='.csv'))\n",
    "#     # v.to_hdf(k, key=f'/{a_name}')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b8ced5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "882    False\n",
       "883    False\n",
       "884    False\n",
       "885    False\n",
       "886    False\n",
       "Name: is_refined_LxC, Length: 887, dtype: bool"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_replay_stats_table['is_refined_LxC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "\n",
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45f5f5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>long_pf_peak_x</th>\n",
       "      <th>short_pf_peak_x</th>\n",
       "      <th>track_membership</th>\n",
       "      <th>long_non_replay_mean</th>\n",
       "      <th>short_non_replay_mean</th>\n",
       "      <th>non_replay_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>neuron_type</th>\n",
       "      <th>aclu</th>\n",
       "      <th>custom_frs_index</th>\n",
       "      <th>is_rate_extrema</th>\n",
       "      <th>is_refined_exclusive</th>\n",
       "      <th>is_refined_LxC</th>\n",
       "      <th>is_refined_SxC</th>\n",
       "      <th>session_uid</th>\n",
       "      <th>neuron_uid</th>\n",
       "      <th>session_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>212.160000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LEFT_ONLY</td>\n",
       "      <td>0.419960</td>\n",
       "      <td>0.114724</td>\n",
       "      <td>-0.305237</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>2</td>\n",
       "      <td>0.235886</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|2</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>136.160000</td>\n",
       "      <td>198.160000</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>0.275226</td>\n",
       "      <td>1.227759</td>\n",
       "      <td>0.952532</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.683602</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|3</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.160000</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.117397</td>\n",
       "      <td>0.834271</td>\n",
       "      <td>0.716874</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.981692</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|4</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>98.160000</td>\n",
       "      <td>202.160000</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>2.090985</td>\n",
       "      <td>1.844885</td>\n",
       "      <td>-0.246099</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.057305</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|5</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>26.129319</td>\n",
       "      <td>12.892497</td>\n",
       "      <td>-13.236821</td>\n",
       "      <td>...</td>\n",
       "      <td>intr</td>\n",
       "      <td>6</td>\n",
       "      <td>0.102215</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|6</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>179.403791</td>\n",
       "      <td>177.403791</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>0.892852</td>\n",
       "      <td>1.027642</td>\n",
       "      <td>0.134789</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.148122</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|28</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>59.403791</td>\n",
       "      <td>107.403791</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>0.837484</td>\n",
       "      <td>0.766268</td>\n",
       "      <td>-0.071216</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>29</td>\n",
       "      <td>0.041598</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|29</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>119.403791</td>\n",
       "      <td>127.403791</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>0.712330</td>\n",
       "      <td>0.577649</td>\n",
       "      <td>-0.134681</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.026850</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|30</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>217.403791</td>\n",
       "      <td>33.403791</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>0.902182</td>\n",
       "      <td>1.016473</td>\n",
       "      <td>0.114291</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>31</td>\n",
       "      <td>0.039185</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|31</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>fet11-01_12-58-54</td>\n",
       "      <td>63.403791</td>\n",
       "      <td>95.403791</td>\n",
       "      <td>SHARED</td>\n",
       "      <td>0.946397</td>\n",
       "      <td>0.529446</td>\n",
       "      <td>-0.416951</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>32</td>\n",
       "      <td>0.141802</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54</td>\n",
       "      <td>kdiba|pin01|one|fet11-01_12-58-54|32</td>\n",
       "      <td>2009-11-01 12:58:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    format_name animal exper_name        session_name  long_pf_peak_x  \\\n",
       "0         kdiba  gor01        one  2006-6-08_14-26-15      212.160000   \n",
       "1         kdiba  gor01        one  2006-6-08_14-26-15      136.160000   \n",
       "2         kdiba  gor01        one  2006-6-08_14-26-15             NaN   \n",
       "3         kdiba  gor01        one  2006-6-08_14-26-15       98.160000   \n",
       "4         kdiba  gor01        one  2006-6-08_14-26-15             NaN   \n",
       "..          ...    ...        ...                 ...             ...   \n",
       "882       kdiba  pin01        one   fet11-01_12-58-54      179.403791   \n",
       "883       kdiba  pin01        one   fet11-01_12-58-54       59.403791   \n",
       "884       kdiba  pin01        one   fet11-01_12-58-54      119.403791   \n",
       "885       kdiba  pin01        one   fet11-01_12-58-54      217.403791   \n",
       "886       kdiba  pin01        one   fet11-01_12-58-54       63.403791   \n",
       "\n",
       "     short_pf_peak_x track_membership  long_non_replay_mean  \\\n",
       "0                NaN        LEFT_ONLY              0.419960   \n",
       "1         198.160000           SHARED              0.275226   \n",
       "2         178.160000       RIGHT_ONLY              0.117397   \n",
       "3         202.160000           SHARED              2.090985   \n",
       "4                NaN           SHARED             26.129319   \n",
       "..               ...              ...                   ...   \n",
       "882       177.403791           SHARED              0.892852   \n",
       "883       107.403791           SHARED              0.837484   \n",
       "884       127.403791           SHARED              0.712330   \n",
       "885        33.403791           SHARED              0.902182   \n",
       "886        95.403791           SHARED              0.946397   \n",
       "\n",
       "     short_non_replay_mean  non_replay_diff  ...  neuron_type  aclu  \\\n",
       "0                 0.114724        -0.305237  ...          pyr     2   \n",
       "1                 1.227759         0.952532  ...          pyr     3   \n",
       "2                 0.834271         0.716874  ...          pyr     4   \n",
       "3                 1.844885        -0.246099  ...          pyr     5   \n",
       "4                12.892497       -13.236821  ...         intr     6   \n",
       "..                     ...              ...  ...          ...   ...   \n",
       "882               1.027642         0.134789  ...          pyr    28   \n",
       "883               0.766268        -0.071216  ...          pyr    29   \n",
       "884               0.577649        -0.134681  ...          pyr    30   \n",
       "885               1.016473         0.114291  ...          pyr    31   \n",
       "886               0.529446        -0.416951  ...          pyr    32   \n",
       "\n",
       "     custom_frs_index  is_rate_extrema  is_refined_exclusive  is_refined_LxC  \\\n",
       "0            0.235886            False                 False           False   \n",
       "1           -0.683602             True                 False           False   \n",
       "2           -0.981692             True                  True           False   \n",
       "3           -0.057305            False                 False           False   \n",
       "4            0.102215            False                 False           False   \n",
       "..                ...              ...                   ...             ...   \n",
       "882         -0.148122            False                 False           False   \n",
       "883          0.041598            False                 False           False   \n",
       "884         -0.026850            False                 False           False   \n",
       "885          0.039185            False                 False           False   \n",
       "886          0.141802            False                 False           False   \n",
       "\n",
       "     is_refined_SxC                         session_uid  \\\n",
       "0             False  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "1             False  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "2              True  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "3             False  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "4             False  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "..              ...                                 ...   \n",
       "882           False   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "883           False   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "884           False   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "885           False   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "886           False   kdiba|pin01|one|fet11-01_12-58-54   \n",
       "\n",
       "                               neuron_uid    session_datetime  \n",
       "0    kdiba|gor01|one|2006-6-08_14-26-15|2 2006-06-08 14:26:15  \n",
       "1    kdiba|gor01|one|2006-6-08_14-26-15|3 2006-06-08 14:26:15  \n",
       "2    kdiba|gor01|one|2006-6-08_14-26-15|4 2006-06-08 14:26:15  \n",
       "3    kdiba|gor01|one|2006-6-08_14-26-15|5 2006-06-08 14:26:15  \n",
       "4    kdiba|gor01|one|2006-6-08_14-26-15|6 2006-06-08 14:26:15  \n",
       "..                                    ...                 ...  \n",
       "882  kdiba|pin01|one|fet11-01_12-58-54|28 2009-11-01 12:58:54  \n",
       "883  kdiba|pin01|one|fet11-01_12-58-54|29 2009-11-01 12:58:54  \n",
       "884  kdiba|pin01|one|fet11-01_12-58-54|30 2009-11-01 12:58:54  \n",
       "885  kdiba|pin01|one|fet11-01_12-58-54|31 2009-11-01 12:58:54  \n",
       "886  kdiba|pin01|one|fet11-01_12-58-54|32 2009-11-01 12:58:54  \n",
       "\n",
       "[887 rows x 29 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.sum(neuron_replay_stats_table['is_refined_LxC'].astype(bool))\n",
    "refined_only_neuron_replay_stats_table = deepcopy(neuron_replay_stats_table).dropna(subset=['is_refined_LxC','is_refined_SxC']) # 887 rows\n",
    "refined_only_neuron_replay_stats_table = refined_only_neuron_replay_stats_table.drop_duplicates(subset=['neuron_uid'], keep='last') # subset=['format_name', 'animal', 'exper_name', 'session_name', 'aclu'])\n",
    "refined_only_neuron_replay_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70691506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['format_name', 'animal', 'exper_name', 'session_name', 'long_pf_peak_x', 'short_pf_peak_x', 'track_membership', 'long_non_replay_mean', 'short_non_replay_mean', 'non_replay_diff', 'long_replay_mean', 'short_replay_mean', 'replay_diff', 'long_mean', 'short_mean', 'mean_diff', 'num_replays', 'long_num_replays', 'short_num_replays', 'neuron_type', 'aclu', 'custom_frs_index', 'is_rate_extrema', 'is_refined_exclusive', 'is_refined_LxC', 'is_refined_SxC', 'session_uid', 'neuron_uid', 'session_datetime']\n"
     ]
    }
   ],
   "source": [
    "print(list(refined_only_neuron_replay_stats_table.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "001d4c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>long_pf_peak_x</th>\n",
       "      <th>short_pf_peak_x</th>\n",
       "      <th>track_membership</th>\n",
       "      <th>long_non_replay_mean</th>\n",
       "      <th>short_non_replay_mean</th>\n",
       "      <th>non_replay_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>neuron_type</th>\n",
       "      <th>aclu</th>\n",
       "      <th>custom_frs_index</th>\n",
       "      <th>is_rate_extrema</th>\n",
       "      <th>is_refined_exclusive</th>\n",
       "      <th>is_refined_LxC</th>\n",
       "      <th>is_refined_SxC</th>\n",
       "      <th>session_uid</th>\n",
       "      <th>neuron_uid</th>\n",
       "      <th>session_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.160000</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.117397</td>\n",
       "      <td>0.834271</td>\n",
       "      <td>0.716874</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.981692</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|4</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224.160000</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.383654</td>\n",
       "      <td>0.624830</td>\n",
       "      <td>0.241177</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.712649</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|13</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-08_14-26-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176.160000</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.342354</td>\n",
       "      <td>1.075711</td>\n",
       "      <td>0.733356</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.513290</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15</td>\n",
       "      <td>kdiba|gor01|one|2006-6-08_14-26-15|58</td>\n",
       "      <td>2006-06-08 14:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183.586204</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.216324</td>\n",
       "      <td>0.847278</td>\n",
       "      <td>0.630953</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>55</td>\n",
       "      <td>-0.869149</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|one|2006-6-09_1-22-43</td>\n",
       "      <td>kdiba|gor01|one|2006-6-09_1-22-43|55</td>\n",
       "      <td>2006-06-09 01:22:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.586204</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.224789</td>\n",
       "      <td>0.620227</td>\n",
       "      <td>0.395438</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>69</td>\n",
       "      <td>-0.587754</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|one|2006-6-09_1-22-43</td>\n",
       "      <td>kdiba|gor01|one|2006-6-09_1-22-43|69</td>\n",
       "      <td>2006-06-09 01:22:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-12_15-55-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.300282</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.042425</td>\n",
       "      <td>0.684426</td>\n",
       "      <td>0.642001</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.909655</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|one|2006-6-12_15-55-31</td>\n",
       "      <td>kdiba|gor01|one|2006-6-12_15-55-31|30</td>\n",
       "      <td>2006-06-12 15:55:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-6-12_15-55-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171.300282</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.076103</td>\n",
       "      <td>0.555817</td>\n",
       "      <td>0.479714</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.867661</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|one|2006-6-12_15-55-31</td>\n",
       "      <td>kdiba|gor01|one|2006-6-12_15-55-31|33</td>\n",
       "      <td>2006-06-12 15:55:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-07_16-40-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.397021</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.181870</td>\n",
       "      <td>0.831176</td>\n",
       "      <td>0.649306</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.976095</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|two|2006-6-07_16-40-19</td>\n",
       "      <td>kdiba|gor01|two|2006-6-07_16-40-19|3</td>\n",
       "      <td>2006-06-07 16:40:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-07_16-40-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.397021</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.199305</td>\n",
       "      <td>1.253306</td>\n",
       "      <td>1.054000</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.940402</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|two|2006-6-07_16-40-19</td>\n",
       "      <td>kdiba|gor01|two|2006-6-07_16-40-19|19</td>\n",
       "      <td>2006-06-07 16:40:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-08_21-16-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197.718247</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.185921</td>\n",
       "      <td>1.572612</td>\n",
       "      <td>1.386691</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.668623</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|two|2006-6-08_21-16-25</td>\n",
       "      <td>kdiba|gor01|two|2006-6-08_21-16-25|4</td>\n",
       "      <td>2006-06-08 21:16:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-08_21-16-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.718247</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.661418</td>\n",
       "      <td>2.549954</td>\n",
       "      <td>1.888536</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.666016</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|two|2006-6-08_21-16-25</td>\n",
       "      <td>kdiba|gor01|two|2006-6-08_21-16-25|8</td>\n",
       "      <td>2006-06-08 21:16:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-08_21-16-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199.718247</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.077781</td>\n",
       "      <td>1.673112</td>\n",
       "      <td>1.595331</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.945526</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|two|2006-6-08_21-16-25</td>\n",
       "      <td>kdiba|gor01|two|2006-6-08_21-16-25|16</td>\n",
       "      <td>2006-06-08 21:16:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-09_22-24-40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204.088605</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>1.119501</td>\n",
       "      <td>3.166389</td>\n",
       "      <td>2.046888</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.530170</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|two|2006-6-09_22-24-40</td>\n",
       "      <td>kdiba|gor01|two|2006-6-09_22-24-40|3</td>\n",
       "      <td>2006-06-09 22:24:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-09_22-24-40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128.088605</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.249559</td>\n",
       "      <td>1.225463</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.674209</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|two|2006-6-09_22-24-40</td>\n",
       "      <td>kdiba|gor01|two|2006-6-09_22-24-40|10</td>\n",
       "      <td>2006-06-09 22:24:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-09_22-24-40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186.088605</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.400991</td>\n",
       "      <td>0.779563</td>\n",
       "      <td>0.378572</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.636673</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|two|2006-6-09_22-24-40</td>\n",
       "      <td>kdiba|gor01|two|2006-6-09_22-24-40|11</td>\n",
       "      <td>2006-06-09 22:24:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-09_22-24-40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206.088605</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.543919</td>\n",
       "      <td>2.030858</td>\n",
       "      <td>1.486939</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>37</td>\n",
       "      <td>-0.537105</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|two|2006-6-09_22-24-40</td>\n",
       "      <td>kdiba|gor01|two|2006-6-09_22-24-40|37</td>\n",
       "      <td>2006-06-09 22:24:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-09_22-24-40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.088605</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.579931</td>\n",
       "      <td>6.210141</td>\n",
       "      <td>5.630210</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.838820</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|gor01|two|2006-6-09_22-24-40</td>\n",
       "      <td>kdiba|gor01|two|2006-6-09_22-24-40|80</td>\n",
       "      <td>2006-06-09 22:24:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-4-09_17-29-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171.543139</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.105414</td>\n",
       "      <td>0.294432</td>\n",
       "      <td>0.189018</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.700365</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|vvp01|one|2006-4-09_17-29-30</td>\n",
       "      <td>kdiba|vvp01|one|2006-4-09_17-29-30|31</td>\n",
       "      <td>2006-04-09 17:29:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-4-09_17-29-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.543139</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.174782</td>\n",
       "      <td>4.027836</td>\n",
       "      <td>3.853054</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.908626</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|vvp01|one|2006-4-09_17-29-30</td>\n",
       "      <td>kdiba|vvp01|one|2006-4-09_17-29-30|41</td>\n",
       "      <td>2006-04-09 17:29:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-4-10_12-25-50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.563733</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.017073</td>\n",
       "      <td>1.722406</td>\n",
       "      <td>1.705333</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.993878</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|vvp01|one|2006-4-10_12-25-50</td>\n",
       "      <td>kdiba|vvp01|one|2006-4-10_12-25-50|29</td>\n",
       "      <td>2006-04-10 12:25:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-02_17-46-44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201.927880</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.140151</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.738354</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.517280</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|pin01|one|11-02_17-46-44</td>\n",
       "      <td>kdiba|pin01|one|11-02_17-46-44|17</td>\n",
       "      <td>2009-11-02 17:46:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-02_17-46-44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>191.927880</td>\n",
       "      <td>RIGHT_ONLY</td>\n",
       "      <td>0.178177</td>\n",
       "      <td>1.136661</td>\n",
       "      <td>0.958484</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.626176</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kdiba|pin01|one|11-02_17-46-44</td>\n",
       "      <td>kdiba|pin01|one|11-02_17-46-44|40</td>\n",
       "      <td>2009-11-02 17:46:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    format_name animal exper_name        session_name  long_pf_peak_x  \\\n",
       "2         kdiba  gor01        one  2006-6-08_14-26-15             NaN   \n",
       "11        kdiba  gor01        one  2006-6-08_14-26-15             NaN   \n",
       "56        kdiba  gor01        one  2006-6-08_14-26-15             NaN   \n",
       "161       kdiba  gor01        one   2006-6-09_1-22-43             NaN   \n",
       "175       kdiba  gor01        one   2006-6-09_1-22-43             NaN   \n",
       "239       kdiba  gor01        one  2006-6-12_15-55-31             NaN   \n",
       "242       kdiba  gor01        one  2006-6-12_15-55-31             NaN   \n",
       "264       kdiba  gor01        two  2006-6-07_16-40-19             NaN   \n",
       "280       kdiba  gor01        two  2006-6-07_16-40-19             NaN   \n",
       "329       kdiba  gor01        two  2006-6-08_21-16-25             NaN   \n",
       "333       kdiba  gor01        two  2006-6-08_21-16-25             NaN   \n",
       "341       kdiba  gor01        two  2006-6-08_21-16-25             NaN   \n",
       "430       kdiba  gor01        two  2006-6-09_22-24-40             NaN   \n",
       "437       kdiba  gor01        two  2006-6-09_22-24-40             NaN   \n",
       "438       kdiba  gor01        two  2006-6-09_22-24-40             NaN   \n",
       "464       kdiba  gor01        two  2006-6-09_22-24-40             NaN   \n",
       "507       kdiba  gor01        two  2006-6-09_22-24-40             NaN   \n",
       "613       kdiba  vvp01        one  2006-4-09_17-29-30             NaN   \n",
       "623       kdiba  vvp01        one  2006-4-09_17-29-30             NaN   \n",
       "655       kdiba  vvp01        one  2006-4-10_12-25-50             NaN   \n",
       "762       kdiba  pin01        one      11-02_17-46-44             NaN   \n",
       "785       kdiba  pin01        one      11-02_17-46-44             NaN   \n",
       "\n",
       "     short_pf_peak_x track_membership  long_non_replay_mean  \\\n",
       "2         178.160000       RIGHT_ONLY              0.117397   \n",
       "11        224.160000       RIGHT_ONLY              0.383654   \n",
       "56        176.160000       RIGHT_ONLY              0.342354   \n",
       "161       183.586204       RIGHT_ONLY              0.216324   \n",
       "175       127.586204       RIGHT_ONLY              0.224789   \n",
       "239       195.300282       RIGHT_ONLY              0.042425   \n",
       "242       171.300282       RIGHT_ONLY              0.076103   \n",
       "264        89.397021       RIGHT_ONLY              0.181870   \n",
       "280       103.397021       RIGHT_ONLY              0.199305   \n",
       "329       197.718247       RIGHT_ONLY              0.185921   \n",
       "333       195.718247       RIGHT_ONLY              0.661418   \n",
       "341       199.718247       RIGHT_ONLY              0.077781   \n",
       "430       204.088605       RIGHT_ONLY              1.119501   \n",
       "437       128.088605       RIGHT_ONLY              0.249559   \n",
       "438       186.088605       RIGHT_ONLY              0.400991   \n",
       "464       206.088605       RIGHT_ONLY              0.543919   \n",
       "507       132.088605       RIGHT_ONLY              0.579931   \n",
       "613       171.543139       RIGHT_ONLY              0.105414   \n",
       "623        85.543139       RIGHT_ONLY              0.174782   \n",
       "655       112.563733       RIGHT_ONLY              0.017073   \n",
       "762       201.927880       RIGHT_ONLY              0.140151   \n",
       "785       191.927880       RIGHT_ONLY              0.178177   \n",
       "\n",
       "     short_non_replay_mean  non_replay_diff  ...  neuron_type  aclu  \\\n",
       "2                 0.834271         0.716874  ...          pyr     4   \n",
       "11                0.624830         0.241177  ...          pyr    13   \n",
       "56                1.075711         0.733356  ...          pyr    58   \n",
       "161               0.847278         0.630953  ...          pyr    55   \n",
       "175               0.620227         0.395438  ...          pyr    69   \n",
       "239               0.684426         0.642001  ...          pyr    30   \n",
       "242               0.555817         0.479714  ...          pyr    33   \n",
       "264               0.831176         0.649306  ...          pyr     3   \n",
       "280               1.253306         1.054000  ...          pyr    19   \n",
       "329               1.572612         1.386691  ...          pyr     4   \n",
       "333               2.549954         1.888536  ...          pyr     8   \n",
       "341               1.673112         1.595331  ...          pyr    16   \n",
       "430               3.166389         2.046888  ...          pyr     3   \n",
       "437               1.225463         0.975904  ...          pyr    10   \n",
       "438               0.779563         0.378572  ...          pyr    11   \n",
       "464               2.030858         1.486939  ...          pyr    37   \n",
       "507               6.210141         5.630210  ...          pyr    80   \n",
       "613               0.294432         0.189018  ...          pyr    31   \n",
       "623               4.027836         3.853054  ...          pyr    41   \n",
       "655               1.722406         1.705333  ...          pyr    29   \n",
       "762               0.878505         0.738354  ...          pyr    17   \n",
       "785               1.136661         0.958484  ...          pyr    40   \n",
       "\n",
       "     custom_frs_index  is_rate_extrema  is_refined_exclusive  is_refined_LxC  \\\n",
       "2           -0.981692             True                  True           False   \n",
       "11          -0.712649             True                  True           False   \n",
       "56          -0.513290             True                  True           False   \n",
       "161         -0.869149             True                  True           False   \n",
       "175         -0.587754             True                  True           False   \n",
       "239         -0.909655             True                  True           False   \n",
       "242         -0.867661             True                  True           False   \n",
       "264         -0.976095             True                  True           False   \n",
       "280         -0.940402             True                  True           False   \n",
       "329         -0.668623             True                  True           False   \n",
       "333         -0.666016             True                  True           False   \n",
       "341         -0.945526             True                  True           False   \n",
       "430         -0.530170             True                  True           False   \n",
       "437         -0.674209             True                  True           False   \n",
       "438         -0.636673             True                  True           False   \n",
       "464         -0.537105             True                  True           False   \n",
       "507         -0.838820             True                  True           False   \n",
       "613         -0.700365             True                  True           False   \n",
       "623         -0.908626             True                  True           False   \n",
       "655         -0.993878             True                  True           False   \n",
       "762         -0.517280             True                  True           False   \n",
       "785         -0.626176             True                  True           False   \n",
       "\n",
       "     is_refined_SxC                         session_uid  \\\n",
       "2              True  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "11             True  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "56             True  kdiba|gor01|one|2006-6-08_14-26-15   \n",
       "161            True   kdiba|gor01|one|2006-6-09_1-22-43   \n",
       "175            True   kdiba|gor01|one|2006-6-09_1-22-43   \n",
       "239            True  kdiba|gor01|one|2006-6-12_15-55-31   \n",
       "242            True  kdiba|gor01|one|2006-6-12_15-55-31   \n",
       "264            True  kdiba|gor01|two|2006-6-07_16-40-19   \n",
       "280            True  kdiba|gor01|two|2006-6-07_16-40-19   \n",
       "329            True  kdiba|gor01|two|2006-6-08_21-16-25   \n",
       "333            True  kdiba|gor01|two|2006-6-08_21-16-25   \n",
       "341            True  kdiba|gor01|two|2006-6-08_21-16-25   \n",
       "430            True  kdiba|gor01|two|2006-6-09_22-24-40   \n",
       "437            True  kdiba|gor01|two|2006-6-09_22-24-40   \n",
       "438            True  kdiba|gor01|two|2006-6-09_22-24-40   \n",
       "464            True  kdiba|gor01|two|2006-6-09_22-24-40   \n",
       "507            True  kdiba|gor01|two|2006-6-09_22-24-40   \n",
       "613            True  kdiba|vvp01|one|2006-4-09_17-29-30   \n",
       "623            True  kdiba|vvp01|one|2006-4-09_17-29-30   \n",
       "655            True  kdiba|vvp01|one|2006-4-10_12-25-50   \n",
       "762            True      kdiba|pin01|one|11-02_17-46-44   \n",
       "785            True      kdiba|pin01|one|11-02_17-46-44   \n",
       "\n",
       "                                neuron_uid    session_datetime  \n",
       "2     kdiba|gor01|one|2006-6-08_14-26-15|4 2006-06-08 14:26:15  \n",
       "11   kdiba|gor01|one|2006-6-08_14-26-15|13 2006-06-08 14:26:15  \n",
       "56   kdiba|gor01|one|2006-6-08_14-26-15|58 2006-06-08 14:26:15  \n",
       "161   kdiba|gor01|one|2006-6-09_1-22-43|55 2006-06-09 01:22:43  \n",
       "175   kdiba|gor01|one|2006-6-09_1-22-43|69 2006-06-09 01:22:43  \n",
       "239  kdiba|gor01|one|2006-6-12_15-55-31|30 2006-06-12 15:55:31  \n",
       "242  kdiba|gor01|one|2006-6-12_15-55-31|33 2006-06-12 15:55:31  \n",
       "264   kdiba|gor01|two|2006-6-07_16-40-19|3 2006-06-07 16:40:19  \n",
       "280  kdiba|gor01|two|2006-6-07_16-40-19|19 2006-06-07 16:40:19  \n",
       "329   kdiba|gor01|two|2006-6-08_21-16-25|4 2006-06-08 21:16:25  \n",
       "333   kdiba|gor01|two|2006-6-08_21-16-25|8 2006-06-08 21:16:25  \n",
       "341  kdiba|gor01|two|2006-6-08_21-16-25|16 2006-06-08 21:16:25  \n",
       "430   kdiba|gor01|two|2006-6-09_22-24-40|3 2006-06-09 22:24:40  \n",
       "437  kdiba|gor01|two|2006-6-09_22-24-40|10 2006-06-09 22:24:40  \n",
       "438  kdiba|gor01|two|2006-6-09_22-24-40|11 2006-06-09 22:24:40  \n",
       "464  kdiba|gor01|two|2006-6-09_22-24-40|37 2006-06-09 22:24:40  \n",
       "507  kdiba|gor01|two|2006-6-09_22-24-40|80 2006-06-09 22:24:40  \n",
       "613  kdiba|vvp01|one|2006-4-09_17-29-30|31 2006-04-09 17:29:30  \n",
       "623  kdiba|vvp01|one|2006-4-09_17-29-30|41 2006-04-09 17:29:30  \n",
       "655  kdiba|vvp01|one|2006-4-10_12-25-50|29 2006-04-10 12:25:50  \n",
       "762      kdiba|pin01|one|11-02_17-46-44|17 2009-11-02 17:46:44  \n",
       "785      kdiba|pin01|one|11-02_17-46-44|40 2009-11-02 17:46:44  \n",
       "\n",
       "[22 rows x 29 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_LxC_df = refined_only_neuron_replay_stats_table[refined_only_neuron_replay_stats_table['is_refined_LxC'].astype(bool)]\n",
    "refined_SxC_df = refined_only_neuron_replay_stats_table[refined_only_neuron_replay_stats_table['is_refined_SxC'].astype(bool)]\n",
    "refined_SxC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88a7303d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>long_pf_peak_x</th>\n",
       "      <th>short_pf_peak_x</th>\n",
       "      <th>track_membership</th>\n",
       "      <th>long_non_replay_mean</th>\n",
       "      <th>short_non_replay_mean</th>\n",
       "      <th>non_replay_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>neuron_type</th>\n",
       "      <th>aclu</th>\n",
       "      <th>custom_frs_index</th>\n",
       "      <th>is_rate_extrema</th>\n",
       "      <th>is_refined_exclusive</th>\n",
       "      <th>is_refined_LxC</th>\n",
       "      <th>is_refined_SxC</th>\n",
       "      <th>session_uid</th>\n",
       "      <th>neuron_uid</th>\n",
       "      <th>session_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>kdiba</td>\n",
       "      <td>gor01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-6-09_22-24-40</td>\n",
       "      <td>158.088605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LEFT_ONLY</td>\n",
       "      <td>3.477167</td>\n",
       "      <td>0.268164</td>\n",
       "      <td>-3.209002</td>\n",
       "      <td>...</td>\n",
       "      <td>pyr</td>\n",
       "      <td>95</td>\n",
       "      <td>0.579315</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>kdiba|gor01|two|2006-6-09_22-24-40</td>\n",
       "      <td>kdiba|gor01|two|2006-6-09_22-24-40|95</td>\n",
       "      <td>2006-06-09 22:24:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    format_name animal exper_name        session_name  long_pf_peak_x  \\\n",
       "522       kdiba  gor01        two  2006-6-09_22-24-40      158.088605   \n",
       "\n",
       "     short_pf_peak_x track_membership  long_non_replay_mean  \\\n",
       "522              NaN        LEFT_ONLY              3.477167   \n",
       "\n",
       "     short_non_replay_mean  non_replay_diff  ...  neuron_type  aclu  \\\n",
       "522               0.268164        -3.209002  ...          pyr    95   \n",
       "\n",
       "     custom_frs_index  is_rate_extrema  is_refined_exclusive  is_refined_LxC  \\\n",
       "522          0.579315             True                  True            True   \n",
       "\n",
       "     is_refined_SxC                         session_uid  \\\n",
       "522           False  kdiba|gor01|two|2006-6-09_22-24-40   \n",
       "\n",
       "                                neuron_uid    session_datetime  \n",
       "522  kdiba|gor01|two|2006-6-09_22-24-40|95 2006-06-09 22:24:40  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_LxC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1335497",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_LxC_aclus = refined_LxC_df['aclu'].to_numpy()\n",
    "refined_SxC_aclus = refined_SxC_df['aclu'].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8615ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "session_identifier_key: str = 'session_name'\n",
    "# session_identifier_key: str = 'session_datetime'\n",
    "\n",
    "## !IMPORTANT! Count of the fields of interest using .value_counts(...) and converting to an explicit pd.DataFrame:\n",
    "# _out_value_counts_df: pd.DataFrame = neuron_replay_stats_table.value_counts(subset=['format_name', 'animal', 'session_name', 'session_datetime','track_membership'], normalize=False, sort=False, ascending=True, dropna=True).reset_index()\n",
    "# _out_value_counts_df.columns = ['format_name', 'animal', 'session_name', 'session_datetime', 'track_membership', 'count']\n",
    "_out_value_counts_df: pd.DataFrame = neuron_replay_stats_table.value_counts(subset=['format_name', 'animal', 'session_name', 'session_datetime','track_membership'], normalize=False, sort=False, ascending=True, dropna=True).reset_index()\n",
    "_out_value_counts_df.columns = ['format_name', 'animal', 'session_name', 'session_datetime', 'track_membership', 'count']\n",
    "_out_value_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af57298",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the time of the first session for each animal:\n",
    "first_session_time  = _out_value_counts_df.groupby(['animal']).agg(session_datetime_first=('session_datetime', 'first')).reset_index()\n",
    "\n",
    "## Subtract this initial time from all of the 'session_datetime' entries for each animal:\n",
    "# Merge the first session time back into the original DataFrame\n",
    "merged_df = pd.merge(_out_value_counts_df, first_session_time, on='animal')\n",
    "\n",
    "# Subtract this initial time from all of the 'session_datetime' entries for each animal\n",
    "merged_df['time_since_first_session'] = merged_df['session_datetime'] - merged_df['session_datetime_first']\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25bb1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "point_size = 8\n",
    "df = _out_value_counts_df.copy()\n",
    "animals = df['animal'].unique()\n",
    "track_memberships = df['track_membership'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(animals), figsize=(15, 5))\n",
    "\n",
    "for i, animal in enumerate(animals):\n",
    "\tax = axes[i]\n",
    "\tsubset_df = df[df['animal'] == animal]\n",
    "\t\n",
    "\tfor track_membership in track_memberships:\n",
    "\t\ttrack_subset_df = subset_df[subset_df['track_membership'] == track_membership]\n",
    "\t\tax.plot(track_subset_df['session_datetime'], track_subset_df['count'], label=f'Track: {track_membership}')\n",
    "\t\tax.scatter(track_subset_df['session_datetime'], track_subset_df['count'], s=point_size)\n",
    "\t\t\n",
    "\tax.set_title(f'Animal: {animal}')\n",
    "\tax.set_xlabel('Session Datetime')\n",
    "\tax.set_ylabel('Count')\n",
    "\tax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94408ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_value_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784fcc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## See if the number of cells decreases over re-exposures to the track\n",
    "df = _out_value_counts_df[_out_value_counts_df['animal'] == 'gor01']\n",
    "# df = _out_value_counts_df[_out_value_counts_df['animal'] == 'pin01']\n",
    "# df = _out_value_counts_df[_out_value_counts_df['animal'] == 'vvp01']\n",
    "\n",
    "# Sort by column: 'session_datetime' (ascending)\n",
    "df = df.sort_values(['session_datetime'])\n",
    "\n",
    "'LEFT_ONLY'\n",
    "\n",
    "# df.to_clipboard(index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a502f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the number of cells in each session of the animal:\n",
    "num_LxCs = df[df['track_membership'] == 'LEFT_ONLY']['count'].to_numpy()\n",
    "num_Shared = df[df['track_membership'] == 'SHARED']['count'].to_numpy()\n",
    "num_SxCs = df[df['track_membership'] == 'RIGHT_ONLY']['count'].to_numpy()\n",
    "\n",
    "num_TotalCs = num_LxCs + num_Shared + num_SxCs\n",
    "num_TotalCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The only safe point to align each session to is the switchpoint (the delta):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046bbce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each session can be expressed in terms of time from the start of the first session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a3da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "long_short_fr_indicies_analysis_table = AcrossSessionTables.build_long_short_fr_indicies_analysis_table(included_session_contexts, included_h5_paths)\n",
    "long_short_fr_indicies_analysis_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4749ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neuron_identities_table = AcrossSessionTables.build_neuron_identities_table(included_session_contexts, included_h5_paths)\n",
    "neuron_identities_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e06675f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neuron_replay_stats_table = AcrossSessionTables.build_neuron_replay_stats_table(included_session_contexts, included_h5_paths)\n",
    "neuron_replay_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09034c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f99ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "\n",
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de182953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "included_h5_paths = [a_dir.joinpath('output','pipeline_results.h5').resolve() for a_dir in included_session_batch_progress_df['basedirs']]\n",
    "included_global_computation_h5_paths = [a_dir.joinpath('output','global_computations.h5').resolve() for a_dir in included_session_batch_progress_df['basedirs']] \n",
    "included_h5_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c02c97-a566-4e24-9219-6ee09a4075b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get only the sessions with non-None results\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "sessions_with_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e19412-2b21-4841-8207-952a04e1080b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session_identifiers = included_session_contexts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc1ac7-5771-4cd5-94c6-7a6244eb8217",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "source": [
    "## Extract output files from all completed sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb0cd9-3e60-4425-9351-dfc903f3f067",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphocorehelpers.Filesystem.path_helpers import convert_filelist_to_new_parent\n",
    "\n",
    "def save_filelist_to_text_file(hdf5_output_paths, filelist_path: Path):\n",
    "    _out_string = '\\n'.join([str(a_file) for a_file in hdf5_output_paths])\n",
    "    print(f'{_out_string}')\n",
    "    print(f'saving out to \"{filelist_path}\"...')\n",
    "    with open(filelist_path, 'w') as f:\n",
    "        f.write(_out_string)\n",
    "    return _out_string, filelist_path\n",
    "\n",
    "# Save output filelist:\n",
    "\n",
    "# '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5'\n",
    "\n",
    "# kdiba_vvp01_two_2006-4-10_12-58-3\n",
    "# \toutputs_local ={'pkl': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl')}\n",
    "# \toutputs_global ={'pkl': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl'), 'hdf5': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5')}\n",
    "session_identifiers, pkl_output_paths, hdf5_output_paths = global_batch_run.build_output_files_lists()\n",
    "\n",
    "h5_filelist_path = global_data_root_parent_path.joinpath(f'fileList_Greatlakes_HDF5_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, src_filelist_HDF5_savepath = save_filelist_to_text_file(hdf5_output_paths, h5_filelist_path)\n",
    "\n",
    "pkls_filelist_path = global_data_root_parent_path.joinpath(f'fileList_Greatlakes_pkls_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, src_filelist_pkls_savepath = save_filelist_to_text_file(pkl_output_paths, pkls_filelist_path)\n",
    "\n",
    "# source_parent_path = Path(r'/media/MAX/cloud/turbo/Data')\n",
    "source_parent_path = Path(r'/nfs/turbo/umms-kdiba/Data')\n",
    "dest_parent_path = Path(r'/~/W/Data/')\n",
    "# # Build the destination filelist from the source_filelist and the two paths:\n",
    "filelist_source = hdf5_output_paths\n",
    "filelist_dest_paths = convert_filelist_to_new_parent(filelist_source, original_parent_path=source_parent_path, dest_parent_path=dest_parent_path)\n",
    "filelist_dest_paths\n",
    "\n",
    "dest_Apogee_h5_filelist_path = global_data_root_parent_path.joinpath(f'dest_fileList_Apogee_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, dest_filelist_savepath = save_filelist_to_text_file(filelist_dest_paths, dest_Apogee_h5_filelist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e69a3",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult\n",
    "from neuropy.core.epoch import Epoch\n",
    "\n",
    "# Save to HDF5\n",
    "suffix = f'{BATCH_DATE_TO_USE}'\n",
    "## Build Pickle Path:\n",
    "file_path = global_data_root_parent_path.joinpath(f'global_batch_output_{suffix}.h5').resolve()\n",
    "file_path\n",
    "global_batch_run.to_hdf(file_path,'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ce774-98fb-4e69-a7e2-e94cbff1b0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get only the sessions with non-None results\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "\n",
    "# list(global_batch_run.session_batch_outputs.keys())\n",
    "\n",
    "# Somewhere in there there are `InstantaneousSpikeRateGroupsComputation` results to extract\n",
    "across_sessions_instantaneous_fr_dict = {} # InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "# good_session_batch_outputs = global_batch_run.session_batch_outputs\n",
    "\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "good_session_batch_outputs = {a_ctxt:a_result for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None}\n",
    "\n",
    "for a_ctxt, a_result in good_session_batch_outputs.items():\n",
    "    if a_result is not None:\n",
    "        # a_good_result = a_result.__dict__.get('across_sessions_batch_results', {}).get('inst_fr_comps', None)\n",
    "        a_good_result = a_result.across_session_results.get('inst_fr_comps', None)\n",
    "        if a_good_result is not None:\n",
    "            across_sessions_instantaneous_fr_dict[a_ctxt] = a_good_result\n",
    "            # print(a_result['across_sessions_batch_results']['inst_fr_comps'])\n",
    "            \n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "\n",
    "# When done, `result_handler.across_sessions_instantaneous_fr_dict` is now equivalent to what it would have been before. It can be saved using the normal `.save_across_sessions_data(...)`\n",
    "\n",
    "## Save the instantaneous firing rate results dict: (# Dict[IdentifyingContext] = InstantaneousSpikeRateGroupsComputation)\n",
    "AcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_instantaneous_fr_dict, global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl')\n",
    "\n",
    "# ## Save pickle:\n",
    "# inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "# global_batch_result_inst_fr_file_path = Path(global_data_root_parent_path).joinpath(inst_fr_output_filename).resolve() # Use Default\n",
    "# print(f'global_batch_result_inst_fr_file_path: {global_batch_result_inst_fr_file_path}')\n",
    "# # Save the all sessions instantaneous firing rate dict to the path:\n",
    "# saveData(global_batch_result_inst_fr_file_path, across_sessions_instantaneous_fr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d19a7-5a89-43f1-aa33-3a7450d1f965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "across_sessions_instantaneous_fr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e178426c-54df-47ac-8103-a66f114c77e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[a_ctxt.get_initialization_code_string() for a_ctxt in sessions_with_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28828512",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be651cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2023-07-14 - Load Saved across-sessions-data and testing Batch-computed inst_firing_rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "# from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "# from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import list_of_dicts_to_dict_of_lists\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "## Load the saved across-session results:\n",
    "# inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "# inst_fr_output_filename = 'across_session_result_long_short_inst_firing_rate.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-07-21.pkl'\n",
    "# inst_fr_output_filename=f'across_session_result_handler_{BATCH_DATE_TO_USE}.pkl'\n",
    "inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-08-09_Test.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a11886",
   "metadata": {},
   "outputs": [],
   "source": [
    "across_sessions_instantaneous_frs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hacks the `PaperFigureTwo` and `InstantaneousSpikeRateGroupsComputation` \n",
    "global_multi_session_context, _out_aggregate_fig_2 = AcrossSessionsVisualizations.across_sessions_bar_graphs(across_session_inst_fr_computation, num_sessions, enable_tiny_point_labels=False, enable_hover_labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381fcf5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "across_session_inst_fr_computation.LxC_scatter_props\n",
    "across_session_inst_fr_computation.SxC_scatter_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db1ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, InstantaneousFiringRatesDataframeAccessor, InstantaneousSpikeRateGroupsComputation, trackMembershipTypesEnum, trackExclusiveToMembershipTypeDict, trackExclusiveToMembershipTypeReverseDict\n",
    "\n",
    "## Specify the output file:\n",
    "common_file_path = Path('output/test_across_session_scatter_plot_new.h5')\n",
    "print(f'common_file_path: {common_file_path}')\n",
    "InstantaneousFiringRatesDataframeAccessor.add_results_to_inst_fr_results_table(curr_active_pipeline, common_file_path, file_mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45d728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the unique scatter plot dictionaries:\n",
    "across_session_contexts = list(across_sessions_instantaneous_fr_dict.keys())\n",
    "unique_animals = IdentifyingContext.find_unique_values(across_session_contexts)['animal'] # {'gor01', 'pin01', 'vvp01'}\n",
    "# Get number of animals to plot\n",
    "marker_list = [(5, i) for i in np.arange(len(unique_animals))] # [(5, 0), (5, 1), (5, 2)]\n",
    "scatter_props = [{'marker': mkr} for mkr in marker_list]  # Example, you should provide your own scatter properties\n",
    "scatter_props_dict = dict(zip(unique_animals, scatter_props))\n",
    "# {'pin01': {'marker': (5, 0)},\n",
    "#  'gor01': {'marker': (5, 1)},\n",
    "#  'vvp01': {'marker': (5, 2)}}\n",
    "scatter_props_dict\n",
    "\n",
    "# Pass a function that will return a set of kwargs for a given context\n",
    "def _return_scatter_props_fn(ctxt: IdentifyingContext):\n",
    "\t\"\"\" captures `scatter_props_dict` \"\"\"\n",
    "\tanimal_id = str(ctxt.animal)\n",
    "\treturn scatter_props_dict[animal_id]\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63258151",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=num_sessions) # some global context across all of the sessions, not sure what to put here.\n",
    "\n",
    "# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\n",
    "\n",
    "## Display the aggregate across sessions:\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn't save this info\n",
    "_out_fig_2.computation_result = across_session_inst_fr_computation # the result loaded from the file\n",
    "_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\n",
    "# Set callback, the only self-specific property\n",
    "# _out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)\n",
    "_out_fig_2.scatter_props_fn = _return_scatter_props_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LxC_aclus = _out_fig_2.computation_result.LxC_aclus\n",
    "SxC_aclus = _out_fig_2.computation_result.SxC_aclus\n",
    "\n",
    "LxC_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c498f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureOutputManager, FigureOutputLocation, ContextToPathMode\n",
    "\n",
    "registered_output_files = {}\n",
    "\n",
    "def output_figure(final_context: IdentifyingContext, fig, write_vector_format:bool=False, write_png:bool=True, debug_print=True):\n",
    "    \"\"\" outputs the figure using the provided context. \"\"\"\n",
    "    from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_and_write_to_file\n",
    "    def register_output_file(output_path, output_metadata=None):\n",
    "        \"\"\" registers a new output file for the pipeline \"\"\"\n",
    "        print(f'register_output_file(output_path: {output_path}, ...)')\n",
    "        registered_output_files[output_path] = output_metadata or {}\n",
    "\n",
    "    fig_out_man = FigureOutputManager(figure_output_location=FigureOutputLocation.DAILY_PROGRAMMATIC_OUTPUT_FOLDER, context_to_path_mode=ContextToPathMode.HIERARCHY_UNIQUE)\n",
    "    active_out_figure_paths = build_and_write_to_file(fig, final_context, fig_out_man, write_vector_format=write_vector_format, write_png=write_png, register_output_file_fn=register_output_file)\n",
    "    return active_out_figure_paths, final_context\n",
    "\n",
    "\n",
    "# Set callback, the only self-specific property\n",
    "_out_fig_2._pipeline_file_callback_fn = output_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17b920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\n",
    "\t\n",
    "_out_fig_2.perform_save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32781c8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Single Session testing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_out = global_batch_run.execute_session(session_context=curr_sess_context, force_reload=True, skip_extended_batch_computations=True, computation_functions_name_includelist =['_perform_baseline_placefield_computation'], active_session_computation_configs=None) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "_test_out\n",
    "\n",
    "# global_batch_run.execute_session(session_context=curr_sess_context, force_reload=True, skip_extended_batch_computations=True, **{'computation_functions_name_includelist': ['_perform_baseline_placefield_computation'], 'active_session_computation_configs': None}) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 23.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf2bb67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "full_good_dirs = [k for k, v in global_batch_run.session_batch_errors.items() if v is None]\n",
    "bad_dirs = [k for k, v in global_batch_run.session_batch_errors.items() if v is not None]\n",
    "full_good_dirs\n",
    "bad_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f73f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_batch_run.session_batch_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcad70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_run.session_batch_status\n",
    "global_batch_run.session_batch_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15faf2bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Get good sessions for use in the specific session processing notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed516134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf02efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get the list of sessions that are completely ready to process:\n",
    "full_good_ready_to_process_sessions = list(good_only_batch_progress_df['context'].to_numpy())\n",
    "full_good_ready_to_process_sessions\n",
    "# Get good sessions for use in the specific session processing notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ad809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run[\"good_sessions_list\"].extend(full_good_ready_to_process_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636e3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.stop()\n",
    "project.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf1322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\",\\n\".join([ctx.get_initialization_code_string() for ctx in full_good_ready_to_process_sessions])) # List definitions\n",
    "\n",
    "# [IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a4bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\ncurr_context = \".join([ctx.get_initialization_code_string() for ctx in full_good_ready_to_process_sessions])) # Line definitions\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5689d1d-6400-4f87-be0e-a184a1d5bee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82aedf-b024-4f07-b1a9-350730b4db8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "save_time = datetime.now()\n",
    " \n",
    "print(\"save_time =\", save_time)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = save_time.strftime(\"%Y-%m-%d_%I-%M%p\")\n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7bc6bd-5b34-41d0-b906-b0ad9927b08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get output file paths:\n",
    "completed_pipeline_filename = 'loadedSessPickle.pkl'\n",
    "completed_global_computations_filename = 'outputs/global_computation_results.pkl'\n",
    "\n",
    "full_good_ready_to_process_session_paths = list(good_only_batch_progress_df['basedirs'].to_numpy())\n",
    "session_paths_output_folders = [sess_path.joinpath('outputs').resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "\n",
    "completed_pipeline_file_paths = [sess_path.joinpath(completed_pipeline_filename).resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "completed_global_computations_file_paths = [sess_path.joinpath(completed_global_computations_filename).resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "completed_global_computations_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab75122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countable Additivity \n",
    "# Any countable collections of points is size 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af06e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
