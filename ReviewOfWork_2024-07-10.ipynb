{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:20.608442900Z",
     "start_time": "2023-11-16T23:21:20.217442100Z"
    },
    "collapsed": true,
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "doc_output_parent_folder: C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\DEVELOPER_NOTES\\DataStructureDocumentation\n",
      "DAY_DATE_STR: 2024-07-10, DAY_DATE_TO_USE: 2024-07-10\n",
      "NOW_DATETIME: 2024-07-10_0533PM, NOW_DATETIME_TO_USE: 2024-07-10_0533PM\n",
      "global_data_root_parent_path changed to W:\\Data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf73fa3a49c470e89355848142b17cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Data Root:', layout=Layout(width='auto'), options=(WindowsPath('W:/Data'),), style=ToggleButtonsStyle(button_width='max-content'), tooltip='global_data_root_parent_path', value=WindowsPath('W:/Data'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "# %xmode Verbose\n",
    "# %xmode context\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "# !pip install viztracer\n",
    "%load_ext viztracer\n",
    "from viztracer import VizTracer\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "import importlib\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "from attrs import define, field, fields, Factory, make_class\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "import builtins\n",
    "\n",
    "import IPython\n",
    "from IPython.core.formatters import PlainTextFormatter\n",
    "from IPython import get_ipython\n",
    "\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "# Jupyter-lab enable printing for any line on its own (instead of just the last one in the cell)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# BEGIN PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "\n",
    "## IPython pprint\n",
    "from pyphocorehelpers.pprint import wide_pprint, wide_pprint_ipython, wide_pprint_jupyter, MAX_LINE_LENGTH\n",
    "# Override default pprint\n",
    "builtins.pprint = wide_pprint\n",
    "\n",
    "from pyphocorehelpers.preferences_helpers import array_repr_with_graphical_shape, dataframe_show_more_button\n",
    "\n",
    "ip = get_ipython()\n",
    "\n",
    "# Register the custom display function for NumPy arrays\n",
    "# ip.display_formatter.formatters['text/html'].for_type(np.ndarray, lambda arr: array_preview_with_graphical_shape_repr_html(arr))\n",
    "ip = array_repr_with_graphical_shape(ip=ip)\n",
    "# ip = dataframe_show_more_button(ip=ip)\n",
    "\n",
    "text_formatter: PlainTextFormatter = ip.display_formatter.formatters['text/plain']\n",
    "text_formatter.max_width = MAX_LINE_LENGTH\n",
    "text_formatter.for_type(object, wide_pprint_jupyter)\n",
    "\n",
    "\n",
    "# END PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "from pyphocorehelpers.print_helpers import get_now_time_str, get_now_day_str\n",
    "from pyphocorehelpers.indexing_helpers import get_dict_subset\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path, file_uri_from_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "import pyphocorehelpers.programming_helpers as programming_helpers\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field, custom_define\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin, HDF_Converter\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_subsession_neuron_differences, debug_print_ratemap, debug_print_spike_counts, debug_plot_2d_binning, print_aligned_columns, parameter_sweeps, _plot_parameter_sweep, compare_placefields_info\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies, paired_incremental_sorting\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, document_active_variables\n",
    "\n",
    "## Pho Programming Helpers:\n",
    "import inspect\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter, TypePrintMode, print_keys_if_possible, debug_dump_object_member_shapes, print_value_overview_only, document_active_variables\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers, PythonDictionaryDefinitionFormat, MemoryManagement, inspect_callable_arguments, get_arguments_as_optional_dict, GeneratedClassDefinitionType, CodeConversion\n",
    "from pyphocorehelpers.notebook_helpers import NotebookCellExecutionLogger\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper, print_widget_hierarchy\n",
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative, dict_to_full_array\n",
    "\n",
    "doc_output_parent_folder: Path = Path('EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation').resolve() # ../.\n",
    "print(f\"doc_output_parent_folder: {doc_output_parent_folder}\")\n",
    "assert doc_output_parent_folder.exists()\n",
    "\n",
    "_notebook_path:Path = Path(IPythonHelpers.try_find_notebook_filepath(IPython.extract_module_locals())).resolve() # Finds the path of THIS notebook\n",
    "_notebook_execution_logger: NotebookCellExecutionLogger = NotebookCellExecutionLogger(notebook_path=_notebook_path, enable_logging_to_file=True) # Builds a logger that records info about this notebook\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_evaluate_required_computations, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphocorehelpers.exception_helpers import ExceptionPrintingContext, CapturedException\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsResult, TrackTemplates, DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions,  RankOrderComputationsContainer, RankOrderResult, RankOrderAnalyses\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ComputationFunctionRegistryHolder import ComputationFunctionRegistryHolder, computation_precidence_specifying_function, global_function\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle, SequenceBasedComputationsContainer\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "# %matplotlib inline\n",
    "# %matplotlib auto\n",
    "\n",
    "\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "# from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget, render_colors\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "\n",
    "DAY_DATE_STR: str = date.today().strftime(\"%Y-%m-%d\")\n",
    "DAY_DATE_TO_USE = f'{DAY_DATE_STR}' # used for filenames throught the notebook\n",
    "print(f'DAY_DATE_STR: {DAY_DATE_STR}, DAY_DATE_TO_USE: {DAY_DATE_TO_USE}')\n",
    "\n",
    "NOW_DATETIME: str = get_now_rounded_time_str()\n",
    "NOW_DATETIME_TO_USE = f'{NOW_DATETIME}' # used for filenames throught the notebook\n",
    "print(f'NOW_DATETIME: {NOW_DATETIME}, NOW_DATETIME_TO_USE: {NOW_DATETIME_TO_USE}')\n",
    "\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import build_global_data_root_parent_path_selection_widget\n",
    "all_paths = [Path('/Volumes/SwapSSD/Data'), Path('/Users/pho/data'), Path(r'/media/halechr/MAX/Data'), Path(r'/home/halechr/FastData'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/Users/pho/cloud/turbo/Data')] # Path('/Volumes/FedoraSSD/FastData'), \n",
    "global_data_root_parent_path = None\n",
    "def on_user_update_path_selection(new_path: Path):\n",
    "\tglobal global_data_root_parent_path\n",
    "\tnew_global_data_root_parent_path = new_path.resolve()\n",
    "\tglobal_data_root_parent_path = new_global_data_root_parent_path\n",
    "\tprint(f'global_data_root_parent_path changed to {global_data_root_parent_path}')\n",
    "\tassert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "\t\t\t\n",
    "global_data_root_parent_path_widget = build_global_data_root_parent_path_selection_widget(all_paths, on_user_update_path_selection)\n",
    "global_data_root_parent_path_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db844b",
   "metadata": {},
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f07773d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # 2024-04-30 - Completely cleaned.\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # Working wcorr_shuffle and trial_by_trial - DONE, might be the BEST SESSION, good example session with lots of place cells, clean replays, and clear bar graphs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays ---- VERY weird effect of the replays, a sharp drop to strongly negative values more than 3/4 through the experiment.\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD, 2023-07-14, unsure why still.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays! Interesting see-saw! #TODO 2024-07-05 23:07: - [ ] This was the one I processed\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE, Added replay selections. Very \"jumpy\" between the starts and ends of the track. 2024-07-10 DONE with custom replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # 2024-05-28 __ DEAD # 2024-01-10 new RANKORDER APOGEE | DONE, Added replay selections. A TON of putative replays in general, most bad, but some good. LOOKIN GOOD! 2024-07-10 DONE with custom replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='twolong_LR_pf1Dsession_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # BAD: Confirmed frequent jumping off of the track in this session. DONE, good. Many good pfs, many good replays. Noticed very strange jumping off the track in the 3D behavior/spikes viewer. Is there something wrong with this session?\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE, good?, replays selected, few  # BAD: Seems like in 3D view there's also jumping off of the track in this session.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE, very few replays\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3') ### KeyError: 'maze1_odd'\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5') ### \n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # NEWDONE, replays selected, quite a few replays but few are very good.\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25')\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# \n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5751ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_pkl_path = Path('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl').resolve()\n",
    "load_pkl_path = Path('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl').resolve()\n",
    "assert load_pkl_path.exists()\n",
    "basedir: Path = load_pkl_path.resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "proposed_load_pkl_path = deepcopy(load_pkl_path).resolve()\n",
    "custom_suffix: str = load_pkl_path.stem.split('loadedSessPickle_', maxsplit=1)[1] # '_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0'\n",
    "custom_suffix = '_' + custom_suffix\n",
    "print(f'custom_suffix: \"{custom_suffix}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21478b32",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "extended_computations_include_includelist=['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "     'ratemap_peaks_prominence2d',\n",
    "    'extended_stats',\n",
    "    'long_short_decoding_analyses',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    # 'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    # 'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'merged_directional_placefields',\n",
    "    'rank_order_shuffle_analysis',\n",
    "    # 'directional_train_test_split',\n",
    "    'directional_decoders_decode_continuous',\n",
    "    'directional_decoders_evaluate_epochs',\n",
    "    'directional_decoders_epoch_heuristic_scoring',\n",
    "    # 'perform_wcorr_shuffle_analysis',\n",
    "    'trial_by_trial_metrics',\n",
    "    # 'extended_pf_peak_information',\n",
    "] # do only specified\n",
    "force_recompute_override_computations_includelist = None\n",
    "# force_recompute_override_computations_includelist = ['merged_directional_placefields']\n",
    "# force_recompute_override_computations_includelist = ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis'] # , 'directional_decoders_decode_continuous'\n",
    "# force_recompute_override_computations_includelist = ['directional_decoders_decode_continuous'] # \n",
    "# force_recompute_override_computations_includelist = ['trial_by_trial_metrics']\n",
    "# force_recompute_override_computations_includelist = ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous'] # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70141a66",
   "metadata": {},
   "source": [
    "## 2024-06-25 - Load from saved custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679473aa",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# Loads custom pipeline pickles that were saved out via `custom_save_filepaths['pipeline_pkl'] = curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, active_pickle_filename=custom_save_filenames['pipeline_pkl'])`\n",
    "\n",
    "## INPUTS: global_data_root_parent_path, active_data_mode_name, basedir, saving_mode, force_reload, custom_save_filenames\n",
    "custom_suffix: str = '_withNewKamranExportedReplays'\n",
    "\n",
    "# custom_suffix: str = '_withNewComputedReplays'\n",
    "custom_suffix: str = '_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0'\n",
    "\n",
    "\n",
    "custom_save_filenames = {\n",
    "    'pipeline_pkl':f'loadedSessPickle{custom_suffix}.pkl',\n",
    "    'global_computation_pkl':f\"global_computation_results{custom_suffix}.pkl\",\n",
    "    'pipeline_h5':f'pipeline{custom_suffix}.h5',\n",
    "}\n",
    "print(f'custom_save_filenames: {custom_save_filenames}')\n",
    "custom_save_filepaths = {k:v for k, v in custom_save_filenames.items()}\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# PIPELINE LOADING                                                                                                     #\n",
    "# ==================================================================================================================== #\n",
    "# load the custom saved outputs\n",
    "active_pickle_filename = custom_save_filenames['pipeline_pkl'] # 'loadedSessPickle_withParameters.pkl'\n",
    "print(f'active_pickle_filename: \"{active_pickle_filename}\"')\n",
    "# assert active_pickle_filename.exists()\n",
    "active_session_h5_filename = custom_save_filenames['pipeline_h5'] # 'pipeline_withParameters.h5'\n",
    "print(f'active_session_h5_filename: \"{active_session_h5_filename}\"')\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "## DO NOT allow recompute if the file doesn't exist!!\n",
    "# Computing loaded session pickle file results : \"W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle_withNewComputedReplays.pkl\"... done.\n",
    "# Failure loading W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle_withNewComputedReplays.pkl.\n",
    "proposed_load_pkl_path = basedir.joinpath(active_pickle_filename).resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d10fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: proposed_load_pkl_path\n",
    "assert proposed_load_pkl_path.exists(), f\"for a saved custom the file must exist!\"\n",
    "\n",
    "epoch_name_includelist=None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination', 'pf_computation','firing_rate_trends', 'position_decoding']\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True, active_pickle_filename=proposed_load_pkl_path) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        if saving_mode == PipelineSavingScheme.SKIP_SAVING:\n",
    "            print(f'WARNING: PipelineSavingScheme.SKIP_SAVING but need to save post_compute_validate changes!!')\n",
    "        else:\n",
    "            curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except BaseException as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "print(f'Pipeline loaded from custom pickle!!')\n",
    "## OUTPUT: curr_active_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88868964",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Global computations loading:                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "# Loads saved global computations that were saved out via: `custom_save_filepaths['global_computation_pkl'] = curr_active_pipeline.save_global_computation_results(override_global_pickle_filename=custom_save_filenames['global_computation_pkl'])`\n",
    "## INPUTS: custom_save_filenames\n",
    "## INPUTS: curr_active_pipeline, override_global_computation_results_pickle_path, extended_computations_include_includelist\n",
    "\n",
    "override_global_computation_results_pickle_path = None\n",
    "# override_global_computation_results_pickle_path = custom_save_filenames['global_computation_pkl']\n",
    "print(f'override_global_computation_results_pickle_path: \"{override_global_computation_results_pickle_path}\"')\n",
    "\n",
    "# Pre-load ___________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Pre-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# valid_computed_results_output_list\n",
    "\n",
    "# Try Unpickling Global Computations to update pipeline ______________________________________________________________ #\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # INPUTS: override_global_computation_results_pickle_path\n",
    "        sucessfully_updated_keys, successfully_loaded_keys = curr_active_pipeline.load_pickled_global_computation_results(override_global_computation_results_pickle_path=override_global_computation_results_pickle_path,\n",
    "                                                                                        allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist, ) # is new\n",
    "        print(f'sucessfully_updated_keys: {sucessfully_updated_keys}\\nsuccessfully_loaded_keys: {successfully_loaded_keys}')\n",
    "    except FileNotFoundError as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results because pickle file does not exist! Maybe it has never been created? {e}')\n",
    "    except BaseException as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'Unhandled exception: cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "# Post-Load __________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "# Compute ____________________________________________________________________________________________________________ #\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# Post-compute _______________________________________________________________________________________________________ #\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=True)\n",
    "print(f'Post-compute validation: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98170b",
   "metadata": {},
   "source": [
    "## Normal Pipeline Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8167df1c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loaded session pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl\"... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:==========================================================================================\n",
      "========== Logger INIT \"2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43\" ==============================\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:NeuropyPipeline.__setstate__(state=\"{'pipeline_name': 'kdiba_pipeline', 'session_data_type': 'kdiba', '_stage': <pyphoplacecellanalysis.General.Pipeline.Stages.Display.DisplayPipelineStage object at 0x00000213B64564C0>}\")\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:select_filters(...) with: []\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_odd]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_odd]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_odd]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_even]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_even]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_even]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_any]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_any]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_any]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing global computations...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:select_filters(...) with: []\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_odd]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_odd]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_odd]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_logger(full_logger_string=\"2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43\", file_logging_dir: None):\n",
      "done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_even]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_even]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_even]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_any]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_any]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_any]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing global computations...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:select_filters(...) with: []\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_odd]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_odd]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_odd]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_even]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_even]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_even]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_any]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_any]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_any]` already exists and is non-None\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:Performing global computations...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:NeuropyPipeline.on_stage_changed(new_stage=\"PipelineStage.Displayed\")\n",
      "WARNING:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination', 'pf_computation',\n",
    "                                            #    'pfdt_computation',\n",
    "                                                'firing_rate_trends',\n",
    "                                                # 'pf_dt_sequential_surprise', \n",
    "                                            #    'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                # 'position_decoding_two_step', \n",
    "                                            #    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                            #     'long_short_inst_spike_rate_groups',\n",
    "                                            #     'long_short_endcap_analysis',\n",
    "                                            # 'split_to_directional_laps',\n",
    "]\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "\n",
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb47e03a",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation', 'ratemap_peaks_prominence2d', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'trial_by_trial_metrics'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "Pre-load global computations: needs_computation_output_dict: ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'trial_by_trial_metrics', 'long_short_decoding_analyses', 'short_long_pf_overlap_analyses', 'long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'lap_direction_determination', 'ratemap_peaks_prominence2d', 'extended_stats', 'pfdt_computation']\n"
     ]
    }
   ],
   "source": [
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Pre-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# valid_computed_results_output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28cf10d2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loaded session pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl\"... done.\n",
      "sucessfully_updated_keys: ['DirectionalLaps', 'DirectionalMergedDecoders', 'RankOrder', 'DirectionalDecodersDecoded', 'DirectionalDecodersEpochsEvaluations']\n",
      "successfully_loaded_keys: ['DirectionalLaps', 'DirectionalMergedDecoders', 'RankOrder', 'DirectionalDecodersDecoded', 'DirectionalDecodersEpochsEvaluations']\n"
     ]
    }
   ],
   "source": [
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # curr_active_pipeline.load_pickled_global_computation_results()\n",
    "        sucessfully_updated_keys, successfully_loaded_keys = curr_active_pipeline.load_pickled_global_computation_results(allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist) # is new\n",
    "        print(f'sucessfully_updated_keys: {sucessfully_updated_keys}\\nsuccessfully_loaded_keys: {successfully_loaded_keys}')\n",
    "    except FileNotFoundError as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results because pickle file does not exist! Maybe it has never been created? {e}')\n",
    "    except BaseException as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'Unhandled exception: cannot load global results: {e}')\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02cdcca0",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation', 'ratemap_peaks_prominence2d', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'trial_by_trial_metrics'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "WARNING: FIXME TODO 2024-05-08 08:20: - [ ] Disabled checking for 'combined_best_direction_indicies', which is missing from both the laps and ripple dataframes after fresh computation for some reason.\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "Post-load global computations: needs_computation_output_dict: ['split_to_directional_laps', 'trial_by_trial_metrics', 'long_short_decoding_analyses', 'short_long_pf_overlap_analyses', 'long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'lap_direction_determination', 'ratemap_peaks_prominence2d', 'extended_stats', 'pfdt_computation']\n"
     ]
    }
   ],
   "source": [
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e0fe66c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation', 'ratemap_peaks_prominence2d', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'trial_by_trial_metrics'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze_any\"\n",
      "lap_direction_determination missing.\n",
      "\t Recomputing lap_direction_determination...\n",
      "===>|> for filtered_session with filter named \"maze1_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x0000021392F3DD30>\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "ratemap_peaks_prominence2d missing.\n",
      "\t Recomputing ratemap_peaks_prominence2d...\n",
      "===>|> for filtered_session with filter named \"maze1_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:528: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = -1 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = {ybin_outer_extrema[0]} to matching_vertical_scan_y_idxs')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:522: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.891\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:533: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = 6 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = {ybin_outer_extrema[1]} to matching_vertical_scan_y_idxs')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:522: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:541: UserWarning: \tWARNING: peak_y_bin_idx (0) == ybin_indicies[0] (0): setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: peak_y_bin_idx ({peak_y_bin_idx}) == ybin_indicies[0] ({ybin_indicies[0]}): setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:528: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = -1 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = {ybin_outer_extrema[0]} to matching_vertical_scan_y_idxs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.8910495161195622\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.49502750895531233\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.8914204801222694\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.49523360006792744\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.891\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.8914306270153439\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:522: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:528: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = -1 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = {ybin_outer_extrema[0]} to matching_vertical_scan_y_idxs')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:533: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = 6 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = {ybin_outer_extrema[1]} to matching_vertical_scan_y_idxs')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:541: UserWarning: \tWARNING: peak_y_bin_idx (0) == ybin_indicies[0] (0): setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: peak_y_bin_idx ({peak_y_bin_idx}) == ybin_indicies[0] ({ybin_indicies[0]}): setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:528: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = -1 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = {ybin_outer_extrema[0]} to matching_vertical_scan_y_idxs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:522: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.8931068608807453\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.4961704782670807\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:522: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:541: UserWarning: \tWARNING: peak_y_bin_idx (0) == ybin_indicies[0] (0): setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: peak_y_bin_idx ({peak_y_bin_idx}) == ybin_indicies[0] ({ybin_indicies[0]}): setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:528: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = -1 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = {ybin_outer_extrema[0]} to matching_vertical_scan_y_idxs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.8912550089632353\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.49514167164624184\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:593: UserWarning: \tWARNING: len(matching_horizontal_scan_x_idxs) == 0: setting matching_horizontal_scan_x_idxs = (-1, 57)\n",
      "  warn(f'\\tWARNING: len(matching_horizontal_scan_x_idxs) == 0: setting matching_horizontal_scan_x_idxs = {xbin_outer_extrema}')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:522: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:528: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = -1 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = {ybin_outer_extrema[0]} to matching_vertical_scan_y_idxs')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:599: UserWarning: \tWARNING: len(matching_horizontal_scan_x_idxs) == 1: missing lower extrema, adding xbin_outer_extrema[0] = -1 to matching_horizontal_scan_x_idxs\n",
      "  warn(f'\\tWARNING: len(matching_horizontal_scan_x_idxs) == 1: missing lower extrema, adding xbin_outer_extrema[0] = {xbin_outer_extrema[0]} to matching_horizontal_scan_x_idxs')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:616: UserWarning: \tWARNING: peak_x_bin_idx (56) == xbin_indicies[-1] (56): setting matching_horizontal_scan_x_idxs = (-1, 57)\n",
      "  warn(f'\\tWARNING: peak_x_bin_idx ({peak_x_bin_idx}) == xbin_indicies[-1] ({xbin_indicies[-1]}): setting matching_horizontal_scan_x_idxs = {xbin_outer_extrema}')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:545: UserWarning: \tWARNING: peak_y_bin_idx (5) == ybin_indicies[-1] (5): setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: peak_y_bin_idx ({peak_y_bin_idx}) == ybin_indicies[-1] ({ybin_indicies[-1]}): setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.891\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.495\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.891\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.495\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.891\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.495\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:528: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = -1 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = {ybin_outer_extrema[0]} to matching_vertical_scan_y_idxs')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:522: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x0000021392F50D30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.8912549664438852\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:593: UserWarning: \tWARNING: len(matching_horizontal_scan_x_idxs) == 0: setting matching_horizontal_scan_x_idxs = (-1, 57)\n",
      "  warn(f'\\tWARNING: len(matching_horizontal_scan_x_idxs) == 0: setting matching_horizontal_scan_x_idxs = {xbin_outer_extrema}')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:522: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:528: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = -1 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = {ybin_outer_extrema[0]} to matching_vertical_scan_y_idxs')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:599: UserWarning: \tWARNING: len(matching_horizontal_scan_x_idxs) == 1: missing lower extrema, adding xbin_outer_extrema[0] = -1 to matching_horizontal_scan_x_idxs\n",
      "  warn(f'\\tWARNING: len(matching_horizontal_scan_x_idxs) == 1: missing lower extrema, adding xbin_outer_extrema[0] = {xbin_outer_extrema[0]} to matching_horizontal_scan_x_idxs')\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:545: UserWarning: \tWARNING: peak_y_bin_idx (5) == ybin_indicies[-1] (5): setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: peak_y_bin_idx ({peak_y_bin_idx}) == ybin_indicies[-1] ({ybin_indicies[-1]}): setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "extended_stats missing.\n",
      "\t Recomputing extended_stats...\n",
      "===>|> for filtered_session with filter named \"maze1_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x0000021392F57430>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "pfdt_computation missing.\n",
      "\t Recomputing pfdt_computation...\n",
      "===>|> for filtered_session with filter named \"maze1_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x0000021392F469D0>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "WARNING: FIXME TODO 2024-05-08 08:20: - [ ] Disabled checking for 'combined_best_direction_indicies', which is missing from both the laps and ripple dataframes after fresh computation for some reason.\n",
      "trial_by_trial_metrics missing.\n",
      "\t Recomputing trial_by_trial_metrics...\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_build_trial_by_trial_activity_metrics'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DirectionalPlacefieldGlobalComputationFunctions._build_trial_by_trial_activity_metrics at 0x0000021388D96CA0>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DirectionalPlacefieldGlobalComputationFunctions._build_trial_by_trial_activity_metrics at 0x000002142DBAEE50>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_long_short_decoding_analyses'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function LongShortTrackComputations._perform_long_short_decoding_analyses at 0x0000021399136670>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function LongShortTrackComputations._perform_long_short_decoding_analyses at 0x000002142DBAEE50>\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "`is_certain_properly_constrained`: True - Correctly initialized pipelines (pfs limited to laps, decoders already long/short constrainted by default, replays already the estimated versions\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\scipy\\spatial\\distance.py:1271: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(js / 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n_neurons = 66, n_all_epoch_timebins = 1618)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\scipy\\spatial\\distance.py:1271: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(js / 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n_neurons = 66, n_all_epoch_timebins = 1618)\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "short_long_pf_overlap_analyses missing.\n",
      "\t Recomputing short_long_pf_overlap_analyses...\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_long_short_pf_overlap_analyses'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function LongShortTrackComputations._perform_long_short_pf_overlap_analyses at 0x0000021399136820>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function LongShortTrackComputations._perform_long_short_pf_overlap_analyses at 0x000002153AE1D9D0>\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_long_short_firing_rate_analyses'], ...)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\MultiContextComputationFunctions\\LongShortTrackComputations.py:2810: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized_convolved_result_subset = convolved_result_subset / convolved_result_subset_area\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function LongShortTrackComputations._perform_long_short_firing_rate_analyses at 0x0000021399136940>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function LongShortTrackComputations._perform_long_short_firing_rate_analyses at 0x000002153AE19040>\n",
      "pipeline_complete_compute_long_short_fr_indicies is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "_generalized_compute_long_short_firing_rate_indicies(...): processing key: \"laps\"\n",
      "_generalized_compute_long_short_firing_rate_indicies(...): processing key: \"replays\"\n",
      "_generalized_compute_long_short_firing_rate_indicies(...): processing key: \"non_replays\"\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_jonathan_replay_firing_rate_analyses'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function LongShortTrackComputations._perform_jonathan_replay_firing_rate_analyses at 0x0000021399136A60>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function LongShortTrackComputations._perform_jonathan_replay_firing_rate_analyses at 0x00000214F26BA8B0>\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_long_short_post_decoding_analysis'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function LongShortTrackComputations._perform_long_short_post_decoding_analysis at 0x0000021399136B80>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function LongShortTrackComputations._perform_long_short_post_decoding_analysis at 0x00000214F26BA160>\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 4 = int(margin: 16 / pos_bin_size: 3.8054171165052444)\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 4 = int(margin: 16 / pos_bin_size: 3.8054171165052444)\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "long_short_inst_spike_rate_groups missing.\n",
      "\t Recomputing long_short_inst_spike_rate_groups...\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_long_short_instantaneous_spike_rate_groups_analysis'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function LongShortTrackComputations._perform_long_short_instantaneous_spike_rate_groups_analysis at 0x0000021399136CA0>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function LongShortTrackComputations._perform_long_short_instantaneous_spike_rate_groups_analysis at 0x000002153AE1DCA0>\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': None})\n",
      "global_computation_results.computation_config.instantaneous_time_bin_size_seconds is None!\n",
      "TEMP TODO: overriding since it is None.\n",
      "setting LxC_aclus/SxC_aclus from user annotation.\n",
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.01).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.01.\t224 remain.\n",
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.01).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.01.\t156 remain.\n",
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.01).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.01.\t224 remain.\n",
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.01).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.01.\t156 remain.\n",
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.01).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.01.\t44 remain.\n",
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.01).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.01.\t40 remain.\n",
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.01).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.01.\t44 remain.\n",
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.01).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.01.\t40 remain.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "long_short_endcap_analysis missing.\n",
      "\t Recomputing long_short_endcap_analysis...\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_long_short_endcap_analysis'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function LongShortTrackComputations._perform_long_short_endcap_analysis at 0x0000021399136DC0>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function LongShortTrackComputations._perform_long_short_endcap_analysis at 0x00000214F26BAD30>\n",
      "loaded_track_limits: {'long_xlim': array([59.0774, 228.69]), 'short_xlim': array([94.0156, 193.757]), 'long_ylim': array([138.164, 146.12]), 'short_ylim': array([138.021, 146.263])}\n",
      "num_disappearing_endcap_cells/num_total_endcap_cells: 0/28\n",
      "num_non_disappearing_endcap_cells/num_total_endcap_cells: 28/28\n",
      "num_significant_position_remappping_endcap_cells/num_non_disappearing_endcap_cells: 7/28\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('lap_direction_determination', 'maze_any'), ('ratemap_peaks_prominence2d', 'maze_any'), ('extended_stats', 'maze_any'), ('pfdt_computation', 'maze_any'), ('trial_by_trial_metrics', 'maze_any'), ('long_short_decoding_analyses', 'maze_any'), ('short_long_pf_overlap_analyses', 'maze_any'), ('long_short_fr_indicies_analyses', 'maze_any'), ('jonathan_firing_rate_analysis', 'maze_any'), ('long_short_post_decoding', 'maze_any'), ('long_short_inst_spike_rate_groups', 'maze_any'), ('long_short_endcap_analysis', 'maze_any')].\n",
      "\n",
      "\n",
      "!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"\n",
      "\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b4793f3",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation', 'ratemap_peaks_prominence2d', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'trial_by_trial_metrics'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "WARNING: FIXME TODO 2024-05-08 08:20: - [ ] Disabled checking for 'combined_best_direction_indicies', which is missing from both the laps and ripple dataframes after fresh computation for some reason.\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "Post-compute validation: needs_computation_output_dict: []\n"
     ]
    }
   ],
   "source": [
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=True)\n",
    "print(f'Post-compute validation: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5f755b",
   "metadata": {},
   "source": [
    "## Shared Post-Pipeline load stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "188ed6fa",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO CUSTOM SUFFIX.\n",
      "collected_outputs_path: K:\\scratch\\collected_outputs\n",
      "CURR_BATCH_OUTPUT_PREFIX: \"2024-07-10_Apogee-2006-6-09_1-22-43\"\n"
     ]
    }
   ],
   "source": [
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_GL'\n",
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_rMBP' # TODO: Change this as needed, templating isn't actually doing anything rn.\n",
    "BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_Apogee'\n",
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_Lab'\n",
    "\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        BATCH_DATE_TO_USE = f'{BATCH_DATE_TO_USE}{custom_suffix}'\n",
    "        print(f'Adding custom suffix: \"{custom_suffix}\" - BATCH_DATE_TO_USE: \"{BATCH_DATE_TO_USE}\"')\n",
    "except NameError as err:\n",
    "    custom_suffix = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "known_collected_output_paths = [Path(v).resolve() for v in ['/nfs/turbo/umms-kdiba/Data/Output/collected_outputs', '/home/halechr/FastData/collected_outputs/',\n",
    "                                                           '/home/halechr/cloud/turbo/Data/Output/collected_outputs',\n",
    "                                                           r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\output\\collected_outputs',\n",
    "                                                           '/Users/pho/data/collected_outputs',\n",
    "                                                          'output/gen_scripts/']]\n",
    "collected_outputs_path = find_first_extant_path(known_collected_output_paths)\n",
    "assert collected_outputs_path.exists(), f\"collected_outputs_path: {collected_outputs_path} does not exist! Is the right computer's config commented out above?\"\n",
    "# fullwidth_path_widget(scripts_output_path, file_name_label='Scripts Output Path:')\n",
    "print(f'collected_outputs_path: {collected_outputs_path}')\n",
    "# collected_outputs_path.mkdir(exist_ok=True)\n",
    "# assert collected_outputs_path.exists()\n",
    "\n",
    "## Build the output prefix from the session context:\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: \"{CURR_BATCH_OUTPUT_PREFIX}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e0148",
   "metadata": {},
   "source": [
    "## Specific Recomputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_most_recent_computation_time, each_epoch_latest_computation_time, each_epoch_each_result_computation_completion_times, (global_computations_latest_computation_time, global_computation_completion_times) = curr_active_pipeline.get_computation_times(debug_print=False)\n",
    "# each_epoch_latest_computation_time\n",
    "each_epoch_each_result_computation_completion_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c26bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload_exported_kdiba_session_position_info_mat_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import reload_exported_kdiba_session_position_info_mat_completion_function\n",
    "    \n",
    "# Results can be extracted from batch output by \n",
    "\n",
    "# Extracts the callback results 'determine_session_t_delta_completion_function':\n",
    "# extracted_callback_fn_results = {a_sess_ctxt:a_result.across_session_results.get('determine_session_t_delta_completion_function', {}) for a_sess_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None}\n",
    "\n",
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import compute_diba_quiescent_style_replay_events, overwrite_replay_epochs_and_recompute, try_load_neuroscope_EVT_file_epochs, replace_replay_epochs, _get_custom_suffix_for_replay_filename, finalize_output_shuffled_wcorr\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "a_dummy.should_suppress_errors = False\n",
    "\n",
    "## Settings:\n",
    "\n",
    "# SimpleBatchComputationDummy = make_class('SimpleBatchComputationDummy', attrs=['BATCH_DATE_TO_USE', 'collected_outputs_path'])\n",
    "# a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path)\n",
    "\n",
    "_temp_batch_results_extended_dict = {}\n",
    "## Combine the output of `reload_exported_kdiba_session_position_info_mat_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "_temp_batch_results_extended_dict = _temp_batch_results_extended_dict | reload_exported_kdiba_session_position_info_mat_completion_function(a_dummy, None,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tacross_session_results_extended_dict=_temp_batch_results_extended_dict,\n",
    "                                                # save_hdf=save_hdf, return_full_decoding_results=return_full_decoding_results,\n",
    "                                                # desired_shared_decoding_time_bin_sizes=desired_shared_decoding_time_bin_sizes,\n",
    "                                                )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d4f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd11d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_config.instantaneous_time_bin_size_seconds = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47820977",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_computations_include_includelist=['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "    #  'ratemap_peaks_prominence2d',\n",
    "    'extended_stats',\n",
    "    'long_short_decoding_analyses',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    # 'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    # 'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'merged_directional_placefields',\n",
    "    # 'rank_order_shuffle_analysis',\n",
    "    # 'directional_decoders_decode_continuous',\n",
    "    # 'directional_decoders_evaluate_epochs',\n",
    "    # 'directional_decoders_epoch_heuristic_scoring',\n",
    "] # do only specified\n",
    "\n",
    "# ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous']\n",
    "\n",
    "force_recompute_override_computations_includelist = [\n",
    "    'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',\n",
    "    'split_to_directional_laps', 'lap_direction_determination', 'DirectionalLaps',\n",
    "    'merged_directional_placefields',\n",
    "    'directional_decoders_decode_continuous',\n",
    "]\n",
    "# force_recompute_override_computations_includelist = None\n",
    "\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "newly_computed_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_recompute_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.reload_default_computation_functions()\n",
    "# force_recompute_override_computations_includelist = ['_decode_continuous_using_directional_decoders']\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_decode_continuous_using_directional_decoders'], force_recompute_override_computations_includelist=force_recompute_override_computations_includelist,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_decode_continuous_using_directional_decoders'], computation_kwargs_list=[{'time_bin_size': 0.025}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(extended_computations_include_includelist=['_decode_continuous_using_directional_decoders'], computation_kwargs_list=[{'time_bin_size': 0.02}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.20}, {'time_bin_size': 0.20}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.025}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "# 2024-04-20 - HACK -- FIXME: Invert the 'is_LR_dir' column since it is clearly reversed. No clue why.\n",
    "# fails due to some types thing?\n",
    "# \terr: Length of values (82) does not match length of index (80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f748deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_evaluate_epochs'], computation_kwargs_list=[{'should_skip_radon_transform': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe380f10",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_epoch_heuristic_scoring'], enabled_filter_names=None, fail_on_exception=True, debug_print=False) # OK FOR PICKLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f372737e",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39417243",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['lap_direction_determination'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89757a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['rank_order_shuffle_analysis'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2745bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['extended_stats', 'rank_order_shuffle_analysis'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['trial_by_trial_metrics'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da92d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['perform_wcorr_shuffle_analysis'], computation_kwargs_list=[{'num_shuffles': 50}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.2}, {'time_bin_size': 0.025}, {'should_skip_radon_transform': False}, {}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62493eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=[\n",
    "    'merged_directional_placefields', \n",
    "    'long_short_decoding_analyses', #'pipeline_complete_compute_long_short_fr_indicies',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    ], enabled_filter_names=None, fail_on_exception=True, debug_print=False) # , computation_kwargs_list=[{'should_skip_radon_transform': False}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed38171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData\n",
    "\n",
    "# directional_decoders_epochs_decode_result\n",
    "# save_path = Path(\"/Users/pho/data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-04-25_CustomDecodingResults.pkl\").resolve()\n",
    "# save_path = curr_active_pipeline.get_output_path().joinpath(\"2024-04-28_CustomDecodingResults.pkl\").resolve()\n",
    "save_path = curr_active_pipeline.get_output_path().joinpath(f\"{DAY_DATE_TO_USE}_CustomDecodingResults.pkl\").resolve()\n",
    "\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "xbin_centers = deepcopy(long_pf2D.xbin_centers)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "ybin_centers = deepcopy(long_pf2D.ybin_centers)\n",
    "\n",
    "print(xbin_centers)\n",
    "save_dict = {\n",
    "'directional_decoders_epochs_decode_result': directional_decoders_epochs_decode_result.__getstate__(),\n",
    "'xbin': xbin, 'xbin_centers': xbin_centers}\n",
    "\n",
    "saveData(save_path, save_dict)\n",
    "print(f'save_path: {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b4531",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# 💾 Export CSVs: \n",
    "## INPUTS: directional_decoders_epochs_decode_result,\n",
    "\n",
    "extracted_merged_scores_df = directional_decoders_epochs_decode_result.build_complete_all_scores_merged_df()\n",
    "# extracted_merged_scores_df\n",
    "\n",
    "print(f'\\tAll scores df CSV exporting...')\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "export_df_dict = {'ripple_all_scores_merged_df': extracted_merged_scores_df}\n",
    "_csv_export_paths = directional_decoders_epochs_decode_result.perform_export_dfs_dict_to_csvs(extracted_dfs_dict=export_df_dict, parent_output_path=collected_outputs_path.resolve(), active_context=active_context, session_name=curr_session_name, curr_session_t_delta=t_delta,\n",
    "                                                                            #   user_annotation_selections={'ripple': any_good_selected_epoch_times},\n",
    "                                                                            #   valid_epochs_selections={'ripple': filtered_valid_epoch_times},\n",
    "                                                                            )\n",
    "\n",
    "print(f'\\t\\tsuccessfully exported ripple_all_scores_merged_df to {collected_outputs_path}!')\n",
    "_output_csv_paths_info_str: str = '\\n'.join([f'{a_name}: \"{file_uri_from_path(a_path)}\"' for a_name, a_path in _csv_export_paths.items()])\n",
    "print(f'\\t\\t\\tCSV Paths: {_output_csv_paths_info_str}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a98fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extracted_merged_scores_df.to_csv('test_(ripple_all_scores_merged_df).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a860a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ripple_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_extras_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbf34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ripple_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_extras_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbcbb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_laps_simple_pf_pearson_merged_df\n",
    "# filtered_ripple_simple_pf_pearson_merged_df\n",
    "# decoder_ripple_weighted_corr_df_dict\n",
    "ripple_weighted_corr_merged_df['ripple_start_t']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a95450",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcorr_column_names = ['wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL']\n",
    "filtered_ripple_simple_pf_pearson_merged_df.label = filtered_ripple_simple_pf_pearson_merged_df.label.astype('int64')\n",
    "ripple_weighted_corr_merged_df['label'] = ripple_weighted_corr_merged_df['ripple_idx'].astype('int64')\n",
    "\n",
    "filtered_ripple_simple_pf_pearson_merged_df.join(ripple_weighted_corr_merged_df[wcorr_column_names], on='start') # , on='label'\n",
    "# filtered_ripple_simple_pf_pearson_merged_df.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac433aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(ripple_weighted_corr_merged_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "a_decoded_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3599f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window.save_selections()\n",
    "\n",
    "a_decoded_filter_epochs_decoder_result_dict.epochs.find_data_indicies_from_epoch_times([380.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77babf98",
   "metadata": {},
   "source": [
    "## 💾 Continue Saving/Exporting stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea89da89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'w+b') pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl\"... \tmoving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\20240710174705-global_computation_results.pkltmp' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\global_computation_results.pkl'\n",
      "saved pickle file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function NotebookCellExecutionLogger.register_callbacks.<locals>.post_run_cell at 0x00000213919AA5E0> (for post_run_cell), with arguments args (<ExecutionResult object at 214f27d8970, execution_count=11 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 214f27d8940, raw_cell=\"curr_active_pipeline.save_global_computation_resul..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2024-07-10.ipynb#Y105sZmlsZQ%3D%3D> result=WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl')>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'WindowsPath' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoCoreHelpers\\src\\pyphocorehelpers\\notebook_helpers.py:169\u001b[0m, in \u001b[0;36mNotebookCellExecutionLogger.register_callbacks.<locals>.post_run_cell\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    166\u001b[0m     exec_info\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;66;03m# Capture the output. A list of things\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# might be a list/tuple of strings\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m     exec_info\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_________________________________________________________________ \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mresult]) \u001b[38;5;66;03m# combine multiple outputs into a single cell\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug_print:\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCell executed in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_format_time(exec_info\u001b[38;5;241m.\u001b[39mduration)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'WindowsPath' object is not iterable"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.save_global_computation_results() # newly_computed_values: [('pfdt_computation', 'maze_any')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7af96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_save_folder, split_save_paths, split_save_output_types, failed_keys = curr_active_pipeline.save_split_global_computation_results(debug_print=True) # encountered issue with pickling `long_short_post_decoding`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_session_h5_filename = custom_save_filenames['pipeline_h5'] # 'pipeline_withParameters.h5'\n",
    "print(f'active_session_h5_filename: \"{active_session_h5_filename}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a869b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5(override_filename=active_session_h5_filename, fail_on_exception=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f06d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "837f39f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:save_pipeline(): Attempting to save pipeline to disk...\n",
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\tfinalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl\n",
      "Saving (file mode 'w+b') pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/20240710174736-loadedSessPickle.pkl\"... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:moving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\20240710174736-loadedSessPickle.pkl' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved pickle file\n",
      "moving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\20240710174736-loadedSessPickle.pkl' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_17-07-47.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t save complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function NotebookCellExecutionLogger.register_callbacks.<locals>.post_run_cell at 0x00000213919AA5E0> (for post_run_cell), with arguments args (<ExecutionResult object at 21739956dc0, execution_count=12 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 21739956e50, raw_cell=\"curr_active_pipeline.save_pipeline(saving_mode=Pip..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2024-07-10.ipynb#Y113sZmlsZQ%3D%3D> result=WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl')>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'WindowsPath' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoCoreHelpers\\src\\pyphocorehelpers\\notebook_helpers.py:169\u001b[0m, in \u001b[0;36mNotebookCellExecutionLogger.register_callbacks.<locals>.post_run_cell\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    166\u001b[0m     exec_info\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;66;03m# Capture the output. A list of things\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# might be a list/tuple of strings\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m     exec_info\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_________________________________________________________________ \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mresult]) \u001b[38;5;66;03m# combine multiple outputs into a single cell\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug_print:\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCell executed in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_format_time(exec_info\u001b[38;5;241m.\u001b[39mduration)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'WindowsPath' object is not iterable"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE) ## #TODO 2024-02-16 14:25: - [ ] PicklingError: Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x7fd35e66b700>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10989b4",
   "metadata": {},
   "source": [
    "#### Get computation times/info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31cab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_most_recent_computation_time, each_epoch_latest_computation_time, each_epoch_each_result_computation_completion_times, (global_computations_latest_computation_time, global_computation_completion_times) = curr_active_pipeline.get_computation_times(debug_print=False)\n",
    "# each_epoch_latest_computation_time\n",
    "# each_epoch_each_result_computation_completion_times\n",
    "# global_computation_completion_times\n",
    "\n",
    "# curr_active_pipeline.get_merged_computation_function_validators()\n",
    "# Get the names of the global and non-global computations:\n",
    "all_validators_dict = curr_active_pipeline.get_merged_computation_function_validators()\n",
    "global_only_validators_dict = {k:v for k, v in all_validators_dict.items() if v.is_global}\n",
    "non_global_only_validators_dict = {k:v for k, v in all_validators_dict.items() if (not v.is_global)}\n",
    "non_global_comp_names: List[str] = [v.short_name for k, v in non_global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))] # ['firing_rate_trends', 'spike_burst_detection', 'pf_dt_sequential_surprise', 'extended_stats', 'placefield_overlap', 'ratemap_peaks_prominence2d', 'velocity_vs_pf_simplified_count_density', 'EloyAnalysis', '_perform_specific_epochs_decoding', 'recursive_latent_pf_decoding', 'position_decoding_two_step', 'position_decoding', 'lap_direction_determination', 'pfdt_computation', 'pf_computation']\n",
    "global_comp_names: List[str] = [v.short_name for k, v in global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))] # ['long_short_endcap_analysis', 'long_short_inst_spike_rate_groups', 'long_short_post_decoding', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_decoding_analyses', 'PBE_stats', 'rank_order_shuffle_analysis', 'directional_decoders_epoch_heuristic_scoring', 'directional_decoders_evaluate_epochs', 'directional_decoders_decode_continuous', 'merged_directional_placefields', 'split_to_directional_laps']\n",
    "\n",
    "# mappings between the long computation function names and their short names:\n",
    "non_global_comp_names_map: Dict[str, str] = {v.computation_fn_name:v.short_name for k, v in non_global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))}\n",
    "global_comp_names_map: Dict[str, str] = {v.computation_fn_name:v.short_name for k, v in global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))} # '_perform_long_short_endcap_analysis': 'long_short_endcap_analysis', '_perform_long_short_instantaneous_spike_rate_groups_analysis': 'long_short_inst_spike_rate_groups', ...}\n",
    "\n",
    "# convert long function names to short-names:\n",
    "each_epoch_each_result_computation_completion_times = {an_epoch:{non_global_comp_names_map.get(k, k):v for k,v in a_results_dict.items()} for an_epoch, a_results_dict in each_epoch_each_result_computation_completion_times.items()}\n",
    "global_computation_completion_times = {global_comp_names_map.get(k, k):v for k,v in global_computation_completion_times.items()}\n",
    "\n",
    "each_epoch_each_result_computation_completion_times\n",
    "global_computation_completion_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967369f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_evaluate_required_computations\n",
    "\n",
    "# force_recompute_global = force_reload\n",
    "force_recompute_global = True\n",
    "active_probe_includelist = extended_computations_include_includelist\n",
    "# active_probe_includelist = ['lap_direction_determination']\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=active_probe_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "needs_computation_output_dict\n",
    "# valid_computed_results_output_list\n",
    "# remaining_include_function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ed3dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import SpecificComputationValidator, SpecificComputationResultsSpecification, DependencyGraph\n",
    "\n",
    "_comp_specifiers_dict: Dict[str, SpecificComputationValidator] = curr_active_pipeline.get_merged_computation_function_validators()\n",
    "_comp_specifiers_graph: DependencyGraph = DependencyGraph(_comp_specifiers_dict)\n",
    "_comp_specifiers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d9d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "_comp_specifiers_graph.visualize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d9d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downstream_dependents = graph.get_downstream_dependents('_build_merged_directional_placefields')\n",
    "# downstream_dependents = graph.get_downstream_dependents('_perform_jonathan_replay_firing_rate_analyses')\n",
    "# downstream_dependents = graph.get_downstream_dependents('jonathan_firing_rate_analysis')\n",
    "downstream_dependents = _comp_specifiers_graph.get_downstream_dependents('perform_wcorr_shuffle_analysis')\n",
    "# 'wcorr_shuffle_analysis'\n",
    "print(downstream_dependents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f56132",
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_requirements = _comp_specifiers_graph.get_upstream_requirements('perform_wcorr_shuffle_analysis')\n",
    "print(upstream_requirements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4b453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_downstream_dependents = []\n",
    "requirements_list = ['perform_wcorr_shuffle_analysis',  'perform_rank_order_shuffle_analysis',  'jonathan_firing_rate_analysis']\n",
    "for a_requirement in requirements_list:\n",
    "    downstream_dependents = graph.get_downstream_dependents(a_requirement)\n",
    "    all_downstream_dependents.extend(downstream_dependents)\n",
    "    \n",
    "# '_split_to_directional_laps'\n",
    "print(set(all_downstream_dependents))\n",
    "# print(downstream_dependents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_computed_results_output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9aeeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "['merged_directional_placefields', ]\n",
    "\n",
    "['long_short_decoding_analyses', 'long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'extended_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probe_fn_name = 'long_short_decoding_analyses'\n",
    "# probe_fn_name = 'long_short_fr_indicies_analyses'\n",
    "\n",
    "# found_validator = None\n",
    "# provided_global_keys = []\n",
    "# remaining_comp_specifiers_dict = deepcopy(_comp_specifiers_dict)\n",
    "\n",
    "# for a_name, a_validator in remaining_comp_specifiers_dict.items():\n",
    "#     if a_validator.does_name_match(probe_fn_name):\n",
    "#         found_validator = a_validator\n",
    "#         print(f'found matching validator: {found_validator}')\n",
    "#     else:\n",
    "#         remaining_comp_specifiers_dict[a_name] = a_validator\n",
    "\n",
    "# if found_validator is not None:\n",
    "#     provided_global_keys = found_validator.results_specification.provides_global_keys\n",
    "#     print(f'provided_global_keys: {provided_global_keys}')\n",
    "# else:\n",
    "#     provided_global_keys = []\n",
    "\n",
    "# provided_global_keys\n",
    "## OUTPUTS: remaining_comp_specifiers_dict, found_validator, provided_global_keys\n",
    "\n",
    "\n",
    "remaining_comp_specifiers_dict = deepcopy(_comp_specifiers_dict)\n",
    "remaining_comp_specifiers_dict, found_matching_validators, provided_global_keys = SpecificComputationValidator.find_matching_validators(remaining_comp_specifiers_dict=remaining_comp_specifiers_dict,\n",
    "                                                                                    probe_fn_names=['long_short_decoding_analyses','long_short_fr_indicies_analyses'])\n",
    "\n",
    "provided_global_keys\n",
    "\n",
    "## INPUTS: remaining_comp_specifiers_dict, found_validator, provided_global_keys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "remaining_comp_specifiers_dict, dependent_validators, provided_global_keys = SpecificComputationValidator.find_immediate_dependencies(remaining_comp_specifiers_dict=remaining_comp_specifiers_dict, provided_global_keys=provided_global_keys)\n",
    "provided_global_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f3094",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_comp_specifiers_dict, dependent_validators, provided_global_keys = SpecificComputationValidator.find_immediate_dependencies(remaining_comp_specifiers_dict=remaining_comp_specifiers_dict, provided_global_keys=provided_global_keys)\n",
    "provided_global_keys # ['long_short_leave_one_out_decoding_analysis', 'long_short_post_decoding']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59374622",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85822a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_estimation_parameters = curr_active_pipeline.sess.config.preprocessing_parameters.epoch_estimation_parameters.replays\n",
    "assert replay_estimation_parameters is not None\n",
    "replay_estimation_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3799ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recompute_earlier_than_date = datetime(2024, 4, 1, 0, 0, 0)\n",
    "recompute_earlier_than_date\n",
    "\n",
    "each_epoch_needing_recompute = [an_epoch for an_epoch, last_computed_datetime in each_epoch_latest_computation_time.items() if (last_computed_datetime < recompute_earlier_than_date)]\n",
    "each_epoch_needing_recompute\n",
    "each_epoch_each_result_needing_recompute = {an_epoch:{a_computation_name:last_computed_datetime for a_computation_name, last_computed_datetime in last_computed_datetimes_dict.items() if (last_computed_datetime < recompute_earlier_than_date)} for an_epoch, last_computed_datetimes_dict in each_epoch_each_result_computation_completion_times.items()}\n",
    "each_epoch_each_result_needing_recompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ffa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_times\n",
    "curr_active_pipeline.global_computation_results\n",
    "# curr_active_pipeline.try_load_split_pickled_global_computation_results\n",
    "\n",
    "global_computation_times = deepcopy(curr_active_pipeline.global_computation_results.computation_times.to_dict()) # DynamicParameters({'perform_rank_order_shuffle_analysis': datetime.datetime(2024, 4, 3, 5, 41, 31, 287680), '_decode_continuous_using_directional_decoders': datetime.datetime(2024, 4, 3, 5, 12, 7, 337326), '_perform_long_short_decoding_analyses': datetime.datetime(2024, 4, 3, 5, 43, 10, 361685), '_perform_long_short_pf_overlap_analyses': datetime.datetime(2024, 4, 3, 5, 43, 10, 489296), '_perform_long_short_firing_rate_analyses': datetime.datetime(2024, 4, 3, 5, 45, 3, 73472), '_perform_jonathan_replay_firing_rate_analyses': datetime.datetime(2024, 4, 3, 5, 45, 5, 168790), '_perform_long_short_post_decoding_analysis': datetime.datetime(2024, 2, 16, 18, 13, 4, 734621), '_perform_long_short_endcap_analysis': datetime.datetime(2024, 4, 3, 5, 45, 24, 274261), '_decode_and_evaluate_epochs_using_directional_decoders': datetime.datetime(2024, 4, 3, 5, 14, 37, 935482), '_perform_long_short_instantaneous_spike_rate_groups_analysis': datetime.datetime(2024, 4, 3, 5, 45, 24, 131955), '_split_to_directional_laps': datetime.datetime(2024, 4, 3, 5, 11, 22, 627789), '_build_merged_directional_placefields': datetime.datetime(2024, 4, 3, 5, 11, 28, 376078)})\n",
    "global_computation_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693db067",
   "metadata": {},
   "source": [
    "# Pho Interactive Pipeline Jupyter Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275e3bb",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "\n",
    "_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\n",
    "# display(_pipeline_jupyter_widget)\n",
    "_pipeline_jupyter_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe54599",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a533ba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:40.700275900Z",
     "start_time": "2023-11-16T23:21:40.584273Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1029.316608761903, 1737.1968310000375)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "\n",
    "assert short_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "assert long_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "t_start, t_delta, t_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e348e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_merged_decoders_result = deepcopy(directional_decoders_epochs_decode_result)\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "spikes_df = deepcopy(curr_active_pipeline.sess.spikes_df)\n",
    "\n",
    "global_computation_results = curr_active_pipeline.global_computation_results\n",
    "\n",
    " # spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "rank_order_results = global_computation_results.computed_data['RankOrder'] # : \"RankOrderComputationsContainer\"\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "# included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "directional_laps_results: DirectionalLapsResult = global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "# print(f'included_qclu_values: {included_qclu_values}')\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "# pos_bin_size = _recover_position_bin_size(track_templates.get_decoders()[0]) # 3.793023081021702\n",
    "# print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "# pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "\n",
    "## Simple Pearson Correlation\n",
    "assert spikes_df is not None\n",
    "(laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names = directional_merged_decoders_result.compute_simple_spike_time_v_pf_peak_x_by_epoch(track_templates=track_templates, spikes_df=deepcopy(spikes_df))\n",
    "## OUTPUTS: (laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names\n",
    "## Computes the highest-valued decoder for this score:\n",
    "best_decoder_index_col_name: str = 'best_decoder_index'\n",
    "laps_simple_pf_pearson_merged_df[best_decoder_index_col_name] = laps_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n",
    "ripple_simple_pf_pearson_merged_df[best_decoder_index_col_name] = ripple_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eed3e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 136\n",
      "pos_bin_size: 3.8054171165052444\n",
      "ripple_decoding_time_bin_size: 0.025\n",
      "laps_decoding_time_bin_size: 0.25\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "print(f'pos_bin_size: {pos_bin_size}')\n",
    "print(f'ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}')\n",
    "\n",
    "# Radon Transforms:\n",
    "decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "# Weighted correlations:\n",
    "laps_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "ripple_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "decoder_laps_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "decoder_ripple_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "# Pearson's correlations:\n",
    "laps_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "ripple_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# laps_simple_pf_pearson_merged_df\n",
    "# ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "## Drop rows where all are missing\n",
    "corr_column_names = ['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr']\n",
    "# ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='all') # 350/412 rows\n",
    "filtered_laps_simple_pf_pearson_merged_df: pd.DataFrame = laps_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "filtered_ripple_simple_pf_pearson_merged_df: pd.DataFrame = ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "\n",
    "## Update the `decoder_ripple_filter_epochs_decoder_result_dict` with the included epochs:\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_ripple_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_laps_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92b35196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Context(format_name: 'kdiba', animal: 'gor01', exper_name: 'one', session_name: '2006-6-09_1-22-43')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006-6-09_1-22-43:\tt_start: 0.0, t_delta: 1029.316608761903, t_end: 1737.1968310000375\n"
     ]
    }
   ],
   "source": [
    "# I have several python variables I want to print: t_start, t_delta, t_end\n",
    "# I want to generate a print statement that explicitly lists the variable name prior to its value like `print(f't_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')`\n",
    "# Currently I have to t_start, t_delta, t_end\n",
    "curr_active_pipeline.get_session_context()\n",
    "\n",
    "print(f'{curr_active_pipeline.session_name}:\\tt_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9071e94f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:43.601382Z",
     "start_time": "2023-11-16T23:21:40.702275600Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "WARNING: PAPER_FIGURE_figure_1_add_replay_epoch_rasters(...): no user-assigned manually labeled replay epochs. Reeturning all epochs.\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n"
     ]
    }
   ],
   "source": [
    "## long_short_decoding_analyses:\n",
    "from attrs import astuple\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import LeaveOneOutDecodingAnalysis\n",
    "\n",
    "curr_long_short_decoding_analyses: LeaveOneOutDecodingAnalysis = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global \n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "## Get global `long_short_fr_indicies_analysis`:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n",
    "long_short_fr_indicies_df = long_short_fr_indicies_analysis_results['long_short_fr_indicies_df']\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result.Flat_epoch_time_bins_mean, expected_v_observed_result.Flat_decoder_time_bin_centers, expected_v_observed_result.num_neurons, expected_v_observed_result.num_timebins_in_epoch, expected_v_observed_result.num_total_flat_timebins, expected_v_observed_result.is_short_track_epoch, expected_v_observed_result.is_long_track_epoch, expected_v_observed_result.short_short_diff, expected_v_observed_result.long_long_diff\n",
    "\n",
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.05)\n",
    "\n",
    "## Update long_exclusive/short_exclusive properties with `long_short_fr_indicies_df`\n",
    "# long_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n",
    "# short_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c49f5d4f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Most popular\n",
    "# long_LR_name, short_LR_name, long_RL_name, short_RL_name, global_any_name\n",
    "\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7104fc37",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum_inclusion_fr_Hz: 5.0\n",
      "included_qclu_values: [1, 2]\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult, DirectionalLapsResult, DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']   \n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "included_qclu_values: float = rank_order_results.included_qclu_values\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93346114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.BatchCompletionHandler import BatchSessionCompletionHandler\n",
    "\n",
    "BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0617e7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maze1_odd', 'maze1_even', 'maze2_odd', 'maze2_even']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(directional_laps_results.directional_lap_specific_configs.keys()) # ['maze1_odd', 'maze1_even', 'maze2_odd', 'maze2_even']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "912656a7",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 136\n",
      "pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.25\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "\n",
    "\n",
    "if ('DirectionalDecodersEpochsEvaluations' in curr_active_pipeline.global_computation_results.computed_data) and (curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] is not None):\n",
    "    directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "    directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "    ## UNPACK HERE via direct property access:\n",
    "    pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "    ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "    laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "    print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "    decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "    decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "    # New items:\n",
    "    decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "    decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "    # Weighted correlations:\n",
    "    laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "    ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "    decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "    # Pearson's correlations:\n",
    "    laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "    ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06f1c291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          start         stop label  duration  lap_id  lap_dir     score   velocity     intercept      speed     wcorr  P_decoder  pearsonr    travel  coverage      jump  sequential_correlation  monotonicity_score  laplacian_smoothness  longest_sequence_length  longest_sequence_length_ratio  direction_change_bin_ratio  congruent_dir_bins_ratio  total_congruent_direction_change  total_variation  integral_second_derivative  stddev_of_diff\n",
       "0      3.054774     4.723224     0  1.668450       1        1  0.318741   6.088667    263.833209   6.088667 -0.053230   0.315984  0.212939  0.380542  0.210526  0.004423           231177.867710       231177.867710         231177.867710                        3                       0.500000                    0.400000                  0.400000                        205.492524       407.179631               160046.216107      107.509600\n",
       "1      6.356765     8.926857     1  2.570092       2        0  0.409887   1.691296    236.408123   1.691296 -0.131103   0.256594  0.237919  0.199557  0.245614  0.003588           191673.155663       191673.155663         191673.155663                        3                       0.300000                    0.555556                  0.444444                        194.076273       384.347129               151053.391260       72.966263\n",
       "2     45.195989    50.869954     2  5.673965       3        1  0.369115  56.537626   2810.619154  56.537626 -0.813306   0.704480 -0.592649  0.088065  0.438596  0.002253            71710.899580        71710.899580          71710.899580                       15                       0.681818                    0.142857                  0.714286                        209.297941       395.763380                15552.808188       29.197929\n",
       "3     65.785018    72.223040     3  6.438022       4        0  0.352251  -6.342362   -207.801316   6.342362  0.770223   0.025573  0.618741  0.110399  0.333333  0.003087           205227.558329       205227.558329         205227.558329                       13                       0.520000                    0.291667                  0.541667                        300.627952       567.007150               149619.752517       46.214182\n",
       "4     84.303384    91.044238     4  6.740854       5        1  0.373533  46.510654   4237.041100  46.510654 -0.968565   0.953580 -0.805770  0.036987  0.263158  0.000668            11932.508331        11932.508331          11932.508331                       26                       1.000000                    0.000000                  0.720000                        194.076273       197.881690                 2418.360305        7.835833\n",
       "5    106.425978   112.964646     5  6.538668       6        0  0.391206  -6.697534   -503.404943   6.697534  0.652650   0.000192  0.649980  0.182091  0.263158  0.003838           505567.634518       505567.634518         505567.634518                        9                       0.346154                    0.280000                  0.520000                        502.315059       974.186782               393671.406521       71.092851\n",
       "..          ...          ...   ...       ...     ...      ...       ...        ...           ...        ...       ...        ...       ...       ...       ...       ...                     ...                 ...                   ...                      ...                            ...                         ...                       ...                               ...              ...                         ...             ...\n",
       "78  1604.668520  1607.804303    78  3.135783      79        1  0.418169   6.918940  11207.142606   6.918940 -0.670182   0.068023 -0.429530  0.079212  0.280702  0.001085            25776.534987        25776.534987          25776.534987                        8                       0.666667                    0.090909                  0.636364                        133.189599       186.465439                 9282.448835       23.087914\n",
       "79  1608.839610  1614.145200    79  5.305590      80        0  0.348563 -10.655168 -16944.980490  10.655168  0.837460   0.002026  0.616301  0.112918  0.263158  0.003922           187734.269423       187734.269423         187734.269423                        8                       0.380952                    0.200000                  0.450000                        342.487540       483.287974                96285.495014       47.381264\n",
       "80  1620.117294  1625.623997    80  5.506703      81        1  0.255322  -2.899365  -4529.310202   2.899365 -0.792317   0.076975 -0.510064  0.115162  0.350877  0.001669            88509.090922        88509.090922          88509.090922                        6                       0.272727                    0.380952                  0.476190                        346.292958       517.536728                44341.432656       31.371901\n",
       "81  1628.792203  1632.596083    81  3.803880      82        0  0.407147   2.174524   3794.203117   2.174524  0.719747   0.002673  0.484013  0.129557  0.210526  0.004089           175164.588317       175164.588317         175164.588317                        5                       0.333333                    0.214286                  0.500000                        296.822535       388.152546                55072.001435       53.967530\n",
       "82  1645.812118  1652.718007    82  6.905889      83        1  0.267771   1.756346   3116.281205   1.756346 -0.903985   0.090393 -0.550924  0.103958  0.263158  0.001335            96734.412199        96734.412199          96734.412199                        5                       0.185185                    0.384615                  0.500000                        384.347129       578.423402                66743.848176       29.607159\n",
       "83  1652.750230  1658.090188    83  5.339958      84        0  0.343285  -5.327584  -8584.191448   5.327584  0.795938   0.002503  0.621650  0.200940  0.263158  0.004089           360871.489819       360871.489819         360871.489819                       10                       0.476190                    0.350000                  0.500000                        509.925894       860.024268               256215.861525       66.686067\n",
       "\n",
       "[84 rows x 27 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "881402df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_config_name: str = 'maze_any'\n",
    "active_config_name: str = global_epoch_name\n",
    "## INPUTS: curr_active_pipeline, active_config_name\n",
    "active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "if active_peak_prominence_2d_results is None:\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=None, fail_on_exception=False, debug_print=False)\n",
    "    # curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=[short_LR_name, short_RL_name, long_any_name, short_any_name], fail_on_exception=False, debug_print=False) # or at least\n",
    "    active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "    assert active_peak_prominence_2d_results is not None, f\"bad even after computation\"\n",
    "\n",
    "# active_peak_prominence_2d_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "238f67cb",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previously_decoded time_bin_sizes: [0.025]\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "if 'DirectionalDecodersDecoded' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "    all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "    spikes_df = directional_decoders_decode_result.spikes_df\n",
    "    continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "    previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "    print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7b4e959",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceBased is not computed.\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle, SequenceBasedComputationsContainer\n",
    "\n",
    "wcorr_shuffle_results: SequenceBasedComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('SequenceBased', None)\n",
    "if wcorr_shuffle_results is not None:    \n",
    "    wcorr_ripple_shuffle: WCorrShuffle = wcorr_shuffle_results.wcorr_ripple_shuffle\n",
    "    print(f'wcorr_ripple_shuffle.n_completed_shuffles: {wcorr_ripple_shuffle.n_completed_shuffles}')\n",
    "else:\n",
    "    print(f'SequenceBased is not computed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fba865e4",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrialByTrialActivityResult\n",
    "\n",
    "directional_trial_by_trial_activity_result: TrialByTrialActivityResult = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None)\n",
    "\n",
    "if directional_trial_by_trial_activity_result is not None:\n",
    "    any_decoder_neuron_IDs = directional_trial_by_trial_activity_result.any_decoder_neuron_IDs\n",
    "    active_pf_dt: PfND_TimeDependent = directional_trial_by_trial_activity_result.active_pf_dt\n",
    "    directional_lap_epochs_dict: Dict[str, Epoch] = directional_trial_by_trial_activity_result.directional_lap_epochs_dict\n",
    "    directional_active_lap_pf_results_dicts: Dict[str, TrialByTrialActivity] = directional_trial_by_trial_activity_result.directional_active_lap_pf_results_dicts\n",
    "    ## OUTPUTS: directional_trial_by_trial_activity_result, directional_active_lap_pf_results_dicts\n",
    "else:\n",
    "    print(f'TrialByTrialActivity is not computed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3ed0870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_bin_size: 0.025\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "most_recent_time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# most_recent_time_bin_size\n",
    "most_recent_continuously_decoded_dict = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\n",
    "# most_recent_continuously_decoded_dict\n",
    "\n",
    "## Adds in the 'pseudo2D' decoder in:\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# time_bin_size: float = 0.01\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict = continuously_decoded_result_cache_dict[time_bin_size]\n",
    "pseudo2D_decoder_continuously_decoded_result = continuously_decoded_dict.get('pseudo2D', None)\n",
    "if pseudo2D_decoder_continuously_decoded_result is None:\n",
    "\t# compute here...\n",
    "\t## Currently used for both cases to decode:\n",
    "\tt_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\tsingle_global_epoch_df: pd.DataFrame = pd.DataFrame({'start': [t_start], 'stop': [t_end], 'label': [0]}) # Build an Epoch object containing a single epoch, corresponding to the global epoch for the entire session:\n",
    "\tsingle_global_epoch: Epoch = Epoch(single_global_epoch_df)\n",
    "\tspikes_df = directional_decoders_decode_result.spikes_df\n",
    "\tpseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = pseudo2D_decoder.decode_specific_epochs(spikes_df=deepcopy(spikes_df), filter_epochs=single_global_epoch, decoding_time_bin_size=time_bin_size, debug_print=False)\n",
    "\tcontinuously_decoded_dict['pseudo2D'] = pseudo2D_decoder_continuously_decoded_result\n",
    "\tcontinuously_decoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa2dc5fe",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# NEW 2023-11-22 method: Get the templates (which can be filtered by frate first) and the from those get the decoders):        \n",
    "# track_templates: TrackTemplates = directional_laps_results.get_shared_aclus_only_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # shared-only\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only\n",
    "long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = track_templates.get_decoders()\n",
    "\n",
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n",
    "\n",
    "# `LongShortStatsItem` form (2024-01-02):\n",
    "# LR_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "# RL_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n",
    "LR_results_long_short_z_diffs = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "RL_results_long_short_z_diff = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c260739a4f36c662",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrainTestSplitResult\n",
    "\n",
    "if 'TrainTestSplit' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data.get('TrainTestSplit', None)\n",
    "    training_data_portion: float = directional_train_test_split_result.training_data_portion\n",
    "    test_data_portion: float = directional_train_test_split_result.test_data_portion\n",
    "    test_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.test_epochs_dict\n",
    "    train_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.train_epochs_dict\n",
    "    train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_train_test_split_result.train_lap_specific_pf1D_Decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec18cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'burst_detection' in curr_active_pipeline.computation_results[global_epoch_name].computed_data:\n",
    "    active_burst_intervals = curr_active_pipeline.computation_results[global_epoch_name].computed_data['burst_detection']['burst_intervals']\n",
    "# active_burst_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d31f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_extended_stats = global_results.get('extended_stats', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "769a1c6006aba5b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pf_dt_sequential_surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Relative Entropy/Surprise Results:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m active_extended_stats \u001b[38;5;241m=\u001b[39m global_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextended_stats\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m active_relative_entropy_results \u001b[38;5;241m=\u001b[39m \u001b[43mactive_extended_stats\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpf_dt_sequential_surprise\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# DynamicParameters\u001b[39;00m\n\u001b[0;32m      4\u001b[0m historical_snapshots \u001b[38;5;241m=\u001b[39m active_relative_entropy_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistorical_snapshots\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m post_update_times: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m active_relative_entropy_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost_update_times\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# (4152,) = (n_post_update_times,)\u001b[39;00m\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoCoreHelpers\\src\\pyphocorehelpers\\DataStructure\\dynamic_parameters.py:33\u001b[0m, in \u001b[0;36mDynamicParameters.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DynamicParameters\u001b[38;5;241m.\u001b[39mdebug_enabled:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDynamicParameters.__getitem__(self, key): key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pf_dt_sequential_surprise'"
     ]
    }
   ],
   "source": [
    "# Relative Entropy/Surprise Results:\n",
    "active_extended_stats = global_results['extended_stats']\n",
    "active_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise'] # DynamicParameters\n",
    "historical_snapshots = active_relative_entropy_results['historical_snapshots']\n",
    "post_update_times: np.ndarray = active_relative_entropy_results['post_update_times'] # (4152,) = (n_post_update_times,)\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals: np.ndarray = active_relative_entropy_results['time_intervals']\n",
    "surprise_time_bin_duration = (post_update_times[2]-post_update_times[1])\n",
    "long_short_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "flat_relative_entropy_results: np.ndarray = active_relative_entropy_results['flat_relative_entropy_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_results: np.ndarray = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_across_all_positions: np.ndarray = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "flat_surprise_across_all_positions: np.ndarray = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\n",
    "## Get the placefield dt matrix:\n",
    "if 'snapshot_occupancy_weighted_tuning_maps' not in active_relative_entropy_results:\n",
    "\t## Compute it if missing:\n",
    "\toccupancy_weighted_tuning_maps_over_time = np.stack([placefield_snapshot.occupancy_weighted_tuning_maps_matrix for placefield_snapshot in historical_snapshots.values()])\n",
    "\tactive_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] = occupancy_weighted_tuning_maps_over_time\n",
    "else:\n",
    "\toccupancy_weighted_tuning_maps_over_time = active_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] # (n_post_update_times, n_neurons, n_xbins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9554d3bf5955d9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8624c62d5c18c556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([16, 55, 62, 69, 100], dtype='int64')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## long_short_endcap_analysis: checks for cells localized to the endcaps that have their placefields truncated after shortening the track\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "# disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "# trivially_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "# significant_distant_remapping_endcap_aclus\n",
    "appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n",
    "appearing_aclus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec24467335a760",
   "metadata": {},
   "source": [
    "# POST-Compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "728c46e6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    },
    "tags": [
     "unwrap"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum_inclusion_fr_Hz: 5.0\n",
      "included_qclu_values: [1, 2]\n",
      "laps_decoding_time_bin_size: 0.25, ripple_decoding_time_bin_size: 0.025\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multi_sort_raster_browser\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import paired_separately_sort_neurons, paired_incremental_sort_neurons # _display_directional_template_debugger\n",
    "from neuropy.utils.indexing_helpers import paired_incremental_sorting, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ScrollBarWithSpinBox.ScrollBarWithSpinBox import ScrollBarWithSpinBox\n",
    "\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_SerializationMixin\n",
    "from pyphoplacecellanalysis.General.Model.ComputationResults import ComputedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses, RankOrderResult, ShuffleHelper, Zscorer, LongShortStatsTuple, DirectionalRankOrderLikelihoods, DirectionalRankOrderResult, RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "## Display Testing\n",
    "# from pyphoplacecellanalysis.External.pyqtgraph import QtGui\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import pyqtplot_build_image_bounds_extent, pyqtplot_plot_image\n",
    "\n",
    "spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "ripple_result_tuple, laps_result_tuple = rank_order_results.ripple_most_likely_result_tuple, rank_order_results.laps_most_likely_result_tuple\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')\n",
    "# ripple_result_tuple\n",
    "\n",
    "## Unpacks `rank_order_results`: \n",
    "# global_replays = Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# global_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# active_replay_epochs, active_epochs_df, active_selected_spikes_df = combine_rank_order_results(rank_order_results, global_replays, track_templates=track_templates)\n",
    "# active_epochs_df\n",
    "\n",
    "# ripple_result_tuple.directional_likelihoods_tuple.long_best_direction_indices\n",
    "dir_index_to_direction_name_map: Dict[int, str] = {0:'LR', 1:\"RL\"}\n",
    "\n",
    "\n",
    "## All three DataFrames are the same number of rows, each with one row corresponding to an Epoch:\n",
    "active_replay_epochs_df = deepcopy(rank_order_results.LR_ripple.epochs_df)\n",
    "# active_replay_epochs_df\n",
    "\n",
    "# Change column type to int8 for columns: 'long_best_direction_indices', 'short_best_direction_indices'\n",
    "# directional_likelihoods_df = pd.DataFrame.from_dict(ripple_result_tuple.directional_likelihoods_tuple._asdict()).astype({'long_best_direction_indices': 'int8', 'short_best_direction_indices': 'int8'})\n",
    "directional_likelihoods_df = ripple_result_tuple.directional_likelihoods_df\n",
    "# directional_likelihoods_df\n",
    "\n",
    "# 2023-12-15 - Newest method:\n",
    "# laps_combined_epoch_stats_df = rank_order_results.laps_combined_epoch_stats_df\n",
    "\n",
    "# ripple_combined_epoch_stats_df: pd.DataFrame  = rank_order_results.ripple_combined_epoch_stats_df\n",
    "# ripple_combined_epoch_stats_df\n",
    "\n",
    "\n",
    "# # Concatenate the three DataFrames along the columns axis:\n",
    "# # Assert that all DataFrames have the same number of rows:\n",
    "# assert len(active_replay_epochs_df) == len(directional_likelihoods_df) == len(ripple_combined_epoch_stats_df), \"DataFrames have different numbers of rows.\"\n",
    "# # Assert that all DataFrames have at least one row:\n",
    "# assert len(active_replay_epochs_df) > 0, \"active_replay_epochs_df is empty.\"\n",
    "# assert len(directional_likelihoods_df) > 0, \"directional_likelihoods_df is empty.\"\n",
    "# assert len(ripple_combined_epoch_stats_df) > 0, \"ripple_combined_epoch_stats_df is empty.\"\n",
    "# merged_complete_epoch_stats_df: pd.DataFrame = pd.concat([active_replay_epochs_df.reset_index(drop=True, inplace=False), directional_likelihoods_df.reset_index(drop=True, inplace=False), ripple_combined_epoch_stats_df.reset_index(drop=True, inplace=False)], axis=1)\n",
    "# merged_complete_epoch_stats_df = merged_complete_epoch_stats_df.set_index(active_replay_epochs_df.index, inplace=False)\n",
    "\n",
    "# merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "# merged_complete_epoch_stats_df.to_csv('output/2023-12-21_merged_complete_epoch_stats_df.csv')\n",
    "# merged_complete_epoch_stats_df\n",
    "\n",
    "laps_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.laps_merged_complete_epoch_stats_df ## New method\n",
    "ripple_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "all_directional_decoder_dict_value = directional_merged_decoders_result.all_directional_decoder_dict\n",
    "all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "# long_directional_pf1D_Decoder_value = directional_merged_decoders_result.long_directional_pf1D_Decoder\n",
    "# long_directional_decoder_dict_value = directional_merged_decoders_result.long_directional_decoder_dict\n",
    "# short_directional_pf1D_Decoder_value = directional_merged_decoders_result.short_directional_pf1D_Decoder\n",
    "# short_directional_decoder_dict_value = directional_merged_decoders_result.short_directional_decoder_dict\n",
    "\n",
    "all_directional_laps_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "all_directional_ripple_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\n",
    "\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = directional_merged_decoders_result.laps_track_identity_marginals_tuple\n",
    "ripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.ripple_directional_marginals_tuple\n",
    "ripple_track_identity_marginals, ripple_track_identity_all_epoch_bins_marginal, ripple_most_likely_track_identity_from_decoder, ripple_is_most_likely_track_identity_Long = directional_merged_decoders_result.ripple_track_identity_marginals_tuple\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "\n",
    "laps_all_epoch_bins_marginals_df = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "ripple_all_epoch_bins_marginals_df = directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08508b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "      <th>LR_Long_ActuallyIncludedAclus</th>\n",
       "      <th>LR_Long_rel_num_cells</th>\n",
       "      <th>RL_Long_ActuallyIncludedAclus</th>\n",
       "      <th>RL_Long_rel_num_cells</th>\n",
       "      <th>LR_Short_ActuallyIncludedAclus</th>\n",
       "      <th>LR_Short_rel_num_cells</th>\n",
       "      <th>RL_Short_ActuallyIncludedAclus</th>\n",
       "      <th>RL_Short_rel_num_cells</th>\n",
       "      <th>combined_best_direction_indicies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.735790</td>\n",
       "      <td>55.897899</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162109</td>\n",
       "      <td>[11, 12, 44, 48, 79, 82, 84, 92, 93]</td>\n",
       "      <td>9</td>\n",
       "      <td>[11, 44, 79, 82, 84, 92, 93]</td>\n",
       "      <td>7</td>\n",
       "      <td>[11, 12, 44, 48, 79, 82, 84, 92, 93]</td>\n",
       "      <td>9</td>\n",
       "      <td>[11, 44, 79, 82, 84, 92, 93]</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.691866</td>\n",
       "      <td>73.909210</td>\n",
       "      <td>2</td>\n",
       "      <td>0.217344</td>\n",
       "      <td>[9, 28, 31, 39, 57, 61, 67]</td>\n",
       "      <td>7</td>\n",
       "      <td>[9, 31, 39, 61]</td>\n",
       "      <td>4</td>\n",
       "      <td>[9, 28, 31, 39, 57, 61, 67]</td>\n",
       "      <td>7</td>\n",
       "      <td>[9, 31, 39, 61]</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92.642502</td>\n",
       "      <td>92.760068</td>\n",
       "      <td>3</td>\n",
       "      <td>0.117565</td>\n",
       "      <td>[12, 58, 61, 72, 92, 104]</td>\n",
       "      <td>6</td>\n",
       "      <td>[43, 58, 61, 72, 92, 104]</td>\n",
       "      <td>6</td>\n",
       "      <td>[12, 58, 61, 72, 92, 104]</td>\n",
       "      <td>6</td>\n",
       "      <td>[43, 58, 61, 72, 92, 104]</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.044443</td>\n",
       "      <td>93.453141</td>\n",
       "      <td>4</td>\n",
       "      <td>0.408699</td>\n",
       "      <td>[4, 11, 18, 38, 39, 57, 61, 82, 84, 89, 91, 92...</td>\n",
       "      <td>13</td>\n",
       "      <td>[6, 11, 18, 39, 61, 82, 84, 89, 92, 98]</td>\n",
       "      <td>10</td>\n",
       "      <td>[4, 11, 18, 38, 39, 57, 61, 82, 84, 89, 91, 92...</td>\n",
       "      <td>13</td>\n",
       "      <td>[6, 11, 18, 39, 61, 82, 84, 89, 92, 98]</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>93.925000</td>\n",
       "      <td>94.029571</td>\n",
       "      <td>5</td>\n",
       "      <td>0.104571</td>\n",
       "      <td>[12, 31, 38, 57]</td>\n",
       "      <td>4</td>\n",
       "      <td>[5, 29, 31, 35]</td>\n",
       "      <td>4</td>\n",
       "      <td>[12, 31, 38, 57]</td>\n",
       "      <td>4</td>\n",
       "      <td>[5, 29, 31, 35]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>102.927307</td>\n",
       "      <td>103.187813</td>\n",
       "      <td>6</td>\n",
       "      <td>0.260505</td>\n",
       "      <td>[18, 57, 58, 72, 92, 93]</td>\n",
       "      <td>6</td>\n",
       "      <td>[2, 18, 58, 72, 92, 93]</td>\n",
       "      <td>6</td>\n",
       "      <td>[18, 57, 58, 72, 92, 93]</td>\n",
       "      <td>6</td>\n",
       "      <td>[2, 18, 58, 72, 92, 93]</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1714.307771</td>\n",
       "      <td>1714.651681</td>\n",
       "      <td>398</td>\n",
       "      <td>0.343910</td>\n",
       "      <td>[4, 12, 18, 20, 24, 58, 72, 80, 81, 82, 84, 90...</td>\n",
       "      <td>14</td>\n",
       "      <td>[18, 24, 35, 43, 58, 72, 80, 81, 82, 84, 90, 9...</td>\n",
       "      <td>13</td>\n",
       "      <td>[4, 12, 18, 20, 24, 58, 72, 80, 81, 82, 84, 90...</td>\n",
       "      <td>14</td>\n",
       "      <td>[18, 24, 35, 43, 58, 72, 80, 81, 82, 84, 90, 9...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1721.291806</td>\n",
       "      <td>1721.362155</td>\n",
       "      <td>401</td>\n",
       "      <td>0.070349</td>\n",
       "      <td>[11, 13, 18, 24, 48, 61, 79, 81, 82, 89]</td>\n",
       "      <td>10</td>\n",
       "      <td>[11, 18, 24, 61, 79, 81, 82, 89]</td>\n",
       "      <td>8</td>\n",
       "      <td>[11, 13, 18, 24, 48, 61, 79, 81, 82, 89]</td>\n",
       "      <td>10</td>\n",
       "      <td>[11, 18, 24, 61, 79, 81, 82, 89]</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1725.280888</td>\n",
       "      <td>1725.574786</td>\n",
       "      <td>403</td>\n",
       "      <td>0.293898</td>\n",
       "      <td>[4, 9, 13, 31, 44, 58, 59, 67, 72, 79, 80, 81,...</td>\n",
       "      <td>18</td>\n",
       "      <td>[2, 9, 31, 35, 43, 44, 58, 72, 79, 80, 81, 82,...</td>\n",
       "      <td>17</td>\n",
       "      <td>[4, 9, 13, 31, 44, 58, 59, 67, 72, 79, 80, 81,...</td>\n",
       "      <td>18</td>\n",
       "      <td>[2, 9, 31, 35, 43, 44, 58, 72, 79, 80, 81, 82,...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1729.689083</td>\n",
       "      <td>1730.227666</td>\n",
       "      <td>406</td>\n",
       "      <td>0.538583</td>\n",
       "      <td>[4, 9, 16, 20, 24, 28, 31, 39, 57, 58, 59, 61,...</td>\n",
       "      <td>19</td>\n",
       "      <td>[2, 5, 9, 16, 24, 29, 31, 39, 43, 58, 61, 72, ...</td>\n",
       "      <td>17</td>\n",
       "      <td>[4, 9, 16, 20, 24, 28, 31, 39, 57, 58, 59, 61,...</td>\n",
       "      <td>19</td>\n",
       "      <td>[2, 5, 9, 16, 24, 29, 31, 39, 43, 58, 61, 72, ...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1731.142015</td>\n",
       "      <td>1731.287905</td>\n",
       "      <td>407</td>\n",
       "      <td>0.145889</td>\n",
       "      <td>[4, 9, 24, 31, 58, 61, 72, 79, 80, 81, 82, 89,...</td>\n",
       "      <td>15</td>\n",
       "      <td>[2, 9, 24, 31, 35, 58, 61, 72, 79, 80, 81, 82,...</td>\n",
       "      <td>17</td>\n",
       "      <td>[4, 9, 24, 31, 58, 61, 72, 79, 80, 81, 82, 89,...</td>\n",
       "      <td>15</td>\n",
       "      <td>[2, 9, 24, 31, 35, 58, 61, 72, 79, 80, 81, 82,...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1733.736195</td>\n",
       "      <td>1733.857078</td>\n",
       "      <td>409</td>\n",
       "      <td>0.120883</td>\n",
       "      <td>[13, 28, 39, 57, 62, 80, 84, 93]</td>\n",
       "      <td>8</td>\n",
       "      <td>[39, 80, 84, 93]</td>\n",
       "      <td>4</td>\n",
       "      <td>[13, 28, 39, 57, 62, 80, 84, 93]</td>\n",
       "      <td>8</td>\n",
       "      <td>[39, 80, 84, 93]</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           start         stop  label  duration                      LR_Long_ActuallyIncludedAclus  LR_Long_rel_num_cells                      RL_Long_ActuallyIncludedAclus  RL_Long_rel_num_cells                     LR_Short_ActuallyIncludedAclus  LR_Short_rel_num_cells                     RL_Short_ActuallyIncludedAclus  RL_Short_rel_num_cells  combined_best_direction_indicies\n",
       "1      55.735790    55.897899      1  0.162109               [11, 12, 44, 48, 79, 82, 84, 92, 93]                      9                       [11, 44, 79, 82, 84, 92, 93]                      7               [11, 12, 44, 48, 79, 82, 84, 92, 93]                       9                       [11, 44, 79, 82, 84, 92, 93]                       7                                 0\n",
       "2      73.691866    73.909210      2  0.217344                        [9, 28, 31, 39, 57, 61, 67]                      7                                    [9, 31, 39, 61]                      4                        [9, 28, 31, 39, 57, 61, 67]                       7                                    [9, 31, 39, 61]                       4                                 0\n",
       "3      92.642502    92.760068      3  0.117565                          [12, 58, 61, 72, 92, 104]                      6                          [43, 58, 61, 72, 92, 104]                      6                          [12, 58, 61, 72, 92, 104]                       6                          [43, 58, 61, 72, 92, 104]                       6                                 1\n",
       "4      93.044443    93.453141      4  0.408699  [4, 11, 18, 38, 39, 57, 61, 82, 84, 89, 91, 92...                     13            [6, 11, 18, 39, 61, 82, 84, 89, 92, 98]                     10  [4, 11, 18, 38, 39, 57, 61, 82, 84, 89, 91, 92...                      13            [6, 11, 18, 39, 61, 82, 84, 89, 92, 98]                      10                                 0\n",
       "5      93.925000    94.029571      5  0.104571                                   [12, 31, 38, 57]                      4                                    [5, 29, 31, 35]                      4                                   [12, 31, 38, 57]                       4                                    [5, 29, 31, 35]                       4                                 1\n",
       "6     102.927307   103.187813      6  0.260505                           [18, 57, 58, 72, 92, 93]                      6                            [2, 18, 58, 72, 92, 93]                      6                           [18, 57, 58, 72, 92, 93]                       6                            [2, 18, 58, 72, 92, 93]                       6                                 1\n",
       "..           ...          ...    ...       ...                                                ...                    ...                                                ...                    ...                                                ...                     ...                                                ...                     ...                               ...\n",
       "396  1714.307771  1714.651681    398  0.343910  [4, 12, 18, 20, 24, 58, 72, 80, 81, 82, 84, 90...                     14  [18, 24, 35, 43, 58, 72, 80, 81, 82, 84, 90, 9...                     13  [4, 12, 18, 20, 24, 58, 72, 80, 81, 82, 84, 90...                      14  [18, 24, 35, 43, 58, 72, 80, 81, 82, 84, 90, 9...                      13                                 1\n",
       "399  1721.291806  1721.362155    401  0.070349           [11, 13, 18, 24, 48, 61, 79, 81, 82, 89]                     10                   [11, 18, 24, 61, 79, 81, 82, 89]                      8           [11, 13, 18, 24, 48, 61, 79, 81, 82, 89]                      10                   [11, 18, 24, 61, 79, 81, 82, 89]                       8                                 0\n",
       "401  1725.280888  1725.574786    403  0.293898  [4, 9, 13, 31, 44, 58, 59, 67, 72, 79, 80, 81,...                     18  [2, 9, 31, 35, 43, 44, 58, 72, 79, 80, 81, 82,...                     17  [4, 9, 13, 31, 44, 58, 59, 67, 72, 79, 80, 81,...                      18  [2, 9, 31, 35, 43, 44, 58, 72, 79, 80, 81, 82,...                      17                                 1\n",
       "404  1729.689083  1730.227666    406  0.538583  [4, 9, 16, 20, 24, 28, 31, 39, 57, 58, 59, 61,...                     19  [2, 5, 9, 16, 24, 29, 31, 39, 43, 58, 61, 72, ...                     17  [4, 9, 16, 20, 24, 28, 31, 39, 57, 58, 59, 61,...                      19  [2, 5, 9, 16, 24, 29, 31, 39, 43, 58, 61, 72, ...                      17                                 0\n",
       "405  1731.142015  1731.287905    407  0.145889  [4, 9, 24, 31, 58, 61, 72, 79, 80, 81, 82, 89,...                     15  [2, 9, 24, 31, 35, 58, 61, 72, 79, 80, 81, 82,...                     17  [4, 9, 24, 31, 58, 61, 72, 79, 80, 81, 82, 89,...                      15  [2, 9, 24, 31, 35, 58, 61, 72, 79, 80, 81, 82,...                      17                                 1\n",
       "407  1733.736195  1733.857078    409  0.120883                   [13, 28, 39, 57, 62, 80, 84, 93]                      8                                   [39, 80, 84, 93]                      4                   [13, 28, 39, 57, 62, 80, 84, 93]                       8                                   [39, 80, 84, 93]                       4                                 0\n",
       "\n",
       "[250 rows x 13 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_replay_epochs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc4e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ripple_is_most_likely_direction_LR_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "753ca336",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 136\n",
      "df_column_names: [['start', 'stop', 'label', 'duration', 'score', 'velocity', 'intercept', 'speed', 'wcorr', 'P_decoder', 'pearsonr', 'travel', 'coverage', 'jump', 'sequential_correlation', 'monotonicity_score', 'laplacian_smoothness', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff', 'is_user_annotated_epoch', 'is_valid_epoch'], ['start', 'stop', 'label', 'duration', 'score', 'velocity', 'intercept', 'speed', 'wcorr', 'P_decoder', 'pearsonr', 'travel', 'coverage', 'jump', 'sequential_correlation', 'monotonicity_score', 'laplacian_smoothness', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff', 'is_user_annotated_epoch', 'is_valid_epoch'], ['start', 'stop', 'label', 'duration', 'score', 'velocity', 'intercept', 'speed', 'wcorr', 'P_decoder', 'pearsonr', 'travel', 'coverage', 'jump', 'sequential_correlation', 'monotonicity_score', 'laplacian_smoothness', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff', 'is_user_annotated_epoch', 'is_valid_epoch'], ['start', 'stop', 'label', 'duration', 'score', 'velocity', 'intercept', 'speed', 'wcorr', 'P_decoder', 'pearsonr', 'travel', 'coverage', 'jump', 'sequential_correlation', 'monotonicity_score', 'laplacian_smoothness', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff', 'is_user_annotated_epoch', 'is_valid_epoch']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "      <th>end</th>\n",
       "      <th>n_unique_aclus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.027055</td>\n",
       "      <td>93.465245</td>\n",
       "      <td>4</td>\n",
       "      <td>0.438190</td>\n",
       "      <td>93.465245</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.400143</td>\n",
       "      <td>105.562560</td>\n",
       "      <td>8</td>\n",
       "      <td>0.162417</td>\n",
       "      <td>105.562560</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113.213433</td>\n",
       "      <td>113.613960</td>\n",
       "      <td>9</td>\n",
       "      <td>0.400527</td>\n",
       "      <td>113.613960</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120.645089</td>\n",
       "      <td>120.861972</td>\n",
       "      <td>11</td>\n",
       "      <td>0.216883</td>\n",
       "      <td>120.861972</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.060134</td>\n",
       "      <td>125.209802</td>\n",
       "      <td>14</td>\n",
       "      <td>0.149668</td>\n",
       "      <td>125.209802</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>132.511389</td>\n",
       "      <td>132.791003</td>\n",
       "      <td>17</td>\n",
       "      <td>0.279613</td>\n",
       "      <td>132.791003</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1705.053099</td>\n",
       "      <td>1705.140866</td>\n",
       "      <td>405</td>\n",
       "      <td>0.087767</td>\n",
       "      <td>1705.140866</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1707.712068</td>\n",
       "      <td>1707.918998</td>\n",
       "      <td>406</td>\n",
       "      <td>0.206930</td>\n",
       "      <td>1707.918998</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1714.307771</td>\n",
       "      <td>1714.651681</td>\n",
       "      <td>409</td>\n",
       "      <td>0.343910</td>\n",
       "      <td>1714.651681</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1725.278891</td>\n",
       "      <td>1725.595092</td>\n",
       "      <td>414</td>\n",
       "      <td>0.316201</td>\n",
       "      <td>1725.595092</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1729.689083</td>\n",
       "      <td>1730.227666</td>\n",
       "      <td>417</td>\n",
       "      <td>0.538583</td>\n",
       "      <td>1730.227666</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1731.111480</td>\n",
       "      <td>1731.287905</td>\n",
       "      <td>418</td>\n",
       "      <td>0.176425</td>\n",
       "      <td>1731.287905</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           start         stop  label  duration          end  n_unique_aclus\n",
       "0      93.027055    93.465245      4  0.438190    93.465245              31\n",
       "1     105.400143   105.562560      8  0.162417   105.562560              26\n",
       "2     113.213433   113.613960      9  0.400527   113.613960              19\n",
       "3     120.645089   120.861972     11  0.216883   120.861972              26\n",
       "4     125.060134   125.209802     14  0.149668   125.209802              26\n",
       "5     132.511389   132.791003     17  0.279613   132.791003              33\n",
       "..           ...          ...    ...       ...          ...             ...\n",
       "130  1705.053099  1705.140866    405  0.087767  1705.140866              18\n",
       "131  1707.712068  1707.918998    406  0.206930  1707.918998              24\n",
       "132  1714.307771  1714.651681    409  0.343910  1714.651681              22\n",
       "133  1725.278891  1725.595092    414  0.316201  1725.595092              30\n",
       "134  1729.689083  1730.227666    417  0.538583  1730.227666              36\n",
       "135  1731.111480  1731.287905    418  0.176425  1731.287905              21\n",
       "\n",
       "[136 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "# from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import HeuristicReplayScoring\n",
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size,\n",
    "                                                                                                                            should_only_include_user_selected_epochs=False)\n",
    "filtered_epochs_df\n",
    "# filtered_ripple_all_epoch_bins_marginals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae6e077",
   "metadata": {},
   "source": [
    "### 2024-02-29 - 4pm - Filter the events for those meeting wcorr criteria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ec8cd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_LR</th>\n",
       "      <th>P_RL</th>\n",
       "      <th>P_Long</th>\n",
       "      <th>P_Short</th>\n",
       "      <th>ripple_idx</th>\n",
       "      <th>ripple_start_t</th>\n",
       "      <th>long_best_wcorr</th>\n",
       "      <th>short_best_wcorr</th>\n",
       "      <th>wcorr_abs_diff</th>\n",
       "      <th>long_best_pearsonr</th>\n",
       "      <th>short_best_pearsonr</th>\n",
       "      <th>pearsonr_abs_diff</th>\n",
       "      <th>session_name</th>\n",
       "      <th>delta_aligned_start_t</th>\n",
       "      <th>time_bin_size</th>\n",
       "      <th>is_user_annotated_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.293781</td>\n",
       "      <td>0.706219</td>\n",
       "      <td>0.741529</td>\n",
       "      <td>0.258471</td>\n",
       "      <td>44</td>\n",
       "      <td>186.459122</td>\n",
       "      <td>-0.463832</td>\n",
       "      <td>-0.220737</td>\n",
       "      <td>0.243095</td>\n",
       "      <td>-0.522767</td>\n",
       "      <td>-0.511169</td>\n",
       "      <td>0.011598</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-842.857486</td>\n",
       "      <td>0.025</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.503324</td>\n",
       "      <td>0.496676</td>\n",
       "      <td>0.552780</td>\n",
       "      <td>0.447220</td>\n",
       "      <td>129</td>\n",
       "      <td>630.115599</td>\n",
       "      <td>0.059162</td>\n",
       "      <td>-0.382265</td>\n",
       "      <td>-0.323103</td>\n",
       "      <td>-0.246498</td>\n",
       "      <td>-0.001932</td>\n",
       "      <td>0.244566</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-399.201009</td>\n",
       "      <td>0.025</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.796799</td>\n",
       "      <td>0.203201</td>\n",
       "      <td>0.781959</td>\n",
       "      <td>0.218041</td>\n",
       "      <td>143</td>\n",
       "      <td>670.215746</td>\n",
       "      <td>0.688041</td>\n",
       "      <td>0.417045</td>\n",
       "      <td>0.270996</td>\n",
       "      <td>-0.153868</td>\n",
       "      <td>0.458274</td>\n",
       "      <td>-0.304406</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-359.100862</td>\n",
       "      <td>0.025</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.852086</td>\n",
       "      <td>0.147914</td>\n",
       "      <td>0.679112</td>\n",
       "      <td>0.320888</td>\n",
       "      <td>146</td>\n",
       "      <td>675.971934</td>\n",
       "      <td>0.768058</td>\n",
       "      <td>0.492482</td>\n",
       "      <td>0.275577</td>\n",
       "      <td>0.200051</td>\n",
       "      <td>-0.075593</td>\n",
       "      <td>0.124458</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-353.344675</td>\n",
       "      <td>0.025</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.492092</td>\n",
       "      <td>0.507908</td>\n",
       "      <td>0.597349</td>\n",
       "      <td>0.402651</td>\n",
       "      <td>163</td>\n",
       "      <td>722.678445</td>\n",
       "      <td>0.408953</td>\n",
       "      <td>0.065776</td>\n",
       "      <td>0.343177</td>\n",
       "      <td>0.287860</td>\n",
       "      <td>0.226217</td>\n",
       "      <td>0.061643</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-306.638164</td>\n",
       "      <td>0.025</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.881797</td>\n",
       "      <td>0.118203</td>\n",
       "      <td>0.830979</td>\n",
       "      <td>0.169021</td>\n",
       "      <td>203</td>\n",
       "      <td>808.799217</td>\n",
       "      <td>-0.308653</td>\n",
       "      <td>-0.031209</td>\n",
       "      <td>0.277445</td>\n",
       "      <td>0.068908</td>\n",
       "      <td>0.364769</td>\n",
       "      <td>-0.295861</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-220.517392</td>\n",
       "      <td>0.025</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.635691</td>\n",
       "      <td>0.364309</td>\n",
       "      <td>240</td>\n",
       "      <td>1085.079611</td>\n",
       "      <td>0.296053</td>\n",
       "      <td>0.764285</td>\n",
       "      <td>-0.468232</td>\n",
       "      <td>0.046353</td>\n",
       "      <td>0.429267</td>\n",
       "      <td>-0.382913</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>55.763002</td>\n",
       "      <td>0.025</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.517359</td>\n",
       "      <td>0.482641</td>\n",
       "      <td>0.389172</td>\n",
       "      <td>0.610828</td>\n",
       "      <td>295</td>\n",
       "      <td>1250.967680</td>\n",
       "      <td>-0.413383</td>\n",
       "      <td>-0.127216</td>\n",
       "      <td>0.286167</td>\n",
       "      <td>-0.105638</td>\n",
       "      <td>-0.207370</td>\n",
       "      <td>-0.101732</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>221.651071</td>\n",
       "      <td>0.025</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.593476</td>\n",
       "      <td>0.406524</td>\n",
       "      <td>0.492643</td>\n",
       "      <td>0.507357</td>\n",
       "      <td>328</td>\n",
       "      <td>1358.721619</td>\n",
       "      <td>0.374909</td>\n",
       "      <td>-0.022498</td>\n",
       "      <td>0.352411</td>\n",
       "      <td>0.813209</td>\n",
       "      <td>0.743783</td>\n",
       "      <td>0.069426</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>329.405010</td>\n",
       "      <td>0.025</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.048819</td>\n",
       "      <td>0.951181</td>\n",
       "      <td>0.527072</td>\n",
       "      <td>0.472928</td>\n",
       "      <td>340</td>\n",
       "      <td>1429.059139</td>\n",
       "      <td>-0.616227</td>\n",
       "      <td>-0.239877</td>\n",
       "      <td>0.376350</td>\n",
       "      <td>-0.629116</td>\n",
       "      <td>-0.312347</td>\n",
       "      <td>0.316769</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>399.742530</td>\n",
       "      <td>0.025</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.524099</td>\n",
       "      <td>0.475901</td>\n",
       "      <td>0.228705</td>\n",
       "      <td>0.771295</td>\n",
       "      <td>395</td>\n",
       "      <td>1707.712068</td>\n",
       "      <td>-0.139340</td>\n",
       "      <td>-0.610319</td>\n",
       "      <td>-0.470978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>678.395459</td>\n",
       "      <td>0.025</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.226308</td>\n",
       "      <td>0.773692</td>\n",
       "      <td>0.301660</td>\n",
       "      <td>0.698340</td>\n",
       "      <td>407</td>\n",
       "      <td>1731.111480</td>\n",
       "      <td>-0.279661</td>\n",
       "      <td>-0.052965</td>\n",
       "      <td>0.226695</td>\n",
       "      <td>-0.139750</td>\n",
       "      <td>-0.136544</td>\n",
       "      <td>0.003206</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>701.794871</td>\n",
       "      <td>0.025</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         P_LR      P_RL    P_Long   P_Short  ripple_idx  ripple_start_t  long_best_wcorr  short_best_wcorr  wcorr_abs_diff  long_best_pearsonr  short_best_pearsonr  pearsonr_abs_diff       session_name  delta_aligned_start_t  time_bin_size  is_user_annotated_epoch\n",
       "10   0.293781  0.706219  0.741529  0.258471          44      186.459122        -0.463832         -0.220737        0.243095           -0.522767            -0.511169           0.011598  2006-6-09_1-22-43            -842.857486          0.025                     True\n",
       "37   0.503324  0.496676  0.552780  0.447220         129      630.115599         0.059162         -0.382265       -0.323103           -0.246498            -0.001932           0.244566  2006-6-09_1-22-43            -399.201009          0.025                     True\n",
       "39   0.796799  0.203201  0.781959  0.218041         143      670.215746         0.688041          0.417045        0.270996           -0.153868             0.458274          -0.304406  2006-6-09_1-22-43            -359.100862          0.025                     True\n",
       "40   0.852086  0.147914  0.679112  0.320888         146      675.971934         0.768058          0.492482        0.275577            0.200051            -0.075593           0.124458  2006-6-09_1-22-43            -353.344675          0.025                     True\n",
       "47   0.492092  0.507908  0.597349  0.402651         163      722.678445         0.408953          0.065776        0.343177            0.287860             0.226217           0.061643  2006-6-09_1-22-43            -306.638164          0.025                     True\n",
       "59   0.881797  0.118203  0.830979  0.169021         203      808.799217        -0.308653         -0.031209        0.277445            0.068908             0.364769          -0.295861  2006-6-09_1-22-43            -220.517392          0.025                     True\n",
       "70   0.000027  0.999973  0.635691  0.364309         240     1085.079611         0.296053          0.764285       -0.468232            0.046353             0.429267          -0.382913  2006-6-09_1-22-43              55.763002          0.025                     True\n",
       "86   0.517359  0.482641  0.389172  0.610828         295     1250.967680        -0.413383         -0.127216        0.286167           -0.105638            -0.207370          -0.101732  2006-6-09_1-22-43             221.651071          0.025                     True\n",
       "105  0.593476  0.406524  0.492643  0.507357         328     1358.721619         0.374909         -0.022498        0.352411            0.813209             0.743783           0.069426  2006-6-09_1-22-43             329.405010          0.025                     True\n",
       "108  0.048819  0.951181  0.527072  0.472928         340     1429.059139        -0.616227         -0.239877        0.376350           -0.629116            -0.312347           0.316769  2006-6-09_1-22-43             399.742530          0.025                     True\n",
       "131  0.524099  0.475901  0.228705  0.771295         395     1707.712068        -0.139340         -0.610319       -0.470978                 NaN                  NaN                NaN  2006-6-09_1-22-43             678.395459          0.025                     True\n",
       "135  0.226308  0.773692  0.301660  0.698340         407     1731.111480        -0.279661         -0.052965        0.226695           -0.139750            -0.136544           0.003206  2006-6-09_1-22-43             701.794871          0.025                     True\n",
       "\n",
       "[12 rows x 16 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_wcorr_threshold: float = 0.33\n",
    "min_wcorr_diff_threshold: float = 0.2\n",
    "\n",
    "is_included_large_wcorr_diff = np.any((filtered_ripple_all_epoch_bins_marginals_df[['wcorr_abs_diff']].abs() > min_wcorr_diff_threshold), axis=1)\n",
    "# is_included_large_wcorr_diff\n",
    "is_included_high_wcorr = np.any((filtered_ripple_all_epoch_bins_marginals_df[['long_best_wcorr', 'short_best_wcorr']].abs() > min_wcorr_threshold), axis=1)\n",
    "\n",
    "df = filtered_ripple_all_epoch_bins_marginals_df[is_included_large_wcorr_diff]\n",
    "# df = filtered_ripple_all_epoch_bins_marginals_df[is_included_high_wcorr]\n",
    "df\n",
    "\n",
    "# delta_aligned_start_t\n",
    "\n",
    "significant_epochs_start_ts = np.squeeze(df['ripple_start_t'].to_numpy()) ## for filtering\n",
    "\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(significant_epochs_start_ts) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict\n",
    "filtered_epochs_df = filtered_epochs_df.epochs.matching_epoch_times_slice(significant_epochs_start_ts)\n",
    "# filtered_ripple_all_epoch_bins_marginals_df = filtered_ripple_all_epoch_bins_marginals_df.epochs.matching_epoch_times_slice(significant_epochs_start_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15332e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "included_qclu_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35edc67f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Long_BestDir_quantile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Long_BestDir_quantile'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m split_time_t: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m short_epoch\u001b[38;5;241m.\u001b[39mt_start\n\u001b[0;32m      8\u001b[0m active_context \u001b[38;5;241m=\u001b[39m curr_active_pipeline\u001b[38;5;241m.\u001b[39msess\u001b[38;5;241m.\u001b[39mget_context()\n\u001b[1;32m---> 10\u001b[0m collector \u001b[38;5;241m=\u001b[39m \u001b[43mplot_quantile_diffs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_ripple_all_epoch_bins_marginals_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_time_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactive_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactive_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\MultiContextComputationFunctions\\RankOrderComputations.py:2988\u001b[0m, in \u001b[0;36mplot_quantile_diffs\u001b[1;34m(merged_complete_epoch_stats_df, t_start, t_split, t_end, quantile_significance_threshold, active_context, perform_write_to_file_callback, include_LR_LR_plot, include_RL_RL_plot)\u001b[0m\n\u001b[0;32m   2985\u001b[0m ripple_combined_epoch_stats_df \u001b[38;5;241m=\u001b[39m deepcopy(merged_complete_epoch_stats_df)\n\u001b[0;32m   2987\u001b[0m \u001b[38;5;66;03m# Filter rows based on columns: 'Long_BestDir_quantile', 'Short_BestDir_quantile'\u001b[39;00m\n\u001b[1;32m-> 2988\u001b[0m significant_BestDir_quantile_stats_df \u001b[38;5;241m=\u001b[39m ripple_combined_epoch_stats_df[(\u001b[43mripple_combined_epoch_stats_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLong_BestDir_quantile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m quantile_significance_threshold) \u001b[38;5;241m|\u001b[39m (ripple_combined_epoch_stats_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShort_BestDir_quantile\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m quantile_significance_threshold)]\n\u001b[0;32m   2989\u001b[0m LR_likely_active_df \u001b[38;5;241m=\u001b[39m ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_best_direction_indicies\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m ((ripple_combined_epoch_stats_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR_Long_pearson_percentile\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m quantile_significance_threshold) \u001b[38;5;241m|\u001b[39m (ripple_combined_epoch_stats_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR_Short_percentile\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m quantile_significance_threshold))]\n\u001b[0;32m   2990\u001b[0m RL_likely_active_df \u001b[38;5;241m=\u001b[39m ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_best_direction_indicies\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m ((ripple_combined_epoch_stats_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRL_Long_percentile\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m quantile_significance_threshold) \u001b[38;5;241m|\u001b[39m (ripple_combined_epoch_stats_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRL_Short_percentile\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m quantile_significance_threshold))]\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Long_BestDir_quantile'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import plot_quantile_diffs\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "global_epoch = curr_active_pipeline.filtered_epochs[global_epoch_name]\n",
    "short_epoch = curr_active_pipeline.filtered_epochs[short_epoch_name]\n",
    "split_time_t: float = short_epoch.t_start\n",
    "active_context = curr_active_pipeline.sess.get_context()\n",
    "\n",
    "collector = plot_quantile_diffs(filtered_ripple_all_epoch_bins_marginals_df, t_split=split_time_t, active_context=active_context)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b53c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ripple_merged_complete_epoch_stats_df\n",
    "laps_merged_complete_epoch_stats_df\n",
    "['long_best_direction_indices', 'short_best_direction_indices', 'combined_best_direction_indicies', 'long_relative_direction_likelihoods', 'short_relative_direction_likelihoods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the time series of Long-likely events\n",
    "# type(long_RL_results) # DynamicParameters\n",
    "long_LR_pf1D_Decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_directional_decoder_dict_value)\n",
    "list(all_directional_decoder_dict_value.keys()) # ['long_LR', 'long_RL', 'short_LR', 'short_RL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_all_epoch_bins_marginals_df\n",
    "laps_most_likely_direction_from_decoder\n",
    "long_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdabd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ripple_result_tuple) # pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations.DirectionalRankOrderResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "\n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15629dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots \n",
    "\n",
    "# @register_type_display(DirectionalRankOrderResult)\n",
    "def plot_histograms(self: DirectionalRankOrderResult, **kwargs) -> \"MatplotlibRenderPlots\":\n",
    "\t\"\"\" \n",
    "\tnum='RipplesRankOrderZscore'\n",
    "\t\"\"\"\n",
    "\tprint(f'.plot_histograms(..., kwargs: {kwargs})')\n",
    "\tfig = plt.figure(layout=\"constrained\", **kwargs)\n",
    "\tax_dict = fig.subplot_mosaic(\n",
    "\t\t[\n",
    "\t\t\t[\"long_short_best_z_score_diff\", \"long_short_best_z_score_diff\"],\n",
    "\t\t\t[\"long_best_z_scores\", \"short_best_z_scores\"],\n",
    "\t\t],\n",
    "\t)\n",
    "\tplots = (pd.DataFrame({'long_best_z_scores': self.long_best_dir_z_score_values}).hist(ax=ax_dict['long_best_z_scores'], bins=21, alpha=0.8),\n",
    "\t\tpd.DataFrame({'short_best_z_scores': self.short_best_dir_z_score_values}).hist(ax=ax_dict['short_best_z_scores'], bins=21, alpha=0.8),\n",
    "\t\tpd.DataFrame({'long_short_best_z_score_diff': self.long_short_best_dir_z_score_diff_values}).hist(ax=ax_dict['long_short_best_z_score_diff'], bins=21, alpha=0.8),\n",
    "\t)\n",
    "\treturn MatplotlibRenderPlots(name='plot_histogram_figure', figures=[fig], axes=ax_dict)\n",
    "\n",
    "\n",
    "register_type_display(plot_histograms, DirectionalRankOrderResult)\n",
    "## Call the newly added `plot_histograms` function on the `ripple_result_tuple` object which is of type `DirectionalRankOrderResult`:\n",
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c291690",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_result_tuple.plot_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b30bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💾 CSVs \n",
    "print(f'\\t try saving to CSV...')\n",
    "merged_complete_epoch_stats_df = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "merged_complete_epoch_stats_df\n",
    "merged_complete_ripple_epoch_stats_df_output_path = curr_active_pipeline.get_output_path().joinpath(f'{DAY_DATE_TO_USE}_merged_complete_epoch_stats_df.csv').resolve()\n",
    "merged_complete_epoch_stats_df.to_csv(merged_complete_ripple_epoch_stats_df_output_path)\n",
    "print(f'\\t saving to CSV: {merged_complete_ripple_epoch_stats_df_output_path} done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732743e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_combined_epoch_stats_df = deepcopy(merged_complete_epoch_stats_df)\n",
    "\n",
    "# Filter rows based on columns: 'Long_BestDir_quantile', 'Short_BestDir_quantile'\n",
    "quantile_significance_threshold: float = 0.95\n",
    "significant_BestDir_quantile_stats_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['Long_BestDir_quantile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['Short_BestDir_quantile'] > quantile_significance_threshold)]\n",
    "LR_likely_active_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['combined_best_direction_indicies']==0) & ((ripple_combined_epoch_stats_df['LR_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['LR_Short_rank_percentile'] > quantile_significance_threshold))]\n",
    "RL_likely_active_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['combined_best_direction_indicies']==1) & ((ripple_combined_epoch_stats_df['RL_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['RL_Short_rank_percentile'] > quantile_significance_threshold))]\n",
    "\n",
    "# significant_ripple_combined_epoch_stats_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['LR_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['LR_Short_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['RL_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['RL_Short_rank_percentile'] > quantile_significance_threshold)]\n",
    "# significant_ripple_combined_epoch_stats_df\n",
    "is_epoch_significant = np.isin(ripple_combined_epoch_stats_df.index, significant_BestDir_quantile_stats_df.index)\n",
    "active_replay_epochs_df = rank_order_results.LR_ripple.epochs_df\n",
    "significant_ripple_epochs: Epoch = Epoch(deepcopy(active_replay_epochs_df).epochs.get_valid_df()).boolean_indicies_slice(is_epoch_significant)\n",
    "epoch_identifiers = significant_ripple_epochs._df.label.astype({'label': RankOrderAnalyses._label_column_type}).values #.labels\n",
    "x_values = significant_ripple_epochs.midtimes\n",
    "x_axis_name_suffix = 'Mid-time (Sec)'\n",
    "\n",
    "# significant_ripple_epochs_df = significant_ripple_epochs.to_dataframe()\n",
    "# significant_ripple_epochs_df\n",
    "\n",
    "significant_BestDir_quantile_stats_df['midtimes'] = significant_ripple_epochs.midtimes\n",
    "significant_BestDir_quantile_stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee47f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import reorder_columns\n",
    "\n",
    "dict(zip(['Long_LR_evidence', 'Long_RL_evidence', 'Short_LR_evidence', 'Short_RL_evidence'], np.arange(4)+4))\n",
    "reorder_columns(merged_complete_epoch_stats_df, column_name_desired_index_dict=dict(zip(['Long_LR_evidence', 'Long_RL_evidence', 'Short_LR_evidence', 'Short_RL_evidence'], np.arange(4)+4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import plot_quantile_diffs\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "global_epoch = curr_active_pipeline.filtered_epochs[global_epoch_name]\n",
    "short_epoch = curr_active_pipeline.filtered_epochs[short_epoch_name]\n",
    "split_time_t: float = short_epoch.t_start\n",
    "active_context = curr_active_pipeline.sess.get_context()\n",
    "\n",
    "collector = plot_quantile_diffs(ripple_merged_complete_epoch_stats_df, t_split=split_time_t, active_context=active_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43327521",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logical_not(np.isnan(rank_order_results.ripple_combined_epoch_stats_df.index).any())\n",
    "# ripple_combined_epoch_stats_df.label.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_combined_epoch_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3cedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(ripple_combined_epoch_stats_df.label).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31224e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(ripple_combined_epoch_stats_df.index).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60749347",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "print(f'\\tdone. building global result.')\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "selected_spikes_df = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.selected_spikes_df)\n",
    "# active_epochs = global_computation_results.computed_data['RankOrder'].ripple_most_likely_result_tuple.active_epochs\n",
    "active_epochs = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.epochs_df)\n",
    "track_templates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ab4052",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_combined_epoch_stats_df, ripple_new_output_tuple = RankOrderAnalyses.pandas_df_based_correlation_computations(selected_spikes_df=selected_spikes_df, active_epochs_df=active_epochs, track_templates=track_templates, num_shuffles=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313886d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_output_tuple (output_active_epoch_computed_values, valid_stacked_arrays, real_stacked_arrays, n_valid_shuffles) = ripple_new_output_tuple\n",
    "curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_combined_epoch_stats_df, curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_new_output_tuple = ripple_combined_epoch_stats_df, ripple_new_output_tuple\n",
    "print(f'done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc018065",
   "metadata": {},
   "source": [
    "# Call perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82c6522e",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(curr_session_context: kdiba_gor01_one_2006-6-09_1-22-43, curr_session_basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43, ...)\n",
      "\tactive_context: kdiba_gor01_one_2006-6-09_1-22-43_testNEW\n",
      "\tsession_ctxt_key: kdiba|gor01|one|2006-6-09_1-22-43|testNEW\n",
      "\tCURR_BATCH_OUTPUT_PREFIX: 2024-07-10_Apogee-2006-6-09_1-22-43-testNEW\n",
      "\tout_path_str: \"2024-07-10_Apogee-2006-6-09_1-22-43-testNEW_time_bin_size_sweep_results.h5\"\n",
      "\tout_path: \"K:\\scratch\\collected_outputs\\2024-07-10_Apogee-2006-6-09_1-22-43-testNEW_time_bin_size_sweep_results.h5\"\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\ta_sweep_dict: {'desired_laps_decoding_time_bin_size': 1.5, 'desired_ripple_decoding_time_bin_size': 0.02, 'use_single_time_bin_per_epoch': False, 'minimum_event_duration': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.02).\n",
      "\tdropping -1 that are shorter than our minimum_event_duration of 0.02.\t411 remain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning: object name is not a valid Python identifier: 'kdiba|gor01|one|2006-6-09_1-22-43|testNEW'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '1.5'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '0.02'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 27/84\n",
      "\tagreeing_rows_ratio: 0.32142857142857145\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 109/411\n",
      "\tagreeing_rows_ratio: 0.26520681265206814\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 72/84\n",
      "\tagreeing_rows_ratio: 0.8571428571428571\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 115/411\n",
      "\tagreeing_rows_ratio: 0.2798053527980535\n",
      "`return_full_decoding_results` is True and `save_hdf` is True, but I do not yet know how to propperly output the `output_alt_directional_merged_decoders_result`\n",
      ">>\t done with kdiba_gor01_one_2006-6-09_1-22-43\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{frozenset({('desired_laps_decoding_time_bin_size', 1.5), ('desired_ripple_decoding_time_bin_size', 0.02), ('minimum_event_duration', 0.02), ('use_single_time_bin_per_epoch', False)}): 1.5}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _subfn_compute_complete_df_metrics\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "save_hdf: bool = True\n",
    "save_csvs:bool = True\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "# %pdb on\n",
    "## Combine the output of `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "# desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=10)\n",
    "# desired_shared_decoding_time_bin_sizes = np.linspace(start=0.005, stop=0.03, num=10)\n",
    "# _across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tacross_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=save_hdf, return_full_decoding_results=return_full_decoding_results,\n",
    "#                                                 desired_shared_decoding_time_bin_sizes=desired_shared_decoding_time_bin_sizes,\n",
    "#                                                 )\n",
    "\n",
    "\n",
    "# desired_laps_decoding_time_bin_size = [None] # doesn't work\n",
    "desired_laps_decoding_time_bin_size = [1.5] # large so it doesn't take long\n",
    "# desired_ripple_decoding_time_bin_size = [0.010, 0.020]\n",
    "desired_ripple_decoding_time_bin_size = [0.020]\n",
    "\n",
    "custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_size,\n",
    "                                                                                desired_ripple_decoding_time_bin_size=desired_ripple_decoding_time_bin_size,\n",
    "                                                                        use_single_time_bin_per_epoch=[False],\n",
    "                                                                        minimum_event_duration=[desired_ripple_decoding_time_bin_size[-1]])\n",
    "\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tacross_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=save_hdf, save_csvs=save_csvs, return_full_decoding_results=return_full_decoding_results,\n",
    "                                                # desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=4),\n",
    "                                                custom_all_param_sweep_options=custom_all_param_sweep_options, # directly provide the parameter sweeps\n",
    "                                                # additional_session_context=additional_session_context,\n",
    "                                                additional_session_context=IdentifyingContext(custom_suffix='testNEW')\n",
    "                                                )\n",
    "\n",
    "\n",
    "if return_full_decoding_results:\n",
    "    # with `return_full_decoding_results == True`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_full_directional_merged_decoders_result, output_directional_decoders_epochs_decode_results_dict = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    # validate the result:\n",
    "    {k:v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size for k,v in output_full_directional_merged_decoders_result.items()}\n",
    "    # assert np.all([np.isclose(dict(k)['desired_shared_decoding_time_bin_size'], v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size) for k,v in output_full_directional_merged_decoders_result.items()]), f\"the desired time_bin_size in the parameters should match the one used that will appear in the decoded result\"\n",
    "\n",
    "else:\n",
    "    # with `return_full_decoding_results == False`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    output_full_directional_merged_decoders_result = None\n",
    "\n",
    "\n",
    "(several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2695a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43_testNEW-(ripple_marginals_df).csv')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ripple_out_path\n",
    "# {k:v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size for k,v in output_full_directional_merged_decoders_result.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee06d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44cb39d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_LR</th>\n",
       "      <th>P_RL</th>\n",
       "      <th>P_Long</th>\n",
       "      <th>P_Short</th>\n",
       "      <th>ripple_idx</th>\n",
       "      <th>ripple_start_t</th>\n",
       "      <th>session_name</th>\n",
       "      <th>delta_aligned_start_t</th>\n",
       "      <th>time_bin_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.997369</td>\n",
       "      <td>0.968938</td>\n",
       "      <td>0.031062</td>\n",
       "      <td>0</td>\n",
       "      <td>42.658077</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-986.658531</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.707599</td>\n",
       "      <td>0.292401</td>\n",
       "      <td>0.497807</td>\n",
       "      <td>0.502193</td>\n",
       "      <td>1</td>\n",
       "      <td>55.723809</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-973.592800</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.535340</td>\n",
       "      <td>0.464660</td>\n",
       "      <td>0.570379</td>\n",
       "      <td>0.429621</td>\n",
       "      <td>2</td>\n",
       "      <td>73.681176</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-955.635433</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.532649</td>\n",
       "      <td>0.537969</td>\n",
       "      <td>0.462031</td>\n",
       "      <td>3</td>\n",
       "      <td>92.642502</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-936.674106</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.521906</td>\n",
       "      <td>0.478094</td>\n",
       "      <td>0.459222</td>\n",
       "      <td>0.540778</td>\n",
       "      <td>4</td>\n",
       "      <td>93.027055</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-936.289554</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.366953</td>\n",
       "      <td>0.633047</td>\n",
       "      <td>0.238760</td>\n",
       "      <td>0.761240</td>\n",
       "      <td>5</td>\n",
       "      <td>93.925000</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-935.391609</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.561169</td>\n",
       "      <td>0.438831</td>\n",
       "      <td>0.426264</td>\n",
       "      <td>0.573736</td>\n",
       "      <td>405</td>\n",
       "      <td>1729.689083</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>700.372474</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.225156</td>\n",
       "      <td>0.774844</td>\n",
       "      <td>0.252030</td>\n",
       "      <td>0.747970</td>\n",
       "      <td>406</td>\n",
       "      <td>1731.111480</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>701.794871</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.584290</td>\n",
       "      <td>0.415710</td>\n",
       "      <td>407</td>\n",
       "      <td>1731.789992</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>702.473383</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.591584</td>\n",
       "      <td>0.408416</td>\n",
       "      <td>0.361110</td>\n",
       "      <td>0.638890</td>\n",
       "      <td>408</td>\n",
       "      <td>1733.729959</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>704.413350</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.201273</td>\n",
       "      <td>0.798727</td>\n",
       "      <td>0.376423</td>\n",
       "      <td>0.623577</td>\n",
       "      <td>409</td>\n",
       "      <td>1734.961032</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>705.644423</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.319264</td>\n",
       "      <td>0.680736</td>\n",
       "      <td>0.669694</td>\n",
       "      <td>0.330306</td>\n",
       "      <td>410</td>\n",
       "      <td>1736.892796</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>707.576188</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         P_LR      P_RL    P_Long   P_Short  ripple_idx  ripple_start_t       session_name  delta_aligned_start_t  time_bin_size\n",
       "0    0.002631  0.997369  0.968938  0.031062           0       42.658077  2006-6-09_1-22-43            -986.658531           0.02\n",
       "1    0.707599  0.292401  0.497807  0.502193           1       55.723809  2006-6-09_1-22-43            -973.592800           0.02\n",
       "2    0.535340  0.464660  0.570379  0.429621           2       73.681176  2006-6-09_1-22-43            -955.635433           0.02\n",
       "3    0.467351  0.532649  0.537969  0.462031           3       92.642502  2006-6-09_1-22-43            -936.674106           0.02\n",
       "4    0.521906  0.478094  0.459222  0.540778           4       93.027055  2006-6-09_1-22-43            -936.289554           0.02\n",
       "5    0.366953  0.633047  0.238760  0.761240           5       93.925000  2006-6-09_1-22-43            -935.391609           0.02\n",
       "..        ...       ...       ...       ...         ...             ...                ...                    ...            ...\n",
       "405  0.561169  0.438831  0.426264  0.573736         405     1729.689083  2006-6-09_1-22-43             700.372474           0.02\n",
       "406  0.225156  0.774844  0.252030  0.747970         406     1731.111480  2006-6-09_1-22-43             701.794871           0.02\n",
       "407  0.000014  0.999986  0.584290  0.415710         407     1731.789992  2006-6-09_1-22-43             702.473383           0.02\n",
       "408  0.591584  0.408416  0.361110  0.638890         408     1733.729959  2006-6-09_1-22-43             704.413350           0.02\n",
       "409  0.201273  0.798727  0.376423  0.623577         409     1734.961032  2006-6-09_1-22-43             705.644423           0.02\n",
       "410  0.319264  0.680736  0.669694  0.330306         410     1736.892796  2006-6-09_1-22-43             707.576188           0.02\n",
       "\n",
       "[411 rows x 9 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43_testNEW-(ripple_marginals_df).csv')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_LR</th>\n",
       "      <th>P_RL</th>\n",
       "      <th>P_Long</th>\n",
       "      <th>P_Short</th>\n",
       "      <th>epoch_idx</th>\n",
       "      <th>t_bin_center</th>\n",
       "      <th>session_name</th>\n",
       "      <th>delta_aligned_start_t</th>\n",
       "      <th>time_bin_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.997369</td>\n",
       "      <td>0.968938</td>\n",
       "      <td>0.031062</td>\n",
       "      <td>0</td>\n",
       "      <td>42.658577</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-986.658031</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.711343</td>\n",
       "      <td>0.288657</td>\n",
       "      <td>0.593983</td>\n",
       "      <td>0.406017</td>\n",
       "      <td>1</td>\n",
       "      <td>55.733809</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-973.582800</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.666535</td>\n",
       "      <td>0.333465</td>\n",
       "      <td>1</td>\n",
       "      <td>55.753809</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-973.562800</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998824</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.650200</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>1</td>\n",
       "      <td>55.773809</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-973.542800</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.988141</td>\n",
       "      <td>0.011859</td>\n",
       "      <td>0.310654</td>\n",
       "      <td>0.689346</td>\n",
       "      <td>1</td>\n",
       "      <td>55.793809</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-973.522800</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.495844</td>\n",
       "      <td>0.504156</td>\n",
       "      <td>0.611505</td>\n",
       "      <td>0.388495</td>\n",
       "      <td>1</td>\n",
       "      <td>55.813809</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>-973.502800</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>0.579477</td>\n",
       "      <td>0.420523</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>0.972892</td>\n",
       "      <td>409</td>\n",
       "      <td>1734.971032</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>705.654423</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>0.024336</td>\n",
       "      <td>0.975664</td>\n",
       "      <td>0.255380</td>\n",
       "      <td>0.744620</td>\n",
       "      <td>409</td>\n",
       "      <td>1734.991032</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>705.674423</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.846782</td>\n",
       "      <td>0.153218</td>\n",
       "      <td>409</td>\n",
       "      <td>1735.011032</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>705.694423</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3662</th>\n",
       "      <td>0.953417</td>\n",
       "      <td>0.046583</td>\n",
       "      <td>0.581639</td>\n",
       "      <td>0.418361</td>\n",
       "      <td>410</td>\n",
       "      <td>1736.902796</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>707.586188</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663</th>\n",
       "      <td>0.003628</td>\n",
       "      <td>0.996372</td>\n",
       "      <td>0.509437</td>\n",
       "      <td>0.490563</td>\n",
       "      <td>410</td>\n",
       "      <td>1736.922796</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>707.606188</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3664</th>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.999251</td>\n",
       "      <td>0.918005</td>\n",
       "      <td>0.081995</td>\n",
       "      <td>410</td>\n",
       "      <td>1736.942796</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>707.626188</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3665 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          P_LR      P_RL    P_Long   P_Short  epoch_idx  t_bin_center       session_name  delta_aligned_start_t  time_bin_size\n",
       "0     0.002631  0.997369  0.968938  0.031062          0     42.658577  2006-6-09_1-22-43            -986.658031           0.02\n",
       "1     0.711343  0.288657  0.593983  0.406017          1     55.733809  2006-6-09_1-22-43            -973.582800           0.02\n",
       "2     0.998944  0.001056  0.666535  0.333465          1     55.753809  2006-6-09_1-22-43            -973.562800           0.02\n",
       "3     0.998824  0.001176  0.650200  0.349800          1     55.773809  2006-6-09_1-22-43            -973.542800           0.02\n",
       "4     0.988141  0.011859  0.310654  0.689346          1     55.793809  2006-6-09_1-22-43            -973.522800           0.02\n",
       "5     0.495844  0.504156  0.611505  0.388495          1     55.813809  2006-6-09_1-22-43            -973.502800           0.02\n",
       "...        ...       ...       ...       ...        ...           ...                ...                    ...            ...\n",
       "3659  0.579477  0.420523  0.027108  0.972892        409   1734.971032  2006-6-09_1-22-43             705.654423           0.02\n",
       "3660  0.024336  0.975664  0.255380  0.744620        409   1734.991032  2006-6-09_1-22-43             705.674423           0.02\n",
       "3661  0.000007  0.999993  0.846782  0.153218        409   1735.011032  2006-6-09_1-22-43             705.694423           0.02\n",
       "3662  0.953417  0.046583  0.581639  0.418361        410   1736.902796  2006-6-09_1-22-43             707.586188           0.02\n",
       "3663  0.003628  0.996372  0.509437  0.490563        410   1736.922796  2006-6-09_1-22-43             707.606188           0.02\n",
       "3664  0.000749  0.999251  0.918005  0.081995        410   1736.942796  2006-6-09_1-22-43             707.626188           0.02\n",
       "\n",
       "[3665 rows x 9 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43_testNEW-(ripple_time_bin_marginals_df).csv')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "several_time_bin_sizes_ripple_df\n",
    "\n",
    "ripple_out_path # 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewKamranExportedReplays-(ripple_marginals_df).csv'\n",
    "# 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_marginals_df).csv'\n",
    "several_time_bin_sizes_time_bin_ripple_df\n",
    "\n",
    "ripple_time_bin_marginals_out_path # 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewKamranExportedReplays-(ripple_time_bin_marginals_df).csv'\n",
    "# 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_time_bin_marginals_df).csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c689e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2dfa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v: DecoderDecodedEpochsResult = list(output_directional_decoders_epochs_decode_results_dict.values())[0]\n",
    "type(v)\n",
    "\n",
    "v.add_all_extra_epoch_columns(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates)\n",
    "# _out = v.export_csvs(parent_output_path=collected_outputs_path, active_context=curr_active_pipeline.get_session_context(), session_name=curr_active_pipeline.session_name, curr_session_t_delta=t_delta)\n",
    "\n",
    "# assert self.collected_outputs_path.exists()\n",
    "# curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "# CURR_BATCH_OUTPUT_PREFIX: str = f\"{self.BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "# print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_computations\n",
    "# curr_active_pipeline.reload_default_computation_functions()\n",
    "# batch_extended_computations(curr_active_pipeline, include_includelist=['merged_directional_placefields'], include_global_functions=True, fail_on_exception=True, force_recompute=False)\n",
    "# directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context()\n",
    "# _out = directional_merged_decoders_result.compute_and_export_marginals_df_csvs(parent_output_path=self.collected_outputs_path, active_context=active_context)\n",
    "# print(f'successfully exported marginals_df_csvs to {self.collected_outputs_path}!')\n",
    "# (laps_marginals_df, laps_out_path), (ripple_marginals_df, ripple_out_path) = _out\n",
    "# (laps_marginals_df, laps_out_path, laps_time_bin_marginals_df, laps_time_bin_marginals_out_path), (ripple_marginals_df, ripple_out_path, ripple_time_bin_marginals_df, ripple_time_bin_marginals_out_path) = _out\n",
    "# print(f'\\tlaps_out_path: {laps_out_path}\\n\\tripple_out_path: {ripple_out_path}\\n\\tdone.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d13db",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.ripple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take extra computations from `_decode_and_evaluate_epochs_using_directional_decoders` and integrate into the multi-time-bin results from `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_all_df_score_metrics\n",
    "\n",
    "should_skip_radon_transform = True\n",
    "## Recompute the epoch scores/metrics such as radon transform and wcorr:\n",
    "\n",
    "a_sweep_tuple, a_pseudo_2D_result = list(output_full_directional_merged_decoders_result.items())[0]\n",
    "a_decoder_laps_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result)\n",
    "a_decoder_ripple_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_ripple_filter_epochs_decoder_result)\n",
    "\n",
    "(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict), merged_df_outputs_tuple, raw_dict_outputs_tuple = _compute_all_df_score_metrics(directional_merged_decoders_result, track_templates,\n",
    "                                                                                                                                                                                    decoder_laps_filter_epochs_decoder_result_dict=a_decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict=a_decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                                                                    spikes_df=deepcopy(curr_active_pipeline.sess.spikes_df),\n",
    "                                                                                                                                                                                    should_skip_radon_transform=should_skip_radon_transform)\n",
    "laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df, laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df = merged_df_outputs_tuple\n",
    "decoder_laps_radon_transform_df_dict, decoder_ripple_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict, decoder_ripple_radon_transform_extras_dict, decoder_laps_weighted_corr_df_dict, decoder_ripple_weighted_corr_df_dict = raw_dict_outputs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a3ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_sweep_tuple, a_pseudo_2D_result in output_full_directional_merged_decoders_result.items():\n",
    "    a_pseudo_2D_result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfda868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `_perform_compute_custom_epoch_decoding`\n",
    "\n",
    "a_sweep_tuple\n",
    "# a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result\n",
    "# a_pseudo_2D_result\n",
    "# a_pseudo_2D_result.short_directional_decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9603a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_keys_if_possible('several_time_bin_sizes_laps_df', several_time_bin_sizes_laps_df)\n",
    "print_keys_if_possible('output_full_directional_merged_decoders_result', output_full_directional_merged_decoders_result, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a71abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_file_pat\n",
    "collected_outputs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_laps_decoding_accuracy_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd970d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd6f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from neuropy.utils.matplotlib_helpers import pho_jointplot\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import pho_jointplot, plot_histograms\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# def pho_jointplot(*args, **kwargs):\n",
    "# \t\"\"\" wraps sns.jointplot to allow adding titles/axis labels/etc.\"\"\"\n",
    "# \ttitle = kwargs.pop('title', None)\n",
    "# \t_out = sns.jointplot(*args, **kwargs)\n",
    "# \tif title is not None:\n",
    "# \t\tplt.suptitle(title)\n",
    "# \treturn _out\n",
    "\n",
    "common_kwargs = dict(ylim=(0,1), hue='time_bin_size') # , marginal_kws=dict(bins=25, fill=True)\n",
    "# sns.jointplot(data=a_laps_all_epoch_bins_marginals_df, x='lap_start_t', y='P_Long', kind=\"scatter\", color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per epoch') #color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per epoch')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per time bin')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per time bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43311ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_histograms\n",
    "\n",
    "# You can use it like this:\n",
    "plot_histograms('Laps', 'One Session', several_time_bin_sizes_time_bin_laps_df, \"several\")\n",
    "plot_histograms('Ripples', 'One Session', several_time_bin_sizes_time_bin_ripple_df, \"several\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "several_time_bin_sizes_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(\n",
    "#     several_time_bin_sizes_laps_df, x=\"P_Long\", col=\"species\", row=\"time_bin_size\",\n",
    "#     binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    "# )\n",
    "\n",
    "sns.displot(\n",
    "    several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', row=\"time_bin_size\",\n",
    "    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be351c18",
   "metadata": {},
   "source": [
    "# 2024-01-31 - Reinvestigation regarding remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d7495",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "## long_short_endcap_analysis:\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "truncation_checking_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d9b54",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "## From Jonathan Long/Short Peaks\n",
    "\n",
    "adds `active_peak_prominence_2d_results` to existing `neuron_replay_stats_df` from `jonathan_firing_rate_analysis_result`, adding the `['long_pf2D_peak_x', 'long_pf2D_peak_y'] + ['short_pf2D_peak_x', 'short_pf2D_peak_y']` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3641aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "neuron_replay_stats_df: pd.DataFrame = deepcopy(jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "neuron_replay_stats_df, all_modified_columns = jonathan_firing_rate_analysis_result.add_peak_promenance_pf_peaks(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates)\n",
    "neuron_replay_stats_df, all_modified_columns = jonathan_firing_rate_analysis_result.add_directional_pf_maximum_peaks(track_templates=track_templates)\n",
    "both_included_neuron_stats_df = deepcopy(neuron_replay_stats_df[neuron_replay_stats_df['LS_pf_peak_x_diff'].notnull()]).drop(columns=['track_membership', 'neuron_type'])\n",
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1325198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(jonathan_firing_rate_analysis_result) # pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.JonathanFiringRateAnalysisResult\n",
    "\n",
    "rdf_df: pd.DataFrame = deepcopy(jonathan_firing_rate_analysis_result.rdf.rdf)\n",
    "rdf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d371a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to JSON\n",
    "output_path = Path(f'output/{get_now_day_str()}_rdf_df.json').resolve()\n",
    "rdf_df.to_json(output_path, orient='records', lines=True) ## This actually looks pretty good!\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a677cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to JSON\n",
    "output_path = Path(f'output/{get_now_day_str()}_neuron_replay_stats_df.json').resolve()\n",
    "neuron_replay_stats_df.to_json(output_path, orient='records', lines=True) ## This actually looks pretty good!\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b794a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_columns = ['start', 'end']\n",
    "invalid_columns = ['active_aclus', 'is_neuron_active', 'firing_rates']\n",
    "invalid_df_subset = rdf_df[join_columns + invalid_columns]\n",
    "invalid_df_subset\n",
    "\n",
    "# Reload DataFrame from JSON\n",
    "df_read: pd.DataFrame = pd.read_json(output_path, orient='records', lines=True)\n",
    "df_read\n",
    "\n",
    "# rdf_df.convert_dtypes().dtypes\n",
    "# rdf_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b50ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf_aclus = both_included_neuron_stats_df.aclu[both_included_neuron_stats_df.has_long_pf].to_numpy()\n",
    "short_pf_aclus = both_included_neuron_stats_df.aclu[both_included_neuron_stats_df.has_short_pf].to_numpy()\n",
    "\n",
    "long_pf_aclus, short_pf_aclus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c34fd9",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "# 2024-04-09 - Maximum peaks only for each template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbcdfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import NumpyHelpers\n",
    "from neuropy.utils.indexing_helpers import intersection_of_arrays, union_of_arrays\n",
    "from neuropy.utils.indexing_helpers import unwrap_single_item\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing import NewType\n",
    "from typing_extensions import TypeAlias\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "DecoderName = NewType('DecoderName', str)\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "\n",
    "# from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _get_directional_pf_peaks_dfs\n",
    "\n",
    "# (LR_only_decoder_aclu_MAX_peak_maps_df, RL_only_decoder_aclu_MAX_peak_maps_df), AnyDir_decoder_aclu_MAX_peak_maps_df = _get_directional_pf_peaks_dfs(track_templates, drop_aclu_if_missing_long_or_short=False)\n",
    "\n",
    "(LR_only_decoder_aclu_MAX_peak_maps_df, RL_only_decoder_aclu_MAX_peak_maps_df), AnyDir_decoder_aclu_MAX_peak_maps_df = track_templates.get_directional_pf_maximum_peaks_dfs(drop_aclu_if_missing_long_or_short=False)\n",
    "\n",
    "\n",
    "AnyDir_decoder_aclu_MAX_peak_maps_df\n",
    "# LR_only_decoder_aclu_MAX_peak_maps_df\n",
    "# RL_only_decoder_aclu_MAX_peak_maps_df\n",
    "\n",
    "long_peak_x = LR_only_decoder_aclu_MAX_peak_maps_df['long_LR'].to_numpy()\n",
    "short_peak_x = LR_only_decoder_aclu_MAX_peak_maps_df['short_LR'].to_numpy()\n",
    "peak_x_diff = LR_only_decoder_aclu_MAX_peak_maps_df['peak_diff'].to_numpy()\n",
    "# decoder_aclu_peak_maps_dict\n",
    "\n",
    "## OUTPUTS: AnyDir_decoder_aclu_MAX_peak_maps_df,\n",
    "## OUTPUTS: LR_only_decoder_aclu_MAX_peak_maps_df, long_peak_x, long_peak_x, peak_x_diff\n",
    "## OUTPUTS: RL_only_decoder_aclu_MAX_peak_maps_df, long_peak_x, long_peak_x, peak_x_diff\n",
    "\n",
    "AnyDir_decoder_aclu_MAX_peak_maps_df\n",
    "LR_only_decoder_aclu_MAX_peak_maps_df\n",
    "RL_only_decoder_aclu_MAX_peak_maps_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed05490",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_filtered_flat_peaks_df: pd.DataFrame = deepcopy(AnyDir_decoder_aclu_MAX_peak_maps_df).reset_index(drop=False, names=['aclu'])\n",
    "a_filtered_flat_peaks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9527c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_peak_prominence_2d_results.filtered_flat_peaks_df\n",
    "\n",
    "binned_peak_columns = ['peak_center_binned_x', 'peak_center_binned_y']\n",
    "continuous_peak_columns = ['peak_center_x', 'peak_center_y']\n",
    "\n",
    "['peak_prominence', 'peak_relative_height', 'slice_level_multiplier']\n",
    "\n",
    "['neuron_id', 'neuron_peak_firing_rate']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604b90dc",
   "metadata": {},
   "source": [
    "## 2024-02-08 - Filter to find only the clear remap examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "from pyphocorehelpers.indexing_helpers import dict_to_full_array\n",
    "\n",
    "any_decoder_neuron_IDs = deepcopy(track_templates.any_decoder_neuron_IDs)\n",
    "any_decoder_neuron_IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0cf56",
   "metadata": {},
   "source": [
    "### Get num peaks exclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c849dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: `directional_active_lap_pf_results_dicts`, not sure why\n",
    "\n",
    "neuron_ids_dict = {k:v.neuron_ids for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "neuron_ids_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec42a8d",
   "metadata": {},
   "source": [
    "### Get stability for each cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ec2d7",
   "metadata": {},
   "source": [
    "#### 2024-02-08 - 3pm - new stability dataframe to look at stability of each cell across decoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57869e27",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "## INPUTS: directional_active_lap_pf_results_dicts\n",
    "\n",
    "# for k,v in directional_active_lap_pf_results_dicts.items():\n",
    "# stability_dict = {k:v.aclu_to_stability_score_dict for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "# stability_dict = {k:dict_to_full_array(v.aclu_to_stability_score_dict, full_indicies=any_decoder_neuron_IDs, fill_value=0.0) for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "# stability_dict\n",
    "\n",
    "\n",
    "# list(stability_dict.values())\n",
    "\n",
    "stability_dict = {k:list(v.aclu_to_stability_score_dict.values()) for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "# stability_dict\n",
    "## all the same size hopefully!\n",
    "# [len(v) for v in list(stability_dict.values())]\n",
    "\n",
    "stability_df: pd.DataFrame = pd.DataFrame({'aclu': any_decoder_neuron_IDs, **stability_dict})\n",
    "# stability_df.rename(dict(zip([], [])))\n",
    "stability_df\n",
    "\n",
    "## OUTPUTS: stability_df, stability_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef13541",
   "metadata": {},
   "source": [
    "# 2024-02-02 - napari_plot_directional_trial_by_trial_activity_viz Trial-by-trial Correlation Matrix C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c4df5b",
   "metadata": {},
   "source": [
    "### 🎨 Show Trial-by-trial Correlation Matrix C in `napari`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad72df59",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import napari\n",
    "from pyphoplacecellanalysis.GUI.Napari.napari_helpers import napari_plot_directional_trial_by_trial_activity_viz, napari_trial_by_trial_activity_viz, build_aclu_label, napari_export_image_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e1057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from magicgui.widgets import ComboBox, Container\n",
    "\n",
    "# annotating a paramater as `napari.Viewer` will automatically provide\n",
    "# the viewer that the function is embedded in, when the function is added to\n",
    "# the viewer with add_function_widget.\n",
    "def my_function(viewer: napari.Viewer):\n",
    "    print(viewer, f\"with {len(viewer.layers)} layers\")\n",
    "\n",
    "# Add our magic function to napari\n",
    "directional_viewer.window.add_function_widget(my_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Directional\n",
    "directional_viewer, directional_image_layer_dict, custom_direction_split_layers_dict = napari_plot_directional_trial_by_trial_activity_viz(directional_active_lap_pf_results_dicts, include_trial_by_trial_correlation_matrix=True)\n",
    "a_result = list(directional_active_lap_pf_results_dicts.values())[0]\n",
    "a_matrix_IDX_to_aclu_map = {v:k for k, v in a_result.aclu_to_matrix_IDX_map.items()}\n",
    "on_update_slider, points_layer = build_aclu_label(directional_viewer, a_matrix_IDX_to_aclu_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d79d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: directional_trial_by_trial_activity_result\n",
    "for a_decoder_name, a_result in directional_trial_by_trial_activity_result.directional_active_lap_pf_results_dicts.items():\n",
    "    # a_result.z_scored_tuning_map_matrix\n",
    "\n",
    "    if a_decoder_name == 'maze_any':\n",
    "        # smoothed_spikes_maps_matrix\n",
    "        curr_cum_z_scored_tuning_map_matrix = np.cumsum(a_result.z_scored_tuning_map_matrix, axis=0) \n",
    "        # curr_cum_z_scored_tuning_map_matrix = curr_cum_z_scored_tuning_map_matrix / np.nansum(curr_cum_z_scored_tuning_map_matrix, axis=2, keepdims=True) # sum across all position bins for each neuron\n",
    "        \n",
    "        ## Global:\n",
    "        # viewer, image_layer_dict = napari_trial_by_trial_activity_viz(a_result.z_scored_tuning_map_matrix, a_result.C_trial_by_trial_correlation_matrix, title=f'Trial-by-trial Correlation Matrix C - Decoder {a_decoder_name}', axis_labels=('aclu', 'lap', 'xbin')) # GLOBAL\n",
    "        \n",
    "        # viewer, image_layer_dict = napari_trial_by_trial_activity_viz(curr_cum_z_scored_tuning_map_matrix, a_result.C_trial_by_trial_correlation_matrix, title=f'Trial-by-trial Cumulative Decoder {a_decoder_name}', axis_labels=('aclu', 'lap', 'xbin')) # GLOBAL\n",
    "        a_viewer, image_layer_dict = napari_trial_by_trial_activity_viz(a_result.z_scored_tuning_map_matrix, a_result.C_trial_by_trial_correlation_matrix, curr_cum_z_scored_tuning_map_matrix, title=f'Trial-by-trial Cumulative Decoder {a_decoder_name}', axis_labels=('aclu', 'lap', 'xbin')) # GLOBAL\n",
    "        a_matrix_IDX_to_aclu_map = {v:k for k, v in a_result.aclu_to_matrix_IDX_map.items()}\n",
    "\n",
    "        on_update_slider, points_layer = build_aclu_label(a_viewer, a_matrix_IDX_to_aclu_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b4ec86",
   "metadata": {},
   "source": [
    "# 2023-09-07 - Track Graphics Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b53254",
   "metadata": {},
   "source": [
    "## 🟢🖼️🎨 2024-02-16 - NOW - Working Track Remapping Diagram Figure!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import plot_bidirectional_track_remapping_diagram, _plot_track_remapping_diagram\n",
    "\n",
    "collector = plot_bidirectional_track_remapping_diagram(track_templates, grid_bin_bounds=long_pf2D.config.grid_bin_bounds, active_context=curr_active_pipeline.build_display_context_for_session(display_fn_name='plot_bidirectional_track_remapping_diagram'),\n",
    "                                                        enable_adjust_overlapping_text=False, draw_point_aclu_labels=False, enable_interactivity=False, is_dark_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d1e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "curr_active_pipeline.display('_display_directional_track_remapping_diagram', save_figure=True, is_dark_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4701a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_aclu_if_missing_long_or_short = True\n",
    "# LR_only_decoder_aclu_MAX_peak_maps_df, RL_only_decoder_aclu_MAX_peak_maps_df = _get_directional_pf_peaks_dfs(track_templates, drop_aclu_if_missing_long_or_short=drop_aclu_if_missing_long_or_short)\n",
    "# drop_aclu_if_missing_long_or_short =False\n",
    "(LR_only_decoder_aclu_MAX_peak_maps_df, RL_only_decoder_aclu_MAX_peak_maps_df), AnyDir_decoder_aclu_MAX_peak_maps_df = track_templates.get_directional_pf_maximum_peaks_dfs(drop_aclu_if_missing_long_or_short=drop_aclu_if_missing_long_or_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c35494",
   "metadata": {},
   "outputs": [],
   "source": [
    "AnyDir_decoder_aclu_MAX_peak_maps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfe113",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "_by_ANY = AnyDir_decoder_aclu_MAX_peak_maps_df.sort_values(by=['long_LR', 'long_RL'], inplace=False)\n",
    "long_peak_sorted_unit_colors_ndarray_map = dict(zip(_by_ANY.index.to_numpy(), list(_unit_colors_ndarray_map.values())))\n",
    "long_peak_sorted_unit_colors_ndarray_map\n",
    "\n",
    "# LR_only_decoder_aclu_MAX_peak_maps_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5286baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "AnyDir_decoder_aclu_MAX_peak_maps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d3a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_helper_neuron_id_to_sort_IDX_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7183e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_peak_sorted_unit_colors_ndarray_map_LR = dict(zip(sorted_neuron_IDs_lists[0], list(_unit_colors_ndarray_map.values())))\n",
    "long_peak_sorted_unit_colors_ndarray_map_RL = dict(zip(sorted_neuron_IDs_lists[1], list(_unit_colors_ndarray_map.values())))\n",
    "long_peak_sorted_unit_colors_ndarray_map_LR\n",
    "long_peak_sorted_unit_colors_ndarray_map_RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be25d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "colormap = mcolors.ListedColormap(['white'])\n",
    "normalize = mcolors.Normalize(vmin=active_aclus.min(), vmax=active_aclus.max())\n",
    "scalar_map = cm.ScalarMappable(norm=normalize, cmap=colormap)\n",
    "\n",
    "# Create a constant colormap with only white color\n",
    "\n",
    "color = scalar_map.to_rgba(active_aclus)\n",
    "\n",
    "color = [_unit_colors_ndarray_map[an_aclu] for an_aclu in active_aclus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a9a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS:\n",
    "neuron_replay_stats_df\n",
    "\n",
    "_active_LR_aclus = np.array(list(_output_by_aclu_dict_LR.keys()))\n",
    "_active_LR_aclus\n",
    "\n",
    "is_active_LR_aclus = np.isin(neuron_replay_stats_df.aclu, _active_LR_aclus)\n",
    "_temp_neuron_replay_stats_df = neuron_replay_stats_df[is_active_LR_aclus]\n",
    "\n",
    "is_active_LR_long_peak_either_cap_dict = _temp_neuron_replay_stats_df['is_long_peak_either_cap'].to_dict()\n",
    "is_active_LR_long_peak_either_cap_dict\n",
    "\n",
    "\n",
    "# either_cap_aclu = {k:v for k,v in is_active_LR_long_peak_either_cap_dict.items() if (v is True)}\n",
    "\n",
    "active_LR_either_cap_aclus = np.array([k for k,v in is_active_LR_long_peak_either_cap_dict.items() if (v is True)])\n",
    "active_LR_either_cap_aclus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dac9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Selected ACLUS manually:\n",
    "\n",
    "## `FakePickEvent` is used to highlight specified aclus by emulating a selection event.\n",
    "#  matplotlib.backend_bases.PickEvent\n",
    "import attrs\n",
    "FakePickEvent = attrs.make_class(\"FakePickEvent\", {k:field() for k in (\"ind\", )})\n",
    "\n",
    "included_aclus = [45, 24, 17, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1689f191",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: included_aclus, LR_only_decoder_aclu_MAX_peak_maps_df, RL_only_decoder_aclu_MAX_peak_maps_df, _outputs_tuple_LR, _outputs_tuple_RL\n",
    "included_aclus = active_LR_either_cap_aclus\n",
    "# LR:\n",
    "LR_included_indicies = np.where(np.isin(LR_only_decoder_aclu_MAX_peak_maps_df.index, included_aclus))[0] # LR_included_indicies # [ 6,  9, 22, 36]\n",
    "LR_fake_event: FakePickEvent = FakePickEvent(ind=np.array(LR_included_indicies))\n",
    "_output_dict_LR, _output_by_aclu_dict_LR = _outputs_tuple_LR\n",
    "scatter_select_function_LR = _output_dict_LR['scatter_select_function']\n",
    "scatter_select_function_LR(LR_fake_event)\n",
    "\n",
    "## RL:\n",
    "RL_included_indicies = np.where(np.isin(RL_only_decoder_aclu_MAX_peak_maps_df.index, included_aclus))[0]\n",
    "RL_fake_event: FakePickEvent = FakePickEvent(ind=np.array(RL_included_indicies))\n",
    "_output_dict_RL, _output_by_aclu_dict_RL = _outputs_tuple_RL\n",
    "scatter_select_function_RL = _output_dict_RL['scatter_select_function']\n",
    "scatter_select_function_RL(RL_fake_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce7326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.preprocessing_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6fcb1",
   "metadata": {},
   "source": [
    "# 🎨 2024-02-06 - Other Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5623a2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "\n",
    "#  Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "curr_active_pipeline.prepare_for_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968df7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.tree_helpers import find_tree_item_by_text\n",
    "from pyphoplacecellanalysis.GUI.Qt.MainApplicationWindows.LauncherWidget.LauncherWidget import LauncherWidget\n",
    "\n",
    "widget = LauncherWidget()\n",
    "treeWidget = widget.mainTreeWidget # QTreeWidget\n",
    "widget.build_for_pipeline(curr_active_pipeline=curr_active_pipeline)\n",
    "widget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650eea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "spike_raster_window, (active_2d_plot, active_3d_plot, main_graphics_layout_widget, main_plot_widget, background_static_scroll_plot_widget) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=True)\n",
    "spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a0c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps'] # , 'AddTimeIntervals.SessionEpochs'\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a70360",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.build_epoch_intervals_visual_configs_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8eda4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b41f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downsample the preview background scroller for more fluid scrolling? Or is that not the problem?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Disconnect the connection to see if that's what lagging out the scrolling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.connection_man.active_connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce9f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.rate_limited_signal_scrolled_proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e77367",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.enable_debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71114415",
   "metadata": {},
   "outputs": [],
   "source": [
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-SpikeRaster2D_update_time.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    active_2d_plot.update_scroll_window_region(441.0, 442.0, block_signals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf6288",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the legends:\n",
    "legends_dict = active_2d_plot.build_or_update_all_epoch_interval_rect_legends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the legends\n",
    "active_2d_plot.remove_all_epoch_interval_rect_legends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72734c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.epochs_plotting_mixins import EpochDisplayConfig, _get_default_epoch_configs\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.EpochRenderConfigWidget.EpochRenderConfigWidget import EpochRenderConfigWidget, EpochRenderConfigsListWidget\n",
    "\n",
    "## Build right-sidebar epoch interval configs widget:\n",
    "spike_raster_window.build_epoch_intervals_visual_configs_widget()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" `Plotted Rects` -> `configs widget`\"\"\" \n",
    "active_2d_plot.build_or_update_epoch_render_configs_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25608e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update plots from configs:\n",
    "#     configs widget -> `Plotted Rects` \n",
    "active_2d_plot.update_epochs_from_configs_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd250fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_epochs_display_list_widget = active_2d_plot.ui['epochs_render_configs_widget']\n",
    "_out_configs = deepcopy(an_epochs_display_list_widget.configs_from_states())\n",
    "_out_configs\n",
    "\n",
    "# {'diba_evt_file': EpochDisplayConfig(brush_color='#008000', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='diba_evt_file', pen_color='#008000', pen_opacity=0.6078431372549019, y_location=-52.0),\n",
    "#  'initial_loaded': EpochDisplayConfig(brush_color='#ffffff', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='initial_loaded', pen_color='#ffffff', pen_opacity=0.6078431372549019, y_location=-42.0),\n",
    "#  'PBEs': EpochDisplayConfig(brush_color='#aa55ff', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='PBEs', pen_color='#aaaaff', pen_opacity=0.6078431372549019, y_location=-32.0),\n",
    "#  'Ripples': EpochDisplayConfig(brush_color='#0000ff', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='Ripples', pen_color='#0000ff', pen_opacity=0.6078431372549019, y_location=-22.0),\n",
    "#  'Laps': EpochDisplayConfig(brush_color='#ff0000', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='Laps', pen_color='#ff0000', pen_opacity=0.6078431372549019, y_location=-12.0),\n",
    "#  'normal_computed': EpochDisplayConfig(brush_color='#800080', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='normal_computed', pen_color='#800080', pen_opacity=0.6078431372549019, y_location=-62.0),\n",
    "#  'diba_quiescent_method_replay_epochs': EpochDisplayConfig(brush_color='#ffa500', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='diba_quiescent_method_replay_epochs', pen_color='#ffa500', pen_opacity=0.6078431372549019, y_location=-72.0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86465b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_dict = {k:v.to_dict() for k, v in _out_configs.items()}\n",
    "update_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a38ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e187827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _on_update_rendered_intervals(active_2d_plot):\n",
    "    print(f'_on_update_rendered_intervals(...)')\n",
    "    _legends_dict = active_2d_plot.build_or_update_all_epoch_interval_rect_legends()\n",
    "    epoch_display_configs = active_2d_plot.extract_interval_display_config_lists()\n",
    "    an_epochs_display_list_widget = active_2d_plot.ui.get('epochs_render_configs_widget', None)\n",
    "    if an_epochs_display_list_widget is None:\n",
    "        # create a new one:    \n",
    "        an_epochs_display_list_widget:EpochRenderConfigsListWidget = EpochRenderConfigsListWidget(epoch_display_configs, parent=a_layout_widget)\n",
    "        active_2d_plot.ui.epochs_render_configs_widget = an_epochs_display_list_widget\n",
    "    else:\n",
    "        an_epochs_display_list_widget.update_from_configs(configs=epoch_display_configs)\n",
    "\n",
    "_a_connection = active_2d_plot.sigRenderedIntervalsListChanged.connect(_on_update_rendered_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3096fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import EpochRenderingMixin\n",
    "\n",
    "@function_attributes(short_name=None, tags=['epoch_intervals', 'layout', 'update', 'IMPORTANT'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2024-07-03 05:21', related_items=[])\n",
    "def rebuild_epoch_interval_layouts_given_normalized_heights(active_2d_plot, desired_epoch_render_stack_height:float=70.0):\n",
    "    \"\"\" Re-builds the stacked epoch layout to prevent them from overlapping and to normalize their height\n",
    "    \n",
    "    desired_epoch_render_stack_height: total height for all of the epochs\n",
    "    \n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import EpochRenderingMixin\n",
    "    active_epochs_formatting_dict = active_2d_plot.extract_interval_display_config_lists() ## gets existing formatting dict\n",
    "\n",
    "    # extracts only the height, considers only the first config if the entry is a list:\n",
    "    # original_epoch_display_config_heights = {k:v[0].to_dict()['height'] for k, v in active_epochs_formatting_dict.items()} # {'Replays': 1.9, 'Laps': 0.9, 'diba_evt_file': 10.0, 'initial_loaded': 10.0, 'diba_quiescent_method_replay_epochs': 10.0, 'Ripples': 0.9, 'normal_computed': 10.0}\n",
    "    # original_epoch_display_config_heights ## original heights\n",
    "    required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout((len(active_epochs_formatting_dict) * [1.0]), epoch_render_stack_height=desired_epoch_render_stack_height, interval_stack_location='below') # ratio of heights to each interval\n",
    "    stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(active_epochs_formatting_dict.keys()), required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "    # stacked_epoch_layout_dict # {'LapsAll': {'y_location': -3.6363636363636367, 'height': 3.6363636363636367}, 'LapsTrain': {'y_location': -21.818181818181817, 'height': 18.18181818181818}, 'LapsTest': {'y_location': -40.0, 'height': 18.18181818181818}}\n",
    "    # stacked_epoch_layout_dict\n",
    "\n",
    "    # replaces 'y_location', 'position' for each dict:\n",
    "    update_dict = {k:(v[0].to_dict()|stacked_epoch_layout_dict[k]) for k, v in active_epochs_formatting_dict.items()} # builds a proper update dict from the `active_epochs_formatting_dict` and the new position and height adjustments\n",
    "    # update_dict\n",
    "    active_2d_plot.update_rendered_intervals_visualization_properties(update_dict=update_dict)\n",
    "\n",
    "rebuild_epoch_interval_layouts_given_normalized_heights(active_2d_plot, desired_epoch_render_stack_height=60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd03f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_display_configs = {k:get_dict_subset(v[0].to_dict(), ['height', 'y_location']) for k, v in active_2d_plot.extract_interval_display_config_lists().items()}\n",
    "# epoch_display_configs\n",
    "\n",
    "## Re-build the stacked epochs to prevent them from overlapping:\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import EpochRenderingMixin\n",
    "\n",
    "\n",
    "active_epochs_formatting_dict = active_2d_plot.extract_interval_display_config_lists()\n",
    "\n",
    "epoch_display_config_heights = {k:v[0].to_dict()['height'] for k, v in active_epochs_formatting_dict.items()} # {'Replays': 1.9, 'Laps': 0.9, 'diba_evt_file': 10.0, 'initial_loaded': 10.0, 'diba_quiescent_method_replay_epochs': 10.0, 'Ripples': 0.9, 'normal_computed': 10.0}\n",
    "epoch_display_config_heights\n",
    "required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout((len(active_epochs_formatting_dict) * [1.0]), epoch_render_stack_height=70.0, interval_stack_location='below') # ratio of heights to each interval\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(active_epochs_formatting_dict.keys()), required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "# stacked_epoch_layout_dict # {'LapsAll': {'y_location': -3.6363636363636367, 'height': 3.6363636363636367}, 'LapsTrain': {'y_location': -21.818181818181817, 'height': 18.18181818181818}, 'LapsTest': {'y_location': -40.0, 'height': 18.18181818181818}}\n",
    "# stacked_epoch_layout_dict\n",
    "\n",
    "# replaces 'y_location', 'position' for each dict:\n",
    "update_dict = {k:(v[0].to_dict()|stacked_epoch_layout_dict[k]) for k, v in active_epochs_formatting_dict.items()}\n",
    "update_dict\n",
    "\n",
    "\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(update_dict=update_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c93e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract/Save all active epochs:\n",
    "active_epochs_formatting_dict: Dict[str, List[EpochDisplayConfig]] = deepcopy(active_2d_plot.extract_interval_display_config_lists())\n",
    "active_epochs_formatting_dict\n",
    "\n",
    "# an_epochs_display_list_widget.configs_from_states()\n",
    "\n",
    "\n",
    "an_epochs_display_list_widget = active_2d_plot.ui.get('epochs_render_configs_widget', None)\n",
    "if an_epochs_display_list_widget is None:\n",
    "    raise NotImplementedError\n",
    "    # create a new one:    \n",
    "    an_epochs_display_list_widget:EpochRenderConfigsListWidget = EpochRenderConfigsListWidget(active_epochs_formatting_dict, parent=a_layout_widget)\n",
    "    active_2d_plot.ui.epochs_render_configs_widget = an_epochs_display_list_widget\n",
    "else:\n",
    "    an_epochs_display_list_widget.update_from_configs(configs=active_epochs_formatting_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ad3bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epochs_confgs_dict: Dict[str, EpochDisplayConfig] = deepcopy(an_epochs_display_list_widget.configs_from_states())\n",
    "active_epochs_confgs_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f93d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveData('SpikeRaster2D_saved_Epochs.pkl', active_epochs_confgs_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epochs_formatting_dict['Replays'][0].brush_QColor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7318fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Restore/Load all active epochs:\n",
    "# update_dict = {k:(v[0].to_dict()|stacked_epoch_layout_dict[k]) for k, v in active_epochs_formatting_dict.items()}\n",
    "\n",
    "update_dict = {k:v.to_dict() for k, v in active_epochs_confgs_dict.items()} ## from active_epochs_confgs_dict\n",
    "update_dict\n",
    "\n",
    "## Updates intervals themselves\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(update_dict=update_dict)\n",
    "\n",
    "## updates configs:\n",
    "# active_2d_plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673515f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_all_rendered_intervals_dict = active_2d_plot.get_all_rendered_intervals_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1292a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epochs_interval_datasources_dict: Dict[str, IntervalsDatasource] = active_2d_plot.interval_datasources\n",
    "active_epochs_interval_datasources_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb58bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {}\n",
    "rendered_epoch_names = active_2d_plot.interval_datasource_names\n",
    "print(f'rendered_epoch_names: {rendered_epoch_names}')\n",
    "for a_name in rendered_epoch_names:\n",
    "    a_render_container = active_2d_plot.rendered_epochs[a_name]\n",
    "    out_dict[a_name] = a_render_container\n",
    "\n",
    "out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86464ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb198ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_widget.setVisible(False) ## top plot disappeared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedfcbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_widget.setVisible(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78c7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Connections\n",
    "active_2d_plot.setVisible(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdaaca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.get_all_rendered_intervals_dict()\n",
    "active_2d_plot.interval_datasources\n",
    "# active_2d_plot.interval_rendering_plots\n",
    "active_2d_plot.interval_datasource_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04656a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaca430",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.setVisible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c1badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.isVisible()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697d558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import ensure_Epoch, Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, inline_mkColor\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.EpochRenderingMixin import EpochRenderingMixin, RenderedEpochsItemsContainer\n",
    "from pyphoplacecellanalysis.General.Model.Datasources.IntervalDatasource import IntervalsDatasource\n",
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "\n",
    "## Add various replay epochs as interval rects:\n",
    "\n",
    "## INPUTS: replay_epoch_variations\n",
    "\n",
    "# replay_epoch_variations\n",
    "\n",
    "\n",
    "## Use the three dataframes as separate Epoch series:\n",
    "custom_replay_dfs_dict = {k:ensure_dataframe(deepcopy(v)) for k, v in replay_epoch_variations.items()}\n",
    "custom_replay_keys = list(custom_replay_dfs_dict.keys()) # \n",
    "print(f'{custom_replay_keys}') # ['initial_loaded', 'normal_computed', 'diba_evt_file', 'diba_quiescent_method_replay_epochs']\n",
    "\n",
    "\n",
    "_color_rotation_order = ['white', 'purple', 'green', 'orange', 'pink', 'red']\n",
    "\n",
    "custom_replay_epochs_formatting_dict = {\n",
    "    'initial_loaded':dict(pen_color=inline_mkColor('white', 0.8), brush_color=inline_mkColor('white', 0.5)),\n",
    "    'normal_computed':dict(pen_color=inline_mkColor('purple', 0.8), brush_color=inline_mkColor('purple', 0.5)),\n",
    "    'diba_evt_file':dict(pen_color=inline_mkColor('green', 0.8), brush_color=inline_mkColor('green', 0.5)),\n",
    "    'diba_quiescent_method_replay_epochs':dict(pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5)),\n",
    "}\n",
    "\n",
    "# required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout((len(custom_replay_dfs_dict) * [1.0]), epoch_render_stack_height=40.0, interval_stack_location='below') # ratio of heights to each interval\n",
    "# stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(custom_replay_epochs_formatting_dict.keys()), required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(custom_replay_epochs_formatting_dict.keys()), *EpochRenderingMixin.build_stacked_epoch_layout((len(custom_replay_dfs_dict) * [1.0]), epoch_render_stack_height=40.0, interval_stack_location='below'))} # Build a stacked_epoch_layout_dict to update the display\n",
    "# replaces 'y_location', 'position' for each dict:\n",
    "custom_replay_epochs_formatting_dict = {k:(v|stacked_epoch_layout_dict[k]) for k, v in custom_replay_epochs_formatting_dict.items()}\n",
    "# custom_replay_epochs_formatting_dict\n",
    "\n",
    "# OUTPUTS: train_test_split_laps_dfs_dict, custom_replay_epochs_formatting_dict\n",
    "## INPUTS: train_test_split_laps_dfs_dict\n",
    "custom_replay_dfs_dict = {k:TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(df=v, required_columns_synonym_dict=IntervalsDatasource._time_column_name_synonyms) for k, v in custom_replay_dfs_dict.items()}\n",
    "\n",
    "## Build interval datasources for them:\n",
    "custom_replay_dfs_datasources_dict = {k:General2DRenderTimeEpochs.build_render_time_epochs_datasource(v) for k, v in custom_replay_dfs_dict.items()}\n",
    "## INPUTS: active_2d_plot, train_test_split_laps_epochs_formatting_dict, train_test_split_laps_dfs_datasources_dict\n",
    "assert len(custom_replay_epochs_formatting_dict) == len(custom_replay_dfs_datasources_dict)\n",
    "for k, an_interval_ds in custom_replay_dfs_datasources_dict.items():\n",
    "    an_interval_ds.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, **(custom_replay_epochs_formatting_dict[k] | kwargs)))\n",
    "\n",
    "\n",
    "## Full output: train_test_split_laps_dfs_datasources_dict\n",
    "\n",
    "\n",
    "# actually add the epochs:\n",
    "for k, an_interval_ds in custom_replay_dfs_datasources_dict.items():\n",
    "    active_2d_plot.add_rendered_intervals(an_interval_ds, name=f'{k}', debug_print=False) # adds the interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34342d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params.enable_time_interval_legend_in_right_margin = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51663689",
   "metadata": {},
   "outputs": [],
   "source": [
    "## They can later be updated via:\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(custom_replay_epochs_formatting_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4765fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747008be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f6520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d073b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_replay_epochs.to_file('new_replays.csv')\n",
    "new_replay_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d680b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_order_results.minimum_inclusion_fr_Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc7f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.long_LR_decoder.neuron_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e8b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a672c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg # Used to get the app for TopLevelWindowHelper.top_level_windows\n",
    "## For searching with `TopLevelWindowHelper.all_widgets(...)`:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike3DRaster import Spike3DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "found_spike_raster_windows = TopLevelWindowHelper.all_widgets(pg.mkQApp(), searchType=Spike3DRasterWindowWidget)\n",
    "\n",
    "if len(found_spike_raster_windows) < 1:\n",
    "\t# no existing spike_raster_windows. Make a new one\n",
    "\tprint(f'no existing SpikeRasterWindow. Creating a new one.')\n",
    "\t# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "\tactive_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\n",
    "\n",
    "else:\n",
    "\tprint(f'found {len(found_spike_raster_windows)} existing Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...). Will use the most recent.')\n",
    "\t# assert len(found_spike_raster_windows) == 1, f\"found {len(found_spike_raster_windows)} Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...) but require exactly one.\"\n",
    "\t# Get the most recent existing one and reuse that:\n",
    "\tspike_raster_window = found_spike_raster_windows[0]\n",
    "\n",
    "\n",
    "# Extras:\n",
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "active_3d_plot = spike_raster_window.spike_raster_plt_3d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "main_graphics_layout_widget = active_2d_plot.ui.main_graphics_layout_widget # GraphicsLayoutWidget\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "background_static_scroll_plot_widget = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d1927",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_items = widget.get_display_function_items()\n",
    "_display_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_fcn_name = '_display_batch_pho_jonathan_replay_firing_rate_comparison'\n",
    "a_fn_handle = widget._perform_get_display_function_code(a_fcn_name=a_fcn_name)\n",
    "assert a_fn_handle is not None\n",
    "# args = []\n",
    "# kwargs = {}\n",
    "a_disp_fn_item = widget.get_display_function_item(a_fn_name=a_fcn_name)\n",
    "assert a_disp_fn_item is not None, f\"a_disp_fn_item is None! for a_fn_name='{a_fcn_name}'\"\n",
    "\n",
    "a_disp_fn_item.is_global\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c91ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display(display_function=a_fcn_name, active_session_configuration_context=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d735d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, n_max_page_rows=10, disable_top_row=True, write_png=False, write_vector_format=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out.figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_spike_rasters_pyqtplot_3D_with_2D_controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c70b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(_display_items.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29925698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import FigureCollector\n",
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_remapping_cells\n",
    "\n",
    "collector: FigureCollector = fig_remapping_cells(curr_active_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not isinstance(curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis, JonathanFiringRateAnalysisResult):\n",
    "    jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "else:\n",
    "    jonathan_firing_rate_analysis_result = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "\n",
    "neuron_replay_stats_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df.copy()\n",
    "neuron_replay_stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_sorted_neuron_stats_df = neuron_replay_stats_df.sort_values(by=sortby, ascending=[True, True, True], inplace=False).copy() # also did test_df = neuron_replay_stats_df.sort_values(by=['long_pf_peak_x'], inplace=False, ascending=True).copy()\n",
    "_sorted_neuron_stats_df = _sorted_neuron_stats_df[np.isin(_sorted_neuron_stats_df.index, curr_any_context_neurons)] # clip to only those neurons included in `curr_any_context_neurons`\n",
    "_sorted_aclus = _sorted_neuron_stats_df.index.to_numpy()\n",
    "_sorted_neuron_IDXs = _sorted_neuron_stats_df.neuron_IDX.to_numpy()\n",
    "if debug_print:\n",
    "    print(f'_sorted_aclus: {_sorted_aclus}')\n",
    "    print(f'_sorted_neuron_IDXs: {_sorted_neuron_IDXs}')\n",
    "\n",
    "## Use this sort for the 'curr_any_context_neurons' sort order:\n",
    "new_all_aclus_sort_indicies, desired_sort_arr = find_desired_sort_indicies(curr_any_context_neurons, _sorted_aclus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2fa1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _directional_laps_overview = curr_active_pipeline.plot._display_directional_laps_overview(curr_active_pipeline.computation_results, a)\n",
    "# _directional_laps_overview = curr_active_pipeline.display('_display_directional_laps_overview')\n",
    "# _directional_laps_overview = curr_active_pipeline.display('_display_grid_bin_bounds_validation')\n",
    "_directional_laps_overview = curr_active_pipeline.display('_display_long_short_pf1D_comparison')\n",
    "\n",
    "_directional_laps_overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9992e42",
   "metadata": {},
   "source": [
    "### 🟢🔝🖼️🎨 2024-06-06 - Works to render the contour curve at a fixed promenence (the shape of the placefield's cap/crest) for each placefield:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff6d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho3D.PyVista.peak_prominences import render_all_neuron_peak_prominence_2d_results_on_pyvista_plotter\n",
    "\n",
    "display_output = {}\n",
    "active_config_name = long_LR_name\n",
    "print(f'active_config_name: {active_config_name}')\n",
    "active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "pActiveTuningCurvesPlotter = None\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "active_config_modifiying_kwargs = {\n",
    "    'plotting_config': {'should_use_linear_track_geometry': True, \n",
    "                        't_start': t_start, 't_delta': t_delta, 't_end': t_end,\n",
    "                        }\n",
    "}\n",
    "display_output = display_output | curr_active_pipeline.display('_display_3d_interactive_tuning_curves_plotter', active_config_name, extant_plotter=display_output.get('pActiveTuningCurvesPlotter', None),\n",
    "                                                panel_controls_mode='Qt', should_nan_non_visited_elements=False, zScalingFactor=2000.0, active_config_modifiying_kwargs=active_config_modifiying_kwargs,\n",
    "                                                params_kwargs=dict(should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                            ) # Works now!\n",
    "ipcDataExplorer = display_output['ipcDataExplorer']\n",
    "display_output['pActiveTuningCurvesPlotter'] = display_output.pop('plotter') # rename the key from the generic \"plotter\" to \"pActiveSpikesBehaviorPlotter\" to avoid collisions with others\n",
    "pActiveTuningCurvesPlotter = display_output['pActiveTuningCurvesPlotter']\n",
    "root_dockAreaWindow, placefieldControlsContainerWidget, pf_widgets = display_output['pane'] # for Qt mode\n",
    "\n",
    "active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "render_all_neuron_peak_prominence_2d_results_on_pyvista_plotter(ipcDataExplorer, active_peak_prominence_2d_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aecde7d",
   "metadata": {},
   "source": [
    "### 2024-06-06 - Works to disable/hide all elements except the contour curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ff05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_placefield_surfaces_are_hidden: bool = True\n",
    "all_placefield_points_are_hidden: bool = True\n",
    "\n",
    "disabled_peak_subactors_names_list = ['boxes', 'text', 'peak_points']\n",
    "# disabled_peak_subactors_names_list = ['text', 'peak_points']\n",
    "for active_neuron_id, a_plot_dict in ipcDataExplorer.plots['tuningCurvePlotActors'].items():\n",
    "    if a_plot_dict is not None:\n",
    "        # a_plot_dict.peaks\n",
    "        print(f'active_neuron_id: {active_neuron_id}, a_plot_dict.keys(): {list(a_plot_dict.keys())}')\n",
    "        # ['main', 'points', 'peaks']\n",
    "        if a_plot_dict.main is not None:\n",
    "            if all_placefield_surfaces_are_hidden:\n",
    "                a_plot_dict.main.SetVisibility(False)\n",
    "                # pass\n",
    "            \n",
    "        if a_plot_dict.points is not None:\n",
    "            if all_placefield_points_are_hidden:\n",
    "                a_plot_dict.points.SetVisibility(False)\n",
    "                # pass\n",
    "\n",
    "        if a_plot_dict.peaks is not None:\n",
    "            print(f'active_neuron_id: {active_neuron_id}, a_plot_dict.peaks: {list(a_plot_dict.peaks.keys())}')\n",
    "            for a_subactor_name in disabled_peak_subactors_names_list:\n",
    "                a_subactor = a_plot_dict.peaks.get(a_subactor_name, None)\n",
    "                if a_subactor is not None:\n",
    "                    a_subactor.SetVisibility(False)\n",
    "            # if all_placefield_surfaces_are_hidden:\n",
    "            #     a_plot_dict.main.SetVisibility(False) # Change the visibility to match the current tuning_curve_visibility_state\n",
    "\n",
    "# Once done, render\n",
    "ipcDataExplorer.p.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c88dd",
   "metadata": {},
   "source": [
    "### 2024-06-05 - Offset the long and short track to match the `_plot_track_remapping_diagram` 2D remapping figure\n",
    "\n",
    "[/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Pho2D/track_shape_drawing.py:1236](vscode://file/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Pho2D/track_shape_drawing.py:1236)\n",
    "```python\n",
    "# From `Pho2D.track_shape_drawing.a_dir_decoder_aclu_MAX_peak_maps_df`\n",
    "_plot_track_remapping_diagram\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391be83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "track_half_offset: float = 25.0\n",
    "\n",
    "# Long:\n",
    "actor = ipcDataExplorer.long_maze_bg\n",
    "# Get the current position\n",
    "current_position = actor.GetPosition()\n",
    "# Translate by 5.0 units in the y-direction\n",
    "# new_position = (current_position[0], current_position[1] + 5.0, current_position[2])\n",
    "new_position = (current_position[0], track_half_offset, current_position[2])\n",
    "# Set the new position\n",
    "actor.SetPosition(new_position)\n",
    "\n",
    "## Short\n",
    "actor = ipcDataExplorer.short_maze_bg\n",
    "# Get the current position\n",
    "current_position = actor.GetPosition()\n",
    "# Translate by 5.0 units in the y-direction\n",
    "# new_position = (current_position[0], current_position[1] + 5.0, current_position[2])\n",
    "new_position = (current_position[0], -track_half_offset, current_position[2])\n",
    "# Set the new position\n",
    "actor.SetPosition(new_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc3078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out_graphics_dict = curr_active_pipeline.display('_display_two_step_decoder_prediction_error_2D', 'maze_any') # 'maze_any'\n",
    "\n",
    "update_fn = _out_graphics_dict.plot_data['draw_update_fn']\n",
    "num_frames = _out_graphics_dict.plot_data['num_frames']\n",
    "\n",
    "print(f'num_frames: {num_frames}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b374e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "all_save_paths = {}\n",
    "\n",
    "ani = animation.FuncAnimation(_out_graphics_dict.figures[0], update_fn, frames=num_frames, blit=False, repeat=False, interval=20, save_count=50)\n",
    "\n",
    "# ani.to_html5_video()\n",
    "\n",
    "# # To save the animation using Pillow as a gif\n",
    "# _temp_gif_save_path = Path('scatter.gif').resolve()\n",
    "# writer = animation.PillowWriter(fps=15, metadata=dict(artist='Pho Hale'), bitrate=1800)\n",
    "# ani.save(_temp_gif_save_path, writer=writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f69ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.pause()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c2cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.show()\n",
    "\n",
    "# # Save the animation to a BytesIO buffer\n",
    "# buf = io.BytesIO()\n",
    "# ani.save(buf, codec='gif', writer='imagemagick', fps=10)\n",
    "# buf.seek(0)\n",
    "\n",
    "# # Display the GIF\n",
    "# display(Image(data=buf.getvalue(), format='gif'))\n",
    "# Display the GIF\n",
    "# assert _temp_gif_save_path.exists()\n",
    "# Image(_temp_gif_save_path)\n",
    "\n",
    "\n",
    "# for i in np.arange(num_frames):\n",
    "#     update_fn(i) ## Adjust the slider, using its callbacks as well to update the displayed epoch.\n",
    "    \n",
    "#     # _out_rank_order_event_raster_debugger.on_update_epoch_IDX(an_epoch_idx=i)\n",
    "#     active_epoch_label = self.active_epoch_label\n",
    "\n",
    "#     save_paths = []\n",
    "\n",
    "#     for a_decoder, a_plot in self.root_plots_dict.items():\n",
    "#         curr_filename_prefix = f'Epoch{active_epoch_label}_{a_decoder}'\n",
    "#         # a_plot.setYRange(-0.5, float(self.max_n_neurons))\n",
    "#         out_path = export_path.joinpath(f'{curr_filename_prefix}_plot.png').resolve()\n",
    "#         export_pyqtgraph_plot(a_plot, savepath=out_path, background=pg.mkColor(0, 0, 0, 0))\n",
    "#         save_paths.append(out_path)\n",
    "\n",
    "#     all_save_paths[active_epoch_label] = save_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77194b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bbd956",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_display_long_short_laps', '_display_long_short_pf1D_comparison', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b267e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_display_two_step_decoder_prediction_error_2D'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8adcd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import Image, display\n",
    "import io\n",
    "from pyphocorehelpers.plotting.media_output_helpers import fig_to_clipboard\n",
    "\n",
    "\n",
    "# Generate the frames for the animation\n",
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "line, = ax.plot(x, np.sin(x))\n",
    "\n",
    "def update(frame):\n",
    "    line.set_ydata(np.sin(x + frame / 10.0))\n",
    "    return line,\n",
    "\n",
    "frames = len(x) - 1\n",
    "ani = animation.FuncAnimation(fig, update, frames=frames, blit=True, repeat=True, interval=50)\n",
    "\n",
    "# To save the animation using Pillow as a gif\n",
    "_temp_gif_save_path = Path('scatter.gif').resolve()\n",
    "writer = animation.PillowWriter(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "ani.save(_temp_gif_save_path, writer=writer)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# # Save the animation to a BytesIO buffer\n",
    "# buf = io.BytesIO()\n",
    "# ani.save(buf, codec='gif', writer='imagemagick', fps=10)\n",
    "# buf.seek(0)\n",
    "\n",
    "# # Display the GIF\n",
    "# display(Image(data=buf.getvalue(), format='gif'))\n",
    "# Display the GIF\n",
    "assert _temp_gif_save_path.exists()\n",
    "Image(_temp_gif_save_path)\n",
    "\n",
    "\n",
    "# fig_to_clipboard(fig, format='gif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7be129",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_long_short_laps')\n",
    "graphics_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedac3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['axs'], graphics_output_dict['plot_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_grid_bin_bounds_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68008d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_long_short_laps()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685113bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "# active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\n",
    "\n",
    "_out_graphics_dict = curr_active_pipeline.display('_display_spike_rasters_pyqtplot_2D', 'maze_any') # 'maze_any'\n",
    "assert isinstance(_out_graphics_dict, dict)\n",
    "active_2d_plot, active_3d_plot, spike_raster_window = _out_graphics_dict['spike_raster_plt_2d'], _out_graphics_dict['spike_raster_plt_3d'], _out_graphics_dict['spike_raster_window']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.SessionEpochs']\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5650ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(add_renderables_menu.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a83aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('add_renderables_menu', add_renderables_menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfbad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d_interactive_tuning_curves_plotter\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "active_config_modifiying_kwargs = {\n",
    "    'plotting_config': {'should_use_linear_track_geometry': True, \n",
    "                        't_start': t_start, 't_delta': t_delta, 't_end': t_end,\n",
    "                        }\n",
    "}\n",
    "_out_graphics_dict = curr_active_pipeline.display('_display_3d_interactive_tuning_curves_plotter', active_session_configuration_context=global_epoch_context,\n",
    "                                            active_config_modifiying_kwargs=active_config_modifiying_kwargs,\n",
    "                                            params_kwargs=dict(should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                           )\n",
    "ipcDataExplorer = _out_graphics_dict['ipcDataExplorer'] # InteractivePlaceCellTuningCurvesDataExplorer \n",
    "p = _out_graphics_dict['plotter']\n",
    "pane = _out_graphics_dict['pane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=global_epoch_context) # , computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.025}]\n",
    "ipspikesDataExplorer = _out['ipspikesDataExplorer']\n",
    "p = _out['plotter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "iplapsDataExplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "\n",
    "an_image_file_path = Path('an_image.png').resolve()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_image_plotter', active_session_configuration_context=global_epoch_context, image_file=an_image_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ce93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_config in curr_active_pipeline.active_configs.items():\n",
    "    print(f'a_config.plotting_config.should_use_linear_track_geometry: {a_config.plotting_config.should_use_linear_track_geometry}')\n",
    "    a_config.plotting_config.should_use_linear_track_geometry = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d560b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "\n",
    "\n",
    "_out = TemplateDebugger.init_templates_debugger(track_templates) # , included_any_context_neuron_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1323cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "\n",
    "\n",
    "_out = batch_perform_all_plots(curr_active_pipeline=curr_active_pipeline, enable_neptune=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 2D matrix\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import pv\n",
    "\n",
    "matrix = np.random.rand(10, 10)\n",
    "\n",
    "# Coordinates\n",
    "x, y = np.meshgrid(np.arange(matrix.shape[1]), np.arange(matrix.shape[0]))\n",
    "z = matrix.flatten()\n",
    "\n",
    "# Colors based on recency of updates (for example purposes, random values)\n",
    "colors = np.random.rand(matrix.size)\n",
    "\n",
    "# Create the plotter\n",
    "plotter = pv.Plotter()\n",
    "\n",
    "# Add points (dots)\n",
    "points = np.column_stack((x.flatten(), y.flatten(), z))\n",
    "point_cloud = pv.PolyData(points)\n",
    "point_cloud['colors'] = colors\n",
    "plotter.add_mesh(point_cloud, render_points_as_spheres=True, point_size=10, scalars='colors', cmap='viridis')\n",
    "\n",
    "# Add stems\n",
    "for i in range(len(z)):\n",
    "    line = pv.Line([x.flatten()[i], y.flatten()[i], 0], [x.flatten()[i], y.flatten()[i], z[i]])\n",
    "    plotter.add_mesh(line, color='black')\n",
    "\n",
    "# Show plot\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23611eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot.display_function_items\n",
    "\n",
    "# '_display_directional_template_debugger'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "directional_laps_overview = curr_active_pipeline.display(display_function='_display_directional_laps_overview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36ee6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_pic_placefields = curr_active_pipeline.display('_display_1d_placefields', long_LR_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_pic_placefields_short_LR = curr_active_pipeline.display('_display_1d_placefields', short_LR_context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c334080",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eafe14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f93040",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3285686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_immediate_dependencies(remaining_comp_specifiers_dict, provided_global_keys):\n",
    "    dependent_validators = {}\n",
    "    for a_name, a_validator in remaining_comp_specifiers_dict.items():\n",
    "        # set(provided_global_keys)\n",
    "        # set(a_validator.results_specification.requires_global_keys)\n",
    "        if a_validator.is_dependency_in_required_global_keys(provided_global_keys):\n",
    "            dependent_validators[a_name] = a_validator\n",
    "        # (provided_global_keys == (a_validator.results_specification.requires_global_keys or []))\n",
    "\n",
    "    for a_name, a_found_validator in dependent_validators.items():\n",
    "        new_provided_global_keys = a_found_validator.results_specification.provides_global_keys\n",
    "        provided_global_keys.extend(new_provided_global_keys)\n",
    "        remaining_comp_specifiers_dict.pop(a_name) # remove\n",
    "\n",
    "    remaining_comp_specifiers_dict = {k:v for k,v in remaining_comp_specifiers_dict.items() if k not in dependent_validators}\n",
    "    # dependent_validators\n",
    "    # remaining_comp_specifiers_dict\n",
    "    print(f'len(remaining_comp_specifiers_dict): {len(remaining_comp_specifiers_dict)}, dependent_validators: {dependent_validators}')\n",
    "    return remaining_comp_specifiers_dict, dependent_validators, provided_global_keys\n",
    "\n",
    "'_display_directional_laps_overview'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd15f5",
   "metadata": {},
   "source": [
    "# 🎨 2024-04-23 - 3D Posterior Plot\n",
    "<!-- t_delta -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba7ac95",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer\n",
    "\n",
    "curr_active_pipeline.prepare_for_display()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_interactive_custom_data_explorer', active_session_configuration_context=global_epoch_context,\n",
    "                                    params_kwargs=dict(should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                    )\n",
    "iplapsDataExplorer: InteractiveCustomDataExplorer = _out['iplapsDataExplorer']\n",
    "pActiveInteractiveLapsPlotter = _out['plotter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "pActiveInteractiveLapsPlotter[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ad7178",
   "metadata": {},
   "outputs": [],
   "source": [
    "pActiveInteractiveLapsPlotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "iplapsDataExplorer.active_config.plotting_config.subplots_shape # '1|5'\n",
    "iplapsDataExplorer.active_config.plotting_config.plotter_type # 'BackgroundPlotter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subplots_shape_str: str = '1|5'\n",
    "subplots_shape_arr_strs = subplots_shape_str.split('|')\n",
    "\n",
    "subplots_shape = [int(k) for k in subplots_shape_arr_strs]\n",
    "subplots_shape\n",
    "\n",
    "total_n_plots: int = np.prod(subplots_shape)\n",
    "if total_n_plots > 1:\n",
    "    iplapsDataExplorer.active_config.plotting_config.plotter_type = 'BackgroundPlotter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iplapsDataExplorer.p.\n",
    "\n",
    "p = iplapsDataExplorer.p[0,0]\n",
    "p\n",
    "# p = self.p[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_global = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=global_epoch_context) # , config_override_kwargs={'plotting_config': {'should_use_linear_track_geometry': True}}\n",
    "# ipspikesDataExplorer = _out_global['ipspikesDataExplorer']\n",
    "# p = _out_global['plotter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: active_config\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "active_config_modifiying_kwargs = {\n",
    "    'plotting_config': {'should_use_linear_track_geometry': True, \n",
    "                        't_start': t_start, 't_delta': t_delta, 't_end': t_end,\n",
    "                        }\n",
    "}\n",
    "_out_global = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=global_epoch_context,\n",
    "                                            active_config_modifiying_kwargs=active_config_modifiying_kwargs,\n",
    "                                            params_kwargs=dict(enable_historical_spikes=False, enable_recent_spikes=False, should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                           )\n",
    "ipspikesDataExplorer = _out_global['ipspikesDataExplorer']\n",
    "p = _out_global['plotter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k, v in active_config_modifiying_kwargs.items():\n",
    "    curr_subdict = active_config.get(k, {})\n",
    "    for sub_k, sub_v in v.items():\n",
    "        try:\n",
    "            curr_subdict[sub_k] = sub_v # apply the update\n",
    "        except TypeError as err:\n",
    "            # TypeError: 'PlottingConfig' object does not support item assignment\n",
    "            setattr(curr_subdict, sub_k, sub_v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27140db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_config.plotting_config.should_use_linear_track_geometry\n",
    "active_config.plotting_config.t_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.time_animations import TrackConfigurationTimeAnimationRoutine\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "custom_track_animatior: TrackConfigurationTimeAnimationRoutine = TrackConfigurationTimeAnimationRoutine(t_start=t_start, t_delta=t_delta, t_end=t_end, \n",
    "        long_maze_bg=ipspikesDataExplorer.plots['long_maze_bg'], short_maze_bg=ipspikesDataExplorer.plots['short_maze_bg'],\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveSliderWrapper import InteractiveSliderWrapper\n",
    "\n",
    "# interactive_plotter = ipspikesDataExplorer.ui.interactive_plotter # PhoInteractivePlotter\n",
    "\n",
    "active_timestamp_slider_wrapper: InteractiveSliderWrapper = ipspikesDataExplorer.ui.interactive_plotter.interface_properties.active_timestamp_slider_wrapper # InteractiveSliderWrapper \n",
    "active_timestamp_slider_wrapper.curr_value # 17659.517659\n",
    "active_timestamp_slider_wrapper.curr_index # 17659\n",
    "\n",
    "\n",
    "curr_i: int = int(active_timestamp_slider_wrapper.curr_index)\n",
    "active_window_sample_indicies = np.squeeze(ipspikesDataExplorer.params.pre_computed_window_sample_indicies[curr_i,:]) # Get the current precomputed indicies for this curr_i\n",
    "\n",
    "## Spike Plotting:\n",
    "# Get the times that fall within the current plot window:\n",
    "curr_time_fixedSegments = ipspikesDataExplorer.t[active_window_sample_indicies] # New Way\n",
    "t_start = curr_time_fixedSegments[0]\n",
    "t_stop = curr_time_fixedSegments[-1]\n",
    "\n",
    "# \n",
    "t_start, t_stop\n",
    "# custom_track_animatior.on_update_current_window(t_start=t_start, t_stop=t_stop)\n",
    "# curr_index\n",
    "active_timestamp_slider_wrapper.slider_obj.SetEnabled(False) # hide the typical timestamp slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b5cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_one_step_decoder = deepcopy(global_results.pf2D_Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _update_nearest_decoded_most_likely_position_callback, _conn = add_nearest_decoded_position_indicator_circle(self, active_one_step_decoder, _debug_print = False)\n",
    "\n",
    "_update_nearest_decoded_most_likely_position_callback, _conn = ipspikesDataExplorer.add_nearest_decoded_position_indicator_circle(active_one_step_decoder=active_one_step_decoder, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d5529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryPyVistaPlotter\n",
    "\n",
    "## plots a decoder posterior viewer with two sliders: one for epoch_idx and another for epoch_time_bin_idx within that epoch\n",
    "active_one_step_decoder = deepcopy(global_results.pf2D_Decoder) # just used for position binning info\n",
    "# a_result: DecodedFilterEpochsResult = deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'])\n",
    "a_result: DecodedFilterEpochsResult = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'])\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = ipspikesDataExplorer.add_decoded_posterior_bars(a_result=a_result,\n",
    "                                                                                                                         xbin=active_one_step_decoder.xbin, xbin_centers=active_one_step_decoder.xbin_centers, ybin=active_one_step_decoder.ybin, ybin_centers=active_one_step_decoder.ybin_centers,\n",
    "                                                                                                                         enable_plot_all_time_bins_in_epoch_mode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df7c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer.params.curr_view_window_length_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79651414",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer.clear_all_added_decoded_posterior_plots()\n",
    "ipspikesDataExplorer.p.clear_slider_widgets() # does not actually clear the added sliders\n",
    "ipspikesDataExplorer.on_slider_update_mesh(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ipspikesDataExplorer.params.curr_view_window_length_samples # 299\n",
    "ipspikesDataExplorer.params.curr_view_window_length_samples = 60.0 * 5.0 * ipspikesDataExplorer.active_session.position.sampling_rate # 5 minutes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_interactions.widgets import RangeSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acebce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipspikesDataExplorer.add_grid_bin_bounds_box(\n",
    "ipspikesDataExplorer.on_slider_update_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f59bafd",
   "metadata": {},
   "source": [
    "# 🖼️🎨 2024-02-28 - WE gotta see the replays on the 3D track. Or the 2D track.\n",
    "2024-04-28 - This is working in both 3D and 2D!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ad549",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: directional_laps_results, global_replays, decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "# global_pf1D\n",
    "# long_replays\n",
    "# direction_max_indices = ripple_all_epoch_bins_marginals_df[['P_Long', 'P_Short']].values.argmax(axis=1)\n",
    "# track_identity_max_indices = ripple_all_epoch_bins_marginals_df[['P_Long', 'P_Short']].values.argmax(axis=1)\n",
    "\n",
    "## How do I get the replays?\n",
    "# long_replay_df: pd.DataFrame = long_replays.to_dataframe() ## These work.\n",
    "# global_replay_df: pd.DataFrame = global_replays.to_dataframe() ## These work.\n",
    "# global_replay_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1D version:\n",
    "## INPUTS: directional_laps_results, decoder_ripple_filter_epochs_decoder_result_dict\n",
    "xbin = deepcopy(directional_laps_results.get_decoders()[0].xbin)\n",
    "xbin_centers = deepcopy(directional_laps_results.get_decoders()[0].xbin_centers)\n",
    "ybin_centers = None\n",
    "ybin = None\n",
    "\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "# a_decoded_filter_epochs_decoder_result_dict\n",
    "\n",
    "## 1D:\n",
    "a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long_LR'] # 1D\n",
    "\n",
    "## OUTPUTS: a_decoded_filter_epochs_decoder_result_dict, xbin_centers, ybin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31cdc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2D version:\n",
    "from neuropy.analyses.placefields import PfND\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BayesianPlacemapPositionDecoder\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_lap_and_ripple_epochs_decoding_for_decoder\n",
    "\n",
    "## INPUTS: long_results, short_results\n",
    "# long_one_step_decoder_2D\n",
    "\n",
    "long_one_step_decoder_2D, short_one_step_decoder_2D  = [results_data.get('pf2D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "one_step_decoder_dict_2D: Dict[str, BayesianPlacemapPositionDecoder] = dict(zip(('long', 'short'), (long_one_step_decoder_2D, short_one_step_decoder_2D)))\n",
    "long_pf2D = long_results.pf2D\n",
    "# short_pf2D = short_results.pf2D\n",
    "\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "xbin_centers = deepcopy(long_pf2D.xbin_centers)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "ybin_centers = deepcopy(long_pf2D.ybin_centers)\n",
    "\n",
    "## OUTPUTS: one_step_decoder_dict_2D, xbin_centers, ybin_centers\n",
    "\n",
    "## INPUTS: one_step_decoder_dict_2D\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "pos_bin_size: Tuple[float, float] = list(one_step_decoder_dict_2D.values())[0].pos_bin_size\n",
    "\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "\n",
    "## Decode epochs for the two decoders ('long', 'short'):\n",
    "LS_decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {}\n",
    "LS_decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {}\n",
    "\n",
    "for a_name, a_decoder in one_step_decoder_dict_2D.items():\n",
    "    LS_decoder_laps_filter_epochs_decoder_result_dict[a_name], LS_decoder_ripple_filter_epochs_decoder_result_dict[a_name] = _compute_lap_and_ripple_epochs_decoding_for_decoder(a_decoder, curr_active_pipeline, desired_laps_decoding_time_bin_size=laps_decoding_time_bin_size, desired_ripple_decoding_time_bin_size=ripple_decoding_time_bin_size)\n",
    "\n",
    "# LS_decoder_ripple_filter_epochs_decoder_result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e591738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2D:\n",
    "# Choose the ripple epochs to plot:\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(LS_decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long'] # 2D\n",
    "# Choose the laps epochs to plot:\n",
    "# a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(LS_decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# a_decoded_filter_epochs_decoder_result_dict\n",
    "\n",
    "\n",
    "# a_result: DecodedFilterEpochsResult = LS_decoder_laps_filter_epochs_decoder_result_dict['long'] # 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryMatplotlibPlotter\n",
    "\n",
    "## INPUTS: a_result: DecodedFilterEpochsResult, an_epoch_idx: int = 18\n",
    "# e.g. `a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long_LR']`\n",
    "\n",
    "# a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long_LR'] # 1D\n",
    "\n",
    "## Convert to plottable posteriors\n",
    "# an_epoch_idx: int = 0\n",
    "\n",
    "# valid_aclus = deepcopy(decoder_aclu_peak_location_df_merged.aclu.unique())\n",
    "num_filter_epochs: int = a_result.num_filter_epochs\n",
    "a_decoded_traj_plotter = DecodedTrajectoryMatplotlibPlotter(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers)\n",
    "fig, axs, laps_pages = a_decoded_traj_plotter.plot_decoded_trajectories_2d(global_session, curr_num_subplots=8, active_page_index=0, plot_actual_lap_lines=False, use_theoretical_tracks_instead=True)\n",
    "\n",
    "integer_slider = a_decoded_traj_plotter.plot_epoch_with_slider_widget(an_epoch_idx=6)\n",
    "integer_slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f60583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(laps_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff87b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps[0].remove()\n",
    "\n",
    "# an_ax.remove(heatmaps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd94ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_ax = axs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plotActors, data_dict = plot_3d_stem_points(pCustom, active_epoch_placefields2D.ratemap.xbin, active_epoch_placefields2D.ratemap.ybin, active_epoch_placefields2D.ratemap.occupancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4627224",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_plot(value=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9cfc42",
   "metadata": {},
   "source": [
    "## add to 3D plotter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12058a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryPyVistaPlotter\n",
    "from pyphoplacecellanalysis.Pho3D.PyVista.graphs import plot_3d_stem_points, plot_3d_binned_bars\n",
    "\n",
    "curr_active_pipeline.prepare_for_display()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_interactive_custom_data_explorer', active_session_configuration_context=global_epoch_context,\n",
    "                                    params_kwargs=dict(should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                    )\n",
    "iplapsDataExplorer: InteractiveCustomDataExplorer = _out['iplapsDataExplorer']\n",
    "pActiveInteractiveLapsPlotter = _out['plotter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b011ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## INPUTS: a_result, xbin_centers, ybin_centers, iplapsDataExplorer\n",
    "# a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = DecodedTrajectoryPyVistaPlotter(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, p=iplapsDataExplorer.p)\n",
    "# a_decoded_trajectory_pyvista_plotter.build_ui()\n",
    "# a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = iplapsDataExplorer.add_decoded_posterior_bars(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, enable_plot_all_time_bins_in_epoch_mode=True)\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = iplapsDataExplorer.add_decoded_posterior_bars(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, enable_plot_all_time_bins_in_epoch_mode=False, active_plot_fn=plot_3d_stem_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24cd81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = iplapsDataExplorer.add_decoded_posterior_bars(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, enable_plot_all_time_bins_in_epoch_mode=False, active_plot_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf0e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "iplapsDataExplorer.clear_all_added_decoded_posterior_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968821ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d6646",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_plot_fn = a_decoded_trajectory_pyvista_plotter.data_dict['plot_3d_binned_bars[55.63197815967686]']['update_plot_fn']\n",
    "# update_plot_fn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_posterior_p_x_given_n, n_epoch_timebins = a_decoded_trajectory_pyvista_plotter._perform_get_curr_posterior(a_result=a_result, an_epoch_idx=a_decoded_trajectory_pyvista_plotter.curr_epoch_idx, time_bin_index=np.arange(a_decoded_trajectory_pyvista_plotter.curr_n_time_bins))\n",
    "# np.shape(a_posterior_p_x_given_n)\n",
    "\n",
    "\n",
    "a_posterior_p_x_given_n, n_epoch_timebins = a_decoded_trajectory_pyvista_plotter.get_curr_posterior(an_epoch_idx=a_decoded_trajectory_pyvista_plotter.curr_epoch_idx, time_bin_index=np.arange(a_decoded_trajectory_pyvista_plotter.curr_n_time_bins))\n",
    "np.shape(a_posterior_p_x_given_n)\n",
    "\n",
    "n_epoch_timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9878ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = a_decoded_trajectory_pyvista_plotter.plotActors['plot_3d_binned_bars[49.11980797704307]']\n",
    "# v['main'].remove()\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter.p.remove_actor(v['main'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6dc498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho3D.PyVista.graphs import clear_3d_binned_bars_plots\n",
    "\n",
    "clear_3d_binned_bars_plots(p=a_decoded_trajectory_pyvista_plotter.p, plotActors=a_decoded_trajectory_pyvista_plotter.plotActors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.plotActors_CenterLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.perform_update_plot_epoch_time_bin_range(value=None) # select all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e721a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.perform_clear_existing_decoded_trajectory_plots()\n",
    "iplapsDataExplorer.p.update()\n",
    "iplapsDataExplorer.p.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bin_index = np.arange(a_decoded_trajectory_pyvista_plotter.curr_n_time_bins)\n",
    "type(time_bin_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7059eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.slider_epoch.RemoveAllObservers()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch.Off()\n",
    "# a_decoded_trajectory_pyvista_plotter.slider_epoch.FastDelete()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch = None\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin.RemoveAllObservers()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin.Off()\n",
    "# a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin.FastDelete()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin = None\n",
    "iplapsDataExplorer.p.clear_slider_widgets()\n",
    "iplapsDataExplorer.p.update()\n",
    "iplapsDataExplorer.p.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66de9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecoderRenderingPyVistaMixin\n",
    "\n",
    "(plotActors, data_dict), (plotActors_CenterLabels, data_dict_CenterLabels) = DecoderRenderingPyVistaMixin.perform_plot_posterior_bars(iplapsDataExplorer.p, xbin=xbin, ybin=ybin, xbin_centers=xbin_centers, ybin_centers=ybin_centers,\n",
    "                                               posterior_p_x_given_n=a_posterior_p_x_given_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d46f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.20720657697753883 * 24.130508176591324"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293adac0",
   "metadata": {},
   "source": [
    "# 🖼️🎨 Rasters Debugger (via `RankOrderRastersDebugger`)\n",
    "<!-- ![image.png|350](attachment:image.png) -->\n",
    "![image.png](attachment:image.png){ width=300; max-width: 300px; }\n",
    "<!-- <img src=\"path_to_your_image.png\" style=\"max-width: 300px;\" /> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c0898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff576652",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "\n",
    "RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "_out_laps_rasters: RankOrderRastersDebugger = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, global_laps_epochs_df, track_templates, rank_order_results, RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict)\n",
    "_out_laps_rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a586d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "# global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "# global_laps_epochs_df = global_laps.to_dataframe()\n",
    "global_ripple_epochs_df = global_replays.to_dataframe()\n",
    "\n",
    "RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "_out_ripple_rasters: RankOrderRastersDebugger = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, global_ripple_epochs_df, track_templates, rank_order_results, RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict)\n",
    "_out_ripple_rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01a20ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "# rank_order_results\n",
    "# used_rank_order_results = deepcopy(rank_order_results)\n",
    "used_rank_order_results = None\n",
    "_out_ripple_rasters: RankOrderRastersDebugger = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, deepcopy(filtered_ripple_simple_pf_pearson_merged_df),\n",
    "                                                                                                   track_templates, used_rank_order_results,\n",
    "                                                                                                    RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict)\n",
    "_out_ripple_rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff2177",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "_out_ripple_rasters: RankOrderRastersDebugger = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, deepcopy(filtered_ripple_simple_pf_pearson_merged_df),\n",
    "                                                                                                   track_templates, None,\n",
    "                                                                                                    None, None,\n",
    "                                                                                                    dock_add_locations = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'), (['right'], ['right'], ['right'], ['right']))),\n",
    "                                                                                                    )\n",
    "_out_ripple_rasters.set_top_info_bar_visibility(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e4ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_ripple_rasters.set_top_info_bar_visibility(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700afa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide top info bar:\n",
    "LongShortColumnsInfo_dock_layout, LongShortColumnsInfo_dock_Dock = _out_ripple_rasters.plots.dock_widgets['LongShortColumnsInfo_dock']\n",
    "# LongShortColumnsInfo_dock_layout.hide() # No use\n",
    "# _out_ripple_rasters.ui.long_short_info_layout.hide() # No use\n",
    "LongShortColumnsInfo_dock_Dock.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95532207",
   "metadata": {},
   "outputs": [],
   "source": [
    "LongShortColumnsInfo_dock_Dock.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174f3c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# found_IDX = _out_ripple_rasters.find_nearest_time_index(193.65)\n",
    "# if found_IDX is not None:\n",
    "#     print(f'found_IDX: {found_IDX}')\n",
    "#     _out_ripple_rasters.programmatically_update_epoch_IDX(found_IDX)\n",
    "\n",
    "\n",
    "_out_ripple_rasters.programmatically_update_epoch_IDX_from_epoch_start_time(193.65)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965556b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_ripple_rasters.on_update_epoch_IDX(45)\n",
    "# on_update_epoch_IDX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_a_ScrollBarWithSpinBox = _out_ripple_rasters.ui.ctrls_widget # ScrollBarWithSpinBox \n",
    "_a_ScrollBarWithSpinBox.setValue(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521bba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_directional_template_debugger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_template_debugger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_track_template_pf1Ds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_two_step_decoder_prediction_error_2D', global_epoch_context, variable_name='p_x_given_n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_plot_most_likely_position_comparisons', global_epoch_context) # , variable_name='p_x_given_n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddebd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d805c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_display_directional_laps_overview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_display_directional_merged_pfs'\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pfs', plot_all_directions=False, plot_long_directional=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47076a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_display_1d_placefield_occupancy'\n",
    "'_display_placemaps_pyqtplot_2D'\n",
    " '_display_2d_placefield_occupancy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481df233",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_2d_placefield_occupancy', global_any_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_grid_bin_bounds_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58951b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import add_rectangular_selector, add_range_selector\n",
    "\n",
    "\n",
    "# epoch_name = global_any_name\n",
    "epoch_name = short_epoch_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = computation_result.computation_config['pf_params'].grid_bin_bounds\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n",
    "            \n",
    "fig, ax = computation_result.computed_data.pf2D.plot_occupancy(identifier_details_list=[epoch_name], active_context=epoch_context) \n",
    "\n",
    "# rect_selector, set_extents, reset_extents = add_rectangular_selector(fig, ax, initial_selection=grid_bin_bounds) # (24.82, 257.88), (125.52, 149.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines\n",
    "\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b862a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.peak_location_representing import compute_placefield_center_of_mass_positions\n",
    "\n",
    "\n",
    "epoch_name = global_any_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = deepcopy(computation_result.computation_config['pf_params'].grid_bin_bounds)\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_pf2D.xbin\n",
    "long_pf2D.ybin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc3d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0416d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage # used for `compute_placefield_center_of_masses`\n",
    "from neuropy.utils.mixins.peak_location_representing import compute_occupancy_center_of_mass_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6352663",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_x_center_dict # {'long_LR': 162.99271603199625, 'long_RL': 112.79866056603696, 'short_LR': 138.45611791646, 'short_RL': 130.78889937230684}\n",
    "\n",
    "occupancy_mask_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.visited_occupancy_mask, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_mask_x_center_dict # {'long_LR': 135.66781520875904, 'long_RL': 130.0042755113645, 'short_LR': 133.77996864296085, 'short_RL': 143.21920147195175}\n",
    "\n",
    "\n",
    "# {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb029d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "\n",
    "# masked_nonzero_occupancy = deepcopy(long_pf2D.nan_never_visited_occupancy)\n",
    "\n",
    "masked_nonzero_occupancy = deepcopy(long_pf2D.visited_occupancy_mask)\n",
    "\n",
    "# occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin)\n",
    "occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(masked_nonzero_occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin) # array([127.704, 145.63])\n",
    "occupancy_CoM_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e7e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf2D.nan_never_visited_occupancy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4caa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict\n",
    "\n",
    "\n",
    "'_display_grid_bin_bounds_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f963a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting on 2024-02-06 to display the LR/RL directions instead of the All/Long/Short pfs:\n",
    "def _display_directional_merged_pfs(owning_pipeline_reference, global_computation_results, computation_results, active_configs, include_includelist=None, save_figure=True, included_any_context_neuron_ids=None,\n",
    "\t\t\t\t\t\t\t\t\tplot_all_directions=True, plot_long_directional=False, plot_short_directional=False, **kwargs):\n",
    "\t\"\"\" Plots the merged pseduo-2D pfs/ratemaps. Plots: All-Directions, Long-Directional, Short-Directional in seperate windows. \n",
    "\t\n",
    "\tHistory: this is the Post 2022-10-22 display_all_pf_2D_pyqtgraph_binned_image_rendering-based method:\n",
    "\t\"\"\"\n",
    "\tfrom pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array, display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "\tfrom pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow \n",
    "\tfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import LayoutScrollability\n",
    "\n",
    "\tdefer_render = kwargs.pop('defer_render', False)\n",
    "\tdirectional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\tactive_merged_pf_plots_data_dict = {} #empty dict\n",
    "\t\n",
    "\tif plot_all_directions:\n",
    "\t\tactive_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='All-Directions', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.all_directional_pf1D_Decoder.pf # all-directions\n",
    "\tif plot_long_directional:\n",
    "\t\tactive_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Long-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.long_directional_pf1D_Decoder.pf # Long-only\n",
    "\tif plot_short_directional:\n",
    "\t\tactive_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Short-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.short_directional_pf1D_Decoder.pf # Short-only\n",
    "\n",
    "\tout_plots_dict = {}\n",
    "\t\n",
    "\tfor active_context, active_pf_2D in active_merged_pf_plots_data_dict.items():\n",
    "\t\t# figure_format_config = {} # empty dict for config\n",
    "\t\tfigure_format_config = {'scrollability_mode': LayoutScrollability.NON_SCROLLABLE} # kwargs # kwargs as default figure_format_config\n",
    "\t\tout_all_pf_2D_pyqtgraph_binned_image_fig: BasicBinnedImageRenderingWindow  = display_all_pf_2D_pyqtgraph_binned_image_rendering(active_pf_2D, figure_format_config) # output is BasicBinnedImageRenderingWindow\n",
    "\t\n",
    "\t\t# Set the window title from the context\n",
    "\t\tout_all_pf_2D_pyqtgraph_binned_image_fig.setWindowTitle(f'{active_context.get_description()}')\n",
    "\t\tout_plots_dict[active_context] = out_all_pf_2D_pyqtgraph_binned_image_fig\n",
    "\n",
    "\t\t# Tries to update the display of the item:\n",
    "\t\tnames_list = [v for v in list(out_all_pf_2D_pyqtgraph_binned_image_fig.plots.keys()) if v not in ('name', 'context')]\n",
    "\t\tfor a_name in names_list:\n",
    "\t\t\t# Adjust the size of the text for the item by passing formatted text\n",
    "\t\t\ta_plot: pg.PlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem # PlotItem \n",
    "\t\t\t# no clue why 2 is a good value for this...\n",
    "\t\t\ta_plot.titleLabel.setMaximumHeight(2)\n",
    "\t\t\ta_plot.layout.setRowFixedHeight(0, 2)\n",
    "\t\t\t\n",
    "\n",
    "\t\tif not defer_render:\n",
    "\t\t\tout_all_pf_2D_pyqtgraph_binned_image_fig.show()\n",
    "\n",
    "\treturn out_plots_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e434945",
   "metadata": {},
   "source": [
    "# 2023-12-18 - Simpily detect bimodal cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cd3ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.peak_location_representing import ContinuousPeakLocationRepresentingMixin\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from scipy.signal import find_peaks\n",
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# curr_active_pipeline.display('_display_1d_placefields', 'maze1_any', sortby=None)\n",
    "\n",
    "# active_ratemap = deepcopy(long_pf1D.ratemap)\n",
    "active_ratemap: Ratemap = deepcopy(long_LR_pf1D.ratemap)\n",
    "peaks_dict, aclu_n_peaks_dict, peaks_results_df = active_ratemap.compute_tuning_curve_modes(height=0.2, width=None)\n",
    "\n",
    "\n",
    "## INPUTS: track_templates\n",
    "included_columns = ['pos', 'peak_heights'] # the columns of interest that you want in the final dataframe.\n",
    "included_columns_renamed = dict(zip(included_columns, ['peak', 'peak_height']))\n",
    "decoder_peaks_results_dfs = [a_decoder.pf.ratemap.get_tuning_curve_peak_df(height=0.2, width=None) for a_decoder in (track_templates.long_LR_decoder, track_templates.long_RL_decoder, track_templates.short_LR_decoder, track_templates.short_RL_decoder)]\n",
    "prefix_names = [f'{a_decoder_name}_' for a_decoder_name in track_templates.get_decoder_names()]\n",
    "all_included_columns = ['aclu', 'series_idx', 'subpeak_idx'] + included_columns # Used to filter out the unwanted columns from the output\n",
    "\n",
    "# [['aclu', 'series_idx', 'subpeak_idx', 'pos']]\n",
    "\n",
    "# rename_list_fn = lambda a_prefix: {'pos': f\"{a_prefix}pos\"}\n",
    "rename_list_fn = lambda a_prefix: {a_col_name:f\"{a_prefix}{included_columns_renamed[a_col_name]}\" for a_col_name in included_columns}\n",
    "\n",
    "# column_names = [f'{a_decoder_name}_peak' for a_decoder_name in track_templates.get_decoder_names()]\n",
    "\n",
    "# dataFrames = decoder_peaks_results_dfs\n",
    "# names = self.get_decoder_names()\n",
    "\n",
    "# rename 'pos' column in each dataframe and then reduce to perform cumulative outer merge\n",
    "result_df = decoder_peaks_results_dfs[0][all_included_columns].rename(columns=rename_list_fn(prefix_names[0]))\n",
    "for df, a_prefix in zip(decoder_peaks_results_dfs[1:], prefix_names[1:]):\n",
    "    result_df = pd.merge(result_df, df[all_included_columns].rename(columns=rename_list_fn(a_prefix)), on=['aclu', 'series_idx', 'subpeak_idx'], how='outer')\n",
    "\n",
    "# result = reorder_columns(result, column_name_desired_index_dict=dict(zip(['Long_LR_evidence', 'Long_RL_evidence', 'Short_LR_evidence', 'Short_RL_evidence'], np.arange(4)+4)))\n",
    "\n",
    "## Move the \"height\" columns to the end\n",
    "# list(filter(lambda column: column.endswith('_peak_heights'), result.columns))\n",
    "# result_df = reorder_columns(result_df, column_name_desired_index_dict=dict(zip(list(filter(lambda column: column.endswith('_peak_heights'), result_df.columns)), np.arange(len(result_df.columns)-4, len(result_df.columns)))))\n",
    "# result_df\n",
    "\n",
    "# print(list(result.columns))\n",
    "\n",
    "## Move the \"height\" columns to the end\n",
    "result_df: pd.DataFrame = reorder_columns_relative(result_df, column_names=list(filter(lambda column: column.endswith('_peak_heights'), result_df.columns)), relative_mode='end').sort_values(['aclu', 'series_idx', 'subpeak_idx']).reset_index(drop=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a292dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually Excluded endcap aclus:\n",
    "IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43')\n",
    "excluded_endcap_aclus: NDArray = np.array(list(set([40, 60, 85, 102, 52, 6] + [83, 60, 52, 102, 40] + [59, 67, 95, 28, 101] + [14, 15, 87, 71] + [43, 84, 87, 19, 33, 51, 53])))\n",
    "excluded_endcap_aclus\n",
    "\n",
    "\n",
    "np.array([  6,  14,  15,  19,  28,  33,  40,  43,  51,  52,  53,  59,  60,  67,  71,  83,  84,  85,  87,  95, 101, 102])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0fdee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_peaks_dict_dict, decoder_aclu_n_peaks_dict_dict, decoder_peaks_results_df_dict = track_templates.get_decoders_tuning_curve_modes()\n",
    "decoder_aclu_n_peaks_dict_dict\n",
    "# decoder_peaks_results_df_dict\n",
    "# decoder_peaks_dict_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f49ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aclu = 51\n",
    "\n",
    "{k:v[test_aclu] for k, v in decoder_aclu_n_peaks_dict_dict.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_results_df = track_templates.get_decoders_aclu_peak_location_df().sort_values(['aclu', 'series_idx', 'subpeak_idx']).reset_index(drop=True) ## Does not seem to merge entries as I would expect via intution. It keeps LR/RL peaks distinct and leaves pd.NA values for the entries.\n",
    "peaks_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c29838",
   "metadata": {},
   "outputs": [],
   "source": [
    "aclu_n_peaks_dict: Dict = peaks_results_df.groupby(['aclu']).agg(subpeak_idx_count=('subpeak_idx', 'count')).reset_index().set_index('aclu').to_dict()['subpeak_idx_count'] # number of peaks (\"models\" for each aclu)\n",
    "aclu_n_peaks_dict\n",
    "\n",
    "# peaks_results_df = peaks_results_df.groupby(['aclu']).agg(subpeak_idx_count=('subpeak_idx', 'count')).reset_index()\n",
    "\n",
    "# peaks_results_df[peaks_results_df.aclu == 5]\n",
    "# peaks_results_df.aclu.value_counts()\n",
    "\n",
    "aclu_n_peaks_dict[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e14bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_ratemap.n_neurons\n",
    "curr_active_pipeline.display('_display_1d_placefields', 'maze1_any', included_unit_neuron_IDs=active_ratemap.neuron_ids, sortby=np.arange(active_ratemap.n_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aclu_n_peaks_dict\n",
    "unimodal_only_aclus = np.array(list(unimodal_peaks_dict.keys()))\n",
    "unimodal_only_aclus\n",
    "curr_active_pipeline.display('_display_1d_placefields', 'maze1_any', included_unit_neuron_IDs=unimodal_only_aclus, sortby=np.arange(active_ratemap.n_neurons))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c9e39",
   "metadata": {},
   "source": [
    "# 🖼️🎨 2024-02-08 - `PhoPaginatedMultiDecoderDecodedEpochsWindow` - Plot Ripple Metrics like Radon Transforms, WCorr, Simple Pearson, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf989bf6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import ensure_dataframe\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import RadonTransformPlotDataProvider\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "decoder_ripple_filter_epochs_decoder_result_dict = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }')\n",
    "\n",
    "# 0.025\n",
    "\n",
    "## OUTPUTS: filtered_decoder_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc5699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "filter_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2162a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs['duration_num_decoding_bins'] = filter_epochs['duration']/ripple_decoding_time_bin_size\n",
    "filter_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c01240",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].nbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d752f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [v.edge_info.step for v in filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].time_bin_containers]\n",
    "\n",
    "\n",
    "[np.max(np.diff(v)) for v in filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].time_bin_edges]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b7dab",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## INPUTS: decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "\n",
    "## filter the epochs by something and only show those:\n",
    "# INPUTS: filtered_epochs_df\n",
    "# filtered_ripple_simple_pf_pearson_merged_df = filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(active_epochs_df[['start', 'stop']].to_numpy())\n",
    "decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "## Update the `decoder_ripple_filter_epochs_decoder_result_dict` with the included epochs:\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "# print(f\"any_good_selected_epoch_times.shape: {any_good_selected_epoch_times.shape}\") # (142, 2)\n",
    "\n",
    "pre_cols = {a_name:set(a_result.filter_epochs.columns) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()}\n",
    "\n",
    "# 🟪 2024-02-29 - `compute_pho_heuristic_replay_scores`\n",
    "filtered_decoder_filter_epochs_decoder_result_dict, _out_new_scores = HeuristicReplayScoring.compute_all_heuristic_scores(track_templates=track_templates, a_decoded_filter_epochs_decoder_result_dict=filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "## 2024-03-08 - Also constrain the user-selected ones (just to try it):\n",
    "decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline, track_templates=track_templates)\n",
    "# ## Constrain again now by the user selections\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(any_good_selected_epoch_times) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()}\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "## Instead, add in the 'is_user_annotated_epoch' column instead of filtering\n",
    "## INPUTS: any_good_selected_epoch_times\n",
    "num_user_selected_times: int = len(any_good_selected_epoch_times)\n",
    "print(f'num_user_selected_times: {num_user_selected_times}')\n",
    "any_good_selected_epoch_indicies = None\n",
    "print(f'adding user annotation column!')\n",
    "\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "\n",
    "## OUT: filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "# ## specifically long_LR\n",
    "# filter_epochs: pd.DataFrame = deepcopy(ensure_dataframe(filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs))\n",
    "\n",
    "\n",
    "## OUTPUTS: filtered_epochs_df\n",
    "filtered_epochs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd98310",
   "metadata": {},
   "source": [
    "### 2024-05-09 - get the most-likely decoder for each epoch using the sequenceless probabilities and used this to selected the appopriate column for each of the heuristic measures.\n",
    "Modifies `extracted_merged_scores_df`, adding \"*_BEST\" columns for each specified heuristic score column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f4853",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_merged_scores_df: pd.DataFrame =  directional_decoders_epochs_decode_result.build_complete_all_scores_merged_df()\n",
    "extracted_merged_scores_df\n",
    "\n",
    "ripple_weighted_corr_merged_df = deepcopy(directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df)\n",
    "\n",
    "## Need 'best_decoder_index':... actually 'most_likely_decoder_index'\n",
    "\n",
    "# best_decoder_index = deepcopy(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result.filter_epochs['best_decoder_index']) # hope this is correct and not just like the best wcorr or something\n",
    "best_decoder_index = deepcopy(directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df['most_likely_decoder_index'])\n",
    "\n",
    "new_heuristic_checking_columns = ['total_variation', 'integral_second_derivative', 'stddev_of_diff', 'score'] # , 'integral_second_derivative', 'stddev_of_diff', 'score'\n",
    "# best_decoder_names = [['long_LR', 'long_RL', 'short_LR', 'short_RL'][an_idx] for an_idx in best_decoder_index]\n",
    "## Example: extracted_merged_scores_df[['total_variation_long_LR', 'total_variation_long_RL', 'total_variation_short_LR', 'total_variation_short_RL']]\n",
    "\n",
    "for a_score_col in new_heuristic_checking_columns:\n",
    "    curr_score_col_decoder_col_names = [f\"{a_score_col}_{a_decoder_name}\" for a_decoder_name in ['long_LR', 'long_RL', 'short_LR', 'short_RL']]\n",
    "    print(f'curr_score_col_decoder_col_names: {curr_score_col_decoder_col_names}')\n",
    "    # extracted_merged_scores_df\n",
    "    _final_out = [extracted_merged_scores_df[curr_score_col_decoder_col_names].to_numpy()[epoch_idx, a_decoder_idx] for epoch_idx, a_decoder_idx in zip(np.arange(np.shape(extracted_merged_scores_df)[0]), best_decoder_index.to_numpy())]\n",
    "    extracted_merged_scores_df[f\"{a_score_col}_BEST\"] = _final_out # extracted_merged_scores_df[curr_score_col_decoder_col_names].to_numpy()[best_decoder_index]\n",
    "\n",
    "extracted_merged_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d2c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_merged_scores_df.groupby('is_user_annotated_epoch').agg(['mean', 'min', 'max', 'std']) ## successfully got the most-likely decoder for each epoch using the sequenceless probabilities and used this to selected the appopriate column for each of the heuristic measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f34a23a",
   "metadata": {},
   "source": [
    "### Continue something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea0bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs_df_dict = {k:deepcopy(v.filter_epochs) for k,v in filtered_decoder_filter_epochs_decoder_result_dict.items()}\n",
    "# filter_epochs_df_dict\n",
    "\n",
    "high_wcorr_filter_epochs_dict = {k:np.where((v['wcorr'].abs() >= 0.9))[0] for k,v in filter_epochs_df_dict.items()}\n",
    "# high_wcorr_filter_epochs_dict\n",
    "\n",
    "high_wcorr_any_epochs = union_of_arrays(*[v for k,v in high_wcorr_filter_epochs_dict.items()]) # get unique indicies\n",
    "# high_wcorr_any_epochs\n",
    "\n",
    "# high_wcorr_only_filtered_decoder_filter_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "high_wcorr_included_epoch_times = {k:v.iloc[high_wcorr_any_epochs][['start', 'stop']].to_numpy() for k,v in filter_epochs_df_dict.items()}\n",
    "# high_wcorr_included_epoch_times\n",
    "\n",
    "high_wcorr_only_filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(high_wcorr_included_epoch_times[a_name]) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "high_wcorr_only_filtered_decoder_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb0cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find high wcorr values:\n",
    "filter_epochs = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "\n",
    "# np.sum((filter_epochs['wcorr'].abs() > 0.9))\n",
    "\n",
    "np.where((filter_epochs['wcorr'].abs() > 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7620d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs.directionality_ratio.unique()\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs.sweep_score.unique()\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs.laplacian_smoothness.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d94fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a merged (single df) frame\n",
    "decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb235522",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_epochs_df\n",
    "filtered_epochs_df[filtered_epochs_df['start'] >= t_delta]\n",
    "filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fdcf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "\n",
    "## INPUTS filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "app, paginated_multi_decoder_decoded_epochs_window, pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                decoder_decoded_epochs_result_dict=filtered_decoder_filter_epochs_decoder_result_dict,\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=high_wcorr_only_filtered_decoder_filter_epochs_decoder_result_dict,\n",
    "                                                                                                epochs_name='ripple',\n",
    "                                                                                                included_epoch_indicies=None, debug_print=False,\n",
    "                                                                                                params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, \n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 10,\n",
    "                                                                                                    'scrollable_figure': False,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': False,\n",
    "                                                                                                })\n",
    "\n",
    "\n",
    "# paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5928125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp_out_selections = paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65b87cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp_out_selections = paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations(source='diba_evt_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cda2838",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.setWindowTitle('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec8d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.perform_update_titles_from_context(page_idx=page_idx, included_page_data_indicies=included_page_data_indicies)\n",
    "update_titles(self, window_title: str, suptitle: str = None)\n",
    "\n",
    "\n",
    "def update_titles(self, window_title: str, suptitle: str = None):\n",
    "    \"\"\" sets the suptitle and window title for the figure \"\"\"\n",
    "    if suptitle is None:\n",
    "        suptitle = window_title # same as window title\n",
    "    # Set the window title:\n",
    "    self.ui.mw.setWindowTitle(window_title)\n",
    "    self.ui.mw.fig.suptitle(suptitle, wrap=True) # set the plot suptitle\n",
    "    self.ui.mw.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad5dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import ClickActionCallbacks\n",
    "\n",
    "paginated_multi_decoder_decoded_epochs_window.params.on_middle_click_item_callbacks['copy_axis_image_to_clipboard_callback'] = ClickActionCallbacks.copy_axis_image_to_clipboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.enable_middle_click_selected_epoch_times_to_clipboard()\n",
    "\n",
    "# clicked_epoch = np.array([132.51138943410479, 132.79100273095537])\n",
    "\n",
    "# clicked_epoch = np.array([149.95935746072792, 150.25439218967222])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654374c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81780963",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.show_message(\"test message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca820df",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.remove_data_overlays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289385ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6097ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get radon transform data:\n",
    "a_pagination_controller = pagination_controller_dict['long_LR']\n",
    "radon_transform_data = a_pagination_controller.plots_data['radon_transform_data']\n",
    "radon_transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30830fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120293e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_selections_dict = paginated_multi_decoder_decoded_epochs_window.save_selections()\n",
    "# paginated_multi_decoder_decoded_epochs_window.ui.print = print\n",
    "_annotations = paginated_multi_decoder_decoded_epochs_window.print_user_annotations()\n",
    "_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d82308",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination_controller_dict['long_LR'].params.xbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eeaad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpldatacursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f785638",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.remove_data_overlays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ee5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3435812",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.params.xbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd64912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show crosshair at cursor position\n",
    "plt.connect('motion_notify_event', lambda event: plt.gcf().gca().format_coord(event.xdata, event.ydata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c382b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5e9ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_keys_if_possible('paginated_multi_decoder_decoded_epochs_window', paginated_multi_decoder_decoded_epochs_window.ui, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a14372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.widgets.toast_notification_widget import ToastWidget, ToastShowingWidgetMixin\n",
    "# paginated_multi_decoder_decoded_epochs_window.ui._contents.windows\n",
    "\n",
    "for a_name, a_window in paginated_multi_decoder_decoded_epochs_window.ui._contents.windows.items():\n",
    "    message = 'This is a toast message!'\n",
    "    a_window.toast.show_message(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_epoch = np.array([1316.0564141790383, 1316.2703788694926])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c265cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import build_attached_raster_viewer_widget\n",
    "\n",
    "_out_ripple_rasters, update_attached_raster_viewer_epoch_callback = build_attached_raster_viewer_widget(paginated_multi_decoder_decoded_epochs_window=paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=filtered_ripple_simple_pf_pearson_merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf5b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625daf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = _out_ripple_rasters.ui.root_dockAreaWindow\n",
    "win.setWindowTitle(f'Debug Directional Template Rasters <Controlled by DecodedEpochSlices window>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae668b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_ripple_rasters.setWindowTitle(f'Debug Directional Template Rasters <Controlled by DecodedEpochSlices window>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8800a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_epoch_start_stop_time = [488.296 488.484]\n",
    "start_t = 488.29642327222973\n",
    "found_IDX = 24\n",
    "\n",
    "# ripple_idx=80, ripple_start_t=488.29642327222973\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e4195",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_attributes(short_name=None, tags=['callback'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2024-04-29 17:16', related_items=[])\n",
    "def an_alt_clicked_epoch_callback(self, event, clicked_ax, clicked_data_index, clicked_epoch_is_selected, clicked_epoch_start_stop_time):\n",
    "    \"\"\" called when the user middle-clicks an epoch \n",
    "    \n",
    "    captures: _out_ripple_rasters\n",
    "    \"\"\"\n",
    "    print(f'an_alt_clicked_epoch_callback(clicked_data_index: {clicked_data_index}, clicked_epoch_is_selected: {clicked_epoch_is_selected}, clicked_epoch_start_stop_time: {clicked_epoch_start_stop_time})')\n",
    "    if clicked_epoch_start_stop_time is not None:\n",
    "        if len(clicked_epoch_start_stop_time) == 2:\n",
    "            start_t, end_t = clicked_epoch_start_stop_time\n",
    "            print(f'start_t: {start_t}')\n",
    "            _out_ripple_rasters.programmatically_update_epoch_IDX_from_epoch_start_time(start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1998f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enable programmatically updating the rasters viewer to the clicked epoch index when middle clicking on a posterior.\n",
    "@function_attributes(short_name=None, tags=['callback'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2024-04-29 17:16', related_items=[])\n",
    "def an_alt_clicked_epoch_callback(self, event, clicked_ax, clicked_data_index, clicked_epoch_is_selected, clicked_epoch_start_stop_time):\n",
    "    \"\"\" called when the user middle-clicks an epoch \n",
    "    \n",
    "    captures: _out_ripple_rasters\n",
    "    \"\"\"\n",
    "    print(f'an_alt_clicked_epoch_callback(clicked_data_index: {clicked_data_index}, clicked_epoch_is_selected: {clicked_epoch_is_selected}, clicked_epoch_start_stop_time: {clicked_epoch_start_stop_time})')\n",
    "    if clicked_epoch_start_stop_time is not None:\n",
    "        if len(clicked_epoch_start_stop_time) == 2:\n",
    "            start_t, end_t = clicked_epoch_start_stop_time\n",
    "            print(f'start_t: {start_t}')\n",
    "            _out_ripple_rasters.programmatically_update_epoch_IDX_from_epoch_start_time(start_t)\n",
    "\n",
    "\n",
    "for a_name, a_pagination_controller in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    # a_pagination_controller.params.debug_print = True\n",
    "    if not a_pagination_controller.params.has_attr('on_middle_click_item_callbacks'):\n",
    "        a_pagination_controller.params['on_middle_click_item_callbacks'] = {}    \n",
    "    a_pagination_controller.params.on_middle_click_item_callbacks['an_alt_clicked_epoch_callback'] = an_alt_clicked_epoch_callback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting to set identical low and high xlims makes transformation singular; automatically expanding. Is this what is causing the white posteriors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f80c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ddc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window.pagination_controllers['long_LR'].params.posterior_heatmap_imshow_kwargs = dict(vmin=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23369f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# paginated_multi_decoder_decoded_epochs_window.update_params(posterior_heatmap_imshow_kwargs = dict(vmin=0.0))\n",
    "\n",
    "paginated_multi_decoder_decoded_epochs_window.update_params(enable_per_epoch_action_buttons = True)\n",
    "paginated_multi_decoder_decoded_epochs_window.refresh_current_page()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.get_children_props('params')\n",
    "# paginated_multi_decoder_decoded_epochs_window.get_children_props('plots')\n",
    "# paginated_multi_decoder_decoded_epochs_window.get_children_props('plots.fig')\n",
    "paginated_multi_decoder_decoded_epochs_window.get_children_props('plots.fig')\n",
    "# paginated_multi_decoder_decoded_epochs_window.get_children_props('params.posterior_heatmap_imshow_kwargs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ca528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window# AttributeError: 'PhoPaginatedMultiDecoderDecodedEpochsWindow' object has no attribute 'params'\n",
    "\n",
    "paginated_multi_decoder_decoded_epochs_window.pagination_controllers['long_LR'].params.should_suppress_callback_exceptions = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a19394",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.jump_to_page(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea69a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f136d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2150f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    # v.params.enable_radon_transform_info = False\n",
    "    # v.params.enable_weighted_correlation_info = False\n",
    "    v._subfn_clear_selectability_rects()\n",
    "    \n",
    "# paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_ctrlr in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    a_ctrlr.perform_update_selections(defer_render=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fb8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009775d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with Ctx(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [[785.7379401021171, 785.9232737672282]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [[427.4610240198672, 427.55720829055645]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [[833.3391086903866, 833.4508065531263]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [[491.7975491596153, 492.17844624456484], [940.0164351915009, 940.2191870877286]]\n",
    "\n",
    "# with Ctx(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [array([785.738, 785.923])]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [array([427.461, 427.557])]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [array([833.339, 833.451])]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [array([491.798, 492.178]), array([940.016, 940.219])]\n",
    "\n",
    "# with Ctx(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [[785.7379401021171, 785.9232737672282]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [[427.4610240198672, 427.55720829055645]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [[833.3391086903866, 833.4508065531263]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [[491.7975491596153, 492.17844624456484], [940.0164351915009, 940.2191870877286]]\n",
    "\n",
    "# with Ctx(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [[208.356, 208.523], [693.842, 693.975], [954.574, 954.679]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [[224.037, 224.312]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [[145.776, 146.022], [198.220, 198.582], [220.041, 220.259], [511.570, 511.874], [865.238, 865.373]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [[191.817, 192.100], [323.147, 323.297]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-paginated_multi_decoder_decoded_epochs_window_page.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    paginated_multi_decoder_decoded_epochs_window.jump_to_page(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f513296",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.jump_to_page(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98478063",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.get_decoder_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec6078",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    # v.params.enable_radon_transform_info = False\n",
    "    # v.params.enable_weighted_correlation_info = False\n",
    "    v.params.enable_radon_transform_info = True\n",
    "    v.params.enable_weighted_correlation_info = True\n",
    "    v.params.debug_enabled = True\n",
    "\n",
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    print(f'decoder[{k}]:')\n",
    "    v.params.name\n",
    "    # v.params.on_render_page_callbacks\n",
    "    # v.params.enable_radon_transform_info\n",
    "    len(v.plots_data.radon_transform_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1ff3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7cc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b447b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.refresh_current_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec3540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sub_subfn_wrapped_in_brackets(s: str, bracket_strings = (\"[\", \"]\")) -> str:\n",
    "        return bracket_strings[0] + s + bracket_strings[1]\n",
    "    \n",
    "def _sub_subfn_format_nested_list(arr, precision:int=3, num_sep=\", \", array_sep=', ') -> str:\n",
    "    \"\"\"\n",
    "    Converts a nested list of floats into a single string,\n",
    "    with each float formatted to the specified precision.\n",
    "    \n",
    "    arr = np.array([[491.798, 492.178], [940.016, 940.219]])\n",
    "    _sub_subfn_format_nested_list(arr)\n",
    "\n",
    "    >> '[[491.798, 492.178], [940.016, 940.219]]'\n",
    "\n",
    "    arr = np.array([[785.738, 785.923]])\n",
    "    _sub_subfn_format_nested_list(arr)\n",
    "    >> '[[785.738, 785.923]]'\n",
    "    \"\"\"\n",
    "    return _sub_subfn_wrapped_in_brackets(array_sep.join([_sub_subfn_wrapped_in_brackets(num_sep.join([f\"{num:.{precision}f}\" for num in row])) for row in arr]))\n",
    "    \n",
    "# arr = np.array([[491.798, 492.178], [940.016, 940.219]])\n",
    "arr = np.array([[785.738, 785.923]])\n",
    "_sub_subfn_format_nested_list(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f0ab5d",
   "metadata": {},
   "source": [
    "### 2024-02-29 3pm - Get the active user-annotated epoch times from the `paginated_multi_decoder_decoded_epochs_window` and use these to filter `filtered_ripple_simple_pf_pearson_merged_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c982e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inputs: paginated_multi_decoder_decoded_epochs_window, filtered_ripple_simple_pf_pearson_merged_df\n",
    "any_good_selected_epoch_times = deepcopy(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times)\n",
    "any_good_selected_epoch_indicies = deepcopy(paginated_multi_decoder_decoded_epochs_window.find_data_indicies_from_epoch_times(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa1f903",
   "metadata": {},
   "source": [
    "## 🔶 2024-03-01 - Get the active user-annotated epoch times from the `UserAnnotationsManager` and use these to filter `filtered_ripple_simple_pf_pearson_merged_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc751d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.misc import numpyify_array\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.epoch import EpochsAccessor\n",
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "## Get from UserAnnotations directly instead of the intermediate viewer\n",
    "\n",
    "## # inputs: any_good_selected_epoch_times, any_good_selected_epoch_times, any_good_selected_epoch_indicies \n",
    "\n",
    "decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline, track_templates=track_templates)\n",
    "# any_good_selected_epoch_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(any_good_selected_epoch_times)\n",
    "# any_good_selected_epoch_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.find_data_indicies_from_epoch_times(any_good_selected_epoch_times)\n",
    "# any_good_selected_epoch_indicies\n",
    "# Add user-selection columns to df\n",
    "a_df = deepcopy(filtered_ripple_simple_pf_pearson_merged_df)\n",
    "# a_df = deepcopy(ripple_weighted_corr_merged_df)\n",
    "a_df['is_user_annotated_epoch'] = False\n",
    "# any_good_selected_epoch_indicies = a_df.epochs.find_data_indicies_from_epoch_times(any_good_selected_epoch_times)\n",
    "any_good_selected_epoch_indicies = find_data_indicies_from_epoch_times(a_df, np.squeeze(any_good_selected_epoch_times[:,0]), t_column_names=['ripple_start_t',])\n",
    "# any_good_selected_epoch_indicies = find_data_indicies_from_epoch_times(a_df, any_good_selected_epoch_times, t_column_names=['ripple_start_t',])\n",
    "any_good_selected_epoch_indicies\n",
    "# a_df['is_user_annotated_epoch'] = np.isin(a_df.index.to_numpy(), any_good_selected_epoch_indicies)\n",
    "a_df['is_user_annotated_epoch'].loc[any_good_selected_epoch_indicies] = True # Here's another .iloc issue! Changing to .loc\n",
    "a_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3a540",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DecoderDecodedEpochsResult.filter_epochs_dfs_by_annotation_times(curr_active_pipeline, any_good_selected_epoch_times, ripple_decoding_time_bin_size, filtered_ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dee7b3",
   "metadata": {},
   "source": [
    "### 2024-02-29 - 4pm - Filter the events for those meeting wcorr criteria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed7e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_wcorr_threshold: float = 0.33\n",
    "min_wcorr_diff_threshold: float = 0.2\n",
    "\n",
    "is_included_large_wcorr_diff = np.any((df[['wcorr_abs_diff']].abs() > min_wcorr_diff_threshold), axis=1)\n",
    "is_included_high_wcorr = np.any((df[['long_best_wcorr', 'short_best_wcorr']].abs() > min_wcorr_threshold), axis=1)\n",
    "\n",
    "df = df[is_included_high_wcorr]\n",
    "df\n",
    "\n",
    "# delta_aligned_start_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fc554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifts the absolute times to delta-relative values, as would be needed to draw on a 'delta_aligned_start_t' axis:\n",
    "delta_relative_t_start, delta_relative_t_delta, delta_relative_t_end = np.array([earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end]) - t_delta\n",
    "delta_relative_t_start, delta_relative_t_delta, delta_relative_t_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['_wcorr_y_col'] = df['long_best_wcorr'].abs()\n",
    "df['_wcorr_y_col_y_diff_col'] = df['long_best_wcorr'].abs() - df['short_best_wcorr'].abs()\n",
    "# df.plot.scatter(x='ripple_start_t', y='wcorr_y_col')\n",
    "df.plot.scatter(x='delta_aligned_start_t', y='_wcorr_y_col_y_diff_col')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5438dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['pearsonr_long_abs'] = df['long_best_pf_peak_x_pearsonr'].abs()\n",
    "# df['pearsonr_short_abs'] = df['short_best_pf_peak_x_pearsonr'].abs()\n",
    "# df['pearsonr_diff'] = df['long_best_pf_peak_x_pearsonr'].abs() - df['short_best_pf_peak_x_pearsonr'].abs()\n",
    "\n",
    "# df.plot.scatter(x='delta_aligned_start_t', y='pearsonr_long_abs')\n",
    "# df.plot.scatter(x='delta_aligned_start_t', y='pearsonr_short_abs')\n",
    "df.plot.scatter(x='delta_aligned_start_t', y='pearsonr_abs_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f951c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271d716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.debug_print = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02556ea",
   "metadata": {},
   "source": [
    "### Add utility footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3888f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, get_utility_dock_colors\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import ThinButtonBarWidget\n",
    "\n",
    "\n",
    "def _add_utility_footer(paginated_multi_decoder_decoded_epochs_window):\n",
    "    ui = paginated_multi_decoder_decoded_epochs_window.ui._contents\n",
    "    # ui.dock_widgets\n",
    "    # ui.dock_configs\n",
    "\n",
    "\n",
    "    ## Build the utility controls at the bottom:\n",
    "    ctrls_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=get_utility_dock_colors, showCloseButton=True, orientation='horizontal')\n",
    "\n",
    "    button_bar_height = 21\n",
    "    ctrls_button_bar_widget = ThinButtonBarWidget()\n",
    "    ctrls_button_bar_widget.setObjectName(\"ctrls_button_bar\")\n",
    "    # Set the background color to blue with 40% opacity (RGBA)\n",
    "    ctrls_button_bar_widget.setStyleSheet(\"background-color: rgba(0, 0, 255, 102);\")\n",
    "\n",
    "    ctrl_layout = pg.LayoutWidget()\n",
    "    ctrl_layout.addWidget(ctrls_button_bar_widget, row=1, rowspan=1, col=1, colspan=2)\n",
    "    ctrl_widgets_dict = dict(ctrls_widget=ctrls_button_bar_widget)\n",
    "    # Set the background color to green with 40% opacity (RGBA)\n",
    "    ctrl_layout.setStyleSheet(\"background-color: rgba(0, 255, 10, 102);\")\n",
    "\n",
    "    # ctrl_layout.setSizePolicy(\n",
    "\n",
    "    def onCopySelectionsClicked():\n",
    "        print(f'onCopySelectionsClicked()')\n",
    "        saved_selections_contexts_dict = paginated_multi_decoder_decoded_epochs_window.print_user_annotations()\n",
    "\n",
    "    ctrl_widgets_dict['copy_selection_connection'] = ctrls_button_bar_widget.sigCopySelections.connect(onCopySelectionsClicked)\n",
    "\n",
    "    ui.dock_widgets['bottom_controls'] = paginated_multi_decoder_decoded_epochs_window.add_display_dock(identifier='bottom_controls', widget=ctrl_layout, dockSize=(600, button_bar_height), dockAddLocationOpts=['bottom'], display_config=ctrls_dock_config, autoOrientation=False)\n",
    "    # ui.dock_widgets['bottom_controls'][1].hideTitleBar()\n",
    "    ui.dock_widgets['bottom_controls']\n",
    "\n",
    "    button_bar_height = 21\n",
    "\n",
    "    a_layout = ui.dock_widgets['bottom_controls'][0]\n",
    "    a_layout.size()\n",
    "    a_layout.setContentsMargins(0,0,0,0)\n",
    "    a_layout.setFixedHeight(21)\n",
    "    ui.dock_widgets['bottom_controls'][1].size()\n",
    "    ui.dock_widgets['bottom_controls'][1].setContentsMargins(0,0,0,0)\n",
    "    ui.dock_widgets['bottom_controls'][1].setStyleSheet(\"background-color: rgba(255, 10, 10, 102);\") # RED\n",
    "\n",
    "    # ui.dock_widgets['bottom_controls'][1].hideTitleBar()\n",
    "    # ui.dock_widgets['bottom_controls'][1].size\n",
    "\n",
    "    return ctrl_layout, ctrls_dock_config, ui\n",
    "\n",
    "\n",
    "ctrl_layout, ctrls_dock_config, ui = _add_utility_footer(paginated_multi_decoder_decoded_epochs_window=new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd6823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window=new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window\n",
    "ui = paginated_multi_decoder_decoded_epochs_window.ui._contents\n",
    "\n",
    "layout_widget, dock_item = ui.dock_widgets['bottom_controls']\n",
    "layout_widget.size()\n",
    "# Set the background color to light grey\n",
    "layout_widget.setStyleSheet(\"background-color: red;\")\n",
    "\n",
    "# layout_widget.setBackgroundColor('black')\n",
    "layout_widget.setAutoFillBackground(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3add584",
   "metadata": {},
   "outputs": [],
   "source": [
    " ui.dock_widgets['bottom_controls'][1].size()\n",
    " ui.dock_widgets['bottom_controls'][1].setFixedHeight(21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b47e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.dock_widgets['bottom_controls'][1].children()\n",
    "# [<pyphoplacecellanalysis.External.pyqtgraph.dockarea.DockDrop.DropAreaOverlay object at 0x00000175C7D24820>,\n",
    "#  <PyQt5.QtWidgets.QGridLayout object at 0x00000175C7D248B0>,\n",
    "#  <pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock.DockLabel object at 0x00000175C7D24E50>,\n",
    "#  <PyQt5.QtWidgets.QWidget object at 0x00000175C7D245E0>,\n",
    "#  <pyphoplacecellanalysis.External.pyqtgraph.dockarea.DockDrop.DropAreaOverlay object at 0x00000175C7D24B80>]\n",
    "\n",
    "ui.dock_widgets['bottom_controls'][1].layout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_item.showTitleBar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_item.setOrientation('horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17726a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_item.setContentsMargins(0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d91d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_widget.setContentsMargins(0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "setMargin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.dock_widgets['bottom_controls'][0].resize(600, 21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39be52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.find_display_dock('bottom_controls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.remove_display_dock('bottom_controls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "\n",
    "## Set epoch annotations from selections epochs \n",
    "annotations_man = UserAnnotationsManager()\n",
    "user_annotations = annotations_man.get_user_annotations()\n",
    "new_selections_dict = paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations(user_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf471332",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_selections_objs_dict = {a_name:EpochSelectionsObject(epoch_times=a_selections_values) for a_name, a_selections_values in loaded_selections_dict.items()}\n",
    "loaded_selections_objs_dict\n",
    "\n",
    "## Select just the selected epoch times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_selections_context_dict = {a_name:v.figure_ctx.adding_context_if_missing(user_annotation='selections') for a_name, v in saved_selections_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d312d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.print_user_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ee6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the excessively long plot titles?\n",
    "# root_dockAreaWindow.update\n",
    "pagination_controller_dict = paginated_multi_decoder_decoded_epochs_window.pagination_controllers\n",
    "all_widgets = {a_decoder_name:a_pagination_controller.ui.mw for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_windows = {a_decoder_name:a_pagination_controller.ui.mw.window() for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_plots = {a_decoder_name:a_pagination_controller.plots for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_plots_data = {a_decoder_name:a_pagination_controller.plots_data for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_params = {a_decoder_name:a_pagination_controller.params for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_current_page_idx = {a_decoder_name:a_pagination_controller.current_page_idx for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_current_page_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cfebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_separate_plots\n",
    "\n",
    "all_separate_weighted_corr_plots = {a_decoder_name:a_pagination_controller.plots.get('weighted_corr', {}) for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_weighted_corr_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.ui.print = self.private_print # builtins.print # the print function to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69313c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import EpochsAccessor\n",
    "\n",
    "# MLM\n",
    "# {a_name:a_ctrlr.params.is_selected for a_name, a_ctrlr in root_dockAreaWindow.pagination_controllers.items()}\n",
    "# {a_name:a_ctrlr.selected_epoch_times for a_name, a_ctrlr in root_dockAreaWindow.pagination_controllers.items()}\n",
    "\n",
    "any_good_selected_epoch_times: NDArray = paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times # drops duplicate rows (present in multiple decoders), and sorts them ascending\n",
    "# any_good_selected_epoch_times\n",
    "# Only at the decoder-level\n",
    "any_good_epoch_idxs_list = [a_ctrlr.find_data_indicies_from_epoch_times(any_good_selected_epoch_times) for a_name, a_ctrlr in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items()]\n",
    "any_good_epoch_idxs: NDArray = any_good_epoch_idxs_list[0]\n",
    "any_good_epoch_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29282203",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531db971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filtered_ripple_simple_pf_pearson_merged_df.epochs.find_data_indicies_from_epoch_times(any_good_selected_epoch_times)\n",
    "# filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(any_good_selected_epoch_times)\n",
    "\n",
    "found_data_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.find_data_indicies_from_epoch_times(epoch_times=any_good_selected_epoch_times)\n",
    "df = filtered_ripple_simple_pf_pearson_merged_df.epochs._obj.iloc[found_data_indicies].copy().reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a78ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ripple_simple_pf_pearson_merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1677479",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_selected_ripple_simple_pf_pearson_merged_df = filtered_ripple_simple_pf_pearson_merged_df.iloc[any_good_epoch_idxs, :].reset_index(drop=True)\n",
    "hand_selected_ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d400bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand_selected_ripple_simple_pf_pearson_merged_df['best_decoder_index']\n",
    "\n",
    "is_most_likely_long = (hand_selected_ripple_simple_pf_pearson_merged_df['P_Long'] >= 0.5)\n",
    "# is_most_likely_long\n",
    "\n",
    "long_likely_hand_selected_ripple_simple_pf_pearson_merged_df = hand_selected_ripple_simple_pf_pearson_merged_df[is_most_likely_long]\n",
    "long_likely_hand_selected_ripple_simple_pf_pearson_merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d33190",
   "metadata": {},
   "source": [
    "## 🖼️🎨 Plot laps to compare between decoders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4873ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import add_laps_groundtruth_information_to_dataframe\n",
    "\n",
    "# decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs # looks like 'lap_dir' column is wrong\n",
    "updated_laps_dfs_dict = {}\n",
    "\n",
    "## Update the .filter_epochs:\n",
    "for k, v in decoder_laps_filter_epochs_decoder_result_dict.items():\n",
    "    updated_laps_dfs_dict[k] = Epoch(add_laps_groundtruth_information_to_dataframe(curr_active_pipeline=curr_active_pipeline, result_laps_epochs_df=ensure_dataframe(v.filter_epochs)))\n",
    "    decoder_laps_filter_epochs_decoder_result_dict[k].filter_epochs =  updated_laps_dfs_dict[k]\n",
    "\n",
    "# updated_laps_dfs_dict['long_LR']\n",
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_app, laps_paginated_multi_decoder_decoded_epochs_window, laps_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                            decoder_decoded_epochs_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epochs_name='laps', included_epoch_indicies=None, \n",
    "    params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': False, \n",
    "    # 'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': True, 'enable_weighted_correlation_info': False,\n",
    "    'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': True, 'enable_weighted_correlation_info': True,\n",
    "    # 'disable_y_label': True,\n",
    "    # 'isPaginatorControlWidgetBackedMode': True,\n",
    "    # 'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "    # 'debug_print': True,\n",
    "    'max_subplots_per_page': 10,\n",
    "    'scrollable_figure': True,\n",
    "    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "    'use_AnchoredCustomText': False,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec05d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "\n",
    "## INPUTS: decoder_laps_filter_epochs_decoder_result_dict\n",
    "\n",
    "## Highlight the correct ones:\n",
    "# {k:Epoch(add_laps_groundtruth_information_to_dataframe(curr_active_pipeline=curr_active_pipeline, result_laps_epochs_df=ensure_dataframe(v.filter_epochs))) for k, v in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "\n",
    "## Select the true laps by emulating user_annotations:\n",
    "filter_epochs = ensure_dataframe(deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)) \n",
    "# filter_epochs\n",
    "\n",
    "decoder_name_idx_map = {'long_LR': 0, 'long_RL': 1, 'short_LR': 2, 'short_RL': 3} \n",
    "selections_dict = {}\n",
    "figure_ctx_dict = laps_paginated_multi_decoder_decoded_epochs_window.figure_ctx_dict\n",
    "loaded_selections_context_dict = {a_name:a_figure_ctx.adding_context_if_missing(user_annotation='selections') for a_name, a_figure_ctx in figure_ctx_dict.items()}\n",
    "\n",
    "for a_name, an_idx in decoder_name_idx_map.items():\n",
    "    a_selections_context = loaded_selections_context_dict[a_name]\n",
    "    selections_dict[a_selections_context] = filter_epochs[filter_epochs['true_decoder_index'] == an_idx][['start', 'stop']].to_numpy()\n",
    "\n",
    "\n",
    "## Clearing the existing selection rects and them having them rebuilt when the selection is updated fixes them being shifted.\n",
    "for k, v in laps_pagination_controller_dict.items():\n",
    "    v._subfn_clear_selectability_rects()\n",
    "\n",
    "# _tmp_out_selections = laps_paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations(user_annotations=selections_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6607cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e840a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f558fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89caf8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15bba6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e364cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_paginated_multi_decoder_decoded_epochs_window.remove_data_overlays(defer_refresh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e23e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_paginated_multi_decoder_decoded_epochs_window.remov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clearing the existing selection rects and them having them rebuilt when the selection is updated fixes them being shifted.\n",
    "for k, v in laps_pagination_controller_dict.items():\n",
    "    v._subfn_clear_selectability_rects()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5675f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b603bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f847f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1556870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(decoder_laps_filter_epochs_decoder_result_dict.keys())\n",
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the figure from the axes:\n",
    "a_fig = ax.get_figure()\n",
    "a_fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_controlling_pagination_controller = laps_paginated_multi_decoder_decoded_epochs_window.contents.pagination_controllers['long_LR'] # DecodedEpochSlicesPaginatedFigureController\n",
    "a_pagination_controller_figure_widget = paginator_controller_widget = a_controlling_pagination_controller.ui.mw # MatplotlibTimeSynchronizedWidget\n",
    "paginator_controller_widget = a_controlling_pagination_controller.ui.mw.ui.paginator_controller_widget # PaginationControlWidget\n",
    "# paginator_controller_widget\n",
    "a_pagination_controller_figure_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92048bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = a_controlling_pagination_controller.plots.axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_figure().canvas.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47481538",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_rectangles_dict = a_controlling_pagination_controller.plots.get('selection_rectangles_dict', None)\n",
    "selection_rectangles_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa452e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_controlling_pagination_controller.plots.fig.canvas.draw_idle()\n",
    "# a_controlling_pagination_controller.plots.fig.canvas.draw()\n",
    "# paginator_controller_widget.update()\n",
    "a_pagination_controller_figure_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72db1753",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator_controller_widget.go_to_page(3)\n",
    "# paginator_controller_widget.jump_to_page(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635fbe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_controlling_pagination_controller.ui.mw.ui.paginator_controller_widget.jump_to_page\n",
    "\n",
    "new_obj.plots_data.paginator\n",
    "new_obj.params.active_identifying_figure_ctx\n",
    "new_obj.on_paginator_control_widget_jump_to_page(page_idx=0)\n",
    "new_obj.ui.connections['paginator_controller_widget_jump_to_page']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c54dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, extant_plots in a_plots['weighted_corr'].items():\n",
    "    extant_wcorr_text = extant_plots.get('wcorr_text', None)\n",
    "    # extant_wcorr_text = extant_plots.pop('wcorr_text', None)\n",
    "    print(f'extant_wcorr_text: {extant_wcorr_text}')\n",
    "    # plot the radon transform line on the epoch:\n",
    "    if (extant_wcorr_text is not None):\n",
    "        # already exists, clear the existing ones. \n",
    "        # Let's assume we want to remove the 'Quadratic' line (line2)\n",
    "        print(f'removing extant text object at index: {i}.')\n",
    "        # extant_wcorr_text.remove()\n",
    "        extant_wcorr_text.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b7e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_pagination_controller in pagination_controller_dict.items():\n",
    "    display_context = a_pagination_controller.params.get('active_identifying_figure_ctx', IdentifyingContext())\n",
    "\n",
    "    # Get context for current page of items:\n",
    "    current_page_idx: int = int(a_pagination_controller.current_page_idx)\n",
    "    a_paginator = a_pagination_controller.paginator\n",
    "    total_num_pages = int(a_paginator.num_pages)\n",
    "    page_context = display_context.overwriting_context(page=current_page_idx, num_pages=total_num_pages)\n",
    "    print(page_context)\n",
    "\n",
    "    ## Get the figure/axes:\n",
    "    a_plots = a_pagination_controller.plots # RenderPlots\n",
    "    a_plot_data = a_pagination_controller.plots_data\n",
    "\n",
    "    a_params = a_pagination_controller.params\n",
    "    a_params.skip_plotting_measured_positions\n",
    "\n",
    "    figs = a_plots.fig\n",
    "    axs = a_plots.axs\n",
    "\n",
    "    # # with mpl.rc_context({'figure.figsize': (8.4, 4.8), 'figure.dpi': '220', 'savefig.transparent': True, 'ps.fonttype': 42, }):\n",
    "    # with mpl.rc_context({'figure.figsize': (16.8, 4.8), 'figure.dpi': '420', 'savefig.transparent': True, 'ps.fonttype': 42, }):\n",
    "    #     curr_active_pipeline.output_figure(final_context=page_context, fig=figs, write_vector_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d32342",
   "metadata": {},
   "source": [
    "## 💾 Export Paginated Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec0488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laps_paginated_multi_decoder_decoded_epochs_window.export_all_pages(curr_active_pipeline)\n",
    "paginated_multi_decoder_decoded_epochs_window.export_all_pages(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be8a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.export_decoder_pagination_controller_figure_page(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd2637",
   "metadata": {},
   "source": [
    "## 🔷🎨 Single Decoder Version (`DecodedEpochSlicesPaginatedFigureController`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d880d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import _subfn_update_decoded_epoch_slices\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController # `plot_decoded_epoch_slices_paginated`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import WeightedCorrelationPaginatedPlotDataProvider\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import DecodedPositionsPlotDataProvider, DecodedAndActualPositionsPlotData\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import perform_plot_1D_single_most_likely_position_curve\n",
    "\n",
    "# Inputs: epochs_name, decoder_ripple_filter_epochs_decoder_result_dict, curr_active_pipeline\n",
    "epochs_name = 'ripple'\n",
    "\n",
    "(a_name, a_decoder) = tuple(track_templates.get_decoders_dict().items())[0]\n",
    "\n",
    "# a_decoder_decoded_epochs_result = decoder_ripple_filter_epochs_decoder_result_dict[a_name]\n",
    "\n",
    "# a_decoder_decoded_epochs_result = decoder_ripple_filter_epochs_decoder_result_dict[a_name]\n",
    "a_decoder_decoded_epochs_result = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict[a_name]) ## FILTERED\n",
    "\n",
    "_out_pagination_controller = DecodedEpochSlicesPaginatedFigureController.init_from_decoder_data(active_filter_epochs=a_decoder_decoded_epochs_result.filter_epochs,\n",
    "                                                                                    filter_epochs_decoder_result= a_decoder_decoded_epochs_result,\n",
    "                                                                                    xbin=a_decoder.xbin, global_pos_df=curr_active_pipeline.sess.position.df,\n",
    "                                                                                    a_name=f'DecodedEpochSlices[{a_name}]', active_context=curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs=epochs_name, decoder=a_name),\n",
    "                                                                                    max_subplots_per_page=32,\n",
    "                                                                                    params_kwargs={'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, 'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': True, #'enable_radon_transform_info': True, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    'enable_radon_transform_info': True, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 32,\n",
    "                                                                                                    'scrollable_figure': True,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': True,\n",
    "                                                                                                    'disable_toolbar': False,\n",
    "                                                                                    }, \n",
    "                                                                                    # disable_toolbar=False\n",
    "                                                                                    )\n",
    "\n",
    "_out_pagination_controller.params.should_suppress_callback_exceptions = False\n",
    "_out_pagination_controller.add_data_overlays(a_decoder_decoded_epochs_result)\n",
    "_tmp_out_selections = _out_pagination_controller.restore_selections_from_user_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c780e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = _out_pagination_controller.plots.fig\n",
    "# fig.toolbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f46ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(_out_pagination_controller)\n",
    "\n",
    "_out_pagination_controller.plot_widget._buildUI_setup_statusbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff74414",
   "metadata": {},
   "source": [
    "single_epoch_field_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e429a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on_selected_epochs_changed\n",
    "\n",
    "active_captured_single_epoch_result: SingleEpochDecodedResult = a_decoder_decoded_epochs_result.get_result_for_epoch(active_epoch_idx=3)\n",
    "\n",
    "def get_selected_posterior_on_secondary_clicked_callback(self, event, clicked_ax, clicked_data_index, clicked_epoch_is_selected, clicked_epoch_start_stop_time):\n",
    "    \"\"\" called when the user alt-clicks an epoch \n",
    "    \n",
    "    captures: active_captured_single_epoch_result\n",
    "    \"\"\"\n",
    "    global active_captured_single_epoch_result\n",
    "    if self.params.debug_print:\n",
    "        print(f'get_selected_posterior_on_secondary_clicked_callback(clicked_data_index: {clicked_data_index}, clicked_epoch_is_selected: {clicked_epoch_is_selected}, clicked_epoch_start_stop_time: {clicked_epoch_start_stop_time})')\n",
    "    if clicked_epoch_start_stop_time is not None:\n",
    "        if len(clicked_epoch_start_stop_time) == 2:\n",
    "            start_t, end_t = clicked_epoch_start_stop_time\n",
    "            # print(f'start_t: {start_t}')\n",
    "            clicked_data_index: int = _out_pagination_controller.find_data_indicies_from_epoch_times(epoch_times=np.array([start_t, end_t]))[0]\n",
    "            if self.params.debug_print:\n",
    "                print(f'\\tclicked_data_index: {clicked_data_index}')            \n",
    "            active_captured_single_epoch_result = a_decoder_decoded_epochs_result.get_result_for_epoch(active_epoch_idx=clicked_data_index)\n",
    "            if self.params.debug_print:\n",
    "                print(f'\\tactive_captured_single_epoch_result.epoch_info_tuple: {active_captured_single_epoch_result.epoch_info_tuple}')\n",
    "                print(f'\\tdone.')\n",
    "\n",
    "\n",
    "# BEGIN FUNCTION BODY ________________________________________________________________________________________________ #\n",
    "if not _out_pagination_controller.params.has_attr('on_middle_click_item_callbacks'):\n",
    "    _out_pagination_controller.params['on_middle_click_item_callbacks'] = {}\n",
    "\n",
    "_out_pagination_controller.params.on_middle_click_item_callbacks['get_selected_posterior_on_secondary_clicked_callback'] = get_selected_posterior_on_secondary_clicked_callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoder_decoded_epochs_result.active_filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a619872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.media_output_helpers import get_array_as_image\n",
    "\n",
    "posterior_image = active_captured_single_epoch_result.get_posterior_as_image(desired_width=2048)\n",
    "posterior_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "\n",
    "# Define 8x8 blur filter kernel\n",
    "blur_kernel = np.ones((8, 8)) / 64\n",
    "\n",
    "# Apply blur to a 2D matrix\n",
    "blurred_matrix = convolve2d(active_captured_single_epoch_result.p_x_given_n, blur_kernel, mode='same', boundary='wrap')\n",
    "\n",
    "get_array_as_image(blurred_matrix, desired_height=400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "{i:col for i, col in enumerate(a_decoder_decoded_epochs_result.active_filter_epochs.columns)}\n",
    "\n",
    "column_indicies = np.arange(12, 19)\n",
    "column_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b8451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_pagination_controller.params.debug_print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc81f8",
   "metadata": {},
   "source": [
    "## 2024-04-30 Heuristic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21abb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *position_relative\": mapped between the ends of the track, 0.0 to 1.0\n",
    "most_likely_position_relative = (np.squeeze(active_captured_single_epoch_result.most_likely_position_indicies) / float(active_captured_single_epoch_result.n_xbins-1))\n",
    "most_likely_position_relative\n",
    "\n",
    "\n",
    "plt.hlines([0], colors='k', xmin=active_captured_single_epoch_result.time_bin_edges[0], xmax=active_captured_single_epoch_result.time_bin_edges[-1])\n",
    "plt.step(active_captured_single_epoch_result.time_bin_container.centers[1:], np.diff(most_likely_position_relative))\n",
    "plt.scatter(active_captured_single_epoch_result.time_bin_container.centers, most_likely_position_relative, color='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c52d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.Qt import QtGui, QtCore, QtWidgets\n",
    "# from pyphoplacecellanalysis.External.pyqtgraph.parametertree.parameterTypes.file import popupFilePicker\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.widgets.FileDialog import FileDialog\n",
    "\n",
    "from silx.gui import qt\n",
    "from silx.gui.dialog.ImageFileDialog import ImageFileDialog\n",
    "from silx.gui.dialog.DataFileDialog import DataFileDialog\n",
    "import silx.io\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import saveFile\n",
    "\n",
    "app = pg.mkQApp('silx_testing')\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc644214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from silx.gui.plot import Plot2D\n",
    "\n",
    "matrix = np.random.rand(10, 10)  # Example 2D matrix\n",
    "plot = Plot2D()\n",
    "plot.addImage(matrix, colormap=\"viridis\", vmin=0, vmax=1)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "\n",
    "HeuristicReplayScoring.bin_wise_track_coverage_score_fn(a_result=a_decoder_decoded_epochs_result, an_epoch_idx=active_captured_single_epoch_result.epoch_data_index, a_decoder_track_length=170.0)\n",
    "\n",
    "# np.diff(active_captured_single_epoch_result.most_likely_position_indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5407a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaeb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CodeConversion.convert_dictionary_to_class_defn(\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = _out_pagination_controller.plots.axs[0]\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d52d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.format_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f28b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ascending sequences of most-likely positions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def format_coord(x, y):\n",
    "    col = round(x)\n",
    "    row = round(y)\n",
    "    nrows, ncols = X.shape\n",
    "    if 0 <= col < ncols and 0 <= row < nrows:\n",
    "        z = X[row, col]\n",
    "        return f'x={x:1.4f}, y={y:1.4f}, z={z:1.4f}'\n",
    "    else:\n",
    "        return f'x={x:1.4f}, y={y:1.4f}'\n",
    "\n",
    "\n",
    "ax.format_coord = format_coord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de603c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_pagination_controller.plot_widget.setStatusTip('LONG STATUS TIP TEST')\n",
    "\n",
    "_out_pagination_controller.plot_widget.update_status('LONG STATUS TIP TEST')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b187c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_pagination_controller.plots.radon_transform\n",
    "fig = _out_pagination_controller.plots.fig\n",
    "\n",
    "# plt.subplots_adjust(left=0.15, right=0.85, top=0.9, bottom=0.1)\n",
    "# Adjust the margins using subplots_adjust\n",
    "fig.subplots_adjust(left=0.15, right=0.85, bottom=0.15, top=0.85)\n",
    "\n",
    "# Adjust the margins using the Figure object\n",
    "# fig.set_tight_layout(dict(rect=[0.1, 0.2, 0.8, 0.8]))\n",
    "# fig.tight_layout(dict(rect=[0.1, 0.2, 0.8, 0.8]))\n",
    "# fig.tight_layout(pad=1.0, rect=[0.1, 0.1, 0.8, 0.8])\n",
    "_out_pagination_controller.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9643ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a_name, a_decoder) = tuple(track_templates.get_decoders_dict().items())[0]\n",
    "a_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d1a25",
   "metadata": {},
   "source": [
    "## 🔷🎨 2024-03-06 - Uni Page Scrollable Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be9e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_decoded_epochs_result_dict: generic\n",
    "single_page_app, single_page_paginated_multi_decoder_decoded_epochs_window, single_page_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                                                                                                decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                included_epoch_indicies=None, debug_print=False,\n",
    "                                                                                                params_kwargs={'skip_plotting_most_likely_positions': False, 'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                               'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                                # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                                # 'disable_y_label': True,\n",
    "                                                                                                                'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                                'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                                # 'debug_print': True,\n",
    "                                                                                                                'max_subplots_per_page': 64,\n",
    "                                                                                                                'scrollable_figure': True,\n",
    "                                                                                                                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2565e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_page_paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "_tmp_out_selections = single_page_paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90abee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for curr_results_obj: LeaveOneOutDecodingAnalysisResult object\n",
    "num_filter_epochs:int = curr_results_obj.active_filter_epochs.n_epochs\n",
    "\n",
    "# `active_filter_epochs_df` native columns approach\n",
    "active_filter_epochs_df = curr_results_obj.active_filter_epochs.to_dataframe().copy()\n",
    "assert np.isin(['score', 'velocity', 'intercept', 'speed'], active_filter_epochs_df.columns).all()\n",
    "epochs_linear_fit_df = active_filter_epochs_df[['score', 'velocity', 'intercept', 'speed']].copy() # get the `epochs_linear_fit_df` as a subset of the filter epochs df\n",
    "# epochs_linear_fit_df approach\n",
    "assert curr_results_obj.all_included_filter_epochs_decoder_result.num_filter_epochs == np.shape(epochs_linear_fit_df)[0]\n",
    "\n",
    "num_filter_epochs:int = curr_results_obj.all_included_filter_epochs_decoder_result.num_filter_epochs # curr_results_obj.num_filter_epochs\n",
    "try:\n",
    "    time_bin_containers: List[BinningContainer] = deepcopy(curr_results_obj.time_bin_containers)\n",
    "except AttributeError as e:\n",
    "    # AttributeError: 'LeaveOneOutDecodingAnalysisResult' object has no attribute 'time_bin_containers' is expected when `curr_results_obj: LeaveOneOutDecodingAnalysisResult - for Long/Short plotting`\n",
    "    time_bin_containers: List[BinningContainer] = deepcopy(curr_results_obj.all_included_filter_epochs_decoder_result.time_bin_containers) # for curr_results_obj: LeaveOneOutDecodingAnalysisResult - for Long/Short plotting\n",
    "\n",
    "radon_transform_data = RadonTransformPlotDataProvider._subfn_build_radon_transform_plotting_data(active_filter_epochs_df=active_filter_epochs_df,\n",
    "            num_filter_epochs = num_filter_epochs, time_bin_containers = time_bin_containers, radon_transform_column_names=['score', 'velocity', 'intercept', 'speed'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d17b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fa458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _display_long_and_short_stacked_epoch_slices\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out_dict = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', save_figure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f3190",
   "metadata": {},
   "source": [
    "## Other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = _out_pagination_controller.plots['radon_transform'][7]\n",
    "extant_line = _out['line'] # matplotlib.lines.Line2D\n",
    "extant_line.linestyle = 'none'\n",
    "# extant_line.draw()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e00165",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(curr_active_pipeline.filtered_contexts.keys())) # ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Converting between decoder names and filtered epoch names:\n",
    "# {'long':'maze1', 'short':'maze2'}\n",
    "# {'LR':'odd', 'RL':'even'}\n",
    "long_LR_name, short_LR_name, long_RL_name, short_RL_name = ['maze1_odd', 'maze2_odd', 'maze1_even', 'maze2_even']\n",
    "decoder_name_to_session_context_name: Dict[str,str] = dict(zip(track_templates.get_decoder_names(), (long_LR_name, long_RL_name, short_LR_name, short_RL_name))) # {'long_LR': 'maze1_odd', 'long_RL': 'maze1_even', 'short_LR': 'maze2_odd', 'short_RL': 'maze2_even'}\n",
    "session_context_to_decoder_name: Dict[str,str] = dict(zip((long_LR_name, long_RL_name, short_LR_name, short_RL_name), track_templates.get_decoder_names())) # {'maze1_odd': 'long_LR', 'maze1_even': 'long_RL', 'maze2_odd': 'short_LR', 'maze2_even': 'short_RL'}\n",
    "\n",
    "decoder_name_to_session_context_name\n",
    "session_context_to_decoder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5896f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_num_slices: int = _out_pagination_controller.params.active_num_slices\n",
    "single_plot_fixed_height: float = _out_pagination_controller.params.single_plot_fixed_height\n",
    "all_plots_height: float = _out_pagination_controller.params.all_plots_height\n",
    "print(f'all_plots_height: {all_plots_height}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad67f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fed6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PendingNotebookCode import _add_maze_id_to_epochs\n",
    "\n",
    "\n",
    "## Add new weighted correlation results as new columns in existing filter_epochs df:\n",
    "active_filter_epochs = long_results_obj.active_filter_epochs\n",
    "# Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "active_filter_epochs = _add_maze_id_to_epochs(active_filter_epochs, short_session.t_start)\n",
    "active_filter_epochs._df['weighted_corr_LONG'] = epoch_long_weighted_corr_results[:,0]\n",
    "active_filter_epochs._df['weighted_corr_SHORT'] = epoch_short_weighted_corr_results[:,0]\n",
    "active_filter_epochs._df['weighted_corr_spearman_LONG'] = epoch_long_weighted_corr_results[:,1]\n",
    "active_filter_epochs._df['weighted_corr_spearman_SHORT'] = epoch_short_weighted_corr_results[:,1]\n",
    "\n",
    "\n",
    "active_filter_epochs\n",
    "active_filter_epochs.to_dataframe()\n",
    "## plot the `weighted_corr_LONG` over time\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=active_num_rows, sharex=True, sharey=sharey, figsize=figsize)\n",
    "\n",
    "## Weighted Correlation during replay epochs:\n",
    "_out_ax = active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_LONG', title='weighted_corr during replay events', marker=\"s\",  s=5, label=f'Long', alpha=0.8)\n",
    "active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_SHORT', xlabel='Replay Epoch Time', ylabel='Weighted Correlation', ax=_out_ax, marker=\"s\", c='r', s=5, label=f'Short', alpha=0.8)\n",
    "_out_ax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line\n",
    "## Weighted Spearman Correlation during replay epochs:\n",
    "_out_ax = active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_spearman_LONG', title='weighted_spearman_corr during replay events', marker=\"s\",  s=5, label=f'Long', alpha=0.8)\n",
    "active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_spearman_SHORT', xlabel='Replay Epoch Time', ylabel='Weighted Spearman Correlation', ax=_out_ax, marker=\"s\", c='r', s=5, label=f'Short', alpha=0.8)\n",
    "_out_ax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line\n",
    "_out_ax = active_filter_epochs._df.plot.scatter(x='start', y='score_LONG', title='Radon Transform Score during replay events', marker=\"s\",  s=5, label=f'Long', alpha=0.8)\n",
    "active_filter_epochs._df.plot.scatter(x='start', y='score_SHORT', xlabel='Replay Epoch Time', ylabel='Replay Radon Transform Score', ax=_out_ax, marker=\"s\", c='r', s=5, label=f'Short', alpha=0.8)\n",
    "_out_ax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe3e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad4f9a0",
   "metadata": {},
   "source": [
    "# 2024-02-15 - Do simple spike-t vs. template pf peak correlation like Kamran suggested this morning\n",
    "\n",
    "Replays can be of trajectories on either the current track configuration or on a temporally distant one (such as a trajectory on the long track after the track has been shortened). \n",
    "The goal of the decoder scoring methods are to evaluate how likely each decoder was. This means for each Epoch we obtain a score for all four decoders: Long_LR, Long_RL, Short_LR, Short_RL\n",
    "\n",
    "#### `posterior decoder likelihoods` - This scoring method produces a probability that the\n",
    "\n",
    "#### Radon Transform - TODO\n",
    "\n",
    "#### `compute_simple_spike_time_v_pf_peak_x_by_epoch` - This epoch scoring metric plots the placefield peak x position against the time in seconds of each spike relative to the start of the epoch. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d1e967",
   "metadata": {},
   "source": [
    "## TODO 2024-02-15 8pm - Add in to previous result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd539a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "\n",
    "# (laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df)\n",
    "# (laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df)\n",
    "laps_simple_pf_pearson_merged_df\n",
    "# laps_radon_transform_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57565cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_lap_epochs_dict = dict(zip((long_LR_name, long_RL_name, short_LR_name, short_RL_name), (long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj)))\n",
    "directional_active_lap_pf_results_dicts = TrialByTrialActivity.directional_compute_trial_by_trial_correlation_matrix(active_pf_dt=active_pf_dt, directional_lap_epochs_dict=directional_lap_epochs_dict, included_neuron_IDs=any_decoder_neuron_IDs)\n",
    "\n",
    "decoder_aclu_peak_location_df_merged = deepcopy(track_templates.get_directional_pf_maximum_peaks_dfs(drop_aclu_if_missing_long_or_short=False))\n",
    "# decoder_aclu_peak_location_df_merged[np.isin(decoder_aclu_peak_location_df_merged['aclu'], both_included_neuron_stats_df.aclu.to_numpy())]\n",
    "decoder_aclu_peak_location_df_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74381521",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result: TrialByTrialActivity = directional_active_lap_pf_results_dicts['long_LR']\n",
    "# a_result.sp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8421fd1a",
   "metadata": {},
   "source": [
    "# 💾 2024-03-04 - Export `DecoderDecodedEpochsResult` CSVs with user annotations for epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ae0ae73",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 136\n",
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 136\n",
      "did_update_user_annotation_col[\"long_LR\"]: True\n",
      "did_update_is_valid[\"long_LR\"]: True\n",
      "did_update_user_annotation_col[\"long_RL\"]: True\n",
      "did_update_is_valid[\"long_RL\"]: True\n",
      "did_update_user_annotation_col[\"short_LR\"]: True\n",
      "did_update_is_valid[\"short_LR\"]: True\n",
      "did_update_user_annotation_col[\"short_RL\"]: True\n",
      "did_update_is_valid[\"short_RL\"]: True\n",
      "\tdone.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_LR</th>\n",
       "      <th>P_RL</th>\n",
       "      <th>P_Long</th>\n",
       "      <th>P_Short</th>\n",
       "      <th>ripple_idx</th>\n",
       "      <th>ripple_start_t</th>\n",
       "      <th>P_Long_LR</th>\n",
       "      <th>P_Long_RL</th>\n",
       "      <th>P_Short_LR</th>\n",
       "      <th>P_Short_RL</th>\n",
       "      <th>most_likely_decoder_index</th>\n",
       "      <th>wcorr_long_LR</th>\n",
       "      <th>wcorr_long_RL</th>\n",
       "      <th>wcorr_short_LR</th>\n",
       "      <th>wcorr_short_RL</th>\n",
       "      <th>best_decoder_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.377521e-03</td>\n",
       "      <td>0.996622</td>\n",
       "      <td>0.968932</td>\n",
       "      <td>0.031068</td>\n",
       "      <td>0</td>\n",
       "      <td>42.658077</td>\n",
       "      <td>3.272587e-03</td>\n",
       "      <td>0.965659</td>\n",
       "      <td>1.049340e-04</td>\n",
       "      <td>0.030963</td>\n",
       "      <td>1</td>\n",
       "      <td>0.724297</td>\n",
       "      <td>-0.515537</td>\n",
       "      <td>0.294705</td>\n",
       "      <td>-0.476819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.847150e-01</td>\n",
       "      <td>0.315285</td>\n",
       "      <td>0.480394</td>\n",
       "      <td>0.519606</td>\n",
       "      <td>1</td>\n",
       "      <td>55.723809</td>\n",
       "      <td>3.289331e-01</td>\n",
       "      <td>0.151461</td>\n",
       "      <td>3.557819e-01</td>\n",
       "      <td>0.163824</td>\n",
       "      <td>2</td>\n",
       "      <td>0.173317</td>\n",
       "      <td>-0.141276</td>\n",
       "      <td>0.093641</td>\n",
       "      <td>-0.079061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.354488e-01</td>\n",
       "      <td>0.464551</td>\n",
       "      <td>0.609787</td>\n",
       "      <td>0.390213</td>\n",
       "      <td>2</td>\n",
       "      <td>73.681176</td>\n",
       "      <td>3.265097e-01</td>\n",
       "      <td>0.283277</td>\n",
       "      <td>2.089391e-01</td>\n",
       "      <td>0.181274</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.107942</td>\n",
       "      <td>-0.357459</td>\n",
       "      <td>-0.116484</td>\n",
       "      <td>-0.276164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.904791e-01</td>\n",
       "      <td>0.609521</td>\n",
       "      <td>0.560678</td>\n",
       "      <td>0.439322</td>\n",
       "      <td>3</td>\n",
       "      <td>92.642502</td>\n",
       "      <td>2.189331e-01</td>\n",
       "      <td>0.341745</td>\n",
       "      <td>1.715460e-01</td>\n",
       "      <td>0.267776</td>\n",
       "      <td>1</td>\n",
       "      <td>0.746645</td>\n",
       "      <td>0.768491</td>\n",
       "      <td>0.588003</td>\n",
       "      <td>0.641184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.549793e-01</td>\n",
       "      <td>0.445021</td>\n",
       "      <td>0.507392</td>\n",
       "      <td>0.492608</td>\n",
       "      <td>4</td>\n",
       "      <td>93.027055</td>\n",
       "      <td>2.815918e-01</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>2.733875e-01</td>\n",
       "      <td>0.219221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.507870</td>\n",
       "      <td>0.496553</td>\n",
       "      <td>0.392682</td>\n",
       "      <td>0.377063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.733433e-01</td>\n",
       "      <td>0.526657</td>\n",
       "      <td>0.258256</td>\n",
       "      <td>0.741744</td>\n",
       "      <td>5</td>\n",
       "      <td>93.925000</td>\n",
       "      <td>1.222436e-01</td>\n",
       "      <td>0.136012</td>\n",
       "      <td>3.510997e-01</td>\n",
       "      <td>0.390645</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.031149</td>\n",
       "      <td>0.226862</td>\n",
       "      <td>-0.026678</td>\n",
       "      <td>0.216318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>6.223742e-01</td>\n",
       "      <td>0.377626</td>\n",
       "      <td>0.372064</td>\n",
       "      <td>0.627936</td>\n",
       "      <td>406</td>\n",
       "      <td>1729.689083</td>\n",
       "      <td>2.315630e-01</td>\n",
       "      <td>0.140501</td>\n",
       "      <td>3.908112e-01</td>\n",
       "      <td>0.237125</td>\n",
       "      <td>2</td>\n",
       "      <td>0.114463</td>\n",
       "      <td>0.303952</td>\n",
       "      <td>0.126077</td>\n",
       "      <td>0.183958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2.263085e-01</td>\n",
       "      <td>0.773692</td>\n",
       "      <td>0.301660</td>\n",
       "      <td>0.698340</td>\n",
       "      <td>407</td>\n",
       "      <td>1731.111480</td>\n",
       "      <td>6.826824e-02</td>\n",
       "      <td>0.233392</td>\n",
       "      <td>1.580403e-01</td>\n",
       "      <td>0.540300</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.279661</td>\n",
       "      <td>-0.580664</td>\n",
       "      <td>-0.052965</td>\n",
       "      <td>-0.295598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>7.050154e-07</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.580727</td>\n",
       "      <td>0.419273</td>\n",
       "      <td>408</td>\n",
       "      <td>1731.789992</td>\n",
       "      <td>4.094216e-07</td>\n",
       "      <td>0.580727</td>\n",
       "      <td>2.955938e-07</td>\n",
       "      <td>0.419272</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.023507</td>\n",
       "      <td>-0.126635</td>\n",
       "      <td>0.145074</td>\n",
       "      <td>0.227193</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>5.131128e-01</td>\n",
       "      <td>0.486887</td>\n",
       "      <td>0.320867</td>\n",
       "      <td>0.679133</td>\n",
       "      <td>409</td>\n",
       "      <td>1733.729959</td>\n",
       "      <td>1.646410e-01</td>\n",
       "      <td>0.156226</td>\n",
       "      <td>3.484718e-01</td>\n",
       "      <td>0.330661</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011708</td>\n",
       "      <td>0.352614</td>\n",
       "      <td>0.134870</td>\n",
       "      <td>0.155268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>3.099668e-01</td>\n",
       "      <td>0.690033</td>\n",
       "      <td>0.304357</td>\n",
       "      <td>0.695643</td>\n",
       "      <td>410</td>\n",
       "      <td>1734.961032</td>\n",
       "      <td>9.434053e-02</td>\n",
       "      <td>0.210016</td>\n",
       "      <td>2.156263e-01</td>\n",
       "      <td>0.480017</td>\n",
       "      <td>3</td>\n",
       "      <td>0.698387</td>\n",
       "      <td>0.681143</td>\n",
       "      <td>0.049096</td>\n",
       "      <td>-0.438151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>4.793921e-01</td>\n",
       "      <td>0.520608</td>\n",
       "      <td>0.718233</td>\n",
       "      <td>0.281767</td>\n",
       "      <td>411</td>\n",
       "      <td>1736.892796</td>\n",
       "      <td>3.443152e-01</td>\n",
       "      <td>0.373918</td>\n",
       "      <td>1.350768e-01</td>\n",
       "      <td>0.146690</td>\n",
       "      <td>1</td>\n",
       "      <td>0.269368</td>\n",
       "      <td>0.589224</td>\n",
       "      <td>0.211011</td>\n",
       "      <td>0.431967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             P_LR      P_RL    P_Long   P_Short  ripple_idx  ripple_start_t     P_Long_LR  P_Long_RL    P_Short_LR  P_Short_RL  most_likely_decoder_index  wcorr_long_LR  wcorr_long_RL  wcorr_short_LR  wcorr_short_RL  best_decoder_index\n",
       "0    3.377521e-03  0.996622  0.968932  0.031068           0       42.658077  3.272587e-03   0.965659  1.049340e-04    0.030963                          1       0.724297      -0.515537        0.294705       -0.476819                   0\n",
       "1    6.847150e-01  0.315285  0.480394  0.519606           1       55.723809  3.289331e-01   0.151461  3.557819e-01    0.163824                          2       0.173317      -0.141276        0.093641       -0.079061                   0\n",
       "2    5.354488e-01  0.464551  0.609787  0.390213           2       73.681176  3.265097e-01   0.283277  2.089391e-01    0.181274                          0      -0.107942      -0.357459       -0.116484       -0.276164                   1\n",
       "3    3.904791e-01  0.609521  0.560678  0.439322           3       92.642502  2.189331e-01   0.341745  1.715460e-01    0.267776                          1       0.746645       0.768491        0.588003        0.641184                   1\n",
       "4    5.549793e-01  0.445021  0.507392  0.492608           4       93.027055  2.815918e-01   0.225800  2.733875e-01    0.219221                          0       0.507870       0.496553        0.392682        0.377063                   0\n",
       "5    4.733433e-01  0.526657  0.258256  0.741744           5       93.925000  1.222436e-01   0.136012  3.510997e-01    0.390645                          3      -0.031149       0.226862       -0.026678        0.216318                   1\n",
       "..            ...       ...       ...       ...         ...             ...           ...        ...           ...         ...                        ...            ...            ...             ...             ...                 ...\n",
       "406  6.223742e-01  0.377626  0.372064  0.627936         406     1729.689083  2.315630e-01   0.140501  3.908112e-01    0.237125                          2       0.114463       0.303952        0.126077        0.183958                   1\n",
       "407  2.263085e-01  0.773692  0.301660  0.698340         407     1731.111480  6.826824e-02   0.233392  1.580403e-01    0.540300                          3      -0.279661      -0.580664       -0.052965       -0.295598                   1\n",
       "408  7.050154e-07  0.999999  0.580727  0.419273         408     1731.789992  4.094216e-07   0.580727  2.955938e-07    0.419272                          1      -0.023507      -0.126635        0.145074        0.227193                   3\n",
       "409  5.131128e-01  0.486887  0.320867  0.679133         409     1733.729959  1.646410e-01   0.156226  3.484718e-01    0.330661                          2       0.011708       0.352614        0.134870        0.155268                   1\n",
       "410  3.099668e-01  0.690033  0.304357  0.695643         410     1734.961032  9.434053e-02   0.210016  2.156263e-01    0.480017                          3       0.698387       0.681143        0.049096       -0.438151                   0\n",
       "411  4.793921e-01  0.520608  0.718233  0.281767         411     1736.892796  3.443152e-01   0.373918  1.350768e-01    0.146690                          1       0.269368       0.589224        0.211011        0.431967                   1\n",
       "\n",
       "[412 rows x 16 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuropy.core.epoch import ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "_, _, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "filtered_valid_epoch_times = filtered_epochs_df[['start', 'stop']].to_numpy()\n",
    "\n",
    "## 2024-03-08 - Also constrain the user-selected ones (just to try it):\n",
    "decoder_user_selected_epoch_times_dict, any_user_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline, track_templates=track_templates)\n",
    "\n",
    "a_result_dict = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "# {a_name:ensure_dataframe(a_result.filter_epochs) for a_name, a_result in a_result_dict.items()}\n",
    "\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=True)\n",
    "\n",
    "# 🟪 2024-02-29 - `compute_pho_heuristic_replay_scores`\n",
    "directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict, _out_new_scores = HeuristicReplayScoring.compute_all_heuristic_scores(track_templates=track_templates, a_decoded_filter_epochs_decoder_result_dict=directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "\n",
    "## Merge the heuristic columns into the wcorr df columns for exports\n",
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "\n",
    "# {a_name:DecoderDecodedEpochsResult.try_add_is_user_annotated_epoch_column(ensure_dataframe(a_result.filter_epochs), any_good_selected_epoch_times=filtered_valid_epoch_times) for a_name, a_result in a_result_dict.items()}\n",
    "\n",
    "for a_name, a_result in a_result_dict.items():\n",
    "    # a_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=True)\n",
    "\n",
    "    ## Merge the heuristic columns into the wcorr df columns for exports\n",
    "    # directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    a_wcorr_result = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict[a_name]\n",
    "    \n",
    "    # did_update_user_annotation_col = DecoderDecodedEpochsResult.try_add_is_user_annotated_epoch_column(ensure_dataframe(a_result.filter_epochs), any_good_selected_epoch_times=any_user_selected_epoch_times, t_column_names=None)\n",
    "    # print(f'did_update_user_annotation_col: {did_update_user_annotation_col}')\n",
    "    # did_update_is_valid = DecoderDecodedEpochsResult.try_add_is_valid_epoch_column(ensure_dataframe(a_result.filter_epochs), any_good_selected_epoch_times=filtered_valid_epoch_times, t_column_names=None)\n",
    "    # print(f'did_update_is_valid: {did_update_is_valid}')\n",
    "\n",
    "# ['start',]\n",
    "\n",
    "a_result_dict = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "\n",
    "# {a_name:ensure_dataframe(a_result.filter_epochs) for a_name, a_result in a_result_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e04fb7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'long_LR':      longest_sequence_length  longest_sequence_length_ratio  direction_change_bin_ratio  congruent_dir_bins_ratio  total_congruent_direction_change  total_variation  integral_second_derivative  stddev_of_diff\n",
       " 0                          2                       1.000000                    0.000000                  1.000000                         87.524594        87.524594                    0.000000        0.000000\n",
       " 1                          3                       0.300000                    0.555556                  0.333333                        251.157530       490.898808               128781.306536       78.542924\n",
       " 2                          4                       0.285714                    0.461538                  0.307692                        350.098375       681.169664               298037.565481       86.539550\n",
       " 3                          3                       0.375000                    0.428571                  0.714286                        220.714193       243.546695                20143.348408       41.179825\n",
       " 4                          6                       0.222222                    0.500000                  0.500000                        939.938028      1723.853954               637694.098126       95.265151\n",
       " 5                          5                       0.625000                    0.428571                  0.428571                        247.352113       494.704225               171819.431244       92.946597\n",
       " ..                       ...                            ...                         ...                       ...                               ...              ...                         ...             ...\n",
       " 406                        5                       0.151515                    0.468750                  0.343750                        479.482557       844.802600               177959.459803       44.009134\n",
       " 407                        4                       0.363636                    0.500000                  0.300000                        296.822535       471.871722                87640.218954       77.312741\n",
       " 408                        3                       1.000000                    0.000000                  1.500000                          0.000000         0.000000                    0.000000        0.000000\n",
       " 409                        5                       0.714286                    0.166667                  0.333333                         38.054171        53.275840                 2534.209900       14.238567\n",
       " 410                        3                       0.750000                    0.333333                  0.666667                        125.578765       133.189599                 5633.186578       42.413285\n",
       " 411                        2                       0.500000                    0.333333                  0.333333                         34.248754        49.470423                 3620.299858       20.688158\n",
       " \n",
       " [412 rows x 8 columns],\n",
       " 'long_RL':      longest_sequence_length  longest_sequence_length_ratio  direction_change_bin_ratio  congruent_dir_bins_ratio  total_congruent_direction_change  total_variation  integral_second_derivative  stddev_of_diff\n",
       " 0                          2                       1.000000                    0.000000                  1.000000                        114.162513       114.162513                0.000000e+00        0.000000\n",
       " 1                          5                       0.500000                    0.333333                  0.222222                        388.152546       570.812567                1.710809e+05       97.482741\n",
       " 2                          7                       0.500000                    0.230769                  0.307692                        327.265872       650.726327                2.860182e+05       91.054698\n",
       " 3                          4                       0.500000                    0.285714                  0.571429                        380.541712       551.785482                2.146693e+05      102.219980\n",
       " 4                          6                       0.222222                    0.576923                  0.384615                       1145.430552      2279.444853                1.017999e+06      119.815227\n",
       " 5                          4                       0.500000                    0.285714                  0.285714                        224.519610       319.655038                9.195562e+04       67.353228\n",
       " ..                       ...                            ...                         ...                       ...                               ...              ...                         ...             ...\n",
       " 406                        5                       0.151515                    0.437500                  0.312500                        624.088407      1076.933044                2.508578e+05       60.870762\n",
       " 407                        4                       0.363636                    0.500000                  0.600000                        213.103359       273.990032                3.821589e+04       34.079205\n",
       " 408                        3                       1.000000                    0.000000                  0.500000                          7.610834         7.610834                5.792480e+01        3.805417\n",
       " 409                        3                       0.428571                    0.333333                  0.333333                        182.660022       357.709209                9.493874e+04       85.421985\n",
       " 410                        4                       1.000000                    0.000000                  1.000000                         26.637920        26.637920                5.792480e+01        3.587782\n",
       " 411                        3                       0.750000                    0.333333                  0.333333                         22.832503        34.248754                1.694300e+03       14.238567\n",
       " \n",
       " [412 rows x 8 columns],\n",
       " 'short_LR':      longest_sequence_length  longest_sequence_length_ratio  direction_change_bin_ratio  congruent_dir_bins_ratio  total_congruent_direction_change  total_variation  integral_second_derivative  stddev_of_diff\n",
       " 0                          2                       1.000000                    0.000000                  1.000000                         11.416251        11.416251                    0.000000        0.000000\n",
       " 1                          4                       0.400000                    0.333333                  0.444444                        178.854604       277.795450                16001.725371       44.918969\n",
       " 2                          4                       0.285714                    0.384615                  0.384615                        437.622968       852.413434               304235.518837       97.438977\n",
       " 3                          2                       0.250000                    0.714286                  0.428571                        380.541712       643.115493               332662.113320      114.141802\n",
       " 4                          4                       0.148148                    0.423077                  0.384615                        528.952979       955.159696               240286.542152       58.397783\n",
       " 5                          6                       0.750000                    0.142857                  0.285714                        156.022102       312.044204                46614.980967       58.847901\n",
       " ..                       ...                            ...                         ...                       ...                               ...              ...                         ...             ...\n",
       " 406                        7                       0.212121                    0.468750                  0.312500                        898.078439      1788.546045               652479.402744       88.147672\n",
       " 407                        4                       0.363636                    0.500000                  0.400000                        197.881690       350.098375                41358.305574       44.404506\n",
       " 408                        3                       1.000000                    0.000000                  1.500000                          0.000000         0.000000                    0.000000        0.000000\n",
       " 409                        2                       0.285714                    0.500000                  0.333333                        232.130444       449.039220               143001.844377      100.289568\n",
       " 410                        4                       1.000000                    0.000000                  1.333333                          0.000000         0.000000                    0.000000        0.000000\n",
       " 411                        2                       0.500000                    0.333333                  0.666667                        175.049187       334.876706               137643.800588      135.162264\n",
       " \n",
       " [412 rows x 8 columns],\n",
       " 'short_RL':      longest_sequence_length  longest_sequence_length_ratio  direction_change_bin_ratio  congruent_dir_bins_ratio  total_congruent_direction_change  total_variation  integral_second_derivative  stddev_of_diff\n",
       " 0                          2                       1.000000                    0.000000                  1.000000                         26.637920        26.637920                    0.000000        0.000000\n",
       " 1                          3                       0.300000                    0.333333                  0.222222                        270.184615       460.455471               108710.364125       72.291797\n",
       " 2                          4                       0.285714                    0.461538                  0.384615                        547.980065       920.910942               305813.969575      101.328315\n",
       " 3                          3                       0.375000                    0.714286                  0.571429                        254.962947       399.568797               135341.289878       77.199433\n",
       " 4                          7                       0.259259                    0.384615                  0.346154                        570.812567      1042.684290               264151.558813       62.689511\n",
       " 5                          4                       0.500000                    0.285714                  0.428571                        190.270856       308.238786                79762.446464       66.153440\n",
       " ..                       ...                            ...                         ...                       ...                               ...              ...                         ...             ...\n",
       " 406                        7                       0.212121                    0.531250                  0.343750                       1095.960130      2100.590248               884395.811625       95.884052\n",
       " 407                        6                       0.545455                    0.400000                  0.300000                        258.768364       372.930877                53015.671115       52.696440\n",
       " 408                        3                       1.000000                    0.000000                  0.500000                          7.610834        11.416251                  130.330795        5.708126\n",
       " 409                        5                       0.714286                    0.166667                  0.500000                        178.854604       338.682123                56853.188965       78.432735\n",
       " 410                        4                       1.000000                    0.000000                  0.333333                         15.221668        19.027086                  246.180390        8.220641\n",
       " 411                        4                       1.000000                    0.000000                  0.666667                        171.243770       171.243770                47570.740129       72.801916\n",
       " \n",
       " [412 rows x 8 columns]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_out_new_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ba9f746",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected_outputs_path: \"K:\\scratch\\collected_outputs\"\n",
      "CURR_BATCH_OUTPUT_PREFIX: 2024-07-10_Apogee-2006-6-09_1-22-43\n",
      "\tComputation complete. Exporting .CSVs...\n",
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 136\n",
      "num_user_selected_times: 49\n",
      "adding user annotation column!\n",
      "\t succeded at getting 49 selected indicies (of 49 user selections) for ripple_weighted_corr_merged_df. got 49 indicies!\n",
      "num_valid_epoch_times: 136\n",
      "adding valid filtered epochs column!\n",
      "\t succeded at getting 136 selected indicies (of 136 valid filter epoch times) for ripple_weighted_corr_merged_df. got 136 indicies!\n",
      "num_user_selected_times: 49\n",
      "adding user annotation column!\n",
      "\t succeded at getting 49 selected indicies (of 49 user selections) for ripple_simple_pf_pearson_merged_df. got 49 indicies!\n",
      "num_valid_epoch_times: 136\n",
      "adding valid filtered epochs column!\n",
      "\t succeded at getting 136 selected indicies (of 136 valid filter epoch times) for ripple_simple_pf_pearson_merged_df. got 136 indicies!\n",
      "\t\tsuccessfully exported directional_decoders_epochs_decode_result to K:\\scratch\\collected_outputs!\n",
      "\t\t\tCSV Paths: laps_weighted_corr_merged_df: \"file:///K:/scratch/collected_outputs/2024-07-10_0630PM-kdiba_gor01_one_2006-6-09_1-22-43-%28laps_weighted_corr_merged_df%29_tbin-0.25.csv\"\n",
      "ripple_weighted_corr_merged_df: \"file:///K:/scratch/collected_outputs/2024-07-10_0630PM-kdiba_gor01_one_2006-6-09_1-22-43-%28ripple_weighted_corr_merged_df%29_tbin-0.025.csv\"\n",
      "laps_simple_pf_pearson_merged_df: \"file:///K:/scratch/collected_outputs/2024-07-10_0630PM-kdiba_gor01_one_2006-6-09_1-22-43-%28laps_simple_pf_pearson_merged_df%29_tbin-0.25.csv\"\n",
      "ripple_simple_pf_pearson_merged_df: \"file:///K:/scratch/collected_outputs/2024-07-10_0630PM-kdiba_gor01_one_2006-6-09_1-22-43-%28ripple_simple_pf_pearson_merged_df%29_tbin-0.025.csv\"\n",
      "ripple_all_scores_merged_df: \"file:///K:/scratch/collected_outputs/2024-07-10_0630PM-kdiba_gor01_one_2006-6-09_1-22-43-%28ripple_all_scores_merged_df%29_tbin-0.025.csv\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pathlib import Path\n",
    "\n",
    "# 💾 export_csvs\n",
    "\n",
    "# BATCH_DATE_TO_USE: str = f'{get_now_day_str()}_APOGEE' # TODO: Change this as needed, templating isn't actually doing anything rn.\n",
    "\n",
    "known_collected_outputs_paths = [Path(v).resolve() for v in ('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs', '/Users/pho/Dropbox (University of Michigan)/MED-DibaLabDropbox/Data/Pho/Outputs/output/collected_outputs', '/home/halechr/cloud/turbo/Data/Output/collected_outputs', '/home/halechr/FastData/gen_scripts/', '/home/halechr/FastData/collected_outputs/', 'output/gen_scripts/')]\n",
    "collected_outputs_path = find_first_extant_path(known_collected_outputs_paths)\n",
    "assert collected_outputs_path.exists(), f\"collected_outputs_path: '{collected_outputs_path}' does not exist! Is the right computer's config commented out above?\"\n",
    "print(f'collected_outputs_path: \"{collected_outputs_path}\"')\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline, track_templates=track_templates)\n",
    "print(f'\\tComputation complete. Exporting .CSVs...')\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "_, _, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "filtered_valid_epoch_times = filtered_epochs_df[['start', 'stop']].to_numpy()\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_output_csv_paths = directional_decoders_epochs_decode_result.export_csvs(parent_output_path=collected_outputs_path.resolve(), active_context=active_context, session_name=curr_session_name, curr_session_t_delta=t_delta,\n",
    "                                                                              user_annotation_selections={'ripple': any_good_selected_epoch_times},\n",
    "                                                                              valid_epochs_selections={'ripple': filtered_valid_epoch_times})\n",
    "\n",
    "print(f'\\t\\tsuccessfully exported directional_decoders_epochs_decode_result to {collected_outputs_path}!')\n",
    "_output_csv_paths_info_str: str = '\\n'.join([f'{a_name}: \"{file_uri_from_path(a_path)}\"' for a_name, a_path in _output_csv_paths.items()])\n",
    "# print(f'\\t\\t\\tCSV Paths: {_output_csv_paths}\\n')\n",
    "print(f'\\t\\t\\tCSV Paths: {_output_csv_paths_info_str}\\n')\n",
    "\n",
    "# {'laps_weighted_corr_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(laps_weighted_corr_merged_df)_tbin-0.025.csv'),\n",
    "#  'ripple_weighted_corr_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(ripple_weighted_corr_merged_df)_tbin-0.025.csv'),\n",
    "#  'laps_simple_pf_pearson_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(laps_simple_pf_pearson_merged_df)_tbin-0.025.csv'),\n",
    "#  'ripple_simple_pf_pearson_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(ripple_simple_pf_pearson_merged_df)_tbin-0.025.csv')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40b77273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_LR</th>\n",
       "      <th>P_RL</th>\n",
       "      <th>P_Long</th>\n",
       "      <th>P_Short</th>\n",
       "      <th>ripple_idx</th>\n",
       "      <th>ripple_start_t</th>\n",
       "      <th>P_Long_LR</th>\n",
       "      <th>P_Long_RL</th>\n",
       "      <th>P_Short_LR</th>\n",
       "      <th>P_Short_RL</th>\n",
       "      <th>most_likely_decoder_index</th>\n",
       "      <th>wcorr_long_LR</th>\n",
       "      <th>wcorr_long_RL</th>\n",
       "      <th>wcorr_short_LR</th>\n",
       "      <th>wcorr_short_RL</th>\n",
       "      <th>best_decoder_index</th>\n",
       "      <th>session_name</th>\n",
       "      <th>time_bin_size</th>\n",
       "      <th>delta_aligned_start_t</th>\n",
       "      <th>is_user_annotated_epoch</th>\n",
       "      <th>is_valid_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.377521e-03</td>\n",
       "      <td>0.996622</td>\n",
       "      <td>0.968932</td>\n",
       "      <td>0.031068</td>\n",
       "      <td>0</td>\n",
       "      <td>42.658077</td>\n",
       "      <td>3.272587e-03</td>\n",
       "      <td>0.965659</td>\n",
       "      <td>1.049340e-04</td>\n",
       "      <td>0.030963</td>\n",
       "      <td>1</td>\n",
       "      <td>0.724297</td>\n",
       "      <td>-0.515537</td>\n",
       "      <td>0.294705</td>\n",
       "      <td>-0.476819</td>\n",
       "      <td>0</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-986.658531</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.847150e-01</td>\n",
       "      <td>0.315285</td>\n",
       "      <td>0.480394</td>\n",
       "      <td>0.519606</td>\n",
       "      <td>1</td>\n",
       "      <td>55.723809</td>\n",
       "      <td>3.289331e-01</td>\n",
       "      <td>0.151461</td>\n",
       "      <td>3.557819e-01</td>\n",
       "      <td>0.163824</td>\n",
       "      <td>2</td>\n",
       "      <td>0.173317</td>\n",
       "      <td>-0.141276</td>\n",
       "      <td>0.093641</td>\n",
       "      <td>-0.079061</td>\n",
       "      <td>0</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-973.592800</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.354488e-01</td>\n",
       "      <td>0.464551</td>\n",
       "      <td>0.609787</td>\n",
       "      <td>0.390213</td>\n",
       "      <td>2</td>\n",
       "      <td>73.681176</td>\n",
       "      <td>3.265097e-01</td>\n",
       "      <td>0.283277</td>\n",
       "      <td>2.089391e-01</td>\n",
       "      <td>0.181274</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.107942</td>\n",
       "      <td>-0.357459</td>\n",
       "      <td>-0.116484</td>\n",
       "      <td>-0.276164</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-955.635433</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.904791e-01</td>\n",
       "      <td>0.609521</td>\n",
       "      <td>0.560678</td>\n",
       "      <td>0.439322</td>\n",
       "      <td>3</td>\n",
       "      <td>92.642502</td>\n",
       "      <td>2.189331e-01</td>\n",
       "      <td>0.341745</td>\n",
       "      <td>1.715460e-01</td>\n",
       "      <td>0.267776</td>\n",
       "      <td>1</td>\n",
       "      <td>0.746645</td>\n",
       "      <td>0.768491</td>\n",
       "      <td>0.588003</td>\n",
       "      <td>0.641184</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-936.674106</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.549793e-01</td>\n",
       "      <td>0.445021</td>\n",
       "      <td>0.507392</td>\n",
       "      <td>0.492608</td>\n",
       "      <td>4</td>\n",
       "      <td>93.027055</td>\n",
       "      <td>2.815918e-01</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>2.733875e-01</td>\n",
       "      <td>0.219221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.507870</td>\n",
       "      <td>0.496553</td>\n",
       "      <td>0.392682</td>\n",
       "      <td>0.377063</td>\n",
       "      <td>0</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-936.289554</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.733433e-01</td>\n",
       "      <td>0.526657</td>\n",
       "      <td>0.258256</td>\n",
       "      <td>0.741744</td>\n",
       "      <td>5</td>\n",
       "      <td>93.925000</td>\n",
       "      <td>1.222436e-01</td>\n",
       "      <td>0.136012</td>\n",
       "      <td>3.510997e-01</td>\n",
       "      <td>0.390645</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.031149</td>\n",
       "      <td>0.226862</td>\n",
       "      <td>-0.026678</td>\n",
       "      <td>0.216318</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-935.391609</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>6.223742e-01</td>\n",
       "      <td>0.377626</td>\n",
       "      <td>0.372064</td>\n",
       "      <td>0.627936</td>\n",
       "      <td>406</td>\n",
       "      <td>1729.689083</td>\n",
       "      <td>2.315630e-01</td>\n",
       "      <td>0.140501</td>\n",
       "      <td>3.908112e-01</td>\n",
       "      <td>0.237125</td>\n",
       "      <td>2</td>\n",
       "      <td>0.114463</td>\n",
       "      <td>0.303952</td>\n",
       "      <td>0.126077</td>\n",
       "      <td>0.183958</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>700.372474</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2.263085e-01</td>\n",
       "      <td>0.773692</td>\n",
       "      <td>0.301660</td>\n",
       "      <td>0.698340</td>\n",
       "      <td>407</td>\n",
       "      <td>1731.111480</td>\n",
       "      <td>6.826824e-02</td>\n",
       "      <td>0.233392</td>\n",
       "      <td>1.580403e-01</td>\n",
       "      <td>0.540300</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.279661</td>\n",
       "      <td>-0.580664</td>\n",
       "      <td>-0.052965</td>\n",
       "      <td>-0.295598</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>701.794871</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>7.050154e-07</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.580727</td>\n",
       "      <td>0.419273</td>\n",
       "      <td>408</td>\n",
       "      <td>1731.789992</td>\n",
       "      <td>4.094216e-07</td>\n",
       "      <td>0.580727</td>\n",
       "      <td>2.955938e-07</td>\n",
       "      <td>0.419272</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.023507</td>\n",
       "      <td>-0.126635</td>\n",
       "      <td>0.145074</td>\n",
       "      <td>0.227193</td>\n",
       "      <td>3</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>702.473383</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>5.131128e-01</td>\n",
       "      <td>0.486887</td>\n",
       "      <td>0.320867</td>\n",
       "      <td>0.679133</td>\n",
       "      <td>409</td>\n",
       "      <td>1733.729959</td>\n",
       "      <td>1.646410e-01</td>\n",
       "      <td>0.156226</td>\n",
       "      <td>3.484718e-01</td>\n",
       "      <td>0.330661</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011708</td>\n",
       "      <td>0.352614</td>\n",
       "      <td>0.134870</td>\n",
       "      <td>0.155268</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>704.413350</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>3.099668e-01</td>\n",
       "      <td>0.690033</td>\n",
       "      <td>0.304357</td>\n",
       "      <td>0.695643</td>\n",
       "      <td>410</td>\n",
       "      <td>1734.961032</td>\n",
       "      <td>9.434053e-02</td>\n",
       "      <td>0.210016</td>\n",
       "      <td>2.156263e-01</td>\n",
       "      <td>0.480017</td>\n",
       "      <td>3</td>\n",
       "      <td>0.698387</td>\n",
       "      <td>0.681143</td>\n",
       "      <td>0.049096</td>\n",
       "      <td>-0.438151</td>\n",
       "      <td>0</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>705.644423</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>4.793921e-01</td>\n",
       "      <td>0.520608</td>\n",
       "      <td>0.718233</td>\n",
       "      <td>0.281767</td>\n",
       "      <td>411</td>\n",
       "      <td>1736.892796</td>\n",
       "      <td>3.443152e-01</td>\n",
       "      <td>0.373918</td>\n",
       "      <td>1.350768e-01</td>\n",
       "      <td>0.146690</td>\n",
       "      <td>1</td>\n",
       "      <td>0.269368</td>\n",
       "      <td>0.589224</td>\n",
       "      <td>0.211011</td>\n",
       "      <td>0.431967</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>707.576188</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             P_LR      P_RL    P_Long   P_Short  ripple_idx  ripple_start_t     P_Long_LR  P_Long_RL    P_Short_LR  P_Short_RL  most_likely_decoder_index  wcorr_long_LR  wcorr_long_RL  wcorr_short_LR  wcorr_short_RL  best_decoder_index       session_name  time_bin_size  delta_aligned_start_t  is_user_annotated_epoch  is_valid_epoch\n",
       "0    3.377521e-03  0.996622  0.968932  0.031068           0       42.658077  3.272587e-03   0.965659  1.049340e-04    0.030963                          1       0.724297      -0.515537        0.294705       -0.476819                   0  2006-6-09_1-22-43          0.025            -986.658531                    False           False\n",
       "1    6.847150e-01  0.315285  0.480394  0.519606           1       55.723809  3.289331e-01   0.151461  3.557819e-01    0.163824                          2       0.173317      -0.141276        0.093641       -0.079061                   0  2006-6-09_1-22-43          0.025            -973.592800                    False           False\n",
       "2    5.354488e-01  0.464551  0.609787  0.390213           2       73.681176  3.265097e-01   0.283277  2.089391e-01    0.181274                          0      -0.107942      -0.357459       -0.116484       -0.276164                   1  2006-6-09_1-22-43          0.025            -955.635433                    False           False\n",
       "3    3.904791e-01  0.609521  0.560678  0.439322           3       92.642502  2.189331e-01   0.341745  1.715460e-01    0.267776                          1       0.746645       0.768491        0.588003        0.641184                   1  2006-6-09_1-22-43          0.025            -936.674106                    False           False\n",
       "4    5.549793e-01  0.445021  0.507392  0.492608           4       93.027055  2.815918e-01   0.225800  2.733875e-01    0.219221                          0       0.507870       0.496553        0.392682        0.377063                   0  2006-6-09_1-22-43          0.025            -936.289554                    False            True\n",
       "5    4.733433e-01  0.526657  0.258256  0.741744           5       93.925000  1.222436e-01   0.136012  3.510997e-01    0.390645                          3      -0.031149       0.226862       -0.026678        0.216318                   1  2006-6-09_1-22-43          0.025            -935.391609                    False           False\n",
       "..            ...       ...       ...       ...         ...             ...           ...        ...           ...         ...                        ...            ...            ...             ...             ...                 ...                ...            ...                    ...                      ...             ...\n",
       "406  6.223742e-01  0.377626  0.372064  0.627936         406     1729.689083  2.315630e-01   0.140501  3.908112e-01    0.237125                          2       0.114463       0.303952        0.126077        0.183958                   1  2006-6-09_1-22-43          0.025             700.372474                    False            True\n",
       "407  2.263085e-01  0.773692  0.301660  0.698340         407     1731.111480  6.826824e-02   0.233392  1.580403e-01    0.540300                          3      -0.279661      -0.580664       -0.052965       -0.295598                   1  2006-6-09_1-22-43          0.025             701.794871                     True            True\n",
       "408  7.050154e-07  0.999999  0.580727  0.419273         408     1731.789992  4.094216e-07   0.580727  2.955938e-07    0.419272                          1      -0.023507      -0.126635        0.145074        0.227193                   3  2006-6-09_1-22-43          0.025             702.473383                    False           False\n",
       "409  5.131128e-01  0.486887  0.320867  0.679133         409     1733.729959  1.646410e-01   0.156226  3.484718e-01    0.330661                          2       0.011708       0.352614        0.134870        0.155268                   1  2006-6-09_1-22-43          0.025             704.413350                    False           False\n",
       "410  3.099668e-01  0.690033  0.304357  0.695643         410     1734.961032  9.434053e-02   0.210016  2.156263e-01    0.480017                          3       0.698387       0.681143        0.049096       -0.438151                   0  2006-6-09_1-22-43          0.025             705.644423                    False           False\n",
       "411  4.793921e-01  0.520608  0.718233  0.281767         411     1736.892796  3.443152e-01   0.373918  1.350768e-01    0.146690                          1       0.269368       0.589224        0.211011        0.431967                   1  2006-6-09_1-22-43          0.025             707.576188                    False           False\n",
       "\n",
       "[412 rows x 21 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0661fcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "      <th>end</th>\n",
       "      <th>n_unique_aclus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.027055</td>\n",
       "      <td>93.465245</td>\n",
       "      <td>4</td>\n",
       "      <td>0.438190</td>\n",
       "      <td>93.465245</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.400143</td>\n",
       "      <td>105.562560</td>\n",
       "      <td>8</td>\n",
       "      <td>0.162417</td>\n",
       "      <td>105.562560</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113.213433</td>\n",
       "      <td>113.613960</td>\n",
       "      <td>9</td>\n",
       "      <td>0.400527</td>\n",
       "      <td>113.613960</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120.645089</td>\n",
       "      <td>120.861972</td>\n",
       "      <td>11</td>\n",
       "      <td>0.216883</td>\n",
       "      <td>120.861972</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.060134</td>\n",
       "      <td>125.209802</td>\n",
       "      <td>14</td>\n",
       "      <td>0.149668</td>\n",
       "      <td>125.209802</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>132.511389</td>\n",
       "      <td>132.791003</td>\n",
       "      <td>17</td>\n",
       "      <td>0.279613</td>\n",
       "      <td>132.791003</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1705.053099</td>\n",
       "      <td>1705.140866</td>\n",
       "      <td>405</td>\n",
       "      <td>0.087767</td>\n",
       "      <td>1705.140866</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1707.712068</td>\n",
       "      <td>1707.918998</td>\n",
       "      <td>406</td>\n",
       "      <td>0.206930</td>\n",
       "      <td>1707.918998</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1714.307771</td>\n",
       "      <td>1714.651681</td>\n",
       "      <td>409</td>\n",
       "      <td>0.343910</td>\n",
       "      <td>1714.651681</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1725.278891</td>\n",
       "      <td>1725.595092</td>\n",
       "      <td>414</td>\n",
       "      <td>0.316201</td>\n",
       "      <td>1725.595092</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1729.689083</td>\n",
       "      <td>1730.227666</td>\n",
       "      <td>417</td>\n",
       "      <td>0.538583</td>\n",
       "      <td>1730.227666</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1731.111480</td>\n",
       "      <td>1731.287905</td>\n",
       "      <td>418</td>\n",
       "      <td>0.176425</td>\n",
       "      <td>1731.287905</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           start         stop  label  duration          end  n_unique_aclus\n",
       "0      93.027055    93.465245      4  0.438190    93.465245              31\n",
       "1     105.400143   105.562560      8  0.162417   105.562560              26\n",
       "2     113.213433   113.613960      9  0.400527   113.613960              19\n",
       "3     120.645089   120.861972     11  0.216883   120.861972              26\n",
       "4     125.060134   125.209802     14  0.149668   125.209802              26\n",
       "5     132.511389   132.791003     17  0.279613   132.791003              33\n",
       "..           ...          ...    ...       ...          ...             ...\n",
       "130  1705.053099  1705.140866    405  0.087767  1705.140866              18\n",
       "131  1707.712068  1707.918998    406  0.206930  1707.918998              24\n",
       "132  1714.307771  1714.651681    409  0.343910  1714.651681              22\n",
       "133  1725.278891  1725.595092    414  0.316201  1725.595092              30\n",
       "134  1729.689083  1730.227666    417  0.538583  1730.227666              36\n",
       "135  1731.111480  1731.287905    418  0.176425  1731.287905              21\n",
       "\n",
       "[136 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88335249",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_good_selected_epoch_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7420982",
   "metadata": {},
   "source": [
    "# 2024-03-04 - Filter out the epochs based on the criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4dcb021f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 136\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "      <th>end</th>\n",
       "      <th>n_unique_aclus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.027055</td>\n",
       "      <td>93.465245</td>\n",
       "      <td>4</td>\n",
       "      <td>0.438190</td>\n",
       "      <td>93.465245</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.400143</td>\n",
       "      <td>105.562560</td>\n",
       "      <td>8</td>\n",
       "      <td>0.162417</td>\n",
       "      <td>105.562560</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113.213433</td>\n",
       "      <td>113.613960</td>\n",
       "      <td>9</td>\n",
       "      <td>0.400527</td>\n",
       "      <td>113.613960</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120.645089</td>\n",
       "      <td>120.861972</td>\n",
       "      <td>11</td>\n",
       "      <td>0.216883</td>\n",
       "      <td>120.861972</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.060134</td>\n",
       "      <td>125.209802</td>\n",
       "      <td>14</td>\n",
       "      <td>0.149668</td>\n",
       "      <td>125.209802</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>132.511389</td>\n",
       "      <td>132.791003</td>\n",
       "      <td>17</td>\n",
       "      <td>0.279613</td>\n",
       "      <td>132.791003</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1705.053099</td>\n",
       "      <td>1705.140866</td>\n",
       "      <td>405</td>\n",
       "      <td>0.087767</td>\n",
       "      <td>1705.140866</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1707.712068</td>\n",
       "      <td>1707.918998</td>\n",
       "      <td>406</td>\n",
       "      <td>0.206930</td>\n",
       "      <td>1707.918998</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1714.307771</td>\n",
       "      <td>1714.651681</td>\n",
       "      <td>409</td>\n",
       "      <td>0.343910</td>\n",
       "      <td>1714.651681</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1725.278891</td>\n",
       "      <td>1725.595092</td>\n",
       "      <td>414</td>\n",
       "      <td>0.316201</td>\n",
       "      <td>1725.595092</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1729.689083</td>\n",
       "      <td>1730.227666</td>\n",
       "      <td>417</td>\n",
       "      <td>0.538583</td>\n",
       "      <td>1730.227666</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1731.111480</td>\n",
       "      <td>1731.287905</td>\n",
       "      <td>418</td>\n",
       "      <td>0.176425</td>\n",
       "      <td>1731.287905</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           start         stop  label  duration          end  n_unique_aclus\n",
       "0      93.027055    93.465245      4  0.438190    93.465245              31\n",
       "1     105.400143   105.562560      8  0.162417   105.562560              26\n",
       "2     113.213433   113.613960      9  0.400527   113.613960              19\n",
       "3     120.645089   120.861972     11  0.216883   120.861972              26\n",
       "4     125.060134   125.209802     14  0.149668   125.209802              26\n",
       "5     132.511389   132.791003     17  0.279613   132.791003              33\n",
       "..           ...          ...    ...       ...          ...             ...\n",
       "130  1705.053099  1705.140866    405  0.087767  1705.140866              18\n",
       "131  1707.712068  1707.918998    406  0.206930  1707.918998              24\n",
       "132  1714.307771  1714.651681    409  0.343910  1714.651681              22\n",
       "133  1725.278891  1725.595092    414  0.316201  1725.595092              30\n",
       "134  1729.689083  1730.227666    417  0.538583  1730.227666              36\n",
       "135  1731.111480  1731.287905    418  0.176425  1731.287905              21\n",
       "\n",
       "[136 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from neuropy.utils.mixins.time_slicing import add_epochs_id_identity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, required_min_percentage_of_active_cells=0.333333, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "filtered_epochs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68233f",
   "metadata": {},
   "source": [
    "# 2024-03-27 - Look at active set cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.HDF5_representable import HDFConvertableEnum\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import TruncationCheckingResults\n",
    "\n",
    "\n",
    "## long_short_endcap_analysis:\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "truncation_checking_aclus_dict, jonathan_firing_rate_analysis_result.neuron_replay_stats_df = truncation_checking_result.build_truncation_checking_aclus_dict(neuron_replay_stats_df=jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "\n",
    "frs_index_inclusion_magnitude:float = 0.5\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "\n",
    "## Unrefined:\n",
    "# neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=frs_index_inclusion_magnitude)\n",
    "\n",
    "## Refine the LxC/SxC designators using the firing rate index metric:\n",
    "\n",
    "## Get global `long_short_fr_indicies_analysis`:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_short_fr_indicies_df = long_short_fr_indicies_analysis_results['long_short_fr_indicies_df']\n",
    "jonathan_firing_rate_analysis_result.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=frs_index_inclusion_magnitude)\n",
    "\n",
    "neuron_replay_stats_df, *exclusivity_tuple = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=frs_index_inclusion_magnitude)\n",
    "# short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = exclusivity_tuple\n",
    "exclusivity_aclus_tuple = [v.track_exclusive_aclus for v in exclusivity_tuple]\n",
    "exclusivity_aclus_dict = dict(zip(['short_exclusive', 'long_exclusive', 'BOTH', 'EITHER', 'XOR', 'NEITHER'], exclusivity_aclus_tuple))\n",
    "any_aclus = union_of_arrays(*exclusivity_aclus_tuple)\n",
    "exclusivity_aclus_dict['any'] = any_aclus\n",
    "refined_exclusivity_aclus_tuple = [v.get_refined_track_exclusive_aclus() for v in exclusivity_tuple]\n",
    "neuron_replay_stats_df: pd.DataFrame = HDFConvertableEnum.convert_dataframe_columns_for_hdf(neuron_replay_stats_df)\n",
    "\n",
    "# These keys exhaustively span all aclus:\n",
    "exhaustive_key_names = ['short_exclusive', 'long_exclusive', 'BOTH', 'NEITHER']\n",
    "assert np.all(any_aclus == union_of_arrays(*[exclusivity_aclus_dict[k] for k in exhaustive_key_names]))\n",
    "exhaustive_key_dict = {k:v for k, v in exclusivity_aclus_dict.items() if k in exhaustive_key_names}\n",
    "\n",
    "\n",
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_any_aclus = np.array([  3,   4,   5,   7,  10,  11,  13,  14,  15,  17,  23,  24,  25,  26,  31,  32,  33,  34,  45,  49,  50,  51,  52,  54,  55,  58,  61,  64,  68,  69,  70,  71,  73,  74,  75,  76,  78,  81,  82,  83,  84,  85,  87,  90,  92,  93,  96,  97, 102, 109])\n",
    "old_appearing_aclus = np.array([ 4, 11, 13, 23, 52, 58, 87])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af361ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_aclus = union_of_arrays(*[v for v in truncation_checking_aclus_dict.values() if len(v) > 0])\n",
    "any_aclus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2385b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520650ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.analyses.placefields import PfND\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import perform_sweep_lap_groud_truth_performance_testing, _perform_variable_time_bin_lap_groud_truth_performance_testing\n",
    "\n",
    "desired_laps_decoding_time_bin_size: float = 0.75\n",
    "\n",
    "## INPUTS: exclusivity_aclus_tuple, desired_laps_decoding_time_bin_size: float\n",
    "# short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = exclusivity_aclus_tuple\n",
    "# included_neuron_ids_list = [short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset]\n",
    "\n",
    "# included_neuron_ids_list = [*exclusivity_aclus_tuple]\n",
    "\n",
    "## INPUTS: truncation_checking_aclus_dict\n",
    "included_neuron_ids_list = list(truncation_checking_aclus_dict.values())\n",
    "row_names = list(truncation_checking_aclus_dict.keys())\n",
    "\n",
    "_output_tuples_list = perform_sweep_lap_groud_truth_performance_testing(curr_active_pipeline, \n",
    "                                                                        included_neuron_ids_list=included_neuron_ids_list,\n",
    "                                                                        desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_size)\n",
    "\n",
    "percent_laps_correctness_df: pd.DataFrame = pd.DataFrame.from_records([complete_decoded_context_correctness_tuple.percent_correct_tuple for (a_directional_merged_decoders_result, result_laps_epochs_df, complete_decoded_context_correctness_tuple) in _output_tuples_list],\n",
    "                          columns=(\"track_ID_correct\", \"dir_correct\", \"complete_correct\"), index=row_names)\n",
    "percent_laps_correctness_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb00384",
   "metadata": {},
   "source": [
    "# 2024-03-29 - Rigorous Decoder Performance assessment\n",
    "Quantify cell contributions to decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9715a6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Inputs: all_directional_pf1D_Decoder, alt_directional_merged_decoders_result\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrainTestLapsSplitting, CustomDecodeEpochsResult, decoder_name, epoch_split_key, get_proper_global_spikes_df\n",
    "\n",
    "## INPUTS: directional_laps_results, track_templates, directional_laps_results\n",
    "\n",
    "## Split the lap epochs into training and test periods.\n",
    "##### Ideally we could test the lap decoding error by sampling randomly from the time bins and omitting 1/6 of time bins from the placefield building (effectively the training data). These missing bins will be used as the \"test data\" and the decoding error will be computed by decoding them and subtracting the actual measured position during these bins.\n",
    "\n",
    "# ### Get the laps to train on\n",
    "# training_data_portion: float = 9.0/10.0\n",
    "# test_data_portion: float = 1.0 - training_data_portion # test data portion is 1/6 of the total duration\n",
    "# print(f'training_data_portion: {training_data_portion}, test_data_portion: {test_data_portion}')\n",
    "\n",
    "# decoders_dict = deepcopy(track_templates.get_decoders_dict())\n",
    "\n",
    "# # debug_output_hdf5_file_path = Path('output', 'laps_train_test_split.h5').resolve()\n",
    "# debug_output_hdf5_file_path = None\n",
    "\n",
    "# # (train_epochs_dict, test_epochs_dict), train_lap_specific_pf1D_Decoder_dict, split_train_test_lap_specific_configs = TrainTestLapsSplitting.compute_train_test_split_laps_decoders(directional_laps_results, track_templates, training_data_portion=training_data_portion,\n",
    "# #                                                                                                                                                              debug_output_hdf5_file_path=debug_output_hdf5_file_path, debug_plot=False, debug_print=True)  # type: Tuple[Tuple[Dict[str, Any], Dict[str, Any]], Dict[str, BasePositionDecoder], Any]\n",
    "\n",
    "# train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = train_lap_specific_pf1D_Decoder_dict\n",
    "\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrainTestSplitResult\n",
    "\n",
    "directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data.get('TrainTestSplit', None)\n",
    "\n",
    "training_data_portion: float = directional_train_test_split_result.training_data_portion\n",
    "test_data_portion: float = directional_train_test_split_result.test_data_portion\n",
    "print(f'training_data_portion: {training_data_portion}, test_data_portion: {test_data_portion}')\n",
    "\n",
    "test_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.test_epochs_dict\n",
    "train_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.train_epochs_dict\n",
    "train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_train_test_split_result.train_lap_specific_pf1D_Decoder_dict\n",
    "\n",
    "\n",
    "# Tuple[Tuple[Dict, Dict], Dict[str, BasePositionDecoder], Dict]\n",
    "\n",
    "# OUTPUTS: train_test_split_laps_df_dict\n",
    "\n",
    "# ## Get test epochs:\n",
    "# train_epoch_names: List[str] = [k for k in train_test_split_laps_df_dict.keys() if k.endswith('_train')]\n",
    "# test_epoch_names: List[str] = [k for k in train_test_split_laps_df_dict.keys() if k.endswith('_test')]\n",
    "# train_lap_specific_pf1D_Decoder_dict: Dict[str,BasePositionDecoder] = {k.split('_train', maxsplit=1)[0]:split_train_test_lap_specific_pf1D_Decoder_dict[k] for k in train_epoch_names} # the `k.split('_train', maxsplit=1)[0]` part just gets the original key like 'long_LR'\n",
    "# test_epochs_dict: Dict[str,Epoch] = {k.split('_test', maxsplit=1)[0]:v for k,v in train_test_split_laps_epoch_obj_dict.items() if k.endswith('_test')} # the `k.split('_test', maxsplit=1)[0]` part just gets the original key like 'long_LR'\n",
    "\n",
    "# a_training_test_split_laps_epoch_obj_dict[a_training_test_names[0]].to_hdf('output/laps_train_test_split.h5', f'{a_train_epoch_name}/laps_training_df')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d0456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _do_custom_decode_epochs_dict\n",
    "\n",
    "active_laps_decoding_time_bin_size: float = 0.75\n",
    "\n",
    "global_spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe()).dropna(subset=['lap']) # computation_result.sess.position.to_dataframe()\n",
    "\n",
    "# Dict[epoch_split_key, Dict[decoder_name, CustomDecodeEpochsResult]]\n",
    "\n",
    "## INPUTS: flat_epochs_to_decode_dict, active_laps_decoding_time_bin_size\n",
    "## Decoding of the test epochs (what matters):\n",
    "test_decoder_results_dict: Dict[decoder_name, CustomDecodeEpochsResult] = _do_custom_decode_epochs_dict(global_spikes_df=global_spikes_df, global_measured_position_df=global_measured_position_df,\n",
    "                                                                                                                                 pf1D_Decoder_dict=train_lap_specific_pf1D_Decoder_dict,\n",
    "                                                                                                                                 epochs_to_decode_dict=test_epochs_dict, \n",
    "                                                                                                                                 decoding_time_bin_size=active_laps_decoding_time_bin_size,\n",
    "                                                                                                                                 decoder_and_epoch_keys_independent=False)\n",
    "\n",
    "\n",
    "# flat_epochs_to_decode_dict = {f'{k}_train':v for k,v in train_epochs_dict.items()} | {f'{k}_test':v for k,v in test_epochs_dict.items()} # (train_epochs_dict, test_epochs_dict)\n",
    "# final_decoder_results_dict: Dict[epoch_split_key, Dict[decoder_name, CustomDecodeEpochsResult]] = _do_custom_decode_epochs_dict(curr_active_pipeline,\n",
    "#                                                                                                                                  pf1D_Decoder_dict=train_lap_specific_pf1D_Decoder_dict,\n",
    "#                                                                                                                                  epochs_to_decode_dict=flat_epochs_to_decode_dict,\n",
    "#                                                                                                                                  decoding_time_bin_size=active_laps_decoding_time_bin_size,\n",
    "#                                                                                                                                  decoder_and_epoch_keys_independent=True) # epochs_to_decode_dict.keys(): ['long_LR_train', 'long_RL_train', 'short_LR_train', 'short_RL_train', 'long_LR_test', 'long_RL_test', 'short_LR_test', 'short_RL_test']\n",
    "# matched_decoder_epochs_final_decoder_results_dict: Dict[decoder_name, CustomDecodeEpochsResult] = {k:v[k.replace('_train', '').replace('_test', '')] for k, v in final_decoder_results_dict.items()} # flatten down to only the matching decoder\n",
    "# matched_decoder_epochs_final_decoder_results_dict\n",
    "# print(list(matched_decoder_epochs_final_decoder_results_dict.keys())) # ['long_LR_train', 'long_RL_train', 'short_LR_train', 'short_RL_train', 'long_LR_test', 'long_RL_test', 'short_LR_test', 'short_RL_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e034df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import compute_weighted_correlations\n",
    "\n",
    "train_decoded_results_dict: Dict[str, DecodedFilterEpochsResult] = {k:v.decoder_result for k, v in test_decoder_results_dict.items()}\n",
    "\n",
    "weighted_corr_data_dict = compute_weighted_correlations(train_decoded_results_dict, debug_print=True)\n",
    "weighted_corr_data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a3a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_decoded_wcorr_df = pd.concat(weighted_corr_data_dict)\n",
    "train_decoded_wcorr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result.p_x_given_n_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f1a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_decoded_measured_diff_df: pd.DataFrame = test_decoder_results_dict['long_LR'].measured_decoded_position_comparion.decoded_measured_diff_df\n",
    "\n",
    "\n",
    "train_decoded_measured_diff_df_dict: Dict[str, pd.DataFrame] = {k:v.measured_decoded_position_comparion.decoded_measured_diff_df for k, v in test_decoder_results_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce176e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import pho_jointplot\n",
    "import seaborn as sns\n",
    "\n",
    "plot_key: str = 'err_cm'\n",
    "\n",
    "# Plot each list as a separate time series\n",
    "plt.figure(figsize=(10, 6))\n",
    "for key, value in train_decoded_measured_diff_df_dict.items():\n",
    "    # sns.lineplot(x=range(len(value)), y=value, label=key)\n",
    "    _out_line = sns.lineplot(data=value, x='t', y=plot_key, label=key)\n",
    "    _out_scatter = sns.scatterplot(data=value, x='t', y=plot_key) # no `, label=key` because we only want one entry in the legend\n",
    "\n",
    "plt.xlabel('lap_center_t (sec)')\n",
    "plt.ylabel('mean_error [cm]')\n",
    "plt.title('LAp Decoding Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10117f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epochs_dict = {k:Epoch(ensure_dataframe(v.measured_decoded_position_comparion.decoded_measured_diff_df)) for k, v in test_decoder_results_dict.items()}\n",
    "active_epochs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epochs_dict = {k:Epoch(ensure_dataframe(v)) for k, v in train_decoded_measured_diff_df_dict.items()}\n",
    "active_epochs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8f168",
   "metadata": {},
   "source": [
    "# 2024-04-03 - Time-bin effect on lap decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea00ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import make_class\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function\n",
    "\n",
    "return_full_decoding_results: bool = True\n",
    "desired_laps_decoding_time_bin_size = np.linspace(start=0.030, stop=1.0, num=4)\n",
    "\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, False)\n",
    "custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_size,\n",
    "                                                                        use_single_time_bin_per_epoch=[False],\n",
    "                                                                        minimum_event_duration=[desired_laps_decoding_time_bin_size[-1]])\n",
    "\n",
    "\n",
    "_across_session_results_extended_dict = {}\n",
    "## Combine the output of `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tacross_session_results_extended_dict=_across_session_results_extended_dict, return_full_decoding_results=return_full_decoding_results,\n",
    "                                                save_hdf=True, save_csvs=True,\n",
    "                                                # desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=4),\n",
    "                                                custom_all_param_sweep_options=custom_all_param_sweep_options, # directly provide the parameter sweeps\n",
    "                                                )\n",
    "if return_full_decoding_results:\n",
    "    # with `return_full_decoding_results == True`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_full_directional_merged_decoders_result = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    # validate the result:\n",
    "    # {k:v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size for k,v in output_full_directional_merged_decoders_result.items()}\n",
    "    # assert np.all([np.isclose(dict(k)['desired_shared_decoding_time_bin_size'], v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size) for k,v in output_full_directional_merged_decoders_result.items()]), f\"the desired time_bin_size in the parameters should match the one used that will appear in the decoded result\"\n",
    "\n",
    "\n",
    "else:\n",
    "    # with `return_full_decoding_results == False`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    output_full_directional_merged_decoders_result = None\n",
    "\n",
    "(several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da04be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d97fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _show_sweep_result\n",
    "\n",
    "## INPUTS: output_full_directional_merged_decoders_result\n",
    "\n",
    "\n",
    "## RUN\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe()).dropna(subset=['lap']) # computation_result.sess.position.to_dataframe()\n",
    "# sweep_key_name: str=\"desired_shared_decoding_time_bin_size\"\n",
    "sweep_key_name: str=\"desired_laps_decoding_time_bin_size\"\n",
    "_out_pagination_controller, (all_swept_measured_positions_dfs_dict, all_swept_decoded_positions_df_dict, all_swept_decoded_measured_diff_df_dict) = _show_sweep_result(output_full_directional_merged_decoders_result, global_measured_position_df=global_measured_position_df,\n",
    "                                                                                                                                                        xbin=long_results_obj.original_1D_decoder.xbin,\n",
    "                                                                                                                                                        active_context=curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='laps', decoder='all_dir'),\n",
    "                                                                                                                                                        sweep_params_idx=2, sweep_key_name=sweep_key_name, max_subplots_per_page=4)\n",
    "# _out_pagination_controller\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed630cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_laps_decoding_time_bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e8f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Context Mask - provides additional information about an Identifying context, like whether a certain component of it should print:\n",
    "# has tags like 'print_debug', 'print_session', 'print_across_sessions'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import CustomDecodeEpochsResult\n",
    "\n",
    "\n",
    "## INPUTS: output_full_directional_merged_decoders_result\n",
    "\n",
    "# Interpolated measured position DataFrame - looks good\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe()).dropna(subset=['lap']) # computation_result.sess.position.to_dataframe()\n",
    "all_swept_measured_positions_dfs_dict, all_swept_decoded_positions_df_dict, all_swept_decoded_measured_diff_df_dict = CustomDecodeEpochsResult.build_measured_decoded_position_comparison({k:deepcopy(v.all_directional_laps_filter_epochs_decoder_result) for k, v in output_full_directional_merged_decoders_result.items()}, global_measured_position_df=global_measured_position_df)\n",
    "# all_swept_decoded_measured_diff_df_dict = {k:pd.DataFrame(v, columns=['t', 'err']) for k, v in all_swept_decoded_measured_diff_df_dict.items()}\n",
    "\n",
    "# global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe()).dropna(subset=['lap']) # computation_result.sess.position.to_dataframe()\n",
    "# test_measured_positions_dfs_dict, test_decoded_positions_df_dict, test_decoded_measured_diff_df_dict = CustomDecodeEpochsResult.build_measured_decoded_position_comparison(test_laps_decoder_results_dict, global_measured_position_df=global_measured_position_df)\n",
    "# train_measured_positions_dfs_dict, train_decoded_positions_df_dict, train_decoded_measured_diff_df_dict = CustomDecodeEpochsResult.build_measured_decoded_position_comparison(train_laps_decoder_results_dict, global_measured_position_df=global_measured_position_df)\n",
    "\n",
    "\n",
    "## OUTPUTS: all_swept_measured_positions_dfs_dict, all_swept_decoded_positions_df_dict, all_swept_decoded_measured_diff_df_dict\n",
    "all_swept_decoded_measured_diff_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# # Plot the time series using Seaborn\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.lineplot(data=df_melted, x=df_melted.index, y='value', hue='type')\n",
    "# plt.xlabel('Index')\n",
    "# plt.ylabel('Value')\n",
    "# plt.title('Time Series Plot')\n",
    "# plt.show()\n",
    "\n",
    "sweep_key_name: str=\"desired_laps_decoding_time_bin_size\"\n",
    "\n",
    "## INPUTS: all_swept_decoded_measured_diff_df_dict, sweep_key_name,\n",
    "\n",
    "\n",
    "# Plot each list as a separate time series\n",
    "plt.figure(figsize=(10, 6))\n",
    "for key, error_df in all_swept_decoded_measured_diff_df_dict.items():\n",
    "    # convert frozenset back to dict\n",
    "    a_sweep_params_dict = {s[0]:s[1] for i, s in enumerate(key)}\n",
    "    # error_df['err_cm'] = np.sqrt(error_df['err'])\n",
    "\n",
    "    # plot_key: str = 'err'\n",
    "    plot_key: str = 'err_cm'\n",
    "    \n",
    "    key_label = f'{round(a_sweep_params_dict[sweep_key_name], ndigits=3)}s'\n",
    "    # sns.lineplot(x=range(len(value)), y=value, label=key)\n",
    "    _out_line = sns.lineplot(data=error_df, x='t', y=plot_key, label=key_label)\n",
    "    _out_scatter = sns.scatterplot(data=error_df, x='t', y=plot_key) #  label=key_label, legend=None\n",
    "\n",
    "\n",
    "plt.xlabel('lap_center_t (sec)')\n",
    "plt.ylabel('mean_squared_error')\n",
    "plt.title('All Swept Time Bin Sizes Lap Decoding Error')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d321945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2024-04-03 - Interactively show the lap decoding performance for a single time bin size:\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "\n",
    "_out_pagination_controller = DecodedEpochSlicesPaginatedFigureController.init_from_decoder_data(an_all_directional_laps_filter_epochs_decoder_result.active_filter_epochs,\n",
    "                                                                                            an_all_directional_laps_filter_epochs_decoder_result,\n",
    "                                                                                            xbin=long_results_obj.original_1D_decoder.xbin, global_pos_df=global_session.position.df,\n",
    "                                                                                            active_context=curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices',\n",
    "                                                                                                                                                                #   t_bin=f'{an_all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size}s',\n",
    "                                                                                                                                                                  t_bin=f\"{a_sweep_params_dict['desired_shared_decoding_time_bin_size']}s\",\n",
    "                                                                                                                                                                   epochs='laps', decoder='all_dir'),\n",
    "                                                                                            a_name='an_all_directional_laps_filter_epochs_decoder_result', max_subplots_per_page=20)\n",
    "_out_pagination_controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbcd125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import compute_weighted_correlations\n",
    "\n",
    "\n",
    "# out_wcorr_df_dict = compute_weighted_correlations({k:[a_p_x_given_n for a_p_x_given_n in deepcopy(v.all_directional_laps_filter_epochs_decoder_result.p_x_given_n_list)] for k, v in output_full_directional_merged_decoders_result.items()})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f59e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result: DirectionalPseudo2DDecodersResult = list(output_full_directional_merged_decoders_result.values())[-2]\n",
    "all_directional_laps_filter_epochs_decoder_result: DecodedFilterEpochsResult = a_result.all_directional_laps_filter_epochs_decoder_result\n",
    "\n",
    "# out_wcorr_df_dict = compute_weighted_correlations({k:deepcopy(v.all_directional_laps_filter_epochs_decoder_result) for k, v in output_full_directional_merged_decoders_result.items()})\n",
    "# out_wcorr_df_dict = compute_weighted_correlations({'out': all_directional_laps_filter_epochs_decoder_result})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4997b1e4",
   "metadata": {},
   "source": [
    "# Completely Different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b61ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import add_laps_groundtruth_information_to_dataframe\n",
    "\n",
    "laps_weighted_corr_merged_df = add_laps_groundtruth_information_to_dataframe(curr_active_pipeline=curr_active_pipeline, result_laps_epochs_df=laps_weighted_corr_merged_df)\n",
    "laps_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5436c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_weighted_corr_merged_df[laps_weighted_corr_merged_df['best_decoder_index'] != laps_weighted_corr_merged_df['true_decoder_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4744404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_weighted_corr_merged_df[laps_weighted_corr_merged_df['best_decoder_index'] == laps_weighted_corr_merged_df['true_decoder_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e57782",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_weighted_corr_merged_df.to_clipboard(excel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325be3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult], decoder_laps_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict,\n",
    "# laps_weighted_corr_merged_df: pd.DataFrame, decoder_laps_weighted_corr_df_dict: Dict[str, pd.DataFrame],\n",
    "# laps_simple_pf_pearson_merged_df: pd.DataFrame\n",
    "# laps_simple_pf_pearson_merged_df\n",
    "laps_weighted_corr_merged_df\n",
    "\n",
    "# ['best_decoder_index'] # gives the index of the decoder with the best value of wcorr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c477ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the ground truth for the decoded laps:\n",
    "groudtruth_laps_epochs_df: pd.DataFrame = directional_merged_decoders_result.add_groundtruth_information(curr_active_pipeline=curr_active_pipeline)\n",
    "groudtruth_laps_epochs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f465051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_column_names = ['maze_id', 'is_LR_dir', 'is_most_likely_track_identity_Long', 'is_most_likely_direction_LR']\n",
    "groudtruth_laps_epochs_df[groundtruth_column_names]\n",
    "\n",
    "lap_idxs = groudtruth_laps_epochs_df['lap_id'] - 1\n",
    "lap_idxs\n",
    "## add the truth columns to `laps_weighted_corr_merged_df`:\n",
    "laps_weighted_corr_merged_df[groundtruth_column_names] = groudtruth_laps_epochs_df[groundtruth_column_names]\n",
    "laps_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6402fe8",
   "metadata": {},
   "source": [
    "## 📈 2024-03-07 - measured v. best-decoded Position + Derivatives Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.position_derivatives import _compute_pos_derivs\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring, HeuristicScoresTuple\n",
    "\n",
    "\n",
    "measured_position_df = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "# # lap positions only:\n",
    "# measured_position_df = measured_position_df[~measured_position_df['lap'].isnull()] # only get the positions during the laps\n",
    "# measured_position_df['lap'] = measured_position_df['lap'].astype('int64')\n",
    "measured_position_df\n",
    "\n",
    "new_measured_pos_df: pd.DataFrame = _compute_pos_derivs(measured_position_df['t'].to_numpy(), position = deepcopy(measured_position_df['lin_pos'].to_numpy()), decoding_time_bin_size=laps_decoding_time_bin_size) \n",
    "# new_measured_pos_df\n",
    "\n",
    "extra_column_names = ['lap', 'lap_dir'] # 'y', \n",
    "assert np.shape(new_measured_pos_df)[0] == np.shape(measured_position_df)[0]\n",
    "new_measured_pos_df[extra_column_names] = measured_position_df[extra_column_names].copy()\n",
    "\n",
    "# lap positions only:\n",
    "new_measured_pos_df = new_measured_pos_df[~new_measured_pos_df['lap'].isnull()] # only get the positions during the laps\n",
    "new_measured_pos_df['lap'] = new_measured_pos_df['lap'].astype('int64')\n",
    "new_measured_pos_df\n",
    "\n",
    "\n",
    "# new_measured_pos_df['lap_dir'] = new_measured_pos_df['lap_dir'].astype('int64')\n",
    "\n",
    "# new_measured_pos_df\n",
    "\n",
    "# new_measured_pos_df.describe()\n",
    "\n",
    "\n",
    "# a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "\n",
    "# all_epochs_position_derivatives_df_dict_dict = {}\n",
    "all_epochs_position_derivatives_df_dict: Dict[str, pd.DataFrame] = {}\n",
    "_out_new_scores = {}\n",
    "\n",
    "# a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "for an_epoch_type_name, a_decoded_filter_epochs_decoder_result_dict in zip(('lap', 'ripple'), (deepcopy(decoder_laps_filter_epochs_decoder_result_dict), deepcopy(decoder_ripple_filter_epochs_decoder_result_dict))):\n",
    "    # all_epochs_position_derivatives_df_dict_dict[an_epoch_type_name] =\n",
    "    # any_good_selected_epoch_times = deepcopy(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times)\n",
    "    # any_good_selected_epoch_indicies = deepcopy(paginated_multi_decoder_decoded_epochs_window.find_data_indicies_from_epoch_times(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times))\n",
    "    # any_good_selected_epoch_indicies\n",
    "\n",
    "    # with suppress_print_context():\n",
    "    # with disable_function_context(builtins, \"print\"):\n",
    "    # _out_new_scores = {}\n",
    "    # an_epoch_idx: int = 0 # 7\n",
    "    axs = None\n",
    "    # all_epochs_position_derivatives_df_dict: Dict[str, pd.DataFrame] = {}\n",
    "    for a_decoder_name, a_result in a_decoded_filter_epochs_decoder_result_dict.items():\n",
    "        # print(f'\\na_name: {a_name}')\n",
    "        combined_key: str = f\"_\".join([an_epoch_type_name, a_decoder_name])\n",
    "                                      \n",
    "        # 🟪 2024-02-29 - `compute_pho_heuristic_replay_scores`\n",
    "        # directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict, _out_new_scores = HeuristicReplayScoring.compute_all_heuristic_scores(track_templates=track_templates, a_decoded_filter_epochs_decoder_result_dict=directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "        _out_new_scores[combined_key] = [HeuristicReplayScoring.compute_pho_heuristic_replay_scores(a_result=a_result, an_epoch_idx=an_epoch_idx, enable_debug_plot=False, debug_plot_axs=axs, debug_plot_name=f\"{combined_key}\") for an_epoch_idx in np.arange(a_result.num_filter_epochs)]\n",
    "        all_epochs_position_derivatives_df_dict[combined_key] = pd.concat([a_scores.position_derivatives_df for a_scores in _out_new_scores[combined_key]], ignore_index=True)\n",
    "\n",
    "_out_new_scores\n",
    "\n",
    "## Outputs: all_epochs_position_derivatives_df_dict, _out_new_scores, (measured_position_df, new_measured_pos_df)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41abbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.position_derivatives import debug_plot_helper_add_position_and_derivatives\n",
    "\n",
    "\n",
    "fig, debug_plot_axs = debug_plot_helper_add_position_and_derivatives(new_measured_pos_df['t'].to_numpy(), new_measured_pos_df['x'].to_numpy(), new_measured_pos_df['vel_x'].to_numpy(), new_measured_pos_df['accel_x'].to_numpy(),\n",
    "                                                                        debug_plot_axs=None, debug_plot_name='measured', common_plot_kwargs=dict(color='k', markersize='5', marker='.', linestyle='None', alpha=0.35))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1bdd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.position_derivatives import debug_plot_position_and_derivatives_figure\n",
    "\n",
    "## INPUTS: new_measured_pos_df, all_epochs_position_derivatives_df_dict\n",
    "fig, debug_plot_axs = debug_plot_position_and_derivatives_figure(new_measured_pos_df, all_epochs_position_derivatives_df_dict, debug_plot_axs=None, debug_figure_title=None, enable_debug_plot = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f5c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.position_derivatives import debug_plot_position_derivatives_stack\n",
    "\n",
    "# fig = debug_plot_position_derivatives_stack(new_measured_pos_df, all_epochs_position_derivatives_df_dict)\n",
    "fig = debug_plot_position_derivatives_stack(new_measured_pos_df, all_epochs_position_derivatives_df_dict, show_scatter=True)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e791125",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import sanitize_filename_for_Windows\n",
    "\n",
    "def save_plotly(a_fig, a_fig_context):\n",
    "    \"\"\" \n",
    "    captures: TODAY_DAY_DATE\n",
    "    \"\"\"\n",
    "    fig_save_path: Path = figures_folder.joinpath('_'.join([get_now_day_str(), sanitize_filename_for_Windows(a_fig_context.get_description())])).resolve()\n",
    "    figure_out_paths = {'.html': fig_save_path.with_suffix('.html'), '.png': fig_save_path.with_suffix('.png')}\n",
    "    a_fig.write_html(figure_out_paths['.html'])\n",
    "    display(fullwidth_path_widget(figure_out_paths['.html'], file_name_label='.html'))\n",
    "    # print(file_uri_from_path(figure_out_paths['.html']))\n",
    "    a_fig.write_image(figure_out_paths['.png'])\n",
    "    # print(file_uri_from_path(figure_out_paths['.png']))\n",
    "    display(fullwidth_path_widget(figure_out_paths['.png'], file_name_label='.png'))\n",
    "    return figure_out_paths\n",
    "\n",
    "\n",
    "figures_folder = Path('output').resolve()\n",
    "a_fig_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='debug_plot_position_derivatives_stack')\n",
    "save_plotly(fig, a_fig_context)\n",
    "\n",
    "# fig_save_path: Path = figures_folder.joinpath('_'.join([get_now_day_str(), sanitize_filename_for_Windows(a_fig_context.get_description())])).resolve()\n",
    "# figure_out_paths = {'.html': fig_save_path.with_suffix('.html'), '.png': fig_save_path.with_suffix('.png')}\n",
    "# a_fig.write_html(figure_out_paths['.html'])\n",
    "# display(fullwidth_path_widget(figure_out_paths['.html'], file_name_label='.html'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7fbba6",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d7aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: df1, df2\n",
    "position_deriv_column_names1 = pos_deriv_column_names\n",
    "df1 = measured_position_df[position_deriv_column_names1]\n",
    "\n",
    "position_deriv_column_names2 = ['x', 'vel_x', 'accel_x']\n",
    "df2 = deepcopy(all_epochs_position_derivatives_df[position_deriv_column_names2])\n",
    "\n",
    "# Set up the figure and axes.\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(8, 6))\n",
    "\n",
    "# List of columns to compare\n",
    "columns_to_compare = ['col1', 'col2', 'col3']\n",
    "\n",
    "\n",
    "# Loop through the list of columns and create a histogram for each.\n",
    "for i, (col1, col2) in enumerate(zip(position_deriv_column_names1, position_deriv_column_names2)):\n",
    "# for i, col in enumerate(columns_to_compare):\n",
    "    # Use the same bin edges for both histograms by computing them from the combined range of both DataFrames\n",
    "    combined_range = pd.concat([df1[col1], df2[col2]])\n",
    "    bins = np.histogram_bin_edges(combined_range, bins='auto')\n",
    "\n",
    "    # Plot the first DataFrame histogram\n",
    "    df1[col1].hist(bins=bins, ax=axes[i], alpha=0.5, label='Decoded')\n",
    "\n",
    "    # Plot the second DataFrame histogram\n",
    "    df2[col2].hist(bins=bins, ax=axes[i], alpha=0.5, label='Measured')\n",
    "\n",
    "    # Set the title and labels\n",
    "    axes[i].set_title(f'Histogram of {col1}')\n",
    "    axes[i].set_xlabel(col1)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "    # Add a legend\n",
    "    axes[i].legend()\n",
    "\n",
    "# Adjust layout for readability\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5670d2",
   "metadata": {},
   "source": [
    "# 💾🖼️ 2024-04-27 - Save Posteriors as Yellow-Blue plots to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c7718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import save_posterior\n",
    "\n",
    "# directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "# laps_marginals_df\n",
    "\n",
    "# ## Get the result after computation:\n",
    "# directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "# all_directional_decoder_dict_value = directional_merged_decoders_result.all_directional_decoder_dict\n",
    "# all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "# # long_directional_pf1D_Decoder_value = directional_merged_decoders_result.long_directional_pf1D_Decoder\n",
    "# # long_directional_decoder_dict_value = directional_merged_decoders_result.long_directional_decoder_dict\n",
    "# # short_directional_pf1D_Decoder_value = directional_merged_decoders_result.short_directional_pf1D_Decoder\n",
    "# # short_directional_decoder_dict_value = directional_merged_decoders_result.short_directional_decoder_dict\n",
    "\n",
    "# all_directional_laps_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "# all_directional_ripple_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\n",
    "\n",
    "# laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.laps_directional_marginals_tuple\n",
    "# laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = directional_merged_decoders_result.laps_track_identity_marginals_tuple\n",
    "# ripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.ripple_directional_marginals_tuple\n",
    "# ripple_track_identity_marginals, ripple_track_identity_all_epoch_bins_marginal, ripple_most_likely_track_identity_from_decoder, ripple_is_most_likely_track_identity_Long = directional_merged_decoders_result.ripple_track_identity_marginals_tuple\n",
    "\n",
    "# ripple_decoding_time_bin_size: float = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result.decoding_time_bin_size\n",
    "# ripple_decoding_time_bin_size\n",
    "# laps_decoding_time_bin_size: float = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size\n",
    "# laps_decoding_time_bin_size\n",
    "\n",
    "# laps_all_epoch_bins_marginals_df = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "# ripple_all_epoch_bins_marginals_df = directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df\n",
    "\n",
    "# ripple_all_epoch_bins_marginals_df\n",
    "# ripple_directional_marginals\n",
    "\n",
    "directional_merged_decoders_result.perform_compute_marginals()\n",
    "directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df\n",
    "\n",
    "# parent_array_as_image_output_folder = Path(r'E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Presentations\\2024-05-30 - Pho iNAV Poster\\Exports\\array_as_image').resolve()\n",
    "parent_array_as_image_output_folder = Path(r'output\\Exports\\array_as_image').resolve()\n",
    "parent_array_as_image_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "assert parent_array_as_image_output_folder.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicked_epoch = np.array([169.95631618227344, 170.15983607806265])\n",
    "clicked_epoch = np.array([132.51138943410479, 132.79100273095537])\n",
    "clicked_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f325d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result.p_x_given_n_list[1])\n",
    "         \n",
    "# directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result.marginal_x_list\n",
    "active_marginals_df: pd.DataFrame = deepcopy(directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df)\n",
    "# active_marginals_df.ripple_idx\n",
    "# directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result.marginal_x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b44569",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_filter_epochs_decoder_result: DecodedFilterEpochsResult = deepcopy(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result)\n",
    "active_filter_epochs_decoder_result.filter_epochs.epochs.find_data_indicies_from_epoch_times(np.atleast_1d(clicked_epoch[0]))\n",
    "\n",
    "# active_filter_epochs_decoder_result.all_directional_ripple_filter_epochs_decoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2daeff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import save_posterior\n",
    "from pyphocorehelpers.plotting.media_output_helpers import get_array_as_image_stack, save_array_as_image_stack\n",
    "\n",
    "def save_marginals_arrays_as_image(directional_merged_decoders_result: DirectionalPseudo2DDecodersResult, parent_array_as_image_output_folder: Path, epoch_id_identifier_str: str = 'ripple', epoch_ids=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    assert epoch_id_identifier_str in ['ripple', 'lap']\n",
    "    # active_marginals_df: pd.DataFrame = deepcopy(ripple_all_epoch_bins_marginals_df)\n",
    "    active_marginals_df: pd.DataFrame = deepcopy(directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df)\n",
    "    # ripple_filter_epochs_decoder_result = deepcopy(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result)\n",
    "    # ripple_filter_epochs_decoder_result = deepcopy(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result)\n",
    "    active_filter_epochs_decoder_result: DecodedFilterEpochsResult = deepcopy(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result)\n",
    "\n",
    "    raw_posterior_active_marginals = deepcopy(active_filter_epochs_decoder_result.p_x_given_n_list)\n",
    "\n",
    "    collapsed_per_lap_epoch_marginal_track_identity_point = active_marginals_df[['P_Long', 'P_Short']].to_numpy().astype(float)\n",
    "    collapsed_per_lap_epoch_marginal_dir_point = active_marginals_df[['P_LR', 'P_RL']].to_numpy().astype(float)\n",
    "\n",
    "    ripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir = directional_merged_decoders_result.ripple_directional_marginals_tuple\n",
    "    # directional_merged_decoders_result.ripple_track_identity_marginals_tuple = DirectionalPseudo2DDecodersResult.determine_long_short_likelihoods(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result)\n",
    "    ripple_track_identity_marginals, ripple_track_identity_all_epoch_bins_marginal, ripple_most_likely_track_identity_from_decoder, ripple_is_most_likely_track_identity_Long = directional_merged_decoders_result.ripple_track_identity_marginals_tuple\n",
    "\n",
    "    # raw_posterior_laps_marginals\n",
    "    # raw_posterior_active_marginals = directional_merged_decoders_result.build_non_marginalized_raw_posteriors(active_filter_epochs_decoder_result)\n",
    "    # raw_posterior_active_marginals\n",
    "\n",
    "    # INPUTS:\n",
    "    # raw_posterior_laps_marginals = deepcopy(raw_posterior_laps_marginals)\n",
    "    # active_directional_marginals = deepcopy(laps_directional_marginals)\n",
    "    # active_track_identity_marginals = deepcopy(laps_track_identity_marginals)\n",
    "    # raw_posterior_active_marginals = deepcopy(raw_posterior_laps_marginals)\n",
    "    active_directional_marginals = deepcopy(ripple_directional_marginals)\n",
    "    active_track_identity_marginals = deepcopy(ripple_track_identity_marginals)\n",
    "\n",
    "    assert parent_array_as_image_output_folder.exists()\n",
    "\n",
    "    if epoch_ids is None:\n",
    "        epoch_ids = np.arange(active_filter_epochs_decoder_result.num_filter_epochs)\n",
    "\n",
    "    for epoch_id in epoch_ids:\n",
    "        raw_tuple, marginal_dir_tuple, marginal_track_identity_tuple, marginal_dir_point_tuple, marginal_track_identity_point_tuple = save_posterior(raw_posterior_active_marginals, active_directional_marginals,\n",
    "                                                                            active_track_identity_marginals, collapsed_per_lap_epoch_marginal_dir_point, collapsed_per_lap_epoch_marginal_track_identity_point,\n",
    "                                                                                    parent_array_as_image_output_folder=parent_array_as_image_output_folder, epoch_id_identifier_str=epoch_id_identifier_str, epoch_id=epoch_id,\n",
    "                                                                                    debug_print=True)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "save_marginals_arrays_as_image(directional_merged_decoders_result=directional_merged_decoders_result, parent_array_as_image_output_folder=parent_array_as_image_output_folder, epoch_id_identifier_str='ripple', epoch_ids=[17])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f77b16",
   "metadata": {},
   "source": [
    "# 🎯🟢 2024-05-24 07:24 - Shuffed WCorr Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## wcorr is computed on each decoded posterior: `curr_results_obj.p_x_given_n_list`\n",
    "\n",
    "## Actually need to shuffle the unit idenities and recompute the posteriors\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "from nptyping import NDArray\n",
    "from typing import NewType\n",
    "\n",
    "import neuropy.utils.type_aliases as types\n",
    "from neuropy.utils.misc import build_shuffled_ids, shuffle_ids # used in _SHELL_analyze_leave_one_out_decoding_results\n",
    "from neuropy.utils.mixins.binning_helpers import find_minimum_time_bin_duration\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle, SequenceBasedComputationsContainer\n",
    "\n",
    "from neuropy.utils.mixins.indexing_helpers import get_dict_subset\n",
    "\n",
    "DecodedEpochsResultsDict = NewType('DecodedEpochsResultsDict', Dict[types.DecoderName, DecodedFilterEpochsResult]) # A Dict containing the decoded filter epochs result for each of the four 1D decoder names\n",
    "ShuffleIdx = NewType('ShuffleIdx', int)\n",
    "\n",
    "wcorr_shuffle_results: SequenceBasedComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('SequenceBased', None)\n",
    "if wcorr_shuffle_results is not None:    \n",
    "    wcorr_ripple_shuffle: WCorrShuffle = wcorr_shuffle_results.wcorr_ripple_shuffle\n",
    "    wcorr_ripple_shuffle: WCorrShuffle = WCorrShuffle(**get_dict_subset(wcorr_ripple_shuffle.to_dict(), subset_excludelist=['_VersionedResultMixin_version']))\n",
    "    curr_active_pipeline.global_computation_results.computed_data.SequenceBased.wcorr_ripple_shuffle = wcorr_ripple_shuffle\n",
    "    filtered_epochs_df: pd.DataFrame = deepcopy(wcorr_ripple_shuffle.filtered_epochs_df)\n",
    "    print(f'wcorr_ripple_shuffle.n_completed_shuffles: {wcorr_ripple_shuffle.n_completed_shuffles}')\n",
    "else:\n",
    "    print(f'SequenceBased is not computed.')\n",
    "\n",
    "# wcorr_ripple_shuffle: WCorrShuffle = WCorrShuffle.init_from_templates(curr_active_pipeline=curr_active_pipeline, enable_saving_entire_decoded_shuffle_result=True)\n",
    "\n",
    "n_epochs: int = wcorr_ripple_shuffle.n_epochs\n",
    "print(f'n_epochs: {n_epochs}')\n",
    "n_completed_shuffles: int = wcorr_ripple_shuffle.n_completed_shuffles\n",
    "print(f'n_completed_shuffles: {n_completed_shuffles}')\n",
    "wcorr_ripple_shuffle.compute_shuffles(num_shuffles=2, curr_active_pipeline=curr_active_pipeline)\n",
    "n_completed_shuffles: int = wcorr_ripple_shuffle.n_completed_shuffles\n",
    "print(f'n_completed_shuffles: {n_completed_shuffles}')\n",
    "desired_ripple_decoding_time_bin_size: float = wcorr_shuffle_results.wcorr_ripple_shuffle.all_templates_decode_kwargs['desired_ripple_decoding_time_bin_size']\n",
    "print(f'{desired_ripple_decoding_time_bin_size = }')\n",
    "# filtered_epochs_df\n",
    "\n",
    "# 7m - 200 shuffles\n",
    "# (_out_p, _out_p_dict), (_out_shuffle_wcorr_ZScore_LONG, _out_shuffle_wcorr_ZScore_SHORT), (total_n_shuffles_more_extreme_than_real_df, total_n_shuffles_more_extreme_than_real_dict), _out_shuffle_wcorr_arr = wcorr_ripple_shuffle.post_compute(decoder_names=deepcopy(TrackTemplates.get_decoder_names()))\n",
    "wcorr_ripple_shuffle_all_df, all_shuffles_wcorr_df = wcorr_ripple_shuffle.build_all_shuffles_dataframes(decoder_names=deepcopy(TrackTemplates.get_decoder_names()))\n",
    "## Prepare for plotting in histogram:\n",
    "wcorr_ripple_shuffle_all_df = wcorr_ripple_shuffle_all_df.dropna(subset=['start', 'stop'], how='any', inplace=False)\n",
    "wcorr_ripple_shuffle_all_df = wcorr_ripple_shuffle_all_df.dropna(subset=['wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL'], how='all', inplace=False)\n",
    "wcorr_ripple_shuffle_all_df = wcorr_ripple_shuffle_all_df.convert_dtypes()\n",
    "# {'long_best_dir_decoder_IDX': int, 'short_best_dir_decoder_IDX': int}\n",
    "# wcorr_ripple_shuffle_all_df\n",
    "## Gets the absolutely most extreme value from any of the four decoders and uses that\n",
    "best_wcorr_max_indices = np.abs(wcorr_ripple_shuffle_all_df[['wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL']].values).argmax(axis=1)\n",
    "wcorr_ripple_shuffle_all_df[f'abs_best_wcorr'] = [wcorr_ripple_shuffle_all_df[['wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL']].values[i, best_idx] for i, best_idx in enumerate(best_wcorr_max_indices)] #  np.where(direction_max_indices, wcorr_ripple_shuffle_all_df['long_LR'].filter_epochs[a_column_name].to_numpy(), wcorr_ripple_shuffle_all_df['long_RL'].filter_epochs[a_column_name].to_numpy())\n",
    "# wcorr_ripple_shuffle_all_df\n",
    "# wcorr_ripple_shuffle_all_df[['wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL']].max(axis=1, skipna=True)\n",
    "\n",
    "## OUTPUTS: wcorr_ripple_shuffle_all_df\n",
    "\n",
    "all_shuffles_only_best_decoder_wcorr_df = pd.concat([all_shuffles_wcorr_df[np.logical_and((all_shuffles_wcorr_df['epoch_idx'] == epoch_idx), (all_shuffles_wcorr_df['decoder_idx'] == best_idx))] for epoch_idx, best_idx in enumerate(best_wcorr_max_indices)])\n",
    "# all_shuffles_only_best_decoder_wcorr_df\n",
    "\n",
    "# wcorr_ripple_shuffle_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cacb4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import finalize_output_shuffled_wcorr, _get_custom_suffix_for_replay_filename\n",
    "\n",
    "custom_suffix: str = _get_custom_suffix_for_replay_filename(new_replay_epochs=new_replay_epochs)\n",
    "print(f'custom_suffix: \"{custom_suffix}\"')\n",
    "wcorr_ripple_shuffle_all_df, all_shuffles_only_best_decoder_wcorr_df, (standalone_pkl_filepath, standalone_mat_filepath) = finalize_output_shuffled_wcorr(curr_active_pipeline=curr_active_pipeline,\n",
    "                                                                                                                                                          decoder_names=deepcopy(TrackTemplates.get_decoder_names()), custom_suffix=custom_suffix)\n",
    "\n",
    "\n",
    "# (n_shuffles = 31, n_epochs = 873, n_decoders = 4); n_total_elements = 108252\n",
    "# saving to \"W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\output\\2024-06-27_0550PM_withNewComputedReplays-qclu_[1, 2]-frateThresh_1.0_standalone_wcorr_ripple_shuffle_data_only_31.pkl\"...\n",
    "# total_n_shuffles: 31\n",
    "# Saving (file mode 'w+b') session pickle file results :... saved session pickle file\n",
    "# saving .mat file to \"W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\output\\2024-06-27_0550PM_withNewComputedReplays-qclu_[1, 2]-frateThresh_1.0_standalone_all_shuffles_wcorr_array.mat\"...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.indexing_helpers import get_dict_subset\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_replay_wcorr_histogram\n",
    "\n",
    "## INPUTS: wcorr_ripple_shuffle_all_df, wcorr_ripple_shuffle_all_df, custom_suffix\n",
    "plot_var_name: str = 'abs_best_wcorr'\n",
    "a_fig_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='replay_wcorr', custom_suffix=custom_suffix)\n",
    "# params_description_str: str = \" | \".join([f\"{str(k)}:{str(v)}\" for k, v in get_dict_subset(new_replay_epochs.metadata, subset_excludelist=['qclu_included_aclus']).items()])\n",
    "params_description_str: str = \"DefaultComputation\" # | \".join([f\"{str(k)}:{str(v)}\" for k, v in get_dict_subset(curr_active_pipeline.sess.replay.metadata, subset_excludelist=['qclu_included_aclus']).items()])\n",
    "footer_annotation_text = f'{curr_active_pipeline.get_session_context()}<br>{params_description_str}'\n",
    "\n",
    "fig = plot_replay_wcorr_histogram(df=wcorr_ripple_shuffle_all_df, plot_var_name=plot_var_name,\n",
    "        all_shuffles_only_best_decoder_wcorr_df=all_shuffles_only_best_decoder_wcorr_df, footer_annotation_text=footer_annotation_text)\n",
    "\n",
    "# Save figure to disk:\n",
    "_out_result = curr_active_pipeline.output_figure(a_fig_context, fig=fig)\n",
    "_out_result\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d707712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histogram_for_z_scores\n",
    "\n",
    "# selected_epoch_index = None\n",
    "# a_decoder_idx = None\n",
    "\n",
    "selected_epoch_index = 0\n",
    "a_decoder_idx = 0\n",
    "\n",
    "if (selected_epoch_index is None) and (a_decoder_idx is None):\n",
    "    _single_epoch_all_shuffles_wcorr_arr = deepcopy(wcorr_ripple_shuffle.all_shuffles_wcorr_array)\n",
    "    _single_epoch_real_wcorr: float = wcorr_ripple_shuffle.real_decoder_ripple_weighted_corr_arr \n",
    "    a_single_decoder_epoch_z_scored_values: NDArray = wcorr_ripple_shuffle.compute_z_transformed_scores(_single_epoch_all_shuffles_wcorr_arr)\n",
    "    a_single_decoder_epoch_z_score: float = wcorr_ripple_shuffle.compute_z_score(_single_epoch_all_shuffles_wcorr_arr, _single_epoch_real_wcorr)\n",
    "    title = f\"histogram_for_z_scores - all decoders, all epochs\"\n",
    "    title_suffix=f': all decoders, all epochs'\n",
    "\n",
    "else: \n",
    "    _single_epoch_all_shuffles_wcorr_arr = wcorr_ripple_shuffle.all_shuffles_wcorr_array[:, selected_epoch_index, a_decoder_idx]\n",
    "    _single_epoch_real_wcorr: float = wcorr_ripple_shuffle.real_decoder_ripple_weighted_corr_arr[selected_epoch_index, a_decoder_idx]\n",
    "\n",
    "    a_single_decoder_epoch_z_scored_values: NDArray = wcorr_ripple_shuffle.compute_z_transformed_scores(_single_epoch_all_shuffles_wcorr_arr)\n",
    "    a_single_decoder_epoch_z_score: float = wcorr_ripple_shuffle.compute_z_score(_single_epoch_all_shuffles_wcorr_arr, _single_epoch_real_wcorr)\n",
    "    title = f\"histogram_for_z_scores - decoder[{a_decoder_idx}], epoch[{selected_epoch_index}]\"\n",
    "    title_suffix=f': decoder[{a_decoder_idx}], epoch[{selected_epoch_index}]'\n",
    "\n",
    "print(f'np.shape(_single_epoch_all_shuffles_wcorr_arr): {np.shape(_single_epoch_all_shuffles_wcorr_arr)}') # (n_shuffles, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b75810",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'a_single_decoder_epoch_z_score: {a_single_decoder_epoch_z_score}')\n",
    "fig = plt.figure(num=title, clear=True)\n",
    "# List of z-scored values\n",
    "z_scores = a_single_decoder_epoch_z_scored_values\n",
    "plot_histogram_for_z_scores(z_scores, title_suffix=title_suffix)\n",
    "plt.axvline(a_single_decoder_epoch_z_score, color='red', linestyle='--', linewidth=2, label='Actual Value')\n",
    "\n",
    "# plot_histogram_for_z_scores(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5d6d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df_dict['ripple_WCorrShuffle_df']['export_date'] = get_now_rounded_time_str()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcorr_ripple_shuffle.plot_histogram_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec84c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcorr_ripple_shuffle.plot_histogram_figure(a_decoder_idx=2, selected_epoch_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3961cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of z-scored values\n",
    "all_shuffles_wcorr_array = deepcopy(wcorr_ripple_shuffle.all_shuffles_wcorr_array)\n",
    "(_out_p, _out_p_dict), (_out_shuffle_wcorr_ZScore_LONG, _out_shuffle_wcorr_ZScore_SHORT), (total_n_shuffles_more_extreme_than_real_df, total_n_shuffles_more_extreme_than_real_dict), all_shuffles_wcorr_array = wcorr_ripple_shuffle.post_compute()\n",
    "## OUTPUTS: all_shuffles_wcorr_array, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fbc814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_shuffle_wcorr_ZScore_LONG\n",
    "all_shuffles_wcorr_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standalone save\n",
    "standalone_pkl_filename: str = f'{get_now_rounded_time_str()}_standalone_wcorr_ripple_shuffle_data_only_{wcorr_ripple_shuffle.n_completed_shuffles}.pkl' \n",
    "standalone_pkl_filepath = curr_active_pipeline.get_output_path().joinpath(standalone_pkl_filename).resolve() # Path(\"W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\2024-05-30_0925AM_standalone_wcorr_ripple_shuffle_data_only_1100.pkl\")\n",
    "print(f'saving to \"{standalone_pkl_filepath}\"...')\n",
    "wcorr_ripple_shuffle.save_data(standalone_pkl_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3441a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: wcorr_ripple_shuffle\n",
    "standalone_mat_filename: str = f'{get_now_rounded_time_str()}_standalone_all_shuffles_wcorr_array.mat' \n",
    "standalone_mat_filepath = curr_active_pipeline.get_output_path().joinpath(standalone_mat_filename).resolve() # r\"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-06-03_0400PM_standalone_all_shuffles_wcorr_array.mat\"\n",
    "wcorr_ripple_shuffle.save_data_mat(filepath=standalone_mat_filepath, **{'session': curr_active_pipeline.get_session_context().to_dict()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcorr_ripple_shuffle.discover_load_and_append_shuffle_data_from_directory(save_directory=curr_active_pipeline.get_output_path().resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94572934",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_context = curr_active_pipeline.get_session_context()\n",
    "session_ctxt_key:str = active_context.get_description(separator='|', subset_includelist=IdentifyingContext._get_session_context_keys())\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "export_files_dict = wcorr_ripple_shuffle.export_csvs(parent_output_path=collected_outputs_path.resolve(), active_context=active_context, session_name=session_name, curr_active_pipeline=curr_active_pipeline)\n",
    "export_files_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5966cf23",
   "metadata": {},
   "source": [
    "### Find clicked index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e823ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times\n",
    "\n",
    "# clicked_epoch = np.array([[149.95935746072792, 150.25439218967222]]).T\n",
    "# clicked_epoch = np.atleast_2d(np.array([637.7847819341114, 638.1821449307026])).T\n",
    "# clicked_epoch = np.atleast_2d(np.array([105.400, 638.1821449307026])).T\n",
    "clicked_epoch = np.atleast_2d(np.array([105.40014315512963, 105.56255971186329])).T\n",
    "# clicked_epoch\n",
    "clicked_epoch_start_times = clicked_epoch[0, :]\n",
    "# clicked_epoch_start_times\n",
    "# clicked_epoch_start_times = np.array([637.7847819341114,])\n",
    "selected_epoch_indicies = find_data_indicies_from_epoch_times(wcorr_ripple_shuffle.filtered_epochs_df, epoch_times=np.squeeze(clicked_epoch_start_times), t_column_names=['start',], atol=0.001, not_found_action='skip_index', debug_print=False)\n",
    "# selected_epoch_indicies\n",
    "\n",
    "assert len(selected_epoch_indicies) > 0\n",
    "\n",
    "selected_epoch_index: int = selected_epoch_indicies[0]\n",
    "print(f'selected_epoch_index: {selected_epoch_index}')\n",
    "print(f'{clicked_epoch_start_times = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97546452",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_decoder_ripple_wcorr_df.iloc[selected_epoch_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_decoder_ripple_wcorr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e8acdd",
   "metadata": {},
   "source": [
    "# 2024-06-03 - Plot decoded wcorr shuffle z-values using `PhoPaginatedMultiDecoderDecodedEpochsWindow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.decoders import wcorr\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# REAL wcorr for other\n",
    "# ==================================================================================================================== #\n",
    "active_spikes_df = deepcopy(curr_active_pipeline.sess.spikes_df)\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "alt_directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = deepcopy(directional_merged_decoders_result)\n",
    "\n",
    "## Filter the epochs by minimum duration:\n",
    "replay_epochs_df: pd.DataFrame = deepcopy(filtered_epochs_df)\n",
    "desired_ripple_decoding_time_bin_size: float = alt_directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "minimum_event_duration: float = 2.0 * float(alt_directional_merged_decoders_result.ripple_decoding_time_bin_size)\n",
    "print(f'{desired_ripple_decoding_time_bin_size = }, {minimum_event_duration = }')\n",
    "\n",
    "all_templates_decode_kwargs = dict(desired_ripple_decoding_time_bin_size=desired_ripple_decoding_time_bin_size,\n",
    "                    override_replay_epochs_df=replay_epochs_df, ## Use the filtered epochs\n",
    "                    use_single_time_bin_per_epoch=False, minimum_event_duration=minimum_event_duration)\n",
    "\n",
    "(real_directional_merged_decoders_result, real_decoder_ripple_filter_epochs_decoder_result_dict), real_decoder_ripple_weighted_corr_arr = WCorrShuffle.build_real_result(track_templates=track_templates, directional_merged_decoders_result=alt_directional_merged_decoders_result, active_spikes_df=active_spikes_df, all_templates_decode_kwargs=all_templates_decode_kwargs)\n",
    "real_decoder_ripple_filter_epochs_decoder_result_dict : Dict[str, DecodedFilterEpochsResult] = deepcopy(real_decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "real_decoder_ripple_filter_epochs_decoder_result_dict\n",
    "# real_decoder_ripple_weighted_corr_arr\n",
    "\n",
    "# real_directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = deepcopy(directional_merged_decoders_result)\n",
    "# # real_output_alt_directional_merged_decoders_result, (real_decoder_laps_filter_epochs_decoder_result_dict, real_decoder_ripple_filter_epochs_decoder_result_dict) = _try_all_templates_decode(spikes_df=deepcopy(curr_active_pipeline.sess.spikes_df), a_directional_merged_decoders_result=real_directional_merged_decoders_result, shuffled_decoders_dict=real_directional_merged_decoders_result.all_directional_decoder_dict, **a_sweep_dict)\n",
    "# real_output_alt_directional_merged_decoders_result, (real_decoder_laps_filter_epochs_decoder_result_dict, real_decoder_ripple_filter_epochs_decoder_result_dict) = cls._try_all_templates_decode(spikes_df=active_spikes_df, a_directional_merged_decoders_result=real_directional_merged_decoders_result, shuffled_decoders_dict=track_templates.get_decoders_dict(), \n",
    "#                                                                                                                                                                                             skip_merged_decoding=True, **all_templates_decode_kwargs)\n",
    "# real_decoder_ripple_weighted_corr_df_dict = compute_weighted_correlations(decoder_decoded_epochs_result_dict=deepcopy(real_decoder_ripple_filter_epochs_decoder_result_dict))\n",
    "# real_decoder_ripple_weighted_corr_dict = {k:v['wcorr'].to_numpy() for k, v in real_decoder_ripple_weighted_corr_df_dict.items()}\n",
    "# real_decoder_ripple_weighted_corr_df = pd.DataFrame(real_decoder_ripple_weighted_corr_dict) ## (n_epochs, 4)\n",
    "# real_decoder_ripple_weighted_corr_arr = real_decoder_ripple_weighted_corr_df.to_numpy()\n",
    "# print(f'real_decoder_ripple_weighted_corr_arr: {np.shape(real_decoder_ripple_weighted_corr_arr)}')\n",
    "# real_directional_merged_decoders_result\n",
    "\n",
    "# real_output_alt_directional_merged_decoders_result, (real_decoder_laps_filter_epochs_decoder_result_dict, real_decoder_ripple_filter_epochs_decoder_result_dict) = WCorrShuffle._try_all_templates_decode(spikes_df=active_spikes_df, a_directional_merged_decoders_result=real_directional_merged_decoders_result, shuffled_decoders_dict=track_templates.get_decoders_dict(), \n",
    "#                                                                                                                                                                                             skip_merged_decoding=True, **all_templates_decode_kwargs)\n",
    "# real_decoder_ripple_filter_epochs_decoder_result_dict : Dict[str, DecodedFilterEpochsResult] = deepcopy(real_decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "# real_decoder_ripple_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS filtered_decoder_filter_epochs_decoder_result_dict\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "new_wcorr_shuffle_app, new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window, new_wcorr_shuffle_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "    # decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "    decoder_decoded_epochs_result_dict=real_decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "    # decoder_decoded_epochs_result_dict=high_wcorr_only_filtered_decoder_filter_epochs_decoder_result_dict,\n",
    "    epochs_name='ripple',\n",
    "    included_epoch_indicies=None, debug_print=False,\n",
    "    params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "        'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, \n",
    "        'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True,\n",
    "        # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "        # 'disable_y_label': True,\n",
    "        'isPaginatorControlWidgetBackedMode': True,\n",
    "        'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "        # 'debug_print': True,\n",
    "        'max_subplots_per_page': 10,\n",
    "        'scrollable_figure': False,\n",
    "        # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "        'use_AnchoredCustomText': False,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f2633",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window.add_data_overlays(None, real_decoder_ripple_filter_epochs_decoder_result_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4453253",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window.remove_data_overlays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304948c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "_tmp_out_selections = new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations(source='diba_evt_file') # : # gets the annotations for the kdiba-evt file exported ripples, consistent with his 2009 paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d034fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window.setWindowTitle(f'PhoPaginatedMultiDecoderDecodedEpochsWindow: NEW Decoded Epoch Slices - real_decoder_ripple_filter_epochs_decoder_result_dict')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400fa60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuropy\n",
    "\n",
    "all_directional_decoder_dict: Dict[str, neuropy.analyses.placefields.PfND] = alt_directional_merged_decoders_result.all_directional_decoder_dict\n",
    "all_directional_decoder_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60921549",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('alt_directional_merged_decoders_result.all_directional_decoder_dict', alt_directional_merged_decoders_result.all_directional_decoder_dict, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc12642",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_container = alt_directional_merged_decoders_result.all_directional_decoder_dict\n",
    "num_elements: int = len(a_container)\n",
    "\n",
    "\n",
    "if isinstance(a_container, dict):\n",
    "    for i in np.arange(num_elements):\n",
    "        for k, v in a_container.items()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ce09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _perform_compute_custom_epoch_decoding\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_all_df_score_metrics\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "pos_bin_size: float = track_templates.get_decoders()[0].pos_bin_size\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict = _perform_compute_custom_epoch_decoding(curr_active_pipeline, directional_merged_decoders_result, track_templates) # Dict[str, Optional[DecodedFilterEpochsResult]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1562be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fefaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# From `General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions._decode_and_evaluate_epochs_using_directional_decoders`\n",
    "## Recompute the epoch scores/metrics such as radon transform and wcorr:\n",
    "(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict), merged_df_outputs_tuple, raw_dict_outputs_tuple = _compute_all_df_score_metrics(directional_merged_decoders_result, track_templates,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdecoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tspikes_df=deepcopy(curr_active_pipeline.sess.spikes_df),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tshould_skip_radon_transform=True)\n",
    "laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df, laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df = merged_df_outputs_tuple\n",
    "decoder_laps_radon_transform_df_dict, decoder_ripple_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict, decoder_ripple_radon_transform_extras_dict, decoder_laps_weighted_corr_df_dict, decoder_ripple_weighted_corr_df_dict = raw_dict_outputs_tuple\n",
    "## INPUT: ripple_weighted_corr_merged_df, wcorr_ripple_shuffle\n",
    "# Synchronize `ripple_weighted_corr_merged_df` to match `wcorr_ripple_shuffle.filtered_epochs_df` to compare wcorr values:\n",
    "filtered_epoch_start_times = deepcopy(wcorr_ripple_shuffle.filtered_epochs_df)['start'].to_numpy() # get the included times from `wcorr_ripple_shuffle`\n",
    "## Apply the filter to `ripple_weighted_corr_merged_df`\n",
    "filtered_epoch_indicies = find_data_indicies_from_epoch_times(ripple_weighted_corr_merged_df, epoch_times=np.squeeze(filtered_epoch_start_times), t_column_names=['ripple_start_t',], atol=0.001, not_found_action='skip_index', debug_print=False)\n",
    "# filtered_epoch_indicies\n",
    "assert len(filtered_epoch_indicies) > 0\n",
    "# filtered_epoch_indicies\n",
    "# ripple_weighted_corr_merged_df.epochs.matching_epoch_times_slice(epoch_times=np.squeeze(filtered_epoch_start_times), t_column_names=['ripple_start_t',])\n",
    "filtered_ripple_weighted_corr_merged_df: pd.DataFrame = ripple_weighted_corr_merged_df.loc[filtered_epoch_indicies].copy().reset_index(drop=True)\n",
    "filtered_ripple_weighted_corr_merged_df\n",
    "\n",
    "## OUTPUT: filtered_ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bfe145",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare real_decoder_ripple_wcorr_df and filtered_ripple_weighted_corr_merged_df\n",
    "\n",
    "## INPUT: filtered_ripple_weighted_corr_merged_df, real_decoder_ripple_wcorr_df\n",
    "assert len(real_decoder_ripple_wcorr_df) == len(filtered_ripple_weighted_corr_merged_df), f\"len(real_decoder_ripple_wcorr_df): {len(real_decoder_ripple_wcorr_df)} != len(filtered_ripple_weighted_corr_merged_df): {len(filtered_ripple_weighted_corr_merged_df)}\"\n",
    "assert np.all(np.isclose(real_decoder_ripple_wcorr_df['start_t'].to_numpy(), filtered_ripple_weighted_corr_merged_df['ripple_start_t'].to_numpy())), f\"all epoch start times must be the same!\"\n",
    "real_decoder_ripple_wcorr_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb4a926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9855dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.enable_middle_click_selected_epoch_times_to_clipboard()\n",
    "\n",
    "# clicked_epoch = np.array([132.51138943410479, 132.79100273095537])\n",
    "\n",
    "# clicked_epoch = np.array([149.95935746072792, 150.25439218967222])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77930766",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_epoch_index: int = filtered_epoch_indicies[0]\n",
    "print(f'selected_epoch_index: {selected_epoch_index}')\n",
    "print(f'{clicked_epoch_start_times = }')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f869b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_wcorr_df: pd.DataFrame = pd.DataFrame({a_name:v['wcorr'].to_numpy() for a_name, v in decoder_ripple_weighted_corr_df_dict.items()})\n",
    "# original_wcorr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474fa734",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_epoch_indicies = find_data_indicies_from_epoch_times(wcorr_ripple_shuffle.filtered_epochs_df, epoch_times=np.squeeze(clicked_epoch_start_times), t_column_names=['start',], atol=0.001, not_found_action='skip_index', debug_print=False)\n",
    "# selected_epoch_indicies\n",
    "\n",
    "assert len(selected_epoch_indicies) > 0\n",
    "\n",
    "selected_epoch_index: int = selected_epoch_indicies[0]\n",
    "print(f'selected_epoch_index: {selected_epoch_index}')\n",
    "print(f'{clicked_epoch_start_times = }')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(merged_df_outputs_tuple)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97648899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8357ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_decoder_ripple_wcorr_df[np.isclose(real_decoder_ripple_wcorr_df['start_t'], 637.7847819341114)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting complete results:\n",
    "a_shuffle_outcome: Dict[types.DecoderName, DecodedFilterEpochsResult] = output_all_shuffles_decoded_results_list[-1]\n",
    "a_shuffle_wcorrs = output_extracted_result_wcorrs_list[-1]\n",
    "\n",
    "## start with one decoder:\n",
    "a_decoder_name: types.DecoderName = 'long_LR'\n",
    "a_decoder_idx: int = 0\n",
    "a_shuffle_decoder_result: DecodedFilterEpochsResult = a_shuffle_outcome[a_decoder_name]\n",
    "# a_shuffle_decoder_result.filter_epochs\n",
    "\n",
    "a_shuffle_decoder_wcorr_result: NDArray = np.squeeze(a_shuffle_wcorrs[a_decoder_name].to_numpy()) # (n_epochs, )\n",
    "\n",
    "# a_shufle_wcorrs\n",
    "a_shuffle_decoder_wcorr_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4846e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: a_decoder_name\n",
    "_out_shuffle_wcorr_arr = np.stack([np.squeeze(v[a_decoder_name].to_numpy()) for v in output_extracted_result_wcorrs_list]) # .shape ## (n_shuffles, n_epochs) \n",
    "print(f'_out_shuffle_wcorr_arr.shape: {np.shape(_out_shuffle_wcorr_arr)}') # _out_shuffle_wcorr_arr.shape: (n_shuffles, n_epochs)\n",
    "n_shuffles: int = np.shape(_out_shuffle_wcorr_arr)[0]\n",
    "print(f'n_shuffles: {n_shuffles}')\n",
    "n_epochs: int = np.shape(_out_shuffle_wcorr_arr)[1]\n",
    "print(f'n_epochs: {n_epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: `wcorr_ripple_shuffle`\n",
    "wcorr_ripple_shuffle.n_completed_shuffles\n",
    "(_out_p, _out_p_dict), (_out_shuffle_wcorr_ZScore_LONG, _out_shuffle_wcorr_ZScore_SHORT), (total_n_shuffles_more_extreme_than_real_df, total_n_shuffles_more_extreme_than_real_dict), all_shuffles_wcorr_array = wcorr_ripple_shuffle.post_compute(curr_active_pipeline=curr_active_pipeline)\n",
    "## OUTPUTS: all_shuffles_wcorr_array, \n",
    "all_shuffles_wcorr_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c91a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all shuffles for a single epoch:\n",
    "## INPUTS: all_shuffles_wcorr_array, a_decoder_idx, selected_epoch_index\n",
    "\n",
    "## start with one decoder:\n",
    "a_decoder_name: types.DecoderName = 'long_LR'\n",
    "a_decoder_idx: int = 0\n",
    "selected_epoch_index: int = 0\n",
    "\n",
    "# _single_epoch_all_shuffles_wcorr_arr = _out_shuffle_wcorr_arr[:, selected_epoch_index]\n",
    "_single_epoch_all_shuffles_wcorr_arr = wcorr_ripple_shuffle.all_shuffles_wcorr_array[:, selected_epoch_index, a_decoder_idx]\n",
    "print(f'np.shape(_single_epoch_all_shuffles_wcorr_arr): {np.shape(_single_epoch_all_shuffles_wcorr_arr)}') # (n_shuffles, )\n",
    "_single_epoch_all_shuffles_wcorr_arr\n",
    "\n",
    "_single_epoch_real_wcorr: float = wcorr_ripple_shuffle.real_decoder_ripple_weighted_corr_arr[selected_epoch_index, a_decoder_idx]\n",
    "_single_epoch_real_wcorr # -0.35003949543741564"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2030bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_single_decoder_epoch_z_scored_values: NDArray = wcorr_ripple_shuffle.compute_z_transformed_scores(_single_epoch_all_shuffles_wcorr_arr)\n",
    "a_single_decoder_epoch_z_scored_values\n",
    "a_single_decoder_epoch_z_score: float = wcorr_ripple_shuffle.compute_z_score(_single_epoch_all_shuffles_wcorr_arr, _single_epoch_real_wcorr)\n",
    "print(f'a_single_decoder_epoch_z_score: {a_single_decoder_epoch_z_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba84417",
   "metadata": {},
   "source": [
    "# :🟢 Build Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import pho_jointplot, plot_histograms\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "import plotly.io as pio\n",
    "import plotly.subplots as sp\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.plotly_templates import PlotlyHelpers\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms_across_sessions, plot_stacked_histograms\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_helper_save_figures, _helper_build_figure, plotly_pre_post_delta_scatter, plot_across_sessions_scatter_results\n",
    "\n",
    "# Plotly Imports:\n",
    "fig_size_kwargs = {'width': 1650, 'height': 480}\n",
    "is_dark_mode, template = PlotlyHelpers.get_plotly_template(is_dark_mode=False)\n",
    "pio.templates.default = template\n",
    "\n",
    "df: pd.DataFrame = deepcopy(wcorr_ripple_shuffle_all_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new scatter plot:\n",
    "# px_scatter_kwargs = {'x': 'epoch_idx', 'y': 'shuffle_wcorr', 'color':\"decoder_idx\", 'title': f\"'wcorr scatter results'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "# df = all_shuffles_wcorr_df\n",
    "\n",
    "## INPUTS: wcorr_ZScore_real_LR_df\n",
    "# px_scatter_kwargs = {'x': 'start_t', 'y': 'long', 'title': f\"'wcorr scatter results LONG'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "# df = wcorr_ZScore_real_LR_df\n",
    "\n",
    "## INPUTS: real_decoder_ripple_wcorr_df\n",
    "px_scatter_kwargs = {'x': 'start', 'y': 'wcorr_z_long', 'title': f\"'real_decoder_ripple_wcorr_df long_RL'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "# df = real_decoder_ripple_wcorr_df\n",
    "\n",
    "\n",
    "# px_scatter_kwargs.pop('color')\n",
    "out_scatter_fig = px.scatter(df, **px_scatter_kwargs)\n",
    "out_scatter_fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da466ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_bins = 25\n",
    "concatenated_ripple_df = deepcopy(all_shuffles_wcorr_df)\n",
    "# variable_name = 'P_Long'\n",
    "variable_name = 'P_Short' # Shows expected effect - short-only replay prior to delta and then split replays post-delta\n",
    "# variable_name = 'long_best_pf_peak_x_pearsonr'\n",
    "# variable_name = 'long_best_jump'\n",
    "# variable_name = 'wcorr_abs_diff'\n",
    "# variable_name = 'pearsonr_abs_diff'\n",
    "# variable_name = 'direction_change_bin_ratio_diff'\n",
    "# variable_name = 'longest_sequence_length_ratio_diff'\n",
    "# variable_name = 'long_best_longest_sequence_length_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'congruent_dir_bins_ratio_diff'\n",
    "# variable_name = 'total_congruent_direction_change_diff'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'long_best_direction_change_bin_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# 'color':'is_user_annotated_epoch'\n",
    "# 'color': 'is_user_annotated_epoch', \n",
    "\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'color':\"is_user_annotated_epoch\", 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "\n",
    "px_scatter_kwargs.pop('color')\n",
    "\n",
    "# hist_kwargs = dict(color=\"time_bin_size\")\n",
    "hist_kwargs = dict(color=\"is_user_annotated_epoch\") # , histnorm='probability density'\n",
    "hist_kwargs.pop('color')\n",
    "new_fig_ripples, new_fig_ripples_context = plotly_pre_post_delta_scatter(data_results_df=concatenated_ripple_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, hist_kwargs=hist_kwargs, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end), legend_title_text='Is User Selected', is_dark_mode=is_dark_mode)\n",
    "new_fig_ripples = new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "figure_out_paths = save_plotly(a_fig=new_fig_ripples, a_fig_context=figure_ripples_context)\n",
    "new_fig_ripples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4fd2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "# mpg = sns.load_dataset(\"mpg\")\n",
    "\n",
    "## INPUT: pd.DataFrame\n",
    "sns.catplot(\n",
    "    data=all_shuffles_wcorr_df, x=\"epoch_idx\", y=\"shuffle_wcorr\", hue=\"decoder_idx\",\n",
    "    native_scale=True, zorder=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89aac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pd.DataFrame(_out_shuffle_wcorr_Zscore_val, columns=['LongLR', 'LongRL', 'ShortLR', 'ShortRL'])\n",
    "\n",
    "# _out_wcorr_ZScore_LR_dict = dict(zip(['LongLR', 'LongRL', 'ShortLR', 'ShortRL'], [v for v in _out_shuffle_wcorr_Zscore_val.T]))\n",
    "# _out_wcorr_ZScore_LR_dict\n",
    "\n",
    "figure_identifier: str = f\"wcorr (best dir selected for each event) fig\"\n",
    "fig = plt.figure(num=figure_identifier, clear=True, figsize=(6, 2))\n",
    "# for time_bin_size in time_bin_sizes:\n",
    "#     df_tbs = pre_delta_df[pre_delta_df['time_bin_size']==time_bin_size]\n",
    "#     df_tbs['P_Long'].hist(alpha=0.5, label=str(time_bin_size)) \n",
    "    \n",
    "\n",
    "n_shuffles: int = wcorr_ripple_shuffle.n_completed_shuffles\n",
    "print(f'n_shuffles')\n",
    "\n",
    "_out_dfs = []\n",
    "# for i, (name, v) in enumerate(total_n_shuffles_more_extreme_than_real_dict.items()):\n",
    "# for i, (name, v) in enumerate(_out_p_dict.items()):\n",
    "# for i, (name, v) in enumerate(_out_shuffle_wcorr_arr_ZScores_LR_dict.items()):\n",
    "for i, (name, v) in enumerate(_out_wcorr_ZScore_LR_dict.items()):\n",
    "\n",
    "    # if i == 0:\n",
    "    assert np.shape(epoch_start_t) == np.shape(_out_shuffle_wcorr_ZScore_LONG)\n",
    "    assert np.shape(epoch_start_t) == np.shape(_out_shuffle_wcorr_ZScore_SHORT)\n",
    "    # curr_is_valid_epoch_shuffle_indicies = np.any(valid_shuffle_indicies[:,:,i]) # (n_shuffles, n_epochs)\n",
    "    # curr_t = np.squeeze(epoch_start_t[curr_is_valid_epoch_shuffle_indicies])\n",
    "    curr_t = np.squeeze(epoch_start_t)\n",
    "    print(f'np.shape(curr_t): {np.shape(curr_t)}')\n",
    "    print(f'np.shape(v): {np.shape(v)}')\n",
    "    curr_shuffle_wcorr_arr = wcorr_ripple_shuffle.all_shuffles_wcorr_array[:,:,i] # (n_shuffles, n_epochs)\n",
    "\n",
    "    # curr_shuffle_wcorr_df[name] = v\n",
    "    # curr_shuffle_wcorr_df = pd.DataFrame(np.hstack([curr_shuffle_wcorr_arr, np.repeat(i, n_shuffles)])) # , columns=[]\n",
    "\n",
    "    n_shuffles, n_epochs = np.shape(curr_shuffle_wcorr_arr)\n",
    "    print(f\"{n_shuffles = }, {n_epochs = }\")\n",
    "    # curr_shuffle_wcorr_df = pd.DataFrame(curr_shuffle_wcorr_arr) # , columns=[]\n",
    "    # curr_shuffle_wcorr_df = pd.DataFrame(np.hstack([np.atleast_2d(np.repeat(i, n_shuffles)).T, curr_shuffle_wcorr_arr]), columns=(['epoch_idx'] + [f'{int(i)}' for i in np.arange(n_epochs)]))\n",
    "    # curr_shuffle_wcorr_df = pd.DataFrame(np.hstack([np.atleast_2d(np.repeat(i, n_shuffles)).T, np.atleast_2d(np.arange(n_shuffles)).T, curr_shuffle_wcorr_arr]), columns=(['epoch_idx', 'shuffle_idx'] + [f'{int(i)}' for i in np.arange(n_epochs)]))\n",
    "\n",
    "    curr_shuffle_wcorr_df = pd.DataFrame(np.hstack([np.atleast_2d(np.repeat(i, n_shuffles)).T, np.atleast_2d(np.arange(n_shuffles)).T]), columns=(['epoch_idx', 'shuffle_idx']))\n",
    "\n",
    "    epoch_id_sequence = np.array([f'{int(i)}' for i in np.arange(n_epochs)])\n",
    "\n",
    "    curr_shuffle_wcorr_df['epoch_idx'] = np.tile(epoch_id_sequence, n_shuffles)\n",
    "    \n",
    "    # curr_shuffle_wcorr_arr\n",
    "    # \n",
    "    curr_shuffle_wcorr_df['epoch_idx'] = curr_shuffle_wcorr_df['epoch_idx'].astype(int)\n",
    "    curr_shuffle_wcorr_df['shuffle_idx'] = curr_shuffle_wcorr_df['shuffle_idx'].astype(int)\n",
    "    curr_shuffle_wcorr_df['track_id'] = name\n",
    "    # curr_shuffle_wcorr_df\n",
    "\n",
    "    _out_dfs.append(curr_shuffle_wcorr_df)\n",
    "    \n",
    "    # _flat_v = np.nanmean(v, axis=0)\n",
    "    # _flat_v = np.abs(v)\n",
    "    # _flat_v = v\n",
    "    # _temp_df = pd.DataFrame({'epoch_start_t': curr_t, 'p': v})\n",
    "    # _temp_df = pd.DataFrame({'epoch_start_t': curr_t, 'flat_Z_corr': _flat_v})\n",
    "    # plt.scatter(np.arange(np.shape(v)[0]), v, label=name)\n",
    "    # plt.scatter(epoch_start_t, _flat_v, label=name)\n",
    "\n",
    "    # _temp_df.hist(column='flat_Z_corr', alpha=0.5, label=str(name)) \n",
    "\n",
    "    # plot_histograms('Laps', 'One Session', several_time_bin_sizes_time_bin_laps_df, \"several\")\n",
    "\n",
    "\n",
    "all_shuffles_wcorr_df: pd.DataFrame = pd.concat(_out_dfs)\n",
    "all_shuffles_wcorr_df\n",
    "\n",
    "\n",
    "all_shuffles_wcorr_df['epoch_idx'].unique()\n",
    "# plt.title(f'{figure_identifier}')\n",
    "# plt.xlabel('time')\n",
    "# plt.ylabel('Z-scored Wcorr')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c401f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how would I represent the results of 1000 shuffles for each epoch. (n_shuffles, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d395c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_shuffle_wcorr_df.co\n",
    "\n",
    "curr_shuffle_wcorr_df.columns[-1] = 'epoch_idx'\n",
    "# curr_shuffle_wcorr_df.set_axis(labels=['n_shuffles', 'n_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff2f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_shuffle_wcorr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e38ce8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aed53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "\n",
    "# \"Melt\" the dataset to \"long-form\" or \"tidy\" representation\n",
    "iris = iris.melt(id_vars=\"species\", var_name=\"measurement\")\n",
    "\n",
    "# Initialize the figure\n",
    "f, ax = plt.subplots()\n",
    "sns.despine(bottom=True, left=True)\n",
    "\n",
    "# Show each observation with a scatterplot\n",
    "sns.stripplot(\n",
    "    data=iris, x=\"value\", y=\"measurement\", hue=\"species\",\n",
    "    dodge=True, alpha=.25, zorder=1, legend=False,\n",
    ")\n",
    "\n",
    "# Show the conditional means, aligning each pointplot in the\n",
    "# center of the strips by adjusting the width allotted to each\n",
    "# category (.8 by default) by the number of hue levels\n",
    "sns.pointplot(\n",
    "    data=iris, x=\"value\", y=\"measurement\", hue=\"species\",\n",
    "    dodge=.8 - .8 / 3, palette=\"dark\", errorbar=None,\n",
    "    markers=\"d\", markersize=4, linestyle=\"none\",\n",
    ")\n",
    "\n",
    "# Improve the legend\n",
    "sns.move_legend(\n",
    "    ax, loc=\"lower right\", ncol=3, frameon=True, columnspacing=1, handletextpad=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35184d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_shuffle_wcorr_ZScore_LONG\n",
    "_out_shuffle_wcorr_ZScore_SHORT\n",
    "epoch_start_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b378dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "common_kwargs = dict(ylim=(0,1), hue='time_bin_size') # , marginal_kws=dict(bins=25, fill=True)\n",
    "# sns.jointplot(data=a_laps_all_epoch_bins_marginals_df, x='lap_start_t', y='P_Long', kind=\"scatter\", color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per epoch') #color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per epoch')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per time bin')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per time bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcorr_ripple_shuffle_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2943319",
   "metadata": {},
   "outputs": [],
   "source": [
    "pho_jointplot(data=wcorr_ripple_shuffle_all_df, x='start', y='wcorr_z_long', kind=\"scatter\", title='Ripple: wcorr long per epoch')\n",
    "pho_jointplot(data=wcorr_ripple_shuffle_all_df, x='start', y='wcorr_z_short', kind=\"scatter\", title='Ripple: wcorr short per epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_shuffle_wcorr_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_decoder_ripple_weighted_corr_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1384c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.logical_not(a_decoder_ripple_weighted_corr_df.notna()))\n",
    "\n",
    "a_shuffle_is_more_extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c84388",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoder_ripple_weighted_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49403abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_decoder_ripple_weighted_corr_df_dicts = np.hstack([output_extracted_result_tuples[i][-1] for i, v in enumerate(output_extracted_result_tuples)])\n",
    "output_decoder_ripple_weighted_corr_df_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd4cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df), (decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict) = _subfn_compute_complete_df_metrics(directional_merged_decoders_result, track_templates, decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                                                                                            decoder_laps_df_dict=deepcopy(decoder_laps_weighted_corr_df_dict), decoder_ripple_df_dict=deepcopy(decoder_ripple_weighted_corr_df_dict), active_df_columns = ['wcorr'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a82089d",
   "metadata": {},
   "source": [
    "# 🎯🟢 2024-05-29 - Trial-by-Trial Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f3cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent\n",
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrialByTrialActivityResult\n",
    "\n",
    "# # spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "# rank_order_results = global_computation_results.computed_data['RankOrder'] # : \"RankOrderComputationsContainer\"\n",
    "# minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "# # included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "# directional_laps_results: DirectionalLapsResult = global_computation_results.computed_data['DirectionalLaps']\n",
    "# track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# # long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = track_templates.get_decoders()\n",
    "\n",
    "# # Unpack all directional variables:\n",
    "# ## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "# long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "# # Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "# long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "\n",
    "## INPUTS: curr_active_pipeline, track_templates, global_epoch_name, (long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj)\n",
    "any_decoder_neuron_IDs: NDArray = deepcopy(track_templates.any_decoder_neuron_IDs)\n",
    "# long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "# ## Directional Trial-by-Trial Activity:\n",
    "if 'pf1D_dt' not in curr_active_pipeline.computation_results[global_epoch_name].computed_data:\n",
    "    # if `KeyError: 'pf1D_dt'` recompute\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['pfdt_computation'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "active_pf_1D_dt: PfND_TimeDependent = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf1D_dt'])\n",
    "# active_pf_2D_dt: PfND_TimeDependent = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf2D_dt'])\n",
    "\n",
    "active_pf_dt: PfND_TimeDependent = active_pf_1D_dt\n",
    "# Limit only to the placefield aclus:\n",
    "active_pf_dt = active_pf_dt.get_by_id(ids=any_decoder_neuron_IDs)\n",
    "\n",
    "# active_pf_dt: PfND_TimeDependent = deepcopy(active_pf_2D_dt) # 2D\n",
    "long_LR_name, long_RL_name, short_LR_name, short_RL_name = track_templates.get_decoder_names()\n",
    "\n",
    "directional_lap_epochs_dict = dict(zip((long_LR_name, long_RL_name, short_LR_name, short_RL_name), (long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj)))\n",
    "directional_active_lap_pf_results_dicts: Dict[str, TrialByTrialActivity] = TrialByTrialActivity.directional_compute_trial_by_trial_correlation_matrix(active_pf_dt=active_pf_dt, directional_lap_epochs_dict=directional_lap_epochs_dict, included_neuron_IDs=any_decoder_neuron_IDs)\n",
    "\n",
    "## OUTPUTS: directional_active_lap_pf_results_dicts\n",
    "a_trial_by_trial_result: TrialByTrialActivityResult = TrialByTrialActivityResult(any_decoder_neuron_IDs=any_decoder_neuron_IDs,\n",
    "                                                                                active_pf_dt=active_pf_dt,\n",
    "                                                                                directional_lap_epochs_dict=directional_lap_epochs_dict,\n",
    "                                                                                directional_active_lap_pf_results_dicts=directional_active_lap_pf_results_dicts,\n",
    "                                                                                is_global=True)  # type: Tuple[Tuple[Dict[str, Any], Dict[str, Any]], Dict[str, BasePositionDecoder], Any]\n",
    "\n",
    "a_trial_by_trial_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71633da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_trial_by_trial_result.directional_active_lap_pf_results_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62264383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_trial_by_trial_result.active_pf_dt.plot_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49cbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af83d268",
   "metadata": {},
   "outputs": [],
   "source": [
    "aTbyT:TrialByTrialActivity = a_trial_by_trial_result.directional_active_lap_pf_results_dicts['long_LR']\n",
    "aTbyT.C_trial_by_trial_correlation_matrix.shape # (40, 21, 21)\n",
    "aTbyT.z_scored_tuning_map_matrix.shape # (21, 40, 57) (n_epochs, n_neurons, n_pos_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14366a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aTbyT.neuron_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_xbins = len(active_pf_dt.xbin_centers)\n",
    "n_xbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5108508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aTbyT.z_scored_tuning_map_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b29c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_trial_by_trial_result.active_pf_dt.historical_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308530d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pf2D_dt.historical_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be70f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "\n",
    "saveData('test_a_trial_by_trial_result_data.pkl', a_trial_by_trial_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038c7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_a_trial_by_trial_result = loadData('test_a_trial_by_trial_result_data.pkl')\n",
    "loaded_a_trial_by_trial_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e425b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b1025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa979505",
   "metadata": {},
   "source": [
    "# 2024-06-25 - Advanced Time-dependent decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56621c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directional Versions: 'long_LR':\n",
    "from neuropy.core.epoch import subdivide_epochs, ensure_dataframe\n",
    "\n",
    "## INPUTS: long_LR_epochs_obj, long_LR_results\n",
    "\n",
    "a_pf1D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf1D_dt)\n",
    "a_pf2D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf2D_dt)\n",
    "\n",
    "# Example usage\n",
    "df: pd.DataFrame = ensure_dataframe(deepcopy(long_LR_epochs_obj)) \n",
    "df['epoch_type'] = 'lap'\n",
    "df['interval_type_id'] = 666\n",
    "\n",
    "subdivide_bin_size = 0.200  # Specify the size of each sub-epoch in seconds\n",
    "subdivided_df: pd.DataFrame = subdivide_epochs(df, subdivide_bin_size)\n",
    "# print(subdivided_df)\n",
    "\n",
    "## Evolve the ratemaps:\n",
    "_a_pf1D_dt_snapshots = a_pf1D_dt.batch_snapshotting(subdivided_df, reset_at_start=True)\n",
    "_a_pf2D_dt_snapshots = a_pf2D_dt.batch_snapshotting(subdivided_df, reset_at_start=True)\n",
    "# a_pf2D_dt.plot_ratemaps_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf75670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "\n",
    "active_pf_2D = deepcopy(a_pf2D_dt)\n",
    "figure_format_config = {}\n",
    "out_all_pf_2D_pyqtgraph_binned_image_fig = display_all_pf_2D_pyqtgraph_binned_image_rendering(active_pf_2D, figure_format_config) # output is BasicBinnedImageRenderingWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d1ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_all_pf_2D_pyqtgraph_binned_image_fig.params.scrollability_mode.is_scrollable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e44aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name in out_all_pf_2D_pyqtgraph_binned_image_fig.plot_names:\n",
    "    local_plots_data = out_all_pf_2D_pyqtgraph_binned_image_fig.plots_data[name]\n",
    "    local_plots = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[name]\n",
    "    newPlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[name].mainPlotItem\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563e5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_all_pf_2D_pyqtgraph_binned_image_fig.toolBarArea\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5523071",
   "metadata": {},
   "source": [
    "# 2024-05-30 - Continuous decoded posterior output videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "spikes_df = directional_decoders_decode_result.spikes_df\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f3ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict = directional_decoders_decode_result.most_recent_continuously_decoded_dict\n",
    "pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "pseudo2D_decoder_continuously_decoded_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b664b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('long_LR', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.media_output_helpers import save_array_as_video\n",
    "\n",
    "\n",
    "def save_posterior_to_video(a_decoder_continuously_decoded_result: DecodedFilterEpochsResult, result_name: str='a_decoder_continuously_decoded_result'):\n",
    "    a_p_x_given_n = deepcopy(a_decoder_continuously_decoded_result.p_x_given_n_list[0]) # (57, 4, 83755) (n_x_bins, n_decoders, n_time_bins)\n",
    "    if np.ndim(a_p_x_given_n) > 2:\n",
    "        n_x_bins, n_decoders, n_time_bins = np.shape(a_p_x_given_n)\n",
    "        transpose_axes_tuple = (2, 1, 0,)\n",
    "    else:\n",
    "        assert np.ndim(a_p_x_given_n) == 2, f\"np.ndim(a_p_x_given_n): {np.ndim(a_p_x_given_n)}\"\n",
    "        n_x_bins, n_time_bins = np.shape(a_p_x_given_n)\n",
    "        a_p_x_given_n = a_p_x_given_n[:, np.newaxis, :]\n",
    "        assert np.ndim(a_p_x_given_n) == 3, f\"np.ndim(a_p_x_given_n): {np.ndim(a_p_x_given_n)}\"\n",
    "        # transpose_axes_tuple = (1, 0,)\n",
    "        transpose_axes_tuple = (2, 1, 0,)\n",
    "    \n",
    "        a_p_x_given_n = np.tile(a_p_x_given_n, (1, 8, 1,))\n",
    "        # display(a_p_x_given_n)\n",
    "    # time_window_centers = deepcopy(a_decoder_continuously_decoded_result.time_window_centers[0])\n",
    "\n",
    "    ## get tiny portion just to test\n",
    "    # a_p_x_given_n = a_p_x_given_n[:, :, :2000]\n",
    "    # a_p_x_given_n\n",
    "\n",
    "    # a_p_x_given_n = np.reshape(a_p_x_given_n, (n_time_bins, n_decoders, n_x_bins))\n",
    "    a_p_x_given_n = np.transpose(a_p_x_given_n, transpose_axes_tuple)\n",
    "    # display(a_p_x_given_n)\n",
    "\n",
    "    decoding_realtime_FPS: float = 1.0 / float(a_decoder_continuously_decoded_result.decoding_time_bin_size)\n",
    "    print(f'decoding_realtime_FPS: {decoding_realtime_FPS}')\n",
    "    ## save video\n",
    "    video_out_path = save_array_as_video(array=a_p_x_given_n, video_filename=f'output/videos/{result_name}.avi', isColor=False, fps=decoding_realtime_FPS)\n",
    "    print(f'video_out_path: {video_out_path}')\n",
    "    # reveal_in_system_file_manager(video_out_path)\n",
    "    return video_out_path\n",
    "\n",
    "\n",
    "a_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('long_LR', None)\n",
    "save_posterior_to_video(a_decoder_continuously_decoded_result=a_decoder_continuously_decoded_result, result_name='continuous_long_LR')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca8a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_posterior_to_video(a_decoder_continuously_decoded_result=pseudo2D_decoder_continuously_decoded_result, result_name='continuous_pseudo2D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f828c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: global_results, global_epoch_name\n",
    "\n",
    "# Get the decoders from the computation result:\n",
    "active_one_step_decoder = global_results['pf2D_Decoder']\n",
    "active_two_step_decoder = global_results.get('pf2D_TwoStepDecoder', None)\n",
    "if active_two_step_decoder is None:\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['position_decoding_two_step'], computation_kwargs_list=[{}], enabled_filter_names=[global_epoch_name, global_LR_name, global_RL_name], fail_on_exception=True, debug_print=False)\n",
    "    active_two_step_decoder = global_results.get('pf2D_TwoStepDecoder', None)\n",
    "    assert active_two_step_decoder is not None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pyphocorehelpers.plotting.media_output_helpers import get_array_as_image\n",
    "from pyphocorehelpers.plotting.media_output_helpers import save_array_as_video\n",
    "\n",
    "def colormap_and_save_as_video(array, video_filename='output.avi', fps=30.0, colormap=cv2.COLORMAP_VIRIDIS):\n",
    "    # array = ((array - array.min()) / (array.max() - array.min()) * 255).astype(np.uint8)\n",
    "    # color_array = cv2.applyColorMap(array, colormap)\n",
    "    return save_array_as_video(array, video_filename=video_filename, fps=fps, isColor=True, colormap=colormap)\n",
    "\n",
    "# image = get_array_as_image(img_data, desired_height=100, desired_width=None, skip_img_normalization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_input_posterior = deepcopy(active_two_step_decoder.p_x_given_n_and_x_prev)\n",
    "result_name: str = f'two_step_maze_all'\n",
    "\n",
    "# an_input_posterior = deepcopy(active_one_step_decoder.p_x_given_n)\n",
    "# result_name: str = f'one_step_2D_maze_all'\n",
    "\n",
    "\n",
    "n_x_bins, n_y_bins, n_time_bins = np.shape(an_input_posterior)\n",
    "transpose_axes_tuple = (2, 1, 0,)\n",
    "an_input_posterior = np.transpose(an_input_posterior, transpose_axes_tuple)\n",
    "decoding_realtime_FPS: float = 1.0 / float(active_one_step_decoder.time_bin_size)\n",
    "print(f'decoding_realtime_FPS: {decoding_realtime_FPS}')\n",
    "## save video\n",
    "video_out_path = save_array_as_video(array=an_input_posterior, video_filename=f'output/videos/{result_name}.avi', isColor=True, fps=decoding_realtime_FPS, colormap=cv2.COLORMAP_VIRIDIS)\n",
    "# video_out_path = colormap_and_save_as_video(array=an_input_posterior, video_filename=f'output/videos/{result_name}.avi', fps=decoding_realtime_FPS)\n",
    "\n",
    "print(f'video_out_path: {video_out_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc44dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['position_decoding_two_step'], computation_kwargs_list=[{}], enabled_filter_names=[global_epoch_name, global_LR_name, global_RL_name], fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96151def",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "time_binned_position_df: pd.DataFrame = global_results.get('extended_stats', {}).get('time_binned_position_df', None)\n",
    "time_binned_position_df\n",
    "# active_measured_positions = computation_result.sess.position.to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c51a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cde2025",
   "metadata": {},
   "source": [
    "# 2024-06-07 - PhoDiba2023Paper figure generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed9ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import main_complete_figure_generations\n",
    "\n",
    "main_complete_figure_generations(curr_active_pipeline, save_figure=True, save_figures_only=True, enable_default_neptune_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327c41f7",
   "metadata": {},
   "source": [
    "# 2024-06-10 - Across Sessions Bar Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae95fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "## long_short_post_decoding:\n",
    "inst_spike_rate_groups_result: InstantaneousSpikeRateGroupsComputation = curr_active_pipeline.global_computation_results.computed_data.long_short_inst_spike_rate_groups\n",
    "inst_spike_rate_groups_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import InstantaneousSpikeRateGroupsComputation\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_instantaneous_spike_rates_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "instantaneous_time_bin_size_seconds: float = 0.0002 # 10ms\n",
    "save_pickle = False\n",
    "save_hdf = True\n",
    "save_across_session_hdf = True\n",
    "\n",
    "_across_session_results_extended_dict = {}\n",
    "## Combine the output of `compute_and_export_session_instantaneous_spike_rates_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_instantaneous_spike_rates_completion_function(a_dummy, None,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tacross_session_results_extended_dict=_across_session_results_extended_dict, instantaneous_time_bin_size_seconds=instantaneous_time_bin_size_seconds,\n",
    "                                                save_hdf=save_hdf, save_pickle=save_pickle, save_across_session_hdf=save_across_session_hdf, #return_full_decoding_results=return_full_decoding_results, desired_shared_decoding_time_bin_sizes=desired_shared_decoding_time_bin_sizes,\n",
    "                                                )\n",
    "\n",
    "# '_perform_long_short_instantaneous_spike_rate_groups_analysis'\n",
    "# global_computation_results = curr_active_pipeline.global_computation_results\n",
    "# global_computation_results.get('computation_config', {})\n",
    "\n",
    "\n",
    "# instantaneous_time_bin_size_seconds: float = global_computation_results.computation_config.instantaneous_time_bin_size_seconds # 0.01 # 10ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a7920",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict\n",
    "\n",
    "\n",
    "## Specify the output file:\n",
    "common_file_path = Path('output/active_across_session_scatter_plot_results.h5')\n",
    "print(f'common_file_path: {common_file_path}')\n",
    "InstantaneousFiringRatesDataframeAccessor.add_results_to_inst_fr_results_table(curr_active_pipeline, common_file_path, file_mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible(curr_key='pipeline', curr_value=_out, max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a979a",
   "metadata": {},
   "source": [
    "# New Replay Events from Diba-2009-style quiescent period detection followed by active period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0cf6c79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function(curr_session_context: kdiba_gor01_one_2006-6-09_1-22-43, curr_session_basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43, ...)\n",
      "n_neurons: 46, min_num_active_neurons: 10\n",
      "saved out newly computed epochs to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2006-6-09_1-22-43.PHONEW.evt\".\n",
      "completed replay extraction, have: ['initial_loaded', 'normal_computed', 'diba_quiescent_method_replay_epochs', 'diba_evt_file']\n",
      "completed replay extraction, have: ['initial_loaded', 'normal_computed', 'diba_quiescent_method_replay_epochs', 'diba_evt_file']\n",
      "performing comp for \"initial_loaded\"...\n",
      "\treplay_epochs_key: initial_loaded: custom_suffix: \"_withOldestImportedReplays-qclu_XX-frateThresh_0.1\"\n",
      "\tgood_filename: 2006-6-09_1-22-43_withOldestImportedReplays-qclu_XX-frateThresh_0.1\n",
      "saved out newly computed epochs of type \"initial_loaded to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2006-6-09_1-22-43_withOldestImportedReplays-qclu_XX-frateThresh_0.PHONEW.evt\".\n",
      "performing comp for \"normal_computed\"...\n",
      "\treplay_epochs_key: normal_computed: custom_suffix: \"_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0\"\n",
      "\tgood_filename: 2006-6-09_1-22-43_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0\n",
      "saved out newly computed epochs of type \"normal_computed to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2006-6-09_1-22-43_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.PHONEW.evt\".\n",
      "performing comp for \"diba_quiescent_method_replay_epochs\"...\n",
      "\treplay_epochs_key: diba_quiescent_method_replay_epochs: custom_suffix: \"_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0\"\n",
      "\tgood_filename: 2006-6-09_1-22-43_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0\n",
      "saved out newly computed epochs of type \"diba_quiescent_method_replay_epochs to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2006-6-09_1-22-43_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.PHONEW.evt\".\n",
      "performing comp for \"diba_evt_file\"...\n",
      "\treplay_epochs_key: diba_evt_file: custom_suffix: \"_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0\"\n",
      "\tgood_filename: 2006-6-09_1-22-43_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0\n",
      "saved out newly computed epochs of type \"diba_evt_file to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2006-6-09_1-22-43_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.PHONEW.evt\".\n",
      "=====================================>> Starting computations for the 4 new epochs...\n",
      "\t=====================================>> performing comp for \"initial_loaded\"...\n",
      "\treplay_epochs_key: initial_loaded: custom_suffix: \"_withOldestImportedReplays-qclu_XX-frateThresh_0.1\"\n",
      "\tcurr_BATCH_DATE_TO_USE: \"2024-07-10_Apogee_withOldestImportedReplays-qclu_XX-frateThresh_0.1\"\n",
      "\tWARNING: should_suppress_errors: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_18-07-15.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:==========================================================================================\n",
      "========== Logger INIT \"2024-07-10_18-07-15.Apogee.kdiba.gor01.one.2006-6-09_1-22-43\" ==============================\n",
      "INFO:2024-07-10_18-07-15.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:NeuropyPipeline.__setstate__(state=\"{'pipeline_name': 'kdiba_pipeline', 'session_data_type': 'kdiba', '_stage': <pyphoplacecellanalysis.General.Pipeline.Stages.Display.DisplayPipelineStage object at 0x00000218859C03D0>}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_logger(full_logger_string=\"2024-07-10_18-07-15.Apogee.kdiba.gor01.one.2006-6-09_1-22-43\", file_logging_dir: None):\n",
      "custom_suffix: \"_withOldestImportedReplays-qclu_XX-frateThresh_0.1\"\n",
      "Using custom suffix: \"_withOldestImportedReplays-qclu_XX-frateThresh_0.1\" - additional_session_context: \"_withOldestImportedReplays-qclu_XX-frateThresh_0.1\"\n",
      "did_change: True\n",
      "custom_save_filenames: {'pipeline_pkl': 'loadedSessPickle_withOldestImportedReplays-qclu_XX-frateThresh_0.1.pkl', 'global_computation_pkl': 'global_computation_results_withOldestImportedReplays-qclu_XX-frateThresh_0.1.pkl', 'pipeline_h5': 'pipeline_withOldestImportedReplays-qclu_XX-frateThresh_0.1.h5'}\n",
      "replay epochs changed!\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['merged_directional_placefields', 'perform_rank_order_shuffle_analysis'], ...)...\n",
      "\trun_specific_computations_single_context(including only 2 out of 16 registered computation functions): active_computation_functions: [<function DirectionalPlacefieldGlobalComputationFunctions._build_merged_directional_placefields at 0x0000021388D969D0>, <function RankOrderGlobalComputationFunctions.perform_rank_order_shuffle_analysis at 0x000002139891D4C0>]...\n",
      "Performing _execute_computation_functions(...) with 2 registered_computation_functions...\n",
      "Executing [0/2]: <function DirectionalPlacefieldGlobalComputationFunctions._build_merged_directional_placefields at 0x00000218948AAA60>\n",
      "skipping lap recomputation because laps_decoding_time_bin_size == None\n",
      "WARN: ripple_decoding_time_bin_size 0.025 < min_possible_time_bin_size (0.053). This used to be enforced but continuing anyway.\n",
      "Executing [1/2]: <function RankOrderGlobalComputationFunctions.perform_rank_order_shuffle_analysis at 0x00000218948AA700>\n",
      "WARN: perform_rank_order_shuffle_analysis(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "####> perform_rank_order_shuffle_analysis(..., num_shuffles=25)\n",
      "\t##> computing Ripple rank-order shuffles:\n",
      "ripple_evts_paired_tests: [TtestResult(statistic=1.0019970685918687, pvalue=0.317259062592609, df=265), TtestResult(statistic=0.2651684903299394, pvalue=0.7910858166899669, df=265)]\n",
      "\tdone. building global result.\n",
      "n_valid_shuffles: 25\n",
      "combined_variable_names: ['long_LR_pearson', 'long_RL_pearson', 'short_LR_spearman', 'long_LR_spearman', 'short_RL_pearson', 'short_LR_pearson', 'long_RL_spearman', 'short_RL_spearman']\n",
      "combined_variable_z_score_column_names: ['long_LR_pearson_Z', 'long_RL_pearson_Z', 'short_LR_spearman_Z', 'long_LR_spearman_Z', 'short_RL_pearson_Z', 'short_LR_pearson_Z', 'long_RL_spearman_Z', 'short_RL_spearman_Z']\n",
      "done!\n",
      "\tdone. building global result.\n",
      "< done with `perform_rank_order_shuffle_analysis(...)`\n",
      "\t all computations complete! (Computed 2 with no errors!.\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], ...)...\n",
      "\trun_specific_computations_single_context(including only 2 out of 16 registered computation functions): active_computation_functions: [<function DirectionalPlacefieldGlobalComputationFunctions._decode_and_evaluate_epochs_using_directional_decoders at 0x0000021388D96AF0>, <function DirectionalPlacefieldGlobalComputationFunctions._decoded_epochs_heuristic_scoring at 0x0000021388D96B80>]...\n",
      "Performing _execute_computation_functions(...) with 2 registered_computation_functions...\n",
      "Executing [0/2]: <function DirectionalPlacefieldGlobalComputationFunctions._decode_and_evaluate_epochs_using_directional_decoders at 0x00000214FDE17430>\n",
      "laps_decoding_time_bin_size: 0.25, ripple_decoding_time_bin_size: 0.025, pos_bin_size: 3.8054171165052444\n",
      "laps_decoding_time_bin_size: 0.25, ripple_decoding_time_bin_size: 0.025, pos_bin_size: 3.8054171165052444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "Performance: Radon Transform:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 16/84\n",
      "\tagreeing_rows_ratio: 0.19047619047619047\n",
      "\tPerformance: Ripple: Radon Transform:\n",
      "agreeing_rows_count/num_total_epochs: 32/412\n",
      "\tagreeing_rows_ratio: 0.07766990291262135\n",
      "WARNING: less than two array elements for an_epoch_idx: 136, a_pearson_v will be NaN for a_peak_x_col_name: long_RL_pf_peak_x, a_decoder_neuron_IDs: [  2   5   6   8   9  11  15  16  18  19  24  25  26  29  30  31  33  34  35  39  40  43  44  47  51  52  53  56  58  60  61  66  68  72  75  77  79  80  81  82  83  84  85  86  87  89  90  92  93  98 101 102 104], min_num_required_unique_aclus: 17\n",
      "WARNING: hit NaN a_pearson_v: nan for a_peak_x_col_name: long_RL_pf_peak_x, a_decoder_neuron_IDs: [  2   5   6   8   9  11  15  16  18  19  24  25  26  29  30  31  33  34  35  39  40  43  44  47  51  52  53  56  58  60  61  66  68  72  75  77  79  80  81  82  83  84  85  86  87  89  90  92  93  98 101 102 104], min_num_required_unique_aclus: 17\n",
      "WARNING: less than two array elements for an_epoch_idx: 136, a_pearson_v will be NaN for a_peak_x_col_name: short_RL_pf_peak_x, a_decoder_neuron_IDs: [  2   5   6   8   9  11  15  16  18  19  24  25  26  29  30  31  33  34  35  39  40  43  44  47  51  52  53  56  58  60  61  66  68  72  75  77  79  80  81  82  83  84  85  86  87  89  90  92  93  98 101 102 104], min_num_required_unique_aclus: 17\n",
      "WARNING: hit NaN a_pearson_v: nan for a_peak_x_col_name: short_RL_pf_peak_x, a_decoder_neuron_IDs: [  2   5   6   8   9  11  15  16  18  19  24  25  26  29  30  31  33  34  35  39  40  43  44  47  51  52  53  56  58  60  61  66  68  72  75  77  79  80  81  82  83  84  85  86  87  89  90  92  93  98 101 102 104], min_num_required_unique_aclus: 17\n",
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 64/84\n",
      "\tagreeing_rows_ratio: 0.7619047619047619\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 145/412\n",
      "\tagreeing_rows_ratio: 0.35194174757281554\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 75/84\n",
      "\tagreeing_rows_ratio: 0.8928571428571429\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 127/412\n",
      "\tagreeing_rows_ratio: 0.308252427184466\n",
      "Executing [1/2]: <function DirectionalPlacefieldGlobalComputationFunctions._decoded_epochs_heuristic_scoring at 0x00000214F26C6F70>\n",
      "\t all computations complete! (Computed 2 with no errors!.\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(curr_session_context: kdiba_gor01_one_2006-6-09_1-22-43, curr_session_basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43, ...)\n",
      "\tactive_context: kdiba_gor01_one_2006-6-09_1-22-43__withOldestImportedReplays-qclu_XX-frateThresh_0.1\n",
      "\tsession_ctxt_key: kdiba|gor01|one|2006-6-09_1-22-43|_withOldestImportedReplays-qclu_XX-frateThresh_0.1\n",
      "\tCURR_BATCH_OUTPUT_PREFIX: 2024-07-10_Apogee_withOldestImportedReplays-qclu_XX-frateThresh_0.1-2006-6-09_1-22-43-_withOldestImportedReplays-qclu_XX-frateThresh_0.1\n",
      "\tout_path_str: \"2024-07-10_Apogee_withOldestImportedReplays-qclu_XX-frateThresh_0.1-2006-6-09_1-22-43-_withOldestImportedReplays-qclu_XX-frateThresh_0.1_time_bin_size_sweep_results.h5\"\n",
      "\tout_path: \"K:\\scratch\\collected_outputs\\2024-07-10_Apogee_withOldestImportedReplays-qclu_XX-frateThresh_0.1-2006-6-09_1-22-43-_withOldestImportedReplays-qclu_XX-frateThresh_0.1_time_bin_size_sweep_results.h5\"\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\ta_sweep_dict: {'desired_laps_decoding_time_bin_size': 1.5, 'desired_ripple_decoding_time_bin_size': 0.01, 'use_single_time_bin_per_epoch': False, 'minimum_event_duration': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.02).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.02.\t412 remain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning: object name is not a valid Python identifier: 'kdiba|gor01|one|2006-6-09_1-22-43|_withOldestImportedReplays-qclu_XX-frateThresh_0.1'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '1.5'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '0.01'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: less than two array elements for an_epoch_idx: 136, a_pearson_v will be NaN for a_peak_x_col_name: long_RL_pf_peak_x, a_decoder_neuron_IDs: [  2   5   6   8   9  11  15  16  18  19  24  25  26  29  30  31  33  34  35  39  40  43  44  47  51  52  53  56  58  60  61  66  68  72  75  77  79  80  81  82  83  84  85  86  87  89  90  92  93  98 101 102 104], min_num_required_unique_aclus: 17\n",
      "WARNING: hit NaN a_pearson_v: nan for a_peak_x_col_name: long_RL_pf_peak_x, a_decoder_neuron_IDs: [  2   5   6   8   9  11  15  16  18  19  24  25  26  29  30  31  33  34  35  39  40  43  44  47  51  52  53  56  58  60  61  66  68  72  75  77  79  80  81  82  83  84  85  86  87  89  90  92  93  98 101 102 104], min_num_required_unique_aclus: 17\n",
      "WARNING: less than two array elements for an_epoch_idx: 136, a_pearson_v will be NaN for a_peak_x_col_name: short_RL_pf_peak_x, a_decoder_neuron_IDs: [  2   5   6   8   9  11  15  16  18  19  24  25  26  29  30  31  33  34  35  39  40  43  44  47  51  52  53  56  58  60  61  66  68  72  75  77  79  80  81  82  83  84  85  86  87  89  90  92  93  98 101 102 104], min_num_required_unique_aclus: 17\n",
      "WARNING: hit NaN a_pearson_v: nan for a_peak_x_col_name: short_RL_pf_peak_x, a_decoder_neuron_IDs: [  2   5   6   8   9  11  15  16  18  19  24  25  26  29  30  31  33  34  35  39  40  43  44  47  51  52  53  56  58  60  61  66  68  72  75  77  79  80  81  82  83  84  85  86  87  89  90  92  93  98 101 102 104], min_num_required_unique_aclus: 17\n",
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 27/84\n",
      "\tagreeing_rows_ratio: 0.32142857142857145\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 142/412\n",
      "\tagreeing_rows_ratio: 0.3446601941747573\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 72/84\n",
      "\tagreeing_rows_ratio: 0.8571428571428571\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 127/412\n",
      "\tagreeing_rows_ratio: 0.308252427184466\n",
      "\ta_sweep_dict: {'desired_laps_decoding_time_bin_size': 1.5, 'desired_ripple_decoding_time_bin_size': 0.02, 'use_single_time_bin_per_epoch': False, 'minimum_event_duration': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.02).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.02.\t412 remain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '0.02'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: less than two array elements for an_epoch_idx: 136, a_pearson_v will be NaN for a_peak_x_col_name: long_RL_pf_peak_x, a_decoder_neuron_IDs: [  2   5   6   8   9  11  15  16  18  19  24  25  26  29  30  31  33  34  35  39  40  43  44  47  51  52  53  56  58  60  61  66  68  72  75  77  79  80  81  82  83  84  85  86  87  89  90  92  93  98 101 102 104], min_num_required_unique_aclus: 17\n",
      "WARNING: hit NaN a_pearson_v: nan for a_peak_x_col_name: long_RL_pf_peak_x, a_decoder_neuron_IDs: [  2   5   6   8   9  11  15  16  18  19  24  25  26  29  30  31  33  34  35  39  40  43  44  47  51  52  53  56  58  60  61  66  68  72  75  77  79  80  81  82  83  84  85  86  87  89  90  92  93  98 101 102 104], min_num_required_unique_aclus: 17\n",
      "WARNING: less than two array elements for an_epoch_idx: 136, a_pearson_v will be NaN for a_peak_x_col_name: short_RL_pf_peak_x, a_decoder_neuron_IDs: [  2   5   6   8   9  11  15  16  18  19  24  25  26  29  30  31  33  34  35  39  40  43  44  47  51  52  53  56  58  60  61  66  68  72  75  77  79  80  81  82  83  84  85  86  87  89  90  92  93  98 101 102 104], min_num_required_unique_aclus: 17\n",
      "WARNING: hit NaN a_pearson_v: nan for a_peak_x_col_name: short_RL_pf_peak_x, a_decoder_neuron_IDs: [  2   5   6   8   9  11  15  16  18  19  24  25  26  29  30  31  33  34  35  39  40  43  44  47  51  52  53  56  58  60  61  66  68  72  75  77  79  80  81  82  83  84  85  86  87  89  90  92  93  98 101 102 104], min_num_required_unique_aclus: 17\n",
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 27/84\n",
      "\tagreeing_rows_ratio: 0.32142857142857145\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 126/412\n",
      "\tagreeing_rows_ratio: 0.3058252427184466\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 72/84\n",
      "\tagreeing_rows_ratio: 0.8571428571428571\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 134/412\n",
      "\tagreeing_rows_ratio: 0.32524271844660196\n",
      ">>\t done with kdiba_gor01_one_2006-6-09_1-22-43\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "perform_drop_computed_result(computed_data_keys_to_drop: ['SequenceBased'], config_names_includelist: None)\n",
      "\t global_computation_results.computed_data['SequenceBased'] did not exist.\n",
      "\t Dropped computation_results['maze1_odd'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze2_odd'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze_odd'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze1_even'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze2_even'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze_even'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze1_any'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze2_any'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze_any'].computed_data['SequenceBased'].\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['wcorr_shuffle_analysis'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function SequenceBasedComputationsGlobalComputationFunctions.perform_wcorr_shuffle_analysis at 0x000002139886AA60>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function SequenceBasedComputationsGlobalComputationFunctions.perform_wcorr_shuffle_analysis at 0x0000021756E26310>\n",
      "WARN: perform_wcorr_shuffle_analysis(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "perform_wcorr_shuffle_analysis(..., num_shuffles=25)\n",
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 107\n",
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_decoder_ripple_weighted_corr_arr: (107, 4)\n",
      "n_prev_completed_shuffles: 0.\n",
      "needed num_shuffles: 25.\n",
      "need desired_new_num_shuffles: 25 more shuffles.\n",
      "a_shuffle_IDXs: [35 79 18  3 34 32 39  6 66 73 41 19 29 69 28 33 30 38  8  2 40 75 57 58 52 16  0 62 21 63  5 20 17 61 78 68 51 70 36 50 45 43 64 26 13 10 12 42 74 11 31  1 27 56 47 55 60 53 48 76 67 14 46 15 23 71 24 72 59  4 22 49 65 77  7  9 54 44 25 37], a_shuffle_aclus: [ 47 104  25   5  45  43  53   9  87  97  56  26  38  91  35  44  39  52  12   4  55 100  77  79  69  23   2  83  28  84   8  27  24  82 103  90  68  92  48  67  60  58  85  33  18  14  16  57  98  15  40   3  34  75  62  72  81  70  63 101  89  19  61  20  30  93  31  95  80   6  29  66  86 102  11  13  71  59  32  51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [54 44 71 75 16  2 30 18  1 17 73 62 60  0 10 36 42 29 32 52 27 51 67  3 26  8 76  7 23 56  6 14 24 53 25 37  5 46 78 58 43 57 34 64 45 49 19 21 63 12 61 20 74 77 65 70  9 13 15 22 69 66 33 39 68 59 38 40 11 79 28 41 55 50 47 31  4 35 48 72], a_shuffle_aclus: [ 71  59  93 100  23   4  39  25   3  24  97  83  81   2  14  48  57  38  43  69  34  68  89   5  33  12 101  11  30  75   9  19  31  70  32  51   8  61 103  79  58  77  45  85  60  66  26  28  84  16  82  27  98 102  86  92  13  18  20  29  91  87  44  53  90  80  52  55  15 104  35  56  72  67  62  40   6  47  63  95]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 75 16 72 21 76 79 29 24 31 19  5 56 33 53 77  4 35 70 11  0 58 62 71 38 61  2 46 20 60 49 36 66 48 78  9 41 18 13 64 57 42 68 59 47 67  6 65 28 73 14 51 23 22 50 40 45 43 27  3 37 39 34 15 74 17 12 10  1 55 52 25 54 32  8 69 26 30 63  7], a_shuffle_aclus: [ 59 100  23  95  28 101 104  38  31  40  26   8  75  44  70 102   6  47  92  15   2  79  83  93  52  82   4  61  27  81  66  48  87  63 103  13  56  25  18  85  77  57  90  80  62  89   9  86  35  97  19  68  30  29  67  55  60  58  34   5  51  53  45  20  98  24  16  14   3  72  69  32  71  43  12  91  33  39  84  11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [65 72 48 55 44 15 35 14 36 22 16 49 37 42 51 18 23 58 69 27 59 45 54 28  0 73  4  7 29 40 38 21 34 47 66 33 63 10 46 60 70  1 76 50 13 74 62 53  9 32 11 56  3 71 30 19 25 12 77 39  2  6 52 78 26 57 31 79 61 43  5 68 20  8 24 41 75 64 67 17], a_shuffle_aclus: [ 86  95  63  72  59  20  47  19  48  29  23  66  51  57  68  25  30  79  91  34  80  60  71  35   2  97   6  11  38  55  52  28  45  62  87  44  84  14  61  81  92   3 101  67  18  98  83  70  13  43  15  75   5  93  39  26  32  16 102  53   4   9  69 103  33  77  40 104  82  58   8  90  27  12  31  56 100  85  89  24]\n",
      "a_shuffle_IDXs: [13 30 43 32 23 24 14  6 11  9 18 60 78 10 75 38 53 17 69 21 40 52 71 67 33 26 73 77 76 79 31 56 15 50 57 63  1 39 29 37 42 20 36 25 58 72 61 19  4 68 51  5 55 48 41  2  7 64 65 12 66 46 54 45 74  8 28 44 49  0 70 22 16 47 59 35 62  3 27 34], a_shuffle_aclus: [ 18  39  58  43  30  31  19   9  15  13  25  81 103  14 100  52  70  24  91  28  55  69  93  89  44  33  97 102 101 104  40  75  20  67  77  84   3  53  38  51  57  27  48  32  79  95  82  26   6  90  68   8  72  63  56   4  11  85  86  16  87  61  71  60  98  12  35  59  66   2  92  29  23  62  80  47  83   5  34  45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29  4 62 14  2 79 78 53 76 49 58 15 39 31 17 73 33 50 21 18  5 70 64 28 54  7  8 60 13 46 11 35  6 22  1 74 24 51 55 65 77 16  3 75 68 61  0 57 63 37 10 56 45 12 67 20 66 26 44 43 34 52 40 19 47 59 48 69 25 72 30 38 27 32 42 41 23 71  9 36], a_shuffle_aclus: [ 38   6  83  19   4 104 103  70 101  66  79  20  53  40  24  97  44  67  28  25   8  92  85  35  71  11  12  81  18  61  15  47   9  29   3  98  31  68  72  86 102  23   5 100  90  82   2  77  84  51  14  75  60  16  89  27  87  33  59  58  45  69  55  26  62  80  63  91  32  95  39  52  34  43  57  56  30  93  13  48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [63 17 57 64 72 16 27 50 23  2 36 43  1  8 51 58 48 55 60 11  7 42 20 33 76 14  4 61 37 62 49 68  0 31 10 32 24 75 29  6  3 30 21 13 41  5 19 73 74 56 25 59 79 12 28 26 53 15 70 40 22 69 66 78 45 47 65  9 46 44 34 54 35 38 39 77 71 52 18 67], a_shuffle_aclus: [ 84  24  77  85  95  23  34  67  30   4  48  58   3  12  68  79  63  72  81  15  11  57  27  44 101  19   6  82  51  83  66  90   2  40  14  43  31 100  38   9   5  39  28  18  56   8  26  97  98  75  32  80 104  16  35  33  70  20  92  55  29  91  87 103  60  62  86  13  61  59  45  71  47  52  53 102  93  69  25  89]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41 29 40 38 39 30 35 59 33 63 57 65 11 50  8 79 16 55 25 15 28  7 20 42 18 13 54 77 72 69 73  2 61 22 34 37 53 74 24 10 52 21 44 51 26 60  9 49 64  6 19 23 75 58 70  4  3 48 78 71  0 67 68 66 46  1 45 62 27 76 56 47  5 32 14 31 12 36 17 43], a_shuffle_aclus: [ 56  38  55  52  53  39  47  80  44  84  77  86  15  67  12 104  23  72  32  20  35  11  27  57  25  18  71 102  95  91  97   4  82  29  45  51  70  98  31  14  69  28  59  68  33  81  13  66  85   9  26  30 100  79  92   6   5  63 103  93   2  89  90  87  61   3  60  83  34 101  75  62   8  43  19  40  16  48  24  58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [20 47 56  4 21  8 30 33 54 22 13 49 19 36 74 67  9 72 60 14 43  1 68 78 28 34 59 37 57 63 39 58 65 11 41 25 66 44 69 17 18 35 10 31 76  6 75 62  5 27  2 55 64 46 42  3 52 71 48 16 26 32 12 38 24 50 45  0 53 77 40 29 70 79 23 73 61 15  7 51], a_shuffle_aclus: [ 27  62  75   6  28  12  39  44  71  29  18  66  26  48  98  89  13  95  81  19  58   3  90 103  35  45  80  51  77  84  53  79  86  15  56  32  87  59  91  24  25  47  14  40 101   9 100  83   8  34   4  72  85  61  57   5  69  93  63  23  33  43  16  52  31  67  60   2  70 102  55  38  92 104  30  97  82  20  11  68]\n",
      "a_shuffle_IDXs: [59 49 35 64 73 32 57 28 12 18  3 39 25 23 17 63 52 45 67 75 58 31 51 41 38 43 26 61 78  7 21 60 54 72 14 24 19 55 50 33  6 11 77 27 47 22 79 42  2  0  5 20 68 37 48 10 71  1 29  9 56 76 34  8  4 30 13 44 74 62 53 69 16 70 40 46 15 65 66 36], a_shuffle_aclus: [ 80  66  47  85  97  43  77  35  16  25   5  53  32  30  24  84  69  60  89 100  79  40  68  56  52  58  33  82 103  11  28  81  71  95  19  31  26  72  67  44   9  15 102  34  62  29 104  57   4   2   8  27  90  51  63  14  93   3  38  13  75 101  45  12   6  39  18  59  98  83  70  91  23  92  55  61  20  86  87  48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [76 65 63 43 54 19 26 75 51 45 32 67 78  8 73 22  5 13 16 69 27 52  0 24 42 58 64 18  4  6 49 44 70  3 15 34 60  1 17 74 48  2 79 11 21  9 47 72 57 30  7 38 28 29 20 68 59 71 25 37 66 36 35 62 14 12 39 50 56 46 10 33 61 31 23 55 41 53 40 77], a_shuffle_aclus: [101  86  84  58  71  26  33 100  68  60  43  89 103  12  97  29   8  18  23  91  34  69   2  31  57  79  85  25   6   9  66  59  92   5  20  45  81   3  24  98  63   4 104  15  28  13  62  95  77  39  11  52  35  38  27  90  80  93  32  51  87  48  47  83  19  16  53  67  75  61  14  44  82  40  30  72  56  70  55 102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [68  5  2 51 67 56 23 13 37 35 71 18 57 47 45 58 44 14 36 48  1  0 70 64 30 50  3 43 28 11 46 65 26 55 41 77 59 34 24 62 61 63 73 33 20 78 12  7 22 54 53 39 72 17 66 52 29 38  4  9 27 60 79 31 40 25 42 69 15 10  6 21 49 16 74  8 76 19 75 32], a_shuffle_aclus: [ 90   8   4  68  89  75  30  18  51  47  93  25  77  62  60  79  59  19  48  63   3   2  92  85  39  67   5  58  35  15  61  86  33  72  56 102  80  45  31  83  82  84  97  44  27 103  16  11  29  71  70  53  95  24  87  69  38  52   6  13  34  81 104  40  55  32  57  91  20  14   9  28  66  23  98  12 101  26 100  43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 27 73 62 21 66 54 11 64 40 29 18 19 79  9  3 61 74 23 71 51 58 33 48 32 37 57 20 60 12 47  2 72 16 70  6 14 49 45 77 25 52 26  4 55 35 15 39  7 44 22 75  0 53 38 30 56 78 68 31 41 50 34 36 17 76 46 59  1 67 63 65  5 42 28  8 24 13 69 43], a_shuffle_aclus: [ 14  34  97  83  28  87  71  15  85  55  38  25  26 104  13   5  82  98  30  93  68  79  44  63  43  51  77  27  81  16  62   4  95  23  92   9  19  66  60 102  32  69  33   6  72  47  20  53  11  59  29 100   2  70  52  39  75 103  90  40  56  67  45  48  24 101  61  80   3  89  84  86   8  57  35  12  31  18  91  58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [69 41 25 67 44 56 51 14 63 22 24 40 46 60 15 45  6 11 16  5 49 59 71 32 27 61 26 74  0 53 21  1 34 42 36 73  7 28 55 10 70 52 18 75 13 29 37  3 54 79  9 33 12 68 23 38  2 39 30 43 62 20 65 57 19 78 48 76 58 17 66 77 47 50 35  8 64 31  4 72], a_shuffle_aclus: [ 91  56  32  89  59  75  68  19  84  29  31  55  61  81  20  60   9  15  23   8  66  80  93  43  34  82  33  98   2  70  28   3  45  57  48  97  11  35  72  14  92  69  25 100  18  38  51   5  71 104  13  44  16  90  30  52   4  53  39  58  83  27  86  77  26 103  63 101  79  24  87 102  62  67  47  12  85  40   6  95]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [66  8 65 33 67 22 60 78 53 29 19 49 64 54 57 13 48 74  6 23 36  3  7 34 71  4  1 26 62 24 11 68 41 42 25 15 28 17 43 16 55 50 10 37  2 38 76 56 32 58  9 79 31 45 14 27 35 69 59 72 61 18 39 63 75 40 21 73 77 46  0 20 70 12 44  5 51 47 30 52], a_shuffle_aclus: [ 87  12  86  44  89  29  81 103  70  38  26  66  85  71  77  18  63  98   9  30  48   5  11  45  93   6   3  33  83  31  15  90  56  57  32  20  35  24  58  23  72  67  14  51   4  52 101  75  43  79  13 104  40  60  19  34  47  91  80  95  82  25  53  84 100  55  28  97 102  61   2  27  92  16  59   8  68  62  39  69]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 61 10 17 43 57 35 64 58 56 48 15 31 49 46  6 66 28 12 67  4 13 73 44 77 29 79 62 74 42 63 69 45 55 18 54 33  2  5  8 26 27 59 53 60 32 78 23 50  0 41 47 76 40 51 39 25 30 65 75 70 21  7 16 24 52 20 68  3 19 71 38  9 72 22 37  1 34 36 11], a_shuffle_aclus: [ 19  82  14  24  58  77  47  85  79  75  63  20  40  66  61   9  87  35  16  89   6  18  97  59 102  38 104  83  98  57  84  91  60  72  25  71  44   4   8  12  33  34  80  70  81  43 103  30  67   2  56  62 101  55  68  53  32  39  86 100  92  28  11  23  31  69  27  90   5  26  93  52  13  95  29  51   3  45  48  15]\n",
      "a_shuffle_IDXs: [72 25 33 75 55 76 50 43  3 62 49 12 19 26 29 22 70 67 38 39 30  6 31  2 15 57 74  9 44  0 66 61 16  8 69 35 20 32 18  4 21 77 42 17 51 40 56 47 54 68 36 24 63 48 59 11 23 71 64 27 13 10  7 45 65 34 79 46 78 14  5 41 53 28  1 73 37 60 52 58], a_shuffle_aclus: [ 95  32  44 100  72 101  67  58   5  83  66  16  26  33  38  29  92  89  52  53  39   9  40   4  20  77  98  13  59   2  87  82  23  12  91  47  27  43  25   6  28 102  57  24  68  55  75  62  71  90  48  31  84  63  80  15  30  93  85  34  18  14  11  60  86  45 104  61 103  19   8  56  70  35   3  97  51  81  69  79]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [59 16 63 20 37 47 44  8 64 29 23 50 68  0 26 73 52 36 53  7 39 62  3 30 38 75 61 22 21 45 70 33 40 57  5 48 74 58 34 56 46 69 10 31 76 32 41 72 19 14 18 55 11 49 51  2  4 17 42 25 12 79 65 43  1  6 27 71 66 15 24 28 67 78  9 13 77 54 35 60], a_shuffle_aclus: [ 80  23  84  27  51  62  59  12  85  38  30  67  90   2  33  97  69  48  70  11  53  83   5  39  52 100  82  29  28  60  92  44  55  77   8  63  98  79  45  75  61  91  14  40 101  43  56  95  26  19  25  72  15  66  68   4   6  24  57  32  16 104  86  58   3   9  34  93  87  20  31  35  89 103  13  18 102  71  47  81]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33 40 34  0 77 28 73 20 24 71 36 76 50 12 23  4 55 32 19 39  6  1  3 43 16  9 22 65 70 52 30 13 74 31 58 15 14 67  5 61 72 21 45 51 75 42 48 17 57 49  2 35 11 27 64 79 60 53 46 62 66 47 59 56 29 63 41 25 69 10 38 37 78 54 68 26  8 44  7 18], a_shuffle_aclus: [ 44  55  45   2 102  35  97  27  31  93  48 101  67  16  30   6  72  43  26  53   9   3   5  58  23  13  29  86  92  69  39  18  98  40  79  20  19  89   8  82  95  28  60  68 100  57  63  24  77  66   4  47  15  34  85 104  81  70  61  83  87  62  80  75  38  84  56  32  91  14  52  51 103  71  90  33  12  59  11  25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [74 47 70 19 36 72 61 13 41 76 45 38 64 18 56 27  9 32 12 21 31 15 51 44 75 62 24 42 39 58 33  6 71 40 49 78 59  7 46 67 34 55 11 69 43 73 35 53 63  2 66 10 60 16 14 30 25 17 65 29 52 48 68  5 26 54 77 79  3 20 37  8 50 28  0  1 57 23 22  4], a_shuffle_aclus: [ 98  62  92  26  48  95  82  18  56 101  60  52  85  25  75  34  13  43  16  28  40  20  68  59 100  83  31  57  53  79  44   9  93  55  66 103  80  11  61  89  45  72  15  91  58  97  47  70  84   4  87  14  81  23  19  39  32  24  86  38  69  63  90   8  33  71 102 104   5  27  51  12  67  35   2   3  77  30  29   6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [56 67 65 10 66 63 68 34 45 29  2 42 12 70 76 57 73 41 11 69 26 36 50 35 72 59 15  7  1 16 27 40 30 38 17 79 33 61 24 39 18 20  0 71 77 31 62 37 48  8 46 52 25 21 54  4 64 32  9 13  5 74 23 14 51 44 55  3 75 53 19  6 28 78 58 43 49 47 22 60], a_shuffle_aclus: [ 75  89  86  14  87  84  90  45  60  38   4  57  16  92 101  77  97  56  15  91  33  48  67  47  95  80  20  11   3  23  34  55  39  52  24 104  44  82  31  53  25  27   2  93 102  40  83  51  63  12  61  69  32  28  71   6  85  43  13  18   8  98  30  19  68  59  72   5 100  70  26   9  35 103  79  58  66  62  29  81]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [57 24 26 17 45 16  3 67 76 79 68 21 71 41 70 15 18  9 20 58 44 60 48 19  0 74  2 34 72 63 12 66 59 10  6 32 55 22 49 11 56 36  5 42 23 33 73 46 62 53 39  4 40 29 35 14 54 77 61 38 47 37 28 25  8 13 31 50 78 27  1 43 30 51 69 52  7 65 64 75], a_shuffle_aclus: [ 77  31  33  24  60  23   5  89 101 104  90  28  93  56  92  20  25  13  27  79  59  81  63  26   2  98   4  45  95  84  16  87  80  14   9  43  72  29  66  15  75  48   8  57  30  44  97  61  83  70  53   6  55  38  47  19  71 102  82  52  62  51  35  32  12  18  40  67 103  34   3  58  39  68  91  69  11  86  85 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [59 45 72 44 50 58 52 20  1 19 61 36 77 16 74 62 17 32 63 23 40 21 47  9 22 66 37  7  5 76 27 14 51 13 35 55 60 26 54  6 46 34 79 68 38 41 70 67 73 71 25 29 10 56 75 31 78 30 24 33 48 28 57 43 64 39  0 53  8 69  4 11  3  2 18 12 42 65 15 49], a_shuffle_aclus: [ 80  60  95  59  67  79  69  27   3  26  82  48 102  23  98  83  24  43  84  30  55  28  62  13  29  87  51  11   8 101  34  19  68  18  47  72  81  33  71   9  61  45 104  90  52  56  92  89  97  93  32  38  14  75 100  40 103  39  31  44  63  35  77  58  85  53   2  70  12  91   6  15   5   4  25  16  57  86  20  66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 51 30 23 34 69 70 72 64 74 27 61 28 33 20 12 55  3 50 60 58 63 67 47 79  4 54 75 17 48 71 56 73  1 18 66 14 52 44 78 10 22 65 13 39  6  8 53 76 15 43 26 68 46 41  5 38 36 35  0 62 40 37 42 57 29 25 77 19 59  9 24 16 11  2 45 31 49 21  7], a_shuffle_aclus: [ 43  68  39  30  45  91  92  95  85  98  34  82  35  44  27  16  72   5  67  81  79  84  89  62 104   6  71 100  24  63  93  75  97   3  25  87  19  69  59 103  14  29  86  18  53   9  12  70 101  20  58  33  90  61  56   8  52  48  47   2  83  55  51  57  77  38  32 102  26  80  13  31  23  15   4  60  40  66  28  11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 17 31 56 77  8 63 51 24 30 65 72 75  5  2 48 50 20 73 60 34 58 66 38 12 71 23  4 74 41 35 67 52 79 39 45 59 18  1  9 49  6 14  7 15 64 55 40 26  3 47 19 36 57 53 27 78 25 54 37 13 33 32 21 76  0 68 70 29 42 28 62 61 44 10 69 11 16 22 46], a_shuffle_aclus: [ 58  24  40  75 102  12  84  68  31  39  86  95 100   8   4  63  67  27  97  81  45  79  87  52  16  93  30   6  98  56  47  89  69 104  53  60  80  25   3  13  66   9  19  11  20  85  72  55  33   5  62  26  48  77  70  34 103  32  71  51  18  44  43  28 101   2  90  92  38  57  35  83  82  59  14  91  15  23  29  61]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "INFO:2024-07-10_18-07-15.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:save_pipeline(): Attempting to save pipeline to disk...\n",
      "INFO:2024-07-10_18-07-15.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\tfinalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withOldestImportedReplays-qclu_XX-frateThresh_0.1.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withOldestImportedReplays-qclu_XX-frateThresh_0.1.pkl\n",
      "Saving (file mode 'w+b') pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/20240710183900-loadedSessPickle_withOldestImportedReplays-qclu_XX-frateThresh_0.1.1.pkl\"... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2024-07-10_18-07-15.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: prev_extant_file_size_MB (12800.801079750061 MB) > new_temporary_file_size_MB (8778.64264678955 MB)! A backup will be made!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved pickle file\n",
      "WARNING: prev_extant_file_size_MB (12800.801079750061 MB) > new_temporary_file_size_MB (8778.64264678955 MB)! A backup will be made!\n",
      "'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withOldestImportedReplays-qclu_XX-frateThresh_0.1.pkl' backing up -> to_file: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\backup-20240710183935-loadedSessPickle_withOldestImportedReplays-qclu_XX-frateThresh_0.1.pkl.bak'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_18-07-15.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:moving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\20240710183900-loadedSessPickle_withOldestImportedReplays-qclu_XX-frateThresh_0.1.1.pkl' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withOldestImportedReplays-qclu_XX-frateThresh_0.1.pkl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\20240710183900-loadedSessPickle_withOldestImportedReplays-qclu_XX-frateThresh_0.1.1.pkl' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withOldestImportedReplays-qclu_XX-frateThresh_0.1.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_18-07-15.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t save complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_save_filepaths: {'pipeline_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withOldestImportedReplays-qclu_XX-frateThresh_0.1.pkl'), 'global_computation_pkl': 'global_computation_results_withOldestImportedReplays-qclu_XX-frateThresh_0.1.pkl', 'pipeline_h5': 'pipeline_withOldestImportedReplays-qclu_XX-frateThresh_0.1.h5', 'ripple_h5_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10_Apogee_withOldestImportedReplays-qclu_XX-frateThresh_0.1-2006-6-09_1-22-43-_withOldestImportedReplays-qclu_XX-frateThresh_0.1_time_bin_size_sweep_results.h5'), 'ripple_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withOldestImportedReplays-qclu_XX-frateThresh_0.1-(ripple_marginals_df).csv'), 'ripple_csv_time_bin_marginals': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withOldestImportedReplays-qclu_XX-frateThresh_0.1-(ripple_time_bin_marginals_df).csv'), 'laps_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withOldestImportedReplays-qclu_XX-frateThresh_0.1-(laps_marginals_df).csv'), 'laps_csv_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withOldestImportedReplays-qclu_XX-frateThresh_0.1-(laps_time_bin_marginals_df).csv')}\n",
      "wcorr_ripple_shuffle.n_completed_shuffles: 25\n",
      "n_epochs: 107\n",
      "n_completed_shuffles: 25\n",
      "a_shuffle_IDXs: [79 13 76 77 22  4 14 75 26 78 61 53 50 41 65 20 39 42 31 32 56 46 17 64  2 70 15 55 68 18 72 16 44 38 40 49  1 52 69 25 27  3 66 45 74 67 62 73 10 47 21 19 24 51 54 11 48 28 59 33  8 71  9 58 12 43 57 63  6 35 60 29  5 23 34 36  0  7 37 30], a_shuffle_aclus: [104  18 101 102  29   6  19 100  33 103  82  70  67  56  86  27  53  57  40  43  75  61  24  85   4  92  20  72  90  25  95  23  59  52  55  66   3  69  91  32  34   5  87  60  98  89  83  97  14  62  28  26  31  68  71  15  63  35  80  44  12  93  13  79  16  58  77  84   9  47  81  38   8  30  45  48   2  11  51  39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [77 15 63 51 44 47 28 79 46 40 10 58 11 56 78  6 34 18 24 59 45 21 43 29 70 42  5 68 75 22 20  0 33  1 49 57 48 14 55 17  7 39  8  9 32 62  2 50 66 37  3 31 71 65 54 74 69 16 67 35 61 76 41 38 13 27 53 26 64 52 25  4 19 72 73 36 60 30 12 23], a_shuffle_aclus: [102  20  84  68  59  62  35 104  61  55  14  79  15  75 103   9  45  25  31  80  60  28  58  38  92  57   8  90 100  29  27   2  44   3  66  77  63  19  72  24  11  53  12  13  43  83   4  67  87  51   5  40  93  86  71  98  91  23  89  47  82 101  56  52  18  34  70  33  85  69  32   6  26  95  97  48  81  39  16  30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_completed_shuffles: 27\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "total_n_shuffles: 27\n",
      "total_n_shuffles: 27\n",
      "(n_shuffles = 27, n_epochs = 107, n_decoders = 4); n_total_elements = 11556\n",
      "saving to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0640PM_withOldestImportedReplays-qclu_XX-frateThresh_0.1_standalone_wcorr_ripple_shuffle_data_only_27.pkl\"...\n",
      "total_n_shuffles: 27\n",
      "Saving (file mode 'w+b') pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0640PM_withOldestImportedReplays-qclu_XX-frateThresh_0.1_standalone_wcorr_ripple_shuffle_data_only_27.pkl\"... saved pickle file\n",
      "saving .mat file to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0640PM_withOldestImportedReplays-qclu_XX-frateThresh_0.1_standalone_all_shuffles_wcorr_array.mat\"...\n",
      "total_n_shuffles: 27\n",
      "(n_shuffles = 27, n_epochs = 107, n_decoders = 4); n_total_elements = 11556\n",
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 107\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "num_user_selected_times: 0\n",
      "adding user annotation column!\n",
      "ERROR: failed for ripple_WCorrShuffle_df. Out of options.\n",
      "\t failed all methods for annotations\n",
      "num_valid_epoch_times: 107\n",
      "adding valid filtered epochs column!\n",
      "\t succeded at getting 107 selected indicies (of 107 valid filter epoch times) for ripple_WCorrShuffle_df. got 107 indicies!\n",
      "Successfully exported ripple_WCorrShuffle_df_export_CSV_path: \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0640PM-kdiba_gor01_one_2006-6-09_1-22-43-(ripple_WCorrShuffle_df)_tbin-0.025.csv\" with wcorr_shuffles.n_completed_shuffles: 27 unique shuffles.\n",
      "completed overwrite_replay_epochs_and_recompute(...). custom_save_filepaths: {'pipeline_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withOldestImportedReplays-qclu_XX-frateThresh_0.1.pkl'), 'global_computation_pkl': 'global_computation_results_withOldestImportedReplays-qclu_XX-frateThresh_0.1.pkl', 'pipeline_h5': 'pipeline_withOldestImportedReplays-qclu_XX-frateThresh_0.1.h5', 'ripple_h5_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10_Apogee_withOldestImportedReplays-qclu_XX-frateThresh_0.1-2006-6-09_1-22-43-_withOldestImportedReplays-qclu_XX-frateThresh_0.1_time_bin_size_sweep_results.h5'), 'ripple_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withOldestImportedReplays-qclu_XX-frateThresh_0.1-(ripple_marginals_df).csv'), 'ripple_csv_time_bin_marginals': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withOldestImportedReplays-qclu_XX-frateThresh_0.1-(ripple_time_bin_marginals_df).csv'), 'laps_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withOldestImportedReplays-qclu_XX-frateThresh_0.1-(laps_marginals_df).csv'), 'laps_csv_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withOldestImportedReplays-qclu_XX-frateThresh_0.1-(laps_time_bin_marginals_df).csv'), 'standalone_wcorr_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0640PM_withOldestImportedReplays-qclu_XX-frateThresh_0.1_standalone_wcorr_ripple_shuffle_data_only_27.pkl'), 'standalone_mat_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0640PM_withOldestImportedReplays-qclu_XX-frateThresh_0.1_standalone_all_shuffles_wcorr_array.mat')}\n",
      "\n",
      "<<<<<<<<<<<<<<< Done with `overwrite_replay_epochs_and_recompute(...)` for replay_epochs_key: initial_loaded\n",
      "\t\twcorr_ripple_shuffle.n_completed_shuffles: 27\n",
      "n_epochs: 107\n",
      "n_completed_shuffles: 27\n",
      "a_shuffle_IDXs: [10 45 74 18  1 37 41 70 77 66 12 68 48  5 47 64 35 71  3 46 26 40 52 33 28 11 49 75  9 65 59 24  2 56 36  8 27 25 54 72 44 79 55 69 17 42 14 15 51 62  7 67 32 13  6  4 30 63 16 43 31 38 34 20 61  0 60 23 22 19 78 53 58 50 73 39 57 21 76 29], a_shuffle_aclus: [ 14  60  98  25   3  51  56  92 102  87  16  90  63   8  62  85  47  93   5  61  33  55  69  44  35  15  66 100  13  86  80  31   4  75  48  12  34  32  71  95  59 104  72  91  24  57  19  20  68  83  11  89  43  18   9   6  39  84  23  58  40  52  45  27  82   2  81  30  29  26 103  70  79  67  97  53  77  28 101  38]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 14 67 21  9  2 72 17 76 19 69 62 36  7 35 22 33 47 54 40 10 44 52 61 59 38 74 27 11 12 73 18 79 57 15 31 32 66 29 78 42 75 56  8 23  0  1 53 55  3 25 58 60 68 64 50 65 34 46  6  5 24 48 49 26 71  4 28 20 63 30 70 16 45 77 13 37 51 39 41], a_shuffle_aclus: [ 58  19  89  28  13   4  95  24 101  26  91  83  48  11  47  29  44  62  71  55  14  59  69  82  80  52  98  34  15  16  97  25 104  77  20  40  43  87  38 103  57 100  75  12  30   2   3  70  72   5  32  79  81  90  85  67  86  45  61   9   8  31  63  66  33  93   6  35  27  84  39  92  23  60 102  18  51  68  53  56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_completed_shuffles: 29\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "total_n_shuffles: 29\n",
      "(n_shuffles = 29, n_epochs = 107, n_decoders = 4); n_total_elements = 12412\n",
      "saving to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0640PM_withOldestImportedReplays-qclu_XX-frateThresh_0.1_standalone_wcorr_ripple_shuffle_data_only_29.pkl\"...\n",
      "total_n_shuffles: 29\n",
      "Saving (file mode 'w+b') pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0640PM_withOldestImportedReplays-qclu_XX-frateThresh_0.1_standalone_wcorr_ripple_shuffle_data_only_29.pkl\"... saved pickle file\n",
      "saving .mat file to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0640PM_withOldestImportedReplays-qclu_XX-frateThresh_0.1_standalone_all_shuffles_wcorr_array.mat\"...\n",
      "total_n_shuffles: 29\n",
      "(n_shuffles = 29, n_epochs = 107, n_decoders = 4); n_total_elements = 12412\n",
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 107\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "num_user_selected_times: 0\n",
      "adding user annotation column!\n",
      "ERROR: failed for ripple_WCorrShuffle_df. Out of options.\n",
      "\t failed all methods for annotations\n",
      "num_valid_epoch_times: 107\n",
      "adding valid filtered epochs column!\n",
      "\t succeded at getting 107 selected indicies (of 107 valid filter epoch times) for ripple_WCorrShuffle_df. got 107 indicies!\n",
      "Successfully exported ripple_WCorrShuffle_df_export_CSV_path: \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0640PM-kdiba_gor01_one_2006-6-09_1-22-43__withOldestImportedReplays-qclu_XX-frateThresh_0.1-(ripple_WCorrShuffle_df)_tbin-0.025.csv\" with wcorr_shuffles.n_completed_shuffles: 29 unique shuffles.\n",
      "\t saved \"file:///C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2024-07-10/kdiba/gor01/one/2006-6-09_1-22-43/replay_wcorr__withOldestImportedReplays-qclu_XX-frateThresh_0%E2%80%A21.png\"\n",
      "\t=====================================>> performing comp for \"normal_computed\"...\n",
      "\treplay_epochs_key: normal_computed: custom_suffix: \"_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0\"\n",
      "\tcurr_BATCH_DATE_TO_USE: \"2024-07-10_Apogee_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0\"\n",
      "\tWARNING: should_suppress_errors: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_18-07-26.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:==========================================================================================\n",
      "========== Logger INIT \"2024-07-10_18-07-26.Apogee.kdiba.gor01.one.2006-6-09_1-22-43\" ==============================\n",
      "INFO:2024-07-10_18-07-26.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:NeuropyPipeline.__setstate__(state=\"{'pipeline_name': 'kdiba_pipeline', 'session_data_type': 'kdiba', '_stage': <pyphoplacecellanalysis.General.Pipeline.Stages.Display.DisplayPipelineStage object at 0x0000021959B190A0>}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_logger(full_logger_string=\"2024-07-10_18-07-26.Apogee.kdiba.gor01.one.2006-6-09_1-22-43\", file_logging_dir: None):\n",
      "custom_suffix: \"_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0\"\n",
      "Using custom suffix: \"_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0\" - additional_session_context: \"_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0\"\n",
      "did_change: True\n",
      "custom_save_filenames: {'pipeline_pkl': 'loadedSessPickle_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.pkl', 'global_computation_pkl': 'global_computation_results_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.pkl', 'pipeline_h5': 'pipeline_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.h5'}\n",
      "replay epochs changed!\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['merged_directional_placefields', 'perform_rank_order_shuffle_analysis'], ...)...\n",
      "\trun_specific_computations_single_context(including only 2 out of 16 registered computation functions): active_computation_functions: [<function DirectionalPlacefieldGlobalComputationFunctions._build_merged_directional_placefields at 0x0000021388D969D0>, <function RankOrderGlobalComputationFunctions.perform_rank_order_shuffle_analysis at 0x000002139891D4C0>]...\n",
      "Performing _execute_computation_functions(...) with 2 registered_computation_functions...\n",
      "Executing [0/2]: <function DirectionalPlacefieldGlobalComputationFunctions._build_merged_directional_placefields at 0x0000021B06D9F550>\n",
      "skipping lap recomputation because laps_decoding_time_bin_size == None\n",
      "Executing [1/2]: <function RankOrderGlobalComputationFunctions.perform_rank_order_shuffle_analysis at 0x0000021B06D9FF70>\n",
      "WARN: perform_rank_order_shuffle_analysis(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "####> perform_rank_order_shuffle_analysis(..., num_shuffles=25)\n",
      "\t##> computing Ripple rank-order shuffles:\n",
      "ripple_evts_paired_tests: [TtestResult(statistic=0.18351254819771434, pvalue=0.8545241150237886, df=290), TtestResult(statistic=-0.1079271231305236, pvalue=0.9141281333318223, df=290)]\n",
      "\tdone. building global result.\n",
      "n_valid_shuffles: 25\n",
      "combined_variable_names: ['long_LR_pearson', 'long_RL_pearson', 'short_LR_spearman', 'long_LR_spearman', 'short_RL_pearson', 'short_LR_pearson', 'long_RL_spearman', 'short_RL_spearman']\n",
      "combined_variable_z_score_column_names: ['long_LR_pearson_Z', 'long_RL_pearson_Z', 'short_LR_spearman_Z', 'long_LR_spearman_Z', 'short_RL_pearson_Z', 'short_LR_pearson_Z', 'long_RL_spearman_Z', 'short_RL_spearman_Z']\n",
      "done!\n",
      "\tdone. building global result.\n",
      "< done with `perform_rank_order_shuffle_analysis(...)`\n",
      "\t all computations complete! (Computed 2 with no errors!.\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], ...)...\n",
      "\trun_specific_computations_single_context(including only 2 out of 16 registered computation functions): active_computation_functions: [<function DirectionalPlacefieldGlobalComputationFunctions._decode_and_evaluate_epochs_using_directional_decoders at 0x0000021388D96AF0>, <function DirectionalPlacefieldGlobalComputationFunctions._decoded_epochs_heuristic_scoring at 0x0000021388D96B80>]...\n",
      "Performing _execute_computation_functions(...) with 2 registered_computation_functions...\n",
      "Executing [0/2]: <function DirectionalPlacefieldGlobalComputationFunctions._decode_and_evaluate_epochs_using_directional_decoders at 0x0000021B06D9FF70>\n",
      "laps_decoding_time_bin_size: 0.25, ripple_decoding_time_bin_size: 0.025, pos_bin_size: 3.8054171165052444\n",
      "laps_decoding_time_bin_size: 0.25, ripple_decoding_time_bin_size: 0.025, pos_bin_size: 3.8054171165052444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "Performance: Radon Transform:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 13/84\n",
      "\tagreeing_rows_ratio: 0.15476190476190477\n",
      "\tPerformance: Ripple: Radon Transform:\n",
      "agreeing_rows_count/num_total_epochs: 42/412\n",
      "\tagreeing_rows_ratio: 0.10194174757281553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 64/84\n",
      "\tagreeing_rows_ratio: 0.7619047619047619\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 148/412\n",
      "\tagreeing_rows_ratio: 0.3592233009708738\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 75/84\n",
      "\tagreeing_rows_ratio: 0.8928571428571429\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 137/412\n",
      "\tagreeing_rows_ratio: 0.3325242718446602\n",
      "Executing [1/2]: <function DirectionalPlacefieldGlobalComputationFunctions._decoded_epochs_heuristic_scoring at 0x0000021B06D9F550>\n",
      "\t all computations complete! (Computed 2 with no errors!.\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(curr_session_context: kdiba_gor01_one_2006-6-09_1-22-43, curr_session_basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43, ...)\n",
      "\tactive_context: kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0\n",
      "\tsession_ctxt_key: kdiba|gor01|one|2006-6-09_1-22-43|_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0\n",
      "\tCURR_BATCH_OUTPUT_PREFIX: 2024-07-10_Apogee_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-2006-6-09_1-22-43-_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0\n",
      "\tout_path_str: \"2024-07-10_Apogee_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-2006-6-09_1-22-43-_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0_time_bin_size_sweep_results.h5\"\n",
      "\tout_path: \"K:\\scratch\\collected_outputs\\2024-07-10_Apogee_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-2006-6-09_1-22-43-_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0_time_bin_size_sweep_results.h5\"\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\ta_sweep_dict: {'desired_laps_decoding_time_bin_size': 1.5, 'desired_ripple_decoding_time_bin_size': 0.01, 'use_single_time_bin_per_epoch': False, 'minimum_event_duration': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.02).\n",
      "\tdropping -1 that are shorter than our minimum_event_duration of 0.02.\t411 remain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning:\n",
      "\n",
      "object name is not a valid Python identifier: 'kdiba|gor01|one|2006-6-09_1-22-43|_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning:\n",
      "\n",
      "object name is not a valid Python identifier: '1.5'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning:\n",
      "\n",
      "object name is not a valid Python identifier: '0.01'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 27/84\n",
      "\tagreeing_rows_ratio: 0.32142857142857145\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 144/411\n",
      "\tagreeing_rows_ratio: 0.35036496350364965\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 72/84\n",
      "\tagreeing_rows_ratio: 0.8571428571428571\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 125/411\n",
      "\tagreeing_rows_ratio: 0.30413625304136255\n",
      "\ta_sweep_dict: {'desired_laps_decoding_time_bin_size': 1.5, 'desired_ripple_decoding_time_bin_size': 0.02, 'use_single_time_bin_per_epoch': False, 'minimum_event_duration': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.02).\n",
      "\tdropping -1 that are shorter than our minimum_event_duration of 0.02.\t411 remain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning:\n",
      "\n",
      "object name is not a valid Python identifier: '0.02'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 27/84\n",
      "\tagreeing_rows_ratio: 0.32142857142857145\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 109/411\n",
      "\tagreeing_rows_ratio: 0.26520681265206814\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 72/84\n",
      "\tagreeing_rows_ratio: 0.8571428571428571\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 130/411\n",
      "\tagreeing_rows_ratio: 0.31630170316301703\n",
      ">>\t done with kdiba_gor01_one_2006-6-09_1-22-43\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "perform_drop_computed_result(computed_data_keys_to_drop: ['SequenceBased'], config_names_includelist: None)\n",
      "\t global_computation_results.computed_data['SequenceBased'] did not exist.\n",
      "\t Dropped computation_results['maze1_odd'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze2_odd'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze_odd'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze1_even'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze2_even'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze_even'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze1_any'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze2_any'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze_any'].computed_data['SequenceBased'].\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['wcorr_shuffle_analysis'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function SequenceBasedComputationsGlobalComputationFunctions.perform_wcorr_shuffle_analysis at 0x000002139886AA60>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function SequenceBasedComputationsGlobalComputationFunctions.perform_wcorr_shuffle_analysis at 0x0000021A47FF8DC0>\n",
      "WARN: perform_wcorr_shuffle_analysis(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "perform_wcorr_shuffle_analysis(..., num_shuffles=25)\n",
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 136\n",
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 136\n",
      "real_decoder_ripple_weighted_corr_arr: (136, 4)\n",
      "n_prev_completed_shuffles: 0.\n",
      "needed num_shuffles: 25.\n",
      "need desired_new_num_shuffles: 25 more shuffles.\n",
      "a_shuffle_IDXs: [13 44 75 50  0 45 59 34 39 69 19 36 42 14  2 77 41 64 60  1 10  6  3 58 70 23 54 21 66 40 30 47 55 67 46 20  7 22 65 16 26 53  4 48 51 57 38 78 79 18  9 49 61 72 35 31 32 12  8 63  5 25 11 24 15 73 37 68 74 29 17 71 62 76 33 43 27 28 56 52], a_shuffle_aclus: [ 18  59 100  67   2  60  80  45  53  91  26  48  57  19   4 102  56  85  81   3  14   9   5  79  92  30  71  28  87  55  39  62  72  89  61  27  11  29  86  23  33  70   6  63  68  77  52 103 104  25  13  66  82  95  47  40  43  16  12  84   8  32  15  31  20  97  51  90  98  38  24  93  83 101  44  58  34  35  75  69]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10  5 76 31 15 55 64 56 27 45  8 14 74 58 79  4 78  3 52  9 42 68 35 77 36 51 28 26 59 23 17  0 66  1 39 65 54 71 12 61 22 24 48  2 18 38 19 53 72 33 30 13 57 20 29 50  6 37 25 40 47 49 73 21 70 67 16 11 34 62 41 46 63 75 32 43 69 60  7 44], a_shuffle_aclus: [ 14   8 101  40  20  72  85  75  34  60  12  19  98  79 104   6 103   5  69  13  57  90  47 102  48  68  35  33  80  30  24   2  87   3  53  86  71  93  16  82  29  31  63   4  25  52  26  70  95  44  39  18  77  27  38  67   9  51  32  55  62  66  97  28  92  89  23  15  45  83  56  61  84 100  43  58  91  81  11  59]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [46 75  6 27 74 19 64 79 20 61  3 15 52 43 59 68 29 30 24 51 13 36  7 76 21 12 35 31 54  5  1 16 45 73 26 71 60 69 32 23  4 57  9 28 41 25 38 58 44  8 37 42 55 39 17 50 10 56 62 33 65 48 40 47  0 66 63 49 34 77 67 22  2 70 18 78 53 11 14 72], a_shuffle_aclus: [ 61 100   9  34  98  26  85 104  27  82   5  20  69  58  80  90  38  39  31  68  18  48  11 101  28  16  47  40  71   8   3  23  60  97  33  93  81  91  43  30   6  77  13  35  56  32  52  79  59  12  51  57  72  53  24  67  14  75  83  44  86  63  55  62   2  87  84  66  45 102  89  29   4  92  25 103  70  15  19  95]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 54 42 44  5 12 11 75 10 70 48 21 66 28 58 33 64 71 17 23  7  2 34 47 53 25 29 76 24 62 32 69  8 14 56 31 15 49 78 72 35 73 45 77 55 19 43 36 38  9  0 13 41 52 60 16  6 37 18 40 59 74 30 26 68 79 22  3 51 67 63 39 57 20 46  1 61 27 50 65], a_shuffle_aclus: [  6  71  57  59   8  16  15 100  14  92  63  28  87  35  79  44  85  93  24  30  11   4  45  62  70  32  38 101  31  83  43  91  12  19  75  40  20  66 103  95  47  97  60 102  72  26  58  48  52  13   2  18  56  69  81  23   9  51  25  55  80  98  39  33  90 104  29   5  68  89  84  53  77  27  61   3  82  34  67  86]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7 23 54 37 22 74 63 69 24  4 16 44 25 34 18 59  5 33 64 42 76 39  3 77 79 61  8 45 65 73 71 30 56 57 52 29 49  0 27  6 55 31 46 75 70 41 72 53 43 60 14 26 62 66  2 51 78 12 58  1 20 13 19 50 40 17 36 35 32 10 28 47 11 48 21 15 68  9 38 67], a_shuffle_aclus: [ 11  30  71  51  29  98  84  91  31   6  23  59  32  45  25  80   8  44  85  57 101  53   5 102 104  82  12  60  86  97  93  39  75  77  69  38  66   2  34   9  72  40  61 100  92  56  95  70  58  81  19  33  83  87   4  68 103  16  79   3  27  18  26  67  55  24  48  47  43  14  35  62  15  63  28  20  90  13  52  89]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [63 22 59 66 42 45 75 36 78 74 15 55  2 61 28 58  5 70 35 43 34  4 76  7 64 29 10 67 19 18 44 31 21 30  0 56 38 17 69 14 50 51 73  8 79 25 54 11 27 39  3 32 52 33 68  9 12 23 13 40 71 49 41  6 77 37 57 48 46 24 26 60 62  1 65 53 72 16 47 20], a_shuffle_aclus: [ 84  29  80  87  57  60 100  48 103  98  20  72   4  82  35  79   8  92  47  58  45   6 101  11  85  38  14  89  26  25  59  40  28  39   2  75  52  24  91  19  67  68  97  12 104  32  71  15  34  53   5  43  69  44  90  13  16  30  18  55  93  66  56   9 102  51  77  63  61  31  33  81  83   3  86  70  95  23  62  27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [70 16 63 56 59 67 62 10 66 55 15 21 40  3 26 50 61 72 19 68  7  8 52 18 75 47 24 28 14 31 71 35 48 32 37 43  2 64 27 69 33 74 36 60  9 78 49 46 20 39 17 76 57  6 11 29  4  0 42 45 77 38 23 51 41 73 53  5 65 12 79 22 25 30  1 13 54 34 58 44], a_shuffle_aclus: [ 92  23  84  75  80  89  83  14  87  72  20  28  55   5  33  67  82  95  26  90  11  12  69  25 100  62  31  35  19  40  93  47  63  43  51  58   4  85  34  91  44  98  48  81  13 103  66  61  27  53  24 101  77   9  15  38   6   2  57  60 102  52  30  68  56  97  70   8  86  16 104  29  32  39   3  18  71  45  79  59]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [63 18 42  4 46 49  0  2 78 35 36 39 41 23 30 68 79 16 24 77 37 12 43 27 67 44 60 20 33 65 22 59 47 11 45 29 73 50 54 55  6 31 76 62 26 14 75 71  1 21 51 69 58  9 48 40 32 57 15 56 66 28 52 13  3  8  5 10 53 34  7 72 25 61 19 64 70 38 74 17], a_shuffle_aclus: [ 84  25  57   6  61  66   2   4 103  47  48  53  56  30  39  90 104  23  31 102  51  16  58  34  89  59  81  27  44  86  29  80  62  15  60  38  97  67  71  72   9  40 101  83  33  19 100  93   3  28  68  91  79  13  63  55  43  77  20  75  87  35  69  18   5  12   8  14  70  45  11  95  32  82  26  85  92  52  98  24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 75 58 77 32 41 15 34 74 47 22 31 66 24 53 51 54 39 23 27 59 45 33 38  1  8 10 25 11 28 69 48 46 67 72 21 55 18 61  4 50 35 79  5 30 40 60 49  9 20 36 63 29 73 68 14  6 26 62 71 76 70 64 78 42 13 43  7 19 44 65 37 56 52 12 57  3  0 17 16], a_shuffle_aclus: [  4 100  79 102  43  56  20  45  98  62  29  40  87  31  70  68  71  53  30  34  80  60  44  52   3  12  14  32  15  35  91  63  61  89  95  28  72  25  82   6  67  47 104   8  39  55  81  66  13  27  48  84  38  97  90  19   9  33  83  93 101  92  85 103  57  18  58  11  26  59  86  51  75  69  16  77   5   2  24  23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [59 60  7 13 65 26 70 28  1 19 34 10 18 17 75 16 22 37 73 74 49  8 66 67 72 48 58  0 63 15 61 25 68 55 38 11 45 27 31 77 64 12 41  3  5  2 62 44  6 69 32 33 43 21 78 47  9 20 42 24 46 39 50 23 79 52 76 29 56 53 54 57 40 36 14  4 35 30 51 71], a_shuffle_aclus: [ 80  81  11  18  86  33  92  35   3  26  45  14  25  24 100  23  29  51  97  98  66  12  87  89  95  63  79   2  84  20  82  32  90  72  52  15  60  34  40 102  85  16  56   5   8   4  83  59   9  91  43  44  58  28 103  62  13  27  57  31  61  53  67  30 104  69 101  38  75  70  71  77  55  48  19   6  47  39  68  93]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 63 45 65 41  8 30 76 74 33 62 72 54 55  5 23  6  1 77 69 78 68 52 15 61 14 57 46 20 43 13 42 48 17  4 29 22 59 28 73 64 70 51 36 66 50 19 53 10  9 47 12 31 40  0 21 71 49 34 44  2 39 16 67 79 75 35 58 26 38 27 56 11 24  3 32  7 60 37 25], a_shuffle_aclus: [ 25  84  60  86  56  12  39 101  98  44  83  95  71  72   8  30   9   3 102  91 103  90  69  20  82  19  77  61  27  58  18  57  63  24   6  38  29  80  35  97  85  92  68  48  87  67  26  70  14  13  62  16  40  55   2  28  93  66  45  59   4  53  23  89 104 100  47  79  33  52  34  75  15  31   5  43  11  81  51  32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 20 10 30  6  0 18 73 24 40 66 63 78 55 21 61  5 36 23 43 59 75 79 77 11 22 34 44 35 16 19 60 74 15  3 42 28  7 58 29 52 33 50 70 48 65  4 17 32 27 69 47 68 76 45 51 71 41 56 31 12 38 62 53 26 57 49  1  8 54 64  9 67 14 72 25 39 13  2 46], a_shuffle_aclus: [ 51  27  14  39   9   2  25  97  31  55  87  84 103  72  28  82   8  48  30  58  80 100 104 102  15  29  45  59  47  23  26  81  98  20   5  57  35  11  79  38  69  44  67  92  63  86   6  24  43  34  91  62  90 101  60  68  93  56  75  40  16  52  83  70  33  77  66   3  12  71  85  13  89  19  95  32  53  18   4  61]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [47 12 41 61 66  6 57 73 37 11  3 39 60 44 21 40 34  0 14 43 36 17 20  5 35 31  1 72 65  8 30 45 54 23 56 50 71 32  7 75 70 49 26 76 28 33  9 48 51 74 62 10 22 15 77 13 19 79 55 64 63 69 46 78 53 16 24 68 38 29  2 25 58 18 42 27 52 67 59  4], a_shuffle_aclus: [ 62  16  56  82  87   9  77  97  51  15   5  53  81  59  28  55  45   2  19  58  48  24  27   8  47  40   3  95  86  12  39  60  71  30  75  67  93  43  11 100  92  66  33 101  35  44  13  63  68  98  83  14  29  20 102  18  26 104  72  85  84  91  61 103  70  23  31  90  52  38   4  32  79  25  57  34  69  89  80   6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 78 63 65  3 38 18 57 10  9 74 26 24  6 52 45 28 77 60 39  1 36 69 73 43 49 16 17 62 19 40 21 72 12 27 32  2 68 22 44  4  8  7 42 20 11 35 50 25 75 31 29 33 70  5 13 46  0 66 34 79 48 30 51 14 67 55 56 59 58 41 15 23 64 54 53 76 61 47 71], a_shuffle_aclus: [ 51 103  84  86   5  52  25  77  14  13  98  33  31   9  69  60  35 102  81  53   3  48  91  97  58  66  23  24  83  26  55  28  95  16  34  43   4  90  29  59   6  12  11  57  27  15  47  67  32 100  40  38  44  92   8  18  61   2  87  45 104  63  39  68  19  89  72  75  80  79  56  20  30  85  71  70 101  82  62  93]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 60 15 58 45 21 31 52 54 62 64 73 36 19 14 18 11  4 39 76 67 66 13 50 10 12 22 79 74 49 28  5 16  2 42 44 48 41 29  7 75 65 34 69 32 61 47 35 46 78 51 70 37 40 33 59  8  0 53 68 38 63  1 24 27 55 71 77  6  9  3 17 57 26 23 56 72 30 20 43], a_shuffle_aclus: [ 32  81  20  79  60  28  40  69  71  83  85  97  48  26  19  25  15   6  53 101  89  87  18  67  14  16  29 104  98  66  35   8  23   4  57  59  63  56  38  11 100  86  45  91  43  82  62  47  61 103  68  92  51  55  44  80  12   2  70  90  52  84   3  31  34  72  93 102   9  13   5  24  77  33  30  75  95  39  27  58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 61 18 14 25 10  1 17 23 47 48 24 74 72 63 65 75 35 31 33 41 37 73  2  7 11  3 34 39  9  0 55 71 69 16 52 29 59 21 78 40 42 57 45 15 51 43  6 68 79 44  4 58 27 50 77 54 19 32 60 56  8 36 66 13 70 64 62 76 20 67 38 26 49 22 30 28  5 46 53], a_shuffle_aclus: [ 16  82  25  19  32  14   3  24  30  62  63  31  98  95  84  86 100  47  40  44  56  51  97   4  11  15   5  45  53  13   2  72  93  91  23  69  38  80  28 103  55  57  77  60  20  68  58   9  90 104  59   6  79  34  67 102  71  26  43  81  75  12  48  87  18  92  85  83 101  27  89  52  33  66  29  39  35   8  61  70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 30 56 71 23 61  0 45 64 53 60 78 66 31 72 46 77 41 34 29 55 50 57 10 69 16 15 35 47 12 73 22 75 49 17 42 25 63  6 33 18 26  8 51 48 76 70 24 14 62  7  1 67 44 21 39 32 40  4 11 38 28 79 37 58 27 65 68 20  3 13 36  2 43 74 54  9 52 19 59], a_shuffle_aclus: [  8  39  75  93  30  82   2  60  85  70  81 103  87  40  95  61 102  56  45  38  72  67  77  14  91  23  20  47  62  16  97  29 100  66  24  57  32  84   9  44  25  33  12  68  63 101  92  31  19  83  11   3  89  59  28  53  43  55   6  15  52  35 104  51  79  34  86  90  27   5  18  48   4  58  98  71  13  69  26  80]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 11 74 16  8 35 42 73  7 22 67 65 47 21  9 39 26 10 72 70 69 61 18 51 37  1 50 20 76 75 54 43 57 45 36 17 49 78 48 13  6 31  0 71 59 56 34  5 38 68 40  2 14 62 15 30 52 77 60 58 64 25 12 46 53  4 44 79 27  3 24 33 63 55 32 29 66 41 23 19], a_shuffle_aclus: [ 35  15  98  23  12  47  57  97  11  29  89  86  62  28  13  53  33  14  95  92  91  82  25  68  51   3  67  27 101 100  71  58  77  60  48  24  66 103  63  18   9  40   2  93  80  75  45   8  52  90  55   4  19  83  20  39  69 102  81  79  85  32  16  61  70   6  59 104  34   5  31  44  84  72  43  38  87  56  30  26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 78  0 51 64 37 10 63 50 34 69 70 19 48 74 18 71 31 79 42 39 45 54 14 76  5 60 52 13 36 66 41 32 67 33 47 43 22 15 77 16  8  6 21  3 58 40 30 68 24 29 25  7 56 72 75 65 61 23 27 35 12 46 49 11 59 38  4 20 26  1 28 53 57 55  9  2 17 73 62], a_shuffle_aclus: [ 59 103   2  68  85  51  14  84  67  45  91  92  26  63  98  25  93  40 104  57  53  60  71  19 101   8  81  69  18  48  87  56  43  89  44  62  58  29  20 102  23  12   9  28   5  79  55  39  90  31  38  32  11  75  95 100  86  82  30  34  47  16  61  66  15  80  52   6  27  33   3  35  70  77  72  13   4  24  97  83]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [58 57 44 51 79 28 61 20 54  8  0 78 50 27 55 72  3 15 75 74  4 18 59 38 63 37 66 32 33  9 69 26  7  2  5 34 39 64 68 70 10 13 21 76 40 30  6 77 48 52 53 43 24 16 49 65 17 46 41 60 14 19 31 36 56 12 22 71 11  1 73 47 67 42 45 23 29 62 25 35], a_shuffle_aclus: [ 79  77  59  68 104  35  82  27  71  12   2 103  67  34  72  95   5  20 100  98   6  25  80  52  84  51  87  43  44  13  91  33  11   4   8  45  53  85  90  92  14  18  28 101  55  39   9 102  63  69  70  58  31  23  66  86  24  61  56  81  19  26  40  48  75  16  29  93  15   3  97  62  89  57  60  30  38  83  32  47]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [71 25 43 57 38 15 53 61 66 54 29 78  8  0 16 73 65 23 64 46 34 21 58 19 72 42 27 60 39 49 51 76 52 26 32 37 35 50 56 79 68 36 67 14  7 28 22  9 41 77 45 75 11 69 44  1 17 18 24 12 13 59 10 30 48 20 63 55  4 31 70 62  5  2  3  6 74 33 40 47], a_shuffle_aclus: [ 93  32  58  77  52  20  70  82  87  71  38 103  12   2  23  97  86  30  85  61  45  28  79  26  95  57  34  81  53  66  68 101  69  33  43  51  47  67  75 104  90  48  89  19  11  35  29  13  56 102  60 100  15  91  59   3  24  25  31  16  18  80  14  39  63  27  84  72   6  40  92  83   8   4   5   9  98  44  55  62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [74 31  2 30 34 63 27 42 46  0 21 35 68  9 79 33 18 51 56 47 71 11 17 76 57 23 69 12 29  1 72 39 64  7 24 16 44  8 62 32 73  4 25 78 58 14 54 15 65 13  6 53 43 52 36 41 40 10 59 70 77 67 75 37 38 55 26  3 50 20 60 48 19 22 45 61  5 28 66 49], a_shuffle_aclus: [ 98  40   4  39  45  84  34  57  61   2  28  47  90  13 104  44  25  68  75  62  93  15  24 101  77  30  91  16  38   3  95  53  85  11  31  23  59  12  83  43  97   6  32 103  79  19  71  20  86  18   9  70  58  69  48  56  55  14  80  92 102  89 100  51  52  72  33   5  67  27  81  63  26  29  60  82   8  35  87  66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [46 66 78 24 26 12 49 70 59 21 63 51 20  3 33 13 10 48 67 65 58 29 57 54 30 76 56 64 53 68 17 73  9 52 36 47 27 50 32 74 44 75 60 41 28  8 72 71 34 38 40 16  1 14 39  4 77 69 19 45 37 18 79 61  5 11 22 43 15 35 31  7  6 25 55  2 23 62  0 42], a_shuffle_aclus: [ 61  87 103  31  33  16  66  92  80  28  84  68  27   5  44  18  14  63  89  86  79  38  77  71  39 101  75  85  70  90  24  97  13  69  48  62  34  67  43  98  59 100  81  56  35  12  95  93  45  52  55  23   3  19  53   6 102  91  26  60  51  25 104  82   8  15  29  58  20  47  40  11   9  32  72   4  30  83   2  57]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [74 46 65 22 32 40 30 35 48 27 45 79 23 43 13  4 39 53 14 11 29 66 21  9 41 36  0 54 24 67 17 42 38 55 44 56  8 10 28 50 62 49 57 19 31 63 72 37 71 75 58 51 78  1 59 61 16  6 25 12 18 15 68 76 64 69 33  3 47  7 26 52 73 70 20  2  5 60 77 34], a_shuffle_aclus: [ 98  61  86  29  43  55  39  47  63  34  60 104  30  58  18   6  53  70  19  15  38  87  28  13  56  48   2  71  31  89  24  57  52  72  59  75  12  14  35  67  83  66  77  26  40  84  95  51  93 100  79  68 103   3  80  82  23   9  32  16  25  20  90 101  85  91  44   5  62  11  33  69  97  92  27   4   8  81 102  45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [53 34 75 38 37 58 72 16 76 50 35 12 54  6 24 22  3 13 43 60 70 65 27 78 49 77 20 19 51 23 31 36 32 66  0 44 47 28 74 67 39 57 15 68  2 79 55  8  1 73 40 48 63 21 11 18 14  4 59 33  7 52 45 17 42 10 25 29 71 30 61 64 56 69 26 46  9 62 41  5], a_shuffle_aclus: [ 70  45 100  52  51  79  95  23 101  67  47  16  71   9  31  29   5  18  58  81  92  86  34 103  66 102  27  26  68  30  40  48  43  87   2  59  62  35  98  89  53  77  20  90   4 104  72  12   3  97  55  63  84  28  15  25  19   6  80  44  11  69  60  24  57  14  32  38  93  39  82  85  75  91  33  61  13  83  56   8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "INFO:2024-07-10_18-07-26.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:save_pipeline(): Attempting to save pipeline to disk...\n",
      "INFO:2024-07-10_18-07-26.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\tfinalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.pkl\n",
      "Saving (file mode 'w+b') pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/20240710184446-loadedSessPickle_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.0.pkl\"... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2024-07-10_18-07-26.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: prev_extant_file_size_MB (12813.496245384216 MB) > new_temporary_file_size_MB (8791.337862968445 MB)! A backup will be made!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved pickle file\n",
      "WARNING: prev_extant_file_size_MB (12813.496245384216 MB) > new_temporary_file_size_MB (8791.337862968445 MB)! A backup will be made!\n",
      "'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.pkl' backing up -> to_file: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\backup-20240710184521-loadedSessPickle_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.pkl.bak'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_18-07-26.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:moving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\20240710184446-loadedSessPickle_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.0.pkl' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.pkl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\20240710184446-loadedSessPickle_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.0.pkl' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_18-07-26.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t save complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_save_filepaths: {'pipeline_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.pkl'), 'global_computation_pkl': 'global_computation_results_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.pkl', 'pipeline_h5': 'pipeline_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.h5', 'ripple_h5_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10_Apogee_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-2006-6-09_1-22-43-_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0_time_bin_size_sweep_results.h5'), 'ripple_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-(ripple_marginals_df).csv'), 'ripple_csv_time_bin_marginals': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-(ripple_time_bin_marginals_df).csv'), 'laps_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-(laps_marginals_df).csv'), 'laps_csv_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-(laps_time_bin_marginals_df).csv')}\n",
      "wcorr_ripple_shuffle.n_completed_shuffles: 25\n",
      "n_epochs: 136\n",
      "n_completed_shuffles: 25\n",
      "a_shuffle_IDXs: [61 22 58 46 42 15 64 40 41 34 20  4  5 53 36 12 19 69 67 62 59 44 28 65 50 37 49 75 26 33 11 66  7 48 74  6 54  8 45 77 68 63 43 57 56 73 70 13 47 39 32  0 23 51  9 71 38  2 10 16 14 30 72 25 24 76 21 31 55 29 79 18 17 60 52  3  1 78 27 35], a_shuffle_aclus: [ 82  29  79  61  57  20  85  55  56  45  27   6   8  70  48  16  26  91  89  83  80  59  35  86  67  51  66 100  33  44  15  87  11  63  98   9  71  12  60 102  90  84  58  77  75  97  92  18  62  53  43   2  30  68  13  93  52   4  14  23  19  39  95  32  31 101  28  40  72  38 104  25  24  81  69   5   3 103  34  47]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [76 32 20 48  4 79 31 26 45 28 30  3 75 55  6 73 19  0 12 14  5 16 49 41 54 65 25 68 63 40 27 37 74 38 13 69 39 33 15 62  7 42 24 58 35  1 29 77 70 23 43 59  9 52  2 34 36 22 72 17 56 60 50 53 78 11 51 47 61 71  8 44 18 64 57 67 10 21 46 66], a_shuffle_aclus: [101  43  27  63   6 104  40  33  60  35  39   5 100  72   9  97  26   2  16  19   8  23  66  56  71  86  32  90  84  55  34  51  98  52  18  91  53  44  20  83  11  57  31  79  47   3  38 102  92  30  58  80  13  69   4  45  48  29  95  24  75  81  67  70 103  15  68  62  82  93  12  59  25  85  77  89  14  28  61  87]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_completed_shuffles: 27\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "total_n_shuffles: 27\n",
      "total_n_shuffles: 27\n",
      "(n_shuffles = 27, n_epochs = 136, n_decoders = 4); n_total_elements = 14688\n",
      "saving to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0645PM_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0_standalone_wcorr_ripple_shuffle_data_only_27.pkl\"...\n",
      "total_n_shuffles: 27\n",
      "Saving (file mode 'w+b') pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0645PM_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0_standalone_wcorr_ripple_shuffle_data_only_27.pkl\"... saved pickle file\n",
      "saving .mat file to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0645PM_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0_standalone_all_shuffles_wcorr_array.mat\"...\n",
      "total_n_shuffles: 27\n",
      "(n_shuffles = 27, n_epochs = 136, n_decoders = 4); n_total_elements = 14688\n",
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 136\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "num_user_selected_times: 0\n",
      "adding user annotation column!\n",
      "ERROR: failed for ripple_WCorrShuffle_df. Out of options.\n",
      "\t failed all methods for annotations\n",
      "num_valid_epoch_times: 136\n",
      "adding valid filtered epochs column!\n",
      "\t succeded at getting 136 selected indicies (of 136 valid filter epoch times) for ripple_WCorrShuffle_df. got 136 indicies!\n",
      "Successfully exported ripple_WCorrShuffle_df_export_CSV_path: \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0640PM-kdiba_gor01_one_2006-6-09_1-22-43-(ripple_WCorrShuffle_df)_tbin-0.025.csv\" with wcorr_shuffles.n_completed_shuffles: 27 unique shuffles.\n",
      "completed overwrite_replay_epochs_and_recompute(...). custom_save_filepaths: {'pipeline_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.pkl'), 'global_computation_pkl': 'global_computation_results_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.pkl', 'pipeline_h5': 'pipeline_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.h5', 'ripple_h5_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10_Apogee_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-2006-6-09_1-22-43-_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0_time_bin_size_sweep_results.h5'), 'ripple_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-(ripple_marginals_df).csv'), 'ripple_csv_time_bin_marginals': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-(ripple_time_bin_marginals_df).csv'), 'laps_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-(laps_marginals_df).csv'), 'laps_csv_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-(laps_time_bin_marginals_df).csv'), 'standalone_wcorr_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0645PM_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0_standalone_wcorr_ripple_shuffle_data_only_27.pkl'), 'standalone_mat_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0645PM_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0_standalone_all_shuffles_wcorr_array.mat')}\n",
      "\n",
      "<<<<<<<<<<<<<<< Done with `overwrite_replay_epochs_and_recompute(...)` for replay_epochs_key: normal_computed\n",
      "\t\twcorr_ripple_shuffle.n_completed_shuffles: 27\n",
      "n_epochs: 136\n",
      "n_completed_shuffles: 27\n",
      "a_shuffle_IDXs: [44 19 52 18 76 50 66 41 30 38 33  9 73 24 34 28 47 78 27 54  0 55 21  3 56 39 63 37 74 72  7 62 31  4 26 77 49 40 68 17  1 59 20 12 29 42  5 45 70  6 25 79 58 13 65 15 75 64 36 35 67 61 53 51 10 46 60 43 14 16 22 11 23 69  8 32 48  2 57 71], a_shuffle_aclus: [ 59  26  69  25 101  67  87  56  39  52  44  13  97  31  45  35  62 103  34  71   2  72  28   5  75  53  84  51  98  95  11  83  40   6  33 102  66  55  90  24   3  80  27  16  38  57   8  60  92   9  32 104  79  18  86  20 100  85  48  47  89  82  70  68  14  61  81  58  19  23  29  15  30  91  12  43  63   4  77  93]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [60 74 40 62 78 23 57 34 29 18 25  5  0 54 47 15 53 43 75 46 14 77  4 76 64  1 61 10 51 39  2 20 17 13  7  6 67  9 33 55 24 22 26 32 73  3 56 72 63 21 12 71 28 44 41 66 52 11 42 31 37 69 50 49 58  8 79 38 16 68 45 19 70 65 35 27 48 36 59 30], a_shuffle_aclus: [ 81  98  55  83 103  30  77  45  38  25  32   8   2  71  62  20  70  58 100  61  19 102   6 101  85   3  82  14  68  53   4  27  24  18  11   9  89  13  44  72  31  29  33  43  97   5  75  95  84  28  16  93  35  59  56  87  69  15  57  40  51  91  67  66  79  12 104  52  23  90  60  26  92  86  47  34  63  48  80  39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_completed_shuffles: 29\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "total_n_shuffles: 29\n",
      "(n_shuffles = 29, n_epochs = 136, n_decoders = 4); n_total_elements = 15776\n",
      "saving to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0645PM_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0_standalone_wcorr_ripple_shuffle_data_only_29.pkl\"...\n",
      "total_n_shuffles: 29\n",
      "Saving (file mode 'w+b') pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0645PM_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0_standalone_wcorr_ripple_shuffle_data_only_29.pkl\"... saved pickle file\n",
      "saving .mat file to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0645PM_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0_standalone_all_shuffles_wcorr_array.mat\"...\n",
      "total_n_shuffles: 29\n",
      "(n_shuffles = 29, n_epochs = 136, n_decoders = 4); n_total_elements = 15776\n",
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 136\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "num_user_selected_times: 0\n",
      "adding user annotation column!\n",
      "ERROR: failed for ripple_WCorrShuffle_df. Out of options.\n",
      "\t failed all methods for annotations\n",
      "num_valid_epoch_times: 136\n",
      "adding valid filtered epochs column!\n",
      "\t succeded at getting 136 selected indicies (of 136 valid filter epoch times) for ripple_WCorrShuffle_df. got 136 indicies!\n",
      "Successfully exported ripple_WCorrShuffle_df_export_CSV_path: \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0640PM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv\" with wcorr_shuffles.n_completed_shuffles: 29 unique shuffles.\n",
      "\t saved \"file:///C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2024-07-10/kdiba/gor01/one/2006-6-09_1-22-43/replay_wcorr__withNormalComputedReplays-qclu_%5B1%2C2%5D-frateThresh_1%E2%80%A20.png\"\n",
      "\t=====================================>> performing comp for \"diba_quiescent_method_replay_epochs\"...\n",
      "\treplay_epochs_key: diba_quiescent_method_replay_epochs: custom_suffix: \"_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0\"\n",
      "\tcurr_BATCH_DATE_TO_USE: \"2024-07-10_Apogee_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0\"\n",
      "\tWARNING: should_suppress_errors: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_18-07-18.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:==========================================================================================\n",
      "========== Logger INIT \"2024-07-10_18-07-18.Apogee.kdiba.gor01.one.2006-6-09_1-22-43\" ==============================\n",
      "INFO:2024-07-10_18-07-18.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:NeuropyPipeline.__setstate__(state=\"{'pipeline_name': 'kdiba_pipeline', 'session_data_type': 'kdiba', '_stage': <pyphoplacecellanalysis.General.Pipeline.Stages.Display.DisplayPipelineStage object at 0x000002171E166BB0>}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_logger(full_logger_string=\"2024-07-10_18-07-18.Apogee.kdiba.gor01.one.2006-6-09_1-22-43\", file_logging_dir: None):\n",
      "custom_suffix: \"_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0\"\n",
      "Using custom suffix: \"_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0\" - additional_session_context: \"_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0\"\n",
      "did_change: True\n",
      "custom_save_filenames: {'pipeline_pkl': 'loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl', 'global_computation_pkl': 'global_computation_results_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl', 'pipeline_h5': 'pipeline_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.h5'}\n",
      "replay epochs changed!\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['merged_directional_placefields', 'perform_rank_order_shuffle_analysis'], ...)...\n",
      "\trun_specific_computations_single_context(including only 2 out of 16 registered computation functions): active_computation_functions: [<function DirectionalPlacefieldGlobalComputationFunctions._build_merged_directional_placefields at 0x0000021388D969D0>, <function RankOrderGlobalComputationFunctions.perform_rank_order_shuffle_analysis at 0x000002139891D4C0>]...\n",
      "Performing _execute_computation_functions(...) with 2 registered_computation_functions...\n",
      "Executing [0/2]: <function DirectionalPlacefieldGlobalComputationFunctions._build_merged_directional_placefields at 0x00000219EB6680D0>\n",
      "skipping lap recomputation because laps_decoding_time_bin_size == None\n",
      "WARN: ripple_decoding_time_bin_size 0.025 < min_possible_time_bin_size (0.051). This used to be enforced but continuing anyway.\n",
      "Executing [1/2]: <function RankOrderGlobalComputationFunctions.perform_rank_order_shuffle_analysis at 0x00000219EB668160>\n",
      "WARN: perform_rank_order_shuffle_analysis(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "####> perform_rank_order_shuffle_analysis(..., num_shuffles=25)\n",
      "\t##> computing Ripple rank-order shuffles:\n",
      "ERROR! BUG?! 2023-12-21 - Need to update the previous 'DirectionalLaps' object with the qclu-restricted one right? on filter\n",
      "ripple_evts_paired_tests: [TtestResult(statistic=-5.520075119832941, pvalue=7.684967293306242e-08, df=282), TtestResult(statistic=-6.789154653438203, pvalue=6.657852650736752e-11, df=282)]\n",
      "\tdone. building global result.\n",
      "n_valid_shuffles: 25\n",
      "combined_variable_names: ['long_LR_pearson', 'long_RL_pearson', 'short_LR_spearman', 'long_LR_spearman', 'short_RL_pearson', 'short_LR_pearson', 'long_RL_spearman', 'short_RL_spearman']\n",
      "combined_variable_z_score_column_names: ['long_LR_pearson_Z', 'long_RL_pearson_Z', 'short_LR_spearman_Z', 'long_LR_spearman_Z', 'short_RL_pearson_Z', 'short_LR_pearson_Z', 'long_RL_spearman_Z', 'short_RL_spearman_Z']\n",
      "done!\n",
      "\tdone. building global result.\n",
      "< done with `perform_rank_order_shuffle_analysis(...)`\n",
      "\t all computations complete! (Computed 2 with no errors!.\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], ...)...\n",
      "\trun_specific_computations_single_context(including only 2 out of 16 registered computation functions): active_computation_functions: [<function DirectionalPlacefieldGlobalComputationFunctions._decode_and_evaluate_epochs_using_directional_decoders at 0x0000021388D96AF0>, <function DirectionalPlacefieldGlobalComputationFunctions._decoded_epochs_heuristic_scoring at 0x0000021388D96B80>]...\n",
      "Performing _execute_computation_functions(...) with 2 registered_computation_functions...\n",
      "Executing [0/2]: <function DirectionalPlacefieldGlobalComputationFunctions._decode_and_evaluate_epochs_using_directional_decoders at 0x00000216AEF5C940>\n",
      "laps_decoding_time_bin_size: 0.25, ripple_decoding_time_bin_size: 0.025, pos_bin_size: 3.8054171165052444\n",
      "laps_decoding_time_bin_size: 0.25, ripple_decoding_time_bin_size: 0.025, pos_bin_size: 3.8054171165052444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "Performance: Radon Transform:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 11/84\n",
      "\tagreeing_rows_ratio: 0.13095238095238096\n",
      "\tPerformance: Ripple: Radon Transform:\n",
      "agreeing_rows_count/num_total_epochs: 27/360\n",
      "\tagreeing_rows_ratio: 0.075\n",
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 64/84\n",
      "\tagreeing_rows_ratio: 0.7619047619047619\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 100/360\n",
      "\tagreeing_rows_ratio: 0.2777777777777778\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 75/84\n",
      "\tagreeing_rows_ratio: 0.8928571428571429\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 95/360\n",
      "\tagreeing_rows_ratio: 0.2638888888888889\n",
      "Executing [1/2]: <function DirectionalPlacefieldGlobalComputationFunctions._decoded_epochs_heuristic_scoring at 0x0000021893C968B0>\n",
      "\t all computations complete! (Computed 2 with no errors!.\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(curr_session_context: kdiba_gor01_one_2006-6-09_1-22-43, curr_session_basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43, ...)\n",
      "\tactive_context: kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0\n",
      "\tsession_ctxt_key: kdiba|gor01|one|2006-6-09_1-22-43|_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0\n",
      "\tCURR_BATCH_OUTPUT_PREFIX: 2024-07-10_Apogee_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-2006-6-09_1-22-43-_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0\n",
      "\tout_path_str: \"2024-07-10_Apogee_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-2006-6-09_1-22-43-_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_time_bin_size_sweep_results.h5\"\n",
      "\tout_path: \"K:\\scratch\\collected_outputs\\2024-07-10_Apogee_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-2006-6-09_1-22-43-_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_time_bin_size_sweep_results.h5\"\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\ta_sweep_dict: {'desired_laps_decoding_time_bin_size': 1.5, 'desired_ripple_decoding_time_bin_size': 0.01, 'use_single_time_bin_per_epoch': False, 'minimum_event_duration': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.02).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.02.\t360 remain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning:\n",
      "\n",
      "object name is not a valid Python identifier: 'kdiba|gor01|one|2006-6-09_1-22-43|_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning:\n",
      "\n",
      "object name is not a valid Python identifier: '1.5'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning:\n",
      "\n",
      "object name is not a valid Python identifier: '0.01'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 27/84\n",
      "\tagreeing_rows_ratio: 0.32142857142857145\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 101/360\n",
      "\tagreeing_rows_ratio: 0.28055555555555556\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 72/84\n",
      "\tagreeing_rows_ratio: 0.8571428571428571\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 102/360\n",
      "\tagreeing_rows_ratio: 0.2833333333333333\n",
      "\ta_sweep_dict: {'desired_laps_decoding_time_bin_size': 1.5, 'desired_ripple_decoding_time_bin_size': 0.02, 'use_single_time_bin_per_epoch': False, 'minimum_event_duration': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.02).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.02.\t360 remain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning:\n",
      "\n",
      "object name is not a valid Python identifier: '0.02'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 27/84\n",
      "\tagreeing_rows_ratio: 0.32142857142857145\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 98/360\n",
      "\tagreeing_rows_ratio: 0.2722222222222222\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 72/84\n",
      "\tagreeing_rows_ratio: 0.8571428571428571\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 100/360\n",
      "\tagreeing_rows_ratio: 0.2777777777777778\n",
      ">>\t done with kdiba_gor01_one_2006-6-09_1-22-43\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "perform_drop_computed_result(computed_data_keys_to_drop: ['SequenceBased'], config_names_includelist: None)\n",
      "\t global_computation_results.computed_data['SequenceBased'] did not exist.\n",
      "\t Dropped computation_results['maze1_odd'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze2_odd'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze_odd'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze1_even'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze2_even'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze_even'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze1_any'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze2_any'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze_any'].computed_data['SequenceBased'].\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['wcorr_shuffle_analysis'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function SequenceBasedComputationsGlobalComputationFunctions.perform_wcorr_shuffle_analysis at 0x000002139886AA60>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function SequenceBasedComputationsGlobalComputationFunctions.perform_wcorr_shuffle_analysis at 0x00000217D61761F0>\n",
      "WARN: perform_wcorr_shuffle_analysis(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "perform_wcorr_shuffle_analysis(..., num_shuffles=25)\n",
      "len(active_epochs_df): 360\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 196\n",
      "len(active_epochs_df): 360\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_decoder_ripple_weighted_corr_arr: (196, 4)\n",
      "n_prev_completed_shuffles: 0.\n",
      "needed num_shuffles: 25.\n",
      "need desired_new_num_shuffles: 25 more shuffles.\n",
      "a_shuffle_IDXs: [42 64 11 28 12 47 78 10 35 56 24 37 39 36 14 21  3 65 52  5  4 49 25 62 67 63 43 51 73 41 75 18  2 55 30 71 72 40 54 48 58 69 32 17 16 26 57 61 45 29  1 77 50 76 27  6  8 70 38 31 34 60  9 59 22  7 44  0 20 46 23 74 68 66 15 13 53 19 33 79], a_shuffle_aclus: [ 57  85  15  35  16  62 103  14  47  75  31  51  53  48  19  28   5  86  69   8   6  66  32  83  89  84  58  68  97  56 100  25   4  72  39  93  95  55  71  63  79  91  43  24  23  33  77  82  60  38   3 102  67 101  34   9  12  92  52  40  45  81  13  80  29  11  59   2  27  61  30  98  90  87  20  18  70  26  44 104]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 51 37 78 68 67 47 73 21 53 33 54 19 77 63  3 22 27 79 25 72 66 29 38  5 18 36 50 64 11 43 55  2 75 59 45 49 39 42 69 60 76 34 16 52 62 10 41 26 23  0 13 65 58 20 40 28 30 71  4 35 44 48  8 46 31  9 74  7 32  6  1 12 61 56 15 70 57 14 24], a_shuffle_aclus: [ 24  68  51 103  90  89  62  97  28  70  44  71  26 102  84   5  29  34 104  32  95  87  38  52   8  25  48  67  85  15  58  72   4 100  80  60  66  53  57  91  81 101  45  23  69  83  14  56  33  30   2  18  86  79  27  55  35  39  93   6  47  59  63  12  61  40  13  98  11  43   9   3  16  82  75  20  92  77  19  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 29  3 59 12 41 42 74  9 75 79 78 38 31 50 62 60  0 24 43  6 16 14 35 28 37 44 19 45 18 48 47 72 34 21 39 17 46 71  5 26 54 51 20  4 55 70 65  7 56 52 36 69  2 10 32 25 77 64 27 40 68 61 49 58 57 15 33 11 22 66 63  1 76  8 23 13 67 73 53], a_shuffle_aclus: [ 39  38   5  80  16  56  57  98  13 100 104 103  52  40  67  83  81   2  31  58   9  23  19  47  35  51  59  26  60  25  63  62  95  45  28  53  24  61  93   8  33  71  68  27   6  72  92  86  11  75  69  48  91   4  14  43  32 102  85  34  55  90  82  66  79  77  20  44  15  29  87  84   3 101  12  30  18  89  97  70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24 54 21 27 37 38 30 10 11  2 52 58 26 17 23 64 70 28 68 76 67 33  3 44 19  4 42 50 65  1 29 36 47 79 71  9 53 22 18 14 39 60 63 74  7 25 78 31 66 34 57 55 45 40 56 12 69 49  6 43 62 73 15 41 61 51  0 59 48  8 32 75 20 46 16 13 72  5 77 35], a_shuffle_aclus: [ 31  71  28  34  51  52  39  14  15   4  69  79  33  24  30  85  92  35  90 101  89  44   5  59  26   6  57  67  86   3  38  48  62 104  93  13  70  29  25  19  53  81  84  98  11  32 103  40  87  45  77  72  60  55  75  16  91  66   9  58  83  97  20  56  82  68   2  80  63  12  43 100  27  61  23  18  95   8 102  47]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 31  6 69 33 43 71 46 62 32 57 58 56 22 19  4 52 28  7 50  3 15 45 17 23 40 68 48  9 21 38 55 67 77 73 78 11 24 12 53 30 75 59 18 26 16 36 25 72 79 76 13 20 74  1 41 66 42 14 51 34 70  8 61  5 65 44 35 54 47  2 60 37 64 63 49 10 29 27  0], a_shuffle_aclus: [ 53  40   9  91  44  58  93  61  83  43  77  79  75  29  26   6  69  35  11  67   5  20  60  24  30  55  90  63  13  28  52  72  89 102  97 103  15  31  16  70  39 100  80  25  33  23  48  32  95 104 101  18  27  98   3  56  87  57  19  68  45  92  12  82   8  86  59  47  71  62   4  81  51  85  84  66  14  38  34   2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 69 37  9 72 39 15 76 38  5  4 77 67 50 49 54 14 40 32 12 73 17 56 71  1 10 61 22 68 58 34 65 24 42 63 41 36 19 29 51  7 26 30 53 62 31 47 35 27 33 70 75 48  8 45 46 79 28  0 44 13  3 60 59  2 25 21 66 52 23 20 11 18 78 64 55 74 57 16 43], a_shuffle_aclus: [  9  91  51  13  95  53  20 101  52   8   6 102  89  67  66  71  19  55  43  16  97  24  75  93   3  14  82  29  90  79  45  86  31  57  84  56  48  26  38  68  11  33  39  70  83  40  62  47  34  44  92 100  63  12  60  61 104  35   2  59  18   5  81  80   4  32  28  87  69  30  27  15  25 103  85  72  98  77  23  58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [58 14 29 37 49  1 35 55 10 50 28 63 59 76 69 26  4  9 56 38  0  3 16 66 12  5 33  7 43 65 73 64 57  8 30 31 51 39 19  6 70 54 71 78 53 11 13 34 74 44 40 61 20 32 41 22 45 15 62 75 47 46  2 25 23 52 67 42 21 60 36 77 48 72 68 79 17 24 27 18], a_shuffle_aclus: [ 79  19  38  51  66   3  47  72  14  67  35  84  80 101  91  33   6  13  75  52   2   5  23  87  16   8  44  11  58  86  97  85  77  12  39  40  68  53  26   9  92  71  93 103  70  15  18  45  98  59  55  82  27  43  56  29  60  20  83 100  62  61   4  32  30  69  89  57  28  81  48 102  63  95  90 104  24  31  34  25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 58 20 29 25 34 19 57  8 31 36  5 16 74  3  1 17 47 54 37 49 64 75 43 55 67 56 59 79  7 65 35 68 53 71 76 60 51 46 12 50 62 23 40 10 69 73 63  9 22 13  4 21 24 30 52 72 48 15  2 42 66 41 33 14 18 28 27 26  6 11 61 77 32 39  0 44 70 38 78], a_shuffle_aclus: [ 60  79  27  38  32  45  26  77  12  40  48   8  23  98   5   3  24  62  71  51  66  85 100  58  72  89  75  80 104  11  86  47  90  70  93 101  81  68  61  16  67  83  30  55  14  91  97  84  13  29  18   6  28  31  39  69  95  63  20   4  57  87  56  44  19  25  35  34  33   9  15  82 102  43  53   2  59  92  52 103]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [68 33 71 45 48 74 60  0 73 63 61 14  6 52 70 79 13 16 18 39 20 59 67  2  9 15 30 56 78 62 17 57 41 66 21 69 75 29 26 64 42 34  8 44 24 37 40 31 22 55  1  5 49 10 23 53 76 50 43 19 46  3 65 28 32 35 27 77  7 25 58 51 12 38 72 54 47  4 11 36], a_shuffle_aclus: [ 90  44  93  60  63  98  81   2  97  84  82  19   9  69  92 104  18  23  25  53  27  80  89   4  13  20  39  75 103  83  24  77  56  87  28  91 100  38  33  85  57  45  12  59  31  51  55  40  29  72   3   8  66  14  30  70 101  67  58  26  61   5  86  35  43  47  34 102  11  32  79  68  16  52  95  71  62   6  15  48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44  4 56 38 51 53 69 41 24 28 46 50 48 26 62 79 27 12 52 75  3 16  6 42 49 63 60 70 65 35 33 21 76  8 72 54 66 17 13 39 40  7 20 55 15 43 25 57 61 10 77 18 32 22 29 74 71  1 23 19 73 31 11 64 37  5 30 67 59 14 34 58 47 78  0 45 36 68  9  2], a_shuffle_aclus: [ 59   6  75  52  68  70  91  56  31  35  61  67  63  33  83 104  34  16  69 100   5  23   9  57  66  84  81  92  86  47  44  28 101  12  95  71  87  24  18  53  55  11  27  72  20  58  32  77  82  14 102  25  43  29  38  98  93   3  30  26  97  40  15  85  51   8  39  89  80  19  45  79  62 103   2  60  48  90  13   4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [70 12 37 27 44 42 35 13 54 47 28 48 62  1 75 41 52 19 21  9 72 29 55 71 57 77 67 46 59  2  5 17 36 25 79 66 40 18 65 14  7 76 43 73 49 64 51 74 56 58  0 45 22 24 78 60  4 33 69 11 61 31 50 20 34 30 39  6 63 68 38  3 16 32 26 15 53  8 10 23], a_shuffle_aclus: [ 92  16  51  34  59  57  47  18  71  62  35  63  83   3 100  56  69  26  28  13  95  38  72  93  77 102  89  61  80   4   8  24  48  32 104  87  55  25  86  19  11 101  58  97  66  85  68  98  75  79   2  60  29  31 103  81   6  44  91  15  82  40  67  27  45  39  53   9  84  90  52   5  23  43  33  20  70  12  14  30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 48 50  2  8  5 54 28 40 45 10 42 18 15 62 38 16 14 11 49 36 32 23 76 20 52 21 43 74 69 67  7 59 13 39 65 64 35 79 29 61 68 73 31 60 53 55  4 57  1 63 58 70 46 71  9 77 72  6 24  3 47 33 51 44 34 19 25 41 75 22 27 17 37 56  0 12 26 78 66], a_shuffle_aclus: [ 39  63  67   4  12   8  71  35  55  60  14  57  25  20  83  52  23  19  15  66  48  43  30 101  27  69  28  58  98  91  89  11  80  18  53  86  85  47 104  38  82  90  97  40  81  70  72   6  77   3  84  79  92  61  93  13 102  95   9  31   5  62  44  68  59  45  26  32  56 100  29  34  24  51  75   2  16  33 103  87]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 77 40  3 74 35 29 10 12 50 19 37 75 11  5 78  1 53 26 41 76  6 34 58 17 73 13 14  2  8 49 43 30 79 64  0 36 16 47 31 57 20  7 48 70 56  9 33 21 61 67 15 55 22 68 65 69 60 27 62 24 52 38 32 39 28 71 44 63 25 66 23 46 72 54 45 59 51 42  4], a_shuffle_aclus: [ 25 102  55   5  98  47  38  14  16  67  26  51 100  15   8 103   3  70  33  56 101   9  45  79  24  97  18  19   4  12  66  58  39 104  85   2  48  23  62  40  77  27  11  63  92  75  13  44  28  82  89  20  72  29  90  86  91  81  34  83  31  69  52  43  53  35  93  59  84  32  87  30  61  95  71  60  80  68  57   6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 14 52 71 22 38  5 77 11 21 24 53 56 32 34 78 49 75  6 48 41 70 79 26 44  7 17 55 67 46 33 13 36  8  0  4 65 76 15  9 20 40 59 64 73  3 10 27 39 61 30 29 28 16 57 18  2 66 19 63 60 23 47 62 74 68 54 37 72 25 58 42 69  1 12 45 51 31 50 35], a_shuffle_aclus: [ 58  19  69  93  29  52   8 102  15  28  31  70  75  43  45 103  66 100   9  63  56  92 104  33  59  11  24  72  89  61  44  18  48  12   2   6  86 101  20  13  27  55  80  85  97   5  14  34  53  82  39  38  35  23  77  25   4  87  26  84  81  30  62  83  98  90  71  51  95  32  79  57  91   3  16  60  68  40  67  47]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [78  4 75 39 79 59 14 32 27 19 48 47 71 37 68 24 65 36 18 62 25  9 11 57 55 21 20 66 10 22 26 53 41 23 43 35 44 67 29 56 12 46 70 51  2 49 16 13 61 17  1 33 15 76  3 58 34 40 64 60  5 73  8 52 54 28 42  6 77 45 38  7 72 50 31 69 74 63  0 30], a_shuffle_aclus: [103   6 100  53 104  80  19  43  34  26  63  62  93  51  90  31  86  48  25  83  32  13  15  77  72  28  27  87  14  29  33  70  56  30  58  47  59  89  38  75  16  61  92  68   4  66  23  18  82  24   3  44  20 101   5  79  45  55  85  81   8  97  12  69  71  35  57   9 102  60  52  11  95  67  40  91  98  84   2  39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 35 21 72 56 11 70 71 64 66 43 75 15  3 45 77 74 61 19 44 23 60 29 40 32 25 59 27 17 46  8 54 33 22 53 13 37 69 39 68 12 52 79 28  9 48 42 36  1 47 62  4 67 51 16  6 50 55 63 38  7 65  5 49 41  2 58 76 18  0 30 26 73 57 24 31 34 78 20 10], a_shuffle_aclus: [ 19  47  28  95  75  15  92  93  85  87  58 100  20   5  60 102  98  82  26  59  30  81  38  55  43  32  80  34  24  61  12  71  44  29  70  18  51  91  53  90  16  69 104  35  13  63  57  48   3  62  83   6  89  68  23   9  67  72  84  52  11  86   8  66  56   4  79 101  25   2  39  33  97  77  31  40  45 103  27  14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 71 62 36  9  7 51 52 63  6 74 76 73 65 58 54 57  3 15 22 72 38 79 21  4 12 64 37 53 31 20  1 30 49 10 27 61 33 68 75 29  5 70 46 11 16 25 40 32 59 26 78 48 41 42 34  2 39 50 67 45 17 60 69 14 24 23 47 35  8  0 56 77 28 44 66 43 55 19 18], a_shuffle_aclus: [ 18  93  83  48  13  11  68  69  84   9  98 101  97  86  79  71  77   5  20  29  95  52 104  28   6  16  85  51  70  40  27   3  39  66  14  34  82  44  90 100  38   8  92  61  15  23  32  55  43  80  33 103  63  56  57  45   4  53  67  89  60  24  81  91  19  31  30  62  47  12   2  75 102  35  59  87  58  72  26  25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 69 67 29 49 37 68 14 12 35 30 16 53 63 64 28 17 10 77 50 41 62  8 26 13 79  3 11 60 15 75 32  2 55 23 56 65 48 74 42  7 27 61 21 39 22 46  6 66 25 52 59  9 57  5 58 24 72 33 44 18 70 43 51  4 31 73 34 36  1 71 76 19 40 54  0 78 20 38 47], a_shuffle_aclus: [ 60  91  89  38  66  51  90  19  16  47  39  23  70  84  85  35  24  14 102  67  56  83  12  33  18 104   5  15  81  20 100  43   4  72  30  75  86  63  98  57  11  34  82  28  53  29  61   9  87  32  69  80  13  77   8  79  31  95  44  59  25  92  58  68   6  40  97  45  48   3  93 101  26  55  71   2 103  27  52  62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [60 21 13 10 19 28 42 78  8 66 63 72 32 16  3 24 37  9 79 49 77 51 54  4 31 20 26 76 41 55 30 70  6 68 58 47 35 65 25 36 12 15 40 64 56 45 50 34  1 23 44 61 43 74 33 69 48 39 11 73 18 71  7 57 62 46 67 53 52  5 59 27 29 22  2 14  0 38 75 17], a_shuffle_aclus: [ 81  28  18  14  26  35  57 103  12  87  84  95  43  23   5  31  51  13 104  66 102  68  71   6  40  27  33 101  56  72  39  92   9  90  79  62  47  86  32  48  16  20  55  85  75  60  67  45   3  30  59  82  58  98  44  91  63  53  15  97  25  93  11  77  83  61  89  70  69   8  80  34  38  29   4  19   2  52 100  24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 31 67 66 33 42 58  2 60  7 25  3 29 73 68 34 78 76 59 61 18 77 48 36 46 43 44 27 74 21 23 32 26 65  6 55 40 52 19 37 15 41 56 62 10 51  9 22 30 14 20  8 11 16 63 57 49 75 28 70 24 45  5 50 47 12 69 53 72 54 13  4  1 71 79 39 35 64 17 38], a_shuffle_aclus: [  2  40  89  87  44  57  79   4  81  11  32   5  38  97  90  45 103 101  80  82  25 102  63  48  61  58  59  34  98  28  30  43  33  86   9  72  55  69  26  51  20  56  75  83  14  68  13  29  39  19  27  12  15  23  84  77  66 100  35  92  31  60   8  67  62  16  91  70  95  71  18   6   3  93 104  53  47  85  24  52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [78  5 40 12 21 24  9 57 52 38 77 19 65 73 45  3 51 23 27 79 26 10 72 36 50 53 18 56 31 55  2 54 33  0 76  4 62 30 44 15 16 48 47 49 29 59 20  6 41 22 58 34 14  1 37 25 68 75 46 60 28 17 67 35 42 64 70 71 63 66 32 69 13  7 61 11 43 74  8 39], a_shuffle_aclus: [103   8  55  16  28  31  13  77  69  52 102  26  86  97  60   5  68  30  34 104  33  14  95  48  67  70  25  75  40  72   4  71  44   2 101   6  83  39  59  20  23  63  62  66  38  80  27   9  56  29  79  45  19   3  51  32  90 100  61  81  35  24  89  47  57  85  92  93  84  87  43  91  18  11  82  15  58  98  12  53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [22 54 52 36 42 55 43 78 71 31 25 74 17 13 67  8 45 68 57 41 33 56 61  4 26 12  7 64 38 24 15 10 50 60 58 37 23 35 29 14 27 44  2 20 66  1 11 62 46 51 79 19 76 48  9  3 77 53 21  5 73 75 65 69 70  0 34 28 47 18 39 49 72 16 63 40  6 59 32 30], a_shuffle_aclus: [ 29  71  69  48  57  72  58 103  93  40  32  98  24  18  89  12  60  90  77  56  44  75  82   6  33  16  11  85  52  31  20  14  67  81  79  51  30  47  38  19  34  59   4  27  87   3  15  83  61  68 104  26 101  63  13   5 102  70  28   8  97 100  86  91  92   2  45  35  62  25  53  66  95  23  84  55   9  80  43  39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [61 13 49 36 72 15 65 21 20 34 47  6 48 22 29 41 43 73  0 77 51 75 26  2 31 71 76 52 68 56 74 59 67 40 27  3 39 60 28 57 23 14 18  7  5 11 69 37 32 55 64 33 19 58 79 16 46 70 50  9 54 12 62 25  4 30 17 45  8 42 10 44 78 35 66  1 38 63 53 24], a_shuffle_aclus: [ 82  18  66  48  95  20  86  28  27  45  62   9  63  29  38  56  58  97   2 102  68 100  33   4  40  93 101  69  90  75  98  80  89  55  34   5  53  81  35  77  30  19  25  11   8  15  91  51  43  72  85  44  26  79 104  23  61  92  67  13  71  16  83  32   6  39  24  60  12  57  14  59 103  47  87   3  52  84  70  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 62 68  9 77 30 74 34 37  1  5 67 22 12 49 60 44 42 55 25 36 29 39 65 56 15 75 52 16 40 19 58 69  3 59 72 32 76 26 10 23 46  2 18 48 11 54  6  7 70  8 38 79 57  0 53 43 20 31 24  4 13 66 33 17 45 14 73 35 21 64 47 63 51 27 41 50 78 71 61], a_shuffle_aclus: [ 35  83  90  13 102  39  98  45  51   3   8  89  29  16  66  81  59  57  72  32  48  38  53  86  75  20 100  69  23  55  26  79  91   5  80  95  43 101  33  14  30  61   4  25  63  15  71   9  11  92  12  52 104  77   2  70  58  27  40  31   6  18  87  44  24  60  19  97  47  28  85  62  84  68  34  56  67 103  93  82]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 67 11 14 37 40 74 44  1 62 36 31 75 42 13 68 30 18 34 77 63 21 26  6 65 28 70  0 69 79 54 15 33 55 64 23 22 20  7 76 78 57 51  9 58 66 72  2 50 39 46  4  8 24 47 17 38 10 41 52 61 16 71 53 19 25  3 56 59 12 29 48 32 60  5 73 49 27 35 43], a_shuffle_aclus: [ 60  89  15  19  51  55  98  59   3  83  48  40 100  57  18  90  39  25  45 102  84  28  33   9  86  35  92   2  91 104  71  20  44  72  85  30  29  27  11 101 103  77  68  13  79  87  95   4  67  53  61   6  12  31  62  24  52  14  56  69  82  23  93  70  26  32   5  75  80  16  38  63  43  81   8  97  66  34  47  58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "INFO:2024-07-10_18-07-18.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:save_pipeline(): Attempting to save pipeline to disk...\n",
      "INFO:2024-07-10_18-07-18.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\tfinalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl\n",
      "Saving (file mode 'w+b') pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/20240710185035-loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.0.pkl\"... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2024-07-10_18-07-18.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: prev_extant_file_size_MB (12804.744535446167 MB) > new_temporary_file_size_MB (8782.586153030396 MB)! A backup will be made!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved pickle file\n",
      "WARNING: prev_extant_file_size_MB (12804.744535446167 MB) > new_temporary_file_size_MB (8782.586153030396 MB)! A backup will be made!\n",
      "'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl' backing up -> to_file: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\backup-20240710185110-loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl.bak'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_18-07-18.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:moving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\20240710185035-loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.0.pkl' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\20240710185035-loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.0.pkl' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_18-07-18.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t save complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_save_filepaths: {'pipeline_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl'), 'global_computation_pkl': 'global_computation_results_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl', 'pipeline_h5': 'pipeline_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.h5', 'ripple_h5_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10_Apogee_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-2006-6-09_1-22-43-_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_time_bin_size_sweep_results.h5'), 'ripple_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_marginals_df).csv'), 'ripple_csv_time_bin_marginals': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_time_bin_marginals_df).csv'), 'laps_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(laps_marginals_df).csv'), 'laps_csv_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(laps_time_bin_marginals_df).csv')}\n",
      "wcorr_ripple_shuffle.n_completed_shuffles: 25\n",
      "n_epochs: 196\n",
      "n_completed_shuffles: 25\n",
      "a_shuffle_IDXs: [ 8 60 52 59 24 11 18  5 55 28 22 46 31 69  2 43 39 45 76 73 58 54 47 15  7 30 23  9 13 21  4 53 70 17 25 12 19 16  3 32 20 48 75 56 67 61 66 72 51 68 27 10  6 63 77 40 44 57 65 29 37 36  1 78 34 26 14 49 41  0 71 62 79 42 64 33 74 35 50 38], a_shuffle_aclus: [ 12  81  69  80  31  15  25   8  72  35  29  61  40  91   4  58  53  60 101  97  79  71  62  20  11  39  30  13  18  28   6  70  92  24  32  16  26  23   5  43  27  63 100  75  89  82  87  95  68  90  34  14   9  84 102  55  59  77  86  38  51  48   3 103  45  33  19  66  56   2  93  83 104  57  85  44  98  47  67  52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 32 39 44 75 59 50 36 31 64 58 41 15 43 77  8 34 55 56 18 40 52 79 54 65 27  9 61 53 33 48 11 68 22 20 42 45 63 76 62 70  4 51 16 26 19 13 17 21 28 74  6 71 30 73  0  1 46 66 12 38  2 35  7 49 69 24 37 60 72 78 57 67 25 10 47  5 29 23 14], a_shuffle_aclus: [  5  43  53  59 100  80  67  48  40  85  79  56  20  58 102  12  45  72  75  25  55  69 104  71  86  34  13  82  70  44  63  15  90  29  27  57  60  84 101  83  92   6  68  23  33  26  18  24  28  35  98   9  93  39  97   2   3  61  87  16  52   4  47  11  66  91  31  51  81  95 103  77  89  32  14  62   8  38  30  19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_completed_shuffles: 27\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "total_n_shuffles: 27\n",
      "total_n_shuffles: 27\n",
      "(n_shuffles = 27, n_epochs = 196, n_decoders = 4); n_total_elements = 21168\n",
      "saving to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0650PM_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_27.pkl\"...\n",
      "total_n_shuffles: 27\n",
      "Saving (file mode 'w+b') pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0650PM_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_27.pkl\"... saved pickle file\n",
      "saving .mat file to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0650PM_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_standalone_all_shuffles_wcorr_array.mat\"...\n",
      "total_n_shuffles: 27\n",
      "(n_shuffles = 27, n_epochs = 196, n_decoders = 4); n_total_elements = 21168\n",
      "len(active_epochs_df): 360\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 196\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "num_user_selected_times: 0\n",
      "adding user annotation column!\n",
      "ERROR: failed for ripple_WCorrShuffle_df. Out of options.\n",
      "\t failed all methods for annotations\n",
      "num_valid_epoch_times: 196\n",
      "adding valid filtered epochs column!\n",
      "\t succeded at getting 196 selected indicies (of 196 valid filter epoch times) for ripple_WCorrShuffle_df. got 196 indicies!\n",
      "Successfully exported ripple_WCorrShuffle_df_export_CSV_path: \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0650PM-kdiba_gor01_one_2006-6-09_1-22-43-(ripple_WCorrShuffle_df)_tbin-0.025.csv\" with wcorr_shuffles.n_completed_shuffles: 27 unique shuffles.\n",
      "completed overwrite_replay_epochs_and_recompute(...). custom_save_filepaths: {'pipeline_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl'), 'global_computation_pkl': 'global_computation_results_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl', 'pipeline_h5': 'pipeline_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.h5', 'ripple_h5_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10_Apogee_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-2006-6-09_1-22-43-_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_time_bin_size_sweep_results.h5'), 'ripple_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_marginals_df).csv'), 'ripple_csv_time_bin_marginals': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_time_bin_marginals_df).csv'), 'laps_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(laps_marginals_df).csv'), 'laps_csv_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(laps_time_bin_marginals_df).csv'), 'standalone_wcorr_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0650PM_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_27.pkl'), 'standalone_mat_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0650PM_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_standalone_all_shuffles_wcorr_array.mat')}\n",
      "\n",
      "<<<<<<<<<<<<<<< Done with `overwrite_replay_epochs_and_recompute(...)` for replay_epochs_key: diba_quiescent_method_replay_epochs\n",
      "\t\twcorr_ripple_shuffle.n_completed_shuffles: 27\n",
      "n_epochs: 196\n",
      "n_completed_shuffles: 27\n",
      "a_shuffle_IDXs: [40 50 75 10 79 64 60  6 73 24 38 41 11 32  5 33 47 14 35 70 45  1 52 74  8 71 28 55 65 63 53 26 59 58 15  2 19 72 43 57 30 54 13 23 77 68 44 36 16 76 21 48 39  0 31 20 37  7 46 17 18 69 49  3  9 25 12 61 51 62 34 42 22  4 67 66 27 29 78 56], a_shuffle_aclus: [ 55  67 100  14 104  85  81   9  97  31  52  56  15  43   8  44  62  19  47  92  60   3  69  98  12  93  35  72  86  84  70  33  80  79  20   4  26  95  58  77  39  71  18  30 102  90  59  48  23 101  28  63  53   2  40  27  51  11  61  24  25  91  66   5  13  32  16  82  68  83  45  57  29   6  89  87  34  38 103  75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [47 35  3 55 42 48 70 29 53 27 16 56 11 75 77 49  0 25 69 31 74 40 59 21 65  6 14 72 62 12 61  5 54  7 73 24 18 79 45 50 36 23 28 19 41 44 52 67 64 78 30 33 13 38 37 15 51 68  2 20  4 10 63 34  9  1 76 58 71 17 43  8 60 32 39 57 22 66 26 46], a_shuffle_aclus: [ 62  47   5  72  57  63  92  38  70  34  23  75  15 100 102  66   2  32  91  40  98  55  80  28  86   9  19  95  83  16  82   8  71  11  97  31  25 104  60  67  48  30  35  26  56  59  69  89  85 103  39  44  18  52  51  20  68  90   4  27   6  14  84  45  13   3 101  79  93  24  58  12  81  43  53  77  29  87  33  61]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_completed_shuffles: 29\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "total_n_shuffles: 29\n",
      "(n_shuffles = 29, n_epochs = 196, n_decoders = 4); n_total_elements = 22736\n",
      "saving to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0650PM_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_29.pkl\"...\n",
      "total_n_shuffles: 29\n",
      "Saving (file mode 'w+b') pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0650PM_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_29.pkl\"... saved pickle file\n",
      "saving .mat file to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0650PM_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_standalone_all_shuffles_wcorr_array.mat\"...\n",
      "total_n_shuffles: 29\n",
      "(n_shuffles = 29, n_epochs = 196, n_decoders = 4); n_total_elements = 22736\n",
      "len(active_epochs_df): 360\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 196\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "num_user_selected_times: 0\n",
      "adding user annotation column!\n",
      "ERROR: failed for ripple_WCorrShuffle_df. Out of options.\n",
      "\t failed all methods for annotations\n",
      "num_valid_epoch_times: 196\n",
      "adding valid filtered epochs column!\n",
      "\t succeded at getting 196 selected indicies (of 196 valid filter epoch times) for ripple_WCorrShuffle_df. got 196 indicies!\n",
      "Successfully exported ripple_WCorrShuffle_df_export_CSV_path: \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0650PM-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv\" with wcorr_shuffles.n_completed_shuffles: 29 unique shuffles.\n",
      "\t saved \"file:///C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2024-07-10/kdiba/gor01/one/2006-6-09_1-22-43/replay_wcorr__withNewComputedReplays-qclu_%5B1%2C%202%5D-frateThresh_5%E2%80%A20.png\"\n",
      "\t=====================================>> performing comp for \"diba_evt_file\"...\n",
      "\treplay_epochs_key: diba_evt_file: custom_suffix: \"_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0\"\n",
      "\tcurr_BATCH_DATE_TO_USE: \"2024-07-10_Apogee_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0\"\n",
      "\tWARNING: should_suppress_errors: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_18-07-56.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:==========================================================================================\n",
      "========== Logger INIT \"2024-07-10_18-07-56.Apogee.kdiba.gor01.one.2006-6-09_1-22-43\" ==============================\n",
      "INFO:2024-07-10_18-07-56.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:NeuropyPipeline.__setstate__(state=\"{'pipeline_name': 'kdiba_pipeline', 'session_data_type': 'kdiba', '_stage': <pyphoplacecellanalysis.General.Pipeline.Stages.Display.DisplayPipelineStage object at 0x0000021AC315BB50>}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_logger(full_logger_string=\"2024-07-10_18-07-56.Apogee.kdiba.gor01.one.2006-6-09_1-22-43\", file_logging_dir: None):\n",
      "custom_suffix: \"_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0\"\n",
      "Using custom suffix: \"_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0\" - additional_session_context: \"_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0\"\n",
      "did_change: True\n",
      "custom_save_filenames: {'pipeline_pkl': 'loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl', 'global_computation_pkl': 'global_computation_results_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl', 'pipeline_h5': 'pipeline_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.h5'}\n",
      "replay epochs changed!\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['merged_directional_placefields', 'perform_rank_order_shuffle_analysis'], ...)...\n",
      "\trun_specific_computations_single_context(including only 2 out of 16 registered computation functions): active_computation_functions: [<function DirectionalPlacefieldGlobalComputationFunctions._build_merged_directional_placefields at 0x0000021388D969D0>, <function RankOrderGlobalComputationFunctions.perform_rank_order_shuffle_analysis at 0x000002139891D4C0>]...\n",
      "Performing _execute_computation_functions(...) with 2 registered_computation_functions...\n",
      "Executing [0/2]: <function DirectionalPlacefieldGlobalComputationFunctions._build_merged_directional_placefields at 0x0000021694B3BC10>\n",
      "skipping lap recomputation because laps_decoding_time_bin_size == None\n",
      "WARN: ripple_decoding_time_bin_size 0.025 < min_possible_time_bin_size (0.027). This used to be enforced but continuing anyway.\n",
      "Executing [1/2]: <function RankOrderGlobalComputationFunctions.perform_rank_order_shuffle_analysis at 0x0000021694B3BB80>\n",
      "WARN: perform_rank_order_shuffle_analysis(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "####> perform_rank_order_shuffle_analysis(..., num_shuffles=25)\n",
      "\t##> computing Ripple rank-order shuffles:\n",
      "ripple_evts_paired_tests: [TtestResult(statistic=-0.3521894145502629, pvalue=0.725266503463794, df=130), TtestResult(statistic=-1.3428625792524258, pvalue=0.181656399096762, df=130)]\n",
      "\tdone. building global result.\n",
      "n_valid_shuffles: 25\n",
      "combined_variable_names: ['long_LR_pearson', 'long_RL_pearson', 'short_LR_spearman', 'long_LR_spearman', 'short_RL_pearson', 'short_LR_pearson', 'long_RL_spearman', 'short_RL_spearman']\n",
      "combined_variable_z_score_column_names: ['long_LR_pearson_Z', 'long_RL_pearson_Z', 'short_LR_spearman_Z', 'long_LR_spearman_Z', 'short_RL_pearson_Z', 'short_LR_pearson_Z', 'long_RL_spearman_Z', 'short_RL_spearman_Z']\n",
      "done!\n",
      "\tdone. building global result.\n",
      "< done with `perform_rank_order_shuffle_analysis(...)`\n",
      "\t all computations complete! (Computed 2 with no errors!.\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], ...)...\n",
      "\trun_specific_computations_single_context(including only 2 out of 16 registered computation functions): active_computation_functions: [<function DirectionalPlacefieldGlobalComputationFunctions._decode_and_evaluate_epochs_using_directional_decoders at 0x0000021388D96AF0>, <function DirectionalPlacefieldGlobalComputationFunctions._decoded_epochs_heuristic_scoring at 0x0000021388D96B80>]...\n",
      "Performing _execute_computation_functions(...) with 2 registered_computation_functions...\n",
      "Executing [0/2]: <function DirectionalPlacefieldGlobalComputationFunctions._decode_and_evaluate_epochs_using_directional_decoders at 0x0000021694B3BDC0>\n",
      "laps_decoding_time_bin_size: 0.25, ripple_decoding_time_bin_size: 0.025, pos_bin_size: 3.8054171165052444\n",
      "laps_decoding_time_bin_size: 0.25, ripple_decoding_time_bin_size: 0.025, pos_bin_size: 3.8054171165052444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 3.8054171165052444)\n",
      "WARNING: n_jobs > 1 (n_jobs: 6) but _allow_parallel_run_general == False, so parallel computation will not be performed.\n",
      "Performance: Radon Transform:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 14/84\n",
      "\tagreeing_rows_ratio: 0.16666666666666666\n",
      "\tPerformance: Ripple: Radon Transform:\n",
      "agreeing_rows_count/num_total_epochs: 31/156\n",
      "\tagreeing_rows_ratio: 0.1987179487179487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 64/84\n",
      "\tagreeing_rows_ratio: 0.7619047619047619\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 51/156\n",
      "\tagreeing_rows_ratio: 0.3269230769230769\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 75/84\n",
      "\tagreeing_rows_ratio: 0.8928571428571429\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 61/156\n",
      "\tagreeing_rows_ratio: 0.391025641025641\n",
      "Executing [1/2]: <function DirectionalPlacefieldGlobalComputationFunctions._decoded_epochs_heuristic_scoring at 0x0000021694B3B4C0>\n",
      "\t all computations complete! (Computed 2 with no errors!.\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(curr_session_context: kdiba_gor01_one_2006-6-09_1-22-43, curr_session_basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43, ...)\n",
      "\tactive_context: kdiba_gor01_one_2006-6-09_1-22-43__withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0\n",
      "\tsession_ctxt_key: kdiba|gor01|one|2006-6-09_1-22-43|_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0\n",
      "\tCURR_BATCH_OUTPUT_PREFIX: 2024-07-10_Apogee_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-2006-6-09_1-22-43-_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0\n",
      "\tout_path_str: \"2024-07-10_Apogee_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-2006-6-09_1-22-43-_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_time_bin_size_sweep_results.h5\"\n",
      "\tout_path: \"K:\\scratch\\collected_outputs\\2024-07-10_Apogee_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-2006-6-09_1-22-43-_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_time_bin_size_sweep_results.h5\"\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\ta_sweep_dict: {'desired_laps_decoding_time_bin_size': 1.5, 'desired_ripple_decoding_time_bin_size': 0.01, 'use_single_time_bin_per_epoch': False, 'minimum_event_duration': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.02).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.02.\t156 remain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning:\n",
      "\n",
      "object name is not a valid Python identifier: 'kdiba|gor01|one|2006-6-09_1-22-43|_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning:\n",
      "\n",
      "object name is not a valid Python identifier: '1.5'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning:\n",
      "\n",
      "object name is not a valid Python identifier: '0.01'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 27/84\n",
      "\tagreeing_rows_ratio: 0.32142857142857145\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 64/156\n",
      "\tagreeing_rows_ratio: 0.41025641025641024\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 72/84\n",
      "\tagreeing_rows_ratio: 0.8571428571428571\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 66/156\n",
      "\tagreeing_rows_ratio: 0.4230769230769231\n",
      "\ta_sweep_dict: {'desired_laps_decoding_time_bin_size': 1.5, 'desired_ripple_decoding_time_bin_size': 0.02, 'use_single_time_bin_per_epoch': False, 'minimum_event_duration': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.02).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.02.\t156 remain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\path.py:137: NaturalNameWarning:\n",
      "\n",
      "object name is not a valid Python identifier: '0.02'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 27/84\n",
      "\tagreeing_rows_ratio: 0.32142857142857145\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 50/156\n",
      "\tagreeing_rows_ratio: 0.32051282051282054\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 72/84\n",
      "\tagreeing_rows_ratio: 0.8571428571428571\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 58/156\n",
      "\tagreeing_rows_ratio: 0.3717948717948718\n",
      ">>\t done with kdiba_gor01_one_2006-6-09_1-22-43\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "perform_drop_computed_result(computed_data_keys_to_drop: ['SequenceBased'], config_names_includelist: None)\n",
      "\t global_computation_results.computed_data['SequenceBased'] did not exist.\n",
      "\t Dropped computation_results['maze1_odd'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze2_odd'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze_odd'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze1_even'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze2_even'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze_even'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze1_any'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze2_any'].computed_data['SequenceBased'].\n",
      "\t Dropped computation_results['maze_any'].computed_data['SequenceBased'].\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['wcorr_shuffle_analysis'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function SequenceBasedComputationsGlobalComputationFunctions.perform_wcorr_shuffle_analysis at 0x000002139886AA60>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function SequenceBasedComputationsGlobalComputationFunctions.perform_wcorr_shuffle_analysis at 0x0000021B7D1BF8B0>\n",
      "WARN: perform_wcorr_shuffle_analysis(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "perform_wcorr_shuffle_analysis(..., num_shuffles=25)\n",
      "len(active_epochs_df): 156\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 77\n",
      "len(active_epochs_df): 156\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 77\n",
      "real_decoder_ripple_weighted_corr_arr: (77, 4)\n",
      "n_prev_completed_shuffles: 0.\n",
      "needed num_shuffles: 25.\n",
      "need desired_new_num_shuffles: 25 more shuffles.\n",
      "a_shuffle_IDXs: [11 50 18 60 46 26 37 59 15  9 69 57 20 78  7 28 70 72 53 76 19 74 10 48 42 22  1 31 54  4 44 16 40 71 73  8 66 63  3 17 38 21 77 30 24 12 56 23  0 79 33 51 14 67  5 41 27 47 32 49 29 13 68 25 36  6 52 35 58 61 55  2 64 34 65 45 75 62 43 39], a_shuffle_aclus: [ 15  67  25  81  61  33  51  80  20  13  91  77  27 103  11  35  92  95  70 101  26  98  14  63  57  29   3  40  71   6  59  23  55  93  97  12  87  84   5  24  52  28 102  39  31  16  75  30   2 104  44  68  19  89   8  56  34  62  43  66  38  18  90  32  48   9  69  47  79  82  72   4  85  45  86  60 100  83  58  53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30  0 34  9 42 79 37 71 19 35 32 78  5  3 46 25 13 43 16 51 11  1  7 48  2 69 53 21 27 24  6 52 68 45 57 40 49 36 75 15 60 62 63 67 26 59 18 61  4 76 23 28 72 74  8 12 47 17 20 44 54 38 33 50 65 39 73 58 55 14 41 77 66 70 56 22 31 29 64 10], a_shuffle_aclus: [ 39   2  45  13  57 104  51  93  26  47  43 103   8   5  61  32  18  58  23  68  15   3  11  63   4  91  70  28  34  31   9  69  90  60  77  55  66  48 100  20  81  83  84  89  33  80  25  82   6 101  30  35  95  98  12  16  62  24  27  59  71  52  44  67  86  53  97  79  72  19  56 102  87  92  75  29  40  38  85  14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [53 70 76 59 29 40 26 62 32 28 44 58 56 66  6 37 18 38 71 50 75 33 27 34 60 46 13 74 17 64 73 51 11 20 39  5 79  9 16 77 15 31  8 47 42 43  0 69 67 55 21 78 22 61 57 45 24 54 52 36 10  3 48 72 12  1 41 19 49  4 68  7 23 14 63 30 25 35  2 65], a_shuffle_aclus: [ 70  92 101  80  38  55  33  83  43  35  59  79  75  87   9  51  25  52  93  67 100  44  34  45  81  61  18  98  24  85  97  68  15  27  53   8 104  13  23 102  20  40  12  62  57  58   2  91  89  72  28 103  29  82  77  60  31  71  69  48  14   5  63  95  16   3  56  26  66   6  90  11  30  19  84  39  32  47   4  86]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 20 18 62 57  0 13 37 11  5 59 45 74 24 22 26 15 41 70 32 14 78 25  2 46 33 44 52 63 29 35 69 49  7 51 36  8 71 76 17 43 16 30 28 50 75 19 72 10  3 23 58 48 39 27 61 34 65 64  9  1 53 68  6  4 42 54 47 67 66 60 77 79 73 31 55 40 38 21 56], a_shuffle_aclus: [ 16  27  25  83  77   2  18  51  15   8  80  60  98  31  29  33  20  56  92  43  19 103  32   4  61  44  59  69  84  38  47  91  66  11  68  48  12  93 101  24  58  23  39  35  67 100  26  95  14   5  30  79  63  53  34  82  45  86  85  13   3  70  90   9   6  57  71  62  89  87  81 102 104  97  40  72  55  52  28  75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [55 45 22 39 44 75 27 32 19 64 79 65  6 61  4 16 67  8 58 57 48 40  1 68 51 25 71 69 33 30 11 14 10 43 63 23  7  0 59 47 15 62 54 73 78 46 34 31  9 66 12  2 70 49 29  3 26 17 38 74 60 13 24 18 77 56 28 50 52 36 76 72 21  5 35 20 41 42 37 53], a_shuffle_aclus: [ 72  60  29  53  59 100  34  43  26  85 104  86   9  82   6  23  89  12  79  77  63  55   3  90  68  32  93  91  44  39  15  19  14  58  84  30  11   2  80  62  20  83  71  97 103  61  45  40  13  87  16   4  92  66  38   5  33  24  52  98  81  18  31  25 102  75  35  67  69  48 101  95  28   8  47  27  56  57  51  70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [71 72 66 61  9  8 37 16 33 28 12 45  4 24 10 47 39  3 62 75 65  2 14 55 27 36 50 56 46 64 78 13 20 32 59 44 21 77 54 68 11 73 57 31 74  7 22 23 35 51 67 49 63 25 48 30 58 43  6 38 15 17 41 18 19 76 70 29 52 60 42 69 34 26 79 53 40  0  5  1], a_shuffle_aclus: [ 93  95  87  82  13  12  51  23  44  35  16  60   6  31  14  62  53   5  83 100  86   4  19  72  34  48  67  75  61  85 103  18  27  43  80  59  28 102  71  90  15  97  77  40  98  11  29  30  47  68  89  66  84  32  63  39  79  58   9  52  20  24  56  25  26 101  92  38  69  81  57  91  45  33 104  70  55   2   8   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 72 32 15  6 47 39 33 25 52 27  3 41 66 49 21 64 22 19 20 11 31 73 58 75 34 14 16 67 53  1 60  0 79 57 55 51 44 42 36 30 29 76 17 35 43 65 26 63 12 48 59  2 69  8 62 70 54 50 37 24  7 38  9  5 61 40 78 56 23 10 46 74 68 77 18  4 71 28 13], a_shuffle_aclus: [ 60  95  43  20   9  62  53  44  32  69  34   5  56  87  66  28  85  29  26  27  15  40  97  79 100  45  19  23  89  70   3  81   2 104  77  72  68  59  57  48  39  38 101  24  47  58  86  33  84  16  63  80   4  91  12  83  92  71  67  51  31  11  52  13   8  82  55 103  75  30  14  61  98  90 102  25   6  93  35  18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42  3 36 68  2 10  7 46 45 23 29 15 37 16  4 13 43 11 54 65 47 64 60 52 79 73 53 14  6 49 48 51 31 32 74 57 24 77 56 21 58 41 25 35 27 12 69 26 70 18 67 76 75 55 44  8 17  5 61 50 28 39  1 34 33 59 62 66  9 20 30 72  0 19 71 63 40 78 22 38], a_shuffle_aclus: [ 57   5  48  90   4  14  11  61  60  30  38  20  51  23   6  18  58  15  71  86  62  85  81  69 104  97  70  19   9  66  63  68  40  43  98  77  31 102  75  28  79  56  32  47  34  16  91  33  92  25  89 101 100  72  59  12  24   8  82  67  35  53   3  45  44  80  83  87  13  27  39  95   2  26  93  84  55 103  29  52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [53 42 72 19 78 57 52 13 41 18 14 55 77 69 39 51 22 27 56 15 28 44 70 38 59 35  0  7 79 20 73 49 64 17 71 60 47  3 29 74 67 34  9 76 66  5 30 46 63 58 31 25  4 32 33 62 75 10 23 37  1  8 16 61 43 65 36 48 40 45 11  6 26 50 21 24 12 54 68  2], a_shuffle_aclus: [ 70  57  95  26 103  77  69  18  56  25  19  72 102  91  53  68  29  34  75  20  35  59  92  52  80  47   2  11 104  27  97  66  85  24  93  81  62   5  38  98  89  45  13 101  87   8  39  61  84  79  40  32   6  43  44  83 100  14  30  51   3  12  23  82  58  86  48  63  55  60  15   9  33  67  28  31  16  71  90   4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 59  2 64 78 16 53 27 18 54 43  8 20 35 68 52 25 58 45 71 13 74 60 31 76 56 65 15  3 36 55 12 17 28 29 77  6 11 61 75 70 41 38 40 47 66 32 51 62 30 21  4 14 50 48 23 10 67 37 24 46 72  7 42 49 63 19 69 22 57 44 33 39 79  0 73 26  5 34  1], a_shuffle_aclus: [ 13  80   4  85 103  23  70  34  25  71  58  12  27  47  90  69  32  79  60  93  18  98  81  40 101  75  86  20   5  48  72  16  24  35  38 102   9  15  82 100  92  56  52  55  62  87  43  68  83  39  28   6  19  67  63  30  14  89  51  31  61  95  11  57  66  84  26  91  29  77  59  44  53 104   2  97  33   8  45   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 35 70 12 21 14  2 55 13 34 72 56 59 60 77  4 18  5 76 50  8 62 38 10 61 20 52 29 73 49 24 47 41 54 67 58 39 48 37 71 26 46 22  3 15 78 23 57 66 40 75 69 36 42 79 11 32  1 33 25 45 53 17 19  0 43 30  9 65 31 51 27 63  7  6 74 64 68 44 16], a_shuffle_aclus: [ 35  47  92  16  28  19   4  72  18  45  95  75  80  81 102   6  25   8 101  67  12  83  52  14  82  27  69  38  97  66  31  62  56  71  89  79  53  63  51  93  33  61  29   5  20 103  30  77  87  55 100  91  48  57 104  15  43   3  44  32  60  70  24  26   2  58  39  13  86  40  68  34  84  11   9  98  85  90  59  23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 22 58 26 46 37  3 50  1 55 56 34 74 68 78 44 42 33 53 63 30 36 27 75 62 65 57 76 47 29  6 14  7 59  5 32 19  9 31 54 20 12 49  4 13 24 43 66  8 51 69 11 79 73  2 70 38 40 48 15 41 61 45 71 72 28 67 25 23 21 10 35 39 17 52 60 18 64 16 77], a_shuffle_aclus: [  2  29  79  33  61  51   5  67   3  72  75  45  98  90 103  59  57  44  70  84  39  48  34 100  83  86  77 101  62  38   9  19  11  80   8  43  26  13  40  71  27  16  66   6  18  31  58  87  12  68  91  15 104  97   4  92  52  55  63  20  56  82  60  93  95  35  89  32  30  28  14  47  53  24  69  81  25  85  23 102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 65 64 23 45 10 13 74 58 49 43 40 51 15  6 77 42 34 41 78 28 29 67  3 37 20  9 32 62 72 55 57  1 48 79 19 61  7 54 66 44 31 75 36 26 18 35  2 22 27 25 68  0  4 39 17 69  8 14 73 70 59 63 52 47 46 76 71  5 50 33 30 16 24 21 38 60 56 12 53], a_shuffle_aclus: [ 15  86  85  30  60  14  18  98  79  66  58  55  68  20   9 102  57  45  56 103  35  38  89   5  51  27  13  43  83  95  72  77   3  63 104  26  82  11  71  87  59  40 100  48  33  25  47   4  29  34  32  90   2   6  53  24  91  12  19  97  92  80  84  69  62  61 101  93   8  67  44  39  23  31  28  52  81  75  16  70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [71  4 63 27 42 32 26 19 10 12  5 47  2 50 15 11 60 78 53 56 40 72 65  3  8 17 30 62 37 44 29 14 77  6 43 46 41 67 23 25 69 57  0 45 75 13 73 55 31 38 18  1 59 51 35 54 70 24 21 39 64 74 61 33 58 28 76 48  7 66 68  9 49 36 22 34 79 52 20 16], a_shuffle_aclus: [ 93   6  84  34  57  43  33  26  14  16   8  62   4  67  20  15  81 103  70  75  55  95  86   5  12  24  39  83  51  59  38  19 102   9  58  61  56  89  30  32  91  77   2  60 100  18  97  72  40  52  25   3  80  68  47  71  92  31  28  53  85  98  82  44  79  35 101  63  11  87  90  13  66  48  29  45 104  69  27  23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [58 65 63  5 36 53 60 62 77 13 48 33 19 31  3 14 34 35 11 10 59 66 64 71 45 56  9 44 67 52  7 22 24 29 76 51 17 25 39 41 69  2 37 26 38 47 55 32 68 23 18 40 27  4 20 43 70 73 79 74  1 54 46 61 72 75 30 21  8 12 42 28 78 15 49  0 16 50  6 57], a_shuffle_aclus: [ 79  86  84   8  48  70  81  83 102  18  63  44  26  40   5  19  45  47  15  14  80  87  85  93  60  75  13  59  89  69  11  29  31  38 101  68  24  32  53  56  91   4  51  33  52  62  72  43  90  30  25  55  34   6  27  58  92  97 104  98   3  71  61  82  95 100  39  28  12  16  57  35 103  20  66   2  23  67   9  77]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 73 75 24 62 11 22 33 46  8 30 50  6 27 78 38 41 72 65 12 17 55 54 28 69 18 58  2 63 25 70 67 13 21 64 32 57 74  0 23 48 56 34  9  5 51 40  4 43 77 14 31 19 52 59 66 47 49 60  1 29 79  3 36 15 35  7 76 61 20 42 26 68 37 44 71 45 16 39 53], a_shuffle_aclus: [ 14  97 100  31  83  15  29  44  61  12  39  67   9  34 103  52  56  95  86  16  24  72  71  35  91  25  79   4  84  32  92  89  18  28  85  43  77  98   2  30  63  75  45  13   8  68  55   6  58 102  19  40  26  69  80  87  62  66  81   3  38 104   5  48  20  47  11 101  82  27  57  33  90  51  59  93  60  23  53  70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [59 41 73 54 17 61 48 43  3 50 26 68 30 66 37 33 28 18 56 71 57 74 11 13 35  7 49 79 70 34 69 77 10 64 42 46 58 12 51 23 25 47 78 45 53  0 60 27 20  8 65 16  1 44 40 38 32  4 62 21 39 67 75 52 15 24  5 63  2 72 36  9 29 19 31 55  6 14 22 76], a_shuffle_aclus: [ 80  56  97  71  24  82  63  58   5  67  33  90  39  87  51  44  35  25  75  93  77  98  15  18  47  11  66 104  92  45  91 102  14  85  57  61  79  16  68  30  32  62 103  60  70   2  81  34  27  12  86  23   3  59  55  52  43   6  83  28  53  89 100  69  20  31   8  84   4  95  48  13  38  26  40  72   9  19  29 101]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 60  7 76 72 24  0  2 28 23 17 14 19  3 51 70  8 31 22 58 13 10 56 62 20 34 33 66 71 44 43 38 49  9 67 32 65 73 41 25  5 15 79 29 21  1 35 39 36 59 64 12 63 42 61 54 50  6 53 30 68 46 52 69 47 77 57 16 18 55 40 78 45 27 26 74 37 48 75  4], a_shuffle_aclus: [ 15  81  11 101  95  31   2   4  35  30  24  19  26   5  68  92  12  40  29  79  18  14  75  83  27  45  44  87  93  59  58  52  66  13  89  43  86  97  56  32   8  20 104  38  28   3  47  53  48  80  85  16  84  57  82  71  67   9  70  39  90  61  69  91  62 102  77  23  25  72  55 103  60  34  33  98  51  63 100   6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [53 59 73 37 22 62 74 58 75 23 39 14  6 49 30 71 12 10 46 18 16 31 69 65 11 79 70 28 50 33  2 57 64  9 41  8 20 29 78 17 54 27 55  4 67 34 26 13 61 38  3 40 56  0 42 72  7 35 25  1 68 77 19 63 66 36 52 76 45 51 15 60 47 24 43 48  5 44 32 21], a_shuffle_aclus: [ 70  80  97  51  29  83  98  79 100  30  53  19   9  66  39  93  16  14  61  25  23  40  91  86  15 104  92  35  67  44   4  77  85  13  56  12  27  38 103  24  71  34  72   6  89  45  33  18  82  52   5  55  75   2  57  95  11  47  32   3  90 102  26  84  87  48  69 101  60  68  20  81  62  31  58  63   8  59  43  28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38 14 50 13 75  4 49 48  2 43 51 32  0 72 77 31 54 70 35  6 12 24 76 36 21 20 23 64 33  8  9 55 15 41 27 25 46 22 73 40 74  5 34 61 58 26 56 18 11 52 63 67 30 44 53  1 78 19 37 69 65 28 71 29 47 42  7 57 39 16 79 10 59 66 68  3 45 17 60 62], a_shuffle_aclus: [ 52  19  67  18 100   6  66  63   4  58  68  43   2  95 102  40  71  92  47   9  16  31 101  48  28  27  30  85  44  12  13  72  20  56  34  32  61  29  97  55  98   8  45  82  79  33  75  25  15  69  84  89  39  59  70   3 103  26  51  91  86  35  93  38  62  57  11  77  53  23 104  14  80  87  90   5  60  24  81  83]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 47 69 43 32 49 66 62 38 53 75 45 70 16 58 36 26  8 33 64 37 12  2 11 23 40 65 78 20 72 54 25 67  7 39 48 57 77 29  3 46 13 34  1 60 27 44 41 71 55 59  6 14 74 10 63 42 35  4 50 17 76 24 21 79 56 73 19 28 30 61 68  0 22  5 52 51 31 15  9], a_shuffle_aclus: [ 25  62  91  58  43  66  87  83  52  70 100  60  92  23  79  48  33  12  44  85  51  16   4  15  30  55  86 103  27  95  71  32  89  11  53  63  77 102  38   5  61  18  45   3  81  34  59  56  93  72  80   9  19  98  14  84  57  47   6  67  24 101  31  28 104  75  97  26  35  39  82  90   2  29   8  69  68  40  20  13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 49 69 46  1 35 40 62 65 31 17 72 38 20 11 25  6 48 27 68  8 75  7 34 29 63 21  3 30  5 71 32 50 13 59 28 74 52 55 47 42 67 23 18 16  0 24 41 58 12 39 60 57 76 56 66 26 61 43  2 51 15 53 19 79 70  9  4 64 44 73 36 10 33 78 77 14 37 54 22], a_shuffle_aclus: [ 60  66  91  61   3  47  55  83  86  40  24  95  52  27  15  32   9  63  34  90  12 100  11  45  38  84  28   5  39   8  93  43  67  18  80  35  98  69  72  62  57  89  30  25  23   2  31  56  79  16  53  81  77 101  75  87  33  82  58   4  68  20  70  26 104  92  13   6  85  59  97  48  14  44 103 102  19  51  71  29]\n",
      "a_shuffle_IDXs: [27 50 37 55 42 72 23 24 76 53 28 48 29 45  8 11  1 26 47  9 43 13 61 73  6 40 70 78 41 56 22 20 54 68 18 19 21 51  3 34 60 30 58 16  7 31 25 32 44 63 59 35 62 74 15 52 57 17  5 33 46 12 64  4 79 65 66 75  2 49 77 36 67 39 71 38 69  0 14 10], a_shuffle_aclus: [ 34  67  51  72  57  95  30  31 101  70  35  63  38  60  12  15   3  33  62  13  58  18  82  97   9  55  92 103  56  75  29  27  71  90  25  26  28  68   5  45  81  39  79  23  11  40  32  43  59  84  80  47  83  98  20  69  77  24   8  44  61  16  85   6 104  86  87 100   4  66 102  48  89  53  93  52  91   2  19  14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 48 23 55 26 79 19 38 49 50 57 46 71 14 75 58 56 35 76  7 25  6 44 10 32 74 36 28 18 52 70 17 42 24 40 72 13 47 21  9 41 51 67 29  4  0 78 20 39  3  5 66 15  2 45 59 60 37 53 62 63 12 64 54 73 34 11 31 22  8 77 65 33 68  1 69 16 43 30 61], a_shuffle_aclus: [ 34  63  30  72  33 104  26  52  66  67  77  61  93  19 100  79  75  47 101  11  32   9  59  14  43  98  48  35  25  69  92  24  57  31  55  95  18  62  28  13  56  68  89  38   6   2 103  27  53   5   8  87  20   4  60  80  81  51  70  83  84  16  85  71  97  45  15  40  29  12 102  86  44  90   3  91  23  58  39  82]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 66 26 50 33 39 59 27 21 48 37 72 55  0 49 19 14 24 41 28 51 58 30 78 40  8 34 68 11 38 76  7 22  9 64  6 31 10 46 71 29  5 36 70 60  1 67 18 69 74 63 42 47  3 77 53 62 61  2 52 20 56  4 12 16 25 32 23 73 79 75 54 44 57 65 13 45 17 43 15], a_shuffle_aclus: [ 47  87  33  67  44  53  80  34  28  63  51  95  72   2  66  26  19  31  56  35  68  79  39 103  55  12  45  90  15  52 101  11  29  13  85   9  40  14  61  93  38   8  48  92  81   3  89  25  91  98  84  57  62   5 102  70  83  82   4  69  27  75   6  16  23  32  43  30  97 104 100  71  59  77  86  18  60  24  58  20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:2024-07-10_18-07-56.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:save_pipeline(): Attempting to save pipeline to disk...\n",
      "INFO:2024-07-10_18-07-56.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\tfinalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl\n",
      "Saving (file mode 'w+b') pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/20240710185421-loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.0.pkl\"... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2024-07-10_18-07-56.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:WARNING: prev_extant_file_size_MB (12781.86063671112 MB) > new_temporary_file_size_MB (8759.70224571228 MB)! A backup will be made!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved pickle file\n",
      "WARNING: prev_extant_file_size_MB (12781.86063671112 MB) > new_temporary_file_size_MB (8759.70224571228 MB)! A backup will be made!\n",
      "'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl' backing up -> to_file: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\backup-20240710185455-loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl.bak'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_18-07-56.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:moving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\20240710185421-loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.0.pkl' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\20240710185421-loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.0.pkl' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-07-10_18-07-56.Apogee.kdiba.gor01.one.2006-6-09_1-22-43:\t save complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_save_filepaths: {'pipeline_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl'), 'global_computation_pkl': 'global_computation_results_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl', 'pipeline_h5': 'pipeline_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.h5', 'ripple_h5_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10_Apogee_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-2006-6-09_1-22-43-_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_time_bin_size_sweep_results.h5'), 'ripple_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-(ripple_marginals_df).csv'), 'ripple_csv_time_bin_marginals': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-(ripple_time_bin_marginals_df).csv'), 'laps_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-(laps_marginals_df).csv'), 'laps_csv_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-(laps_time_bin_marginals_df).csv')}\n",
      "wcorr_ripple_shuffle.n_completed_shuffles: 25\n",
      "n_epochs: 77\n",
      "n_completed_shuffles: 25\n",
      "a_shuffle_IDXs: [70 67 79 12 34 11 61 28 44 22 15 23 33 65 53 18  5 59  7 39 41 56 77  1 49 68 46  8 74 29 13 64 24 35 16 54 62 19 52 48 75 55  9 50 57 66 21 42 25  3 31 32 40 14 60 47 73 63 71  6 37  2  4 69 27 17 76 51 78 45 10 26  0 58 72 20 43 36 38 30], a_shuffle_aclus: [ 92  89 104  16  45  15  82  35  59  29  20  30  44  86  70  25   8  80  11  53  56  75 102   3  66  90  61  12  98  38  18  85  31  47  23  71  83  26  69  63 100  72  13  67  77  87  28  57  32   5  40  43  55  19  81  62  97  84  93   9  51   4   6  91  34  24 101  68 103  60  14  33   2  79  95  27  58  48  52  39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:401: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15 20 50 29 27 78 19 30 64 26 68 17 45 40 72 62  7 54 48 25 12 46 42 43 71 14  5 66 28 35  1 79 70 11 58 51 37 18  4  8 10 47  6 13 77 53 39 32 55 74 38  3 31 49 23 44 75 21 24 57 34 60 61 65 67 56  2 36 33 41 52 69 59 73 76 16 22  0  9 63], a_shuffle_aclus: [ 20  27  67  38  34 103  26  39  85  33  90  24  60  55  95  83  11  71  63  32  16  61  57  58  93  19   8  87  35  47   3 104  92  15  79  68  51  25   6  12  14  62   9  18 102  70  53  43  72  98  52   5  40  66  30  59 100  28  31  77  45  81  82  86  89  75   4  48  44  56  69  91  80  97 101  23  29   2  13  84]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_completed_shuffles: 27\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "total_n_shuffles: 27\n",
      "total_n_shuffles: 27\n",
      "(n_shuffles = 27, n_epochs = 77, n_decoders = 4); n_total_elements = 8316\n",
      "saving to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0655PM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_27.pkl\"...\n",
      "total_n_shuffles: 27\n",
      "Saving (file mode 'w+b') pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0655PM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_27.pkl\"... saved pickle file\n",
      "saving .mat file to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0655PM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_all_shuffles_wcorr_array.mat\"...\n",
      "total_n_shuffles: 27\n",
      "(n_shuffles = 27, n_epochs = 77, n_decoders = 4); n_total_elements = 8316\n",
      "len(active_epochs_df): 156\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 77\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "num_user_selected_times: 0\n",
      "adding user annotation column!\n",
      "ERROR: failed for ripple_WCorrShuffle_df. Out of options.\n",
      "\t failed all methods for annotations\n",
      "num_valid_epoch_times: 77\n",
      "adding valid filtered epochs column!\n",
      "\t succeded at getting 77 selected indicies (of 77 valid filter epoch times) for ripple_WCorrShuffle_df. got 77 indicies!\n",
      "Successfully exported ripple_WCorrShuffle_df_export_CSV_path: \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0650PM-kdiba_gor01_one_2006-6-09_1-22-43-(ripple_WCorrShuffle_df)_tbin-0.025.csv\" with wcorr_shuffles.n_completed_shuffles: 27 unique shuffles.\n",
      "completed overwrite_replay_epochs_and_recompute(...). custom_save_filepaths: {'pipeline_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl'), 'global_computation_pkl': 'global_computation_results_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl', 'pipeline_h5': 'pipeline_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.h5', 'ripple_h5_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10_Apogee_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-2006-6-09_1-22-43-_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_time_bin_size_sweep_results.h5'), 'ripple_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-(ripple_marginals_df).csv'), 'ripple_csv_time_bin_marginals': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-(ripple_time_bin_marginals_df).csv'), 'laps_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-(laps_marginals_df).csv'), 'laps_csv_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-(laps_time_bin_marginals_df).csv'), 'standalone_wcorr_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0655PM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_27.pkl'), 'standalone_mat_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0655PM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_all_shuffles_wcorr_array.mat')}\n",
      "\n",
      "<<<<<<<<<<<<<<< Done with `overwrite_replay_epochs_and_recompute(...)` for replay_epochs_key: diba_evt_file\n",
      "\t\twcorr_ripple_shuffle.n_completed_shuffles: 27\n",
      "n_epochs: 77\n",
      "n_completed_shuffles: 27\n",
      "a_shuffle_IDXs: [78 40 53 54  0  9 33 22 35 64 18 44 58 24 73  6 15 79 71  5 36 77  2 66 46 51 10 61 75 37 38 42 45 28 43 30 29 25  8 27 50 19 47 17 56 60  7 41  1 57 34 12 31 13 65 48 52 67 62  4 39 23 72 69  3 11 32 55 76 20 49 26 68 59 70 63 21 14 16 74], a_shuffle_aclus: [103  55  70  71   2  13  44  29  47  85  25  59  79  31  97   9  20 104  93   8  48 102   4  87  61  68  14  82 100  51  52  57  60  35  58  39  38  32  12  34  67  26  62  24  75  81  11  56   3  77  45  16  40  18  86  63  69  89  83   6  53  30  95  91   5  15  43  72 101  27  66  33  90  80  92  84  28  19  23  98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [76 62 58 17 30 35 19  6 28 63 65 10 54 45 66 20 68  1 55 13  0 75 15  7 11 51 24 64 70 47 40 27  9 77 42 74  2 14 46 49 12 32  5 60 31 22  4 34 43 73 41 26 52 33 79 69 71 16 50 36 38 57 39 78  3 67 59  8 25 21 44 18 48 23 53 37 61 56 72 29], a_shuffle_aclus: [101  83  79  24  39  47  26   9  35  84  86  14  71  60  87  27  90   3  72  18   2 100  20  11  15  68  31  85  92  62  55  34  13 102  57  98   4  19  61  66  16  43   8  81  40  29   6  45  58  97  56  33  69  44 104  91  93  23  67  48  52  77  53 103   5  89  80  12  32  28  59  25  63  30  70  51  82  75  95  38]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:344: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_completed_shuffles: 29\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "total_n_shuffles: 29\n",
      "(n_shuffles = 29, n_epochs = 77, n_decoders = 4); n_total_elements = 8932\n",
      "saving to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0655PM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_29.pkl\"...\n",
      "total_n_shuffles: 29\n",
      "Saving (file mode 'w+b') pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0655PM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_29.pkl\"... saved pickle file\n",
      "saving .mat file to \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0655PM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_all_shuffles_wcorr_array.mat\"...\n",
      "total_n_shuffles: 29\n",
      "(n_shuffles = 29, n_epochs = 77, n_decoders = 4); n_total_elements = 8932\n",
      "len(active_epochs_df): 156\n",
      "min_num_unique_aclu_inclusions: 18\n",
      "len(active_epochs_df): 77\n",
      "desired_ripple_decoding_time_bin_size = 0.025\n",
      "num_user_selected_times: 0\n",
      "adding user annotation column!\n",
      "ERROR: failed for ripple_WCorrShuffle_df. Out of options.\n",
      "\t failed all methods for annotations\n",
      "num_valid_epoch_times: 77\n",
      "adding valid filtered epochs column!\n",
      "\t succeded at getting 77 selected indicies (of 77 valid filter epoch times) for ripple_WCorrShuffle_df. got 77 indicies!\n",
      "Successfully exported ripple_WCorrShuffle_df_export_CSV_path: \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-07-10_0650PM-kdiba_gor01_one_2006-6-09_1-22-43__withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv\" with wcorr_shuffles.n_completed_shuffles: 29 unique shuffles.\n",
      "\t saved \"file:///C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2024-07-10/kdiba/gor01/one/2006-6-09_1-22-43/replay_wcorr__withNewKamranExportedReplays-qclu_%5B1%2C2%5D-frateThresh_5%E2%80%A20.png\"\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import compute_diba_quiescent_style_replay_events, overwrite_replay_epochs_and_recompute, try_load_neuroscope_EVT_file_epochs, replace_replay_epochs, _get_custom_suffix_for_replay_filename, finalize_output_shuffled_wcorr\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "# %pdb on\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "a_dummy.should_suppress_errors = False\n",
    "\n",
    "## Settings:\n",
    "\n",
    "# SimpleBatchComputationDummy = make_class('SimpleBatchComputationDummy', attrs=['BATCH_DATE_TO_USE', 'collected_outputs_path'])\n",
    "# a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path)\n",
    "\n",
    "_across_session_results_extended_dict = {}\n",
    "## Combine the output of `compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function(a_dummy, None,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tacross_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # save_hdf=save_hdf, return_full_decoding_results=return_full_decoding_results,\n",
    "                                                # desired_shared_decoding_time_bin_sizes=desired_shared_decoding_time_bin_sizes,\n",
    "                                                )\n",
    "\n",
    "\n",
    "# 60m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae803054",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c0781e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e318bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completed overwrite_replay_epochs_and_recompute(...). custom_save_filepaths: {'pipeline_pkl': WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl'), 'global_computation_pkl': 'global_computation_results_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl', 'pipeline_h5': 'pipeline_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.h5', 'csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-05_Apogee_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-2006-6-07_16-40-19_time_bin_size_sweep_results.h5'), 'ripple_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19-(ripple_marginals_df).csv'), 'standalone_wcorr_pkl': WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/2024-07-05_0505PM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_27.pkl'), 'standalone_mat_pkl': WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/2024-07-05_0505PM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_all_shuffles_wcorr_array.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d33e58e",
   "metadata": {},
   "source": [
    "# Serialize: `replay_epoch_variations and _across_session_results_extended_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2db50f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Extract results and save to pickle:\n",
    "replay_epoch_variations = deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function']['replay_epoch_variations'])\n",
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results: Dict = deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'])\n",
    "# compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7021df23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving (file mode 'w+b') pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results.pkl\"... \tmoving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\20240710185712-compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results.pkltmp' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results.pkl'\n",
      "saved pickle file\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData\n",
    "# Saving (file mode 'w+b') session pickle file results :... saved session pickle file\n",
    "\n",
    "_specific_out_file_path = curr_active_pipeline.get_output_path().joinpath('compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results.pkl').resolve()\n",
    "saveData(_specific_out_file_path, deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function']))\n",
    "# saveData('output/compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results.pkl', deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25445fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function', _across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'], max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ccc9e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl'),\n",
       " 'global_computation_pkl': 'global_computation_results_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl',\n",
       " 'pipeline_h5': 'pipeline_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.h5',\n",
       " 'ripple_h5_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10_Apogee_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-2006-6-09_1-22-43-_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_time_bin_size_sweep_results.h5'),\n",
       " 'ripple_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_marginals_df).csv'),\n",
       " 'ripple_csv_time_bin_marginals': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_time_bin_marginals_df).csv'),\n",
       " 'laps_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(laps_marginals_df).csv'),\n",
       " 'laps_csv_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(laps_time_bin_marginals_df).csv'),\n",
       " 'standalone_wcorr_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0650PM_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_27.pkl'),\n",
       " 'standalone_mat_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0650PM_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_standalone_all_shuffles_wcorr_array.mat')}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "KeyError",
     "evalue": "'csv_out_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m _curr_outpaths\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# _curr_outpaths['pipeline_pkl'].exists()\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43m_curr_outpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcsv_out_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mexists()\n",
      "\u001b[1;31mKeyError\u001b[0m: 'csv_out_path'"
     ]
    }
   ],
   "source": [
    "_curr_outpaths = compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results['replay_epoch_outputs']['diba_quiescent_method_replay_epochs']['custom_save_filepaths']\n",
    "_curr_outpaths\n",
    "# _curr_outpaths['pipeline_pkl'].exists()\n",
    "_curr_outpaths['csv_out_path'].exists()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95b18dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'initial_loaded': {'pipeline_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withOldestImportedReplays-qclu_XX-frateThresh_0.1.pkl'),\n",
       "  'ripple_h5_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10_Apogee_withOldestImportedReplays-qclu_XX-frateThresh_0.1-2006-6-09_1-22-43-_withOldestImportedReplays-qclu_XX-frateThresh_0.1_time_bin_size_sweep_results.h5'),\n",
       "  'ripple_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withOldestImportedReplays-qclu_XX-frateThresh_0.1-(ripple_marginals_df).csv'),\n",
       "  'ripple_csv_time_bin_marginals': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withOldestImportedReplays-qclu_XX-frateThresh_0.1-(ripple_time_bin_marginals_df).csv'),\n",
       "  'laps_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withOldestImportedReplays-qclu_XX-frateThresh_0.1-(laps_marginals_df).csv'),\n",
       "  'laps_csv_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withOldestImportedReplays-qclu_XX-frateThresh_0.1-(laps_time_bin_marginals_df).csv'),\n",
       "  'standalone_wcorr_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0640PM_withOldestImportedReplays-qclu_XX-frateThresh_0.1_standalone_wcorr_ripple_shuffle_data_only_27.pkl'),\n",
       "  'standalone_mat_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0640PM_withOldestImportedReplays-qclu_XX-frateThresh_0.1_standalone_all_shuffles_wcorr_array.mat')},\n",
       " 'normal_computed': {'pipeline_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0.pkl'),\n",
       "  'ripple_h5_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10_Apogee_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-2006-6-09_1-22-43-_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0_time_bin_size_sweep_results.h5'),\n",
       "  'ripple_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-(ripple_marginals_df).csv'),\n",
       "  'ripple_csv_time_bin_marginals': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-(ripple_time_bin_marginals_df).csv'),\n",
       "  'laps_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-(laps_marginals_df).csv'),\n",
       "  'laps_csv_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0-(laps_time_bin_marginals_df).csv'),\n",
       "  'standalone_wcorr_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0645PM_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0_standalone_wcorr_ripple_shuffle_data_only_27.pkl'),\n",
       "  'standalone_mat_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0645PM_withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0_standalone_all_shuffles_wcorr_array.mat')},\n",
       " 'diba_quiescent_method_replay_epochs': {'pipeline_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl'),\n",
       "  'ripple_h5_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10_Apogee_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-2006-6-09_1-22-43-_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_time_bin_size_sweep_results.h5'),\n",
       "  'ripple_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_marginals_df).csv'),\n",
       "  'ripple_csv_time_bin_marginals': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_time_bin_marginals_df).csv'),\n",
       "  'laps_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(laps_marginals_df).csv'),\n",
       "  'laps_csv_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(laps_time_bin_marginals_df).csv'),\n",
       "  'standalone_wcorr_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0650PM_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_27.pkl'),\n",
       "  'standalone_mat_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0650PM_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0_standalone_all_shuffles_wcorr_array.mat')},\n",
       " 'diba_evt_file': {'pipeline_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl'),\n",
       "  'ripple_h5_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10_Apogee_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-2006-6-09_1-22-43-_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_time_bin_size_sweep_results.h5'),\n",
       "  'ripple_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-(ripple_marginals_df).csv'),\n",
       "  'ripple_csv_time_bin_marginals': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-(ripple_time_bin_marginals_df).csv'),\n",
       "  'laps_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-(laps_marginals_df).csv'),\n",
       "  'laps_csv_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-10-kdiba_gor01_one_2006-6-09_1-22-43__withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-(laps_time_bin_marginals_df).csv'),\n",
       "  'standalone_wcorr_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0655PM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_27.pkl'),\n",
       "  'standalone_mat_pkl': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-10_0655PM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_all_shuffles_wcorr_array.mat')}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _drop_non_existing_file_values(a_dict):\n",
    "    return {k:Path(v).resolve() for k, v in a_dict.items() if Path(v).exists()}\n",
    "\n",
    "# _curr_outpaths_dict = {a_replay_name:v['custom_save_filepaths'] for a_replay_name, v in compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results['replay_epoch_outputs'].items()}\n",
    "_curr_outpaths_dict = {a_replay_name:_drop_non_existing_file_values(v['custom_save_filepaths']) for a_replay_name, v in compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results['replay_epoch_outputs'].items()}\n",
    "_curr_outpaths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "_drop_non_existing_file_values(_curr_outpaths_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c0743",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Document `compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results`\n",
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=doc_output_parent_folder, doc_name='compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results')\n",
    "doc_printer.save_documentation('compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results', compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results,\n",
    "                                non_expanded_item_keys=['_reverse_cellID_index_map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd27d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import loadData\n",
    "\n",
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results = loadData('output/compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results.pkl')\n",
    "replay_epoch_variations = deepcopy(compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results['replay_epoch_variations'])\n",
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b70fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'standalone_pkl_filepath': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-01_1000AM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_29.pkl'),\n",
    "# 'standalone_mat_filepath': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-01_1000AM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_all_shuffles_wcorr_array.mat'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de49582",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e403f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## See how the Long/Short replay detection looks using the Diba-loaded intervals:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413dd9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# spikes_df = curr_active_pipeline.sess.spikes_df # inferior way\n",
    "spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b90d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e214f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'] #['out_hist_fig_result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c91d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute new epochs: \n",
    "included_qclu_values=[1,2]\n",
    "minimum_inclusion_fr_Hz=5.0\n",
    "spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "(qclu_included_aclus, active_track_templates, active_spikes_df, quiescent_periods), (diba_quiescent_method_replay_epochs_df, diba_quiescent_method_replay_epochs) = compute_diba_quiescent_style_replay_events(curr_active_pipeline=curr_active_pipeline,\n",
    "                                                                                                                                                                            included_qclu_values=included_qclu_values, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, spikes_df=spikes_df)\n",
    "\n",
    "## OUTPUTS: diba_quiescent_method_replay_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "included_qclu_values=[1,2]\n",
    "minimum_inclusion_fr_Hz=5.0\n",
    "spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "(qclu_included_aclus, active_track_templates, active_spikes_df, quiescent_periods), (diba_quiescent_method_replay_epochs_df, diba_quiescent_method_replay_epochs) = compute_diba_quiescent_style_replay_events(curr_active_pipeline=curr_active_pipeline,\n",
    "                                                                                                                                                                            included_qclu_values=included_qclu_values, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, spikes_df=spikes_df)\n",
    "\n",
    "## OUTPUTS: diba_quiescent_method_replay_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b2fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FROM .evt file\n",
    "## Load exported epochs from a neuroscope .evt file:\n",
    "diba_evt_file_replay_epochs: Epoch = try_load_neuroscope_EVT_file_epochs(curr_active_pipeline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64495b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Use `diba_evt_file_replay_epochs` as `new_replay_epochs`\n",
    "new_replay_epochs = deepcopy(diba_evt_file_replay_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ec361",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use `diba_quiescent_method_replay_epochs` as `new_replay_epochs`:\n",
    "new_replay_epochs = deepcopy(diba_quiescent_method_replay_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08597aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_replay_epochs_df = ensure_dataframe(new_replay_epochs)\n",
    "new_replay_epochs_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b99020",
   "metadata": {},
   "outputs": [],
   "source": [
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-overwrite_replay_epochs_and_recompute.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    did_change, custom_save_filenames, custom_save_filepaths = overwrite_replay_epochs_and_recompute(curr_active_pipeline=curr_active_pipeline, new_replay_epochs=new_replay_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a9a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "did_change, custom_save_filenames, custom_save_filepaths = overwrite_replay_epochs_and_recompute(curr_active_pipeline=curr_active_pipeline, new_replay_epochs=new_replay_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f64b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_replay_epochs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec3a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.replay_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1547be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add ALL of the possible replay periods to the session as a new `replay_epoch_variations` variable:\n",
    "# if not hasattr(curr_active_pipeline.sess, 'replay_epoch_variations'):\n",
    "#     curr_active_pipeline.sess.replay_epoch_variations = {}\n",
    "\n",
    "\n",
    "# curr_active_pipeline.sess.replay_epoch_variations.update({\n",
    "#     'initial_loaded': deepcopy(curr_active_pipeline.sess.replay_backup),\n",
    "#     'diba_evt_file': deepcopy(diba_evt_file_replay_epochs),\n",
    "#     'diba_quiescent_method_replay_epochs': deepcopy(diba_quiescent_method_replay_epochs),\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3017a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import Epoch, ensure_Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import compute_all_replay_epoch_variations\n",
    "\n",
    "replay_epoch_variations = compute_all_replay_epoch_variations(curr_active_pipeline)\n",
    "replay_epoch_variations\n",
    "## OUTPUT: replay_epoch_variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e400e",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": [
     "2024-07-03"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import CustomDecodeEpochsResult, decoder_name, epoch_split_key, get_proper_global_spikes_df, _compute_arbitrary_epochs_decoding_for_decoder\n",
    "\n",
    "active_decoding_epochs: Epoch = deepcopy(replay_epoch_variations['diba_quiescent_method_replay_epochs'])\n",
    "active_decoding_time_bin_size: float = 0.02 # 20ms\n",
    "minimum_inclusion_fr_Hz: float = active_decoding_epochs.metadata.get('minimum_inclusion_fr_Hz', 1.0)\n",
    "included_qclu_values: List[int] = active_decoding_epochs.metadata.get('included_qclu_values', [1,2])\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# spikes_df = curr_active_pipeline.sess.spikes_df # inferior way\n",
    "spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "## Decode epochs for all four decoders:\n",
    "new_epochs_decoder_result_dict: Dict[str, Optional[\"DecodedFilterEpochsResult\"]] = {}\n",
    "for a_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    new_epochs_decoder_result_dict[a_name] = _compute_arbitrary_epochs_decoding_for_decoder(a_decoder, spikes_df=deepcopy(spikes_df), decoding_epochs=active_decoding_epochs, desired_epoch_decoding_time_bin_size=active_decoding_time_bin_size)\n",
    "\n",
    "## OUTPUTS: new_epochs_decoder_result_dict,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c06f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTPUTS: new_epochs_decoder_result_dict\n",
    "new_epochs_decoder_result_dict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2951da7",
   "metadata": {
    "tags": [
     "2024-07-03"
    ]
   },
   "outputs": [],
   "source": [
    "# rank_order_results = curr_active_pipeline.global_computation_results.computed_data['RankOrder'] # : \"RankOrderComputationsContainer\"\n",
    "# minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "# included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "# print(f'included_qclu_values: {included_qclu_values}')\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: \"DirectionalPseudo2DDecodersResult\" = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "pos_bin_size: float = track_templates.get_decoders()[0].pos_bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d664c4",
   "metadata": {
    "tags": [
     "2024-07-03"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_all_df_score_metrics\n",
    "\n",
    "\n",
    "## Recompute the epoch scores/metrics such as radon transform and wcorr:\n",
    "spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict), merged_df_outputs_tuple, raw_dict_outputs_tuple = _compute_all_df_score_metrics(directional_merged_decoders_result, track_templates,\n",
    "                                                                                                                                                                                    decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                                                                    spikes_df=deepcopy(spikes_df),\n",
    "                                                                                                                                                                                    should_skip_radon_transform=should_skip_radon_transform)\n",
    "laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df, laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df = merged_df_outputs_tuple\n",
    "decoder_laps_radon_transform_df_dict, decoder_ripple_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict, decoder_ripple_radon_transform_extras_dict, decoder_laps_weighted_corr_df_dict, decoder_ripple_weighted_corr_df_dict = raw_dict_outputs_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Document `curr_active_pipeline.sess`\n",
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=doc_output_parent_folder, doc_name='curr_active_pipeline.sess')\n",
    "doc_printer.save_documentation('curr_active_pipeline.sess', curr_active_pipeline.sess, non_expanded_item_keys=['_reverse_cellID_index_map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "from pyphocorehelpers.gui.PhoUIContainer import PhoUIContainer\n",
    "from pyphoplacecellanalysis.GUI.Qt.Menus.PhoMenuHelper import PhoMenuHelper\n",
    "from pyphoplacecellanalysis.GUI.Qt.Menus.LocalMenus_AddRenderable.LocalMenus_AddRenderable import LocalMenus_AddRenderable\n",
    "from qtpy.QtWidgets import QAction\n",
    "from pyphoplacecellanalysis.GUI.Qt.Menus.LocalMenus_AddRenderable.LocalMenus_AddRenderable import LocalMenus_AddRenderable\n",
    "\n",
    "epoch_variations_name_list = list(replay_epoch_variations.keys())\n",
    "epoch_variations_name_list\n",
    "\n",
    "\n",
    "## GOAL: build (CUSTOM_submenu_addTimeIntervals, CUSTOM_submenu_addTimeIntervals_ONLY_NEW, CUSTOM_submenu_addTimeIntervalCallbacks, CUSTOM_submenu_addTimeIntervals_Connections)\n",
    "\n",
    "## Add new dynamic intervals:\n",
    "\n",
    "# Assuming add_renderables_menu and add_time_intervals_menu are already defined\n",
    "add_renderables_menu: benedict[str, benedict[str, QAction]] = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "# print(type(add_renderables_menu))\n",
    "add_renderables_menu\n",
    "add_time_intervals_menu: benedict[str, QAction] = add_renderables_menu['AddTimeIntervals']\n",
    "# print(type(add_time_intervals_menu))\n",
    "add_time_intervals_menu\n",
    "\n",
    "_gui_menu_parent: LocalMenus_AddRenderable = add_time_intervals_menu['Laps'].parent()\n",
    "print(_gui_menu_parent.ui)\n",
    "_gui_menu_parent.ui.menuAdd_Renderable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf9971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Epoch/Interval Rectangles:\n",
    "debug_print = True\n",
    "interval_datasource_names = active_2d_plot.interval_datasource_names # ['CustomPBEs', 'PBEs', 'Ripples', 'Laps', 'Replays', 'SessionEpochs']\n",
    "if debug_print:\n",
    "    print(f'interval_datasource_names: {interval_datasource_names}')\n",
    "restore_epoch_menu_commands = [f'AddTimeIntervals.{a_name}' for a_name in interval_datasource_names]\n",
    "if debug_print:\n",
    "    print(f'restore_epoch_menu_commands: {restore_epoch_menu_commands}')\n",
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "for a_command in restore_epoch_menu_commands:\n",
    "    if a_command not in add_renderables_menu:\n",
    "        print(f\"WARNING: command '{a_command}' is not present in add_renderables_menu, so restore will not work for this item!\")\n",
    "    # add_renderables_menu[a_command].trigger()\n",
    "\n",
    "variations_epoch_menu_commands = [f'AddTimeIntervals.{a_name}' for a_name in epoch_variations_name_list]\n",
    "if debug_print:\n",
    "    print(f'variations_epoch_menu_commands: {variations_epoch_menu_commands}')\n",
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "for a_command in variations_epoch_menu_commands:\n",
    "    if a_command not in add_renderables_menu:\n",
    "        print(f\"WARNING: command '{a_command}' is not present in add_renderables_menu, so restore will not work for this item!\")\n",
    "    # add_renderables_menu[a_command].trigger()\n",
    "\n",
    "\n",
    "# add_time_intervals_menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687de0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import Replays_2DRenderTimeEpochs\n",
    "## Callbacks to render the epochs:\n",
    "## INPUTS: destination_plot\n",
    "destination_plot = active_2d_plot\n",
    "\n",
    "# class CustomReplays_2DRenderTimeEpochs(General2DRenderTimeEpochs):\n",
    "#     default_datasource_name = 'NewRipples'\n",
    "    \n",
    "#     @classmethod\n",
    "#     def build_epochs_dataframe_formatter(cls, **kwargs):\n",
    "#         def _add_interval_dataframe_visualization_columns_general_epoch(active_df):\n",
    "#             ## parameters:\n",
    "#             y_location = 0.0\n",
    "#             height = 2.0\n",
    "#             pen_color = pg.mkColor('cyan')\n",
    "#             brush_color = pg.mkColor('cyan')\n",
    "#             brush_color.setAlphaF(0.5)\n",
    "            \n",
    "#             ## Add the missing parameters to the dataframe:\n",
    "#             active_df = cls._update_df_visualization_columns(active_df, y_location, height, pen_color, brush_color, **kwargs)\n",
    "#             return active_df\n",
    "\n",
    "#         return _add_interval_dataframe_visualization_columns_general_epoch\n",
    "    \n",
    "# from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, Ripples_2DRenderTimeEpochs, inline_mkColor\n",
    "# ## Inline Concise: Position Replays, PBEs, and Ripples all below the scatter:\n",
    "# # active_2d_plot.interval_datasources.Replays.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-10.0, height=7.5, pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5), **kwargs)) ## Fully inline\n",
    "# # active_2d_plot.interval_datasources.PBEs.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-2.0, height=1.5, pen_color=inline_mkColor('pink', 0.8), brush_color=inline_mkColor('pink', 0.5), **kwargs)) ## Fully inline\n",
    "# # active_2d_plot.interval_datasources.Ripples.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5), **kwargs)) ## Fully inline\n",
    "# # active_2d_plot.interval_datasources.SessionEpochs .update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5), **kwargs)) ## Fully inline\n",
    "# epochs_update_dict = {\n",
    "#     'Replays':dict(y_location=-10.0, height=7.5, pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5)),\n",
    "#     'PBEs':dict(y_location=-2.0, height=1.5, pen_color=inline_mkColor('pink', 0.8), brush_color=inline_mkColor('pink', 0.5)),\n",
    "#     'Ripples':dict(y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5)),\n",
    "#     'SessionEpochs ':dict(y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5)),\n",
    "# }\n",
    "# active_2d_plot.update_rendered_intervals_visualization_properties(epochs_update_dict)\n",
    "\n",
    "\n",
    "# submenu_addTimeIntervalCallbacks: List[Callable] = [lambda evt=None: Replays_2DRenderTimeEpochs.add_render_time_epochs(curr_sess=v, destination_plot=destination_plot) for k, v in replay_epoch_variations.items()]\n",
    "\n",
    "# CUSTOM_submenu_addTimeIntervalCallbacks: List[Callable] = [lambda evt=None: General2DRenderTimeEpochs.add_render_time_epochs(curr_sess=v, destination_plot=destination_plot, name=interval_name) for interval_name, v in replay_epoch_variations.items()]\n",
    "# CUSTOM_submenu_addTimeIntervalCallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a2e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: destination_plot\n",
    "destination_plot = active_2d_plot\n",
    "\n",
    "# # Define the new intervals and their callbacks\n",
    "# new_intervals = [\n",
    "#     (\"New Interval 1\", lambda: print(\"Interval 1 callback\")),\n",
    "#     (\"New Interval 2\", lambda: print(\"Interval 2 callback\")),\n",
    "#     (\"New Interval 3\", lambda: print(\"Interval 3 callback\")),\n",
    "#     (\"New Interval 4\", lambda: print(\"Interval 4 callback\"))\n",
    "# ]\n",
    "\n",
    "CUSTOM_submenu_addTimeIntervals: List[QAction] = []\n",
    "CUSTOM_submenu_addTimeIntervals_ONLY_NEW: List[QAction] = []\n",
    "CUSTOM_submenu_addTimeIntervalCallbacks: List[Callable] =[]\n",
    "CUSTOM_submenu_addTimeIntervals_Connections = []\n",
    "# only_new_time_intervals_menu: benedict[str, QAction] = benedict()\n",
    "\n",
    "\n",
    "# Add new actions to the add_time_intervals_menu\n",
    "# for interval_name, a_callback in new_intervals:\n",
    "for interval_name, a_replay_epoch in replay_epoch_variations.items():\n",
    "\n",
    "    # action = QAction(interval_name, add_time_intervals_menu)\n",
    "    an_action = QAction(interval_name, parent=_gui_menu_parent)  # Set parent to None\n",
    "    an_action.setText(interval_name)\n",
    "    an_action.setObjectName(f\"actionAddTimeIntervals_{interval_name}\")\n",
    "\n",
    "    a_callback = (lambda evt=None: General2DRenderTimeEpochs.add_render_time_epochs(curr_sess=a_replay_epoch, destination_plot=destination_plot, name=interval_name))\n",
    "    CUSTOM_submenu_addTimeIntervalCallbacks.append(a_callback)\n",
    "\n",
    "    # QtWidgets.QAction(LocalMenus_AddRenderable)\n",
    "    _curr_conn = an_action.triggered.connect(a_callback)\n",
    "    CUSTOM_submenu_addTimeIntervals_Connections.append(_curr_conn)\n",
    "    extracted_menu_path = PhoMenuHelper.parse_QAction_for_menu_path(an_action)\n",
    "    print(f'extracted_menu_path: {extracted_menu_path}')\n",
    "    new_key: str = '.'.join(extracted_menu_path)\n",
    "    CUSTOM_submenu_addTimeIntervals.append(an_action)\n",
    "\n",
    "    if new_key not in add_time_intervals_menu:\n",
    "        ## completely new\n",
    "        # only_new_time_intervals_menu[new_key] = an_action\n",
    "        CUSTOM_submenu_addTimeIntervals_ONLY_NEW.append(an_action)\n",
    "\n",
    "    add_time_intervals_menu[new_key] = an_action # have to use a string keypath because `out_command_dict[*extracted_menu_path]` is not allowed\n",
    "    # add_time_intervals_menu.addAction(an_action)\n",
    "    # Add the action to the actual menu\n",
    "    _gui_menu_parent.ui.menuAdd_Renderable.addAction(an_action)\n",
    "\n",
    "\n",
    "# add_time_intervals_menu\n",
    "# only_new_time_intervals_menu\n",
    "\n",
    "\n",
    "# cls.add_dynamic_time_intervals(widget, new_intervals)\n",
    "\n",
    "## INPUTS: add_time_intervals_menu, _gui_menu_parent.ui.menuAdd_Renderable\n",
    "\n",
    "\n",
    "## OUTPUTS: CUSTOM_submenu_addTimeIntervals, CUSTOM_submenu_addTimeIntervals_ONLY_NEW, CUSTOM_submenu_addTimeIntervals_Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9386c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_epoch_name: str = curr_active_pipeline.find_LongShortGlobal_epoch_names()[-1]\n",
    "active_2d_plot_renderable_menus_tuple: Tuple = LocalMenus_AddRenderable._build_renderable_menu(destination_plot=active_2d_plot, curr_active_pipeline=curr_active_pipeline, active_config_name=global_epoch_name)\n",
    "widget, renderable_menu, (submenu_addTimeIntervals, submenu_addTimeIntervalCallbacks, submenu_addTimeIntervals_Connections), (submenu_addTimeCurves, submenu_addTimeCurvesCallbacks, submenu_addTimeCurves_Connections), (submenu_addMatplotlibPlot, submenu_addMatplotlibPlotCallbacks, submenu_addMatplotlibPlot_Connections) = active_2d_plot_renderable_menus_tuple ## Unpack\n",
    "\n",
    "# extend: (submenu_addTimeIntervals, submenu_addTimeIntervalCallbacks, submenu_addTimeIntervals_Connections)\n",
    "\n",
    "# my items (CUSTOM_submenu_addTimeIntervals, CUSTOM_submenu_addTimeIntervals_ONLY_NEW, CUSTOM_submenu_addTimeIntervalCallbacks, CUSTOM_submenu_addTimeIntervals_Connections)\n",
    "\n",
    "\n",
    "# submenu_addTimeIntervals\n",
    "# submenu_addTimeIntervals\n",
    "submenu_addTimeIntervals.extend(CUSTOM_submenu_addTimeIntervals_ONLY_NEW)\n",
    "submenu_addTimeIntervalCallbacks.extend(CUSTOM_submenu_addTimeIntervalCallbacks)\n",
    "submenu_addTimeIntervals_Connections.extend(CUSTOM_submenu_addTimeIntervals_Connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd6237",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_epoch_name: str = curr_active_pipeline.find_LongShortGlobal_epoch_names()[-1]\n",
    "global_epoch_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b74d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Menus.LocalMenus_AddRenderable.LocalMenus_AddRenderable import LocalMenus_AddRenderable\n",
    "\n",
    "# active_2d_plot = spike_raster_window.spike_raster_plt_2d \n",
    "menuAdd_Renderable: QtWidgets.QMenu = LocalMenus_AddRenderable.add_renderable_context_menu(active_2d_plot=active_2d_plot, curr_active_pipeline=curr_active_pipeline, active_config_name=global_epoch_name)\n",
    "menuAdd_Renderable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e40ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_renderable_context_menu(active_2d_plot, curr_active_pipeline, active_config_name, override_custom_menu: Optional[QtWidgets.QMenu]=None, additional_menu_items=None) -> QtWidgets.QMenu:\n",
    "    \"\"\" \n",
    "    Usage:\n",
    "        active_2d_plot = spike_raster_window.spike_raster_plt_2d \n",
    "        menuAdd_Renderable = LocalMenus_AddRenderable.add_renderable_context_menu(active_2d_plot, sess)\n",
    "        \n",
    "    \"\"\"\n",
    "    def _subFn_append_custom_menu_to_context_menu(parent_widget, additional_menu: QtWidgets.QMenu, debug_print=False):\n",
    "        \"\"\" Adds the custom menu, such as one loaded from a .ui file, to the end of the context menu\n",
    "        parent_widget: PlotItem\n",
    "        additional_menu: QMenu\n",
    "        \n",
    "        Example:\n",
    "            from pyphoplacecellanalysis.Resources import GuiResources, ActionIcons\n",
    "            from pyphoplacecellanalysis.GUI.Qt.GlobalApplicationMenus.LocalMenus_AddRenderable import LocalMenus_AddRenderable\n",
    "            widget = LocalMenus_AddRenderable()\n",
    "            append_custom_menu_to_context_menu(main_plot_widget, widget.ui.menuAdd_Renderable)\n",
    "            append_custom_menu_to_context_menu(background_static_scroll_plot_widget, widget.ui.menuAdd_Renderable)\n",
    "        \"\"\"\n",
    "        \n",
    "        plot_options_context_menu = parent_widget.getContextMenus(None) # This gets the \"Plot Options\" menu\n",
    "        # top_level_parent_context_menu = parent_context_menus.parent()\n",
    "        top_level_parent_context_menu = parent_widget.vb.menu # ViewBoxMenu\n",
    "        \n",
    "        active_parent_menu = top_level_parent_context_menu\n",
    "        active_parent_menu.addSeparator()\n",
    "        active_parent_menu.addMenu(additional_menu)\n",
    "        if debug_print:\n",
    "            print(f'parent_context_menus.actions: {[an_action.text() for an_action in active_parent_menu.actions()]}') # parent_context_menus.actions: ['Transforms', 'Downsample', 'Average', 'Alpha', 'Grid', 'Points']\n",
    "            \n",
    "        ## Build `partial` versions of the functions specific to each raster plotter that can be called with no arguments (capturing the destination plotter and the session\n",
    "    # build_renderable_menu_to_Spike2DRaster = partial(cls.build_renderable_menu, active_2d_plot, sess) # destination_plot\n",
    "    # active_2d_plot_renderable_menus = cls._build_renderable_menu(active_2d_plot, sess)\n",
    "    \n",
    "\n",
    "\n",
    "    if override_custom_menu is None:\n",
    "        active_2d_plot_renderable_menus: Tuple = LocalMenus_AddRenderable._build_renderable_menu(active_2d_plot, curr_active_pipeline, active_config_name)\n",
    "        menuAdd_Renderable: QtWidgets.QMenu = widget_2d_menu.ui.menuAdd_Renderable\n",
    "    else:\n",
    "        active_2d_plot_renderable_menus: Tuple = LocalMenus_AddRenderable._build_renderable_menu(active_2d_plot, curr_active_pipeline, active_config_name) # not sure where they should come from, the flat dict?\n",
    "        menuAdd_Renderable: QtWidgets.QMenu = override_custom_menu\n",
    "\n",
    "\n",
    "\n",
    "    if additional_menu_items is not None:\n",
    "        ## add them\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    # active_2d_plot_renderable_menus: Tuple = LocalMenus_AddRenderable._build_renderable_menu(active_2d_plot, curr_active_pipeline, active_config_name)\n",
    "    widget_2d_menu: LocalMenus_AddRenderable = active_2d_plot_renderable_menus[0]\n",
    "    \n",
    "    # programmatic_actions_dict = widget_2d_menu.programmatic_actions_dict\n",
    "    print(f'active_2d_plot_renderable_menus: {active_2d_plot_renderable_menus}, type(active_2d_plot_renderable_menus): {type(active_2d_plot_renderable_menus)}')\n",
    "    print(f'widget_2d_menu: {widget_2d_menu}, type(widget_2d_menu): {type(widget_2d_menu)}')\n",
    "    print(f'menuAdd_Renderable: {menuAdd_Renderable}, type(menuAdd_Renderable): {type(menuAdd_Renderable)}')\n",
    "    # print(f'menuAdd_Renderable: {menuAdd_Renderable}, type(menuAdd_Renderable): {type(menuAdd_Renderable)}')\n",
    "\n",
    "\n",
    "\n",
    "    ## Specific to SpikeRaster2D:        \n",
    "    ## Add the custom menu to the context menus of the plots in SpikeRaster2D:        \n",
    "    main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "    background_static_scroll_plot_widget = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "    _subFn_append_custom_menu_to_context_menu(main_plot_widget, menuAdd_Renderable)\n",
    "    _subFn_append_custom_menu_to_context_menu(background_static_scroll_plot_widget, menuAdd_Renderable)\n",
    "    \n",
    "    # Add the reference to the context menus to owner, so it isn't released:\n",
    "    ## TODO: currently replaces the dict entry, which we might want to use for other menus\n",
    "    active_2d_plot.ui.menus = PhoUIContainer.init_from_dict({'custom_context_menus': PhoUIContainer.init_from_dict({'add_renderables': active_2d_plot_renderable_menus})})\n",
    "\n",
    "    # # Build final programmatic dict from nested PhoUIContainers:\n",
    "    # out_final = PhoUIContainer.init_from_dict({})\n",
    "    # for k, v in programmatic_actions_dict.items_sorted_by_keys(reverse=False):\n",
    "    #     out_final[k] = PhoUIContainer.init_from_dict(v)\n",
    "    #     # print(k, v)\n",
    "    # widget_2d_menu.programmatic_actions_dict = out_final\n",
    "\n",
    "\n",
    "    return menuAdd_Renderable # try returning just the menu and not the stupid references to everything # Works when we hold a reference\n",
    "\n",
    "\n",
    "## INPUTS: add_time_intervals_menu, _gui_menu_parent.ui.menuAdd_Renderable\n",
    "\n",
    "menuAdd_Renderable: QtWidgets.QMenu = add_renderable_context_menu(active_2d_plot=active_2d_plot, curr_active_pipeline=curr_active_pipeline, active_config_name=global_epoch_name,\n",
    "                                                                  override_custom_menu=_gui_menu_parent.ui.menuAdd_Renderable,\n",
    "                                                                    # additional_menu_items=add_time_intervals_menu,\n",
    "                                                                    )\n",
    "menuAdd_Renderable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submenu_addTimeIntervals_Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb1fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force a refresh of the context menu\n",
    "def rebuild_context_menu():\n",
    "    _gui_menu_parent.ui.menuAdd_Renderable.clear()\n",
    "    for action in add_time_intervals_menu.values():\n",
    "        _gui_menu_parent.ui.menuAdd_Renderable.addAction(action)\n",
    "\n",
    "rebuild_context_menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8bb51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01629e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_epochs_key = 'diba_quiescent_method_replay_epochs'\n",
    "a_replay_epochs = replay_epoch_variations[replay_epochs_key]\n",
    "\n",
    "# for replay_epochs_key, a_replay_epochs in replay_epoch_variations.items():\n",
    "_temp_curr_active_pipeline = deepcopy(curr_active_pipeline)\n",
    "did_change, custom_save_filenames, custom_save_filepaths = overwrite_replay_epochs_and_recompute(curr_active_pipeline=_temp_curr_active_pipeline, new_replay_epochs=a_replay_epochs, enable_save_pipeline_pkl=True, enable_save_global_computations_pkl=False, enable_save_h5=False)\n",
    "\n",
    "## modifies `_temp_curr_active_pipeline`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1cd763",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_save_filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63846311",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "custom_save_filepaths = helper_perform_pickle_pipeline(a_curr_active_pipeline=_temp_curr_active_pipeline, custom_save_filenames=custom_save_filenames, custom_save_filepaths=custom_save_filepaths, enable_save_pipeline_pkl=True, enable_save_global_computations_pkl=False, enable_save_h5=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc661c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_save_filepaths # 'pipeline_pkl': PosixPath('/Users/pho/data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl'),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf10b54",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5df735b",
   "metadata": {},
   "source": [
    "# 🎯🔷💯 2024-07-02 - New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "if ('DirectionalDecodersEpochsEvaluations' in curr_active_pipeline.global_computation_results.computed_data) and (curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] is not None):\n",
    "    directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "    directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "    ## UNPACK HERE via direct property access:\n",
    "    pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "    ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "    laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "    print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "    decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "    decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "    # New items:\n",
    "    decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "    decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "    # Weighted correlations:\n",
    "    laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "    ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "    decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "    # Pearson's correlations:\n",
    "    laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "    ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992bc1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context().adding_context_if_missing(custom_\n",
    "\n",
    "# session_name: str = curr_active_pipeline.session_name\n",
    "\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "session_name: str = f\"{curr_active_pipeline.session_name}{custom_suffix}\" ## appending this here is a hack, but it makes the correct filename\n",
    "active_context = active_context.adding_context_if_missing(suffix=custom_suffix)\n",
    "session_ctxt_key:str = active_context.get_description(separator='|', subset_includelist=(IdentifyingContext._get_session_context_keys() + ['suffix']))\n",
    "\n",
    "\n",
    "earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "active_context\n",
    "session_ctxt_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c0fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifts the absolute times to delta-relative values, as would be needed to draw on a 'delta_aligned_start_t' axis:\n",
    "delta_relative_t_start, delta_relative_t_delta, delta_relative_t_end = np.array([earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end]) - t_delta\n",
    "# decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline)\n",
    "# any_good_selected_epoch_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(any_good_selected_epoch_times)\n",
    "# df = filter_epochs_dfs_by_annotation_times(curr_active_pipeline, any_good_selected_epoch_times, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, filtered_ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df)\n",
    "# df\n",
    "\n",
    "# collected_outputs_path = self.collected_outputs_path.resolve()\n",
    "\n",
    "collected_outputs_path = collected_outputs_path.resolve()\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_output_csv_paths = directional_decoders_epochs_decode_result.export_csvs(parent_output_path=collected_outputs_path, active_context=active_context, session_name=curr_session_name, curr_session_t_delta=t_delta,\n",
    "                                                                        # user_annotation_selections={'ripple': any_good_selected_epoch_times},\n",
    "                                                                        # valid_epochs_selections={'ripple': filtered_valid_epoch_times},\n",
    "                                                                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c7a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'\\t\\tsuccessfully exported directional_decoders_epochs_decode_result to {collected_outputs_path}!')\n",
    "_output_csv_paths_info_str: str = '\\n'.join([f'{a_name}: \"{file_uri_from_path(a_path)}\"' for a_name, a_path in _output_csv_paths.items()])\n",
    "# print(f'\\t\\t\\tCSV Paths: {_output_csv_paths}\\n')\n",
    "print(f'\\t\\t\\tCSV Paths: {_output_csv_paths_info_str}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e709f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "for a_ripple_df in (directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df, directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df):\n",
    "    if ('time_bin_size' not in a_ripple_df.columns) and (ripple_decoding_time_bin_size is not None):\n",
    "        ## add the column\n",
    "        a_ripple_df['time_bin_size'] = ripple_decoding_time_bin_size\n",
    "        # ripple_simple_pf_pearson_merged_df['time_bin_size'] = ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "    # Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "    a_ripple_df = DecoderDecodedEpochsResult.add_session_df_columns(a_ripple_df, session_name=session_name, time_bin_size=None, curr_session_t_delta=t_delta, time_col='ripple_start_t')\n",
    "    # df = _add_maze_id_to_epochs(df, t_delta)\n",
    "    # df[\"time_bin_size\"] = ripple_decoding_time_bin_size\n",
    "    # df['is_user_annotated_epoch'] = True # if it's filtered here, it's true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a00cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_ripple_df in (ripple_weighted_corr_merged_df, ripple_simple_pf_pearson_merged_df):\n",
    "    if ('time_bin_size' not in a_ripple_df.columns) and (ripple_decoding_time_bin_size is not None):\n",
    "        ## add the column\n",
    "        a_ripple_df['time_bin_size'] = ripple_decoding_time_bin_size\n",
    "        # ripple_simple_pf_pearson_merged_df['time_bin_size'] = ripple_simple_pf_pearson_merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72763c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_simple_pf_pearson_merged_df\n",
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fe34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "# directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict # vector for each decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea151325",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot: directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "\n",
    "ripple_weighted_corr_merged_df = deepcopy(directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df)\n",
    "ripple_weighted_corr_merged_df\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c440a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram_bins = 'auto'\n",
    "histogram_bins: int = 25\n",
    "\n",
    "# ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "new_ripple_fig, new_ripple_fig_context = plotly_pre_post_delta_scatter(data_results_df=ripple_weighted_corr_merged_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                                                                        px_scatter_kwargs=dict(title='Ripple'), histogram_variable_name='P_Short')\n",
    "\n",
    "# new_laps_fig = new_laps_fig.update_layout(fig_size_kwargs, \n",
    "#     xaxis_title=\"X Axis Title\",\n",
    "#     yaxis_title=\"Y Axis Title\",\n",
    "#     legend_title=\"Legend Title\",\n",
    "#     font=dict(\n",
    "#         family=\"Courier New, monospace\",\n",
    "#         size=18,\n",
    "#         color=\"RebeccaPurple\"\n",
    "#     ),\n",
    "# )\n",
    "# Update x-axis labels\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=1)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Delta-aligned Event Time (seconds)\", row=1, col=2)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=3)\n",
    "\n",
    "\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_ripple_fig.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "new_ripple_fig\n",
    "\n",
    "\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "\n",
    "# new_laps_fig_context: IdentifyingContext = new_laps_fig_context.adding_context_if_missing(epoch='withNewKamranExportedReplays', num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "# figure_out_paths = save_plotly(a_fig=new_laps_fig, a_fig_context=new_laps_fig_context)\n",
    "# new_laps_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8cd65e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553f6001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca35d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import CustomTreeFormatters, DocumentationFilePrinter\n",
    "\n",
    "custom_memory_size_value_formatter = (lambda depth_string, curr_key, curr_value, type_string, type_name, is_omitted_from_expansion=False, value_formatting_fn=DocumentationFilePrinter.value_memory_usage_MB: DocumentationFilePrinter._default_rich_text_formatter(depth_string, curr_key, curr_value, type_string, type_name, is_omitted_from_expansion=is_omitted_from_expansion, value_formatting_fn=DocumentationFilePrinter.value_memory_usage_MB))\n",
    "\n",
    "# _default_plain_text_object_size_formatter = lambda DocumentationFilePrinter._default_rich_text_formatter(*args, **kwargs, value_formatting_fn=DocumentationFilePrinter.value_memory_usage_MB)\n",
    "\n",
    "\n",
    "\n",
    "# def _default_plain_text_object_size_formatter(depth_string, curr_key, curr_value, type_string, type_name, is_omitted_from_expansion=False, value_formatting_fn=None):\n",
    "#     \"\"\"       \"\"\"\n",
    "#     memory_size_str_value: str = f\"{print_object_memory_usage(curr_value, enable_print=False):0.3f} MB\"\n",
    "#     # return CustomTreeFormatters.basic_custom_tree_formatter(depth_string=depth_string, curr_key=curr_key, curr_value=memory_size_str_value, type_string=type_string, type_name=type_name, is_omitted_from_expansion=is_omitted_from_expansion)\n",
    "#     prefix = '├── ' if depth_string else ''\n",
    "#     link_char = '│   ' if depth_string else '    '\n",
    "#     depth_string_with_link = depth_string + link_char\n",
    "#     formatted_string = f\"{depth_string_with_link}{prefix}{curr_key}: {type_name}\"\n",
    "#     if is_omitted_from_expansion:\n",
    "#         formatted_string += ' (children omitted)'\n",
    "    \n",
    "#     formatted_string += f\"- {memory_size_str_value}\" \n",
    "#     return formatted_string\n",
    "\n",
    "\n",
    "# print_keys_if_possible('global_computation_results', curr_active_pipeline.global_computation_results, max_depth=2,\n",
    "#                        custom_item_formatter=_default_plain_text_object_size_formatter)\n",
    "\n",
    "# print_keys_if_possible('curr_active_pipeline', curr_active_pipeline, max_depth=2,\n",
    "#                        custom_item_formatter=_default_plain_text_object_size_formatter)\n",
    "\n",
    "print_keys_if_possible('curr_active_pipeline', curr_active_pipeline, max_depth=2,\n",
    "                       custom_item_formatter=custom_memory_size_value_formatter)\n",
    "\n",
    "\n",
    "# global_computation_results: pyphoplacecellanalysis.General.Model.ComputationResults.ComputationResult\t  12728.756100654602MB\n",
    "# │   ├── sess: neuropy.core.session.dataSession.DataSession\t  563.4777412414551MB\n",
    "# │   ├── computation_config: neuropy.utils.dynamic_container.DynamicContainer\t  0.000553131103515625MB\n",
    "# │   ├── computed_data: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\t  12165.277884483337MB\n",
    "# │   ├── accumulated_errors: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\t  0.0002593994140625MB\n",
    "# │   ├── computation_times: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\t  0.00142669677734375MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b0b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import make_class\n",
    "\n",
    "dummy_pipeline_attrs_names_list = ['sess', 'filtered_sessions', 'filtered_contexts', 'computation_results', 'global_computation_results']\n",
    "SimpleCurrActivePipelineComputationDummy = make_class('SimpleCurrActivePipelineComputationDummy', attrs=dummy_pipeline_attrs_names_list, kw_only=True)\n",
    "\n",
    "\n",
    "# Accessed properties: {'global_computation_results', 'sess', 'filtered_sessions', 'computation_results', 'filtered_contexts', 'find_LongShortGlobal_epoch_names'}\n",
    "# Modified properties: set()\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import \n",
    "\n",
    "# a_dummy = SimpleCurrActivePipelineComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.__getstate__()\n",
    "curr_active_pipeline.sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.__getstate__()\n",
    "\n",
    "# _temp_pipeline_dict = get_dict_subset(curr_active_pipeline.__getstate__(), dummy_pipeline_attrs_names_list)\n",
    "_temp_pipeline_dict = get_dict_subset(curr_active_pipeline.stage.__getstate__(), dummy_pipeline_attrs_names_list) | {'sess': deepcopy(curr_active_pipeline.sess)}\n",
    "_temp_pipeline_dict\n",
    "\n",
    "print_keys_if_possible('curr_active_pipeline.stage.__getstate__()', _temp_pipeline_dict, max_depth=2)\n",
    "\n",
    "a_dummy_pipeline: SimpleCurrActivePipelineComputationDummy = SimpleCurrActivePipelineComputationDummy(**_temp_pipeline_dict)\n",
    "a_dummy_pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf39ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a_dummy_pipeline = SimpleCurrActivePipelineComputationDummy(**curr_active_pipeline.__getstate__())\n",
    "a_dummy_pipeline\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
