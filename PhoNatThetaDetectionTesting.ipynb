{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e4f6b1-02ff-407f-a303-1946a2708a0e",
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import sys\n",
    "import traceback # for stack trace formatting\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from benedict import benedict\n",
    "import numpy as np\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "# %gui qt\n",
    "# !env QT_API=\"pyqt5\"\n",
    "%gui qt5\n",
    "# %gui qt6\n",
    "# from PyQt5.Qt import QApplication\n",
    "# # start qt event loop\n",
    "# _instance = QApplication.instance()\n",
    "# if not _instance:\n",
    "#     _instance = QApplication([])\n",
    "# app = _instance\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from benedict import benedict # https://github.com/fabiocaccamo/python-benedict#usage\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import CodeConversion\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible, print_value_overview_only, document_active_variables\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "\n",
    "# from PendingNotebookCode import _perform_batch_plot, _build_batch_plot_kwargs\n",
    "from pyphoplacecellanalysis.General.NonInteractiveWrapper import batch_load_session, batch_extended_computations, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "session_batch_status = {}\n",
    "session_batch_errors = {}\n",
    "enable_saving_to_disk = False\n",
    "\n",
    "global_data_root_parent_path = Path(r'W:\\Data') # Windows Apogee\n",
    "# global_data_root_parent_path = Path(r'/media/MAX/Data') # Diba Lab Workstation Linux\n",
    "# global_data_root_parent_path = Path(r'/Volumes/MoverNew/data') # rMBP\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98d9aad-f22c-4607-8bb7-e315312b325a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40fa1a4-56ac-49fe-aefc-c25669d862d4",
   "metadata": {
    "tags": [
     "load"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_session_names_list: ['2006-6-07_11-26-53', '2006-6-08_14-26-15', '2006-6-09_1-22-43', '2006-6-09_3-23-37', '2006-6-12_15-55-31', '2006-6-13_14-42-6']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-07_11-26-53'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_3-23-37'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-13_14-42-6'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "#     neuropy/data_session_pre_processing_scripts/KDIBA/IIDataMat_Export_ToPython_2022_08_01.m\n",
    "# From pre-computed .mat files:\n",
    "\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "## Animal `gor01`:\n",
    "local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='one') # IdentifyingContext<('kdiba', 'gor01', 'one')>\n",
    "local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # 'gor01', 'one'\n",
    "local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['PhoHelpers', 'Spike3D-Minimal-Test', 'Unused'])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "### Animal `vvp01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "## Build session contexts list:\n",
    "local_session_contexts_list = [local_session_parent_context.adding_context(collision_prefix='sess', session_name=a_name) for a_name in local_session_names_list] # [IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-07_11-26-53')>, ..., IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-13_14-42-6')>]\n",
    "\n",
    "## Initialize `session_batch_status` with the NOT_STARTED status if it doesn't already have a different status\n",
    "for curr_session_basedir in local_session_paths_list:\n",
    "    curr_session_status = session_batch_status.get(curr_session_basedir, None)\n",
    "    if curr_session_status is None:\n",
    "        session_batch_status[curr_session_basedir] = SessionBatchProgress.NOT_STARTED # set to not started if not present\n",
    "        # session_batch_status[curr_session_basedir] = SessionBatchProgress.COMPLETED # set to not started if not present\n",
    "\n",
    "session_batch_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26506af-54f3-43f4-af6f-be88d37e2013",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Single basedir (non-batch) testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe7768e9-3492-4312-abfc-c239adc7229c",
   "metadata": {
    "tags": [
     "load",
     "single_session"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.epochs_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.spikes.mat... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\neuropy\\core\\session\\Formats\\SessionSpecifications.py:140: UserWarning: WARNING: Optional File: W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.dat does not exist. Continuing without it.\n",
      "  warnings.warn(f'WARNING: Optional File: {an_optional_filepath} does not exist. Continuing without it.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Computing linear positions for all active epochs for session... Saving updated position results results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position.npy... 2006-6-07_11-26-53.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.interpolated_spike_positions.npy... 2006-6-07_11-26-53.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.replay_info.mat... done.\n",
      "session.replays loaded successfully!\n",
      "Loading success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\ripple_df.pkl.\n",
      "Loading success: .mua.npy.\n",
      "Loading success: .pbe.npy.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... done.\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1739.1533641185379)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 1739.1533641185379, end: 1932.4200048116618)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1932.4200048116618)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to whitelist, including only 7 out of 15 registered computation functions.\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (52700,)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cv2 must be installed manually. Try to: <pip install opencv-python>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\findpeaks\\stats.py:38\u001b[0m, in \u001b[0;36m_import_cv2\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cv2\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasedir: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(basedir)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# ==================================================================================================================== #\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load Pipeline                                                                                                        #\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# ==================================================================================================================== #\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, force_reload=True, skip_extended_batch_computations=True)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m curr_active_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_load_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglobal_data_root_parent_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactive_data_mode_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasedir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaving_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPipelineSavingScheme\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSKIP_SAVING\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_extended_batch_computations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_reload=True, skip_extended_batch_computations=True) # temp no-save\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m## SAVE AFTERWARDS!\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_reload=False, active_pickle_filename='20221214200324-loadedSessPickle.pkl', skip_extended_batch_computations=True)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_reload=False, active_pickle_filename='loadedSessPickle - full-good.pkl', skip_extended_batch_computations=True)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\pyphoplacecellanalysis\\General\\NonInteractiveWrapper.py:320\u001b[0m, in \u001b[0;36mbatch_load_session\u001b[1;34m(global_data_root_parent_path, active_data_mode_name, basedir, force_reload, saving_mode, fail_on_exception, skip_extended_batch_computations, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m     computation_functions_name_blacklist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;66;03m# # Blacklist Mode:\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# computation_functions_name_whitelist=None\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# computation_functions_name_blacklist=['_perform_spike_burst_detection_computation','_perform_recursive_latent_placefield_decoding']\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m## TODO 2023-01-15 - perform_computations for all configs!!\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m \u001b[43mcurr_active_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_computations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactive_session_computation_configs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation_functions_name_whitelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomputation_functions_name_whitelist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation_functions_name_blacklist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomputation_functions_name_blacklist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfail_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfail_on_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug_print\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, overwrite_extant_results=False  ], fail_on_exception=True, debug_print=False)\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_extended_batch_computations:\n\u001b[0;32m    323\u001b[0m     batch_extended_computations(curr_active_pipeline, include_global_functions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, fail_on_exception\u001b[38;5;241m=\u001b[39mfail_on_exception, progress_print\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, debug_print\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:767\u001b[0m, in \u001b[0;36mPipelineWithComputedPipelineStageMixin.perform_computations\u001b[1;34m(self, active_computation_params, enabled_filter_names, overwrite_extant_results, computation_functions_name_whitelist, computation_functions_name_blacklist, fail_on_exception, debug_print)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcan_compute), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent self.stage must already be a ComputedPipelineStage. Call self.filter_sessions with filter configs to reach this step.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    765\u001b[0m progress_logger_callback\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(x))\n\u001b[1;32m--> 767\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_action_for_all_contexts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvaluationActions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEVALUATE_COMPUTATIONS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menabled_filter_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled_filter_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactive_computation_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactive_computation_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_extant_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_extant_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomputation_functions_name_whitelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomputation_functions_name_whitelist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation_functions_name_blacklist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomputation_functions_name_blacklist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfail_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfail_on_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_logger_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_logger_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug_print\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;66;03m# self.stage.evaluate_computations_for_single_params(active_computation_params, enabled_filter_names=enabled_filter_names, overwrite_extant_results=overwrite_extant_results,\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;66;03m#     computation_functions_name_whitelist=computation_functions_name_whitelist, computation_functions_name_blacklist=computation_functions_name_blacklist, fail_on_exception=fail_on_exception, progress_logger_callback=progress_logger_callback, debug_print=debug_print)\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \n\u001b[0;32m    772\u001b[0m \u001b[38;5;66;03m# Global MultiContext computations will be done here:\u001b[39;00m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m progress_logger_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:379\u001b[0m, in \u001b[0;36mComputedPipelineStage.perform_action_for_all_contexts\u001b[1;34m(self, action, enabled_filter_names, active_computation_params, overwrite_extant_results, computation_functions_name_whitelist, computation_functions_name_blacklist, fail_on_exception, progress_logger_callback, are_global, debug_print)\u001b[0m\n\u001b[0;32m    375\u001b[0m         skip_computations_for_this_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_computations_for_this_result:\n\u001b[0;32m    378\u001b[0m         \u001b[38;5;66;03m# call to perform any registered computations:\u001b[39;00m\n\u001b[1;32m--> 379\u001b[0m         active_computation_results[a_select_config_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_registered_computations_single_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactive_computation_results\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma_select_config_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcomputation_functions_name_whitelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomputation_functions_name_whitelist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation_functions_name_blacklist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomputation_functions_name_blacklist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfail_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfail_on_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_logger_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_logger_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mare_global\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mare_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug_print\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m action\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m EvaluationActions\u001b[38;5;241m.\u001b[39mRUN_SPECIFIC\u001b[38;5;241m.\u001b[39mname:\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerforming run_specific_computations_single_context on filtered_session with filter named \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma_select_config_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:233\u001b[0m, in \u001b[0;36mComputedPipelineStage.perform_registered_computations_single_context\u001b[1;34m(self, previous_computation_result, computation_functions_name_whitelist, computation_functions_name_blacklist, fail_on_exception, progress_logger_callback, are_global, debug_print)\u001b[0m\n\u001b[0;32m    230\u001b[0m         active_computation_functions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregistered_computation_functions\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# Perform the computations:\u001b[39;00m\n\u001b[1;32m--> 233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mComputedPipelineStage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_computation_functions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactive_computation_functions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_computation_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprevious_computation_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfail_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfail_on_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_logger_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_logger_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mare_global\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mare_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug_print\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:533\u001b[0m, in \u001b[0;36mComputedPipelineStage._execute_computation_functions\u001b[1;34m(active_computation_functions, previous_computation_result, computation_kwargs_list, fail_on_exception, progress_logger_callback, are_global, debug_print)\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m progress_logger_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m         progress_logger_callback(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExecuting [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_num_funcs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 533\u001b[0m     previous_computation_result \u001b[38;5;241m=\u001b[39m f(previous_computation_result, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomputation_kwargs_list[i])\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# Since there's no error handling, gettin ghere means that there were no accumulated errors\u001b[39;00m\n\u001b[0;32m    536\u001b[0m accumulated_errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:335\u001b[0m, in \u001b[0;36mPlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_computation\u001b[1;34m(computation_result, debug_print, peak_score_inclusion_percent_threshold)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# ==================================================================================================================== #\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# BEGIN MAIN FUNCTION BODY                                                                                             #\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# ==================================================================================================================== #\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;66;03m# active_pf_1D = computation_result.computed_data['pf1D']\u001b[39;00m\n\u001b[0;32m    334\u001b[0m active_pf_2D \u001b[38;5;241m=\u001b[39m computation_result\u001b[38;5;241m.\u001b[39mcomputed_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpf2D\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 335\u001b[0m fp_mask_list, mask_results_df_list, fp_topo_list, topo_results_df_list, topo_persistence_df_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[ratemap_find_placefields(a_tuning_curve\u001b[38;5;241m.\u001b[39mcopy(), debug_print\u001b[38;5;241m=\u001b[39mdebug_print) \u001b[38;5;28;01mfor\u001b[39;00m a_tuning_curve \u001b[38;5;129;01min\u001b[39;00m active_pf_2D\u001b[38;5;241m.\u001b[39mratemap\u001b[38;5;241m.\u001b[39mpdf_normalized_tuning_curves]))\n\u001b[0;32m    336\u001b[0m topo_results_peak_xy_pos_list \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mvstack((active_pf_2D\u001b[38;5;241m.\u001b[39mxbin[curr_topo_result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxbin_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()], active_pf_2D\u001b[38;5;241m.\u001b[39mybin[curr_topo_result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mybin_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()])) \u001b[38;5;28;01mfor\u001b[39;00m curr_topo_result_df \u001b[38;5;129;01min\u001b[39;00m topo_results_df_list]\n\u001b[0;32m    337\u001b[0m peaks_are_included_list, filtered_df_list, filtered_peak_xy_points_pos_list \u001b[38;5;241m=\u001b[39m _filter_found_peaks_by_exclusion_threshold(topo_results_df_list, topo_results_peak_xy_pos_list, peak_score_inclusion_percent_threshold\u001b[38;5;241m=\u001b[39mpeak_score_inclusion_percent_threshold)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:335\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# ==================================================================================================================== #\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# BEGIN MAIN FUNCTION BODY                                                                                             #\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# ==================================================================================================================== #\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;66;03m# active_pf_1D = computation_result.computed_data['pf1D']\u001b[39;00m\n\u001b[0;32m    334\u001b[0m active_pf_2D \u001b[38;5;241m=\u001b[39m computation_result\u001b[38;5;241m.\u001b[39mcomputed_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpf2D\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 335\u001b[0m fp_mask_list, mask_results_df_list, fp_topo_list, topo_results_df_list, topo_persistence_df_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[\u001b[43mratemap_find_placefields\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_tuning_curve\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug_print\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a_tuning_curve \u001b[38;5;129;01min\u001b[39;00m active_pf_2D\u001b[38;5;241m.\u001b[39mratemap\u001b[38;5;241m.\u001b[39mpdf_normalized_tuning_curves]))\n\u001b[0;32m    336\u001b[0m topo_results_peak_xy_pos_list \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mvstack((active_pf_2D\u001b[38;5;241m.\u001b[39mxbin[curr_topo_result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxbin_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()], active_pf_2D\u001b[38;5;241m.\u001b[39mybin[curr_topo_result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mybin_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()])) \u001b[38;5;28;01mfor\u001b[39;00m curr_topo_result_df \u001b[38;5;129;01min\u001b[39;00m topo_results_df_list]\n\u001b[0;32m    337\u001b[0m peaks_are_included_list, filtered_df_list, filtered_peak_xy_points_pos_list \u001b[38;5;241m=\u001b[39m _filter_found_peaks_by_exclusion_threshold(topo_results_df_list, topo_results_peak_xy_pos_list, peak_score_inclusion_percent_threshold\u001b[38;5;241m=\u001b[39mpeak_score_inclusion_percent_threshold)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:303\u001b[0m, in \u001b[0;36mPlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_computation.<locals>.ratemap_find_placefields\u001b[1;34m(ratemap, debug_print)\u001b[0m\n\u001b[0;32m    299\u001b[0m     out_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (out_df, results_topo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpersistence\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 303\u001b[0m fp_mask, results_mask, fp_topo, results_topo \u001b[38;5;241m=\u001b[39m \u001b[43m_ratemap_compute_peaks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratemap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug_print\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug_print:\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults_topo.keys(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(results_topo\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\PlacefieldDensityAnalysisComputationFunctions.py:247\u001b[0m, in \u001b[0;36mPlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_computation.<locals>.ratemap_find_placefields.<locals>._ratemap_compute_peaks\u001b[1;34m(X, debug_print)\u001b[0m\n\u001b[0;32m    245\u001b[0m fp_mask \u001b[38;5;241m=\u001b[39m findpeaks(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39mverboosity_level)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Fit\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m results_mask \u001b[38;5;241m=\u001b[39m \u001b[43mfp_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# Initialize\u001b[39;00m\n\u001b[0;32m    249\u001b[0m fp_topo \u001b[38;5;241m=\u001b[39m findpeaks(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopology\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39mverboosity_level)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\findpeaks\\findpeaks.py:186\u001b[0m, in \u001b[0;36mfindpeaks.fit\u001b[1;34m(self, X, x)\u001b[0m\n\u001b[0;32m    182\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;66;03m# 2d-array (image)\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpeaks2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;66;03m# 1d-array (vector)\u001b[39;00m\n\u001b[0;32m    189\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeaks1d(X, x\u001b[38;5;241m=\u001b[39mx, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\findpeaks\\findpeaks.py:471\u001b[0m, in \u001b[0;36mfindpeaks.peaks2d\u001b[1;34m(self, X, method)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtogray) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m3\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopology\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[findpeaks] >Error: Topology method requires 2d-array. Your input is 3d. Hint: set togray=True.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# Preprocessing the image\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m Xproc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshowfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# Compute peaks based on method\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopology\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;66;03m# Compute persistence based on topology method\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\findpeaks\\findpeaks.py:580\u001b[0m, in \u001b[0;36mfindpeaks.preprocessing\u001b[1;34m(self, X, showfig)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;66;03m# Convert to gray image\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtogray:\n\u001b[1;32m--> 580\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtogray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m showfig:\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;66;03m# plt.figure(figsize=self.figsize)\u001b[39;00m\n\u001b[0;32m    583\u001b[0m         ax[iax]\u001b[38;5;241m.\u001b[39mimshow(X, cmap\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray_r\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtogray \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\findpeaks\\stats.py:100\u001b[0m, in \u001b[0;36mtogray\u001b[1;34m(X, verbose)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert color to grey-image.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03mDescription\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m \n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Import cv2\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m cv2 \u001b[38;5;241m=\u001b[39m \u001b[43m_import_cv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[findpeaks] >Conversion to gray image.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-pZq3eobA-py3.9\\lib\\site-packages\\findpeaks\\stats.py:41\u001b[0m, in \u001b[0;36m_import_cv2\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cv2\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcv2 must be installed manually. Try to: <pip install opencv-python>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cv2 must be installed manually. Try to: <pip install opencv-python>"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "basedir = local_session_paths_list[0] # NOT 3\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, force_reload=True, skip_extended_batch_computations=True)\n",
    "curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_reload=True, skip_extended_batch_computations=True, debug_print=False)\n",
    "# curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_reload=True, skip_extended_batch_computations=True) # temp no-save\n",
    "## SAVE AFTERWARDS!\n",
    "\n",
    "# curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_reload=False, active_pickle_filename='20221214200324-loadedSessPickle.pkl', skip_extended_batch_computations=True)\n",
    "# curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_reload=False, active_pickle_filename='loadedSessPickle - full-good.pkl', skip_extended_batch_computations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d446496b-c286-4a76-b888-94be2f92aee3",
   "metadata": {
    "incorrectly_encoded_metadata": "jp-MarkdownHeadingCollapsed=true tags=[] jp-MarkdownHeadingCollapsed=true",
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "# Future: theta-dependent placefields: build separate placefields for each phase of theta (binned in theta). There should be one set (where the animal is representing the present) that nearly perfectly predicts the animal's location.\n",
    "    # the rest of the variability \n",
    "\n",
    "    1. Basic Hilbert transform\n",
    "    2. But Theta wave-shape (sawtooth) at higher running speeds.\n",
    "        - do peak-to-trough and trough-to-peak separate\n",
    "        ** Nat will send me something\n",
    "        \n",
    "- remember Eloy's theta-dependent placefields. I'm ashamed that I fucked up with Eloy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47ff852-0f53-4eac-89d7-3a890d7fd743",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36565a6-97ac-4ed7-be87-87d972fa3057",
   "metadata": {},
   "source": [
    "https://github.com/diba-lab/ephys/blob/master/Analysis/python/LFP/scripts/theta_phase_stim_verify.py\n",
    "Nat's code for detecting the sawtooth theta is here (lines 271-393ish): https://github.com/diba-lab/ephys/blob/master/Analysis/python/LFP/scripts/theta_phase_stim_verify.py\n",
    "\n",
    "It's all based on this paper: https://www.jneurosci.org/content/32/2/423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7b015-d93e-488c-8575-4525546a93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scratchpad for opto\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import Analysis.python.LFP.preprocess_data as pd\n",
    "\n",
    "import scipy.signal as signal\n",
    "import pickle\n",
    "import os\n",
    "# import Analysis.python.LFP.helpers as helpers\n",
    "\n",
    "## LFP analysis functions from https://github.com/diba-lab/ephys/blob/master/Analysis/python/LFP/lfp_analysis.py\n",
    "\n",
    "# instead of `import Analysis.python.LFP.lfp_analysis as lfp`\n",
    "class lfp(object):\n",
    "    ## Create Butterworth filter - copied from scipy-cookbook webpage\n",
    "    @staticmethod\n",
    "    def butter_bandpass(lowcut, highcut, fs, order=2):\n",
    "        \"\"\"\n",
    "        Simplify inputs for creating a Butterworth filter. copied from scipy-cookbook webpage.\n",
    "        :param lowcut: Hz\n",
    "        :param highcut: Hz\n",
    "        :param fs: Sampling rate in Hz\n",
    "        :param order: (optional) 2 = default\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = signal.butter(order, [low, high], btype='band')\n",
    "\n",
    "        return b, a\n",
    "\n",
    "\n",
    "    ## filter data through butterworth filter\n",
    "    @staticmethod\n",
    "    def butter_bandpass_filter(data, lowcut, highcut, fs, type='filtfilt', order=2):\n",
    "        \"\"\"\n",
    "        Filter data through butterworth bandpass filter. Copied from scipy-cookbook webpage.\n",
    "        :param data: array of data sampled at fs\n",
    "        :param lowcut: 4\n",
    "        :param highcut: 10\n",
    "        :param type: 'filtfilt' (default) filters both ways, 'lfilt' filters forward only (and likely induces a phase offset).\n",
    "        :param fs: 30000\n",
    "        :param order: (optional) default = 2 to match Sieglie et al., eLife (2014)\n",
    "        :return: filt_data: filtered data\n",
    "        \"\"\"\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        if type == 'lfilt':\n",
    "            filt_data = signal.lfilter(b, a, data)\n",
    "        elif type == 'filtfilt':\n",
    "            filt_data = signal.filtfilt(b, a, data)\n",
    "\n",
    "        return filt_data\n",
    "\n",
    "\n",
    "    ## Peak-trough detection via Belluscio et al. (2012) J. Neuro\n",
    "    @staticmethod\n",
    "    def get_local_extrema(trace, type='max'):\n",
    "        \"\"\" Get local extrema, assuming it occurs near the middle of the trace. spits out an np.nan if there a relative min\n",
    "        or max occurs at the edge.\n",
    "        :param trace: lfp trace\n",
    "        :param type: 'max' (default) or 'min'\n",
    "        :return: index in trace where max/min is located. np.nan if there is a relative minima/maxima at edge of trace.\n",
    "        \"\"\"\n",
    "        if type == 'max':\n",
    "            temp = signal.argrelmax(trace, order=int(len(trace)/2))[0]\n",
    "        elif type == 'min':\n",
    "            temp = signal.argrelmin(trace, order=int(len(trace)/2))[0]\n",
    "\n",
    "        if temp.size == 1:\n",
    "            ind_rel_extreme = temp[0]\n",
    "        else:\n",
    "            ind_rel_extreme = np.nan\n",
    "\n",
    "        return ind_rel_extreme\n",
    "\n",
    "    \n",
    "from neuropy.analyses import oscillations\n",
    "## Plot trace in a nice working window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b575b75-f436-47e7-a1aa-80c5c826d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c484a14-bdd1-4519-803c-c9b34664c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfpFile = curr_active_pipeline.sess.eegfile # neuropy.io.binarysignalio.BinarysignalIO\n",
    "traces = lfpFile.get_signal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa71c73-96ee-4923-bfd0-7889cca3f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_epochs = oscillations.detect_ripple_epochs(traces, curr_active_pipeline.sess.probegroup)\n",
    "ripple_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc596523-4b4d-496a-a22b-ad2200a7bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = lfpFile.get_signal(channel_indx=19)\n",
    "traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e47941-6e39-4deb-a2b5-405ae7d5a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfpFile.n_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e62af39-2df5-482f-80a7-712ac145137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfpFile.n_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02fcbf-2848-4a26-b143-eeabc1500628",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cc6215-452d-4e85-ad47-44b43d1d5ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_plot = 19  # channel you triggered off of\n",
    "artifact_chan = 13  # this channel should have good stimulation artifact on it for reference...\n",
    "\n",
    "trace = traces_ds[plot_bool, chan_plot]\n",
    "trace_lfilt = lfp.butter_bandpass_filter(trace, lowcut, highcut, SRlfp, order=order, type='lfilt')\n",
    "trace_filtfilt = lfp.butter_bandpass_filter(trace, lowcut, highcut, SRlfp, order=order, type='filtfilt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e10681-746a-4440-9995-8257b51b8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Peak-trough method (Belluscio et al. 2012 J Neuro) - fold into lfp_analysis.peak_trough_detect eventually\n",
    "# from Nat's https://github.com/diba-lab/ephys/blob/master/Analysis/python/LFP/scripts/theta_phase_stim_verify.py\n",
    "\n",
    "## Needs: trace, SRlfp, order\n",
    "order = 2\n",
    "\n",
    "lowcut_bell = 1  # Hz\n",
    "highcut_bell = 80  # Hz\n",
    "peak_trough_offset_sec = 0.07  # seconds to look for trough of wide-filtered trace next to 4-10Hz filtered trace\n",
    "\n",
    "wide_filt = lfp.butter_bandpass_filter(trace, lowcut_bell, highcut_bell, SRlfp, order=order)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, sharex=True, sharey=True)\n",
    "fig.set_size_inches([26, 3])\n",
    "hraw = ax.plot(time_plot, trace)\n",
    "ax.plot(time_plot, wide_filt, 'm')\n",
    "ax.plot(time_plot, trace_lfilt, 'k--')\n",
    "ax.set_xlim([start_time*60, start_time*60 + time_span])\n",
    "ax.set_ylim([-v_range, v_range])\n",
    "ax.set_xlabel(['Time (s)'])\n",
    "ax.set_ylabel('uV')\n",
    "\n",
    "offset_frames = np.round(peak_trough_offset_sec*SRlfp)\n",
    "\n",
    "# First detect peak and trough off narrowband filtered signal - do hilbert transform\n",
    "# trough = -pi->pi, peak = 0 (- -> +)\n",
    "trace_analytic = signal.hilbert(trace_lfilt)  # get real and imaginary parts of signal\n",
    "trig_trace_phase = np.angle(trace_analytic)\n",
    "# ax.plot(time_plot, trig_trace_phase*v_range/8, 'r-')\n",
    "peak_bool = np.bitwise_and(trig_trace_phase[0:-1] < 0, trig_trace_phase[1:] >= 0)\n",
    "peak_bool = np.append(peak_bool, False)\n",
    "trough_bool = np.bitwise_and(trig_trace_phase[0:-1] > 0, trig_trace_phase[1:] <= 0)\n",
    "trough_bool = np.append(trough_bool, False)\n",
    "\n",
    "# Indices to peak and trough of narrowband trace\n",
    "peak_inds = np.where(peak_bool)[0]\n",
    "trough_inds = np.where(trough_bool)[0]\n",
    "\n",
    "# Check that above code works...\n",
    "# ax.plot(time_plot[peak_bool], trace_lfilt[peak_bool], 'r*')\n",
    "# ax.plot(time_plot[trough_bool], trace_lfilt[trough_bool], 'g*')\n",
    "\n",
    "##  Plot times between peak and trough - seems likes looking 0.07 seconds to either side should be ok...\n",
    "fig2, ax2 = plt.subplots(1, 2)\n",
    "ax2[0].hist(np.diff(np.where(trough_bool))[0]/SRlfp)\n",
    "ax2[0].set_xlabel('Trough-to-trough times (s)')\n",
    "ax2[1].hist(np.diff(np.where(peak_bool))[0]/SRlfp)\n",
    "ax2[1].set_xlabel('Peak-to-peak times (s)')\n",
    "\n",
    "## now step through and find closest peak/trough in the wide-filtered trace when compared to the narrowband filtered trace.\n",
    "# THIS IS ALL COMMENTED NOW SO THAT YOU DONT ACCIDENTALLY OVERWRITE EXISTING VALUES - NEED TO IMPLEMENT DOWNSAMPLING FIRST!!!\n",
    "wide_peak_inds = []\n",
    "wide_trough_inds = []\n",
    "\n",
    "# Step through and look for each trough in the WIDE filtered signal between two peaks in the NARROW filtered signal\n",
    "# how fast is this compared to just running it on all the trace and looking for closest inds? Bet it depends on if I\n",
    "# downsample first...\n",
    "\n",
    "n = 0\n",
    "for idp, idp1 in zip(peak_inds[0:-1], peak_inds[1:]):\n",
    "    wide_trough_inds.append(lfp.get_local_extrema(wide_filt[idp:idp1], type='min') + idp)\n",
    "    n = n + 1\n",
    "    if int(n/100) == n/100:\n",
    "        print(n)\n",
    "\n",
    "n = 0\n",
    "# Ditto to above but for peaks\n",
    "for idt, idt1 in zip(trough_inds[0:-1], trough_inds[1:]):\n",
    "    wide_peak_inds.append(lfp.get_local_extrema(wide_filt[idt:idt1], type='max') + idt)\n",
    "    n = n + 1\n",
    "    if int(n/100) == n/100:\n",
    "        print(n)\n",
    "\n",
    "## looks decent except when there is crappy theta. Filter out these epochs? Put on speed threshold?\n",
    "wide_peak_inds_good = [idp for idp in wide_peak_inds if not np.isnan(idp)]\n",
    "wide_trough_inds_good = [idt for idt in wide_trough_inds if not np.isnan(idt)]\n",
    "\n",
    "ax.plot(time_plot[wide_peak_inds_good], wide_filt[wide_peak_inds_good], 'ro')\n",
    "ax.plot(time_plot[wide_trough_inds_good], wide_filt[wide_trough_inds_good], 'go')\n",
    "\n",
    "## Get rise and falling times of theta - trough = -pi/+pi, peak = 0\n",
    "\n",
    "# if peak times generally lead trough times, chop off first peak value\n",
    "if np.nanmean(np.array(wide_peak_inds) - np.array(wide_trough_inds)) < 0:\n",
    "    peak_inds_use = wide_peak_inds[1:]\n",
    "    trough_inds_use = wide_trough_inds[0:-1]\n",
    "    next_trough_inds = wide_trough_inds[1:]\n",
    "else:\n",
    "    peak_inds_use = wide_peak_inds\n",
    "    trough_inds_use = wide_trough_inds\n",
    "    next_trough_inds = wide_trough_inds[1:]\n",
    "\n",
    "\n",
    "wave_phase_inds = []\n",
    "wave_phases = []\n",
    "for idt, idp, idt1 in zip(trough_inds_use, peak_inds_use, next_trough_inds):\n",
    "    if not np.any(np.isnan([idt, idp, idt1])) and idt < idp < idt1:  # only run below if you have reliable peak/trough info\n",
    "        trace_snippet = wide_filt[idt:idt1]  # grab a snippet of the trace to use\n",
    "        if np.all(trace_snippet <= 0) or np.all(trace_snippet >= 0) or trace_snippet[0] > 0 or trace_snippet[-1] > 0\\\n",
    "                or wide_filt[idp] < 0:  # Make sure trace is not all above or below zero and that peak/troughs are above/below zero\n",
    "            wave_phase_inds.extend([np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "        else:\n",
    "            rise_zero = np.max(np.where(np.bitwise_and(trace_snippet <= 0, np.arange(idt, idt1) < idp))[0])\n",
    "            fall_zero = np.min(np.where(np.bitwise_and(trace_snippet <= 0, np.arange(idt, idt1) > idp))[0])\n",
    "            wave_phase_inds.extend([idt, idt + rise_zero, idp, idt + fall_zero, idt1-1])\n",
    "    else:\n",
    "        wave_phase_inds.extend([np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "    wave_phases.extend([-np.pi, -np.pi/2, 0, np.pi/2, np.pi])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e10e5a-5d95-4a95-bed7-fe99b179a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot\n",
    "wave_phase_inds_good = [idph for idph in wave_phase_inds if not np.isnan(idph)]\n",
    "wave_phases_good = [ph for ph, idph in zip(wave_phases, wave_phase_inds) if not np.isnan(idph)]\n",
    "ax.plot(time_plot[wave_phase_inds_good], np.asarray(wave_phases_good)*v_range/8, 'r-')\n",
    "\n",
    "\n",
    "## histogram of rise times vs fall times overlaid to prove I'm doing things correctly\n",
    "fig35, ax35 = plt.subplots(1, 2)\n",
    "fig35.set_size_inches([13.5, 4.8])\n",
    "rise_times = (np.array(peak_inds_use) - np.array(trough_inds_use))/SRlfp\n",
    "fall_times = (np.array(next_trough_inds) - np.array(peak_inds_use))/SRlfp\n",
    "ax35[0].hist(rise_times, bins=20, range=(-0.15, 0.3))\n",
    "ax35[0].set_title('Peak-Trough Method')\n",
    "ax35[0].set_xlabel('Rising Phase Times (s)')\n",
    "ax35[0].text(0.15, 1000, 'mean = ' + '{:.3f}'.format(np.nanmean(rise_times)) + ' sec')\n",
    "ax35[1].hist(fall_times, bins=20, range=(-0.15, 0.3))\n",
    "ax35[1].set_title('Peak-Trough Method')\n",
    "ax35[1].set_xlabel('Falling Phase Times (s)')\n",
    "ax35[1].text(0.15, 1000, 'mean = ' + '{:.3f}'.format(np.nanmean(fall_times)) + ' sec')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike3d-poetry",
   "language": "python",
   "name": "spike3d-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
