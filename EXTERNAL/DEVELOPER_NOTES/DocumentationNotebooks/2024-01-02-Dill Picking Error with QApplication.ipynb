{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"2024-01-02-Dill Picking Error with QApplication.ipynb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem: QApplication cannot be pickled error occurs when trying to pickle pipeline after adding RankOrder global computation results despite not ever being used.\n",
    "\n",
    "# Solution: Unsolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation: Sometimes specific result can be successfully picked while entire pipeline cannot:\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import save_rank_order_results, SaveStringGenerator\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData\n",
    "\n",
    "save_rank_order_results(curr_active_pipeline, day_date=f\"{DAY_DATE_TO_USE}_322pm\") # \"2024-01-02_301pm\" \"2024-01-02_322pm\" 322pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-01-02 - Fails SOMETIMES, even when called immediately after the above save command which worked:\n",
    "curr_active_pipeline.save_global_computation_results()\n",
    "\n",
    "# Clearing and reloading the notebook, skipping these computations, and then re-applying them to the pipeline does allow resaving with `curr_active_pipeline.save_global_computation_results()` for some reason.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "def diagnose_pickling_issues(object_to_pickle):\n",
    "   \"\"\"Intellegently diagnoses which property on an object is causing pickling via Dill to fail.\"\"\"\n",
    "\n",
    "   try:\n",
    "       # Attempt to pickle the object directly\n",
    "       pickle.dumps(object_to_pickle)\n",
    "   except pickle.PicklingError as e:\n",
    "       # If pickling fails, initiate a diagnostic process\n",
    "       print(f\"Pickling error encountered: {e}\")\n",
    "\n",
    "       # Gather information about the object's attributes\n",
    "       object_attributes = [attr for attr in dir(object_to_pickle) if not attr.startswith(\"__\")]\n",
    "\n",
    "       # Isolate problematic attributes through iterative testing\n",
    "       problematic_attribute = None\n",
    "       for attribute in object_attributes:\n",
    "           try:\n",
    "               pickle.dumps(getattr(object_to_pickle, attribute))\n",
    "           except pickle.PicklingError:\n",
    "               problematic_attribute = attribute\n",
    "               break\n",
    "\n",
    "       # Provide informative output\n",
    "       if problematic_attribute:\n",
    "           print(f\"Identified problematic attribute: {problematic_attribute}\")\n",
    "           print(\"Potential causes:\")\n",
    "           print(\"- Attribute contains unpicklable data types (e.g., lambda functions, file objects).\")\n",
    "           print(\"- Attribute refers to external resources (e.g., database connections).\")\n",
    "           print(\"- Attribute has circular references within the object's structure.\")\n",
    "       else:\n",
    "           print(\"Unable to isolate the specific attribute causing the pickling error.\")\n",
    "           print(\"Consider:\")\n",
    "           print(\"- Examining the object's structure and dependencies for potential conflicts.\")\n",
    "           print(\"- Providing a minimal reproducible example for further analysis.\")\n",
    "\n",
    "   else:\n",
    "       # If pickling succeeds, indicate no issues found\n",
    "       print(\"No pickling issues detected.\")\n",
    "\n",
    "\n",
    "diagnose_pickling_issues(curr_active_pipeline.global_computation_results.computed_data['RankOrder'])\n",
    "\n",
    "# make a copy of an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_order_output_path = Path(r'W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\2023-12-22_807pm-minimum_inclusion_fr-5-included_qclu_values-[1, 2]RankOrder.pkl').resolve()\n",
    "\n",
    "\n",
    "from pyphocorehelpers.Filesystem.pickling_helpers import custom_dump, custom_dumps\n",
    "import dill.detect\n",
    "dill.detect.trace(True)\n",
    "\n",
    "# dill.detect.badobjects(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].__dict__)\n",
    "\n",
    "test_obj = curr_active_pipeline.global_computation_results.computed_data['RankOrder'] # pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations.RankOrderComputationsContainer\n",
    "dill.detect.badtypes(test_obj)\n",
    "\n",
    "# dill.detect.errors(test_obj)\n",
    "\n",
    "# with dill.detect.trace(True):\n",
    "# saveData(rank_order_output_path, (curr_active_pipeline.global_computation_results.computed_data['RankOrder'].__dict__,))\n",
    "# custom_dumps(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].__dict__)\n",
    "#  with open(pkl_path, file_mode) as dbfile: \n",
    "# \t# source, destination\n",
    "# \t# pickle.dump(db, dbfile)\n",
    "# \tcustom_dump(db, dbfile) # ModuleExcludesPickler\n",
    "# \tdbfile.close()\n",
    "\t\n",
    "# # dumps(squared)\n",
    "# custom_dump(db, dbfile) # ModuleExcludesPickler\n",
    "# saveData(rank_order_output_path, (curr_active_pipeline.global_computation_results.computed_data['RankOrder'].__dict__,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "\t\"name\": \"TypeError\",\n",
    "\t\"message\": \"<lambda>() missing 4 required positional arguments: 'short_stats_z_scorer', 'long_short_z_diff', 'long_short_naive_z_diff', and 'is_forward_replay'\",\n",
    "\t\"stack\": \"---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "c:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\ReviewOfWork_2024-01-02.ipynb Cell 88 line 1\n",
    "----> <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2024-01-02.ipynb#Z2361sZmlsZQ%3D%3D?line=0'>1</a> diagnose_pickling_issues(rank_order_obj.to_dict())\n",
    "\n",
    "File ~\\\\repos\\\\Spike3DWorkEnv\\\\pyPhoPlaceCellAnalysis\\\\src\\\\pyphoplacecellanalysis\\\\General\\\\Pipeline\\\\Stages\\\\ComputationFunctions\\\\MultiContextComputationFunctions\\\\RankOrderComputations.py:685, in to_dict(self)\n",
    "    683 epoch_identifiers = significant_ripple_epochs._df.label.astype({'label': RankOrderAnalyses._label_column_type}).values #.labels\n",
    "    684 x_values = significant_ripple_epochs.midtimes\n",
    "--> 685 x_axis_name_suffix = 'Mid-time (Sec)'\n",
    "    687 significant_ripple_epochs_df = significant_ripple_epochs.to_dataframe()\n",
    "    688 significant_ripple_epochs_df\n",
    "\n",
    "File c:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\.venv\\\\lib\\\\site-packages\\\\attr\\\\_next_gen.py:208, in asdict(inst, recurse, filter, value_serializer)\n",
    "    201 def asdict(inst, *, recurse=True, filter=None, value_serializer=None):\n",
    "    202     \\\"\\\"\\\"\n",
    "    203     Same as `attr.asdict`, except that collections types are always retained\n",
    "    204     and dict is always used as *dict_factory*.\n",
    "    205 \n",
    "    206     .. versionadded:: 21.3.0\n",
    "    207     \\\"\\\"\\\"\n",
    "--> 208     return _asdict(\n",
    "    209         inst=inst,\n",
    "    210         recurse=recurse,\n",
    "    211         filter=filter,\n",
    "    212         value_serializer=value_serializer,\n",
    "    213         retain_collection_types=True,\n",
    "    214     )\n",
    "\n",
    "File c:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\.venv\\\\lib\\\\site-packages\\\\attr\\\\_funcs.py:64, in asdict(inst, recurse, filter, dict_factory, retain_collection_types, value_serializer)\n",
    "     62 if recurse is True:\n",
    "     63     if has(v.__class__):\n",
    "---> 64         rv[a.name] = asdict(\n",
    "     65             v,\n",
    "     66             recurse=True,\n",
    "     67             filter=filter,\n",
    "     68             dict_factory=dict_factory,\n",
    "     69             retain_collection_types=retain_collection_types,\n",
    "     70             value_serializer=value_serializer,\n",
    "     71         )\n",
    "     72     elif isinstance(v, (tuple, list, set, frozenset)):\n",
    "     73         cf = v.__class__ if retain_collection_types is True else list\n",
    "\n",
    "File c:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\.venv\\\\lib\\\\site-packages\\\\attr\\\\_funcs.py:89, in asdict(inst, recurse, filter, dict_factory, retain_collection_types, value_serializer)\n",
    "     87 elif isinstance(v, dict):\n",
    "     88     df = dict_factory\n",
    "---> 89     rv[a.name] = df(\n",
    "     90         (\n",
    "     91             _asdict_anything(\n",
    "     92                 kk,\n",
    "     93                 is_key=True,\n",
    "     94                 filter=filter,\n",
    "     95                 dict_factory=df,\n",
    "     96                 retain_collection_types=retain_collection_types,\n",
    "     97                 value_serializer=value_serializer,\n",
    "     98             ),\n",
    "     99             _asdict_anything(\n",
    "    100                 vv,\n",
    "    101                 is_key=False,\n",
    "    102                 filter=filter,\n",
    "    103                 dict_factory=df,\n",
    "    104                 retain_collection_types=retain_collection_types,\n",
    "    105                 value_serializer=value_serializer,\n",
    "    106             ),\n",
    "    107         )\n",
    "    108         for kk, vv in v.items()\n",
    "    109     )\n",
    "    110 else:\n",
    "    111     rv[a.name] = v\n",
    "\n",
    "File c:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\.venv\\\\lib\\\\site-packages\\\\attr\\\\_funcs.py:99, in <genexpr>(.0)\n",
    "     87 elif isinstance(v, dict):\n",
    "     88     df = dict_factory\n",
    "     89     rv[a.name] = df(\n",
    "     90         (\n",
    "     91             _asdict_anything(\n",
    "     92                 kk,\n",
    "     93                 is_key=True,\n",
    "     94                 filter=filter,\n",
    "     95                 dict_factory=df,\n",
    "     96                 retain_collection_types=retain_collection_types,\n",
    "     97                 value_serializer=value_serializer,\n",
    "     98             ),\n",
    "---> 99             _asdict_anything(\n",
    "    100                 vv,\n",
    "    101                 is_key=False,\n",
    "    102                 filter=filter,\n",
    "    103                 dict_factory=df,\n",
    "    104                 retain_collection_types=retain_collection_types,\n",
    "    105                 value_serializer=value_serializer,\n",
    "    106             ),\n",
    "    107         )\n",
    "    108         for kk, vv in v.items()\n",
    "    109     )\n",
    "    110 else:\n",
    "    111     rv[a.name] = v\n",
    "\n",
    "File c:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\.venv\\\\lib\\\\site-packages\\\\attr\\\\_funcs.py:146, in _asdict_anything(val, is_key, filter, dict_factory, retain_collection_types, value_serializer)\n",
    "    143     else:\n",
    "    144         cf = list\n",
    "--> 146     rv = cf(\n",
    "    147         [\n",
    "    148             _asdict_anything(\n",
    "    149                 i,\n",
    "    150                 is_key=False,\n",
    "    151                 filter=filter,\n",
    "    152                 dict_factory=dict_factory,\n",
    "    153                 retain_collection_types=retain_collection_types,\n",
    "    154                 value_serializer=value_serializer,\n",
    "    155             )\n",
    "    156             for i in val\n",
    "    157         ]\n",
    "    158     )\n",
    "    159 elif isinstance(val, dict):\n",
    "    160     df = dict_factory\n",
    "\n",
    "TypeError: <lambda>() missing 4 required positional arguments: 'short_stats_z_scorer', 'long_short_z_diff', 'long_short_naive_z_diff', and 'is_forward_replay'\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(rank_order_obj.__dict__.keys())) # ['is_global', 'LR_ripple', 'RL_ripple', 'LR_laps', 'RL_laps', 'ripple_most_likely_result_tuple', 'laps_most_likely_result_tuple', 'ripple_combined_epoch_stats_df', 'ripple_new_output_tuple', 'laps_combined_epoch_stats_df', 'laps_new_output_tuple', 'minimum_inclusion_fr_Hz', 'included_qclu_values']\n",
    "for k, v in rank_order_obj.__dict__.items():\n",
    "    print(f'trying to pickle: {k}')\n",
    "    try:\n",
    "        diagnose_pickling_issues(v)\n",
    "    except TypeError as e:\n",
    "        print(f'failed to pickle .{k} with error {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['is_global', 'LR_ripple', 'RL_ripple', 'LR_laps', 'RL_laps', 'ripple_most_likely_result_tuple', 'laps_most_likely_result_tuple', 'ripple_combined_epoch_stats_df', 'ripple_new_output_tuple', 'laps_combined_epoch_stats_df', 'laps_new_output_tuple', 'minimum_inclusion_fr_Hz', 'included_qclu_values']\n",
    "trying to pickle: is_global\n",
    "No pickling issues detected.\n",
    "trying to pickle: LR_ripple\n",
    "failed to pickle .LR_ripple with error cannot pickle 'QApplication' object\n",
    "trying to pickle: RL_ripple\n",
    "failed to pickle .RL_ripple with error cannot pickle 'QApplication' object\n",
    "trying to pickle: LR_laps\n",
    "failed to pickle .LR_laps with error cannot pickle 'QApplication' object\n",
    "trying to pickle: RL_laps\n",
    "failed to pickle .RL_laps with error cannot pickle 'QApplication' object\n",
    "trying to pickle: ripple_most_likely_result_tuple\n",
    "No pickling issues detected.\n",
    "trying to pickle: laps_most_likely_result_tuple\n",
    "No pickling issues detected.\n",
    "trying to pickle: ripple_combined_epoch_stats_df\n",
    "No pickling issues detected.\n",
    "trying to pickle: ripple_new_output_tuple\n",
    "No pickling issues detected.\n",
    "trying to pickle: laps_combined_epoch_stats_df\n",
    "No pickling issues detected.\n",
    "trying to pickle: laps_new_output_tuple\n",
    "No pickling issues detected.\n",
    "trying to pickle: minimum_inclusion_fr_Hz\n",
    "No pickling issues detected.\n",
    "trying to pickle: included_qclu_values\n",
    "No pickling issues detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['is_global', 'LR_ripple', 'RL_ripple', 'LR_laps', 'RL_laps', 'ripple_most_likely_result_tuple', 'laps_most_likely_result_tuple', 'ripple_combined_epoch_stats_df', 'ripple_new_output_tuple', 'laps_combined_epoch_stats_df', 'laps_new_output_tuple', 'minimum_inclusion_fr_Hz', 'included_qclu_values']\n",
    "trying to pickle: .is_global\n",
    "No pickling issues detected.\n",
    "trying to pickle: .LR_ripple\n",
    "Pickling error encountered: cannot pickle 'QApplication' object\n",
    "Identified problematic attribute: to_hdf\n",
    "Potential causes:\n",
    "- Attribute contains unpicklable data types (e.g., lambda functions, file objects).\n",
    "- Attribute refers to external resources (e.g., database connections).\n",
    "- Attribute has circular references within the object's structure.\n",
    "trying to pickle: .RL_ripple\n",
    "Pickling error encountered: cannot pickle 'QApplication' object\n",
    "Identified problematic attribute: to_hdf\n",
    "Potential causes:\n",
    "- Attribute contains unpicklable data types (e.g., lambda functions, file objects).\n",
    "- Attribute refers to external resources (e.g., database connections).\n",
    "- Attribute has circular references within the object's structure.\n",
    "trying to pickle: .LR_laps\n",
    "Pickling error encountered: cannot pickle 'QApplication' object\n",
    "Identified problematic attribute: to_hdf\n",
    "Potential causes:\n",
    "- Attribute contains unpicklable data types (e.g., lambda functions, file objects).\n",
    "- Attribute refers to external resources (e.g., database connections).\n",
    "- Attribute has circular references within the object's structure.\n",
    "trying to pickle: .RL_laps\n",
    "Pickling error encountered: cannot pickle 'QApplication' object\n",
    "Identified problematic attribute: to_hdf\n",
    "Potential causes:\n",
    "- Attribute contains unpicklable data types (e.g., lambda functions, file objects).\n",
    "- Attribute refers to external resources (e.g., database connections).\n",
    "- Attribute has circular references within the object's structure.\n",
    "trying to pickle: .ripple_most_likely_result_tuple\n",
    "No pickling issues detected.\n",
    "trying to pickle: .laps_most_likely_result_tuple\n",
    "No pickling issues detected.\n",
    "trying to pickle: .ripple_combined_epoch_stats_df\n",
    "No pickling issues detected.\n",
    "trying to pickle: .ripple_new_output_tuple\n",
    "No pickling issues detected.\n",
    "trying to pickle: .laps_combined_epoch_stats_df\n",
    "No pickling issues detected.\n",
    "trying to pickle: .laps_new_output_tuple\n",
    "No pickling issues detected.\n",
    "trying to pickle: .minimum_inclusion_fr_Hz\n",
    "No pickling issues detected.\n",
    "trying to pickle: .included_qclu_values\n",
    "No pickling issues detected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear issue in `rank_order_obj.LR_ripple.ranked_aclus_stats_dict`: values contain LongShortStatsTuple which contains long_stats_z_scorer\n",
    "`pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations.Zscorer`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
