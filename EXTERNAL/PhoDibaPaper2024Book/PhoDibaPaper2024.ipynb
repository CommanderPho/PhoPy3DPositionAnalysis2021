{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "remove-input",
     "run_main"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "TODAY_DAY_DATE: 2024-09-18_Apogee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['kdiba_pin01_one_11-02_17-46-44']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from neuropy.utils.indexing_helpers import PandasHelpers\n",
    "from pyphocorehelpers.indexing_helpers import partition_df\n",
    "# Set the maximum number of columns to display\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import IPython\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers\n",
    "from pyphocorehelpers.notebook_helpers import NotebookCellExecutionLogger\n",
    "from pyphocorehelpers.assertion_helpers import Assert\n",
    "\n",
    "# Jupyter-lab enable printing for any line on its own (instead of just the last one in the cell)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "_notebook_path:Path = Path(IPythonHelpers.try_find_notebook_filepath(IPython.extract_module_locals())).resolve() # Finds the path of THIS notebook\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "# Switch to the desired interactivity mode\n",
    "plt.interactive(True)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "pio.templates.default = template\n",
    "from pyphocorehelpers.plotting.media_output_helpers import fig_to_clipboard\n",
    "from pyphocorehelpers.Filesystem.path_helpers import file_uri_from_path, sanitize_filename_for_Windows\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget, simple_path_display_widget\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_helper_save_figures, _helper_build_figure, plotly_pre_post_delta_scatter, plot_across_sessions_scatter_results\n",
    "from pyphocorehelpers.assertion_helpers import Assert\n",
    "\n",
    "# from ..PendingNotebookCode import plot_across_sessions_scatter_results, plot_histograms, plot_stacked_histograms\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import find_csv_files, find_HDF5_files, find_most_recent_files\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms_across_sessions, plot_histograms, plot_stacked_histograms\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import load_across_sessions_exported_files, _process_and_load_exported_file, _common_cleanup_operations\n",
    "\n",
    "from pyphocorehelpers.programming_helpers import metadata_attributes\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import build_session_t_delta, _new_process_csv_files, _old_process_csv_files\n",
    "\n",
    "debug_print: bool = False\n",
    "enable_neptune: bool = False\n",
    "\n",
    "_TODAY_DAY_ONLY_DATE: str = \"2024-09-18\"\n",
    "TODAY_DAY_DATE: str = f\"{_TODAY_DAY_ONLY_DATE}_Apogee\"\n",
    "# TODAY_DAY_DATE: str = f\"{_TODAY_DAY_ONLY_DATE}_GL\"\n",
    "# TODAY_DAY_DATE: str = f\"{_TODAY_DAY_ONLY_DATE}_Lab\"\n",
    "# TODAY_DAY_DATE: str = f\"{_TODAY_DAY_ONLY_DATE}_rMBP\"\n",
    "\n",
    "print(f'TODAY_DAY_DATE: {TODAY_DAY_DATE}')\n",
    "\n",
    "types.session_str: TypeAlias = str # a unique session identifier\n",
    "\n",
    "if enable_neptune:\n",
    "    import neptune # for logging progress and results\n",
    "    from neptune.types import File\n",
    "    from pyphoplacecellanalysis.General.Batch.NeptuneAiHelpers import Neptuner, AutoValueConvertingNeptuneRun, set_environment_variables \n",
    "\n",
    "    ## Gets the notebook filepath for Neptune:\n",
    "    import IPython\n",
    "    from pyphocorehelpers.programming_helpers import IPythonHelpers\n",
    "    notebook_filepath: str = IPythonHelpers.try_find_notebook_filepath(IPython.extract_module_locals())\n",
    "    assert Path(notebook_filepath).resolve().exists(), f\"found notebook filepath: '{notebook_filepath}' does not exist\"\n",
    "    # notebook_filepath\n",
    "\n",
    "    neptune_kwargs = {'project':\"commander.pho/PhoDibaLongShortAcrossSessions\",\n",
    "    'api_token':\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGIxODU2My1lZTNhLTQ2ZWMtOTkzNS02ZTRmNzM5YmNjNjIifQ==\"}\n",
    "            \n",
    "    neptuner = Neptuner(project_name=neptune_kwargs['project'], api_token=neptune_kwargs['api_token'])\n",
    "\n",
    "\n",
    "    if neptuner.run is None:\n",
    "        neptuner.run = AutoValueConvertingNeptuneRun(project=neptuner.project_name, api_token=neptuner.api_token, dependencies=\"infer\", source_files=[notebook_filepath])\n",
    "        params = {\"TODAY_DAY_DATE\": TODAY_DAY_DATE, \"run_workstation\": \"Apogee\"}\n",
    "        neptuner.run[\"parameters\"] = params\n",
    "        neptuner.outputs = neptuner.run['outputs']\n",
    "        neptuner.figures = neptuner.outputs['figures']\n",
    "\n",
    "    neptuner_run: AutoValueConvertingNeptuneRun = neptuner.run\n",
    "    \n",
    "    # run = neptune.init_run(source_files=[\"**/*.dvc\"])\n",
    "\n",
    "    # # Pre-execution dataframe view:\n",
    "    # run[\"dataset/global_batch_run_progress_df\"].upload(File.as_html(global_batch_run.to_dataframe(expand_context=True, good_only=False))) # \"path/to/test_preds.csv\"\n",
    "\n",
    "else:\n",
    "    # no neptune:\n",
    "    neptuner = None    \n",
    "    neptuner_run = None\n",
    "\n",
    "\n",
    "known_bad_sessions = [IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44')]\n",
    "known_bad_session_strs = [str(v.get_description()) for v in known_bad_sessions]\n",
    "known_bad_session_strs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "remove-cell",
     "run_main"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected_outputs_directory: K:\\scratch\\collected_outputs\n",
      "\tfigures_folder: file:///K:/scratch/collected_outputs/figures\n",
      "\tacross_sessions_output_folder: file:///K:/scratch/across_sessions\n",
      "earliest_delta_aligned_t_start: -2057.2259484970764, latest_delta_aligned_t_end: 1661.8560019930592\n",
      "ERR: Could not parse filename: \"session_h5_files_copydict_2024-09-10_GL\"\n",
      "ERR: Could not parse filename: \"session_h5_files_copydict_2024-09-11_GL\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"11-02_17-46-44\"\n",
      "File type merged_complete_epoch_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"11-02_17-46-44\"\n",
      "File type neuron_replay_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"11-02_19-28-0\"\n",
      "File type merged_complete_epoch_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"11-02_19-28-0\"\n",
      "File type neuron_replay_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-4-09_16-40-54\"\n",
      "File type merged_complete_epoch_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-4-09_16-40-54\"\n",
      "File type neuron_replay_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-4-09_17-29-30\"\n",
      "File type merged_complete_epoch_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-4-09_17-29-30\"\n",
      "File type neuron_replay_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-4-10_12-25-50\"\n",
      "File type merged_complete_epoch_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-4-10_12-25-50\"\n",
      "File type neuron_replay_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-4-10_12-58-3\"\n",
      "File type merged_complete_epoch_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-4-10_12-58-3\"\n",
      "File type neuron_replay_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-6-07_11-26-53\"\n",
      "File type neuron_replay_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-6-07_16-40-19\"\n",
      "File type merged_complete_epoch_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-6-07_16-40-19\"\n",
      "File type neuron_replay_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-6-08_14-26-15\"\n",
      "File type merged_complete_epoch_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-6-08_14-26-15\"\n",
      "File type neuron_replay_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-6-08_21-16-25\"\n",
      "File type merged_complete_epoch_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-6-08_21-16-25\"\n",
      "File type neuron_replay_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-6-09_1-22-43\"\n",
      "File type merged_complete_epoch_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-6-09_1-22-43\"\n",
      "File type neuron_replay_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-6-09_22-24-40\"\n",
      "File type merged_complete_epoch_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-6-09_22-24-40\"\n",
      "File type neuron_replay_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-6-12_15-55-31\"\n",
      "File type merged_complete_epoch_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"2006-6-12_16-53-46\"\n",
      "File type neuron_replay_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"fet11-01_12-58-54\"\n",
      "File type merged_complete_epoch_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"fet11-01_12-58-54\"\n",
      "File type neuron_replay_stats_df not implemented.\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-07_11-26-53_long_short_firing_rate_indicies\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-08_14-26-15_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-08_14-26-15_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-08_14-26-15_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-08_14-26-15_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-08_14-26-15_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-08_14-26-15_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-08_14-26-15_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-08_14-26-15_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-08_14-26-15_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-08_14-26-15_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-08_14-26-15_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-08_14-26-15_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-08_14-26-15_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-08_14-26-15_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_gor01_one_2006-6-09_1-22-43_None\"\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "Skipping \"kdiba_pin01_one_11-02_17-46-44\" because it is in known_bad_session_strs.\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_vvp01_two_2006-4-16_18-47-52\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_vvp01_two_2006-4-16_18-47-52\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_vvp01_two_2006-4-16_18-47-52\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_vvp01_two_2006-4-16_18-47-52\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"kdiba_vvp01_two_2006-4-16_18-47-52\"\n",
      "WARN: curr_session_t_delta is None for session_str = \"t\"\n",
      "File type split_df not implemented.\n",
      "failed to find proper 'is_user_annotated_epoch' and 'is_valid_epoch' columns for the epochs passed with error: Cannot mask with non-boolean array containing NA / NaN values. Skipping.\n",
      "WARNING: no `all_sessions_all_scores_df` to get \"is_valid_epoch\" and \"is_user_annotated_epoch\" from!\n",
      "\tSetting \"is_valid_epoch\" all to True and \"is_user_annotated_Epoch\" all to False.\n"
     ]
    }
   ],
   "source": [
    "## Load across session t_delta CSV, which contains the t_delta for each session:\n",
    "\n",
    "## INPUTS: known_bad_session_strs,\n",
    "\n",
    "# cuttoff_date = datetime(2024, 8, 29)\n",
    "cuttoff_date = datetime(2024, 7, 1)\n",
    "# cuttoff_date = datetime(2024, 5, 18)\n",
    "# cuttoff_date = None\n",
    "\n",
    "known_collected_outputs_paths = [Path(v).resolve() for v in ['/Users/pho/data/collected_outputs',\n",
    "                                                            '/Volumes/SwapSSD/Data/collected_outputs', r\"K:/scratch/collected_outputs\", '/Users/pho/Dropbox (University of Michigan)/MED-DibaLabDropbox/Data/Pho/Outputs/output/collected_outputs', r'C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs',\n",
    "                                                            '/home/halechr/FastData/collected_outputs/', '/home/halechr/cloud/turbo/Data/Output/collected_outputs']]\n",
    "collected_outputs_directory = find_first_extant_path(known_collected_outputs_paths)\n",
    "assert collected_outputs_directory.exists(), f\"collected_outputs_directory: {collected_outputs_directory} does not exist! Is the right computer's config commented out above?\"\n",
    "# fullwidth_path_widget(scripts_output_path, file_name_label='Scripts Output Path:')\n",
    "print(f'collected_outputs_directory: {collected_outputs_directory}')\n",
    "\n",
    "# _active_folder_widget = fullwidth_path_widget(collected_outputs_directory)\n",
    "# display(_active_folder_widget)\n",
    "\n",
    "# Create a 'figures' subfolder if it doesn't exist\n",
    "figures_folder: Path = collected_outputs_directory.joinpath('figures').resolve()\n",
    "figures_folder.mkdir(parents=False, exist_ok=True)\n",
    "assert figures_folder.exists()\n",
    "print(f'\\tfigures_folder: {file_uri_from_path(figures_folder)}')\n",
    "\n",
    "# Create an output path for the across session collected results (like the aggregate CSVs built from the individual session CSVs)\n",
    "across_sessions_output_folder: Path = collected_outputs_directory.joinpath('../across_sessions').resolve()\n",
    "across_sessions_output_folder.mkdir(parents=False, exist_ok=True)\n",
    "assert across_sessions_output_folder.exists()\n",
    "print(f'\\tacross_sessions_output_folder: {file_uri_from_path(across_sessions_output_folder)}')\n",
    "\n",
    "## sessions' t_delta:\n",
    "t_delta_csv_path = collected_outputs_directory.joinpath('../2024-01-18_GL_t_split_df.csv').resolve() # GL\n",
    "# t_delta_csv_path = collected_outputs_directory.joinpath('2024-06-11_GL_t_split_df.csv').resolve()\n",
    "\n",
    "t_delta_df, t_delta_dict, (earliest_delta_aligned_t_start, latest_delta_aligned_t_end) = build_session_t_delta(t_delta_csv_path=t_delta_csv_path)\n",
    "\n",
    "if neptuner_run is not None:\n",
    "    _neptuner_run_parameters = dict(cuttoff_date=cuttoff_date, collected_outputs_directory=collected_outputs_directory.as_posix(), figures_folder=figures_folder.as_posix(),\n",
    "                           across_sessions_output_folder=across_sessions_output_folder.as_posix(), t_delta_csv_path=t_delta_csv_path.as_posix())\n",
    "    for k, v in _neptuner_run_parameters.items():\n",
    "        neptuner_run[f'parameters/{k}'] = v\n",
    "    _neptuner_run_parameters = {} # reset after writing\n",
    "\n",
    "## Find the files:\n",
    "csv_files = find_csv_files(collected_outputs_directory)\n",
    "h5_files = find_HDF5_files(collected_outputs_directory)\n",
    "\n",
    "csv_sessions, parsed_csv_files_df  = find_most_recent_files(found_session_export_paths=csv_files, cuttoff_date=cuttoff_date)\n",
    "h5_sessions, parsed_h5_files_df = find_most_recent_files(found_session_export_paths=h5_files)\n",
    "\n",
    "## OUTPUTS: csv_files, csv_sessions, parsed_csv_files_df\n",
    "## OUTPUTS: h5_files, h5_sessions, parsed_h5_files_df\n",
    "\n",
    "_neptuner_run_parameters = dict(csv_files=csv_files, h5_files=h5_files, csv_sessions=csv_sessions, h5_sessions=h5_sessions)\n",
    "\n",
    "# #TODO 2024-03-02 12:12: - [ ] Could add weighted correlation if there is a dataframe for that and it's computed:\n",
    "_df_raw_variable_names = ['simple_pf_pearson_merged_df', 'weighted_corr_merged_df']\n",
    "_df_variables_names = ['laps_weighted_corr_merged_df', 'ripple_weighted_corr_merged_df', 'laps_simple_pf_pearson_merged_df', 'ripple_simple_pf_pearson_merged_df']\n",
    "\n",
    "# # tbin_values_dict = {'laps': self.laps_decoding_time_bin_size, 'ripple': self.ripple_decoding_time_bin_size}\n",
    "time_col_name_dict = {'laps': 'lap_start_t', 'ripple': 'ripple_start_t'} ## default should be 't_bin_center'\n",
    "\n",
    "# fold older files:\n",
    "# {'laps_marginals_df': 'lap_start_t', 'ripple_marginals_df': 'ripple_start_t', 'laps_time_bin_marginals_df':'t_bin_center', 'ripple_time_bin_marginals_df':'t_bin_center'}\n",
    "\n",
    "if neptuner_run is not None:\n",
    "    _neptuner_run_parameters = _neptuner_run_parameters | dict(earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end,\n",
    "                                     t_delta_df=t_delta_df)\n",
    "    for k, v in _neptuner_run_parameters.items():\n",
    "        neptuner_run[f'parsed/{k}'] = v\n",
    "    _neptuner_run_parameters = {} # reset after writing\n",
    "\n",
    "all_session_experiment_experience_csv_path = Path(\"./EXTERNAL/sessions_experiment_datetime_df.csv\").resolve()\n",
    "Assert.path_exists(all_session_experiment_experience_csv_path)\n",
    "## NEW `parsed_csv_files_df1-based approach 2024-07-11 - \n",
    "## INPUTS: parsed_csv_files_df\n",
    "dict_results, df_results, excluded_or_outdated_files_list = _new_process_csv_files(parsed_csv_files_df=parsed_csv_files_df, t_delta_dict=t_delta_dict, cuttoff_date=cuttoff_date, known_bad_session_strs=known_bad_session_strs, all_session_experiment_experience_csv_path=all_session_experiment_experience_csv_path, debug_print=False) # , known_bad_session_strs=known_bad_session_strs\n",
    "(final_sessions_loaded_laps_dict, final_sessions_loaded_ripple_dict, final_sessions_loaded_laps_time_bin_dict, final_sessions_loaded_ripple_time_bin_dict, final_sessions_loaded_simple_pearson_laps_dict, final_sessions_loaded_simple_pearson_ripple_dict, final_sessions_loaded_laps_wcorr_dict, final_sessions_loaded_ripple_wcorr_dict, final_sessions_loaded_laps_all_scores_dict, final_sessions_loaded_ripple_all_scores_dict) = dict_results\n",
    "(all_sessions_laps_df, all_sessions_ripple_df, all_sessions_laps_time_bin_df, all_sessions_ripple_time_bin_df, all_sessions_simple_pearson_laps_df, all_sessions_simple_pearson_ripple_df, all_sessions_wcorr_laps_df, all_sessions_wcorr_ripple_df, all_sessions_all_scores_ripple_df) = df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "run_main"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>format_name</th>\n",
       "      <th>animal</th>\n",
       "      <th>exper_name</th>\n",
       "      <th>session_name</th>\n",
       "      <th>path</th>\n",
       "      <th>session_datetime</th>\n",
       "      <th>experience_rank</th>\n",
       "      <th>experience_orientation_rank</th>\n",
       "      <th>session_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-4-09_16-40-54</td>\n",
       "      <td>W:/Data/KDIBA/vvp01/two/2006-4-09_16-40-54</td>\n",
       "      <td>2006-04-09 16:40:54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kdiba|vvp01|two|2006-4-09_16-40-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-4-09_17-29-30</td>\n",
       "      <td>W:/Data/KDIBA/vvp01/one/2006-4-09_17-29-30</td>\n",
       "      <td>2006-04-09 17:29:30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>kdiba|vvp01|one|2006-4-09_17-29-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>one</td>\n",
       "      <td>2006-4-10_12-25-50</td>\n",
       "      <td>W:/Data/KDIBA/vvp01/one/2006-4-10_12-25-50</td>\n",
       "      <td>2006-04-10 12:25:50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>kdiba|vvp01|one|2006-4-10_12-25-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-4-10_12-58-3</td>\n",
       "      <td>W:/Data/KDIBA/vvp01/two/2006-4-10_12-58-3</td>\n",
       "      <td>2006-04-10 12:58:03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>kdiba|vvp01|two|2006-4-10_12-58-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>vvp01</td>\n",
       "      <td>two</td>\n",
       "      <td>2006-4-10_19-11-57</td>\n",
       "      <td>W:/Data/KDIBA/vvp01/two/2006-4-10_19-11-57</td>\n",
       "      <td>2006-04-10 19:11:57</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>kdiba|vvp01|two|2006-4-10_19-11-57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>59</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-09_21-17-16</td>\n",
       "      <td>W:/Data/KDIBA/pin01/one/11-09_21-17-16</td>\n",
       "      <td>2006-11-09 21:17:16</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>kdiba|pin01|one|11-09_21-17-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>60</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-09_22-4-5</td>\n",
       "      <td>W:/Data/KDIBA/pin01/one/11-09_22-4-5</td>\n",
       "      <td>2006-11-09 22:04:05</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>kdiba|pin01|one|11-09_22-4-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>61</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-19_12-35-59</td>\n",
       "      <td>W:/Data/KDIBA/pin01/one/11-19_12-35-59</td>\n",
       "      <td>2006-11-19 12:35:59</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>kdiba|pin01|one|11-19_12-35-59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>62</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-19_13-2-0</td>\n",
       "      <td>W:/Data/KDIBA/pin01/one/11-19_13-2-0</td>\n",
       "      <td>2006-11-19 13:02:00</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>kdiba|pin01|one|11-19_13-2-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>63</td>\n",
       "      <td>kdiba</td>\n",
       "      <td>pin01</td>\n",
       "      <td>one</td>\n",
       "      <td>11-19_13-55-7</td>\n",
       "      <td>W:/Data/KDIBA/pin01/one/11-19_13-55-7</td>\n",
       "      <td>2006-11-19 13:55:07</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>kdiba|pin01|one|11-19_13-55-7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 format_name animal exper_name        session_name  \\\n",
       "0           31       kdiba  vvp01        two  2006-4-09_16-40-54   \n",
       "1           12       kdiba  vvp01        one  2006-4-09_17-29-30   \n",
       "2           13       kdiba  vvp01        one  2006-4-10_12-25-50   \n",
       "3           32       kdiba  vvp01        two   2006-4-10_12-58-3   \n",
       "4           33       kdiba  vvp01        two  2006-4-10_19-11-57   \n",
       "..         ...         ...    ...        ...                 ...   \n",
       "63          59       kdiba  pin01        one      11-09_21-17-16   \n",
       "64          60       kdiba  pin01        one        11-09_22-4-5   \n",
       "65          61       kdiba  pin01        one      11-19_12-35-59   \n",
       "66          62       kdiba  pin01        one        11-19_13-2-0   \n",
       "67          63       kdiba  pin01        one       11-19_13-55-7   \n",
       "\n",
       "                                          path     session_datetime  \\\n",
       "0   W:/Data/KDIBA/vvp01/two/2006-4-09_16-40-54  2006-04-09 16:40:54   \n",
       "1   W:/Data/KDIBA/vvp01/one/2006-4-09_17-29-30  2006-04-09 17:29:30   \n",
       "2   W:/Data/KDIBA/vvp01/one/2006-4-10_12-25-50  2006-04-10 12:25:50   \n",
       "3    W:/Data/KDIBA/vvp01/two/2006-4-10_12-58-3  2006-04-10 12:58:03   \n",
       "4   W:/Data/KDIBA/vvp01/two/2006-4-10_19-11-57  2006-04-10 19:11:57   \n",
       "..                                         ...                  ...   \n",
       "63      W:/Data/KDIBA/pin01/one/11-09_21-17-16  2006-11-09 21:17:16   \n",
       "64        W:/Data/KDIBA/pin01/one/11-09_22-4-5  2006-11-09 22:04:05   \n",
       "65      W:/Data/KDIBA/pin01/one/11-19_12-35-59  2006-11-19 12:35:59   \n",
       "66        W:/Data/KDIBA/pin01/one/11-19_13-2-0  2006-11-19 13:02:00   \n",
       "67       W:/Data/KDIBA/pin01/one/11-19_13-55-7  2006-11-19 13:55:07   \n",
       "\n",
       "    experience_rank  experience_orientation_rank  \\\n",
       "0                 0                            0   \n",
       "1                 1                            0   \n",
       "2                 2                            1   \n",
       "3                 3                            1   \n",
       "4                 4                            2   \n",
       "..              ...                          ...   \n",
       "63               11                           11   \n",
       "64               12                           12   \n",
       "65               13                           13   \n",
       "66               14                           14   \n",
       "67               15                           15   \n",
       "\n",
       "                           session_uid  \n",
       "0   kdiba|vvp01|two|2006-4-09_16-40-54  \n",
       "1   kdiba|vvp01|one|2006-4-09_17-29-30  \n",
       "2   kdiba|vvp01|one|2006-4-10_12-25-50  \n",
       "3    kdiba|vvp01|two|2006-4-10_12-58-3  \n",
       "4   kdiba|vvp01|two|2006-4-10_19-11-57  \n",
       "..                                 ...  \n",
       "63      kdiba|pin01|one|11-09_21-17-16  \n",
       "64        kdiba|pin01|one|11-09_22-4-5  \n",
       "65      kdiba|pin01|one|11-19_12-35-59  \n",
       "66        kdiba|pin01|one|11-19_13-2-0  \n",
       "67       kdiba|pin01|one|11-19_13-55-7  \n",
       "\n",
       "[68 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import load_and_apply_session_experience_rank_csv\n",
    "\n",
    "all_session_experiment_experience_csv_path = Path(\"./EXTERNAL/sessions_experiment_datetime_df.csv\").resolve()\n",
    "Assert.path_exists(all_session_experiment_experience_csv_path)\n",
    "sessions_df, (experience_rank_map_dict, experience_orientation_rank_map_dict), _callback_add_df_columns = load_and_apply_session_experience_rank_csv(all_session_experiment_experience_csv_path, session_uid_str_sep='_')\n",
    "df_results = [_callback_add_df_columns(a_df, session_id_column_name='session_name') for a_df in df_results]\n",
    "all_sessions_all_scores_ripple_df: pd.DataFrame = _callback_add_df_columns(all_sessions_all_scores_ripple_df, session_id_column_name='session_name')\n",
    "\n",
    "\n",
    "# all_sessions_all_scores_ripple_df\n",
    "# all_sessions_all_scores_ripple_df['session_name']\n",
    "sessions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(sessions_df.columns)) # ['Unnamed: 0', 'format_name', 'animal', 'exper_name', 'session_name', 'path', 'session_datetime', 'experience_rank', 'experience_orientation_rank', 'session_uid']\n",
    "\n",
    "# sessions_df[['format_name', 'animal', 'exper_name', 'session_name']]\n",
    "\n",
    "# ensure no repeats:\n",
    "if sessions_df[['format_name', 'animal', 'exper_name', 'session_name']].duplicated().any():\n",
    "    raise ValueError(\"Duplicate entries found in the specified columns.\")\n",
    "\n",
    "# sessions_df.drop_duplicates(subset=['format_name', 'animal', 'exper_name', 'session_name'], inplace=False)\n",
    "\n",
    "if sessions_df[['session_uid']].duplicated().any():\n",
    "    raise ValueError(\"Duplicate entries found in the session_uid columns.\")\n",
    "\n",
    "\n",
    "df: pd.DataFrame = deepcopy(sessions_df)\n",
    "\n",
    "unique_animals = df['animal'].unique().tolist()\n",
    "unique_exper_names = df['exper_name'].unique().tolist()\n",
    "unique_session_names = df['session_name'].unique().tolist()\n",
    "\n",
    "sessions_tree = {}\n",
    "sessions_number_tree = {}\n",
    "\n",
    "\n",
    "for animal in unique_animals:\n",
    "    sessions_tree[animal] = list(unique_session_names)\n",
    "    sessions_number_tree[animal] = len(list(unique_session_names))\n",
    "    # unique_exper_names\n",
    "\n",
    "\n",
    "    # for sess in unique_session_names:\n",
    "# sessions_tree\n",
    "sessions_number_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performed 1 aggregation grouped on columns: 'animal', 'exper_name'\n",
    "sessions_count_df = sessions_df.groupby(['animal', 'exper_name']).agg(session_name_count=('session_name', 'count')).reset_index()\n",
    "# \tanimal\texper_name\tsession_name_count\n",
    "# 0\tgor01\tone\t6\n",
    "# 1\tgor01\ttwo\t6\n",
    "# 2\tpin01\tone\t16\n",
    "# 3\tvvp01\tone\t19\n",
    "# 4\tvvp01\ttwo\t21\n",
    "\n",
    "# sessions_count_df.to_clipboard() #['session_name_count']\n",
    "sessions_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_all_scores_ripple_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_sessions_ripple_time_bin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h5_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell",
     "run_main"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import load_across_sessions_exported_h5_files\n",
    "\n",
    "## INPUTS: h5_sessions, session_dict, cuttoff_date, known_bad_session_strs\n",
    "parsed_h5_files_df, h5_contexts_paths_dict = load_across_sessions_exported_h5_files(collected_outputs_directory=collected_outputs_directory, cuttoff_date=cuttoff_date,\n",
    "                                                                                    known_bad_session_strs=known_bad_session_strs)\n",
    "h5_session_contexts = list(h5_contexts_paths_dict.keys())\n",
    "included_h5_paths = list(h5_contexts_paths_dict.values())\n",
    "\n",
    "if neptuner_run is not None:\n",
    "    _neptuner_run_parameters = dict(parsed_h5_files_df=parsed_h5_files_df,\n",
    "                                       )\n",
    "    for k, v in _neptuner_run_parameters.items():\n",
    "        neptuner_run[f'parsed/{k}'] = v\n",
    "    _neptuner_run_parameters = {} # reset after writing\n",
    "\n",
    "parsed_h5_files_df\n",
    "# h5_contexts_paths_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell",
     "run_main"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative\n",
    "\n",
    "included_session_contexts = deepcopy(h5_session_contexts)\n",
    "included_h5_paths = deepcopy(included_h5_paths)\n",
    "num_sessions = len(included_session_contexts)\n",
    "(neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table), output_path_dicts = AcrossSessionTables.build_and_save_all_combined_tables(included_session_contexts, included_h5_paths,\n",
    "                                                                                                                                                    override_output_parent_path=across_sessions_output_folder, output_path_suffix=f'{TODAY_DAY_DATE}',\n",
    "                                                                                                                                                    should_restore_native_column_types=True, include_csv=True, include_pkl=True)\n",
    "\n",
    "\n",
    "if neptuner_run is not None:\n",
    "    _neptuner_run_parameters = dict(neuron_identities_table=neuron_identities_table, long_short_fr_indicies_analysis_table=long_short_fr_indicies_analysis_table, neuron_replay_stats_table=neuron_replay_stats_table,\n",
    "                                       num_sessions=num_sessions)\n",
    "    for k, v in _neptuner_run_parameters.items():\n",
    "        neptuner_run[f'parsed/{k}'] = v\n",
    "    _neptuner_run_parameters = {} # reset after writing\n",
    "\n",
    "    for output_name, a_paths_dict in output_path_dicts.items():\n",
    "        for format_extension, an_output_path in a_paths_dict.items():\n",
    "            neptuner_run[f\"output_files/{format_extension}/{output_name}\"].upload(an_output_path.resolve().as_posix())\n",
    "\n",
    "\n",
    "# {'neuron_identities_table': {'.csv': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee/neuron_identities_table.csv'),\n",
    "#   '.pkl': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee/neuron_identities_table.pkl')},\n",
    "#  'long_short_fr_indicies_analysis_table': {'.csv': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee/long_short_fr_indicies_analysis_table.csv'),\n",
    "#   '.pkl': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee/long_short_fr_indicies_analysis_table.pkl')},\n",
    "#  'neuron_replay_stats_table': {'.csv': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee/neuron_replay_stats_table.csv'),\n",
    "#   '.pkl': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee/neuron_replay_stats_table.pkl')}}\n",
    "\n",
    "output_path_dicts\n",
    "\n",
    "## Move the \"height\" columns to the end\n",
    "neuron_replay_stats_table = reorder_columns_relative(neuron_replay_stats_table, column_names=['neuron_uid', 'format_name', 'animal', 'exper_name', 'session_name', 'neuron_type', 'aclu', 'session_uid', 'session_datetime'], relative_mode='start')\n",
    "\n",
    "neuron_replay_stats_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "run_main"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "\n",
    "# output_path_suffix: str = f'2024-09-11_GL'\n",
    "output_path_suffix: str = f'2024-09-12'\n",
    "inst_fr_output_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{output_path_suffix}.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=collected_outputs_directory, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "across_session_inst_fr_computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "across_sessions_instantaneous_frs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "run_main"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "\n",
    "# matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# output_path_suffix: str = f'{TODAY_DAY_DATE}'\n",
    "# output_path_suffix: str = f'2024-09-11_GL'\n",
    "output_path_suffix: str = f'2024-09-12'\n",
    "print(F'output_path_suffix: {output_path_suffix}')\n",
    "AcrossSessionsResults.post_compute_all_sessions_processing(global_data_root_parent_path=collected_outputs_directory, output_path_suffix=output_path_suffix, plotting_enabled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get filtered for a particular type of replay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run_main"
    ]
   },
   "outputs": [],
   "source": [
    "## filter by specific set of replays:\n",
    "# dfs_list = (all_sessions_ripple_df, all_sessions_ripple_time_bin_df, all_sessions_simple_pearson_ripple_df, all_sessions_wcorr_ripple_df, all_sessions_all_scores_ripple_df)\n",
    "\n",
    "replay_name: str = ''\n",
    "# replay_name: str = 'withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0' # 4307 rows\n",
    "# replay_name: str = 'withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0' # 1417 rows, 1437 rows\n",
    "# replay_name: str = 'withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0' # 2802 rows, 2831 rows\n",
    "\n",
    "time_bin_size: float = 0.025\n",
    "# time_bin_size: float = 0.02\n",
    "# time_bin_size: float = 0.01\n",
    "filtered_all_sessions_ripple_df = deepcopy(all_sessions_ripple_df)[(all_sessions_ripple_df['custom_replay_name'] == replay_name) & (all_sessions_ripple_df['time_bin_size'] == time_bin_size)]\n",
    "filtered_all_sessions_ripple_time_bin_df = deepcopy(all_sessions_ripple_time_bin_df)[(all_sessions_ripple_time_bin_df['custom_replay_name'] == replay_name) & (all_sessions_ripple_time_bin_df['time_bin_size'] == time_bin_size)]\n",
    "filtered_all_sessions_simple_pearson_ripple_df = deepcopy(all_sessions_simple_pearson_ripple_df)[(all_sessions_simple_pearson_ripple_df['custom_replay_name'] == replay_name) & (all_sessions_simple_pearson_ripple_df['time_bin_size'] == time_bin_size)]\n",
    "filtered_all_sessions_wcorr_ripple_df = deepcopy(all_sessions_wcorr_ripple_df)[(all_sessions_wcorr_ripple_df['custom_replay_name'] == replay_name) & (all_sessions_wcorr_ripple_df['time_bin_size'] == time_bin_size)]\n",
    "filtered_all_sessions_all_scores_ripple_df = deepcopy(all_sessions_all_scores_ripple_df)[(all_sessions_all_scores_ripple_df['custom_replay_name'] == replay_name) & (all_sessions_all_scores_ripple_df['time_bin_size'] == time_bin_size)]\n",
    "## OUTPUTS: filtered_all_sessions_ripple_df, filtered_all_sessions_ripple_time_bin_df, filtered_all_sessions_simple_pearson_ripple_df, filtered_all_sessions_wcorr_ripple_df, filtered_all_sessions_all_scores_ripple_df\n",
    "# filtered_all_sessions_simple_pearson_ripple_df\n",
    "filtered_all_sessions_all_scores_ripple_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Enumerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'all_sessions_ripple_df': all_sessions_ripple_df,\n",
    "    'all_sessions_ripple_time_bin_df': all_sessions_ripple_time_bin_df,\n",
    "    'all_sessions_simple_pearson_ripple_df': all_sessions_simple_pearson_ripple_df,\n",
    "    'all_sessions_wcorr_ripple_df': all_sessions_wcorr_ripple_df,\n",
    "    'all_sessions_all_scores_ripple_df': all_sessions_all_scores_ripple_df\n",
    "}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    unique_time_bin_counts = df.groupby('custom_replay_name')['time_bin_size'].nunique()\n",
    "    print(f\"== '{name}':\")\n",
    "    print(unique_time_bin_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "all_sessions_ripple_df['custom_replay_name'].unique()\n",
    "all_sessions_ripple_time_bin_df['custom_replay_name'].unique()\n",
    "all_sessions_simple_pearson_ripple_df['custom_replay_name'].unique()\n",
    "all_sessions_all_scores_ripple_df['custom_replay_name'].unique() \n",
    "\n",
    "# ['', 'withOldestImportedReplays-qclu_XX-frateThresh_0.1',\n",
    "# 'withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0',\n",
    "# 'withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0',\n",
    "# 'withNormalComputedReplays-qclu_[1,2]-frateThresh_1.0']\n",
    "\n",
    "\n",
    "all_sessions_all_scores_ripple_df['custom_replay_name'].unique() ## OH no, only this one is missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "all_sessions_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# sess_names, replay_names = all_sessions_ripple_df['session_name'].str.split('__') # , maxsplit=1\n",
    "\n",
    "for a_split in all_sessions_ripple_df['session_name'].str.split('__'):\n",
    "\tprint(f'a_split: {a_split}')\n",
    "\n",
    "\tif len(a_split) > 1:\n",
    "\t\tprint(f'a_split: {a_split}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "all_sessions_ripple_time_bin_df['custom_replay_name'].unique()\n",
    "# all_sessions_ripple_df['custom_replay_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.min_rows', 50)\n",
    "# pd.set_option('display.max_rows', 50)\n",
    "# pd.set_option('display.show_dimensions', True)\n",
    "\n",
    "with pd.option_context('display.min_rows', 50, 'display.show_dimensions', True):\n",
    "    # max_elements\n",
    "    display(parsed_csv_files_df)\n",
    "\n",
    "# parsed_csv_files_df[parsed_csv_files_df['file_type'] == 'ripple_all_scores_merged_df']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "parsed_csv_files_df[parsed_csv_files_df['file_type'] == 'ripple_all_scores_merged_df']\n",
    "\n",
    "# all_sessions_all_scores_ripple_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "all_sessions_ripple_time_bin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "print(list(np.unique(parsed_csv_files_df.file_type))) # ['laps_marginals_df', 'laps_simple_pf_pearson_merged_df', 'laps_time_bin_marginals_df', 'laps_weighted_corr_merged_df', 'merged_complete_epoch_stats_df', 'ripple_all_scores_merged_df', 'ripple_marginals_df', 'ripple_simple_pf_pearson_merged_df', 'ripple_time_bin_marginals_df', 'ripple_weighted_corr_merged_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Across Session CSV Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "export",
     "CSV",
     "run_main"
    ]
   },
   "outputs": [],
   "source": [
    "display(parsed_csv_files_df)\n",
    "\n",
    "across_sessions_parsed_csv_files_path = across_sessions_output_folder.joinpath(f'{TODAY_DAY_DATE}_parsed_csv_files_df.csv').resolve()\n",
    "# parsed_csv_files_df.to_clipboard(excel=True)\n",
    "parsed_csv_files_df.to_csv(across_sessions_parsed_csv_files_path)\n",
    "display(fullwidth_path_widget(across_sessions_parsed_csv_files_path, file_name_label='across_sessions_parsed_csv_files_path:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "export",
     "CSV",
     "run_main"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import export_across_session_CSVs\n",
    "\n",
    "final_across_session_summary_CSVs_output_path = across_sessions_output_folder.resolve()\n",
    "display(fullwidth_path_widget(final_across_session_summary_CSVs_output_path, file_name_label='final_across_session_summary_CSVs_output_path:'))\n",
    "final_csv_export_paths = export_across_session_CSVs(final_output_path=final_across_session_summary_CSVs_output_path, TODAY_DAY_DATE=TODAY_DAY_DATE,\n",
    "                                                    all_sessions_laps_df=all_sessions_laps_df,  all_sessions_ripple_df=all_sessions_ripple_df,  all_sessions_laps_time_bin_df=all_sessions_laps_time_bin_df,  all_sessions_ripple_time_bin_df=all_sessions_ripple_time_bin_df, \n",
    "                                                    all_sessions_simple_pearson_laps_df=all_sessions_simple_pearson_laps_df,  all_sessions_simple_pearson_ripple_df=all_sessions_simple_pearson_ripple_df,\n",
    "                                                    all_sessions_all_scores_ripple_df=all_sessions_all_scores_ripple_df,  all_sessions_all_scores_laps_df=None,\n",
    "                                                )\n",
    "\n",
    "# final_csv_export_paths: {'AcrossSession_Laps_per-Epoch': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee_AcrossSession_Laps_per-Epoch.csv'),\n",
    "#  'AcrossSession_Ripple_per-Epoch': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee_AcrossSession_Ripple_per-Epoch.csv'),\n",
    "#  'AcrossSession_Laps_per-TimeBin': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee_AcrossSession_Laps_per-TimeBin.csv'),\n",
    "#  'AcrossSession_Ripple_per-TimeBin': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee_AcrossSession_Ripple_per-TimeBin.csv'),\n",
    "#  'AcrossSession_SimplePearson_Laps_per-Epoch': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee_AcrossSession_SimplePearson_Laps_per-Epoch.csv'),\n",
    "#  'AcrossSession_SimplePearson_Ripple_per-Epoch': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee_AcrossSession_SimplePearson_Ripple_per-Epoch.csv'),\n",
    "#  'AcrossSession_AllScores_Ripple_per-Epoch': WindowsPath('K:/scratch/across_sessions/2024-06-05_Apogee_AcrossSession_AllScores_Ripple_per-Epoch.csv')}\n",
    "\n",
    "if neptuner_run is not None:\n",
    "    _neptuner_run_parameters = dict(across_sessions_parsed_csv_files_path=across_sessions_parsed_csv_files_path.as_posix(), final_across_session_summary_CSVs_output_path=final_across_session_summary_CSVs_output_path.as_posix(),\n",
    "                                       )\n",
    "    for k, v in _neptuner_run_parameters.items():\n",
    "        neptuner_run[f'output_files/{k}'] = v\n",
    "    _neptuner_run_parameters = {} # reset after writing\n",
    "\n",
    "    for k, v in final_csv_export_paths.items():\n",
    "        neptuner_run[f\"output_files/{k}\"].upload(v.resolve().as_posix())\n",
    "        \n",
    "    neptuner_run.sync()\n",
    "    \n",
    "final_csv_export_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "print(list(all_sessions_all_scores_ripple_df.columns)) # ['start', 'stop', 'label', 'duration', 'is_user_annotated_epoch', 'is_valid_epoch', 'P_LR', 'P_RL', 'P_Long', 'P_Short', 'P_Long_LR', 'score_long_LR', 'velocity_long_LR', 'intercept_long_LR', 'speed_long_LR', 'wcorr_long_LR', 'pearsonr_long_LR', 'travel_long_LR', 'coverage_long_LR', 'jump_long_LR', 'longest_sequence_length_ratio_long_LR', 'direction_change_bin_ratio_long_LR', 'congruent_dir_bins_ratio_long_LR', 'total_congruent_direction_change_long_LR', 'P_Long_RL', 'score_long_RL', 'velocity_long_RL', 'intercept_long_RL', 'speed_long_RL', 'wcorr_long_RL', 'pearsonr_long_RL', 'travel_long_RL', 'coverage_long_RL', 'jump_long_RL', 'longest_sequence_length_ratio_long_RL', 'direction_change_bin_ratio_long_RL', 'congruent_dir_bins_ratio_long_RL', 'total_congruent_direction_change_long_RL', 'P_Short_LR', 'score_short_LR', 'velocity_short_LR', 'intercept_short_LR', 'speed_short_LR', 'wcorr_short_LR', 'pearsonr_short_LR', 'travel_short_LR', 'coverage_short_LR', 'jump_short_LR', 'longest_sequence_length_ratio_short_LR', 'direction_change_bin_ratio_short_LR', 'congruent_dir_bins_ratio_short_LR', 'total_congruent_direction_change_short_LR', 'P_Short_RL', 'score_short_RL', 'velocity_short_RL', 'intercept_short_RL', 'speed_short_RL', 'wcorr_short_RL', 'pearsonr_short_RL', 'travel_short_RL', 'coverage_short_RL', 'jump_short_RL', 'longest_sequence_length_ratio_short_RL', 'direction_change_bin_ratio_short_RL', 'congruent_dir_bins_ratio_short_RL', 'total_congruent_direction_change_short_RL', 'ripple_start_t', 'long_best_travel', 'short_best_travel', 'travel_diff', 'long_best_coverage', 'short_best_coverage', 'coverage_diff', 'long_best_jump', 'short_best_jump', 'jump_diff', 'long_best_longest_sequence_length_ratio', 'short_best_longest_sequence_length_ratio', 'longest_sequence_length_ratio_diff', 'long_best_direction_change_bin_ratio', 'short_best_direction_change_bin_ratio', 'direction_change_bin_ratio_diff', 'long_best_congruent_dir_bins_ratio', 'short_best_congruent_dir_bins_ratio', 'congruent_dir_bins_ratio_diff', 'long_best_total_congruent_direction_change', 'short_best_total_congruent_direction_change', 'total_congruent_direction_change_diff', 'session_name', 'time_bin_size', 'delta_aligned_start_t']\n",
    "# ['long_best_total_congruent_direction_change', 'short_best_total_congruent_direction_change']\n",
    "['longest_sequence_length_ratio_diff', 'direction_change_bin_ratio_diff', 'congruent_dir_bins_ratio_diff', 'total_congruent_direction_change_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "all_sessions_simple_pearson_ripple_df # 3138 rows × 24 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "all_sessions_simple_pearson_laps_df # 931 rows × 25 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "all_sessions_ripple_df # 17592 rows × 10 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "all_sessions_simple_pearson_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import loadData\n",
    "\n",
    "across_sessions_recomputed_instantaneous_fr_dict = {}\n",
    "\n",
    "for a_session_folder in good_session_concrete_folders:\n",
    "    \n",
    "    curr_pkl = custom_file_types_dict['recomputed_inst_fr_comps'](a_session_folder)\n",
    "    if curr_pkl is not None and (curr_pkl.exists()):\n",
    "        assert curr_pkl.exists()\n",
    "        print(a_session_folder)\n",
    "        print(curr_pkl)\n",
    "        across_sessions_recomputed_instantaneous_fr_dict[a_session_folder.context] = loadData(curr_pkl) # InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "# OUTPUT:  across_sessions_recomputed_instantaneous_fr_dict\n",
    "num_sessions = len(across_sessions_recomputed_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "\n",
    "## Outputs: across_sessions_instantaneous_fr_dict, across_sessions_recomputed_instantaneous_fr_dict\n",
    "across_session_result_long_short_recomputed_inst_firing_rate_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "AcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_recomputed_instantaneous_fr_dict, global_data_root_parent_path=collected_outputs_directory.resolve(),\n",
    "                                                 inst_fr_output_filename=across_session_result_long_short_recomputed_inst_firing_rate_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024-03-02 - Get only the user-annotated ripples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import _split_user_annotated_ripple_df\n",
    "\n",
    "## Bump\n",
    "# input_df = all_sessions_simple_pearson_ripple_df\n",
    "# input_df = all_sessions_all_scores_ripple_df\n",
    "\n",
    "all_sessions_all_scores_ripple_df, (valid_ripple_df, invalid_ripple_df), (user_approved_ripple_df, user_rejected_ripple_df) = _split_user_annotated_ripple_df(all_sessions_all_scores_ripple_df)\n",
    "\n",
    "## 2024-03-14 - 'is_valid_epoch' column\n",
    "# 'is_valid_epoch'\n",
    "## OUTPUTS: valid_ripple_df, invalid_ripple_df, user_approved_ripple_df, user_rejected_ripple_df, (user_annotated_epoch_unique_session_names, unannotated_session_names)\n",
    "user_approved_ripple_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2024-02-29 - 4pm - Filter the events for those meeting wcorr criteria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df: pd.DataFrame = deepcopy(all_sessions_user_annotated_ripple_df)\n",
    "df: pd.DataFrame = deepcopy(valid_ripple_df) # valid epochs, but not just those that the user approved\n",
    "# df: pd.DataFrame = deepcopy(user_approved_ripple_df)\n",
    "\n",
    "## INPUTS: df\n",
    "\n",
    "min_wcorr_threshold: float = 0.33\n",
    "min_wcorr_diff_threshold: float = 0.2\n",
    "\n",
    "# is_included_large_wcorr_diff = np.any((df[['wcorr_abs_diff']].abs() > min_wcorr_diff_threshold), axis=1)\n",
    "is_included_large_wcorr_diff = np.any((df[['wcorr_diff']].abs() > min_wcorr_diff_threshold), axis=1)\n",
    "is_included_high_wcorr = np.any((df[['long_best_wcorr', 'short_best_wcorr']].abs() > min_wcorr_threshold), axis=1)\n",
    "\n",
    "df = df[is_included_high_wcorr]\n",
    "df\n",
    "\n",
    "# wcorr_long_LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_all_scores_ripple_df.time_bin_size.unique() # does not seem to return NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_ripple_time_bin_df.time_bin_size.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_ripple_time_bin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-time bin size version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import build_single_time_bin_size_dfs\n",
    "\n",
    "# Select the periods:\n",
    "# active_all_sessions_all_scores_ripple_df, (active_all_sessions_ripple_df, active_all_sessions_ripple_time_bin_df) = all_sessions_all_scores_ripple_df, (all_sessions_ripple_df, all_sessions_ripple_time_bin_df)\n",
    "active_all_sessions_all_scores_ripple_df, (active_all_sessions_ripple_df, active_all_sessions_ripple_time_bin_df) = filtered_all_sessions_all_scores_ripple_df, (filtered_all_sessions_ripple_df, filtered_all_sessions_ripple_time_bin_df)\n",
    "\n",
    "target_time_bin_size: float = np.nan\n",
    "# target_time_bin_size: float = 0.005 # 0.025 # 0.08222222\n",
    "# target_time_bin_size: float = 0.02\n",
    "# target_time_bin_size: float = 0.025\n",
    "\n",
    "## INPUTS: all_sessions_all_scores_ripple_df, (all_sessions_ripple_df, all_sessions_ripple_time_bin_df)\n",
    "single_time_bin_size_all_sessions_ripple_df, single_time_bin_size_all_sessions_ripple_time_bin_df = build_single_time_bin_size_dfs(all_sessions_all_scores_epochs_df=active_all_sessions_all_scores_ripple_df,\n",
    "                                                                                                            all_sessions_epochs_df=active_all_sessions_ripple_df, all_sessions_epochs_time_bin_df=active_all_sessions_ripple_time_bin_df, target_time_bin_size=target_time_bin_size,\n",
    "                                                                                                            included_columns = ['delta_aligned_start_t', 'is_user_annotated_epoch', 'is_valid_epoch'])\n",
    "\n",
    "                                                                                                            \n",
    "single_time_bin_size_all_sessions_laps_df, single_time_bin_size_all_sessions_laps_time_bin_df = build_single_time_bin_size_dfs(all_sessions_all_scores_epochs_df=all_sessions_simple_pearson_laps_df,\n",
    "                                                                                                            all_sessions_epochs_df=all_sessions_laps_df, all_sessions_epochs_time_bin_df=all_sessions_laps_time_bin_df, target_time_bin_size=target_time_bin_size,\n",
    "                                                                                                            included_columns = ['delta_aligned_start_t',])\n",
    "\n",
    "## OUTPUTS: single_time_bin_size_all_sessions_ripple_df, single_time_bin_size_all_sessions_ripple_time_bin_df\n",
    "## OUTPUTS: single_time_bin_size_all_sessions_laps_df, single_time_bin_size_all_sessions_laps_time_bin_df \n",
    "\n",
    "single_time_bin_size_all_sessions_laps_df\n",
    "\n",
    "\n",
    "# # Recover the important columns from the newer `all_sessions_all_scores_ripple_df`\n",
    "# included_columns = ['delta_aligned_start_t', 'is_user_annotated_epoch', 'is_valid_epoch']  # Added 'delta_aligned_start_t' for the merge\n",
    "# single_time_bin_size_all_sessions_ripple_df = pd.merge(single_time_bin_size_all_sessions_ripple_df, \n",
    "#                      all_sessions_all_scores_ripple_df[included_columns], \n",
    "#                      on='delta_aligned_start_t', \n",
    "#                      how='left')\n",
    "\n",
    "\n",
    "# single_time_bin_size_all_sessions_ripple_df\n",
    "## OUTPUTS: single_time_bin_size_all_sessions_ripple_df, single_time_bin_size_all_sessions_ripple_df\n",
    "# single_time_bin_size_all_sessions_ripple_time_bin_df\n",
    "all_sessions_simple_pearson_laps_df\n",
    "single_time_bin_size_all_sessions_laps_time_bin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS: all_sessions_all_scores_ripple_df, (all_sessions_ripple_df, all_sessions_ripple_time_bin_df)\n",
    "all_sessions_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_ripple_time_bin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🟢🔜 2024-03-28 - AcrossSessionTable (PhoDibaPaper2023 formats) .h5 and figure exports\n",
    "\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table: all tables of the same length, one entry per neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell",
     "run_main"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables, AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_Converter\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchResultDataframeAccessor\n",
    "\n",
    "output_path_suffix: str = '2024-09-12'\n",
    "# inst_fr_output_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{output_path_suffix}.pkl'\n",
    "# inst_fr_output_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{output_path_suffix}_0.0009.pkl' # single time bin size\n",
    "# inst_fr_output_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{output_path_suffix}_0.0015.pkl' # single time bin size\n",
    "# inst_fr_output_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{output_path_suffix}_0.0025.pkl' # single time bin size\n",
    "# inst_fr_output_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{output_path_suffix}_0.025.pkl' # single time bin size\n",
    "inst_fr_output_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{output_path_suffix}_1000.0.pkl' # single time bin size\n",
    "\n",
    "## INPUTS: included_session_contexts, included_h5_paths\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_all_known_tables(included_session_contexts, included_h5_paths, should_restore_native_column_types=True)\n",
    "\n",
    "## different than load_all_combined_tables, which seems to work with `long_short_fr_indicies_analysis_table`\n",
    "# graphics_output_dict |= AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=num_sessions, save_figure=True)\n",
    "\n",
    "## Load all across-session tables from the pickles:\n",
    "output_path_suffix: str = f'{output_path_suffix}'\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.load_all_combined_tables(override_output_parent_path=collected_outputs_directory, output_path_suffix=output_path_suffix) # output_path_suffix=f'2023-10-04-GL-Recomp'\n",
    "# num_sessions = len(neuron_replay_stats_table.session_uid.unique().to_numpy())\n",
    "# print(f'num_sessions: {num_sessions}')\n",
    "num_sessions: int = len(long_short_fr_indicies_analysis_table['session_uid'].unique())\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "\n",
    "inst_fr_output_load_filepath: Path = collected_outputs_directory.joinpath(inst_fr_output_filename).resolve() # single time bin size # non-instantaneous version\n",
    "assert inst_fr_output_load_filepath.exists()\n",
    "# inst_fr_output_filename: str = inst_fr_output_load_filepath.name\n",
    "# across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=inst_fr_output_load_filepath.parent, inst_fr_output_filename=inst_fr_output_filename)\n",
    "\n",
    "graphics_output_dict = AcrossSessionsResults.post_compute_all_sessions_processing(global_data_root_parent_path=collected_outputs_directory, output_path_suffix=output_path_suffix, plotting_enabled=True, output_override_path=Path('../../output'), inst_fr_output_filename=inst_fr_output_filename)\n",
    "\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "\n",
    "# Convert byte strings to regular strings\n",
    "neuron_replay_stats_table = neuron_replay_stats_table.applymap(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "neuron_replay_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "# matplotlib.use('Qt5Agg')\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults, AcrossSessionTables, AcrossSessionsVisualizations\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PaperFigureTwo\n",
    "\n",
    "def _save_matplotlib_fig(matplotlib_output_container: MatplotlibRenderPlots):\n",
    "\n",
    "    a_fig_context = matplotlib_output_container.context\n",
    "    assert len(matplotlib_output_container.saved_figures) == 1\n",
    "    a_saved_fig_path = matplotlib_output_container.saved_figures[0][0]\n",
    "    assert a_saved_fig_path.exists()\n",
    "\n",
    "    if neptuner_run is not None:\n",
    "        a_full_figure_path_key: str = a_fig_context.get_description(separator='/', include_property_names=True, key_value_separator=':') # .replace(' ', '_')\n",
    "        # a_full_figure_path_key: str = a_fig_context.get_description(separator=':', include_property_names=True, key_value_separator='|')\n",
    "        print(f'a_full_figure_path_key: \"{a_full_figure_path_key}\"')\n",
    "        # neptuner_run['outputs']['figures'][f\"{a_full_figure_path_key}\"].upload(a_fig)\n",
    "        neptuner_run['outputs']['figures'][f\"{a_full_figure_path_key}\"].upload(a_saved_fig_path.as_posix())\n",
    "        # neptuner.figures[f\"{a_full_figure_path_key}\"].upload(a_fig)\n",
    "        \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# with matplotlib_configuration_update(is_interactive=False, backend='nbAgg'):\n",
    "# 'collected_outputs/across_session_result_long_short_recomputed_inst_firing_rate_2024-06-11_GL.pkl'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "tiny-test",
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "long_short_fr_indicies_analysis_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_identities_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import pho_stats_bar_graph_t_tests\n",
    "\n",
    "LxC_Laps_T_result, SxC_Laps_T_result, LxC_Replay_T_result, SxC_Replay_T_result = pho_stats_bar_graph_t_tests(across_session_inst_fr_computation)\n",
    "\n",
    "# LxC_Laps_T_result: TtestResult(statistic=5.550057784140024, pvalue=4.394229331160663e-05, df=16)\n",
    "# SxC_Laps_T_result: TtestResult(statistic=-4.50982955925142, pvalue=0.001125880142367611, df=10)\n",
    "# LxC_Replay_T_result: TtestResult(statistic=-0.4086778656072959, pvalue=0.6881937588138113, df=16)\n",
    "# SxC_Replay_T_result: TtestResult(statistic=-3.551930809035679, pvalue=0.0052513298000637825, df=10)\n",
    "\n",
    "\n",
    "\n",
    "# LxC_Replay_T_result is NOT p<0.05 significant (pvalue=0.6882)\n",
    "# SxC_Replay_T_result IS NOT p<0.05 significant (pvalue=0.0052513298000637825)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PaperFigureTwo\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "\n",
    "# %matplotlib inline \n",
    "%matplotlib qt5\n",
    "## Plotting:\n",
    "graphics_output_dict = {}\n",
    "\n",
    "# matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "## 2023-10-04 - Run `AcrossSessionsVisualizations` corresponding to the PhoDibaPaper2023 figures for all sessions\n",
    "## Hacks the `PaperFigureTwo` and `InstantaneousSpikeRateGroupsComputation`\n",
    "global_multi_session_context, _out_aggregate_fig_2 = AcrossSessionsVisualizations.across_sessions_bar_graphs(across_session_inst_fr_computation, num_sessions=num_sessions, enable_tiny_point_labels=False, enable_hover_labels=False, enabled_point_connection_lines=True, save_figure=False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# across_session_inst_fr_computation\n",
    "## Document `InstantaneousSpikeRateGroupsComputation`\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible\n",
    "\n",
    "doc_output_parent_folder = Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\DEVELOPER_NOTES\\DataStructureDocumentation').resolve()\n",
    "Assert.path_exists(doc_output_parent_folder)\n",
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=doc_output_parent_folder, doc_name='InstantaneousSpikeRateGroupsComputation')\n",
    "doc_printer.save_documentation('InstantaneousSpikeRateGroupsComputation', across_session_inst_fr_computation, non_expanded_item_keys=['_reverse_cellID_index_map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=doc_output_parent_folder, doc_name='SingleBarResult')\n",
    "doc_printer.save_documentation('SingleBarResult', across_session_inst_fr_computation.Fig2_Replay_FR[0], non_expanded_item_keys=['_reverse_cellID_index_map'])\n",
    "doc_printer.save_documentation('SingleBarResult', across_session_inst_fr_computation.Fig2_Replay_FR[1], non_expanded_item_keys=['_reverse_cellID_index_map'])\n",
    "doc_printer.save_documentation('SingleBarResult', across_session_inst_fr_computation.Fig2_Replay_FR[2], non_expanded_item_keys=['_reverse_cellID_index_map'])\n",
    "doc_printer.save_documentation('SingleBarResult', across_session_inst_fr_computation.Fig2_Replay_FR[3], non_expanded_item_keys=['_reverse_cellID_index_map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "across_session_inst_fr_computation.get_summary_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "across_sessions_instantaneous_frs_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_keys_if_possible('InstantaneousSpikeRateGroupsComputation', across_session_inst_fr_computation, max_depth=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2024-09-10 - TODO: Filter out the datapoints from the bar plot corresponding to the novel vs. non-novel sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Tuple\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import ConciseSessionIdentifiers\n",
    "\n",
    "# `across_session_inst_fr_computation.Fig2_Replay_FR`\n",
    "\n",
    "novel_Fig2_Replay_FR = deepcopy(across_session_inst_fr_computation.Fig2_Replay_FR)\n",
    "non_novel_Fig2_Replay_FR = deepcopy(across_session_inst_fr_computation.Fig2_Replay_FR)\n",
    "\n",
    "# [0] and [1] both only use LxC_aclus\n",
    "LxC_aclus = deepcopy(across_session_inst_fr_computation.Fig2_Replay_FR[0].LxC_aclus.tolist()) # ['a0s0_109', 'a0s1_3', 'a0s1_29', 'a0s1_103', 'a0s3_90', 'a0s4_91', 'a0s4_95', 'a1s1_23', 'a1s2_25', 'a1s3_14', 'a1s3_30', 'a1s3_32', 'a2s0_8', 'a2s0_27', 'a2s1_27']\n",
    "_LxC_aclus_alt = deepcopy(across_session_inst_fr_computation.Fig2_Replay_FR[1].LxC_aclus.tolist()) # ['a0s0_109', 'a0s1_3', 'a0s1_29', 'a0s1_103', 'a0s3_90', 'a0s4_91', 'a0s4_95', 'a1s1_23', 'a1s2_25', 'a1s3_14', 'a1s3_30', 'a1s3_32', 'a2s0_8', 'a2s0_27', 'a2s1_27']\n",
    "assert _LxC_aclus_alt == LxC_aclus\n",
    "\n",
    "# [2] and [3] both only use SxC_aclus\n",
    "SxC_aclus = deepcopy(across_session_inst_fr_computation.Fig2_Replay_FR[2].SxC_aclus.tolist()) # ['a0s0_109', 'a0s1_3', 'a0s1_29', 'a0s1_103', 'a0s3_90', 'a0s4_91', 'a0s4_95', 'a1s1_23', 'a1s2_25', 'a1s3_14', 'a1s3_30', 'a1s3_32', 'a2s0_8', 'a2s0_27', 'a2s1_27']\n",
    "_SxC_aclus_alt = deepcopy(across_session_inst_fr_computation.Fig2_Replay_FR[3].SxC_aclus.tolist()) # ['a0s0_109', 'a0s1_3', 'a0s1_29', 'a0s1_103', 'a0s3_90', 'a0s4_91', 'a0s4_95', 'a1s1_23', 'a1s2_25', 'a1s3_14', 'a1s3_30', 'a1s3_32', 'a2s0_8', 'a2s0_27', 'a2s1_27']\n",
    "assert _SxC_aclus_alt == SxC_aclus\n",
    "\n",
    "parsed_LxC_aclus_df: pd.DataFrame = ConciseSessionIdentifiers.parse_concise_abbreviated_neuron_identifying_strings(LxC_aclus)\n",
    "# parsed_LxC_aclus_df\n",
    "\n",
    "parsed_SxC_aclus_df: pd.DataFrame = ConciseSessionIdentifiers.parse_concise_abbreviated_neuron_identifying_strings(SxC_aclus)\n",
    "# parsed_SxC_aclus_df\n",
    "\n",
    "# novel_LxC_indicies, non_novel_LxC_indicies = \n",
    "# partition_df(parsed_LxC_aclus_df, partitionColumn='is_session_novel')\n",
    "# partition_df(parsed_SxC_aclus_df, partitionColumn='is_session_novel')\n",
    "\n",
    "novel_LxC_indicies = np.where(parsed_LxC_aclus_df['is_session_novel'])[0]\n",
    "non_novel_LxC_indicies = np.where(np.logical_not(parsed_LxC_aclus_df['is_session_novel']))[0]\n",
    "\n",
    "(novel_LxC_indicies, non_novel_LxC_indicies)\n",
    "\n",
    "novel_SxC_indicies = np.where(parsed_SxC_aclus_df['is_session_novel'])[0]\n",
    "non_novel_SxC_indicies = np.where(np.logical_not(parsed_SxC_aclus_df['is_session_novel']))[0]\n",
    "\n",
    "(novel_SxC_indicies, non_novel_SxC_indicies)\n",
    "\n",
    "## OUTPUTS: (novel_LxC_indicies, non_novel_LxC_indicies), (novel_SxC_indicies, non_novel_SxC_indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_idx: int = 0\n",
    "novel_Fig2_Replay_FR[curr_idx].LxC_aclus = novel_Fig2_Replay_FR[curr_idx].LxC_aclus[novel_LxC_indicies]\n",
    "novel_Fig2_Replay_FR[curr_idx].values = novel_Fig2_Replay_FR[curr_idx].values[novel_LxC_indicies]\n",
    "curr_idx: int = 1\n",
    "novel_Fig2_Replay_FR[curr_idx].LxC_aclus = novel_Fig2_Replay_FR[curr_idx].LxC_aclus[novel_LxC_indicies]\n",
    "novel_Fig2_Replay_FR[curr_idx].values = novel_Fig2_Replay_FR[curr_idx].values[novel_LxC_indicies]\n",
    "curr_idx: int = 2\n",
    "novel_Fig2_Replay_FR[curr_idx].SxC_aclus = novel_Fig2_Replay_FR[curr_idx].SxC_aclus[novel_SxC_indicies]\n",
    "novel_Fig2_Replay_FR[curr_idx].values = novel_Fig2_Replay_FR[curr_idx].values[novel_SxC_indicies]\n",
    "curr_idx: int = 3\n",
    "novel_Fig2_Replay_FR[curr_idx].SxC_aclus = novel_Fig2_Replay_FR[curr_idx].SxC_aclus[novel_SxC_indicies]\n",
    "novel_Fig2_Replay_FR[curr_idx].values = novel_Fig2_Replay_FR[curr_idx].values[novel_SxC_indicies]\n",
    "\n",
    "across_session_inst_fr_computation.Fig2_Replay_FR = novel_Fig2_Replay_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_multi_session_context, _out_aggregate_fig_2 = AcrossSessionsVisualizations.across_sessions_bar_graphs(across_session_inst_fr_computation, num_sessions=num_sessions, enable_tiny_point_labels=True, enable_hover_labels=False, save_figure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## group by 'is_novel_exposure'\n",
    "## for `long_short_fr_indicies_analysis_table`\n",
    "is_novel_partitioned_dfs = dict(zip(*partition_df(long_short_fr_indicies_analysis_table, partitionColumn='is_novel_exposure')))\n",
    "novel_session_uids = is_novel_partitioned_dfs[True]['session_uid'].unique().tolist()\n",
    "non_novel_session_uids = is_novel_partitioned_dfs[False]['session_uid'].unique().tolist()\n",
    "## build dicts:\n",
    "novel_only_inst_fr_dict = {k:v for k, v in across_sessions_instantaneous_fr_dict.items() if k.get_description(separator='|') in novel_session_uids}\n",
    "non_novel_inst_fr_dict = {k:v for k, v in across_sessions_instantaneous_fr_dict.items() if k.get_description(separator='|') not in novel_session_uids}\n",
    "# novel_only_inst_fr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all\n",
    "# graphics_output_dict |= AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=num_sessions, save_figure=False)\n",
    "# split based on session novelty:\n",
    "graphics_output_dict |= AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=is_novel_partitioned_dfs[True], num_sessions=len(novel_session_uids), save_figure=False)\n",
    "graphics_output_dict |= AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=is_novel_partitioned_dfs[False], num_sessions=len(non_novel_session_uids), save_figure=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphics_output_dict |= AcrossSessionsVisualizations.across_sessions_long_and_short_firing_rate_replays_v_laps_figure(neuron_replay_stats_table=neuron_replay_stats_table, num_sessions=num_sessions, save_figure=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=num_sessions) # some global context across all of the sessions, not sure what to put here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=False, backend='AGG')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "matplotlib_output_container: MatplotlibRenderPlots = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=num_sessions, save_figure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "long_short_fr_indicies_analysis_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = long_short_fr_indicies_analysis_table[['x_frs_index', 'y_frs_index']].duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(long_short_fr_indicies_analysis_table[['x_frs_index', 'y_frs_index']].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# long_short_fr_indicies_analysis_table[['x_frs_index']].corrwith(long_short_fr_indicies_analysis_table['y_frs_index']) # long_short_fr_indicies_analysis_table[['x_frs_index']].corrwith(long_short_fr_indicies_analysis_table['y_frs_index'])\n",
    "# Compute correlation and p-value\n",
    "df_cleaned: pd.DataFrame = long_short_fr_indicies_analysis_table[['x_frs_index', 'y_frs_index']].dropna()\n",
    "df_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cleaned.shape)\n",
    "corr, p_value = pearsonr(df_cleaned['x_frs_index'], df_cleaned['y_frs_index'])\n",
    "print(f\"Correlation: {corr}, P-value: {p_value}\")\n",
    "# Correlation: 0.48548405144431905, P-value: 1.0243398539233502e-48\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "graphics_output_dict.saved_figures[0][0] #.plot_data['saved_figures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.media_output_helpers import fig_to_clipboard\n",
    "\n",
    "fig_to_clipboard(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# copy_image_to_clipboard(graphics_output_dict['figures'][0])\n",
    "fig_to_clipboard(matplotlib_output_container.figures[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_long_and_short_firing_rate_replays_v_laps_figure(neuron_replay_stats_table=neuron_replay_stats_table, num_sessions=num_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_save_matplotlib_fig(graphics_output_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "## Load the saved across-session results:\n",
    "# Outputs: across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list, neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table\n",
    "\n",
    "BATCH_DATE_TO_USE = f'2024-09-03'\n",
    "inst_fr_output_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "\n",
    "inst_fr_output_file = collected_outputs_directory.joinpath(inst_fr_output_filename).resolve()\n",
    "Assert.path_exists(inst_fr_output_file)\n",
    "\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=collected_outputs_directory, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import \n",
    "\n",
    "## Load all across-session tables from the pickles:\n",
    "output_path_suffix: str = f'{BATCH_DATE_TO_USE}'\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.load_all_combined_tables(override_output_parent_path=collected_outputs_directory, output_path_suffix=output_path_suffix) # output_path_suffix=f'2023-10-04-GL-Recomp'\n",
    "num_sessions = len(neuron_replay_stats_table.session_uid.unique().to_numpy())\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "# neuron_replay_stats_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptuner.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2024-09-04 - Batch Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_file_metadata\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file, save_copydict_to_text_file, read_copydict_from_text_file, invert_filedict\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import get_file_str_if_file_exists\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import check_output_h5_files, copy_files_in_filelist_to_dest\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import ConcreteSessionFolder, BackupMethods\n",
    "\n",
    "# a_batch_progress_df = included_session_batch_progress_df.copy()\n",
    "included_session_contexts\n",
    "h5_contexts_paths_dict\n",
    "# h5_session_contexts\n",
    "\n",
    "debug_print = False\n",
    "known_global_data_root_parent_paths = [Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/media/halechr/MAX/Data'), Path(r'/Volumes/MoverNew/data')] # , Path(r'/home/halechr/FastData'), Path(r'/home/halechr/turbo/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data')\n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "## Build Pickle Path:\n",
    "# Hardcoded included_session_contexts:\n",
    "included_session_contexts = UserAnnotationsManager.get_hardcoded_good_sessions()\n",
    "good_session_concrete_folders = ConcreteSessionFolder.build_concrete_session_folders(global_data_root_parent_path, included_session_contexts)\n",
    "\n",
    "# Output Paths:\n",
    "included_h5_paths = [get_file_str_if_file_exists(v.pipeline_results_h5) for v in good_session_concrete_folders]\n",
    "# copy_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, backup_mode=BackupMethods.RenameInSourceDirectory, only_include_file_types=['local_pkl', 'global_pkl'])\n",
    "check_output_h5_files(included_h5_paths)\n",
    "\n",
    "## OUTPUTS: included_h5_paths, included_session_contexts, good_session_concrete_folders\n",
    "\n",
    "included_h5_paths\n",
    "\n",
    "\n",
    "RESULT_DATE_TO_USE = '2024-09-04'\n",
    "# RESULT_DATE_TO_USE = '2024-07-02'\n",
    "\n",
    "# included_file_types_paths_dict = {'h5': included_h5_paths, 'recomputed_inst_fr_comps': []}\n",
    "# included_file_types_paths_dict['recomputed_inst_fr_comps'] = [get_file_path_if_file_exists(v.output_folder.joinpath(f'{RESULT_DATE_TO_USE}_recomputed_inst_fr_comps_0.0005.h5').resolve()) for v in good_session_concrete_folders]\n",
    "# included_file_types_paths_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: good_session_concrete_folders, target_dir, BATCH_DATE_TO_USE, custom_file_types_dict\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import get_file_path_if_file_exists\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import copy_session_folder_files_to_target_dir\n",
    "\n",
    "custom_file_types_dict = {'recomputed_inst_fr_comps': (lambda a_session_folder: get_file_path_if_file_exists(a_session_folder.output_folder.joinpath(f'{RESULT_DATE_TO_USE}_recomputed_inst_fr_comps_0.0005.pkl').resolve())),\n",
    "\t\t\t\t\t\t#   'PHONEW.evt': (lambda a_session_folder: get_file_path_if_file_exists(a_session_folder.output_folder.joinpath(f'{a_session_folder.context.session_name}.PHONEW.evt').resolve())),\n",
    "\t\t\t\t\t\t  }\n",
    "\n",
    "# target_dir: Path = Path(global_data_root_parent_path)\n",
    "target_dir: Path = collected_outputs_directory\n",
    "moved_files_dict_files, (filelist_path, filedict_out_path) = copy_session_folder_files_to_target_dir(good_session_concrete_folders, target_dir=target_dir, RESULT_DATE_TO_USE=BATCH_DATE_TO_USE, custom_file_types_dict=custom_file_types_dict, dry_run=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `across_sessions_instantaneous_fr_dict` from the computation outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting via Plotly\n",
    "`!pip install kaleido==\"v0.1.0.post1\" `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.plotly_templates import PlotlyHelpers\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms_across_sessions, plot_stacked_histograms\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_helper_save_figures, _helper_build_figure, plotly_pre_post_delta_scatter, plot_across_sessions_scatter_results\n",
    "\n",
    "# fig_size_kwargs = {'width': 1650, 'height': 480}\n",
    "resolution_multiplier = 1\n",
    "# fig_size_kwargs = {'width': resolution_multiplier*1650, 'height': resolution_multiplier*480}\n",
    "fig_size_kwargs = {'width': resolution_multiplier*1920, 'height': resolution_multiplier*480}\n",
    "is_dark_mode, template = PlotlyHelpers.get_plotly_template(is_dark_mode=False)\n",
    "pio.templates.default = template\n",
    "\n",
    "# figure_export_path = Path(r'E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Presentations\\2024-05-30 - Pho iNAV Poster\\Figures').resolve()\n",
    "# figure_export_path = Path('/Users/pho/Dropbox (Personal)/Active/Kamran Diba Lab/Presentations/2024-05-30 - Pho iNAV Poster/Figures').resolve()\n",
    "\n",
    "# assert figure_export_path.exists()\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from pyphocorehelpers.programming_helpers import copy_image_to_clipboard\n",
    "\n",
    "def save_plotly(a_fig, a_fig_context):\n",
    "    \"\"\" \n",
    "    captures: TODAY_DAY_DATE, figures_folder, neptuner_run\n",
    "    \"\"\"\n",
    "    fig_save_path: Path = figures_folder.joinpath('_'.join([TODAY_DAY_DATE, sanitize_filename_for_Windows(a_fig_context.get_description())])).resolve()\n",
    "    figure_out_paths = {'.html': fig_save_path.with_suffix('.html'), '.png': fig_save_path.with_suffix('.png')}\n",
    "    a_fig.write_html(figure_out_paths['.html'])\n",
    "    display(fullwidth_path_widget(figure_out_paths['.html'], file_name_label='.html'))\n",
    "    # print(file_uri_from_path(figure_out_paths['.html']))\n",
    "    a_fig.write_image(figure_out_paths['.png'])\n",
    "    # print(file_uri_from_path(figure_out_paths['.png']))\n",
    "    display(fullwidth_path_widget(figure_out_paths['.png'], file_name_label='.png'))\n",
    "\n",
    "    if neptuner_run is not None:\n",
    "        a_full_figure_path_key: str = a_fig_context.get_description(separator='/', include_property_names=True, key_value_separator=':') # .replace(' ', '_')\n",
    "        # a_full_figure_path_key: str = a_fig_context.get_description(separator=':', include_property_names=True, key_value_separator='|')\n",
    "        print(f'a_full_figure_path_key: \"{a_full_figure_path_key}\"')\n",
    "        # neptuner_run['outputs']['figures'][f\"{a_full_figure_path_key}\"].upload(a_fig)\n",
    "        neptuner_run['outputs']['figures'][f\"{a_full_figure_path_key}\"].upload(figure_out_paths['.html'].as_posix())\n",
    "        # neptuner.figures[f\"{a_full_figure_path_key}\"].upload(a_fig)\n",
    "        \n",
    "    return figure_out_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'short_best_wcorr', 'long_best_wcorr', 'wcorr_diff'\n",
    "# 'pearsonr_long_LR', 'long_best_wcorr', 'wcorr_diff'\n",
    "all_sessions_all_scores_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_ripple_df = deepcopy(filtered_all_sessions_all_scores_ripple_df)\n",
    "concatenated_ripple_df['session_name'].unique()\n",
    "\n",
    "# ['kdiba_gor01_one_2006-6-08_14-26-15',\n",
    "# 'kdiba_gor01_one_2006-6-08_14-26-15_None',\n",
    "# 'kdiba_gor01_one_2006-6-09_1-22-43',\n",
    "# 'kdiba_gor01_one_2006-6-12_15-55-31',\n",
    "# 'kdiba_gor01_two_2006-6-07_16-40-19',\n",
    "# 'kdiba_gor01_two_2006-6-08_21-16-25',\n",
    "# 'kdiba_gor01_two_2006-6-09_22-24-40',\n",
    "# 'kdiba_pin01_one_11-02_19-28-0',\n",
    "# 'kdiba_pin01_one_fet11-01_12-58-54']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_bins = 25\n",
    "num_sessions = 1\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(df)\n",
    "## INPUTS: all_sessions_all_scores_ripple_df\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(concatenated_ripple_df)\n",
    "# concatenated_ripple_df = deepcopy(all_sessions_ripple_df)\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(filtered_all_sessions_wcorr_ripple_df)\n",
    "\n",
    "concatenated_ripple_df = deepcopy(filtered_all_sessions_all_scores_ripple_df)\n",
    "\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(all_sessions_all_scores_ripple_df)\n",
    "# concatenated_ripple_df = concatenated_ripple_df[concatenated_ripple_df['custom_replay_name'] != ''] # non-custom\n",
    "# concatenated_ripple_df = deepcopy(filtered_all_sessions_all_scores_ripple_df)\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(all_sessions_ripple_time_bin_df)\n",
    "# concatenated_ripple_df = deepcopy(all_sessions_all_scores_ripple_df)\n",
    "# concatenated_ripple_df = deepcopy(single_time_bin_size_all_sessions_ripple_df)\n",
    "display(concatenated_ripple_df)\n",
    "# ['longest_sequence_length_ratio_diff', 'direction_change_bin_ratio_diff', 'congruent_dir_bins_ratio_diff', 'total_congruent_direction_change_diff']\n",
    "\n",
    "\n",
    "# variable_name = 'P_Long'\n",
    "variable_name = 'P_Short' # Shows expected effect - short-only replay prior to delta and then split replays post-delta\n",
    "# variable_name = 'short_best_wcorr'\n",
    "# variable_name = 'long_best_pf_peak_x_pearsonr'\n",
    "# variable_name = 'long_best_jump'\n",
    "# variable_name = 'wcorr_abs_diff'\n",
    "# variable_name = 'pearsonr_abs_diff'\n",
    "# variable_name = 'direction_change_bin_ratio_diff'\n",
    "# variable_name = 'longest_sequence_length_ratio_diff'\n",
    "# variable_name = 'long_best_longest_sequence_length_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'congruent_dir_bins_ratio_diff'\n",
    "# variable_name = 'total_congruent_direction_change_diff'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'long_best_direction_change_bin_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# 'color':'is_user_annotated_epoch'\n",
    "# 'color': 'is_user_annotated_epoch', \n",
    "\n",
    "\n",
    "# concatenated_ripple_df = concatenated_ripple_df[concatenated_ripple_df[variable_name].abs() > 0.25]\n",
    "\n",
    "y_baseline_level: float = 0.5 # for P(short), etc\n",
    "# y_baseline_level: float = 0.0 # for wcorr, etc\n",
    "\n",
    "# px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'color':\"is_user_annotated_epoch\", 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "# px_scatter_kwargs.pop('color')\n",
    "\n",
    "\n",
    "# hist_kwargs = dict(color=\"time_bin_size\")\n",
    "hist_kwargs = dict(color=\"is_user_annotated_epoch\") # , histnorm='probability density'\n",
    "hist_kwargs.pop('color')\n",
    "\n",
    "# px_scatter_kwargs['color'] = 'custom_replay_name'\n",
    "# hist_kwargs['color'] = 'custom_replay_name'\n",
    "\n",
    "\n",
    "# px_scatter_kwargs['color'] = 'session_name'\n",
    "# hist_kwargs['color'] = 'session_name'\n",
    "\n",
    "px_scatter_kwargs['color'] = 'session_experience_rank'\n",
    "hist_kwargs['color'] = 'session_experience_rank'\n",
    "\n",
    "# px_scatter_kwargs['color'] = 'session_experience_orientation_rank'\n",
    "# hist_kwargs['color'] = 'session_experience_orientation_rank'\n",
    "\n",
    "\n",
    "new_fig_ripples, new_fig_ripples_context = plotly_pre_post_delta_scatter(data_results_df=concatenated_ripple_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, hist_kwargs=hist_kwargs, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end), legend_title_text=None, is_dark_mode=is_dark_mode)\n",
    "\n",
    "new_fig_ripples = new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "_extras_output_dict = {}\n",
    "if is_dark_mode:\n",
    "    _extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=y_baseline_level, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "else:\n",
    "    _extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=y_baseline_level, line=dict(color=\"rgba(0.2,0.2,0.2,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "new_fig_ripples_context = new_fig_ripples_context.adding_context_if_missing(num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "figure_out_paths = save_plotly(a_fig=new_fig_ripples, a_fig_context=new_fig_ripples_context)\n",
    "new_fig_ripples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_bins = 25\n",
    "num_sessions = 1\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(filtered_all_sessions_wcorr_ripple_df)\n",
    "concatenated_ripple_df = deepcopy(filtered_all_sessions_simple_pearson_ripple_df) # ['P_LR', 'P_RL', 'P_Long', 'P_Short', 'ripple_idx', 'ripple_start_t', 'P_Long_LR', 'P_Long_RL', 'P_Short_LR', 'P_Short_RL', 'most_likely_decoder_index', 'start', 'stop', 'label', 'duration', 'long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr', 'best_decoder_index', 'session_name', 'time_bin_size', 'delta_aligned_start_t', 'is_user_annotated_epoch', 'is_valid_epoch', 'custom_replay_name', 'epoch_idx', 'long_best_pf_peak_x_pearsonr', 'short_best_pf_peak_x_pearsonr', 'wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL', 'long_best_wcorr', 'short_best_wcorr', 'wcorr_abs_diff', 'pearsonr_abs_diff']\n",
    "\n",
    "print(f'concatenated_ripple_df.columns: {list(concatenated_ripple_df.columns)}')\n",
    "# variable_name = 'P_Long'\n",
    "variable_name = 'P_Short' # Shows expected effect - short-only replay prior to delta and then split replays post-delta\n",
    "# variable_name = 'short_best_wcorr'\n",
    "# variable_name = 'long_best_pf_peak_x_pearsonr'\n",
    "# variable_name = 'long_best_jump'\n",
    "# variable_name = 'wcorr_abs_diff'\n",
    "# variable_name = 'short_best_wcorr'\n",
    "# variable_name = 'wcorr_long_LR'\n",
    "# variable_name = 'pearsonr_abs_diff'\n",
    "# variable_name = 'direction_change_bin_ratio_diff'\n",
    "# variable_name = 'longest_sequence_length_ratio_diff'\n",
    "# variable_name = 'long_best_longest_sequence_length_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'congruent_dir_bins_ratio_diff'\n",
    "# variable_name = 'total_congruent_direction_change_diff'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'long_best_direction_change_bin_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# 'color':'is_user_annotated_epoch'\n",
    "# 'color': 'is_user_annotated_epoch', \n",
    "\n",
    "y_baseline_level: float = 0.5 # for P(short), etc\n",
    "# y_baseline_level: float = 0.0 # for wcorr, etc\n",
    "\n",
    "# px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'color':\"is_user_annotated_epoch\", 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "# px_scatter_kwargs.pop('color')\n",
    "\n",
    "# hist_kwargs = dict(color=\"time_bin_size\")\n",
    "hist_kwargs = dict(color=\"is_user_annotated_epoch\") # , histnorm='probability density'\n",
    "hist_kwargs.pop('color')\n",
    "new_fig_ripples, new_fig_ripples_context = plotly_pre_post_delta_scatter(data_results_df=concatenated_ripple_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, hist_kwargs=hist_kwargs, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end), legend_title_text=None, is_dark_mode=is_dark_mode)\n",
    "\n",
    "new_fig_ripples = new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "\n",
    "_extras_output_dict = {}\n",
    "if is_dark_mode:\n",
    "    _extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=y_baseline_level, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "else:\n",
    "    _extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=y_baseline_level, line=dict(color=\"rgba(0.2,0.2,0.2,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "new_fig_ripples_context = new_fig_ripples_context.adding_context_if_missing(num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "# figure_out_paths = save_plotly(a_fig=new_fig_ripples, a_fig_context=new_fig_ripples_context)\n",
    "new_fig_ripples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_bins = 25\n",
    "num_sessions = 1\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Laps                                                                                                                 #\n",
    "# ==================================================================================================================== #\n",
    "all_sessions_laps_time_bin_df\n",
    "all_sessions_simple_pearson_laps_df\n",
    "\n",
    "\n",
    "concatenated_ripple_df = deepcopy(all_sessions_simple_pearson_laps_df) # ['P_LR', 'P_RL', 'P_Long', 'P_Short', 'ripple_idx', 'ripple_start_t', 'P_Long_LR', 'P_Long_RL', 'P_Short_LR', 'P_Short_RL', 'most_likely_decoder_index', 'start', 'stop', 'label', 'duration', 'long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr', 'best_decoder_index', 'session_name', 'time_bin_size', 'delta_aligned_start_t', 'is_user_annotated_epoch', 'is_valid_epoch', 'custom_replay_name', 'epoch_idx', 'long_best_pf_peak_x_pearsonr', 'short_best_pf_peak_x_pearsonr', 'wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL', 'long_best_wcorr', 'short_best_wcorr', 'wcorr_abs_diff', 'pearsonr_abs_diff']\n",
    "\n",
    "print(f'concatenated_ripple_df.columns: {list(concatenated_ripple_df.columns)}')\n",
    "# variable_name = 'P_Long'\n",
    "variable_name = 'P_Short' # Shows expected effect - short-only replay prior to delta and then split replays post-delta\n",
    "\n",
    "y_baseline_level: float = 0.5 # for P(short), etc\n",
    "# y_baseline_level: float = 0.0 # for wcorr, etc\n",
    "\n",
    "# px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'color':\"is_user_annotated_epoch\", 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': f\"Lap Individual Time Bins - '{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "# px_scatter_kwargs.pop('color')\n",
    "\n",
    "hist_kwargs = dict(color=\"time_bin_size\")\n",
    "# hist_kwargs = dict(color=\"is_user_annotated_epoch\") # , histnorm='probability density'\n",
    "# hist_kwargs.pop('color')\n",
    "new_fig_laps, new_fig_laps_context = plotly_pre_post_delta_scatter(data_results_df=concatenated_ripple_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, hist_kwargs=hist_kwargs, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end), legend_title_text=None, is_dark_mode=is_dark_mode)\n",
    "\n",
    "new_fig_laps = new_fig_laps.update_layout(fig_size_kwargs)\n",
    "\n",
    "_extras_output_dict = {}\n",
    "if is_dark_mode:\n",
    "    _extras_output_dict[\"y_mid_line\"] = new_fig_laps.add_hline(y=y_baseline_level, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "else:\n",
    "    _extras_output_dict[\"y_mid_line\"] = new_fig_laps.add_hline(y=y_baseline_level, line=dict(color=\"rgba(0.2,0.2,0.2,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "\n",
    "fig_to_clipboard(new_fig_laps, **fig_size_kwargs)\n",
    "new_fig_laps_context = new_fig_laps_context.adding_context_if_missing(num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "figure_out_paths = save_plotly(a_fig=new_fig_laps, a_fig_context=new_fig_laps_context)\n",
    "new_fig_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable_name = 'short_best_direction_change_bin_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "variable_name = 'short_best_wcorr'\n",
    "# 'color':'is_user_annotated_epoch'\n",
    "# 'color': 'is_user_annotated_epoch', \n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], , 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "# hist_kwargs = dict(color=\"time_bin_size\")\n",
    "hist_kwargs = dict(color=\"pre_post_delta_category\") # , histnorm='probability density'\n",
    "new_fig_ripples, figure_context = plotly_pre_post_delta_scatter(data_results_df=concatenated_ripple_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, hist_kwargs=hist_kwargs, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end), is_dark_mode=is_dark_mode)\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=0.0, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "new_fig_ripples.show()\n",
    "figure_out_paths = save_plotly(a_fig=new_fig_ripples, a_fig_context=figure_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable_name = 'total_congruent_direction_change_diff'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'long_best_total_congruent_direction_change'\n",
    "variable_name = 'wcorr_diff'\n",
    "# variable_name = 'long_best_wcorr'\n",
    "# 'color':'is_user_annotated_epoch'\n",
    "# 'color': 'is_user_annotated_epoch', \n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'color':\"is_user_annotated_epoch\", 'title': f\"'{variable_name}'\", 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], \n",
    "# hist_kwargs = dict(color=\"time_bin_size\")\n",
    "hist_kwargs = dict(color=\"is_user_annotated_epoch\") # , histnorm='probability density'\n",
    "new_fig_ripples, figure_context = plotly_pre_post_delta_scatter(data_results_df=concatenated_ripple_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, hist_kwargs=hist_kwargs, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end), is_dark_mode=is_dark_mode)\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=0.0, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "new_fig_ripples.show()\n",
    "\n",
    "figure_context = figure_context.adding_context_if_missing(num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "figure_out_paths = save_plotly(a_fig=new_fig_ripples, a_fig_context=figure_context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import _perform_stats_tests\n",
    "\n",
    "stats_variable_name: str = 'P_Short'\n",
    "# stats_variable_name: str = 'short_best_direction_change_bin_ratio'\n",
    "# stats_variable_name: str = 'short_best_wcorr'\n",
    "\n",
    "shuffle_results, p_value, f_value, (dof1, dof2), (variance1, variance2) = _perform_stats_tests(deepcopy(concatenated_ripple_df), stats_variable_name=stats_variable_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that wcorr in both periods is higher than shuffles\n",
    "\n",
    "stats_variable_name: str = 'P_Short'\n",
    "stats_variable_name = 'short_best_wcorr'\n",
    "# stats_variable_name = 'long_best_wcorr'\n",
    "# stats_variable_name = 'long_best_wcorr'\n",
    "\n",
    "\n",
    "\n",
    "shuffle_results, p_value, f_value, (dof1, dof2), (variance1, variance2) = _perform_stats_tests(deepcopy(concatenated_ripple_df), stats_variable_name=stats_variable_name)\n",
    "\n",
    "\n",
    "# stats_variable_name: \"short_best_wcorr\" -- actual_diff_means: -0.00983910691641765\n",
    "# stats_variable_name: short_best_wcorr\n",
    "# Statistics=72308.00, p=0.73\n",
    "# Do not Reject Null Hypothesis (No significant difference between two samples)\n",
    "# Variance 1: 0.1395112660465373\n",
    "# Variance 2: 0.18436187114204847\n",
    "# Degree of freedom 1: 395\n",
    "# Degree of freedom 2: 359\n",
    "# F-statistic: 0.756725157877388\n",
    "# p-value: 0.003419223265796241\n",
    "\n",
    "# stats_variable_name: \"long_best_wcorr\" -- actual_diff_means: -0.0028337579937901397\n",
    "# stats_variable_name: long_best_wcorr\n",
    "# Statistics=71529.00, p=0.93\n",
    "# Do not Reject Null Hypothesis (No significant difference between two samples)\n",
    "# Variance 1: 0.1659575407149896\n",
    "# Variance 2: 0.20687539745971859\n",
    "# Degree of freedom 1: 395\n",
    "# Degree of freedom 2: 359\n",
    "# F-statistic: 0.8022101359215698\n",
    "# p-value: 0.016221081810852238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## User non-selected:\n",
    "scatter_title = f'user_approved_ripple_df Several Sessions {variable_name}'\n",
    "# variable_name = 'wcorr_abs_diff'\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': scatter_title, 'range_y': [0.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size'}} # , 'color': 'time_bin_size'\n",
    "new_fig_ripples, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(user_approved_ripple_df), out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end), is_dark_mode=is_dark_mode)\n",
    "_extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "new_fig_ripples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEA: The ones with clear replays (diagonal sequences in the decoded posteriors) are by definiition ambiguous, because there's not much difference between the long/short decoders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## User non-selected:\n",
    "scatter_title = f'Non-selected Several Sessions {variable_name}'\n",
    "# variable_name = 'wcorr_abs_diff'\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': scatter_title, 'range_y': [0.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size'}} # , 'color': 'time_bin_size'\n",
    "new_fig_ripples, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(user_rejected_ripple_df), out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end))\n",
    "new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "new_fig_ripples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laps test\n",
    "concatenated_ripple_df = deepcopy(all_sessions_simple_pearson_laps_df)\n",
    "\n",
    "scatter_title = 'Several Sessions'\n",
    "variable_name = 'wcorr_abs_diff'\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': scatter_title, 'range_y': [0.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size'}} \n",
    "new_fig_ripples, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(concatenated_ripple_df), out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end))\n",
    "new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "new_fig_ripples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import PlottingHelpers\n",
    "# from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import plot_across_sessions_scatter_results\n",
    "\n",
    "# Example usage:\n",
    "all_session_figures = plot_across_sessions_scatter_results(collected_outputs_directory, concatenated_laps_df=all_sessions_laps_df, concatenated_ripple_df=all_sessions_ripple_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t#    enabled_time_bin_sizes=[0.03, 0.10],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   laps_title_prefix=f\"Laps\", ripple_title_prefix=f\"Ripples\", save_figures=True, figure_save_extension=['.html','.png'], is_dark_mode=is_dark_mode)\n",
    "fig_laps, fig_ripples = all_session_figures[0]\n",
    "# fig_laps.update_layout(fig_size_kwargs)\n",
    "# fig_ripples.update_layout(fig_size_kwargs)\n",
    "\n",
    "# fig_laps.show()\n",
    "fig_ripples.show()\n",
    "# fig_laps.write_html(f\"../output/{TODAY_DAY_DATE}_AcrossSession_fig_laps.html\")\n",
    "# fig_ripples.write_html(f\"../output/{TODAY_DAY_DATE}_AcrossSession_fig_ripples.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_context = figure_context.adding_context_if_missing(num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_to_clipboard(fig_ripples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## time_bin version:\n",
    "all_time_bin_session_figures = plot_across_sessions_scatter_results(collected_outputs_directory, concatenated_laps_df=all_sessions_laps_time_bin_df, concatenated_ripple_df=all_sessions_ripple_time_bin_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t#    enabled_time_bin_sizes=[0.03, 0.10],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   main_plot_mode='separate_row_per_session',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   laps_title_prefix=f\"Laps_per_time_bin\", ripple_title_prefix=f\"Ripples_per_time_bin\", save_figures=True, figure_save_extension=['.html','.png'], is_dark_mode=is_dark_mode)\n",
    "fig_time_bin_laps, fig_time_bin_ripples = all_time_bin_session_figures[0]\n",
    "# fig_time_bin_laps.show()\n",
    "fig_time_bin_ripples.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test collapsed histograms-only results:\n",
    "histograms_only_all_time_bin_session_figures = plot_across_sessions_scatter_results(collected_outputs_directory, concatenated_laps_df=all_sessions_laps_time_bin_df, concatenated_ripple_df=all_sessions_ripple_time_bin_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t#    enabled_time_bin_sizes=[0.03, 0.10],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# enabled_time_bin_sizes=[0.03, 0.058, 0.10], # [0.03 , 0.044, 0.058, 0.072, 0.086, 0.1]\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   main_plot_mode='default',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   laps_title_prefix=f\"Laps_per_time_bin\", ripple_title_prefix=f\"Ripples_per_time_bin\", save_figures=False, figure_save_extension=['.html','.png'])\n",
    "histograms_only_fig_time_bin_laps, histograms_only_fig_time_bin_ripples = histograms_only_all_time_bin_session_figures[0]\n",
    "# histograms_only_fig_time_bin_laps.show()\n",
    "histograms_only_fig_time_bin_ripples.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.subplots as sp\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "all_session_figures = plot_across_sessions_scatter_results(collected_outputs_directory, concatenated_laps_df=single_time_bin_size_all_sessions_laps_df, concatenated_ripple_df=single_time_bin_size_all_sessions_ripple_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t#    enabled_time_bin_sizes=[0.03, 0.10],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   laps_title_prefix=f\"Laps\", ripple_title_prefix=f\"Ripples\", save_figures=True, figure_save_extension=['.html','.png'], is_dark_mode=is_dark_mode, main_plot_mode='default')\n",
    "fig_laps, fig_ripples = all_session_figures[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "\n",
    "# data_results_df: pd.DataFrame = deepcopy(all_sessions_laps_df) # all_sessions_laps_time_bin_df\n",
    "data_results_df: pd.DataFrame = deepcopy(single_time_bin_size_all_sessions_laps_time_bin_df).infer_objects()\n",
    "\n",
    "# histogram_bins = 'auto'\n",
    "histogram_bins: int = 25\n",
    "new_laps_fig, new_laps_fig_context = plotly_pre_post_delta_scatter(data_results_df=data_results_df, out_scatter_fig=fig_laps, histogram_bins=histogram_bins, px_scatter_kwargs=dict(title='Laps'))\n",
    "\n",
    "\n",
    "# new_laps_fig = new_laps_fig.update_layout(fig_size_kwargs, \n",
    "#     xaxis_title=\"X Axis Title\",\n",
    "#     yaxis_title=\"Y Axis Title\",\n",
    "#     legend_title=\"Legend Title\",\n",
    "#     font=dict(\n",
    "#         family=\"Courier New, monospace\",\n",
    "#         size=18,\n",
    "#         color=\"RebeccaPurple\"\n",
    "#     ),\n",
    "# )\n",
    "# Update x-axis labels\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=1)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Delta-aligned Event Time (seconds)\", row=1, col=2)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=3)\n",
    "\n",
    "\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_laps_fig.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "new_laps_fig\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "\n",
    "new_laps_fig_context: IdentifyingContext = new_laps_fig_context.adding_context_if_missing(epoch='laps', num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "figure_out_paths = save_plotly(a_fig=new_laps_fig, a_fig_context=new_laps_fig_context)\n",
    "new_laps_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data_results_df['time_bin_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_results_df[data_results_df['time_bin_size'] == 0.005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib-based versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms_across_sessions, plot_stacked_histograms\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #TODO 2024-06-05 09:15: - [ ] Define save_matplotlib function\n",
    "new_laps_fig_context: IdentifyingContext = new_laps_fig_context.adding_context_if_missing(epoch='laps', num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Spike3D.PendingNotebookCode import plot_stacked_histograms\n",
    "\n",
    "# You can use it like this:'long_best_dir_simple_pearsonr'\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms_across_sessions(data_type='Laps', session_spec='All Sessions', data_results_df=all_sessions_laps_time_bin_df, time_bin_duration_str=\"75 ms\")\n",
    "_out1: \"MatplotlibRenderPlots\" = plot_histograms_across_sessions(data_type='Ripples', session_spec='All Sessions', data_results_df=all_sessions_ripple_time_bin_df, time_bin_duration_str=\"75 ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig_to_clipboard(_out0.figures[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all_sessions_new_laps_df, all_sessions_new_ripple_df\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms_across_sessions(data_type='New Laps', session_spec='All Sessions', data_results_df=all_sessions_new_laps_df, time_bin_duration_str=\"25 ms\")\n",
    "_out1: \"MatplotlibRenderPlots\" = plot_histograms_across_sessions(data_type='New Ripples', session_spec='All Sessions', data_results_df=all_sessions_new_ripple_df, time_bin_duration_str=\"25 ms\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_new_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_sessions_new_laps_df['session_name'].unique()) # 10 sessions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "column_name: str = 'P_Short'\n",
    "\n",
    "# You can use it like this:\n",
    "num_unique_sessions: int = all_sessions_laps_time_bin_df.session_name.nunique(dropna=True) # number of unique sessions, ignoring the NA entries\n",
    "num_unique_time_bins: int = all_sessions_laps_time_bin_df.time_bin_size.nunique(dropna=True)\n",
    "_laps_histogram_out = plot_stacked_histograms(all_sessions_laps_time_bin_df, 'Laps', f'{num_unique_sessions} Sessions', f\"{num_unique_time_bins} tbin sizes\", column_name=column_name)\n",
    "\n",
    "fig_to_clipboard(_laps_histogram_out.figures[0])\n",
    "\n",
    "num_unique_sessions: int = all_sessions_ripple_time_bin_df.session_name.nunique(dropna=True) # number of unique sessions, ignoring the NA entries\n",
    "num_unique_time_bins: int = all_sessions_ripple_time_bin_df.time_bin_size.nunique(dropna=True)\n",
    "_ripple_histogram_out = plot_stacked_histograms(all_sessions_ripple_time_bin_df, 'Ripples', f'{num_unique_sessions} Sessions', f\"{num_unique_time_bins} tbin sizes\", column_name=column_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_ripple_time_bin_df['time_bin_size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_time_bin_size: float = 0.072 # 0.058\n",
    "# active_time_bin_size: float = 0.086\n",
    "# active_time_bin_size: float = 0.1 # looks the most bimodal with as little of an intermediate value as possible.\n",
    "active_time_bin_size: float = 0.13444444 # looks the most bimodal with as little of an intermediate value as possible.\n",
    "_single_time_bin_ripple_histogram_out = plot_stacked_histograms(all_sessions_ripple_time_bin_df[np.isclose(all_sessions_ripple_time_bin_df['time_bin_size'], active_time_bin_size)], 'Ripples', f'{num_unique_sessions} Sessions', f\"tbin: {active_time_bin_size:0.3f}s\", column_name=column_name)\n",
    "fig_to_clipboard(_single_time_bin_ripple_histogram_out.figures[0], bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_to_clipboard(_ripple_histogram_out.figures[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_white",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
