{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed89add9-df17-4537-86bd-efdfeede07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: pho\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "C:\\Users\\pho\\repos\\PhoDibaLab_REM_HiddenMarkovModel\\DEVELOPMENT\\NeuroPyExporting2022\\PhoNeuroPyConvert_ExportAllToPython_MAIN.m\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False\n",
    "import sys\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import hdf5storage # conda install hdf5storage\n",
    "\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatBaseRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "from neuropy.core import DataWriter, NeuronType, Neurons, BinnedSpiketrain, Mua, ProbeGroup, Position, Epoch, Signal, Laps, FlattenedSpiketrains\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "\n",
    "\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible, debug_dump_object_member_shapes\n",
    "# # import PhoPositionalData as pdp\n",
    "# # from pyphoplacecellanalysis.PhoPositionalData. import load_exported, process_data\n",
    "# from pyphoplacecellanalysis.PhoPositionalData.load_exported import *\n",
    "# # from pyphoplacecellanalysis.PhoPositionalData.process_data import process_positionalAnalysis_data, gen_2d_histrogram, get_heatmap_color_vectors, process_chunk_equal_poritions_data, extract_spike_timeseries\n",
    "# from pyphoplacecellanalysis.PhoPositionalData.process_data import *\n",
    "# from pyphoplacecellanalysis.PhoPositionalData.plot_data import *\n",
    "# from pyphoplacecellanalysis.PhoPositionalData.import_data import *\n",
    "# from pyphoplacecellanalysis.PhoPositionalData.load_exported import import_mat_file\n",
    "# from pyphoplacecellanalysis.PhoPositionalData.process_data import process_positionalAnalysis_data, gen_2d_histrogram, get_heatmap_color_vectors, process_chunk_equal_poritions_data, extract_spike_timeseries\n",
    "# from pyphoplacecellanalysis.PhoPositionalData.process_data import process_positionalAnalysis_data, extract_spike_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2fc9c1-1492-426b-a465-9d78d4b21a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drastically improve Python Tracebacks on exceptions:\n",
    "# from rich.traceback import install\n",
    "# install()\n",
    "\n",
    "## Automatic debugger on exception raised\n",
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1ddc233-5f3a-46e7-803b-6177e8312c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RoyMaze1:\n",
    "# mat_import_parent_path = Path(r'R:\\data\\RoyMaze1')\n",
    "mat_import_parent_path = Path(r'R:\\rMBP Python Repos 2022-07-07\\PhoNeuronGillespie2021CodeRepo\\PhoMatlabDataScripting\\ExportedData\\RoyMaze1')\n",
    "# mat_import_parent_path = Path(r'R:\\rMBP Python Repos 2022-07-07\\PhoNeuronGillespie2021CodeRepo\\PhoMatlabDataScripting\\ExportedData\\RoyMaze2')\n",
    "# mat_import_parent_path = Path(r'C:\\Share\\data\\RoyMaze1') # Old one\n",
    "# mat_import_file = r'C:\\Share\\data\\RoyMaze1\\ExportedData.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efaf8954-ddd7-4e6b-a200-3dec5a2dbb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading matlab import file results to R:\\rMBP Python Repos 2022-07-07\\PhoNeuronGillespie2021CodeRepo\\PhoMatlabDataScripting\\ExportedData\\RoyMaze2\\ExportedData\\positionAnalysis.mat... done.\n",
      "Loading matlab import file results to R:\\rMBP Python Repos 2022-07-07\\PhoNeuronGillespie2021CodeRepo\\PhoMatlabDataScripting\\ExportedData\\RoyMaze2\\ExportedData\\spikesAnalysis.mat... done.\n",
      "KeyError: 'spike_cells_ids'\n",
      "\t Valid Keys: ['spike_cells', 'spike_matrix']\n",
      "KeyError: 'shank'.\n",
      "\\t Did you export from Pho 2022-07-08 Extra fields exported from `C:\\Users\\pho\\repos\\PhoDibaLab_REM_HiddenMarkovModel\\DEVELOPMENT\\NeuroPyExporting2022\\PhoNeuroPyConvert_ExportSpikesToPython.m`\n",
      "\t Valid Keys: ['spike_cells', 'spike_matrix']\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'cell_ids' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m session \u001b[38;5;241m=\u001b[39m \u001b[43mHiroDataSessionFormatRegisteredClass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasedir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmat_import_parent_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m session\n",
      "File \u001b[1;32mc:\\users\\pho\\repos\\neuropy\\neuropy\\core\\session\\Formats\\BaseDataSessionFormats.py:124\u001b[0m, in \u001b[0;36mDataSessionFormatBaseRegisteredClass.get_session\u001b[1;34m(cls, basedir)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_session\u001b[39m(\u001b[38;5;28mcls\u001b[39m, basedir):\n\u001b[0;32m    123\u001b[0m     _test_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_session(Path(basedir))\n\u001b[1;32m--> 124\u001b[0m     _test_session, loaded_file_record_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_test_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _test_session\n",
      "File \u001b[1;32mc:\\users\\pho\\repos\\neuropy\\neuropy\\core\\session\\Formats\\Specific\\HiroDataSessionFormat.py:178\u001b[0m, in \u001b[0;36mHiroDataSessionFormatRegisteredClass.load_session\u001b[1;34m(cls, session, debug_print)\u001b[0m\n\u001b[0;32m    166\u001b[0m session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_fallback_recinfo(session\u001b[38;5;241m.\u001b[39mbasepath\u001b[38;5;241m.\u001b[39mjoinpath(session\u001b[38;5;241m.\u001b[39mname), session)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# remaining_required_filespecs = {k: v for k, v in session.config.resolved_required_filespecs_dict.items() if k not in loaded_file_record_list}\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# if debug_print:\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m#     print(f'remaining_required_filespecs: {remaining_required_filespecs}')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m#         session = file_spec.session_load_callback(file_path, session)\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m#         loaded_file_record_list.append(file_path)\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m all_vars \u001b[38;5;241m=\u001b[39m \u001b[43mHiroDataSessionFormatRegisteredClass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_all_mats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m## Adds Session.paradigm (Epochs)\u001b[39;00m\n\u001b[0;32m    181\u001b[0m session_absolute_start_timestamp \u001b[38;5;241m=\u001b[39m all_vars\u001b[38;5;241m.\u001b[39mextras\u001b[38;5;241m.\u001b[39mbehavioral_epochs\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_seconds_absolute\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# 68368.714228\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\pho\\repos\\neuropy\\neuropy\\core\\session\\Formats\\Specific\\HiroDataSessionFormat.py:338\u001b[0m, in \u001b[0;36mHiroDataSessionFormatRegisteredClass._load_all_mats\u001b[1;34m(cls, parent_path)\u001b[0m\n\u001b[0;32m    335\u001b[0m pos_vars \u001b[38;5;241m=\u001b[39m DynamicContainer(t\u001b[38;5;241m=\u001b[39mt,x\u001b[38;5;241m=\u001b[39mx,y\u001b[38;5;241m=\u001b[39my,speeds\u001b[38;5;241m=\u001b[39mspeeds,dt\u001b[38;5;241m=\u001b[39mdt,dx\u001b[38;5;241m=\u001b[39mdx,dy\u001b[38;5;241m=\u001b[39mdy)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# Import the spikes: NOTE: Currently only using the 'spike_list' and not 'spike_matrix', 'spike_cells', etc.\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m spike_cells, num_cells, spike_list, spike_positions_list, flat_cell_ids, reverse_cellID_idx_lookup_map, spikes_cell_info_out_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_import_spikes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat_import_parent_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmat_import_parent_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m spikes_vars \u001b[38;5;241m=\u001b[39m DynamicContainer(spike_cells\u001b[38;5;241m=\u001b[39mspike_cells, num_cells\u001b[38;5;241m=\u001b[39mnum_cells, spike_list\u001b[38;5;241m=\u001b[39mspike_list, spike_positions_list\u001b[38;5;241m=\u001b[39mspike_positions_list, flat_cell_ids\u001b[38;5;241m=\u001b[39mflat_cell_ids, reverse_cellID_idx_lookup_map\u001b[38;5;241m=\u001b[39mreverse_cellID_idx_lookup_map, spikes_cell_info_out_dict\u001b[38;5;241m=\u001b[39mDynamicContainer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mspikes_cell_info_out_dict))\n\u001b[0;32m    341\u001b[0m behavioral_periods, behavioral_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mperform_import_extras(mat_import_parent_path\u001b[38;5;241m=\u001b[39mmat_import_parent_path)\n",
      "File \u001b[1;32mc:\\users\\pho\\repos\\neuropy\\neuropy\\core\\session\\Formats\\Specific\\HiroDataSessionFormat.py:435\u001b[0m, in \u001b[0;36mHiroDataSessionFormatRegisteredClass.perform_import_spikes\u001b[1;34m(cls, t, x, y, mat_import_parent_path, debug_print)\u001b[0m\n\u001b[0;32m    430\u001b[0m     spikes_cell_info_out_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# print('spike_matrix: {}, spike_cells: {}'.format(np.shape(spike_matrix), np.shape(spike_cells)))\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# num_cells = np.shape(spike_matrix)[0]        \u001b[39;00m\n\u001b[1;32m--> 435\u001b[0m num_cells \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mcell_ids\u001b[49m)\n\u001b[0;32m    437\u001b[0m \u001b[38;5;66;03m# extract_spike_timeseries(spike_cells[8])\u001b[39;00m\n\u001b[0;32m    438\u001b[0m spike_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mextract_spike_timeseries(spike_cell) \u001b[38;5;28;01mfor\u001b[39;00m spike_cell \u001b[38;5;129;01min\u001b[39;00m spike_cells]\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'cell_ids' referenced before assignment"
     ]
    }
   ],
   "source": [
    "session = HiroDataSessionFormatRegisteredClass.get_session(basedir=mat_import_parent_path)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e531a7-219d-469f-93e9-f719e5dcd86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895c1836-6734-4deb-ad8e-7b955f6cc69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630cecee-6455-495d-add7-0e3da7e4c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.epochs.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd99344b-ffc6-4677-af94-3f2e11ae86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Extended properties:\n",
    "session = HiroDataSessionFormatRegisteredClass._default_extended_postload(session.filePrefix, session)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4f63f3-f699-48d9-8fc1-a8cc9e3a5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_file_suffix = '.flattened.spikes.npy'\n",
    "active_file_suffix = '.flattened.spikes.npy'\n",
    "found_datafile = session.filePrefix.with_suffix(active_file_suffix)\n",
    "print(f'found_datafile: {str(found_datafile)} -- exists? {found_datafile.exists()}')\n",
    "\n",
    "# if found_datafile is not None:\n",
    "#     print('Loading success: {}.'.format(active_file_suffix))\n",
    "#     session.flattened_spiketrains = found_datafile\n",
    "# else:\n",
    "#     # Otherwise load failed, perform the fallback computation\n",
    "#     print('Failure loading {}. Must recompute.\\n'.format(active_file_suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f0011-0e99-4a1e-b551-f05585212514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or compute linear positions if needed:\n",
    "session = HiroDataSessionFormatRegisteredClass._default_compute_linear_position_if_needed(session)\n",
    "# debug_print = True\n",
    "# # compute linear positions:\n",
    "# print('Computing linear positions for all active epochs for session...', end=' ')\n",
    "# # end result will be session.computed_traces of the same length as session.traces in terms of frames, with all non-maze times holding NaN values\n",
    "# session.position.linear_pos = np.full_like(session.position.time, np.nan)\n",
    "# for anEpochLabelName in session.epochs.labels:\n",
    "#     if anEpochLabelName in ['track']:\n",
    "#         curr_active_epoch_timeslice_indicies, active_positions_maze1, linearized_positions_maze1 = DataSession.compute_linearized_position(session, epochLabelName=anEpochLabelName, method='pca')\n",
    "#         # session.position.linear_pos[curr_active_epoch_timeslice_indicies] = linearized_positions_maze1.traces\n",
    "#         if debug_print:\n",
    "#             print('\\t curr_active_epoch_timeslice_indicies: {}\\n \\t np.shape(curr_active_epoch_timeslice_indicies): {}'.format(curr_active_epoch_timeslice_indicies, np.shape(curr_active_epoch_timeslice_indicies)))\n",
    "\n",
    "#         session.position._data.loc[curr_active_epoch_timeslice_indicies, 'lin_pos'] = linearized_positions_maze1.x\n",
    "#     else:\n",
    "#         if debug_print:\n",
    "#             print(f'\\t skipping non-maze epoch \"{anEpochLabelName}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64344a39-f98e-45c7-ac06-103d27bc501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79733986-d330-4f0a-84bd-c9ce89150154",
   "metadata": {},
   "source": [
    "## Previous Notebook Session-loading implementation before refactoring into HiroDataSessionFormat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cef7e2-039b-4717-898e-6b490544f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = HiroDataSessionFormatRegisteredClass.build_session(basedir=mat_import_parent_path)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063fa0cc-e9f0-47dc-be23-ed389eb98b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session, loaded_file_record_list = DataSessionFormatBaseRegisteredClass.load_session(session, debug_print=True) # call the super class load_session(...) to load the common things (.recinfo, .filePrefix, .eegfile, .datfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d063e-cf61-4369-ae7d-b6c0b7f76885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_vars = load_position_spikes_extras_mats(parent_path=mat_import_parent_path)\n",
    "all_vars = HiroDataSessionFormatRegisteredClass._load_all_mats(parent_path=mat_import_parent_path)\n",
    "# all_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f291d11-8bb6-4e4c-8c3e-7bd56165c1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_vars.extras\n",
    "# print_keys_if_possible('pos', all_vars.pos)\n",
    "print_keys_if_possible('extras', all_vars.extras)\n",
    "# print_keys_if_possible('all_vars', all_vars)\n",
    "# debug_dump_object_member_shapes(all_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80d5c0-3d7a-4b9b-b9cc-29c3a41007d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_vars.extras.behavioral_epochs) # pandas.core.frame.DataFrame\n",
    "print(list(all_vars.extras.behavioral_epochs.columns)) # ['epoch_index', 'start_seconds_absolute', 'end_seconds_absolute', 'start_seconds', 'end_seconds', 'duration']\n",
    "all_vars.extras.behavioral_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f198a781-2fac-4e06-a9b4-85e8b4d1cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adds Session.paradigm (Epochs)\n",
    "session_absolute_start_timestamp = all_vars.extras.behavioral_epochs.loc[0, 'start_seconds_absolute'] # 68368.714228\n",
    "session.config.absolute_start_timestamp = session_absolute_start_timestamp\n",
    "# 'start_seconds' and 'end_seconds' are relative to start\n",
    "if 'label' in all_vars.extras.behavioral_epochs.columns:\n",
    "    epoch_labels = all_vars.extras.behavioral_epochs['label']\n",
    "else:\n",
    "    num_rows = all_vars.extras.behavioral_epochs.shape[0]\n",
    "    epoch_labels = [f'epoch{i}' for i in np.arange(num_rows)]\n",
    "epochs_df = pd.DataFrame({'label':epoch_labels, 'start':all_vars.extras.behavioral_epochs['start_seconds'].to_numpy(),'stop':all_vars.extras.behavioral_epochs['end_seconds'].to_numpy()})\n",
    "session.paradigm = Epoch(epochs=epochs_df)\n",
    "session.paradigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5f826f-2f84-4bfc-afa4-a47ce11c3423",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adds Positions:\n",
    "position_sampling_rate_Hz = 1.0 / np.nanmean(np.diff(all_vars.pos.t)) # 1.0/0.03336651239320582 = 29.97016853950917 Hz\n",
    "session.config.position_sampling_rate_Hz = position_sampling_rate_Hz\n",
    "# session.position = Position(traces=np.vstack((x, y)), computed_traces=np.full([1, num_samples], np.nan), t_start=active_t_start, sampling_rate=position_sampling_rate_Hz)\n",
    "t_rel = all_vars.pos.t\n",
    "x = all_vars.pos.x\n",
    "y = all_vars.pos.y\n",
    "session.position = Position.from_separate_arrays(t_rel, x, y)\n",
    "session.position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb11e244-79ac-4fad-b310-b633cb5e8c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adds Spikes:\n",
    "print(list(all_vars.spikes.keys())) # ['spike_matrix', 'spike_cells', 'num_cells', 'spike_list', 'spike_positions_list', 'flat_cell_ids', 'reverse_cellID_idx_lookup_map', 'spikes_cell_info_out_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a5f516-ff48-4e9c-ab94-14017304d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars.spikes.spike_list[0].shape # (293076,)\n",
    "all_vars.spikes.spike_list[1].shape # (9297,)\n",
    "\n",
    "# len(all_vars.spikes.spike_list) # 126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7da513-e894-4d82-8b20-e6a69539cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.paradigm.t_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812e7e55-cf4e-4959-af66-803d7d008875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_vars.spikes\n",
    "# 'spike_cells'\n",
    "all_vars.spikes.spikes_cell_info_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0a78c-32f9-4b50-ac9a-0c8f04e3f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_cell_ids = all_vars.spikes.spikes_cell_info_out_dict.aclu\n",
    "cell_type = NeuronType.from_qclu_series(qclu_Series=all_vars.spikes.spikes_cell_info_out_dict.qclu)\n",
    "shank_ids = all_vars.spikes.spikes_cell_info_out_dict.shank\n",
    "# cluster_ids = all_vars.spikes.spikes_cell_info_out_dict.cluster # NOT USED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cccd941-2fda-4183-a1f4-34037302993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiketrains = np.array(all_vars.spikes.spike_list, dtype='object')\n",
    "# t_stop = np.max(flat_spikes_out_dict[time_variable_name])\n",
    "t_stop = session.paradigm.t_stop\n",
    "flat_cell_ids = np.array(flat_cell_ids)\n",
    "# all_vars.spikes.spikes_cell_info_out_dict.speculated_unit_type\n",
    "\n",
    "dat_sampling_rate = 30000.0\n",
    "lfpSampleRate = 1250.0\n",
    "posSampleRate = 29.9700\n",
    "\n",
    "session.neurons = Neurons(spiketrains, t_stop, t_start=0,\n",
    "    sampling_rate=dat_sampling_rate, # session.recinfo.dat_sampling_rate\n",
    "    neuron_ids=flat_cell_ids,\n",
    "    neuron_type=cell_type,\n",
    "    shank_ids=shank_ids\n",
    ")\n",
    "session.neurons\n",
    "\n",
    "# Neurons\n",
    "#  n_neurons: 126\n",
    "#  n_total_spikes: 11214527\n",
    "#  t_start: 0\n",
    "#  t_stop: 35351.059333\n",
    "\n",
    "# 'num_cells': 86, 'spike_list', 'reverse_cellID_idx_lookup_map'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039da3ac-0a1f-457a-aefd-197524ebeb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IDEA: Define a series of fallback options for each variable using the command chain pattern."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phoviz_ultimate]",
   "language": "python",
   "name": "conda-env-phoviz_ultimate-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
