{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import neptune # for logging progress and results\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import neptune_output_figures\n",
    "neptune_kwargs = {'project':\"commander.pho/PhoDibaLongShort2023\",\n",
    "'api_token':\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGIxODU2My1lZTNhLTQ2ZWMtOTkzNS02ZTRmNzM5YmNjNjIifQ==\"}\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import CodeConversion\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible, print_value_overview_only, document_active_variables, objsize, print_object_memory_usage, debug_dump_object_member_shapes, TypePrintMode\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "\n",
    "\n",
    "from pyphocorehelpers.print_helpers import generate_html_string\n",
    "\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot, create_daily_programmatic_display_function_testing_folder_if_needed, session_context_to_relative_path\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import batch_load_session, batch_extended_computations, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import build_pyqtgraph_epoch_indicator_regions # Add session indicators to pyqtgraph plot\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _helper_add_long_short_session_indicator_regions\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "# 'time_bin_indices': valid_time_bin_indicies, 'posterior_to_pf_mean_surprise': one_left_out_posterior_to_pf_surprises_mean, 'posterior_to_scrambled_pf_mean_surprise': one_left_out_posterior_to_scrambled_pf_surprises_mean}\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_long_short_expected_vs_observed_firing_rates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_long_short_surprise_difference_plot\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import _update_pipeline_missing_preprocessing_parameters\n",
    "\n",
    "\n",
    "session_batch_status = {}\n",
    "session_batch_errors = {}\n",
    "enable_saving_to_disk = False\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "#     neuropy/data_session_pre_processing_scripts/KDIBA/IIDataMat_Export_ToPython_2022_08_01.m\n",
    "# From pre-computed .mat files:\n",
    "\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "good_contexts_list = [IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-17_12-33-47'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-18_13-6-1'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-18_15-23-32'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-27_14-43-12'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-11_12-48-38'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-11_16-2-46'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_14-49-24'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-19_13-50-7'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-26_13-51-50'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_21-26-8'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-05_19-26-43'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_21-17-16'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-04_21-20-3')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e68b4-03e0-4388-a35c-87a352a6e6b3",
   "metadata": {
    "scrolled": true,
    "tags": [
     "load",
     "single_session",
     "REQUIRED"
    ]
   },
   "outputs": [],
   "source": [
    "%pdb off\n",
    "# %%viztracer\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13\n",
    "curr_context = good_contexts_list[3] # select the session from all of the good sessions here.\n",
    "local_session_parent_path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# # Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# #Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE \n",
    "# force_reload = True\n",
    "\n",
    "    # ==================================================================================================================== #\n",
    "    # Load Pipeline                                                                                                        #\n",
    "    # ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_whitelist = ['maze']\n",
    "epoch_name_whitelist = None\n",
    "active_computation_functions_name_whitelist=[#'_perform_estimated_epochs_computation', \n",
    "                                            '_perform_baseline_placefield_computation',\n",
    "                                        # '_perform_time_dependent_placefield_computation',\n",
    "                                        '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        # '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding'\n",
    "                                    ]\n",
    "# active_computation_functions_name_whitelist=['_perform_baseline_placefield_computation']\n",
    "\n",
    "curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_whitelist=epoch_name_whitelist,\n",
    "                                        computation_functions_name_whitelist=active_computation_functions_name_whitelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        curr_active_pipeline.load_pickled_global_computation_results()\n",
    "    except Exception as e:\n",
    "        print(f'cannot load global results: {e}')\n",
    "\n",
    "# 6m 1.1s\n",
    "# 12m 15.6s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a29b890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Post Compute Validate 2023-05-16:\n",
    "from scripts.run_BatchAnalysis import post_compute_validate\n",
    "\n",
    "post_compute_validate(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f4bc79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2023-01-* - Call extended computations to build `_display_short_long_firing_rate_index_comparison` figures:\n",
    "extended_computations_include_whitelist=['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses'] # do only specifiedl\n",
    "# extended_computations_include_whitelist=['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis'] # do only specifiedl\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_whitelist=extended_computations_include_whitelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=True, debug_print=False)\n",
    "if len(newly_computed_values) > 0:\n",
    "\tprint(f'newly_computed_values: {newly_computed_values}. Saving global results...')\n",
    "\ttry:\n",
    "\t\t# Try to write out the global computation function results:\n",
    "\t\tcurr_active_pipeline.save_global_computation_results()\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f'!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "\t\tprint(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!')\n",
    "else:\n",
    "\tprint(f'no changes in global results.')\n",
    "# 10m 29.5s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6e13d31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Pipeline Loading/Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: versioning pickles with date?\n",
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "save_time = datetime.now()\n",
    " \n",
    "print(\"save_time =\", save_time)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = save_time.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(\"date and time =\", dt_string)\n",
    "\n",
    "# save_time = date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c17a70f",
   "metadata": {},
   "source": [
    "#### 2023-05-26 - On only updating/appending the pickle file instead of having to re-write the whole 30GB+ thing\n",
    "The pickle file format is a sequential format. Thus, if you change one item, at least everything behind that position in the file has to be rewritten.\n",
    "\n",
    "Also see: https://docs.python.org/3.6/library/shelve.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d64a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter, print_filesystem_file_size, print_object_memory_usage, print_keys_if_possible, debug_dump_object_member_shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a9f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_object_memory_usage(curr_active_pipeline)\n",
    "# print_keys_if_possible(\"curr_active_pipeline._stage\", curr_active_pipeline._stage, max_depth=1, non_expanded_item_keys=['display_output'], additional_excluded_item_classes=['DynamicParameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944d3fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=Path('/home/halechr/repo/Spike3D/EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation'), doc_name='NeuropyPipeline')\n",
    "doc_printer.save_documentation('NeuropyPipeline', curr_active_pipeline, non_expanded_item_keys=['stage','_reverse_cellID_index_map', 'pf_listed_colormap', 'computation_results', 'active_configs', 'logger', 'plot', '_plot_object', 'display_output'],\n",
    "                               additional_excluded_item_classes=[\"<class 'pyphoplacecellanalysis.General.Pipeline.Stages.Display.Plot'>\"], max_depth=16) # 'Logger'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec5043",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE) # AttributeError: 'PfND_TimeDependent' object has no attribute '_included_thresh_neurons_indx'\n",
    "# TypeError: cannot pickle 'MplMultiTab' object\n",
    "# PicklingError: Can't pickle .set_closure_cell at 0x000002BF248F50D0>: it's not found as attr._compat.make_set_closure_cell..set_closure_cell\n",
    "# TypeError: cannot pickle 'PyQt5.QtCore.pyqtSignal' object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2bd0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results() # PicklingError: Can't pickle .set_closure_cell at 0x000002BF248F50D0>: it's not found as attr._compat.make_set_closure_cell..set_closure_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e894282",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.load_pickled_global_computation_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6274bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_active_pipeline.display_output_history_list\n",
    "curr_active_pipeline.display_output.clear()\n",
    "# curr_active_pipeline.display_output = DynamicParameters()\n",
    "# curr_active_pipeline.display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae39cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE)\n",
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "\n",
    "# Get existing laps from session:\n",
    "long_laps, short_laps, global_laps = [curr_active_pipeline.filtered_sessions[an_epoch_name].laps.as_epoch_obj() for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_replays, short_replays, global_replays = [Epoch(curr_active_pipeline.filtered_sessions[an_epoch_name].replay.epochs.get_valid_df()) for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "# short_laps.n_epochs: 40, long_laps.n_epochs: 40\n",
    "# short_replays.n_epochs: 6, long_replays.n_epochs: 8\n",
    "\n",
    "print(f'short_laps.n_epochs: {short_laps.n_epochs}, long_laps.n_epochs: {long_laps.n_epochs}')\n",
    "print(f'short_replays.n_epochs: {short_replays.n_epochs}, long_replays.n_epochs: {long_replays.n_epochs}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c850782f",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda48261",
   "metadata": {
    "tags": [
     "load",
     "ACTIVE"
    ]
   },
   "outputs": [],
   "source": [
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "## Extract variables from results object:\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global\n",
    "\n",
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35dbb4d2-0e85-45b8-8794-34d1bea96c0d",
   "metadata": {},
   "source": [
    "# Display Functions Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e308ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "batch_extended_programmatic_figures(curr_active_pipeline=curr_active_pipeline)\n",
    "# \n",
    "\n",
    "\n",
    "_out = curr_active_pipeline.display('_display_long_short_laps', curr_active_pipeline.sess.get_context())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee06cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_output_figures(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1245ff74-29c9-4410-9b31-99203502bdf6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# `attrs` object shape specifications, updating `LeaveOneOutDecodingAnalysisResult`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047dd77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import fields, fields_dict, asdict\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import LeaveOneOutDecodingAnalysisResult, TimebinnedNeuronActivity, LeaveOneOutDecodingResult\n",
    "\n",
    "LeaveOneOutDecodingAnalysisResult.__annotations__\n",
    "\n",
    "\n",
    "type(long_results_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba31db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fields(C).x.metadata\n",
    "\n",
    "# fields(C).x.metadata\n",
    "\n",
    "def _filter_obj_attribute(an_attr, attr_value):\n",
    "\t\"\"\" return attributes only if they have n_neurons in their shape metadata \"\"\"\n",
    "\treturn ('n_neurons' in an_attr.metadata.get('shape', ()))\n",
    "\n",
    "# Find all fields that contain a 'n_neurons':\n",
    "neuron_indexed_attributes = [a_field for a_field in fields(type(long_results_obj)) if ('n_neurons' in a_field.metadata.get('shape', ()))]\n",
    "# neuron_shape_index_for_attributes = [a_field.metadata['shape'].index('n_neurons') for a_field in neuron_indexed_attributes]\n",
    "neuron_shape_index_for_attribute_name_dict = {a_field.name:a_field.metadata['shape'].index('n_neurons') for a_field in neuron_indexed_attributes} # need the actual attributes so that we can get the .metadata['shape'] from them and find the n_neurons index location\n",
    "neuron_shape_index_for_attribute_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d674f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_specifying_fields = {a_field.name:a_field.metadata.get('shape', None) for a_field in fields(type(long_results_obj)) if a_field.metadata.get('shape', None) is not None}\n",
    "shape_specifying_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_temp_obj_dict = asdict(long_results_obj, filter=_filter_obj_attribute)\n",
    "_temp_obj_dict = {k:v.take(indices=aclu_is_included, axis=neuron_shape_index_for_attribute_name_dict[k]) for k, v in _temp_obj_dict.items()} # filter the n_neurons axis containing items to get a reduced dictionary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def sliced_by_aclus(self, aclus):\n",
    "# \t\"\"\" returns a copy of itself sliced by the aclus provided. \"\"\"\n",
    "# \tfrom attrs import asdict, fields, evolve\n",
    "# \taclu_is_included = np.isin(self.original_1D_decoder.neuron_IDs, aclus)  #.shape # (104, 63)\n",
    "# \tdef _filter_obj_attribute(an_attr, attr_value):\n",
    "# \t\t\"\"\" return attributes only if they have n_neurons in their shape metadata \"\"\"\n",
    "# \t\treturn ('n_neurons' in an_attr.metadata.get('shape', ()))            \n",
    "# \t_temp_obj_dict = asdict(self, filter=_filter_obj_attribute)\n",
    "# \t# Find all fields that contain a 'n_neurons':\n",
    "# \tneuron_indexed_attributes = [a_field for a_field in fields(type(self)) if ('n_neurons' in a_field.metadata.get('shape', ()))]\n",
    "# \t# neuron_shape_index_for_attributes = [a_field.metadata['shape'].index('n_neurons') for a_field in neuron_indexed_attributes]\n",
    "# \tneuron_shape_index_for_attribute_name_dict = {a_field.name:a_field.metadata['shape'].index('n_neurons') for a_field in neuron_indexed_attributes} # need the actual attributes so that we can get the .metadata['shape'] from them and find the n_neurons index location\n",
    "# \t_temp_obj_dict = {k:v.take(indices=aclu_is_included, axis=neuron_shape_index_for_attribute_name_dict[k]) for k, v in _temp_obj_dict.items()} # filter the n_neurons axis containing items to get a reduced dictionary\n",
    "# \treturn evolve(self, **_temp_obj_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_decoder_result.most_likely_position_indicies_list: list<np.ndarray<(1, epoch_num_time_bins[epoch_idx])>>[num_epochs]\n",
    "a_decoder_1D.num_neurons\n",
    "a_decoder_1D.flat_position_size\n",
    "# a_decoder_1D.original_position_data_shape\n",
    "\n",
    "# a_decoder_1D.F: (flat_position_size, num_neurons)\n",
    "\n",
    "\n",
    "## Decoder Result (DecodedFilterEpochsResult):\n",
    "a_decoder_result.num_filter_epochs\n",
    "\n",
    "\n",
    "# [a_decoder_1D.F[:,np.squeeze(curr_most_likely_position_indicies)] for curr_most_likely_position_indicies in a_decoder_result.most_likely_position_indicies_list] # [decoded_epoch_idx]\n",
    "[a_decoder_1D.F[np.squeeze(curr_most_likely_position_indicies),:] for curr_most_likely_position_indicies in a_decoder_result.most_likely_position_indicies_list] # [decoded_epoch_idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "844354b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2023-05-26 - Expected vs Observed firing rates\n",
    "## 2023-05-30 Comments from Kourosh:\n",
    "- concern: is it valid to use the most-likely predicted position for each decoder for this? Isn't it a bit circular because the firing rates determine the likelihood of the position?\n",
    "- sine-rank is equivalent of paired t-test for non-parametric, use that to compare the means for each cell after averaging over replays to remove the noise from that\n",
    "- OPTION: could add a continuous plot that shows the difference between the two decoders and the animal's measured position as a function of time (observed_x - long_decoded_x), (observed_x - short_decoded_x).\n",
    "- [x] Plot just replay-to-replay series, removing the time axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a1c8d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import compute_measured_vs_expected_firing_rates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import simpler_compute_measured_vs_expected_firing_rates\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from nptyping import NDArray, DataFrame, Shape, assert_isinstance, Int, Structure as S\n",
    "import awkward as ak # `simpler_compute_measured_vs_expected_firing_rates` new Awkward array for ragged arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31600914",
   "metadata": {
    "tags": [
     "prototyping",
     "testing_ONLY"
    ]
   },
   "outputs": [],
   "source": [
    "# # Testing breakout for `simpler_compute_measured_vs_expected_firing_rates`:\n",
    "# active_pos_df = active_pos_df\n",
    "# active_filter_epochs = active_filter_epochs\n",
    "# a_decoder_1D: \"BasePositionDecoder\" = decoder_1D_LONG\n",
    "# a_decoder_result: \"DecodedFilterEpochsResult\" = decoder_result_LONG\n",
    "\n",
    "# num_epochs = a_decoder_result.num_filter_epochs\n",
    "\n",
    "# all_cells_decoded_expected_firing_rates_list: List[np.ndarray] = [a_decoder_1D.F[np.squeeze(curr_most_likely_position_indicies),:] for curr_most_likely_position_indicies in a_decoder_result.most_likely_position_indicies_list]\n",
    "\n",
    "# assert len(all_cells_decoded_expected_firing_rates_list) == a_decoder_result.num_filter_epochs # one for each epoch\n",
    "\n",
    "# num_timebins_in_epoch: NDArray[Shape[\"Num_epochs\"], Int] = np.array([np.shape(epoch_values)[0] for epoch_values in all_cells_decoded_expected_firing_rates_list])\n",
    "# num_total_flat_timebins: int = np.sum(num_timebins_in_epoch) # number of timebins across all epochs\n",
    "# flat_epoch_idxs: NDArray[Shape[\"N_total_flat_timebins\"], Int] = np.concatenate([np.repeat(i, np.shape(epoch_values)[0]) for i, epoch_values in enumerate(all_cells_decoded_expected_firing_rates_list)]) # for each time bin repeat the epoch_id so we can recover it if needed\n",
    "\n",
    "# flat_expected_firing_rates: NDArray[Shape[\"N_total_flat_timebins, N_neurons\"], Any] = np.vstack(all_cells_decoded_expected_firing_rates_list)\n",
    "# flat_expected_num_spikes: NDArray[Shape[\"N_total_flat_timebins, N_neurons\"], Any] = flat_expected_firing_rates * a_decoder_result.decoding_time_bin_size\n",
    "# flat_observed_num_spikes: NDArray[Shape[\"N_total_flat_timebins, N_neurons\"], Any] = np.hstack(a_decoder_result.spkcount).T\n",
    "# flat_observed_from_expected_difference: NDArray[Shape[\"N_total_flat_timebins, N_neurons\"], Any] = flat_expected_num_spikes - flat_observed_num_spikes\n",
    "\n",
    "\n",
    "# # df = pd.DataFrame(dict(zip(('epoch_idx', 'expected_fr', 'expected_spikes', 'observed_spikes', 'observed_from_expected_diff'), (flat_epoch_idxs, flat_expected_firing_rates, flat_expected_num_spikes, flat_observed_num_spikes, flat_observed_from_expected_difference))))\n",
    "# # all_cells_decoded_expected_firing_rates_arr\n",
    "\n",
    "# ## Awkward Array (Ragged-array) version:\n",
    "# ragged_expected_firing_rates_arr = ak.Array(all_cells_decoded_expected_firing_rates_list) # awkward array\n",
    "# num_timebins_in_epoch = ak.num(ragged_expected_firing_rates_arr, axis=1)\n",
    "# num_total_flat_timebins: int = np.sum(num_timebins_in_epoch)\n",
    "# print(f'num_neurons: {a_decoder_1D.num_neurons}, num_epochs: {num_epochs}, num_total_flat_timebins: {num_total_flat_timebins}')\n",
    "\n",
    "# ragged_expected_num_spikes_arr = ragged_expected_firing_rates_arr * a_decoder_result.decoding_time_bin_size\n",
    "# ragged_observed_from_expected_diff = ragged_expected_num_spikes_arr - ak.Array([v.T for v in a_decoder_result.spkcount])\n",
    "# # ragged_observed_from_expected_diff\n",
    "# # ragged_observed_from_expected_diff_MAXIMUMS = ragged_observed_from_expected_diff[ak.argmax(np.abs(ragged_observed_from_expected_diff), axis=1, keepdims=False)]\n",
    "# # ragged_observed_from_expected_diff_MAXIMUMS\n",
    "# # ragged_expected_num_spikes_arr\n",
    "# # flat_observed_from_expected_diff_MAXIMUMS = ak.flatten(ragged_observed_from_expected_diff_MAXIMUMS, axis=2)\n",
    "\n",
    "# ## By epoch quantities, this is correct:\n",
    "# observed_from_expected_diff_ptp = ak.to_regular(ak.ptp(ragged_observed_from_expected_diff, axis=1)).to_numpy().T # type: 120 * 30 * float64\n",
    "# observed_from_expected_diff_mean = ak.to_regular(ak.mean(ragged_observed_from_expected_diff, axis=1)).to_numpy().T # type: 120 * 30 * float64\n",
    "# observed_from_expected_diff_std = ak.to_regular(ak.std(ragged_observed_from_expected_diff, axis=1)).to_numpy().T # type: 120 * 30 * float64\n",
    "\n",
    "# # ragged_observed_from_expected_diff_MAXIMUMS[0][0][0]\n",
    "# # ragged_observed_from_expected_diff\n",
    "# # ragged_expected_firing_rates_arr[0, 0, :]\n",
    "# # ragged_expected_firing_rates_arr\n",
    "# # flat_observed_from_expected_diff_MAXIMUMS[0,:,0]\n",
    "# # ragged_observed_from_expected_diff_MAXIMUMS.to_list()\n",
    "\n",
    "# # ragged_observed_from_expected_diff_MAXIMUMS.show()\n",
    "\n",
    "# # observed_from_expected_diff_mean\n",
    "# # num_total_flat_timebins\n",
    "\n",
    "# # observed_from_expected_diff_mean.to_list()\n",
    "\n",
    "# # [observed_from_expected_diff_mean[:,i].to_numpy() for i in np.arange(a_decoder_1D.num_neurons)]\n",
    "# observed_from_expected_diff_ptp.shape\n",
    "\n",
    "# # ak.flatten(observed_from_expected_diff_mean[:,i,:], axis=0)\n",
    "# # ak.to_regular(ragged_observed_from_expected_diff_MAXIMUMS, axis=0)\n",
    "# # ak.concatenate(observed_from_expected_diff_mean, axis=1)\n",
    "\n",
    "# # ragged_observed_from_expected_diff_MAXIMUMS[:, 0, :]\n",
    "# # latitude = ragged_observed_from_expected_diff_MAXIMUMS[..., 1]\n",
    "# # longitude, latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ba9abd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Common to both Long and Short:\n",
    "active_pos_df = global_session.position.to_dataframe()\n",
    "assert (long_results_obj.active_filter_epochs.as_array() == short_results_obj.active_filter_epochs.as_array()).all() # ensure that the active_filter_epochs for both are the same.\n",
    "active_filter_epochs = long_results_obj.active_filter_epochs\n",
    "num_epochs = active_filter_epochs.n_epochs\n",
    "\n",
    "## Long Specific:\n",
    "decoder_1D_LONG = long_results_obj.original_1D_decoder\n",
    "decoder_result_LONG = long_results_obj.all_included_filter_epochs_decoder_result\n",
    "# call `compute_measured_vs_expected_firing_rates`\n",
    "decoder_time_bin_centers_LONG, all_epochs_computed_expected_cell_num_spikes_LONG, all_epochs_computed_observed_from_expected_difference_LONG, measured_pos_window_centers_LONG, (all_epochs_decoded_epoch_time_bins_mean_LONG, all_epochs_computed_expected_cell_firing_rates_mean_LONG, all_epochs_computed_expected_cell_firing_rates_stddev_LONG, all_epochs_computed_observed_from_expected_difference_maximum_LONG) = compute_measured_vs_expected_firing_rates(active_pos_df, active_filter_epochs, decoder_1D_LONG, decoder_result_LONG)\n",
    "# The Flat_* versions exist because it's difficult to plot while all of the metrics are separated in lists.\n",
    "Flat_decoder_time_bin_centers_LONG = np.concatenate(decoder_time_bin_centers_LONG) # .shape: (412,)\n",
    "Flat_all_epochs_computed_expected_cell_num_spikes_LONG = np.vstack([np.concatenate([all_epochs_computed_observed_from_expected_difference_LONG[decoded_epoch_idx][target_neuron_IDX, :] for decoded_epoch_idx in np.arange(decoder_result_LONG.num_filter_epochs)]) for target_neuron_IDX in decoder_1D_LONG.neuron_IDXs]) #.shape (20, 22)\n",
    "\n",
    "# call `simpler_compute_measured_vs_expected_firing_rates`\n",
    "returned_shape_tuple_LONG, (observed_from_expected_diff_ptp_LONG, observed_from_expected_diff_mean_LONG, observed_from_expected_diff_std_LONG) = simpler_compute_measured_vs_expected_firing_rates(active_pos_df, active_filter_epochs, a_decoder_1D=decoder_1D_LONG, a_decoder_result=decoder_result_LONG)\n",
    "## Short Specific:\n",
    "decoder_1D_SHORT = short_results_obj.original_1D_decoder\n",
    "decoder_result_SHORT = short_results_obj.all_included_filter_epochs_decoder_result\n",
    "\n",
    "# call `compute_measured_vs_expected_firing_rates`\n",
    "decoder_time_bin_centers_SHORT, all_epochs_computed_expected_cell_num_spikes_SHORT, all_epochs_computed_observed_from_expected_difference_SHORT, measured_pos_window_centers_SHORT, (all_epochs_decoded_epoch_time_bins_mean_SHORT, all_epochs_computed_expected_cell_firing_rates_mean_SHORT, all_epochs_computed_expected_cell_firing_rates_stddev_SHORT, all_epochs_computed_observed_from_expected_difference_maximum_SHORT) = compute_measured_vs_expected_firing_rates(active_pos_df, active_filter_epochs, decoder_1D_SHORT, decoder_result_SHORT)\n",
    "# The Flat_* versions exist because it's difficult to plot while all of the metrics are separated in lists.\n",
    "Flat_decoder_time_bin_centers_SHORT = np.concatenate(decoder_time_bin_centers_SHORT) # .shape: (412,)\n",
    "Flat_all_epochs_computed_expected_cell_num_spikes_SHORT = np.vstack([np.concatenate([all_epochs_computed_observed_from_expected_difference_SHORT[decoded_epoch_idx][target_neuron_IDX, :] for decoded_epoch_idx in np.arange(decoder_result_SHORT.num_filter_epochs)]) for target_neuron_IDX in decoder_1D_SHORT.neuron_IDXs]) #.shape (20, 22)\n",
    "Flat_epoch_time_bins_mean = all_epochs_decoded_epoch_time_bins_mean_SHORT[:,0]\n",
    "\n",
    "# call `simpler_compute_measured_vs_expected_firing_rates`\n",
    "returned_shape_tuple_SHORT, (observed_from_expected_diff_ptp_SHORT, observed_from_expected_diff_mean_SHORT, observed_from_expected_diff_std_SHORT) = simpler_compute_measured_vs_expected_firing_rates(active_pos_df, active_filter_epochs, a_decoder_1D=decoder_1D_SHORT, a_decoder_result=decoder_result_SHORT)\n",
    "\n",
    "## Sanity Checks that the LONG and SHORT decoders and their decoded results aren't identical:\n",
    "assert (Flat_decoder_time_bin_centers_SHORT == Flat_decoder_time_bin_centers_LONG).all()\n",
    "Flat_decoder_time_bin_centers = Flat_decoder_time_bin_centers_LONG # equivalent\n",
    "assert (decoder_1D_LONG.neuron_IDs == decoder_1D_SHORT.neuron_IDs).all()\n",
    "assert not (decoder_1D_LONG.P_x == decoder_1D_SHORT.P_x).all() # the occupancies shouldn't be identical between the two encoders, this might indicate an error\n",
    "assert not (decoder_1D_LONG.F == decoder_1D_SHORT.F).all() # the placefields shouldn't be identical between the two encoders, this might indicate an error\n",
    "\n",
    "print(f\"returned_shape_tuple_LONG: {returned_shape_tuple_LONG}, returned_shape_tuple_SHORT: {returned_shape_tuple_SHORT}\")\n",
    "assert (returned_shape_tuple_LONG[0] == returned_shape_tuple_SHORT[0]) and (returned_shape_tuple_LONG[-1] == returned_shape_tuple_SHORT[-1]) , f\"returned_shape_tuple_LONG: {returned_shape_tuple_LONG}, returned_shape_tuple_SHORT: {returned_shape_tuple_SHORT}\"\n",
    "num_neurons, num_timebins_in_epoch, num_total_flat_timebins = returned_shape_tuple_LONG # after the assert they're guaranteed to be the same for short\n",
    "# assert not np.array([(Flat_all_epochs_computed_expected_cell_num_spikes_LONG[i] == Flat_all_epochs_computed_expected_cell_num_spikes_SHORT[i]).all() for i in np.arange(active_filter_epochs.n_epochs)]).all(), \"all expected number spikes for all cells should not be the same for two different decoders! This likely indicates an error!\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "767fe16d",
   "metadata": {},
   "source": [
    "### 2023-05-26 - MONDAY TODO - Plot the `all_epochs_computed_observed_from_expected_difference_maximum` which should show the change from expectation for each neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07e626f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(all_epochs_computed_observed_from_expected_difference_maximum_LONG) # len(...): 20 (n_epochs)\n",
    "all_epochs_computed_observed_from_expected_difference_maximum_LONG[0].shape # [0].shape: (22, ) (n_cells, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb2906",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "# 2023-05-30 9:30pm - just compute the aggregate stats for the short v long expected firing rates:\n",
    "\n",
    "## Get the epochs that occur on the short and the long tracks:\n",
    "is_short_track_epoch = (Flat_epoch_time_bins_mean >= short_session.t_start)\n",
    "is_long_track_epoch = np.logical_not(is_short_track_epoch)\n",
    "\n",
    "# All comparisons should be (native - alternative), so a positive value (> 0) is expected\n",
    "# analyze the decodings of the events on the short track:\n",
    "short_short_diff = (observed_from_expected_diff_mean_SHORT[:, is_short_track_epoch] - observed_from_expected_diff_mean_LONG[:, is_short_track_epoch])\n",
    "# expect that the short_short decoding is better than the long_short decoding, so short_short_diff should be significantly < 0.0\n",
    "\n",
    "# analyze the decodings of the events on the long track:\n",
    "long_long_diff = (observed_from_expected_diff_mean_LONG[:, is_long_track_epoch] - observed_from_expected_diff_mean_SHORT[:, is_long_track_epoch])\n",
    "\n",
    "# np.mean(long_long_diff)\n",
    "# np.mean(short_short_diff)\n",
    "\n",
    "# ttest_results = scipy.stats.ttest_rel(long_long_diff, short_short_diff)\n",
    "\n",
    "print(f'long_test: {np.mean(long_long_diff)}')\n",
    "print(f'short_test: {np.mean(short_short_diff)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c394bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.efficient_interval_search import determine_event_interval_identity\n",
    "from neuropy.utils.efficient_interval_search import OverlappingIntervalsFallbackBehavior\n",
    "\n",
    "# active_filter_epochs\n",
    "# spk_df = add_epochs_id_identity(spk_df, epochs_df=pbe_epoch_df, epoch_id_key_name='PBE_id', epoch_label_column_name=None, override_time_variable_name='t_seconds', no_interval_fill_value=np.nan) # uses new add_epochs_id_identity method which is general\n",
    "event_interval_identity_arr, interval_timestamp_indicies_lists = determine_event_interval_identity(Flat_epoch_time_bins_mean, curr_active_pipeline.sess.epochs.as_array(), curr_active_pipeline.sess.epochs.to_dataframe().index.to_numpy(), overlap_behavior=OverlappingIntervalsFallbackBehavior.FALLBACK_TO_SLOW_SEARCH)\n",
    "event_interval_identity_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98720e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.geometry_helpers import map_value\n",
    "# Map the times to the epoch index axes:\n",
    "map_value_time_to_epoch_idx_space = lambda v: map_value(v, (Flat_epoch_time_bins_mean[0], Flat_epoch_time_bins_mean[-1]), (0, (num_epochs-1))) # same map\n",
    "track_change_time = short_session.t_start\n",
    "track_change_mapped_idx = map_value_time_to_epoch_idx_space(track_change_time)\n",
    "\n",
    "track_epochs_index_space = deepcopy(curr_active_pipeline.sess.epochs)\n",
    "track_epochs_index_space._df[['start','stop','duration']] = map_value_time_to_epoch_idx_space(track_epochs_index_space._df[['start','stop','duration']]) # convert epochs to array index space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_SHARED = Flat_decoder_time_bin_centers.copy()\n",
    "y_LONG = Flat_all_epochs_computed_expected_cell_num_spikes_LONG.copy()\n",
    "y_SHORT = Flat_all_epochs_computed_expected_cell_num_spikes_SHORT.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfaf1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_SHARED = Flat_epoch_time_bins_mean.copy()\n",
    "y_LONG = all_epochs_computed_observed_from_expected_difference_maximum_LONG.copy()\n",
    "y_SHORT = all_epochs_computed_observed_from_expected_difference_maximum_SHORT.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_SHARED = Flat_epoch_time_bins_mean.copy() # time mode\n",
    "# display_kwargs = dict(x_variable='time', variable='obs_exp_diff_ptp')\n",
    "\n",
    "t_SHARED = np.arange(num_epochs) # one for each epoch if not using time\n",
    "display_kwargs = dict(x_variable='epoch_idx', variable='obs_exp_diff_ptp')\n",
    "\n",
    "y_LONG = observed_from_expected_diff_ptp_LONG.copy()\n",
    "y_SHORT = observed_from_expected_diff_ptp_SHORT.copy()\n",
    "# y_LONG = observed_from_expected_diff_mean_LONG.copy()\n",
    "# y_SHORT = observed_from_expected_diff_mean_SHORT.copy()\n",
    "# assert y_LONG.shape[0] == t_SHARED.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aacaeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import PipelineWithComputedPipelineStageMixin, ComputedPipelineStage\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline\n",
    "\n",
    "curr_active_pipeline.get_session_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9401c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "f## MATPLOTLIB Imports:\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.backends import backend_pdf # for `perform_write_to_file`\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import create_daily_programmatic_display_function_testing_folder_if_needed, session_context_to_relative_path # for `perform_write_to_file`\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_figure_basename_from_display_context, build_pdf_metadata_from_display_context # for `perform_write_to_file`\n",
    "\n",
    "\n",
    "# def get_daily_programmatic_session_output_path(curr_active_pipeline, debug_print=False) -> Path:\n",
    "#     active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "#     # curr_sess_ctx # IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-07_11-26-53')>\n",
    "#     figures_parent_out_path = create_daily_programmatic_display_function_testing_folder_if_needed()\n",
    "#     active_session_figures_out_path = session_context_to_relative_path(figures_parent_out_path, active_identifying_session_ctx)\n",
    "#     if debug_print:\n",
    "#         print(f'curr_session_parent_out_path: {active_session_figures_out_path}')\n",
    "#     active_session_figures_out_path.mkdir(parents=True, exist_ok=True) # make folder if needed\n",
    "#     return active_session_figures_out_path\n",
    "\n",
    "def output_display(curr_active_pipeline, display_fn_name='_display_plot_decoded_epoch_slices', subset_whitelist=None, subset_blacklist=None,  debug_print=False, **kwargs):\n",
    "    \"\"\" 2023-05-31 - Inspired by `programmatic_display_to_PDF` but with aims to make it more general (.png outputs, etc) \"\"\"\n",
    "    ## Get the output path (active_session_figures_out_path) for this session (and all of its filtered_contexts as well):\n",
    "    active_identifying_session_ctx = curr_active_pipeline.get_session_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "    active_session_figures_out_path = curr_active_pipeline.get_daily_programmatic_session_output_path()\n",
    "    \n",
    "    # Get the desired display function context:\n",
    "    active_identifying_display_ctx = active_identifying_session_ctx.adding_context('display_fn', display_fn_name=display_fn_name)\n",
    "    # final_context = active_identifying_display_ctx # Display only context    \n",
    "\n",
    "    # # Add in the desired display variable:\n",
    "    active_identifying_ctx = active_identifying_display_ctx.adding_context('display_kwargs', **kwargs) # , filter_epochs='ripple' ## TODO: this is only right for a single function!\n",
    "    final_context = active_identifying_ctx # Display/Variable context mode\n",
    "\n",
    "    active_identifying_ctx_string = final_context.get_description(separator='|') # Get final discription string\n",
    "    if debug_print:\n",
    "        print(f'active_identifying_ctx_string: \"{active_identifying_ctx_string}\"')\n",
    "\n",
    "    return final_context, active_session_figures_out_path\n",
    "\n",
    "\n",
    "def perform_write_to_file(a_fig, active_identifying_ctx, figures_parent_out_path=None, subset_whitelist=None, subset_blacklist=None, write_pdf=False, write_png=True, progress_print=True, debug_print=False):\n",
    "    \"\"\" Writes a single matplotlib figure out to one or more files based on whether write_png and write_pdf are specified. \n",
    "    \n",
    "    override_active_save_basename=None\n",
    "    \"\"\"\n",
    "    if figures_parent_out_path is None:\n",
    "        figures_parent_out_path = create_daily_programmatic_display_function_testing_folder_if_needed()\n",
    "\n",
    "    active_out_figure_paths = []\n",
    "    \n",
    "    # PDF:\n",
    "    if write_pdf:\n",
    "        try:\n",
    "            active_pdf_metadata, active_pdf_save_filename = build_pdf_metadata_from_display_context(active_identifying_ctx, subset_whitelist=subset_whitelist, subset_blacklist=subset_blacklist)\n",
    "            # print(f'active_pdf_save_filename: {active_pdf_save_filename}')\n",
    "            curr_pdf_save_path = figures_parent_out_path.joinpath(active_pdf_save_filename) # build the final output pdf path from the pdf_parent_out_path (which is the daily folder)\n",
    "        \n",
    "            with backend_pdf.PdfPages(curr_pdf_save_path, keep_empty=False, metadata=active_pdf_metadata) as pdf:\n",
    "                # a_fig = cls._subfn_batch_plot_automated(curr_active_pipeline, **curr_batch_plot_kwargs)\n",
    "                ## TODO UNFINISHED - Have to plot the figure here.\n",
    "                raise NotImplementedError\n",
    "                active_out_figure_paths.append(curr_pdf_save_path)\n",
    "                # Save out PDF page:\n",
    "                pdf.savefig(a_fig)\n",
    "                curr_active_pipeline.register_output_file(output_path=curr_pdf_save_path, output_metadata={'context': active_identifying_ctx, 'fig': (a_fig), 'pdf_metadata': active_pdf_metadata})\n",
    "        except Exception as e:\n",
    "            print(f'Error occured while writing .pdf for fig. {e}. Skipping.')\n",
    "            # raise e\n",
    "\n",
    "    # PNG: .png versions:\n",
    "    if write_png:\n",
    "        # curr_page_str = f'pg{i+1}of{num_pages}'\n",
    "        try:\n",
    "            curr_fig_save_basename = build_figure_basename_from_display_context(active_identifying_ctx, subset_whitelist=subset_whitelist, subset_blacklist=subset_blacklist, context_tuple_join_character='_')\n",
    "            curr_fig_save_path = figures_parent_out_path.joinpath(curr_fig_save_basename)\n",
    "            fig_png_out_path = curr_fig_save_path.with_suffix('.png')\n",
    "            # fig_png_out_path = fig_png_out_path.with_stem(f'{curr_pdf_save_path.stem}_{curr_page_str}') # note this replaces the current .pdf extension with .png, resulting in a good filename for a .png\n",
    "            a_fig.savefig(fig_png_out_path)\n",
    "            curr_active_pipeline.register_output_file(output_path=fig_png_out_path, output_metadata={'context': active_identifying_ctx, 'fig': (a_fig)})\n",
    "            if progress_print:\n",
    "                print(f'\\t saved {fig_png_out_path}')\n",
    "            active_out_figure_paths.append(fig_png_out_path)\n",
    "        except Exception as e:\n",
    "            print(f'Error occured while writing .png for fig. {e}. Skipping.')\n",
    "            # raise e\n",
    "        \n",
    "\n",
    "    return active_out_figure_paths\n",
    "\n",
    "# active_out_figure_paths = perform_write_to_file(a_fig, active_identifying_ctx, figures_parent_out_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fe25ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Begin Function _____________________________________________________________________________________________________ #\n",
    "# @print_args\n",
    "def plot_expected_vs_observed(t_SHARED, y_SHORT, y_LONG, neuron_IDXs, neuron_IDs, track_epochs, sharey=True, figsize=(4, 13), max_num_rows:int=50, shift_offset:int=0, y_scale = \"linear\"):\n",
    "\t\"\"\" 2023-05-31 - plots the expected firing rates for the decoded postions for both the long and short decoder vs. the observed\n",
    "\t\n",
    "\tplots one subplot for each neuron. \n",
    "\n",
    "\t\tt_SHARED, y_LONG, y_SHORT\n",
    "\n",
    "\t\"\"\"\n",
    "\tactive_num_rows = min(num_neurons, max_num_rows)\n",
    "\t# the y-min and max across all cells and time bins:\n",
    "\tglobal_y_max_SHORT = np.max([np.max(v) for v in y_SHORT]) # 0.9280231494040394\n",
    "\tglobal_y_min_SHORT = np.min([np.min(v) for v in y_SHORT]) # -4.850176354048617\n",
    "\tprint(f'global_y_min_SHORT: {global_y_min_SHORT}, global_y_max_SHORT: {global_y_max_SHORT}')\n",
    "\n",
    "\tglobal_y_max_LONG = np.max([np.max(v) for v in y_LONG]) # 0.9280231494040394\n",
    "\tglobal_y_min_LONG = np.min([np.min(v) for v in y_LONG]) # -4.850176354048617\n",
    "\tprint(f'global_y_min_LONG: {global_y_min_LONG}, global_y_max_LONG: {global_y_max_LONG}')\n",
    "\n",
    "\t# the y-min and max across all cells and time bins:\n",
    "\tglobal_y_max = np.max([global_y_max_LONG, global_y_max_SHORT]) # 0.9280231494040394\n",
    "\t# global_y_min = np.min([global_y_min_LONG, global_y_min_SHORT]) # -4.850176354048617\n",
    "\tglobal_y_min = 0.0 # y min is overriden to 0 for peak-to-peak (ptp) mode\n",
    "\tprint(f'global_y_min: {global_y_min}, global_y_max: {global_y_max}')\n",
    "\n",
    "\t# global_x_min, global_x_max = Flat_decoder_time_bin_centers_LONG[0], Flat_decoder_time_bin_centers_LONG[-1]\n",
    "\tglobal_x_min, global_x_max = t_SHARED[0], t_SHARED[-1]\n",
    "\n",
    "\n",
    "\tfig, axes = plt.subplots(ncols=1, nrows=active_num_rows, sharex=True, sharey=sharey, figsize=figsize) # , sharey=True\n",
    "\t# Set the x-axis and y-axis limits of the first subplot, which because sharex=True and sharey=True will set the rest of the plots too. NOTE: setting the axis limits FIRST disables autoscaling which cause problems when adding the epoch region indicator\n",
    "\taxes[0].set_xlim([global_x_min, global_x_max])\n",
    "\taxes[0].set_ylim([global_y_min, global_y_max])\n",
    "\n",
    "\tfor i, ax in enumerate(axes):\n",
    "\t\tshifted_i = shift_offset + i\n",
    "\t\tneuron_IDX = neuron_IDXs[shifted_i]\n",
    "\t\tneuron_id = neuron_IDs[shifted_i]\n",
    "\t\t\n",
    "\t\t# convert y-axis to Logarithmic scale\n",
    "\t\tax.set_yscale(y_scale)\n",
    "\n",
    "\t\t# ax.scatter(Flat_decoder_time_bin_centers, np.concatenate([all_epochs_computed_observed_from_expected_difference[decoded_epoch_idx][neuron_IDX, :] for decoded_epoch_idx in np.arange(decoder_result.num_filter_epochs)]), marker=\"o\",  s=2)\n",
    "\t\t# ax.scatter(Flat_decoder_time_bin_centers, Flat_all_epochs_computed_expected_cell_num_spikes[neuron_IDX], marker=\"o\",  s=2, label=f'long[{neuron_id}]')\n",
    "\t\tax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line\n",
    "\t\t# Per-epoch result:\n",
    "\t\t# ax.scatter(Flat_decoder_time_bin_centers_LONG, Flat_all_epochs_computed_expected_cell_num_spikes_LONG[neuron_IDX], marker=\"o\",  s=2, label=f'Long[{neuron_id}]')\n",
    "\t\t# ax.scatter(Flat_decoder_time_bin_centers_SHORT, Flat_all_epochs_computed_expected_cell_num_spikes_SHORT[neuron_IDX], marker=\"o\",  s=2, label=f'Short[{neuron_id}]')\n",
    "\n",
    "\t\t## Add in the mean epoch difference:\n",
    "\t\t_s_long = ax.scatter(t_SHARED, y_LONG[neuron_IDX, :], marker=\"s\",  s=5, label=f'E<Long[{neuron_id}]>', alpha=0.8)\n",
    "\t\t_s_short = ax.scatter(t_SHARED, y_SHORT[neuron_IDX, :], marker=\"s\",  s=5, label=f'E<Short[{neuron_id}]>', alpha=0.8)\n",
    "\n",
    "\t\tax.set_ylabel(f'{neuron_id}')\n",
    "\t\t\n",
    "\t\tepochs_collection, epoch_labels = draw_epoch_regions(track_epochs, ax, defer_render=False, debug_print=False)\n",
    "\t\t\n",
    "\t# axes[-1].set_xlabel('time')\n",
    "\taxes[-1].set_xlabel('replay idx')\n",
    "\t# axes[-1].legend() # show the legend\n",
    "\n",
    "\taxes[0].legend((_s_long, _s_short), ('E<Long>', 'E<Short>'), loc='lower left', bbox_to_anchor=(0.0, 1.01), ncol=2, borderaxespad=0, frameon=False)\n",
    "\t# plt.legend(bbox_to_anchor=(0.5, 1.2), loc='upper center')\n",
    "\n",
    "\t# (top=0.921, bottom=0.063, left=0.06, right=0.986, hspace=1.0, wspace=0.2)\n",
    "\t# plt.tight_layout()\n",
    "\tplt.suptitle('Expected vs. Observed Firing Rate Differences (by Replay Epoch)', wrap=True)\n",
    "\treturn fig, axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c754028",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "## Settings\n",
    "# sharey = False\n",
    "sharey=True\n",
    "shift_offset = 0 # num aclus to offset\n",
    "# y_scale = \"log\" # ax.set_yscale()\n",
    "y_scale = \"linear\" \n",
    "\n",
    "# track_epochs = curr_active_pipeline.sess.epochs # time space\n",
    "track_epochs = track_epochs_index_space # index space\n",
    "\n",
    "print(f'num_neurons: {num_neurons}')\n",
    "# active_num_rows = min(num_neurons, 20)\n",
    "active_num_rows = num_neurons\n",
    "\n",
    "# figsize=(32,16)\n",
    "figsize=(4, 13) #(24, 8)\n",
    "fig, axes = plot_expected_vs_observed(t_SHARED, y_SHORT, y_LONG, neuron_IDXs=decoder_1D_LONG.neuron_IDXs, neuron_IDs=decoder_1D_LONG.neuron_IDs, track_epochs=track_epochs_index_space, sharey=True, figsize=(4, 13), max_num_rows=150, y_scale=\"linear\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeef8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_context, active_session_figures_out_path = output_display(curr_active_pipeline, display_fn_name='plot_expected_vs_observed', **display_kwargs)\n",
    "\n",
    "active_session_figures_out_path = get_daily_programmatic_session_output_path(curr_active_pipeline)\n",
    "final_context = curr_active_pipeline.sess.get_context().adding_context('display_fn', display_fn_name='plot_expected_vs_observed').adding_context('display_kwargs', **display_kwargs)\n",
    "print(f'final_context: {final_context}')\n",
    "active_out_figure_paths = perform_write_to_file(fig, final_context, figures_parent_out_path=active_session_figures_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3348cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_sess_context = curr_active_pipeline.sess.get_context()\n",
    "## Finally, add the display function to the active context\n",
    "active_identifying_ctx = curr_sess_context.adding_context('display_fn', display_fn_name='long_short_expected_vs_observed_firing')\n",
    "active_identifying_ctx_string = active_identifying_ctx.get_description(separator='|') # Get final discription string:\n",
    "\n",
    "print(f'active_identifying_ctx_string: {active_identifying_ctx_string}')\n",
    "\n",
    "\t\n",
    "# curr_sess_context.\n",
    "# fig.savefig("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab9540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.get_figwidth()\n",
    "fig.get_figheight()\n",
    "# fig.set_figheight()\n",
    "\n",
    "print(f'fig.get_figwidth(): {fig.get_figwidth()}\\nfig.get_figheight(): {fig.get_figheight()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993412e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs_computed_observed_from_expected_difference_LONG[0] #.shape (42, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs_computed_observed_from_expected_difference_maximum_LONG[0] # .shape (42, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs_computed_expected_cell_firing_rates_mean_LONG[0] # .shape (42,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21dbc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs_computed_observed_from_expected_difference_LONG[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c232970",
   "metadata": {},
   "source": [
    "# Rate Remapping Investigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af84b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.neurons import NeuronType\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import compute_rate_remapping_stats\n",
    "rate_remapping_df = compute_rate_remapping_stats(curr_active_pipeline.global_computation_results.computed_data.long_short_fr_indicies_analysis, global_session.neurons.aclu_to_neuron_type_map, considerable_remapping_threshold=0.7)\n",
    "# rate_remapping_df\n",
    "high_remapping_cells_only = rate_remapping_df[rate_remapping_df['has_considerable_remapping']] \n",
    "high_remapping_cells_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9003439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract rr_* variables from rate_remapping_df\n",
    "rr_aclus = rate_remapping_df.index.values\n",
    "rr_laps, rr_replays, rr_skew, rr_neuron_type = [rate_remapping_df[n].values for n in ['laps', 'replays', 'skew', 'neuron_type']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79483e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot using Paginator:\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import RateRemappingPaginatedFigureController\n",
    "\n",
    "## Paginated multi-plot\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context()\n",
    "_out_rr_pagination_controller = RateRemappingPaginatedFigureController.init_from_rr_data(rr_aclus, rr_laps, rr_replays, rr_neuron_type, max_subplots_per_page=20, a_name='TestRateRemappingPaginatedFigureController', active_context=active_identifying_session_ctx)\n",
    "a_paginator = _out_rr_pagination_controller.plots_data.paginator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a16a3469",
   "metadata": {},
   "source": [
    "# Weird Plotting Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_identifying_filtered_session_ctx = global_epoch_context\n",
    "display_output = curr_active_pipeline.display('_display_spike_rasters_window', active_identifying_filtered_session_ctx, type_of_3d_plotter=None) # , type_of_3d_plotter=None\n",
    "spike_raster_window = display_output['spike_raster_window']\n",
    "# Extras:\n",
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "active_3d_plot = spike_raster_window.spike_raster_plt_3d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "main_graphics_layout_widget = active_2d_plot.ui.main_graphics_layout_widget # GraphicsLayoutWidget\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "background_static_scroll_plot_widget = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "\n",
    "# _plot_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cdbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.programming_helpers import IPythonHelpers\n",
    "\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_dict, y_frs_dict = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']\n",
    "# IPythonHelpers.cell_vars(lambda: globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f99839",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_fr_indicies_df = pd.DataFrame({'aclu': list(x_frs_dict.keys()), 'replay_fr_idx': list(x_frs_dict.values()), 'laps_fr_idx': list(y_frs_dict.values())}) # , columns=['aclu','replay_frs']\n",
    "long_short_fr_indicies_df.set_index('aclu', inplace=True)\n",
    "# long_short_fr_indicies_df\n",
    "# long_short_fr_indicies_df.to_clipboard()\n",
    "long_short_fr_indicies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58696b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_fr_indicies_analysis_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7742482",
   "metadata": {},
   "source": [
    "## 2023-05-01 - Test my interneuron hypothesis by looking at interneurons across the long/short divide\n",
    "\n",
    " 1. Interneuron identity should be best determinant of active environment.\n",
    "\n",
    " 2. Do people know anything about interneurons that activate in a given environment? For example, to interneurons activate alongside pyramidal cells when replaying a given environment?\n",
    "\n",
    " 3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b7df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Interneuron identity should be best determinant of active environment.\n",
    "\n",
    "# 2. Do people know anything about interneurons that activate in a given environment? For example, to interneurons activate alongside pyramidal cells when replaying a given environment?\n",
    "\n",
    "# 3. \n",
    "# global_results.pf1D_dt.reset()\n",
    "# global_results.pf2D_dt.reset()\n",
    "# global_results.all_attributes\n",
    "\n",
    "list(curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.keys())\n",
    "\n",
    "curr_active_pipeline.global_computation_results.computed_data.long_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d06a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.rdf.rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc9c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.time_binned_instantaneous_unit_specific_spike_rate.time_bins #.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ca961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "instantaneous_fr_df = deepcopy(jonathan_firing_rate_analysis_result.time_binned_instantaneous_unit_specific_spike_rate.instantaneous_unit_specific_spike_rate_values)\n",
    "instantaneous_fr_df['t'] = jonathan_firing_rate_analysis_result.time_binned_instantaneous_unit_specific_spike_rate.time_bins\n",
    "instantaneous_fr_df #.plot()\n",
    "\n",
    "smoothed_instantaneous_fr_df = instantaneous_fr_df.ewm(span=60).mean()\n",
    "\n",
    "smoothed_instantaneous_fr_df.plot(x='t')\n",
    "plt.title(\"Instantaneous Firing Rates\")\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('Firing Rate (Hz)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b7bbd",
   "metadata": {
    "tags": [
     "output",
     "figure",
     "display",
     "ACTIVE"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_figure_basename_from_display_context\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _plot_session_long_short_track_firing_rate_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "long_plots, short_plots = _plot_session_long_short_track_firing_rate_figures(curr_active_pipeline, jonathan_firing_rate_analysis_result, figures_parent_out_path=curr_active_pipeline.get_output_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "instantaneous_fr_df.set_index('t').to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Require placefield presence on either the long or the short\n",
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[np.logical_or(jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_long_pf'], jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_short_pf'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87851fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df[np.logical_or(jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_long_pf'], jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_short_pf'])].index.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8de2e3da",
   "metadata": {},
   "source": [
    "# 2023-05-19 - Testing S-only emergence, L-only replays in S, peak position remappings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d082385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "neuron_replay_stats_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df.copy()\n",
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership, SetPartition\n",
    "## 2023-05-19 - Get S-only pfs\n",
    "is_S_pf_only = np.logical_and(np.logical_not(neuron_replay_stats_df['has_long_pf']), neuron_replay_stats_df['has_short_pf'])\n",
    "is_S_only = neuron_replay_stats_df.track_membership == SplitPartitionMembership.RIGHT_ONLY\n",
    "assert (is_S_pf_only == is_S_only).all()\n",
    "S_only_aclus = neuron_replay_stats_df.index[is_S_only].to_numpy()\n",
    "neuron_replay_stats_df[is_S_pf_only]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Show L-only pfs stop replaying on S\n",
    "is_L_pf_only = np.logical_and(np.logical_not(neuron_replay_stats_df['has_short_pf']), neuron_replay_stats_df['has_long_pf'])\n",
    "is_L_only = neuron_replay_stats_df.track_membership == SplitPartitionMembership.LEFT_ONLY\n",
    "assert (is_L_pf_only == is_L_only).all()\n",
    "L_only_aclus = neuron_replay_stats_df.index[is_L_only].to_numpy()\n",
    "neuron_replay_stats_df[is_L_only]\n",
    "\n",
    "\n",
    "## For ('kdiba', 'gor01', 'one', '2006-6-09_1-22-43') - Have L-only cells [24, 98] that have ['short_num_replays'] = [8, 7]. We were hoping that there would be few to no replays on the S-track that involved L-only cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3bdd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-05-23 - Get Common (SHARED) placefields\n",
    "## Goal 1: From the cells with the placefields on both tracks, compute the degree to which they remap in position and sort them according to their distance.\n",
    "is_BOTH_pf_only = np.logical_and(neuron_replay_stats_df['has_short_pf'], neuron_replay_stats_df['has_long_pf']) # (63,)\n",
    "BOTH_pf_only_aclus = neuron_replay_stats_df.index[is_BOTH_pf_only].to_numpy()\n",
    "\n",
    "## NOTE: is_BOTH_pf_only is a much more stringent requirement (and a strict subset) than `is_BOTH_only`\n",
    "is_BOTH_only = neuron_replay_stats_df.track_membership == SplitPartitionMembership.SHARED # (99,)\n",
    "BOTH_only_aclus = neuron_replay_stats_df.index[is_BOTH_only].to_numpy()\n",
    "assert BOTH_only_aclus.shape[0] >= BOTH_pf_only_aclus.shape[0]\n",
    "\n",
    "BOTH_pf_only_df = neuron_replay_stats_df[is_BOTH_pf_only].copy()\n",
    "BOTH_pf_only_df['long_short_pf_peak_x_displacement'] = BOTH_pf_only_df['long_pf_peak_x'].values - BOTH_pf_only_df['short_pf_peak_x'].values\n",
    "BOTH_pf_only_df['long_short_pf_peak_x_distance'] = BOTH_pf_only_df['long_short_pf_peak_x_displacement'].abs()\n",
    "BOTH_pf_only_df.sort_values(by=['long_short_pf_peak_x_distance'], inplace=True, ascending=False)\n",
    "BOTH_pf_only_df\n",
    "\n",
    "#TODO 2023-05-23 - Can do more detailed peaks analysis with: long_results.RatemapPeaksAnalysis and short_results.RatemapPeaksAnalysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f51c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 24 cells, 133 Epochs, 789 Total Timebins\n",
    "# Other\n",
    "\t\n",
    "\t- is_non_firing_time_bin: numpy.ndarray - (24, 789)\n",
    "\t- all_epochs_num_epoch_time_bins: numpy.ndarray - (133,)\n",
    "\t\n",
    "    ## Indexing Helpers:\n",
    "\t\t- all_epochs_reverse_flat_epoch_indicies_array: numpy.ndarray - (789,)\n",
    "\t\t- split_by_epoch_reverse_flattened_time_bin_indicies: list - (133,)\n",
    "    \n",
    "\t- original_1D_decoder: pyphoplacecellanalysis.Analysis.Decoder.reconstruction.BasePositionDecoder\n",
    "\t\t- pf: neuropy.analyses.placefields.PfND\n",
    "\t\t- neuron_IDXs: numpy.ndarray - (24,)\n",
    "\t\t- neuron_IDs: numpy.ndarray - (24,)\n",
    "\t\t- F: numpy.ndarray - (119, 24)\n",
    "\t\t- P_x: numpy.ndarray - (119, 1)\n",
    "        \n",
    "\t- flat_all_epochs_decoded_epoch_time_bins: numpy.ndarray - (24, 789)\n",
    "\n",
    "# Measured\n",
    "\t- flat_all_epochs_measured_cell_spike_counts: numpy.ndarray - (24, 789)\n",
    "\t- flat_all_epochs_measured_cell_firing_rates: numpy.ndarray - (24, 789)\n",
    "\n",
    "\n",
    "# Expected\n",
    "\t- flat_all_epochs_computed_expected_cell_firing_rates: numpy.ndarray - (24, 789)\n",
    "\t- flat_all_epochs_difference_from_expected_cell_spike_counts: numpy.ndarray - (24, 789)\n",
    "\t- flat_all_epochs_difference_from_expected_cell_firing_rates: numpy.ndarray - (24, 789)\n",
    "    \n",
    "    \n",
    "    \n",
    "## Epoch-based\n",
    "\t- all_epochs_decoded_epoch_time_bins_mean: numpy.ndarray - (133, 24)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "- flat_all_epochs_measured_cell_firing_rates: numpy.ndarray - .shape: (24, 789) \n",
    "- flat_all_epochs_computed_expected_cell_firing_rates: numpy.ndarray - .shape: (24, 789)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b3a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_results_obj.flat_all_epochs_computed_expected_cell_firing_rates\n",
    "long_results_obj.flat_all_epochs_measured_cell_firing_rates\n",
    "\n",
    "# long_results_obj.result_df_grouped\n",
    "\n",
    "\n",
    "measured_dfs = pd.DataFrame(long_results_obj.flat_all_epochs_measured_cell_firing_rates.T, columns=long_results_obj.original_1D_decoder.neuron_IDs)\n",
    "expected_dfs = pd.DataFrame(long_results_obj.flat_all_epochs_computed_expected_cell_firing_rates.T, columns=long_results_obj.original_1D_decoder.neuron_IDs)\n",
    "# pd.DataFrame(np.stack((long_results_obj.flat_all_epochs_measured_cell_firing_rates, long_results_obj.flat_all_epochs_computed_expected_cell_firing_rates)), columns=['measured_fr', 'expected_fr'])\n",
    "measured_dfs.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8566f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cdb9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import compute_evening_morning_parition\n",
    "\n",
    "difference_sorted_aclus, evening_sorted_aclus, morning_sorted_aclus = compute_evening_morning_parition(neuron_replay_stats_df, debug_print=True)\n",
    "sorted_neuron_replay_stats_df = neuron_replay_stats_df.reindex(difference_sorted_aclus).copy() # This seems to work to re-sort the dataframe by the sort indicies\n",
    "sorted_neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.neurons import NeuronType\n",
    "\n",
    "%matplotlib qt\n",
    "# Look at replays during ripples vs. those not during ripples. Also potentially PBEs vs. not PBEs.\n",
    "\n",
    "# NeuronType.from_any_string_series(['pyr','intr'])\n",
    "'pyr','cont','intr'\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "curr_active_pipeline.display('_display_jonathan_interactive_replay_firing_rate_comparison', active_identifying_session_ctx, included_neuron_types=NeuronType.from_any_string_series(['pyr'])) # only the pyramidal neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ebf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f61971",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_jonathan_interactive_replay_firing_rate_comparison', active_identifying_session_ctx, included_neuron_types=NeuronType.from_any_string_series(['intr']), require_placefield=False) # only the pyramidal neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0859e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import build_replays_custom_scatter_markers, CustomScatterMarkerMode\n",
    "\n",
    "_curr_included_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[np.logical_or(jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_long_pf'], jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_short_pf'])].index.to_numpy()\n",
    "_curr_output = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', active_identifying_session_ctx, included_unit_neuron_IDs=_curr_included_aclus, marker_split_mode=CustomScatterMarkerMode.NoSplit)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d69eed8a",
   "metadata": {},
   "source": [
    "## 2023-04-13 - Shuffled Surprise\n",
    "\"\"\" \n",
    "Relevant Functions:\n",
    "`perform_full_session_leave_one_out_decoding_analysis`:\n",
    "\t`perform_leave_one_aclu_out_decoding_analysis`:\tfrom pyphoplacecellanalysis.Analysis.Decoder.decoder_result import perform_leave_one_aclu_out_decoding_analysis\n",
    "\t`_analyze_leave_one_out_decoding_results`: from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.DefaultComputationFunctions import _analyze_leave_one_out_decoding_results\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac42d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-04-18 - Refactored into decoder_result\n",
    "result, result_df, result_df_grouped = long_results_obj.result, long_results_obj.result_df, long_results_obj.result_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c107570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import DiagnosticDistanceMetricFigure\n",
    "\n",
    "## Render the internactive slider that allows selecting the timebin index to debug\n",
    "n_timebins = np.sum(long_results_obj.all_epochs_num_epoch_time_bins)\n",
    "timebinned_neuron_info = long_results_obj.timebinned_neuron_info\n",
    "result = long_results_obj.new_result\n",
    "active_fig_obj, update_function = DiagnosticDistanceMetricFigure.build_interactive_diagnostic_distance_metric_figure(long_results_obj, timebinned_neuron_info, result)\n",
    "active_fig_obj.integer_slider(n_timebins=n_timebins, update_func=update_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Get set of cells active in a given time bin, for each compute the surprise of its placefield with the leave-one-out decoded posterior.\n",
    "\n",
    "# 2. From the remainder of cells (those not active), randomly choose one to grab the placefield of and compute the surprise with that and the same posterior.\n",
    "\n",
    "# Expectation: The cells that are included in the time bin are expected to have a lower surprise (be less correlated with) the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1692fd1",
   "metadata": {
    "tags": [
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "win, plots = plot_long_short_surprise_difference_plot(curr_active_pipeline, long_results_obj, short_results_obj, long_epoch_name, short_epoch_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118c3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_results_obj.timebinned_neuron_info.n_timebins # 736\n",
    "short_results_obj.timebinned_neuron_info.n_timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893964b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_results_obj.flat_all_epochs_measured_cell_firing_rates.shape # (30, 736)\n",
    "# short_results_obj.flat_all_epochs_measured_cell_firing_rates.shape # (30, 736)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae2e695",
   "metadata": {
    "tags": [
     "active",
     "NOW_05-25",
     "expected_vs_observed"
    ]
   },
   "outputs": [],
   "source": [
    "win, plots_tuple, legend = plot_long_short_expected_vs_observed_firing_rates(long_results_obj, short_results_obj, limit_aclus=list(BOTH_pf_only_df.index[:2].values))\n",
    "long_epoch_indicator_region_items, short_epoch_indicator_region_items = _helper_add_long_short_session_indicator_regions(win, long_epoch=curr_active_pipeline.filtered_epochs[long_epoch_name], short_epoch=curr_active_pipeline.filtered_epochs[short_epoch_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot # works pretty well seemingly\n",
    "\n",
    "export_pyqtgraph_plot(win)\n",
    "# pg.setConfigOption('leftTitle', 'MathText')\n",
    "# win.setTitle(r'JSD(p_x_given_n, pf[<font size=\"4\"><b><span style=\"color:red;\">i</span></b></font>]) - JSD(p_x_given_n, pf[<font size=\"4\"><b>j</b></font>]) where <font size=\"4\"><b>j</b></font> non-firing')\n",
    "\n",
    "# win.setTitle(generate_html_string(f'JSD(p_x_given_n, pf[{i_str}]) - JSD(p_x_given_n, pf[{j_str}]) where {j_str} non-firing', font_size=8))\n",
    "\n",
    "# r'$\\fn{JSD}{\\matr{pf}_{i}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}} - \\fn{JSD}{\\matr{pf}_{j}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}}$'\n",
    "# title_str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f996fd9",
   "metadata": {},
   "source": [
    "## Pre 2023-04-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b6ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import plot_kourosh_activity_style_figure\n",
    "\n",
    "from neuropy.core.neurons import NeuronType\n",
    "# # Include only pyramidal aclus:\n",
    "# print(f'all shared_aclus: {len(shared_aclus)}\\nshared_aclus: {shared_aclus}')\n",
    "# shared_aclu_neuron_type = long_session.neurons.neuron_type[np.isin(long_session.neurons.neuron_ids, shared_aclus)]\n",
    "# assert len(shared_aclu_neuron_type) == len(shared_aclus)\n",
    "# # Find only the aclus that are pyramidal:\n",
    "# is_shared_aclu_pyramidal = (shared_aclu_neuron_type == NeuronType.PYRAMIDAL)\n",
    "# pyramidal_only_shared_aclus = shared_aclus[is_shared_aclu_pyramidal]\n",
    "# print(f'num pyramidal_only_shared_aclus: {len(pyramidal_only_shared_aclus)}\\npyramidal_only_shared_aclus: {pyramidal_only_shared_aclus}')\n",
    "\n",
    "\n",
    "## Drop Pyramidal but don't use only shared aclus:\n",
    "all_aclus = deepcopy(long_session.neurons.neuron_ids)\n",
    "neuron_type = long_session.neurons.neuron_type\n",
    "assert len(neuron_type) == len(all_aclus)\n",
    "# Find only the aclus that are pyramidal:\n",
    "is_aclu_pyramidal = (neuron_type == NeuronType.PYRAMIDAL)\n",
    "pyramidal_only_all_aclus = all_aclus[is_aclu_pyramidal]\n",
    "print(f'num pyramidal_only_all_aclus: {len(pyramidal_only_all_aclus)}\\npyramidal_only_all_aclus: {pyramidal_only_all_aclus}')\n",
    "\n",
    "is_aclu_interneuron = (neuron_type == NeuronType.INTERNEURONS)\n",
    "interneuron_only_all_aclus = all_aclus[is_aclu_interneuron]\n",
    "print(f'num interneuron_only_all_aclus: {len(interneuron_only_all_aclus)}\\ninterneurons: {interneuron_only_all_aclus}')\n",
    "\n",
    "# app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, shared_aclus, epoch_idx=5, callout_epoch_IDXs=[0,1,2,3], skip_rendering_callouts=True)\n",
    "# app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_shared_aclus, epoch_idx=2, callout_epoch_IDXs=[0,4], skip_rendering_callouts=False)\n",
    "app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_all_aclus, epoch_idx=6, callout_epoch_IDXs=[2,4,6], skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985977d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the Jupyter Index Thing\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import DiagnosticDistanceMetricFigure\n",
    "\n",
    "## Render the internactive slider that allows selecting the timebin index to debug\n",
    "n_timebins = np.sum(long_results_obj.all_epochs_num_epoch_time_bins)\n",
    "timebinned_neuron_info = long_results_obj.timebinned_neuron_info\n",
    "result = long_results_obj.new_result\n",
    "active_fig_obj, update_function = DiagnosticDistanceMetricFigure.build_interactive_diagnostic_distance_metric_figure(long_results_obj, timebinned_neuron_info, result)\n",
    "active_fig_obj.integer_slider(n_timebins=n_timebins, update_func=update_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1aa692",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_fig_obj.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea983fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, self.plots, self.plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_all_aclus, epoch_idx=11, callout_epoch_IDXs=[0,1,2, 3, 4, 5], skip_rendering_callouts=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f519e392",
   "metadata": {},
   "source": [
    "# 2023-04-13 Show Surprise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b417bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions import plot_long_short, plot_long_short_any_values, plot_long_short_expected_vs_observed_firing_rates, _helper_add_long_short_session_indicator_regions\n",
    "# plot_long_short(long_results_obj, short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feefc5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_long_short_any_values(long_results_obj=long_results_obj, short_results_obj=short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_long_short_expected_vs_observed_firing_rates(long_results_obj=long_results_obj, short_results_obj=short_results_obj, limit_aclus=[89]) # 4, 89, 28, 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fn = lambda a_results_obj: a_results_obj.all_epochs_decoded_epoch_time_bins_mean[:,0]\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_scrambled_pf_surprises_mean\n",
    "y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_computed_one_left_out_posterior_to_pf_surprises\n",
    "\n",
    "# (time_bins, neurons), (epochs, neurons), (epochs)\n",
    "# all_epochs_computed_one_left_out_posterior_to_pf_surprises, all_epochs_computed_cell_one_left_out_posterior_to_pf_surprises_mean, all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "win, plots_tuple, legend = plot_long_short_any_values(long_results_obj, short_results_obj, x=x_fn, y=y_fn, limit_aclus=[20])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fe80559",
   "metadata": {},
   "source": [
    "# 2023-04-13 - Find Good looking epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "from pyphocorehelpers.plotting.figure_management import PhoActiveFigureManager2D\n",
    "from pyphoplacecellanalysis.GUI.Qt.Mixins.PaginationMixins import PaginatedFigureController\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context()\n",
    "_out_pagination_controller = DecodedEpochSlicesPaginatedFigureController.init_from_decoder_data(long_results_obj.active_filter_epochs, long_results_obj.all_included_filter_epochs_decoder_result, \n",
    "\txbin=long_results_obj.original_1D_decoder.xbin, global_pos_df=global_session.position.df, a_name='TestDecodedEpochSlicesPaginationController', active_context=active_identifying_session_ctx,  max_subplots_per_page=10)\n",
    "# _out_pagination_controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa14005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_pagination_controller.params.debug_print = True\n",
    "_pagination_widget = _out_pagination_controller.ui.mw.ui.paginator_controller_widget\n",
    "_pagination_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2443fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test rendering multiple figures sequentially:\n",
    "list(_out_pagination_controller.plots_data.keys())\n",
    "\n",
    "# _out_pagination_controller.on_paginator_control_widget_jump_to_page()\n",
    "\n",
    "_out_pagination_controller.params.active_identifying_figure_ctx\n",
    "# _out_pagination_controller.params.variable_name\n",
    "_out_pagination_controller.plots_data.paginator.num_pages\n",
    "\n",
    "# `included_combined_indicies_pages` is what was used in the other `BatchPhoJonathanFiguresHelper._build_batch_plot_kwargs(...)` call\n",
    "included_combined_indicies_pages = _out_pagination_controller.plots_data.paginator.included_combined_indicies_pages\n",
    "_out_pagination_controller.plots_data.paginator.subplot_no_pagination_configuration\n",
    "\n",
    "fig = _out_pagination_controller.plots.fig\n",
    "# _out_pagination_controller.plots.figure_id\n",
    "# _out_pagination_controller.plots.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a9a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_linear_fit_df.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f0018ec",
   "metadata": {},
   "source": [
    "### 2023-05-30 - Add the radon-transformed linear fits to each epoch to the stacked epoch plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert long_results_obj.all_included_filter_epochs_decoder_result.num_filter_epochs == np.shape(epochs_linear_fit_df)[0]\n",
    "\n",
    "radon_transform_plots = []\n",
    "_out_pagination_controller.plots_data.radon_transform_line_data = []\n",
    "\n",
    "for epoch_idx, epoch_vel, epoch_intercept in zip(np.arange(long_results_obj.all_included_filter_epochs_decoder_result.num_filter_epochs), epochs_linear_fit_df['velocity'].values, epochs_linear_fit_df['intercept'].values):\n",
    "    # build the discrete line over the centered time bins:\n",
    "    epoch_time_bins = long_results_obj.all_included_filter_epochs_decoder_result.time_bin_containers[epoch_idx].centers\n",
    "    epoch_time_bins = epoch_time_bins - epoch_time_bins[0] # all values should be relative to the start of the epoch:\n",
    "    epoch_line_eqn = (epoch_vel * epoch_time_bins) + epoch_intercept\n",
    "    _out_pagination_controller.plots_data.radon_transform_line_data.append(epoch_line_eqn)\n",
    "\n",
    "def _callback_update_decoded_single_epoch_slice_plot(curr_ax, params: \"VisualizationParameters\", plots_data: \"RenderPlotsData\", plots: \"RenderPlots\", ui: \"PhoUIContainer\", i:int, curr_time_bins, *args, **kwargs): # curr_posterior, curr_most_likely_positions, debug_print:bool=False\n",
    "    \"\"\" 2023-05-30 - Based off of `_helper_update_decoded_single_epoch_slice_plot` to enable plotting radon transform lines on paged decoded epochs\n",
    "\n",
    "    Needs only: curr_time_bins, plots_data, i\n",
    "    Accesses: plots_data.epoch_slices[i,:], plots_data.global_pos_df, params.variable_name, params.xbin, params.enable_flat_line_drawing\n",
    "    \"\"\"\n",
    "    debug_print = kwargs.pop('debug_print', False)\n",
    "    if debug_print:\n",
    "        print(f'_callback_update_decoded_single_epoch_slice_plot(..., i: {i}, curr_time_bins: {curr_time_bins})')\n",
    "    # plot the radon transform line on the epoch:\n",
    "    radon_transform_plot = curr_ax.plot(curr_time_bins, plots_data.radon_transform_line_data[i], label=f'computed radon transform', linestyle='dashed', linewidth=3, color='#e5ff00', alpha=0.8, marker='+', markersize=10) # Opaque RED # , linestyle='dashed', linewidth=2, color='#ff0000ff'\n",
    "    if debug_print:\n",
    "        print(f'\\t success!')\n",
    "    return params, plots_data, plots, ui\n",
    "\n",
    "\n",
    "# .params.on_render_page_callbacks: a dict of callbacks to be called when the page changes and needs to be re-rendered\n",
    "on_render_page_callbacks = _out_pagination_controller.params.get('on_render_page_callbacks', None)\n",
    "if on_render_page_callbacks is None:\n",
    "    _out_pagination_controller.params.on_render_page_callbacks = {} # allocate a new list\n",
    "## add or update this callback:\n",
    "_out_pagination_controller.params.on_render_page_callbacks['plot_radon_transform_line_data'] = _callback_update_decoded_single_epoch_slice_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a26325",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_pagination_controller.plots.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d1db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_pagination_controller.ui.mw.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d526f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .\n",
    "\n",
    "current_page_idx = _out_pagination_controller.ui.mw.ui.paginator_controller_widget.current_page_idx\n",
    "curr_page_data_indicies, curr_page_data_items =  _out_pagination_controller.plots_data.paginator.get_page_data(page_idx=current_page_idx)\n",
    "print(f'current_page_idx: {current_page_idx}, curr_page_data_indicies: {curr_page_data_indicies}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_pagination_controller.on_paginator_control_widget_jump_to_page(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ace00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import safe_find_index_in_list\n",
    "\n",
    "def _get_current_page_data_indicies():\n",
    "\t\"\"\" captures `ui.mw.ui.paginator_controller_widget.current_page_idx`, `plots_data.paginator` \"\"\"\n",
    "\tcurrent_page_idx = _out_pagination_controller.ui.mw.ui.paginator_controller_widget.current_page_idx\n",
    "\tcurr_page_data_indicies, curr_page_data_items =  _out_pagination_controller.plots_data.paginator.get_page_data(page_idx=current_page_idx)\n",
    "\treturn current_page_idx, curr_page_data_indicies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e6526e9",
   "metadata": {},
   "source": [
    "# 2023-03-28 - Playing around with older computations/visualizations from the `_display_short_long_firing_rate_index_comparison` era:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a13cccd",
   "metadata": {},
   "source": [
    "# Plot long|short firing rate index using 'long_short_fr_indicies_analyses':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_save_parent_path = Path(r'E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Results from 2023-01-20 - LongShort Firing Rate Indicies')\n",
    "## Get the output path (active_session_figures_out_path) for this session (and all of its filtered_contexts as well):\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "figures_parent_out_path = create_daily_programmatic_display_function_testing_folder_if_needed()\n",
    "active_session_figures_out_path = session_context_to_relative_path(figures_parent_out_path, active_identifying_session_ctx)\n",
    "print(f'curr_session_parent_out_path: {active_session_figures_out_path}')\n",
    "active_session_figures_out_path.mkdir(parents=True, exist_ok=True) # make folder if needed\n",
    "curr_active_pipeline.display('_display_short_long_firing_rate_index_comparison', curr_active_pipeline.sess.get_context(), fig_save_parent_path=active_session_figures_out_path)\n",
    "# plt.close() # closes the current figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71511c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_short_long_firing_rate_index_comparison', long_short_fr_indicies_analysis_results['active_context'], fig_save_parent_path=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5e3dc",
   "metadata": {
    "tags": [
     "NOW_05_25"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# configure backend here\n",
    "# matplotlib.use('Qt5Agg')\n",
    "# backend_qt5agg\n",
    "matplotlib.use('Qt5Agg') # non-interactive backend ## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _plot_long_short_firing_rate_indicies\n",
    "\n",
    "\n",
    "# Plot long|short firing rate index:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_dict, y_frs_dict = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']\n",
    "fig, _temp_full_fig_save_path = _plot_long_short_firing_rate_indicies(x_frs_dict, y_frs_dict, active_context, fig_save_parent_path=None, debug_print=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fcb225",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.spines[['top', 'right']].set_visible(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_long_short_firing_rate_analyses'], fail_on_exception=True, debug_print=False) # fail_on_exception MUST be True or error handling is all messed up \n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_dict, y_frs_dict = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']\n",
    "long_short_fr_indicies_analysis_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0409e08",
   "metadata": {},
   "source": [
    "# Other Programmatic Figures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ecc42a2",
   "metadata": {},
   "source": [
    "### 2023-05-25 - Neptune Figure Uploads from `registered_output_files`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f32c5ea",
   "metadata": {
    "tags": [
     "NOW_05-25"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import neptune_output_figures\n",
    "\n",
    "# curr_active_pipeline.registered_output_files\n",
    "# curr_active_pipeline.register_output_file(output_path=test_path, output_metadata={})\n",
    "\n",
    "neptune_output_figures(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86bf7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_output_files\n",
    "# curr_active_pipeline.registered_output_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a53d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import create_daily_programmatic_display_function_testing_folder_if_needed, session_context_to_relative_path, programmatic_display_to_PDF\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_pdf_metadata_from_display_context # newer version of build_pdf_export_metadata\n",
    "from neuropy.core.neuron_identities import PlotStringBrevityModeEnum\n",
    "from neuropy.plotting.ratemaps import BackgroundRenderingOptions\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "mpl.rcParams['toolbar'] = 'None' # disable toolbars\n",
    "matplotlib.use('AGG') # non-interactive backend ## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "# active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "# programmatic_display_to_PDF(curr_active_pipeline, curr_display_function_name='_display_1d_placefields', debug_print=False) # 🟢✅ Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear.\n",
    "# programmatic_display_to_PDF(curr_active_pipeline, curr_display_function_name='_display_1d_placefield_validations') # , filter_name=active_config_name 🟢✅ Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear. Moderate visual improvements can still be made (titles overlap and stuff). Works with %%capture\n",
    "# programmatic_display_to_PDF(curr_active_pipeline, curr_display_function_name='_display_2d_placefield_result_plot_ratemaps_2D') #  🟢✅ Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear.\n",
    "programmatic_display_to_PDF(curr_active_pipeline, curr_display_function_name='_display_2d_placefield_occupancy') #  🟢✅ Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a5a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "active_identifying_session_ctx, active_session_figures_out_path, active_out_figures_list = batch_programmatic_figures(curr_active_pipeline)\n",
    "batch_extended_programmatic_figures(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7172c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_helper = curr_active_pipeline.plot\n",
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2926235",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display_output_history_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# '_display_2d_placefield_result_plot_ratemaps_2D'\n",
    "# %matplotlib inline\n",
    "%matplotlib qt\n",
    "# curr_active_pipeline.display('_display_2d_placefield_result_plot_ratemaps_2D', long_epoch_context) # MatplotlibRenderPlots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48029c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# long_pf2D.plot_occupancy()\n",
    "_out = short_one_step_decoder_2D.pf.plot_ratemaps_2D(included_unit_neuron_IDs=[2,4,5], bg_rendering_mode=BackgroundRenderingOptions.EMPTY, use_special_overlayed_title=False, missing_aclu_string_formatter=None, debug_print=False, brev_mode=PlotStringBrevityModeEnum.NONE)\n",
    "\n",
    "## Single column output: subplots=(None, 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14977e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "active_display_to_pdf_fn(curr_active_pipeline, curr_display_function_name='_display_1d_placefields', debug_print=False) # 🟢✅ Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2686e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_shared_aclus_only_decoder.pf.plot_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "long_one_step_decoder_2D.pf.plot_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8006610",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_one_step_decoder_2D.pf.plot_ratemaps_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49dcc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_session_configuration_context=global_epoch_context, single_figure=False)\n",
    "\n",
    "short_one_step_decoder_1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402834bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "long_single_cell_pfmap_processing_fn = None\n",
    "short_single_cell_pfmap_processing_fn = None\n",
    "sort_idx = None\n",
    "\n",
    "out = curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_identifying_session_ctx, single_figure=False, debug_print=False, fignum='Short v Long pf1D Comparison',\n",
    "                                   long_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': long_single_cell_pfmap_processing_fn},\n",
    "                                   short_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': short_single_cell_pfmap_processing_fn, 'curve_hatch_style': {'hatch':'///', 'edgecolor':'k'}},\n",
    "                                  )\n",
    "\n",
    "# ax = out.axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cfbb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(product_overlap_scalars_df.prod_overlap.to_numpy())[::-1] # the `[::-1]` term reverses the array, which by defaul is returned in ascending order and we want descending\n",
    "sort_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe831b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_ratemap = long_one_step_decoder_1D.pf.ratemap\n",
    "curr_ratemap.get_sort_indicies()\n",
    "# .pf1D.ratemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23228854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create `master_dock_win` - centralized plot output window to collect individual figures/controls in (2022-08-18)\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.filtered_contexts['maze']\n",
    "display_output = curr_active_pipeline.display('_display_context_nested_docks', active_identifying_session_ctx, enable_gui=False, debug_print=True) # returns {'master_dock_win': master_dock_win, 'app': app, 'out_items': out_items}\n",
    "master_dock_win = display_output['master_dock_win']\n",
    "app = display_output['app']\n",
    "out_items = display_output['out_items']\n",
    "\n",
    "# def _get_curr_figure_format_config():\n",
    "# \t\"\"\" Aims to fetch the current figure_format_config and context from the figure_format_config widget:    \n",
    "# \tImplicitly captures: `out_items`, `active_config_name`, `active_identifying_filtered_session_ctx` \n",
    "# \t\"\"\"\n",
    "# \t## Get the figure_format_config from the figure_format_config widget:\n",
    "# \t# Fetch the context from the GUI:\n",
    "# \t_curr_gui_session_ctx, _curr_gui_out_display_items = out_items[active_config_name]\n",
    "# \t_curr_gui_figure_format_config_widget = _curr_gui_out_display_items[active_identifying_filtered_session_ctx.adding_context('display_fn', display_fn_name='figure_format_config_widget')] # [0] is seemingly not needed to unpack the tuple\n",
    "# \tif _curr_gui_figure_format_config_widget is not None:\n",
    "# \t\t# has GUI for config\n",
    "# \t\tfigure_format_config = _curr_gui_figure_format_config_widget.figure_format_config\n",
    "# \telse:\n",
    "# \t\t# has non-GUI provider of figure_format_config\n",
    "# \t\tfigure_format_config = _curr_gui_figure_format_config_widget.figure_format_config\n",
    "\n",
    "# \tif debug_print:\n",
    "# \t\tprint(f'recovered gui figure_format_config: {figure_format_config}')\n",
    "\n",
    "# \treturn figure_format_config\n",
    "\n",
    "# figure_format_config = _get_curr_figure_format_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1e8629a",
   "metadata": {},
   "source": [
    "# 2023-04-27 - Idea: Candidate Replay \"Quality\" Metric\n",
    "Observed that I visually distinguish \"good\" replays from bad ones based on their mostly-monotonically increasing nature.\n",
    "\n",
    "#### They don't have to:\n",
    "\tSpan the whole track\n",
    "\tStart or end at an end-cap\n",
    "\tIncrease linearly\n",
    "\n",
    "#### The algorithm must:\n",
    "\ttolerate ocasional jumps in an otherwise linear sequence\n",
    "\tallow sequences to \"start\" only halfway through. They should extract out the coherent sequence\n",
    "\n",
    "#### Ideas:\n",
    "\t- just a linear fit\n",
    "\t- a monotonicity check using some sort of cumulative sum over the differences in position.\n",
    "\t- \"radon transform\"?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fad7d0f",
   "metadata": {
    "tags": [
     "radon_transform",
     "testing"
    ]
   },
   "source": [
    "# 20230-05-25 - Radon Transform approach to finding line of best fit for each replay Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b5fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import get_radon_transform\n",
    "\n",
    "## 2023-05-25 - Get the 1D Posteriors for each replay epoch so they can be analyzed via score_posterior(...) with a Radon Transform approch to find the line of best fit (which gives the velocity).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "active_epoch_decoder_result = long_results_obj.all_included_filter_epochs_decoder_result\n",
    "epochs_linear_fit_df = compute_radon_transforms(active_epoch_decoder_result)\n",
    "epochs_linear_fit_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de511aa5",
   "metadata": {},
   "source": [
    "# 2023-05-02 - Session Validation Check Info\n",
    "Generate info about the number of laps detected, the duration, the number of cells, the number of replays, etc for the active session so that it can be ensured that there wasn't an error that is messing up the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15697281",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.active_sess_config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5045805",
   "metadata": {},
   "source": [
    "# Pipeline Comprehensive:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Top level objects:\n",
    "curr_active_pipeline.active_sess_config\n",
    "curr_active_pipeline.sess\n",
    "\n",
    "\n",
    "\n",
    "# Function of config names or contexts:\n",
    "curr_active_pipeline.filtered_contexts\n",
    "\n",
    "curr_active_pipeline.filtered_sessions\n",
    "curr_active_pipeline.active_configs # each is a `InteractivePlaceCellConfig` type object\n",
    "\tcurr_active_pipeline._stage.active_configs['maze1']\n",
    "\n",
    "\n",
    "\n",
    "curr_active_pipeline.computation_results\n",
    "\n",
    "\n",
    "curr_active_pipeline.global_computation_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f30d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = curr_active_pipeline.sess\n",
    "sess.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05560f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import EpochsAccessor, Epoch\n",
    "\n",
    "sess = curr_active_pipeline.sess\n",
    "# sess.replay.epochs.debug_print_info('replays')\n",
    "\n",
    "\n",
    "def debug_print_session_epochs_info(sess, session_name:str):\n",
    "\t\"\"\" \n",
    "\n",
    "\tExample:\n",
    "\t\tdebug_print_session_epochs_info(curr_active_pipeline.sess, 'sess')\n",
    "\t\tdebug_print_session_epochs_info(long_session, 'long_session')\n",
    "\t\tdebug_print_session_epochs_info(short_session, 'short_session')\n",
    "\t\tdebug_print_session_epochs_info(global_session, 'global_session')\n",
    "\n",
    "\tsess:\n",
    "\t\tnum replays: 1729\n",
    "\t\tnum laps: 80\n",
    "\tlong_session:\n",
    "\t\tnum replays: 661\n",
    "\t\tnum laps: 40\n",
    "\tshort_session:\n",
    "\t\tnum replays: 1068\n",
    "\t\tnum laps: 40\n",
    "\tglobal_session:\n",
    "\t\tnum replays: 1729\n",
    "\t\tnum laps: 80\n",
    "\t\t\n",
    "\t\n",
    "\t\"\"\"\t\n",
    "\n",
    "\treplays_df = sess.replay\n",
    "\tlaps_df = sess.laps.as_epoch_obj().to_dataframe()\n",
    "\tprint(f'{session_name}:')\n",
    "\tprint(f'\\tnum replays: {replays_df.epochs.n_epochs}')\n",
    "\tprint(f'\\tnum laps: {laps_df.epochs.n_epochs}')\n",
    "\n",
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "# long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "# long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "# long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "# decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "debug_print_session_epochs_info(curr_active_pipeline.sess, 'sess')\n",
    "debug_print_session_epochs_info(long_session, 'long_session')\n",
    "debug_print_session_epochs_info(short_session, 'short_session')\n",
    "debug_print_session_epochs_info(global_session, 'global_session')\n",
    "\n",
    "\n",
    "# epoch_df = sess.laps.to_dataframe()\n",
    "\n",
    "# epoch_df.epochs.n_epochs\n",
    "\n",
    "# epoch_name = 'laps'\n",
    "# num_epochs = epoch_df.epochs.n_epochs # np.shape(epoch_df)[0]\n",
    "# print(f'num {epoch_name}: {num_epochs}')\n",
    "\n",
    "# sess.replay.to_dataframe()\n",
    "\n",
    "# def debug_print_session_epochs_info(num_updated_total_items: int, num_original_total_items: int, item_label=None, subsession_name=None):\n",
    "#     print('{}/{} total {} remain in subsession {}'.format(num_updated_total_items, num_original_total_items, (item_label or \"items\"), (subsession_name or \"\")))\n",
    "\n",
    "# debug_print_subsession_epochs_differences(num_updated_total_items=len(long_session.replay), num_original_total_items=len(long_session.replay_backup), item_label='replays', subsession_name='\"long\"')\n",
    "# debug_print_subsession_epochs_differences(num_updated_total_items=len(short_session.replay), num_original_total_items=len(short_session.replay_backup), item_label='replays', subsession_name='\"short\"')\n",
    "\n",
    "(long_epoch_name, short_epoch_name, global_epoch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75cf03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BUG 2023-05-25 - Found ERROR for a loaded pipeline where for some reason the filtered_contexts[long_epoch_name]'s actual context was the same as the short maze ('...maze2'). Unsure how this happened.\n",
    "ctx = curr_active_pipeline.filtered_contexts[long_epoch_name]\n",
    "ctx.filter_name = long_epoch_name\n",
    "assert ctx.filter_name == long_epoch_name, f\"ctx.filter_name: {ctx.filter_name} != long_epoch_name: {long_epoch_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8874b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(curr_active_pipeline.active_configs.keys())\n",
    "list(curr_active_pipeline.filtered_sessions.keys())\n",
    "list(curr_active_pipeline.filtered_contexts.keys())\n",
    "# curr_active_pipeline.filtered_sessions\n",
    "curr_active_pipeline.filtered_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed69eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def debug_print_subsession_epochs_differences(num_updated_total_items: int, num_original_total_items: int, item_label=None, subsession_name=None):\n",
    "    print('{}/{} total {} remain in subsession {}'.format(num_updated_total_items, num_original_total_items, (item_label or \"items\"), (subsession_name or \"\")))\n",
    "\n",
    "debug_print_subsession_epochs_differences(num_updated_total_items=len(long_session.replay), num_original_total_items=len(long_session.replay_backup), item_label='replays', subsession_name='\"long\"')\n",
    "debug_print_subsession_epochs_differences(num_updated_total_items=len(short_session.replay), num_original_total_items=len(short_session.replay_backup), item_label='replays', subsession_name='\"short\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e67e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_print_subsession_epochs_differences(num_updated_total_items=len(long_session.laps), num_original_total_items=len(long_session.replay_backup), item_label='laps', subsession_name='\"long\"')\n",
    "debug_print_subsession_epochs_differences(num_updated_total_items=len(short_session.laps), num_original_total_items=len(short_session.replay_backup), item_label='laps', subsession_name='\"short\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_num_rows = self.n_epochs        \n",
    "filtered_epochs = convert_PortionInterval_to_epochs_df(_convert_start_end_tuples_list_to_PortionInterval(zip(self.starts, self.stops)))\n",
    "after_num_rows = np.shape(filtered_epochs)[0]\n",
    "changed_num_rows = after_num_rows - before_num_rows\n",
    "print(f'Dataframe Changed from {before_num_rows} -> {after_num_rows} ({changed_num_rows = })')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8caf529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_spike_counts, debug_print_subsession_neuron_differences, print_aligned_columns\n",
    "from neuropy.utils.misc import print_seconds_human_readable\n",
    "\n",
    "debug_print_spike_counts(global_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80205471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _compare_computation_results\n",
    "# curr_active_pipeline.computation_results\n",
    "# pf_neurons_diff = _compare_computation_results(curr_active_pipeline.computation_results.maze1_PYR, curr_active_pipeline.computation_results.maze2_PYR)\n",
    "pf_neurons_diff = _compare_computation_results(long_results, short_results)\n",
    "pf_neurons_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0000ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pf_neurons_diff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7125b9f7",
   "metadata": {},
   "source": [
    "### Plotting Validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b942014",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "short_one_step_decoder_1D.pf.plot_ratemaps_1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_results.pf1D_Decoder.pf.plot_ratemaps_1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_results.pf2D_Decoder.pf.plot_ratemaps_2D()\n",
    "short_one_step_decoder_2D.pf.plot_ratemaps_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "long_session.plot_laps_2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d18bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "\n",
    "%matplotlib qt\n",
    "fig, out_axes_list = plot_laps_2d(global_session, legacy_plotting_mode=False)\n",
    "out_axes_list[0].set_title('New Pho Position Thresholding Estimated Laps')\n",
    "fig.canvas.manager.set_window_title('New Pho Position Thresholding Estimated Laps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae2e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Laps \n",
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.Mixins.LapsVisualizationMixin import LapsVisualizationMixin\n",
    "\n",
    "curr_position_df, lap_specific_position_dfs = LapsVisualizationMixin._compute_laps_specific_position_dfs(curr_active_pipeline.sess)\n",
    "lap_specific_position_dfs = [curr_position_df.groupby('lap').get_group(i)[['t','x','y','lin_pos']] for i in curr_active_pipeline.sess.laps.lap_id] # dataframes split for each ID:\n",
    "laps_position_times_list = [np.squeeze(lap_pos_df[['t']].to_numpy()) for lap_pos_df in lap_specific_position_dfs]\n",
    "laps_position_traces_list = [lap_pos_df[['x','y']].to_numpy().T for lap_pos_df in lap_specific_position_dfs]\n",
    "## Build Epochs:\n",
    "epochs = curr_active_pipeline.sess.laps.to_dataframe()\n",
    "epoch_slices = epochs[['start', 'stop']].to_numpy()\n",
    "epoch_description_list = [f'lap {epoch_tuple.lap_id} (maze: {epoch_tuple.maze_id}, direction: {epoch_tuple.lap_dir})' for epoch_tuple in epochs[['lap_id','maze_id','lap_dir']].itertuples()]\n",
    "# print(f'epoch_description_list: {epoch_description_list}') # epoch_descriptions: ['lap 41 (maze: 2, direction: 1)', 'lap 42 (maze: 2, direction: 0)', 'lap 43 (maze: 2, direction: 1)', 'lap 44 (maze: 2, direction: 0)', 'lap 45 (maze: 2, direction: 1)', 'lap 46 (maze: 2, direction: 0)', 'lap 47 (maze: 2, direction: 1)', 'lap 48 (maze: 2, direction: 0)', 'lap 49 (maze: 2, direction: 1)', 'lap 50 (maze: 2, direction: 0)', 'lap 51 (maze: 2, direction: 1)', 'lap 52 (maze: 2, direction: 0)', 'lap 53 (maze: 2, direction: 1)', 'lap 54 (maze: 2, direction: 0)', 'lap 55 (maze: 2, direction: 1)', 'lap 56 (maze: 2, direction: 0)', 'lap 57 (maze: 2, direction: 1)', 'lap 58 (maze: 2, direction: 0)', 'lap 59 (maze: 2, direction: 1)', 'lap 60 (maze: 2, direction: 0)', 'lap 61 (maze: 2, direction: 1)', 'lap 62 (maze: 2, direction: 0)', 'lap 63 (maze: 2, direction: 1)', 'lap 64 (maze: 2, direction: 0)', 'lap 65 (maze: 2, direction: 1)', 'lap 66 (maze: 2, direction: 0)', 'lap 67 (maze: 2, direction: 1)', 'lap 68 (maze: 2, direction: 0)', 'lap 69 (maze: 2, direction: 1)', 'lap 70 (maze: 2, direction: 0)', 'lap 71 (maze: 2, direction: 1)', 'lap 72 (maze: 2, direction: 0)', 'lap 73 (maze: 2, direction: 1)', 'lap 74 (maze: 2, direction: 0)', 'lap 75 (maze: 2, direction: 1)', 'lap 76 (maze: 2, direction: 0)', 'lap 77 (maze: 2, direction: 1)', 'lap 78 (maze: 2, direction: 0)', 'lap 79 (maze: 2, direction: 1)']\n",
    "# -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
