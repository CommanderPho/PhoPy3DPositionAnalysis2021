{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "\n",
    "# old import\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import SessionBatchProgress\n",
    "\n",
    "import pyphoplacecellanalysis.General.Batch.runBatch\n",
    "# New Import:\n",
    "# from pyphoplacecellanalysis.General.Batch.runBatch import SessionBatchProgress\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun, BatchResultDataframeAccessor, run_diba_batch, BatchComputationProcessOptions, BatchSessionCompletionHandler\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "\n",
    "\n",
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ed3a22-ac46-449c-a6d3-c1c7272114ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# active_global_batch_result_filename='global_batch_result_2023-07-12.pkl'\n",
    "# active_global_batch_result_filename='global_batch_result_2023-07-07.pkl'\n",
    "# active_global_batch_result_filename='global_batch_result_2023-07-07_extra.pkl'\n",
    "# active_global_batch_result_filename='global_batch_result_2023-07-20.pkl'\n",
    "active_global_batch_result_filename='global_batch_result_2023-07-21_Greatlakes.pkl'\n",
    "debug_print = False\n",
    "enable_neptune = False\n",
    "\n",
    "if enable_neptune:\n",
    "    import neptune # for logging progress and results\n",
    "    from neptune.types import File\n",
    "    from pyphoplacecellanalysis.General.Batch.NeptuneAiHelpers import set_environment_variables, neptune_output_figures\n",
    "    neptune_kwargs = {'project':\"commander.pho/PhoDibaLongShort2023\",\n",
    "    'api_token':\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGIxODU2My1lZTNhLTQ2ZWMtOTkzNS02ZTRmNzM5YmNjNjIifQ==\"}\n",
    "    set_environment_variables(neptune_kwargs)\n",
    "\"\"\" \n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import main, BatchRun, run_diba_batch, run_specific_batch\n",
    "\n",
    "\"\"\"\n",
    "known_global_data_root_parent_paths = [Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/nfs/turbo/umms-kdiba/Data')]\n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "\n",
    "## NEPTUNE:\n",
    "if enable_neptune:\n",
    "\tproject = neptune.init_project(**neptune_kwargs)\n",
    "\tproject[\"general/global_batch_result_filename\"] = active_global_batch_result_filename\n",
    "\tproject[\"general/global_data_root_parent_path\"] = global_data_root_parent_path.as_posix()\n",
    "\n",
    "## TODO: load the batch result initially:\n",
    "\n",
    "## Build Pickle Path:\n",
    "global_batch_result_file_path = Path(global_data_root_parent_path).joinpath(active_global_batch_result_filename).resolve() # Use Default\n",
    "\n",
    "if enable_neptune:\n",
    "\trun = neptune.init_run() # rember to run.stop()\n",
    "\trun['parameters/global_batch_result_file_path'] = global_batch_result_file_path.as_posix()\n",
    "\t# project[\"general/data_analysis\"].upload(\"data_analysis.ipynb\")\n",
    "\trun[\"dataset/latest\"].track_files(f\"file://{global_batch_result_file_path}\") # \"s3://datasets/images\"\n",
    "\n",
    "# try to load an existing batch result:\n",
    "# with set_posix_windows():\n",
    "global_batch_run = BatchRun.try_init_from_file(global_data_root_parent_path, active_global_batch_result_filename=active_global_batch_result_filename,\n",
    "\t\t\t\t\t\t\tskip_root_path_conversion=False, debug_print=debug_print) # on_needs_create_callback_fn=run_diba_batch\n",
    "\n",
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "batch_progress_df.batch_results.build_all_columns()\n",
    "good_only_batch_progress_df.batch_results.build_all_columns()\n",
    "if enable_neptune:\n",
    "\trun[\"dataset/global_batch_run_progress_df\"].upload(File.as_html(batch_progress_df)) # \"path/to/test_preds.csv\"\n",
    "\trun[\"dataset/global_batch_run_good_only_df\"].upload(File.as_html(good_only_batch_progress_df)) # \"path/to/test_preds.csv\"\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    # display(batch_progress_df)\n",
    "    # display(good_only_batch_progress_df)\n",
    "    display(batch_progress_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7dfb03f-b546-47f2-ab6f-e21d1a4d8fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a0s0', 'a0s1', 'a0s2', 'a0s3', 'a0s4', 'a0s5', 'a0s6', 'a0s7', 'a0s8', 'a0s9', 'a0s10', 'a0s11', 'a1s0', 'a1s1', 'a1s2', 'a1s3', 'a1s4', 'a1s5', 'a1s6', 'a1s7', 'a1s8', 'a1s9', 'a1s10', 'a1s11', 'a1s12', 'a1s13', 'a1s14', 'a1s15', 'a1s16', 'a1s17', 'a1s18', 'a1s19', 'a1s20', 'a1s21', 'a1s22', 'a1s23', 'a1s24', 'a1s25', 'a1s26', 'a1s27', 'a1s28', 'a1s29', 'a1s30', 'a1s31', 'a1s32', 'a1s33', 'a1s34', 'a1s35', 'a1s36', 'a1s37', 'a1s38', 'a1s39', 'a2s0', 'a2s1', 'a2s2', 'a2s3', 'a2s4', 'a2s5', 'a2s6', 'a2s7', 'a2s8', 'a2s9', 'a2s10', 'a2s11', 'a2s12', 'a2s13', 'a2s14', 'a2s15', 'a2s16', 'a2s17', 'a2s18', 'a2s19']\n"
     ]
    }
   ],
   "source": [
    "print(list(batch_progress_df.batch_results._build_minimal_session_identifiers_list().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "543306f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "format_name                             object\n",
       "animal                                  object\n",
       "exper_name                              object\n",
       "session_name                            object\n",
       "context                                 object\n",
       "basedirs                                object\n",
       "status                                  object\n",
       "errors                                  object\n",
       "n_long_laps                              int64\n",
       "n_long_replays                           int64\n",
       "n_short_laps                             int64\n",
       "n_short_replays                          int64\n",
       "is_ready                                  bool\n",
       "global_computation_result_file          object\n",
       "loaded_session_pickle_file              object\n",
       "ripple_result_file                      object\n",
       "has_user_replay_annotations               bool\n",
       "has_user_grid_bin_bounds_annotations      bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_progress_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f42b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Build `global_batch_run` pre-loading results (before execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496a7c6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# global_batch_result = loadData('global_batch_result.pkl')\n",
    "global_batch_run = run_diba_batch(global_data_root_parent_path, execute_all=False, extant_batch_run=global_batch_run, debug_print=False)\n",
    "# print(f'global_batch_result: {global_batch_run}')\n",
    "global_batch_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab824348",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Batch Executions/Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd73b8d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## I got it doing the bare-minimum loading and computations, so it should be ready to update the laps and constraint the placefields to those. Then we should be able to set up the replays at the same time.\n",
    "# finally, we then finish by computing.\n",
    "\n",
    "# included_session_contexts = batch_progress_df[np.logical_and(batch_progress_df['has_user_replay_annotations'], batch_progress_df['is_ready'])]['context'].to_numpy().tolist()\n",
    "\n",
    "# Only require sessions to have replay annotations:\n",
    "# included_session_contexts = batch_progress_df[batch_progress_df['has_user_replay_annotations']]['context'].to_numpy().tolist()\n",
    "\n",
    "## No filtering the sessions:\n",
    "included_session_contexts = None\n",
    "\n",
    "if included_session_contexts is not None:\n",
    "    print(f'len(included_session_contexts): {len(included_session_contexts)}')\n",
    "else:\n",
    "    print(f'included_session_contexts is None so all session contexts will be included.')\n",
    "\n",
    "# included_session_contexts\n",
    "\n",
    "# No Reloading\n",
    "# result_handler = BatchSessionCompletionHandler(force_reload_all=False,\n",
    "#                                                 session_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=False, should_save=False),\n",
    "#                                                 global_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=False, should_save=False),\n",
    "#                                                 should_perform_figure_generation_to_file=False, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_global_recompute=False)\n",
    "\n",
    "# Forced Reloading:\n",
    "result_handler = BatchSessionCompletionHandler(force_reload_all=True,\n",
    "                                                session_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=True),\n",
    "                                                global_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=True),\n",
    "                                                should_perform_figure_generation_to_file=True, saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE, force_global_recompute=True)\n",
    "\n",
    "# multiprocessing_kwargs = dict(use_multiprocessing=False, num_processes=1)\n",
    "multiprocessing_kwargs = dict(use_multiprocessing=True, num_processes=6)\n",
    "\n",
    "## Execute with the custom arguments.\n",
    "active_computation_functions_name_includelist=['_perform_baseline_placefield_computation',\n",
    "                                        # '_perform_time_dependent_placefield_computation',\n",
    "                                        '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        # '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding'\n",
    "                                    ]\n",
    "# active_computation_functions_name_includelist=['_perform_baseline_placefield_computation']\n",
    "global_batch_run.execute_all(force_reload=result_handler.force_reload_all, saving_mode=result_handler.saving_mode, skip_extended_batch_computations=True, post_run_callback_fn=result_handler.on_complete_success_execution_session,\n",
    "                             fail_on_exception=False, included_session_contexts=included_session_contexts,\n",
    "                                                                                        **{'computation_functions_name_includelist': active_computation_functions_name_includelist,\n",
    "                                                                                            'active_session_computation_configs': None,\n",
    "                                                                                            'allow_processing_previously_completed': True}, **multiprocessing_kwargs) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 4m 39.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab00d2-66a4-4087-81ed-7db2aec94aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to file:\n",
    "\n",
    "active_global_batch_result_filename\n",
    "\n",
    "saveData(global_batch_result_file_path, global_batch_run) # Update the global batch run dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac8e215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-07-31 Conversion\n",
    "# from pyphoplacecellanalysis.General.Batch.runBatch import SessionBatchProgress\n",
    "# pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing.SessionBatchProgress = SessionBatchProgress\n",
    "\n",
    "# old import\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import SessionBatchProgress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10dbee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enum 'SessionBatchProgress'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing.SessionBatchProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90cbc6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving (file mode 'w+b') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/global_batch_result_2023-07-31_Greatlakes.pkl... done.\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <enum 'SessionBatchProgress'>: it's not the same object as pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing.SessionBatchProgress",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m## Build Pickle Path:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m new_global_batch_result_file_path \u001b[39m=\u001b[39m Path(global_data_root_parent_path)\u001b[39m.\u001b[39mjoinpath(new_global_batch_result_filename)\u001b[39m.\u001b[39mresolve() \u001b[39m# Use Default\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m saveData(new_global_batch_result_file_path, global_batch_run) \u001b[39m# Update the global batch run dictionary\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m## Now throws: `PicklingError: Can't pickle : it's not the same object as pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing.SessionBatchProgress`\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Loading.py:35\u001b[0m, in \u001b[0;36msaveData\u001b[0;34m(pkl_path, db, should_append)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mwith\u001b[39;00m ProgressMessagePrinter(pkl_path, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSaving (file mode \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfile_mode\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msaved session pickle file\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     33\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(pkl_path, file_mode) \u001b[39mas\u001b[39;00m dbfile: \n\u001b[1;32m     34\u001b[0m         \u001b[39m# source, destination\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m         pickle\u001b[39m.\u001b[39;49mdump(db, dbfile)\n\u001b[1;32m     36\u001b[0m         dbfile\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/repos/Spike3D/.venv/lib/python3.9/site-packages/dill/_dill.py:336\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol, byref, fmode, recurse, **kwds)\u001b[0m\n\u001b[1;32m    334\u001b[0m _kwds \u001b[39m=\u001b[39m kwds\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m _kwds\u001b[39m.\u001b[39mupdate(\u001b[39mdict\u001b[39m(byref\u001b[39m=\u001b[39mbyref, fmode\u001b[39m=\u001b[39mfmode, recurse\u001b[39m=\u001b[39mrecurse))\n\u001b[0;32m--> 336\u001b[0m Pickler(file, protocol, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_kwds)\u001b[39m.\u001b[39;49mdump(obj)\n\u001b[1;32m    337\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/Spike3D/.venv/lib/python3.9/site-packages/dill/_dill.py:620\u001b[0m, in \u001b[0;36mPickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m    619\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 620\u001b[0m     StockPickler\u001b[39m.\u001b[39;49mdump(\u001b[39mself\u001b[39;49m, obj)\n\u001b[1;32m    621\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m    486\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mstart_framing()\n\u001b[0;32m--> 487\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave(obj)\n\u001b[1;32m    488\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(STOP)\n\u001b[1;32m    489\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mend_framing()\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         save(state)\n\u001b[1;32m    718\u001b[0m         write(BUILD)\n\u001b[1;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[1;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/Spike3D/.venv/lib/python3.9/site-packages/dill/_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[1;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[1;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[1;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m    996\u001b[0m         save(k)\n\u001b[0;32m--> 997\u001b[0m         save(v)\n\u001b[1;32m    998\u001b[0m     write(SETITEMS)\n\u001b[1;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/Spike3D/.venv/lib/python3.9/site-packages/dill/_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[1;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[1;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[1;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m    996\u001b[0m         save(k)\n\u001b[0;32m--> 997\u001b[0m         save(v)\n\u001b[1;32m    998\u001b[0m     write(SETITEMS)\n\u001b[1;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:691\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    689\u001b[0m     write(NEWOBJ)\n\u001b[1;32m    690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 691\u001b[0m     save(func)\n\u001b[1;32m    692\u001b[0m     save(args)\n\u001b[1;32m    693\u001b[0m     write(REDUCE)\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/Spike3D/.venv/lib/python3.9/site-packages/dill/_dill.py:1838\u001b[0m, in \u001b[0;36msave_type\u001b[0;34m(pickler, obj, postproc_list)\u001b[0m\n\u001b[1;32m   1836\u001b[0m             postproc_list \u001b[39m=\u001b[39m []\n\u001b[1;32m   1837\u001b[0m         postproc_list\u001b[39m.\u001b[39mappend((\u001b[39msetattr\u001b[39m, (obj, \u001b[39m'\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m'\u001b[39m, obj_name)))\n\u001b[0;32m-> 1838\u001b[0m     _save_with_postproc(pickler, (_create_type, (\n\u001b[1;32m   1839\u001b[0m         \u001b[39mtype\u001b[39;49m(obj), obj\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m, obj\u001b[39m.\u001b[39;49m\u001b[39m__bases__\u001b[39;49m, _dict\n\u001b[1;32m   1840\u001b[0m     )), obj\u001b[39m=\u001b[39;49mobj, postproc_list\u001b[39m=\u001b[39;49mpostproc_list)\n\u001b[1;32m   1841\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m _t)\n\u001b[1;32m   1842\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/repos/Spike3D/.venv/lib/python3.9/site-packages/dill/_dill.py:1140\u001b[0m, in \u001b[0;36m_save_with_postproc\u001b[0;34m(pickler, reduction, is_pickler_dill, obj, postproc_list)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     pickler\u001b[39m.\u001b[39m_postproc[\u001b[39mid\u001b[39m(obj)] \u001b[39m=\u001b[39m postproc_list\n\u001b[1;32m   1139\u001b[0m \u001b[39m# TODO: Use state_setter in Python 3.8 to allow for faster cPickle implementations\u001b[39;00m\n\u001b[0;32m-> 1140\u001b[0m pickler\u001b[39m.\u001b[39;49msave_reduce(\u001b[39m*\u001b[39;49mreduction, obj\u001b[39m=\u001b[39;49mobj)\n\u001b[1;32m   1142\u001b[0m \u001b[39mif\u001b[39;00m is_pickler_dill:\n\u001b[1;32m   1143\u001b[0m     \u001b[39m# pickler.x -= 1\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m     \u001b[39m# print(pickler.x*' ', 'pop', obj, id(obj))\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     postproc \u001b[39m=\u001b[39m pickler\u001b[39m.\u001b[39m_postproc\u001b[39m.\u001b[39mpop(\u001b[39mid\u001b[39m(obj))\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:692\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     save(func)\n\u001b[0;32m--> 692\u001b[0m     save(args)\n\u001b[1;32m    693\u001b[0m     write(REDUCE)\n\u001b[1;32m    695\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    696\u001b[0m     \u001b[39m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[1;32m    697\u001b[0m     \u001b[39m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[1;32m    698\u001b[0m     \u001b[39m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:901\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    899\u001b[0m write(MARK)\n\u001b[1;32m    900\u001b[0m \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[0;32m--> 901\u001b[0m     save(element)\n\u001b[1;32m    903\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n\u001b[1;32m    904\u001b[0m     \u001b[39m# Subtle.  d was not in memo when we entered save_tuple(), so\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     \u001b[39m# the process of saving the tuple's elements must have saved\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[39m# could have been done in the \"for element\" loop instead, but\u001b[39;00m\n\u001b[1;32m    910\u001b[0m     \u001b[39m# recursive tuples are a rare thing.\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     get \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(memo[\u001b[39mid\u001b[39m(obj)][\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/Spike3D/.venv/lib/python3.9/site-packages/dill/_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[1;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[1;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[1;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m    996\u001b[0m         save(k)\n\u001b[0;32m--> 997\u001b[0m         save(v)\n\u001b[1;32m    998\u001b[0m     write(SETITEMS)\n\u001b[1;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/Spike3D/.venv/lib/python3.9/site-packages/dill/_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[1;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[1;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[1;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m    996\u001b[0m         save(k)\n\u001b[0;32m--> 997\u001b[0m         save(v)\n\u001b[1;32m    998\u001b[0m     write(SETITEMS)\n\u001b[1;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:691\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    689\u001b[0m     write(NEWOBJ)\n\u001b[1;32m    690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 691\u001b[0m     save(func)\n\u001b[1;32m    692\u001b[0m     save(args)\n\u001b[1;32m    693\u001b[0m     write(REDUCE)\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/Spike3D/.venv/lib/python3.9/site-packages/dill/_dill.py:1851\u001b[0m, in \u001b[0;36msave_type\u001b[0;34m(pickler, obj, postproc_list)\u001b[0m\n\u001b[1;32m   1847\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39mCannot pickle \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m has recursive self-references that trigger a RecursionError.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (obj, obj\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m, obj_name), PicklingWarning)\n\u001b[1;32m   1848\u001b[0m        \u001b[39m#print (obj.__dict__)\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m        \u001b[39m#print (\"%s\\n%s\" % (type(obj), obj.__name__))\u001b[39;00m\n\u001b[1;32m   1850\u001b[0m        \u001b[39m#print (\"%s\\n%s\" % (obj.__bases__, obj.__dict__))\u001b[39;00m\n\u001b[0;32m-> 1851\u001b[0m         StockPickler\u001b[39m.\u001b[39;49msave_global(pickler, obj, name\u001b[39m=\u001b[39;49mobj_name)\n\u001b[1;32m   1852\u001b[0m         log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# T4\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1853\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/sw/pkgs/arc/python/3.9.12/lib/python3.9/pickle.py:1075\u001b[0m, in \u001b[0;36m_Pickler.save_global\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1074\u001b[0m     \u001b[39mif\u001b[39;00m obj2 \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m obj:\n\u001b[0;32m-> 1075\u001b[0m         \u001b[39mraise\u001b[39;00m PicklingError(\n\u001b[1;32m   1076\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m: it\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms not the same object as \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1077\u001b[0m             (obj, module_name, name))\n\u001b[1;32m   1079\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   1080\u001b[0m     code \u001b[39m=\u001b[39m _extension_registry\u001b[39m.\u001b[39mget((module_name, name))\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <enum 'SessionBatchProgress'>: it's not the same object as pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing.SessionBatchProgress"
     ]
    }
   ],
   "source": [
    "\n",
    "# pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing.SessionBatchProgress\n",
    "# Getting `PicklingError: Can't pickle : it's not found as pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing.SessionBatchProgress` after moving `SessionBatchProgress` from `pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing` to `pyphoplacecellanalysis.General.Batch.runBatch`\n",
    "new_global_batch_result_filename='global_batch_result_2023-07-31_Greatlakes.pkl'\n",
    "## Build Pickle Path:\n",
    "new_global_batch_result_file_path = Path(global_data_root_parent_path).joinpath(new_global_batch_result_filename).resolve() # Use Default\n",
    "saveData(new_global_batch_result_file_path, global_batch_run) # Update the global batch run dictionary\n",
    "\n",
    "## Now throws: `PicklingError: Can't pickle : it's not the same object as pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing.SessionBatchProgress`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511725ed-4794-44f4-b398-cf25dcb06201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list(global_batch_run.session_batch_outputs.keys())\n",
    "\n",
    "# Somewhere in there there are `InstantaneousSpikeRateGroupsComputation` results to extract\n",
    "across_sessions_instantaneous_fr_dict = {} # InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "for a_ctxt, a_result in global_batch_run.session_batch_outputs.items():\n",
    "    if a_result is not None:\n",
    "        a_good_result = a_result.get('across_sessions_batch_results', {}).get('inst_fr_comps', None)\n",
    "        if a_good_result is not None:\n",
    "            across_sessions_instantaneous_fr_dict[a_ctxt] = a_good_result\n",
    "            # print(a_result['across_sessions_batch_results']['inst_fr_comps'])\n",
    "            \n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "# When done, `result_handler.across_sessions_instantaneous_fr_dict` is now equivalent to what it would have been before. It can be saved using the normal `.save_across_sessions_data(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2131bc6-efb9-4768-87de-374d857c8227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-07-19.pkl'\n",
    "global_batch_result_inst_fr_file_path = Path(global_data_root_parent_path).joinpath(inst_fr_output_filename).resolve() # Use Default\n",
    "print(f'global_batch_result_inst_fr_file_path: {global_batch_result_inst_fr_file_path}')\n",
    "# Save the all sessions instantaneous firing rate dict to the path:\n",
    "saveData(global_batch_result_inst_fr_file_path, across_sessions_instantaneous_fr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf462d87-76a1-4a3b-b077-5215f433deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the instantaneous firing rate results dict: (# Dict[IdentifyingContext] = InstantaneousSpikeRateGroupsComputation)\n",
    "#TODO 2023-07-12 10:12: - [ ] New save way after we save out current result and reload\n",
    "result_handler.save_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-07-19.pkl')\n",
    "num_sessions = len(result_handler.across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be651cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2023-07-14 - Load Saved across-sessions-data and testing Batch-computed inst_firing_rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ad5bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_batch_result_inst_fr_file_path: /nfs/turbo/umms-kdiba/Data/across_session_result_handler_2023-07-21.pkl\n",
      "Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/across_session_result_handler_2023-07-21.pkl... done.\n",
      "num_sessions: 12\n",
      "num_sessions: 12\n"
     ]
    }
   ],
   "source": [
    "from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "# from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import list_of_dicts_to_dict_of_lists\n",
    "\n",
    "## Load the saved across-session results:\n",
    "# inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "# inst_fr_output_filename = 'across_session_result_long_short_inst_firing_rate.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-07-21.pkl'\n",
    "inst_fr_output_filename='across_session_result_handler_2023-07-21.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = BatchSessionCompletionHandler.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455519dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_progress_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc1152c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_sessions: 12\n",
      "WARNING: missing 3 keys from context: ['animal', 'exper_name', 'session_name']. Building path anyway.\n",
      "register_output_file(output_path: /home/halechr/repos/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-31/kdiba/12_2_inst_FR_bar_graphs.png, ...)\n",
      "\t saved /home/halechr/repos/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-31/kdiba/12_2_inst_FR_bar_graphs.png\n",
      "WARNING: missing 3 keys from context: ['animal', 'exper_name', 'session_name']. Building path anyway.\n",
      "register_output_file(output_path: /home/halechr/repos/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-31/kdiba/12_2_inst_FR_bar_graphs.png, ...)\n",
      "\t saved /home/halechr/repos/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-07-31/kdiba/12_2_inst_FR_bar_graphs.png\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "output_figure() missing 2 required positional arguments: 'final_context' and 'fig'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyphoplacecellanalysis\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mGeneral\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mBatch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mPhoDiba2023Paper\u001b[39;00m \u001b[39mimport\u001b[39;00m across_sessions_bar_graphs\n\u001b[1;32m      3\u001b[0m \u001b[39m## Hacks the `PaperFigureTwo` and `InstantaneousSpikeRateGroupsComputation` \u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m global_multi_session_context, _out_aggregate_fig_2 \u001b[39m=\u001b[39m across_sessions_bar_graphs(across_session_inst_fr_computation, num_sessions, enable_tiny_point_labels\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, enable_hover_labels\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/PhoDiba2023Paper.py:1101\u001b[0m, in \u001b[0;36macross_sessions_bar_graphs\u001b[0;34m(across_session_inst_fr_computation, num_sessions, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# Perform interactive Matplotlib operations with 'Qt5Agg' backend\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m _fig_2_theta_out, _fig_2_replay_out \u001b[39m=\u001b[39m _out_aggregate_fig_2\u001b[39m.\u001b[39mdisplay(active_context\u001b[39m=\u001b[39mglobal_multi_session_context, title_modifier_fn\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m original_title: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00moriginal_title\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00mnum_sessions\u001b[39m}\u001b[39;00m\u001b[39m sessions)\u001b[39m\u001b[39m\"\u001b[39m, save_figure\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1101\u001b[0m _out_aggregate_fig_2\u001b[39m.\u001b[39;49mperform_save()\n\u001b[1;32m   1103\u001b[0m global_multi_session_context, _out_aggregate_fig_2\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/PhoDiba2023Paper.py:1011\u001b[0m, in \u001b[0;36mPaperFigureTwo.perform_save\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" used to save the figure without needing a hard reference to curr_active_pipeline \"\"\"\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline_file_callback_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1011\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipeline_file_callback_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: output_figure() missing 2 required positional arguments: 'final_context' and 'fig'"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import across_sessions_bar_graphs\n",
    "\n",
    "## Hacks the `PaperFigureTwo` and `InstantaneousSpikeRateGroupsComputation` \n",
    "global_multi_session_context, _out_aggregate_fig_2 = across_sessions_bar_graphs(across_session_inst_fr_computation, num_sessions, enable_tiny_point_labels=False, enable_hover_labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381fcf5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "across_session_inst_fr_computation.LxC_scatter_props\n",
    "across_session_inst_fr_computation.SxC_scatter_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db1ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45d728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the unique scatter plot dictionaries:\n",
    "across_session_contexts = list(across_sessions_instantaneous_fr_dict.keys())\n",
    "unique_animals = IdentifyingContext.find_unique_values(across_session_contexts)['animal'] # {'gor01', 'pin01', 'vvp01'}\n",
    "# Get number of animals to plot\n",
    "marker_list = [(5, i) for i in np.arange(len(unique_animals))] # [(5, 0), (5, 1), (5, 2)]\n",
    "scatter_props = [{'marker': mkr} for mkr in marker_list]  # Example, you should provide your own scatter properties\n",
    "scatter_props_dict = dict(zip(unique_animals, scatter_props))\n",
    "# {'pin01': {'marker': (5, 0)},\n",
    "#  'gor01': {'marker': (5, 1)},\n",
    "#  'vvp01': {'marker': (5, 2)}}\n",
    "scatter_props_dict\n",
    "\n",
    "# Pass a function that will return a set of kwargs for a given context\n",
    "def _return_scatter_props_fn(ctxt: IdentifyingContext):\n",
    "\t\"\"\" captures `scatter_props_dict` \"\"\"\n",
    "\tanimal_id = str(ctxt.animal)\n",
    "\treturn scatter_props_dict[animal_id]\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63258151",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=num_sessions) # some global context across all of the sessions, not sure what to put here.\n",
    "\n",
    "# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\n",
    "\n",
    "## Display the aggregate across sessions:\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn't save this info\n",
    "_out_fig_2.computation_result = across_session_inst_fr_computation # the result loaded from the file\n",
    "_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\n",
    "# Set callback, the only self-specific property\n",
    "# _out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)\n",
    "_out_fig_2.scatter_props_fn = _return_scatter_props_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LxC_aclus = _out_fig_2.computation_result.LxC_aclus\n",
    "SxC_aclus = _out_fig_2.computation_result.SxC_aclus\n",
    "\n",
    "LxC_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c498f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureOutputManager, FigureOutputLocation, ContextToPathMode\n",
    "\n",
    "registered_output_files = {}\n",
    "\n",
    "def output_figure(final_context: IdentifyingContext, fig, write_vector_format:bool=False, write_png:bool=True, debug_print=True):\n",
    "    \"\"\" outputs the figure using the provided context. \"\"\"\n",
    "    from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_and_write_to_file\n",
    "    def register_output_file(output_path, output_metadata=None):\n",
    "        \"\"\" registers a new output file for the pipeline \"\"\"\n",
    "        print(f'register_output_file(output_path: {output_path}, ...)')\n",
    "        registered_output_files[output_path] = output_metadata or {}\n",
    "\n",
    "    fig_out_man = FigureOutputManager(figure_output_location=FigureOutputLocation.DAILY_PROGRAMMATIC_OUTPUT_FOLDER, context_to_path_mode=ContextToPathMode.HIERARCHY_UNIQUE)\n",
    "    active_out_figure_paths = build_and_write_to_file(fig, final_context, fig_out_man, write_vector_format=write_vector_format, write_png=write_png, register_output_file_fn=register_output_file)\n",
    "    return active_out_figure_paths, final_context\n",
    "\n",
    "\n",
    "# Set callback, the only self-specific property\n",
    "_out_fig_2._pipeline_file_callback_fn = output_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17b920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\n",
    "\t\n",
    "_out_fig_2.perform_save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32781c8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Single Session testing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_out = global_batch_run.execute_session(session_context=curr_sess_context, force_reload=True, skip_extended_batch_computations=True, computation_functions_name_includelist =['_perform_baseline_placefield_computation'], active_session_computation_configs=None) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "_test_out\n",
    "\n",
    "# global_batch_run.execute_session(session_context=curr_sess_context, force_reload=True, skip_extended_batch_computations=True, **{'computation_functions_name_includelist': ['_perform_baseline_placefield_computation'], 'active_session_computation_configs': None}) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 23.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf2bb67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "full_good_dirs = [k for k, v in global_batch_run.session_batch_errors.items() if v is None]\n",
    "bad_dirs = [k for k, v in global_batch_run.session_batch_errors.items() if v is not None]\n",
    "full_good_dirs\n",
    "bad_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f73f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_batch_run.session_batch_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcad70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_run.session_batch_status\n",
    "global_batch_run.session_batch_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15faf2bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get good sessions for use in the specific session processing notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed516134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf02efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get the list of sessions that are completely ready to process:\n",
    "full_good_ready_to_process_sessions = list(good_only_batch_progress_df['context'].to_numpy())\n",
    "full_good_ready_to_process_sessions\n",
    "# Get good sessions for use in the specific session processing notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ad809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run[\"good_sessions_list\"].extend(full_good_ready_to_process_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636e3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.stop()\n",
    "project.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf1322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\",\\n\".join([ctx.get_initialization_code_string() for ctx in full_good_ready_to_process_sessions])) # List definitions\n",
    "\n",
    "# [IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a4bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\ncurr_context = \".join([ctx.get_initialization_code_string() for ctx in full_good_ready_to_process_sessions])) # Line definitions\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5689d1d-6400-4f87-be0e-a184a1d5bee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82aedf-b024-4f07-b1a9-350730b4db8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "save_time = datetime.now()\n",
    " \n",
    "print(\"save_time =\", save_time)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = save_time.strftime(\"%Y-%m-%d_%I-%M%p\")\n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7bc6bd-5b34-41d0-b906-b0ad9927b08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get output file paths:\n",
    "completed_pipeline_filename = 'loadedSessPickle.pkl'\n",
    "completed_global_computations_filename = 'outputs/global_computation_results.pkl'\n",
    "\n",
    "full_good_ready_to_process_session_paths = list(good_only_batch_progress_df['basedirs'].to_numpy())\n",
    "session_paths_output_folders = [sess_path.joinpath('outputs').resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "\n",
    "completed_pipeline_file_paths = [sess_path.joinpath(completed_pipeline_filename).resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "completed_global_computations_file_paths = [sess_path.joinpath(completed_global_computations_filename).resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "completed_global_computations_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab75122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countable Additivity \n",
    "# Any countable collections of points is size 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af06e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
