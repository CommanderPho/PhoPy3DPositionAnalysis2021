{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from benedict import benedict\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from benedict import benedict # https://github.com/fabiocaccamo/python-benedict#usage\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import CodeConversion\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible, print_value_overview_only, document_active_variables, objsize, print_object_memory_usage, debug_dump_object_member_shapes, TypePrintMode\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import batch_load_session, batch_extended_computations, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "\n",
    "# from PendingNotebookCode import _perform_batch_plot, _build_batch_plot_kwargs\n",
    "\n",
    "session_batch_status = {}\n",
    "session_batch_errors = {}\n",
    "enable_saving_to_disk = False\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_session_names_list: ['2006-6-07_11-26-53', '2006-6-08_14-26-15', '2006-6-09_1-22-43', '2006-6-09_3-23-37', '2006-6-12_15-55-31', '2006-6-13_14-42-6']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-07_11-26-53'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_3-23-37'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-13_14-42-6'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "#     neuropy/data_session_pre_processing_scripts/KDIBA/IIDataMat_Export_ToPython_2022_08_01.m\n",
    "# From pre-computed .mat files:\n",
    "\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# Animal `gor01`:\n",
    "local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='one') # IdentifyingContext<('kdiba', 'gor01', 'one')>\n",
    "local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # 'gor01', 'one'\n",
    "local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['PhoHelpers', 'Spike3D-Minimal-Test', 'Unused'])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# ## Animal `vvp01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# ### Animal `pin01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='pin01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # no exper_name ('one' or 'two') folders for this animal.\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['redundant','showclus','sleep','tmaze'])\n",
    "\n",
    "## Build session contexts list:\n",
    "local_session_contexts_list = [local_session_parent_context.adding_context(collision_prefix='sess', session_name=a_name) for a_name in local_session_names_list] # [IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-07_11-26-53')>, ..., IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-13_14-42-6')>]\n",
    "\n",
    "## Initialize `session_batch_status` with the NOT_STARTED status if it doesn't already have a different status\n",
    "for curr_session_basedir in local_session_paths_list:\n",
    "    curr_session_status = session_batch_status.get(curr_session_basedir, None)\n",
    "    if curr_session_status is None:\n",
    "        session_batch_status[curr_session_basedir] = SessionBatchProgress.NOT_STARTED # set to not started if not present\n",
    "        # session_batch_status[curr_session_basedir] = SessionBatchProgress.COMPLETED # set to not started if not present\n",
    "\n",
    "session_batch_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d13e68b4-03e0-4388-a35c-87a352a6e6b3",
   "metadata": {
    "tags": [
     "load",
     "single_session",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl.\n",
      "property already present in pickled version. No need to save.\n",
      "using provided computation_functions_name_whitelist: ['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# %%viztracer\n",
    "basedir = local_session_paths_list[2] # NOT 3\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "## Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# epoch_name_whitelist = ['maze']\n",
    "epoch_name_whitelist = None\n",
    "active_computation_functions_name_whitelist=['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        # '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding'\n",
    "                                    ]\n",
    "curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_whitelist=epoch_name_whitelist,\n",
    "                                          computation_functions_name_whitelist=active_computation_functions_name_whitelist,\n",
    "                                          saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                          skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e403d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sane_midpoint_x: 119.8706391699152, hardcoded_track_midpoint_x: 150.0, track_min_max_x: (20.53900014070859, 260.280278480539)\n",
      "desc_crossings_x: (21,), asc_crossings_x: (22,)\n",
      "WARNING: must drop last asc_crossing_midpoints.\n"
     ]
    }
   ],
   "source": [
    "from neuropy.analyses.placefields import PfND\n",
    "from neuropy.analyses.laps import estimation_session_laps\n",
    "\n",
    "## 2023-04-07 - Builds the laps using estimation_session_laps(...) if needed for each epoch, and then sets the decoder's .epochs property to the laps object so the occupancy is correct.\n",
    "def constrain_to_laps(curr_active_pipeline):\n",
    "\t\"\"\" 2023-04-07 - Constrains the placefields to just the laps, computing the laps if needed.\n",
    "\tOther laps-related things?\n",
    "\t\t# ??? pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "\t\t# DataSession.compute_position_laps(self)\n",
    "\t\t# DataSession.compute_laps_position_df(position_df, laps_df)\n",
    "\t\"\"\"\n",
    "\tlong_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\tlong_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "\tlong_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "\n",
    "\t# curr_active_pipeline.computation_results\n",
    "\tfor a_name, a_sess, a_result in zip((long_epoch_name, short_epoch_name, global_epoch_name), (long_session, short_session, global_session), (long_results, short_results, global_results)):\n",
    "\t\ta_sess = estimation_session_laps(a_sess, should_plot_laps_2d=False)\n",
    "\t\t# # long_session.laps.as_epoch_obj()\n",
    "\t\tcurr_laps_obj = a_sess.laps.as_epoch_obj() # set this to the laps object\n",
    "\t\tcurr_laps_obj = curr_laps_obj.get_non_overlapping()\n",
    "\t\tcurr_laps_obj = curr_laps_obj.filtered_by_duration(1.0, 10.0) # the lap must be at least 1 second long and at most 10 seconds long\n",
    "\t\tcurr_active_pipeline.active_configs[a_name].computation_config.pf_params.computation_epochs = curr_laps_obj\n",
    "\t\tcurr_pf1D, curr_pf2D = a_result.pf1D, a_result.pf2D\n",
    "\n",
    "\t\tlap_filtered_curr_pf1D = deepcopy(curr_pf1D)\n",
    "\t\tlap_filtered_curr_pf1D = PfND(spikes_df=lap_filtered_curr_pf1D.spikes_df, position=lap_filtered_curr_pf1D.position, epochs=deepcopy(curr_laps_obj), config=lap_filtered_curr_pf1D.config, compute_on_init=True)\n",
    "\t\tlap_filtered_curr_pf2D = deepcopy(curr_pf2D)\n",
    "\t\tlap_filtered_curr_pf2D = PfND(spikes_df=lap_filtered_curr_pf2D.spikes_df, position=lap_filtered_curr_pf2D.position, epochs=deepcopy(curr_laps_obj), config=lap_filtered_curr_pf2D.config, compute_on_init=True)\n",
    "\t\ta_result.pf1D = lap_filtered_curr_pf1D\n",
    "\t\ta_result.pf2D = lap_filtered_curr_pf2D\n",
    "\t\treturn curr_active_pipeline\n",
    "\n",
    "curr_active_pipeline = constrain_to_laps(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02f14325",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D  = [results_data.get('pf1D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "recalculate_anyway = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f54a9300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20033,) should be less than time_window_edges: (29844,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20033,) should be less than time_window_edges: (29844,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "self will be re-binned to match target_pf...\n",
      "done.\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "decoding_time_bin_size: 0.03333\n"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_position_decoding_computation'], computation_kwargs_list=[dict(ndim=1)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "# long_one_step_decoder_1D, short_one_step_decoder_1D  = [results_data.get('pf1D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D  = [deepcopy(results_data.get('pf1D_Decoder', None)) for results_data in (long_results, short_results)]\n",
    "# ds and Decoders conform between the long and the short epochs:\n",
    "short_one_step_decoder_1D, did_recompute = short_one_step_decoder_1D.conform_to_position_bins(long_one_step_decoder_1D, force_recompute=True)\n",
    "\n",
    "# ## Build or get the two-step decoders for both the long and short:\n",
    "# long_two_step_decoder_1D, short_two_step_decoder_1D  = [results_data.get('pf1D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "# if recalculate_anyway or did_recompute or (long_two_step_decoder_1D is None) or (short_two_step_decoder_1D is None):\n",
    "#     curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_two_step_position_decoding_computation'], computation_kwargs_list=[dict(ndim=1)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "#     long_two_step_decoder_1D, short_two_step_decoder_1D  = [results_data.get('pf1D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "#     assert (long_two_step_decoder_1D is not None and short_two_step_decoder_1D is not None)\n",
    "\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "# decoding_time_bin_size = 0.03 # 0.03333333333333333\n",
    "print(f'decoding_time_bin_size: {decoding_time_bin_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e20ceb",
   "metadata": {},
   "source": [
    "#### Get 2D Decoders for validation and comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26c39017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend Qt5Agg is interactive backend. Turning interactive mode on.\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20033,) should be less than time_window_edges: (29844,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20033,) should be less than time_window_edges: (29844,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "self will be re-binned to match target_pf...\n",
      "done.\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "np.sum(long_one_step_decoder_2D.marginal.x.p_x_given_n) =30139.999999999978,\t np.sum(long_one_step_decoder_1D.p_x_given_n) = 30139.999999999996\n"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_position_decoding_computation'], computation_kwargs_list=[dict(ndim=2)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "# Make the 2D Placefields and Decoders conform between the long and the short epochs:\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "long_one_step_decoder_2D, short_one_step_decoder_2D  = [results_data.get('pf2D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "short_one_step_decoder_2D, did_recompute = short_one_step_decoder_2D.conform_to_position_bins(long_one_step_decoder_2D)\n",
    "\n",
    "# ## Build or get the two-step decoders for both the long and short:\n",
    "# long_two_step_decoder_2D, short_two_step_decoder_2D  = [results_data.get('pf2D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "# if recalculate_anyway or did_recompute or (long_two_step_decoder_2D is None) or (short_two_step_decoder_2D is None):\n",
    "#     curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_two_step_position_decoding_computation'], computation_kwargs_list=[dict(ndim=2)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "#     long_two_step_decoder_2D, short_two_step_decoder_2D  = [results_data.get('pf2D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "#     assert (long_two_step_decoder_2D is not None and short_two_step_decoder_2D is not None)\n",
    "# Sums are similar:\n",
    "print(f'{np.sum(long_one_step_decoder_2D.marginal.x.p_x_given_n) =},\\t {np.sum(long_one_step_decoder_1D.p_x_given_n) = }') # 31181.999999999996 vs 31181.99999999999\n",
    "\n",
    "## Validate:\n",
    "assert long_one_step_decoder_2D.marginal.x.p_x_given_n.shape == long_one_step_decoder_1D.p_x_given_n.shape, f\"Must equal but: {long_one_step_decoder_2D.marginal.x.p_x_given_n.shape =} and {long_one_step_decoder_1D.p_x_given_n.shape =}\"\n",
    "assert long_one_step_decoder_2D.marginal.x.most_likely_positions_1D.shape == long_one_step_decoder_1D.most_likely_positions.shape, f\"Must equal but: {long_one_step_decoder_2D.marginal.x.most_likely_positions_1D.shape =} and {long_one_step_decoder_1D.most_likely_positions.shape =}\"\n",
    "\n",
    "## validate values:\n",
    "# assert np.allclose(long_one_step_decoder_2D.marginal.x.p_x_given_n, long_one_step_decoder_1D.p_x_given_n), f\"1D Decoder should have an x-posterior equal to its own posterior\"\n",
    "# assert np.allclose(curr_epoch_result['marginal_x']['most_likely_positions_1D'], curr_epoch_result['most_likely_positions']), f\"1D Decoder should have an x-posterior with most_likely_positions_1D equal to its own most_likely_positions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048000a",
   "metadata": {},
   "source": [
    "# 2023-04-11 - Review of Year's Progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f50c94a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_display_1d_placefield_validations': ' Renders all of the flat 1D place cell validations with the yellow lines that trace across to their horizontally drawn placefield (rendered on the right of the plot) ',\n",
       " '_display_2d_placefield_result_plot_raw': ' produces a stupid figure ',\n",
       " '_display_1d_placefields': None,\n",
       " '_display_2d_placefield_result_plot_ratemaps_2D': ' displays 2D placefields in a MATPLOTLIB window \\n        \\n        Internally wraps `PfND.plot_ratemaps_2D` which itself wraps `neuropy.plotting.ratemaps.plot_ratemap_2D`\\n        \\n            optionally shows peak firing rates\\n            \\n            \\n        TODO: plot the information about the source of the data, such as the session information? Or perhaps we could just leave that encoded in the exported file name? It is hard to track the figures though\\n        \\n        ',\n",
       " '_display_normal': \"\\n        \\n        Internally wraps `neuropy.plotting.placemaps.plot_all_placefields` which itself wraps `PfND.plot_ratemaps_2D` which itself wraps `neuropy.plotting.ratemaps.plot_ratemap_2D`\\n        \\n        Usage:\\n            _display_normal(curr_kdiba_pipeline.computation_results['maze1'], curr_kdiba_pipeline.active_configs['maze1'])\\n        \",\n",
       " '_display_placemaps_pyqtplot_2D': '  displays 2D placefields in a pyqtgraph window\\n        ',\n",
       " '_display_recurrsive_latent_placefield_comparisons': \" Create `master_dock_win` - centralized plot output window to collect individual figures/controls in (2022-08-18) \\n            NOTE: Ignores `active_config` because context_nested_docks is for all contexts\\n            \\n            Usage:\\n            \\n                _out = curr_active_pipeline.display('_display_recurrsive_latent_placefield_comparisons', active_identifying_filtered_session_ctx)\\n                master_dock_win = _out['master_dock_win']\\n                curr_out_items = _out['out_items']\\n\\n            \",\n",
       " '_display_decoder_result': None,\n",
       " '_display_plot_decoded_epoch_slices': \" renders a plot with the 1D Marginals either (x and y position axes): the computed posterior for the position from the Bayesian decoder and overlays the animal's actual position over the top. \\n        \\n        TODO: This display function is currently atypically implemented as it performs computations as needed.\\n\\n        Depends on `_compute_specific_decoded_epochs` to compute the decoder for the epochs.\\n        The final step, which is where most display functions start, is calling the actual plot function:\\n            plot_decoded_epoch_slices(...)\\n\\n        Inputs:\\n            most_likely_positions_mode: 'standard'|'corrected'\\n        \\n        \\n        ax = destination_plot.ui.matplotlib_view_widget.ax,\\n        variable_name = 'x',\\n        \\n        \",\n",
       " '_display_plot_marginal_1D_most_likely_position_comparisons': \" renders a plot with the 1D Marginals either (x and y position axes): the computed posterior for the position from the Bayesian decoder and overlays the animal's actual position over the top. \\n        \\n        most_likely_positions_mode: 'standard'|'corrected'\\n        posterior_name: 'p_x_given_n'|'p_x_given_n_and_x_prev'\\n        \\n        ax = destination_plot.ui.matplotlib_view_widget.ax,\\n        variable_name = 'x',\\n        \\n        \",\n",
       " '_display_plot_most_likely_position_comparisons': \" renders a 2D plot with separate subplots for the (x and y position axes): the computed posterior for the position from the Bayesian decoder and overlays the animal's actual position over the top. \",\n",
       " '_display_two_step_decoder_prediction_error_2D': ' Plots the prediction error for the two_step decoder at each point in time.\\n                Based off of \"_temp_debug_two_step_plots_animated_imshow\"\\n                \\n                THIS ONE WORKS. \\n            ',\n",
       " '_display_spike_rasters_pyqtplot_2D': ' Plots a standalone 2D raster plot\\n        ',\n",
       " '_display_spike_rasters_pyqtplot_3D': ' Plots a standalone 3D raster plot with independent/standalone controls built-in\\n        ',\n",
       " '_display_spike_rasters_pyqtplot_3D_with_2D_controls': ' Plots a standalone 3D raster plot (via pyqtgraph) with a separate 2D raster plot as the window with which you can adjust the viewed window. \\n        ',\n",
       " '_display_spike_rasters_vedo_3D': ' Plots a standalone 3D raster plot with independent/standalone controls built-in\\n        ',\n",
       " '_display_spike_rasters_vedo_3D_with_2D_controls': ' Plots a standalone 3D raster plot (via Vedo) with a separate 2D raster plot as the window with which you can adjust the viewed window. \\n        ',\n",
       " '_display_spike_rasters_window': ' Displays a Spike3DRasterWindowWidget with a configurable set of raster widgets and controls in it.\\n        ',\n",
       " '_display_pf_peak_prominence2d_default_quadrant_plots': \" Plots the 4-quadrant figure generated by default from peak_rpominence2d to show the found prominence peaks\\n            \\n            Usage:\\n                curr_display_function_name = '_display_pf_peak_prominence2d_plots'\\n                out_figs, out_axes, out_idxs = curr_active_pipeline.display(curr_display_function_name, active_config_name) \\n                curr_display_function_name = 'plot_Prominence'\\n                built_pdf_metadata, curr_pdf_save_path = _build_pdf_pages_output_info(curr_display_function_name)\\n                with backend_pdf.PdfPages(curr_pdf_save_path, keep_empty=False, metadata=built_pdf_metadata) as pdf:\\n                    for an_idx, a_fig in zip(active_peak_prominence_2d_results.neuron_extended_ids, out_figs):\\n                        a_fig.suptitle(f'neuron: {an_idx.id}', fontsize=16)\\n                        pdf.savefig(a_fig)\\n            \",\n",
       " '_display_pf_peak_prominence2d_plots': \" Plots a the custom placefield width/height results for each peak belonging to a single neuron/ratemap.\\n                Uses the prominence2d results\\n            Usage:\\n                curr_display_function_name = '_display_pf_peak_prominence2d_plots'\\n                figure, ax = curr_active_pipeline.display(curr_display_function_name, active_config_name, neuron_id=5) \\n\\n            \",\n",
       " '_display_speed_vs_PFoverlapDensity_plots': ' Plot the 1D and 2D sorted avg_speed_per_pos and PFoverlapDensity to reveal any trends\\n        ',\n",
       " '_display_3d_image_plotter': \" \\n        Inputs: {'extant_plotter': None} \\n        Outputs: {'plotter'}\\n        \",\n",
       " '_display_3d_interactive_custom_data_explorer': \" \\n        Inputs: {'extant_plotter': None} \\n        Outputs: {'iplapsDataExplorer', 'plotter'}\\n        \",\n",
       " '_display_3d_interactive_spike_and_behavior_browser': \" \\n        Inputs: {'extant_plotter': None} \\n        Outputs: {'ipspikesDataExplorer', 'plotter'}\\n        \",\n",
       " '_display_3d_interactive_tuning_curves_plotter': \" \\n        Inputs: {'extant_plotter': None} \\n        Outputs: {'ipcDataExplorer', 'plotter', 'pane'}\\n        \\n        Optional Keywords:\\n            override_pf2D: the placefield PfND or PfND_TimeDependent object to use as the source data.\\n        \\n        \",\n",
       " 'display_firing_rate_trends': \" DOCTODO\\n        \\n        TODO: this sucks, it displays a beeswarm plot that locks everything up for minutes\\n        \\n        \\n        Usage:\\n        \\n            # np.shape(active_one_step_decoder.active_time_windows) # (2892, 2)\\n\\n            active_firing_rate_trends = computation_result.computed_data['firing_rate_trends']\\n\\n            active_rolling_window_times = active_firing_rate_trends['active_rolling_window_times']\\n            mean_firing_rates = active_firing_rate_trends['mean_firing_rates']\\n            moving_mean_firing_rates_df = active_firing_rate_trends['moving_mean_firing_rates_df']\\n            moving_mean_firing_rates_df # 3969 rows x 43 columns\\n\\n            # mean_firing_rates\\n            # pg.plot(mean_firing_rates)\\n\\n            np.shape(moving_mean_firing_rates_df) # (3969, 43)\\n            good_only_moving_mean_firing_rates_df = moving_mean_firing_rates_df.dropna() # 3910 rows x 43 columns\\n            good_only_moving_mean_firing_rates_df.T\\n            err, win = _display_firing_rate_trends(good_only_moving_mean_firing_rates_df.T)\\n            win.show()\\n\\n            # active_rolling_window_times # dtype='timedelta64[ns]', name='time_delta_sec', length=2900, freq='S'\\n            # pg.plot(moving_mean_firing_rates_df)\\n\\n        \",\n",
       " '_display_batch_pho_jonathan_replay_firing_rate_comparison': \" Stacked Jonathan-style firing-rate-across-epochs-plot. Pho's batch adaptation of the primary elements from Jonathan's interactive display.\\n                Usage:\\n\\n                    %matplotlib qt\\n                    active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\\n\\n                    graphics_output_dict = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', active_identifying_session_ctx)\\n                    fig, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['axs'], graphics_output_dict['plot_data']\\n                    neuron_df, rdf, aclu_to_idx, irdf = plot_data['df'], plot_data['rdf'], plot_data['aclu_to_idx'], plot_data['irdf']\\n                    # Grab the output axes:\\n                    curr_axs_dict = axs[0]\\n                    curr_firing_rate_ax, curr_lap_spikes_ax, curr_placefield_ax = curr_axs_dict['firing_rate'], curr_axs_dict['lap_spikes'], curr_axs_dict['placefield'] # Extract variables from the `curr_axs_dict` dictionary to the local workspace\\n\\n            \",\n",
       " '_display_context_nested_docks': \" Create `master_dock_win` - centralized plot output window to collect individual figures/controls in (2022-08-18)\\n        NOTE: Ignores `active_config` because context_nested_docks is for all contexts\\n\\n        Input:\\n            owning_pipeline_reference: A reference to the pipeline upon which this display function is being called\\n\\n        Usage:\\n\\n        display_output = active_display_output | curr_active_pipeline.display('_display_context_nested_docks', active_identifying_filtered_session_ctx, enable_gui=False, debug_print=False) # returns {'master_dock_win': master_dock_win, 'app': app, 'out_items': out_items}\\n        master_dock_win = display_output['master_dock_win']\\n        app = display_output['app']\\n        out_items = display_output['out_items']\\n\\n        \",\n",
       " '_display_jonathan_interactive_replay_firing_rate_comparison': \" Jonathan's interactive display. Currently hacked up to directly compute the results to display within this function\\n                Internally calls `_make_jonathan_interactive_plot(...)`\\n\\n                Usage:\\n                active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\\n                curr_active_pipeline.display('_display_jonathan_replay_firing_rate_comparison', active_identifying_session_ctx)\\n\\n            \",\n",
       " '_display_short_long_firing_rate_index_comparison': \" Displays a figure for comparing the 1D placefields across-epochs (between the short and long tracks)\\n                Usage:\\n\\n                    %matplotlib qt\\n                    active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\\n\\n                    graphics_output_dict = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', active_identifying_session_ctx)\\n                    fig, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['axs'], graphics_output_dict['plot_data']\\n                    neuron_df, rdf, aclu_to_idx, irdf = plot_data['df'], plot_data['rdf'], plot_data['aclu_to_idx'], plot_data['irdf']\\n                    # Grab the output axes:\\n                    curr_axs_dict = axs[0]\\n                    curr_firing_rate_ax, curr_lap_spikes_ax, curr_placefield_ax = curr_axs_dict['firing_rate'], curr_axs_dict['lap_spikes'], curr_axs_dict['placefield'] # Extract variables from the `curr_axs_dict` dictionary to the local workspace\\n\\n            \",\n",
       " '_display_short_long_pf1D_comparison': \" Displays a figure for comparing the 1D placefields across-epochs (between the short and long tracks). By default renders the second track's placefield flipped over the x-axis and hatched. \\n                Usage:\\n\\n                    %matplotlib qt\\n                    active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\\n\\n                    graphics_output_dict = curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_identifying_session_ctx)\\n                    fig, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['axs'], graphics_output_dict['plot_data']\\n                    \\n\\n            \",\n",
       " '_display_short_long_pf1D_scalar_overlap_comparison': \" Displays a figure for comparing the scalar comparison quantities computed for 1D placefields across-epochs (between the short and long tracks)\\n                This currently renders as a bar-graph\\n\\n                Usage:\\n\\n                    %matplotlib qt\\n                    active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\\n\\n                    graphics_output_dict = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', active_identifying_session_ctx)\\n                    fig, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['axs'], graphics_output_dict['plot_data']\\n                    neuron_df, rdf, aclu_to_idx, irdf = plot_data['df'], plot_data['rdf'], plot_data['aclu_to_idx'], plot_data['irdf']\\n                    # Grab the output axes:\\n                    curr_axs_dict = axs[0]\\n                    curr_firing_rate_ax, curr_lap_spikes_ax, curr_placefield_ax = curr_axs_dict['firing_rate'], curr_axs_dict['lap_spikes'], curr_axs_dict['placefield'] # Extract variables from the `curr_axs_dict` dictionary to the local workspace\\n\\n            \"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for interactive\n",
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37d48a74",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_display_short_long_firing_rate_index_comparison() missing 2 required positional arguments: 'computation_results' and 'active_configs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m curr_active_pipeline\u001b[39m.\u001b[39;49mplot\u001b[39m.\u001b[39;49m_display_short_long_firing_rate_index_comparison\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Display.py:52\u001b[0m, in \u001b[0;36mPlot.__getattr__\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[39mreturn\u001b[39;00m _dummy\n\u001b[0;32m     50\u001b[0m \u001b[39m# return self[k]\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39m# return self._pipeline_reference.display(display_function=k, active_identifying_session_ctx=self._pipeline_reference.sess.get_context())\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipeline_reference\u001b[39m.\u001b[39;49mdisplay(display_function\u001b[39m=\u001b[39;49mk, active_session_configuration_context\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipeline_reference\u001b[39m.\u001b[39;49mfiltered_contexts\u001b[39m.\u001b[39;49mvalues())[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Display.py:386\u001b[0m, in \u001b[0;36mPipelineWithDisplayPipelineStageMixin.display\u001b[1;34m(self, display_function, active_session_configuration_context, **kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m active_display_fn_identifying_ctx \u001b[39m=\u001b[39m active_session_configuration_context\u001b[39m.\u001b[39madding_context(\u001b[39m'\u001b[39m\u001b[39mdisplay_fn\u001b[39m\u001b[39m'\u001b[39m, display_fn_name\u001b[39m=\u001b[39mdisplay_fn_name) \u001b[39m# display_fn_name should be like '_display_1d_placefields'\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39m# Add the display outputs to the active context. Each display function should return a structure like: dict(fig=active_figure, ax=ax_pf_1D)\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[39m# owning_pipeline.display_output[active_display_fn_identifying_ctx] = (active_figure, ax_pf_1D)\u001b[39;00m\n\u001b[1;32m--> 386\u001b[0m curr_display_output \u001b[39m=\u001b[39m display_function(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomputation_results[active_session_configuration_name], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactive_configs[active_session_configuration_name], owning_pipeline\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, active_config_name\u001b[39m=\u001b[39mactive_session_configuration_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    387\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisplay_output[active_display_fn_identifying_ctx] \u001b[39m=\u001b[39m curr_display_output \u001b[39m# sets the internal display reference to that item\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[39mreturn\u001b[39;00m curr_display_output\n",
      "\u001b[1;31mTypeError\u001b[0m: _display_short_long_firing_rate_index_comparison() missing 2 required positional arguments: 'computation_results' and 'active_configs'"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.plot._display_short_long_firing_rate_index_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0431c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot.display_short_long_firing_rate_index_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4c69d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
