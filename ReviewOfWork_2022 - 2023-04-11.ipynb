{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from benedict import benedict\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from benedict import benedict # https://github.com/fabiocaccamo/python-benedict#usage\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import CodeConversion\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible, print_value_overview_only, document_active_variables, objsize, print_object_memory_usage, debug_dump_object_member_shapes, TypePrintMode\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import batch_load_session, batch_extended_computations, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "\n",
    "# from PendingNotebookCode import _perform_batch_plot, _build_batch_plot_kwargs\n",
    "\n",
    "session_batch_status = {}\n",
    "session_batch_errors = {}\n",
    "enable_saving_to_disk = False\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_session_names_list: ['2006-6-07_11-26-53', '2006-6-08_14-26-15', '2006-6-09_1-22-43', '2006-6-09_3-23-37', '2006-6-12_15-55-31', '2006-6-13_14-42-6']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-07_11-26-53'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_3-23-37'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-13_14-42-6'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "#     neuropy/data_session_pre_processing_scripts/KDIBA/IIDataMat_Export_ToPython_2022_08_01.m\n",
    "# From pre-computed .mat files:\n",
    "\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# Animal `gor01`:\n",
    "local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='one') # IdentifyingContext<('kdiba', 'gor01', 'one')>\n",
    "local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # 'gor01', 'one'\n",
    "local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['PhoHelpers', 'Spike3D-Minimal-Test', 'Unused'])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# ## Animal `vvp01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# ### Animal `pin01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='pin01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # no exper_name ('one' or 'two') folders for this animal.\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['redundant','showclus','sleep','tmaze'])\n",
    "\n",
    "## Build session contexts list:\n",
    "local_session_contexts_list = [local_session_parent_context.adding_context(collision_prefix='sess', session_name=a_name) for a_name in local_session_names_list] # [IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-07_11-26-53')>, ..., IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-13_14-42-6')>]\n",
    "\n",
    "## Initialize `session_batch_status` with the NOT_STARTED status if it doesn't already have a different status\n",
    "for curr_session_basedir in local_session_paths_list:\n",
    "    curr_session_status = session_batch_status.get(curr_session_basedir, None)\n",
    "    if curr_session_status is None:\n",
    "        session_batch_status[curr_session_basedir] = SessionBatchProgress.NOT_STARTED # set to not started if not present\n",
    "        # session_batch_status[curr_session_basedir] = SessionBatchProgress.COMPLETED # set to not started if not present\n",
    "\n",
    "session_batch_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d13e68b4-03e0-4388-a35c-87a352a6e6b3",
   "metadata": {
    "tags": [
     "load",
     "single_session",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl.\n",
      "property already present in pickled version. No need to save.\n",
      "using provided computation_functions_name_whitelist: ['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# %%viztracer\n",
    "basedir = local_session_paths_list[2] # NOT 3\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "## Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# epoch_name_whitelist = ['maze']\n",
    "epoch_name_whitelist = None\n",
    "active_computation_functions_name_whitelist=['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        # '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding'\n",
    "                                    ]\n",
    "curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_whitelist=epoch_name_whitelist,\n",
    "                                          computation_functions_name_whitelist=active_computation_functions_name_whitelist,\n",
    "                                          saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                          skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e403d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sane_midpoint_x: 119.8706391699152, hardcoded_track_midpoint_x: 150.0, track_min_max_x: (20.53900014070859, 260.280278480539)\n",
      "desc_crossings_x: (21,), asc_crossings_x: (22,)\n",
      "WARNING: must drop last asc_crossing_midpoints.\n"
     ]
    }
   ],
   "source": [
    "from neuropy.analyses.placefields import PfND\n",
    "from neuropy.analyses.laps import estimation_session_laps\n",
    "\n",
    "## 2023-04-07 - Builds the laps using estimation_session_laps(...) if needed for each epoch, and then sets the decoder's .epochs property to the laps object so the occupancy is correct.\n",
    "def constrain_to_laps(curr_active_pipeline):\n",
    "\t\"\"\" 2023-04-07 - Constrains the placefields to just the laps, computing the laps if needed.\n",
    "\tOther laps-related things?\n",
    "\t\t# ??? pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "\t\t# DataSession.compute_position_laps(self)\n",
    "\t\t# DataSession.compute_laps_position_df(position_df, laps_df)\n",
    "\t\"\"\"\n",
    "\tlong_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\tlong_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "\tlong_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "\n",
    "\t# curr_active_pipeline.computation_results\n",
    "\tfor a_name, a_sess, a_result in zip((long_epoch_name, short_epoch_name, global_epoch_name), (long_session, short_session, global_session), (long_results, short_results, global_results)):\n",
    "\t\ta_sess = estimation_session_laps(a_sess, should_plot_laps_2d=False)\n",
    "\t\t# # long_session.laps.as_epoch_obj()\n",
    "\t\tcurr_laps_obj = a_sess.laps.as_epoch_obj() # set this to the laps object\n",
    "\t\tcurr_laps_obj = curr_laps_obj.get_non_overlapping()\n",
    "\t\tcurr_laps_obj = curr_laps_obj.filtered_by_duration(1.0, 10.0) # the lap must be at least 1 second long and at most 10 seconds long\n",
    "\t\tcurr_active_pipeline.active_configs[a_name].computation_config.pf_params.computation_epochs = curr_laps_obj\n",
    "\t\tcurr_pf1D, curr_pf2D = a_result.pf1D, a_result.pf2D\n",
    "\n",
    "\t\tlap_filtered_curr_pf1D = deepcopy(curr_pf1D)\n",
    "\t\tlap_filtered_curr_pf1D = PfND(spikes_df=lap_filtered_curr_pf1D.spikes_df, position=lap_filtered_curr_pf1D.position, epochs=deepcopy(curr_laps_obj), config=lap_filtered_curr_pf1D.config, compute_on_init=True)\n",
    "\t\tlap_filtered_curr_pf2D = deepcopy(curr_pf2D)\n",
    "\t\tlap_filtered_curr_pf2D = PfND(spikes_df=lap_filtered_curr_pf2D.spikes_df, position=lap_filtered_curr_pf2D.position, epochs=deepcopy(curr_laps_obj), config=lap_filtered_curr_pf2D.config, compute_on_init=True)\n",
    "\t\ta_result.pf1D = lap_filtered_curr_pf1D\n",
    "\t\ta_result.pf2D = lap_filtered_curr_pf2D\n",
    "\t\treturn curr_active_pipeline\n",
    "\n",
    "curr_active_pipeline = constrain_to_laps(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02f14325",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D  = [results_data.get('pf1D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "recalculate_anyway = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f54a9300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20033,) should be less than time_window_edges: (29844,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20033,) should be less than time_window_edges: (29844,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "self will be re-binned to match target_pf...\n",
      "done.\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "decoding_time_bin_size: 0.03333\n"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_position_decoding_computation'], computation_kwargs_list=[dict(ndim=1)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "# long_one_step_decoder_1D, short_one_step_decoder_1D  = [results_data.get('pf1D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D  = [deepcopy(results_data.get('pf1D_Decoder', None)) for results_data in (long_results, short_results)]\n",
    "# ds and Decoders conform between the long and the short epochs:\n",
    "short_one_step_decoder_1D, did_recompute = short_one_step_decoder_1D.conform_to_position_bins(long_one_step_decoder_1D, force_recompute=True)\n",
    "\n",
    "# ## Build or get the two-step decoders for both the long and short:\n",
    "# long_two_step_decoder_1D, short_two_step_decoder_1D  = [results_data.get('pf1D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "# if recalculate_anyway or did_recompute or (long_two_step_decoder_1D is None) or (short_two_step_decoder_1D is None):\n",
    "#     curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_two_step_position_decoding_computation'], computation_kwargs_list=[dict(ndim=1)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "#     long_two_step_decoder_1D, short_two_step_decoder_1D  = [results_data.get('pf1D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "#     assert (long_two_step_decoder_1D is not None and short_two_step_decoder_1D is not None)\n",
    "\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "# decoding_time_bin_size = 0.03 # 0.03333333333333333\n",
    "print(f'decoding_time_bin_size: {decoding_time_bin_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e20ceb",
   "metadata": {},
   "source": [
    "#### Get 2D Decoders for validation and comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26c39017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20033,) should be less than time_window_edges: (29844,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (20033,) should be less than time_window_edges: (29844,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "self will be re-binned to match target_pf...\n",
      "done.\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "np.sum(long_one_step_decoder_2D.marginal.x.p_x_given_n) =30139.999999999978,\t np.sum(long_one_step_decoder_1D.p_x_given_n) = 30139.999999999996\n"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_position_decoding_computation'], computation_kwargs_list=[dict(ndim=2)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "# Make the 2D Placefields and Decoders conform between the long and the short epochs:\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "long_one_step_decoder_2D, short_one_step_decoder_2D  = [results_data.get('pf2D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "short_one_step_decoder_2D, did_recompute = short_one_step_decoder_2D.conform_to_position_bins(long_one_step_decoder_2D)\n",
    "\n",
    "# ## Build or get the two-step decoders for both the long and short:\n",
    "# long_two_step_decoder_2D, short_two_step_decoder_2D  = [results_data.get('pf2D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "# if recalculate_anyway or did_recompute or (long_two_step_decoder_2D is None) or (short_two_step_decoder_2D is None):\n",
    "#     curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_two_step_position_decoding_computation'], computation_kwargs_list=[dict(ndim=2)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "#     long_two_step_decoder_2D, short_two_step_decoder_2D  = [results_data.get('pf2D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "#     assert (long_two_step_decoder_2D is not None and short_two_step_decoder_2D is not None)\n",
    "# Sums are similar:\n",
    "print(f'{np.sum(long_one_step_decoder_2D.marginal.x.p_x_given_n) =},\\t {np.sum(long_one_step_decoder_1D.p_x_given_n) = }') # 31181.999999999996 vs 31181.99999999999\n",
    "\n",
    "## Validate:\n",
    "assert long_one_step_decoder_2D.marginal.x.p_x_given_n.shape == long_one_step_decoder_1D.p_x_given_n.shape, f\"Must equal but: {long_one_step_decoder_2D.marginal.x.p_x_given_n.shape =} and {long_one_step_decoder_1D.p_x_given_n.shape =}\"\n",
    "assert long_one_step_decoder_2D.marginal.x.most_likely_positions_1D.shape == long_one_step_decoder_1D.most_likely_positions.shape, f\"Must equal but: {long_one_step_decoder_2D.marginal.x.most_likely_positions_1D.shape =} and {long_one_step_decoder_1D.most_likely_positions.shape =}\"\n",
    "\n",
    "## validate values:\n",
    "# assert np.allclose(long_one_step_decoder_2D.marginal.x.p_x_given_n, long_one_step_decoder_1D.p_x_given_n), f\"1D Decoder should have an x-posterior equal to its own posterior\"\n",
    "# assert np.allclose(curr_epoch_result['marginal_x']['most_likely_positions_1D'], curr_epoch_result['most_likely_positions']), f\"1D Decoder should have an x-posterior with most_likely_positions_1D equal to its own most_likely_positions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20cee514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n"
     ]
    }
   ],
   "source": [
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_time_dependent_placefield_computation'], enabled_filter_names=[long_epoch_name, short_epoch_name, global_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "\n",
    "# long_results.pf1D_dt.reset()\n",
    "# long_results.pf1D_dt._included_thresh_neurons_indx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b21fb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spikes_df':                  t      t_seconds  t_rel_seconds  shank  cluster  aclu  qclu  \\\n",
       " 1            101.0  643040.536897       0.003103     12        7    98     1   \n",
       " 6            222.0  643040.540614       0.006820     12        7    98     1   \n",
       " 10           368.0  643040.545099       0.011305     12        7    98     1   \n",
       " 13           603.0  643040.552318       0.018524     12        7    98     1   \n",
       " 31          1320.0  643040.574344       0.040550     12        7    98     1   \n",
       " ...            ...            ...            ...    ...      ...   ...   ...   \n",
       " 524038  33504176.0  644069.781554    1029.247760      2       31    28     2   \n",
       " 524039  33504255.0  644069.783981    1029.250187      2        2    13     2   \n",
       " 524040  33504281.0  644069.784779    1029.250985      8        5    57     2   \n",
       " 524046  33504789.0  644069.800385    1029.266591      8        5    57     2   \n",
       " 524072  33506370.0  644069.848953    1029.315159      1       14     9     2   \n",
       " \n",
       "                  x           y      speed  ...  maze_relative_lap  maze_id  \\\n",
       " 1       149.051586   65.778444   0.000000  ...                 -1        1   \n",
       " 6       149.051586   65.778444   0.000000  ...                 -1        1   \n",
       " 10      149.051586   65.778444   0.000000  ...                 -1        1   \n",
       " 13      149.051586   65.778444   0.000000  ...                 -1        1   \n",
       " 31      149.051586   65.778444   0.000000  ...                 -1        1   \n",
       " ...            ...         ...        ...  ...                ...      ...   \n",
       " 524038  198.702047  134.031830  21.834145  ...                 -1        1   \n",
       " 524039  198.646939  134.045052  22.012574  ...                 -1        1   \n",
       " 524040  198.628802  134.049404  22.071297  ...                 -1        1   \n",
       " 524046  198.294397  134.157374  22.333615  ...                 -1        1   \n",
       " 524072  197.468875  134.540132  17.277974  ...                 -1        1   \n",
       " \n",
       "                    cell_type  flat_spike_idx  x_loaded  y_loaded    lin_pos  \\\n",
       " 1       NeuronType.PYRAMIDAL               1       NaN       NaN  27.752915   \n",
       " 6       NeuronType.PYRAMIDAL               6       NaN       NaN  27.752915   \n",
       " 10      NeuronType.PYRAMIDAL              10       NaN       NaN  27.752915   \n",
       " 13      NeuronType.PYRAMIDAL              13       NaN       NaN  27.752915   \n",
       " 31      NeuronType.PYRAMIDAL              31       NaN       NaN  27.752915   \n",
       " ...                      ...             ...       ...       ...        ...   \n",
       " 524038  NeuronType.PYRAMIDAL          524038  0.715257  0.477187 -22.383369   \n",
       " 524039  NeuronType.PYRAMIDAL          524039  0.715074  0.477166 -22.349705   \n",
       " 524040  NeuronType.PYRAMIDAL          524040  0.715014  0.477158 -22.338625   \n",
       " 524046  NeuronType.PYRAMIDAL          524046  0.713856  0.476947 -22.196319   \n",
       " 524072  NeuronType.PYRAMIDAL          524072  0.710309  0.476170 -27.157040   \n",
       " \n",
       "         fragile_linear_neuron_IDX  PBE_id      scISI  \n",
       " 1                              96      -1        NaN  \n",
       " 6                              96      -1   0.003717  \n",
       " 10                             96      -1   0.004485  \n",
       " 13                             96      -1   0.007219  \n",
       " 31                             96      -1   0.022026  \n",
       " ...                           ...     ...        ...  \n",
       " 524038                         26      -1   0.120914  \n",
       " 524039                         11      -1   0.124293  \n",
       " 524040                         55      -1   0.092283  \n",
       " 524046                         55      -1   0.015606  \n",
       " 524072                          7      -1  13.426507  \n",
       " \n",
       " [76534 rows x 22 columns],\n",
       " 'position': <Position: {'_filename': None, '_metadata': None, '_data':                  t    lin_pos          x      speed\n",
       " 0         0.150794  27.752915  27.752915   0.000000\n",
       " 1         0.184080  27.873635  27.873635   3.617933\n",
       " 2         0.217780  28.088848  28.088848   6.449885\n",
       " 3         0.251359  28.354823  28.354823   7.971213\n",
       " 4         0.285226  28.621418  28.621418   7.989786\n",
       " ...            ...        ...        ...        ...\n",
       " 30839  1029.155519 -23.883073 -23.883073  18.705413\n",
       " 30840  1029.189352 -23.281045 -23.281045  18.042633\n",
       " 30841  1029.222954 -22.727464 -22.727464  16.590706\n",
       " 30842  1029.254903 -22.284281 -22.284281  13.282068\n",
       " 30843  1029.288295 -22.032979 -22.032979   7.531470\n",
       " \n",
       " [30844 rows x 4 columns]};>,\n",
       " 'epochs': None,\n",
       " 'config': <PlacefieldComputationParameters: {'speed_thresh': 10.0, 'grid_bin': (3.8054171165052444, 1.4477079927649104), 'grid_bin_bounds': (None, None), 'smooth': (2.0, 2.0), 'frate_thresh': 0.2};>,\n",
       " 'position_srate': 29.969756198785802,\n",
       " 'setup_on_init': True,\n",
       " 'compute_on_init': True,\n",
       " '_save_intermediate_spikes_maps': True,\n",
       " '_filtered_pos_df':                  t    lin_pos          x      speed binned_x\n",
       " 0         0.150794  27.752915  27.752915   0.000000       30\n",
       " 1         0.184080  27.873635  27.873635   3.617933       30\n",
       " 2         0.217780  28.088848  28.088848   6.449885       30\n",
       " 3         0.251359  28.354823  28.354823   7.971213       30\n",
       " 4         0.285226  28.621418  28.621418   7.989786       30\n",
       " ...            ...        ...        ...        ...      ...\n",
       " 30839  1029.155519 -23.883073 -23.883073  18.705413       16\n",
       " 30840  1029.189352 -23.281045 -23.281045  18.042633       16\n",
       " 30841  1029.222954 -22.727464 -22.727464  16.590706       16\n",
       " 30842  1029.254903 -22.284281 -22.284281  13.282068       17\n",
       " 30843  1029.288295 -22.032979 -22.032979   7.531470       17\n",
       " \n",
       " [30844 rows x 5 columns],\n",
       " '_filtered_spikes_df':                  t      t_seconds  t_rel_seconds  shank  cluster  aclu  qclu  \\\n",
       " 142         8254.0  643040.787357       0.253563     12        7    98     1   \n",
       " 146         8390.0  643040.791535       0.257741     12        7    98     1   \n",
       " 174        10466.0  643040.855309       0.321515      1        2     2     2   \n",
       " 769        65068.0  643042.532682       1.998888     12        7    98     1   \n",
       " 776        65196.0  643042.536614       2.002820     12        7    98     1   \n",
       " ...            ...            ...            ...    ...      ...   ...   ...   \n",
       " 524033  33503399.0  644069.757684    1029.223890     10        6    82     2   \n",
       " 524038  33504176.0  644069.781554    1029.247760      2       31    28     2   \n",
       " 524039  33504255.0  644069.783981    1029.250187      2        2    13     2   \n",
       " 524040  33504281.0  644069.784779    1029.250985      8        5    57     2   \n",
       " 524046  33504789.0  644069.800385    1029.266591      8        5    57     2   \n",
       " \n",
       "                 x           y      speed  ...             cell_type  \\\n",
       " 142     28.372171   65.810894  10.117847  ...  NeuronType.PYRAMIDAL   \n",
       " 146     28.405059   65.819192  10.468901  ...  NeuronType.PYRAMIDAL   \n",
       " 174     28.856654   65.992572  10.909890  ...  NeuronType.PYRAMIDAL   \n",
       " 769     29.855423   65.832809  10.404884  ...  NeuronType.PYRAMIDAL   \n",
       " 776     29.868901   65.884852  11.022175  ...  NeuronType.PYRAMIDAL   \n",
       " ...           ...         ...        ...  ...                   ...   \n",
       " 524033 -22.714475  133.901779  20.079226  ...  NeuronType.PYRAMIDAL   \n",
       " 524038 -22.383369  134.031830  21.834145  ...  NeuronType.PYRAMIDAL   \n",
       " 524039 -22.349705  134.045052  22.012574  ...  NeuronType.PYRAMIDAL   \n",
       " 524040 -22.338625  134.049404  22.071297  ...  NeuronType.PYRAMIDAL   \n",
       " 524046 -22.196319  134.157374  22.333615  ...  NeuronType.PYRAMIDAL   \n",
       " \n",
       "         flat_spike_idx  x_loaded  y_loaded    lin_pos  \\\n",
       " 142                142  0.497666  0.247145  28.372171   \n",
       " 146                146  0.497580  0.247203  28.405059   \n",
       " 174                174  0.496388  0.247976  28.856654   \n",
       " 769                769  0.493557  0.249034  29.855423   \n",
       " 776                776  0.493415  0.249016  29.868901   \n",
       " ...                ...       ...       ...        ...   \n",
       " 524033          524033  0.717057  0.477377 -22.714475   \n",
       " 524038          524038  0.715257  0.477187 -22.383369   \n",
       " 524039          524039  0.715074  0.477166 -22.349705   \n",
       " 524040          524040  0.715014  0.477158 -22.338625   \n",
       " 524046          524046  0.713856  0.476947 -22.196319   \n",
       " \n",
       "         fragile_linear_neuron_IDX  PBE_id     scISI  neuron_IDX  binned_x  \n",
       " 142                            66      -1  0.030382          66        30  \n",
       " 146                            66      -1  0.004178          66        30  \n",
       " 174                             0      -1       NaN           0        30  \n",
       " 769                            66      -1  0.050657          66        30  \n",
       " 776                            66      -1  0.003932          66        30  \n",
       " ...                           ...     ...       ...         ...       ...  \n",
       " 524033                         55      -1  0.281764          55        16  \n",
       " 524038                         20      -1  0.120914          20        16  \n",
       " 524039                          9      -1  0.124293           9        17  \n",
       " 524040                         38      -1  0.092283          38        17  \n",
       " 524046                         38      -1  0.015606          38        17  \n",
       " \n",
       " [31111 rows x 24 columns],\n",
       " 'ndim': 1,\n",
       " 'xbin': array([-83.23955369, -79.43413657, -75.62871946, -71.82330234,\n",
       "        -68.01788522, -64.21246811, -60.40705099, -56.60163387,\n",
       "        -52.79621676, -48.99079964, -45.18538252, -41.37996541,\n",
       "        -37.57454829, -33.76913117, -29.96371406, -26.15829694,\n",
       "        -22.35287982, -18.54746271, -14.74204559, -10.93662847,\n",
       "         -7.13121136,  -3.32579424,   0.47962287,   4.28503999,\n",
       "          8.09045711,  11.89587422,  15.70129134,  19.50670846,\n",
       "         23.31212557,  27.11754269,  30.92295981,  34.72837692,\n",
       "         38.53379404,  42.33921116,  46.14462827,  49.95004539,\n",
       "         53.75546251,  57.56087962,  61.36629674,  65.17171386,\n",
       "         68.97713097,  72.78254809,  76.5879652 ,  80.39338232,\n",
       "         84.19879944,  88.00421655,  91.80963367,  95.61505079,\n",
       "         99.4204679 , 103.22588502, 107.03130214, 110.83671925,\n",
       "        114.64213637, 118.44755349, 122.2529706 , 126.05838772,\n",
       "        129.86380484, 133.66922195, 137.47463907, 141.28005619,\n",
       "        145.0854733 , 148.89089042, 152.69630753, 156.50172465]),\n",
       " 'ybin': None,\n",
       " 'bin_info': {'mode': 'bin_size',\n",
       "  'xstep': 3.8054171165052444,\n",
       "  'xnum_bins': 64},\n",
       " 'last_t': 0.0,\n",
       " 'historical_snapshots': {0.0: <neuropy.analyses.time_dependent_placefields.PlacefieldSnapshot at 0x2a9bbde93a0>},\n",
       " 'fragile_linear_neuron_IDXs': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "        68, 69, 70]),\n",
       " 'n_fragile_linear_neuron_IDXs': 71}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_results.pf1D_dt.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a896c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\20230411043239-loadedSessPickle.pkl... done.\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x000002A8BC0309D0>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m curr_active_pipeline\u001b[39m.\u001b[39;49msave_pipeline(saving_mode\u001b[39m=\u001b[39;49mPipelineSavingScheme\u001b[39m.\u001b[39;49mTEMP_THEN_OVERWRITE)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\NeuropyPipeline.py:605\u001b[0m, in \u001b[0;36mNeuropyPipeline.save_pipeline\u001b[1;34m(self, saving_mode, active_pickle_filename)\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mWARNING: saving_mode is OVERWRITE_IN_PLACE so \u001b[39m\u001b[39m{\u001b[39;00mfinalized_loaded_sess_pickle_path\u001b[39m}\u001b[39;00m\u001b[39m will be overwritten even though exists.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    604\u001b[0m \u001b[39m# Save reloaded pipeline out to pickle for future loading\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m saveData(finalized_loaded_sess_pickle_path, db\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m) \u001b[39m# Save the pipeline out to pickle.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[39m# If we saved to a temporary name, now see if we should overwrite or backup and then replace:\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \u001b[39mif\u001b[39;00m saving_mode\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m PipelineSavingScheme\u001b[39m.\u001b[39mTEMP_THEN_OVERWRITE\u001b[39m.\u001b[39mname:\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Loading.py:30\u001b[0m, in \u001b[0;36msaveData\u001b[1;34m(pkl_path, db, should_append)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mwith\u001b[39;00m ProgressMessagePrinter(pkl_path, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSaving (file mode \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfile_mode\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msaved session pickle file\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     28\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(pkl_path, file_mode) \u001b[39mas\u001b[39;00m dbfile: \n\u001b[0;32m     29\u001b[0m         \u001b[39m# source, destination\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m         pickle\u001b[39m.\u001b[39;49mdump(db, dbfile)\n\u001b[0;32m     31\u001b[0m         dbfile\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\dill\\_dill.py:336\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol, byref, fmode, recurse, **kwds)\u001b[0m\n\u001b[0;32m    334\u001b[0m _kwds \u001b[39m=\u001b[39m kwds\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    335\u001b[0m _kwds\u001b[39m.\u001b[39mupdate(\u001b[39mdict\u001b[39m(byref\u001b[39m=\u001b[39mbyref, fmode\u001b[39m=\u001b[39mfmode, recurse\u001b[39m=\u001b[39mrecurse))\n\u001b[1;32m--> 336\u001b[0m Pickler(file, protocol, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_kwds)\u001b[39m.\u001b[39;49mdump(obj)\n\u001b[0;32m    337\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\dill\\_dill.py:620\u001b[0m, in \u001b[0;36mPickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m    619\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 620\u001b[0m     StockPickler\u001b[39m.\u001b[39;49mdump(\u001b[39mself\u001b[39;49m, obj)\n\u001b[0;32m    621\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[0;32m    486\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mstart_framing()\n\u001b[1;32m--> 487\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave(obj)\n\u001b[0;32m    488\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(STOP)\n\u001b[0;32m    489\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mend_framing()\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\dill\\_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\dill\\_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:713\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    710\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_appends(listitems)\n\u001b[0;32m    712\u001b[0m \u001b[39mif\u001b[39;00m dictitems \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 713\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(dictitems)\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\dill\\_dill.py:1963\u001b[0m, in \u001b[0;36msave_function\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1960\u001b[0m     \u001b[39mif\u001b[39;00m state_dict:\n\u001b[0;32m   1961\u001b[0m         state \u001b[39m=\u001b[39m state, state_dict\n\u001b[1;32m-> 1963\u001b[0m     _save_with_postproc(pickler, (_create_function, (\n\u001b[0;32m   1964\u001b[0m           obj\u001b[39m.\u001b[39;49m\u001b[39m__code__\u001b[39;49m, globs, obj\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m, obj\u001b[39m.\u001b[39;49m\u001b[39m__defaults__\u001b[39;49m,\n\u001b[0;32m   1965\u001b[0m           closure\n\u001b[0;32m   1966\u001b[0m     ), state), obj\u001b[39m=\u001b[39;49mobj, postproc_list\u001b[39m=\u001b[39;49mpostproc_list)\n\u001b[0;32m   1967\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1968\u001b[0m     closure \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mfunc_closure\n",
      "File \u001b[1;32mc:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\dill\\_dill.py:1154\u001b[0m, in \u001b[0;36m_save_with_postproc\u001b[1;34m(pickler, reduction, is_pickler_dill, obj, postproc_list)\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m source:\n\u001b[0;32m   1153\u001b[0m     pickler\u001b[39m.\u001b[39mwrite(pickler\u001b[39m.\u001b[39mget(pickler\u001b[39m.\u001b[39mmemo[\u001b[39mid\u001b[39m(dest)][\u001b[39m0\u001b[39m]))\n\u001b[1;32m-> 1154\u001b[0m     pickler\u001b[39m.\u001b[39;49m_batch_setitems(\u001b[39miter\u001b[39;49m(source\u001b[39m.\u001b[39;49mitems()))\n\u001b[0;32m   1155\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1156\u001b[0m     \u001b[39m# Updating with an empty dictionary. Same as doing nothing.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\dill\\_dill.py:1838\u001b[0m, in \u001b[0;36msave_type\u001b[1;34m(pickler, obj, postproc_list)\u001b[0m\n\u001b[0;32m   1836\u001b[0m             postproc_list \u001b[39m=\u001b[39m []\n\u001b[0;32m   1837\u001b[0m         postproc_list\u001b[39m.\u001b[39mappend((\u001b[39msetattr\u001b[39m, (obj, \u001b[39m'\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m'\u001b[39m, obj_name)))\n\u001b[1;32m-> 1838\u001b[0m     _save_with_postproc(pickler, (_create_type, (\n\u001b[0;32m   1839\u001b[0m         \u001b[39mtype\u001b[39;49m(obj), obj\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m, obj\u001b[39m.\u001b[39;49m\u001b[39m__bases__\u001b[39;49m, _dict\n\u001b[0;32m   1840\u001b[0m     )), obj\u001b[39m=\u001b[39;49mobj, postproc_list\u001b[39m=\u001b[39;49mpostproc_list)\n\u001b[0;32m   1841\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m _t)\n\u001b[0;32m   1842\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\dill\\_dill.py:1140\u001b[0m, in \u001b[0;36m_save_with_postproc\u001b[1;34m(pickler, reduction, is_pickler_dill, obj, postproc_list)\u001b[0m\n\u001b[0;32m   1137\u001b[0m     pickler\u001b[39m.\u001b[39m_postproc[\u001b[39mid\u001b[39m(obj)] \u001b[39m=\u001b[39m postproc_list\n\u001b[0;32m   1139\u001b[0m \u001b[39m# TODO: Use state_setter in Python 3.8 to allow for faster cPickle implementations\u001b[39;00m\n\u001b[1;32m-> 1140\u001b[0m pickler\u001b[39m.\u001b[39;49msave_reduce(\u001b[39m*\u001b[39;49mreduction, obj\u001b[39m=\u001b[39;49mobj)\n\u001b[0;32m   1142\u001b[0m \u001b[39mif\u001b[39;00m is_pickler_dill:\n\u001b[0;32m   1143\u001b[0m     \u001b[39m# pickler.x -= 1\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m     \u001b[39m# print(pickler.x*' ', 'pop', obj, id(obj))\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     postproc \u001b[39m=\u001b[39m pickler\u001b[39m.\u001b[39m_postproc\u001b[39m.\u001b[39mpop(\u001b[39mid\u001b[39m(obj))\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:692\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    691\u001b[0m     save(func)\n\u001b[1;32m--> 692\u001b[0m     save(args)\n\u001b[0;32m    693\u001b[0m     write(REDUCE)\n\u001b[0;32m    695\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    696\u001b[0m     \u001b[39m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[0;32m    697\u001b[0m     \u001b[39m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[0;32m    698\u001b[0m     \u001b[39m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:901\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    899\u001b[0m write(MARK)\n\u001b[0;32m    900\u001b[0m \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[1;32m--> 901\u001b[0m     save(element)\n\u001b[0;32m    903\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n\u001b[0;32m    904\u001b[0m     \u001b[39m# Subtle.  d was not in memo when we entered save_tuple(), so\u001b[39;00m\n\u001b[0;32m    905\u001b[0m     \u001b[39m# the process of saving the tuple's elements must have saved\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    909\u001b[0m     \u001b[39m# could have been done in the \"for element\" loop instead, but\u001b[39;00m\n\u001b[0;32m    910\u001b[0m     \u001b[39m# recursive tuples are a rare thing.\u001b[39;00m\n\u001b[0;32m    911\u001b[0m     get \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(memo[\u001b[39mid\u001b[39m(obj)][\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\dill\\_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\dill\\_dill.py:1963\u001b[0m, in \u001b[0;36msave_function\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1960\u001b[0m     \u001b[39mif\u001b[39;00m state_dict:\n\u001b[0;32m   1961\u001b[0m         state \u001b[39m=\u001b[39m state, state_dict\n\u001b[1;32m-> 1963\u001b[0m     _save_with_postproc(pickler, (_create_function, (\n\u001b[0;32m   1964\u001b[0m           obj\u001b[39m.\u001b[39;49m\u001b[39m__code__\u001b[39;49m, globs, obj\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m, obj\u001b[39m.\u001b[39;49m\u001b[39m__defaults__\u001b[39;49m,\n\u001b[0;32m   1965\u001b[0m           closure\n\u001b[0;32m   1966\u001b[0m     ), state), obj\u001b[39m=\u001b[39;49mobj, postproc_list\u001b[39m=\u001b[39;49mpostproc_list)\n\u001b[0;32m   1967\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1968\u001b[0m     closure \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mfunc_closure\n",
      "File \u001b[1;32mc:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\dill\\_dill.py:1154\u001b[0m, in \u001b[0;36m_save_with_postproc\u001b[1;34m(pickler, reduction, is_pickler_dill, obj, postproc_list)\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m source:\n\u001b[0;32m   1153\u001b[0m     pickler\u001b[39m.\u001b[39mwrite(pickler\u001b[39m.\u001b[39mget(pickler\u001b[39m.\u001b[39mmemo[\u001b[39mid\u001b[39m(dest)][\u001b[39m0\u001b[39m]))\n\u001b[1;32m-> 1154\u001b[0m     pickler\u001b[39m.\u001b[39;49m_batch_setitems(\u001b[39miter\u001b[39;49m(source\u001b[39m.\u001b[39;49mitems()))\n\u001b[0;32m   1155\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1156\u001b[0m     \u001b[39m# Updating with an empty dictionary. Same as doing nothing.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\dill\\_dill.py:2004\u001b[0m, in \u001b[0;36msave_function\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   2002\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mF2: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m obj)\n\u001b[0;32m   2003\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m'\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mgetattr\u001b[39m(obj, \u001b[39m'\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m-> 2004\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_global(pickler, obj, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   2005\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# F2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2006\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:1070\u001b[0m, in \u001b[0;36m_Pickler.save_global\u001b[1;34m(self, obj, name)\u001b[0m\n\u001b[0;32m   1068\u001b[0m     obj2, parent \u001b[39m=\u001b[39m _getattribute(module, name)\n\u001b[0;32m   1069\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mImportError\u001b[39;00m, \u001b[39mKeyError\u001b[39;00m, \u001b[39mAttributeError\u001b[39;00m):\n\u001b[1;32m-> 1070\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\n\u001b[0;32m   1071\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m: it\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms not found as \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1072\u001b[0m         (obj, module_name, name)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m   1073\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1074\u001b[0m     \u001b[39mif\u001b[39;00m obj2 \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m obj:\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x000002A8BC0309D0>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048000a",
   "metadata": {},
   "source": [
    "# 2023-04-11 - Review of Year's Progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50c94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for interactive\n",
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = curr_active_pipeline.plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plotter._display_normal(long_epoch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d48a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_short_long_firing_rate_index_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0431c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot.display_short_long_firing_rate_index_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4c69d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
