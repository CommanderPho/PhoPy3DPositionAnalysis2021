{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from benedict import benedict\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from benedict import benedict # https://github.com/fabiocaccamo/python-benedict#usage\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import CodeConversion\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible, print_value_overview_only, document_active_variables, objsize, print_object_memory_usage, debug_dump_object_member_shapes, TypePrintMode\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import batch_load_session, batch_extended_computations, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "\n",
    "# from PendingNotebookCode import _perform_batch_plot, _build_batch_plot_kwargs\n",
    "\n",
    "session_batch_status = {}\n",
    "session_batch_errors = {}\n",
    "enable_saving_to_disk = False\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_session_names_list: ['2006-6-07_16-40-19', '2006-6-08_15-46-47', '2006-6-08_21-16-25', '2006-6-09_22-24-40', '2006-6-12_16-53-46', '2006-6-13_15-22-3']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-08_15-46-47'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-08_21-16-25'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-09_22-24-40'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-12_16-53-46'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-13_15-22-3'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "#     neuropy/data_session_pre_processing_scripts/KDIBA/IIDataMat_Export_ToPython_2022_08_01.m\n",
    "# From pre-computed .mat files:\n",
    "\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# Animal `gor01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='one') # IdentifyingContext<('kdiba', 'gor01', 'one')>\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # 'gor01', 'one'\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['PhoHelpers', 'Spike3D-Minimal-Test', 'Unused'])\n",
    "\n",
    "local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='two')\n",
    "local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# ## Animal `vvp01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# ### Animal `pin01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='pin01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # no exper_name ('one' or 'two') folders for this animal.\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['redundant','showclus','sleep','tmaze'])\n",
    "\n",
    "## Build session contexts list:\n",
    "local_session_contexts_list = [local_session_parent_context.adding_context(collision_prefix='sess', session_name=a_name) for a_name in local_session_names_list] # [IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-07_11-26-53')>, ..., IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-13_14-42-6')>]\n",
    "\n",
    "## Initialize `session_batch_status` with the NOT_STARTED status if it doesn't already have a different status\n",
    "for curr_session_basedir in local_session_paths_list:\n",
    "    curr_session_status = session_batch_status.get(curr_session_basedir, None)\n",
    "    if curr_session_status is None:\n",
    "        session_batch_status[curr_session_basedir] = SessionBatchProgress.NOT_STARTED # set to not started if not present\n",
    "        # session_batch_status[curr_session_basedir] = SessionBatchProgress.COMPLETED # set to not started if not present\n",
    "\n",
    "session_batch_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13e68b4-03e0-4388-a35c-87a352a6e6b3",
   "metadata": {
    "tags": [
     "load",
     "single_session",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle.pkl.\n",
      "property already present in pickled version. No need to save.\n",
      "using provided computation_functions_name_whitelist: ['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# %%viztracer\n",
    "basedir = local_session_paths_list[0] # NOT 3\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "## Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# epoch_name_whitelist = ['maze']\n",
    "epoch_name_whitelist = None\n",
    "active_computation_functions_name_whitelist=['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        # '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding'\n",
    "                                    ]\n",
    "curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_whitelist=epoch_name_whitelist,\n",
    "                                          computation_functions_name_whitelist=active_computation_functions_name_whitelist,\n",
    "                                          saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                          skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e403d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sane_midpoint_x: 118.93433364528494, hardcoded_track_midpoint_x: 150.0, track_min_max_x: (18.67140495721134, 256.5400722477812)\n",
      "desc_crossings_x: (20,), asc_crossings_x: (20,)\n"
     ]
    }
   ],
   "source": [
    "from neuropy.analyses.placefields import PfND\n",
    "from neuropy.analyses.laps import estimate_session_laps\n",
    "\n",
    "## 2023-04-07 - Builds the laps using estimation_session_laps(...) if needed for each epoch, and then sets the decoder's .epochs property to the laps object so the occupancy is correct.\n",
    "def constrain_to_laps(curr_active_pipeline):\n",
    "\t\"\"\" 2023-04-07 - Constrains the placefields to just the laps, computing the laps if needed.\n",
    "\tOther laps-related things?\n",
    "\t\t# ??? pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "\t\t# DataSession.compute_position_laps(self)\n",
    "\t\t# DataSession.compute_laps_position_df(position_df, laps_df)\n",
    "\t\"\"\"\n",
    "\tlong_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\tlong_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "\tlong_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "\n",
    "\tfor a_name, a_sess, a_result in zip((long_epoch_name, short_epoch_name, global_epoch_name), (long_session, short_session, global_session), (long_results, short_results, global_results)):\n",
    "\t\ta_sess = estimate_session_laps(a_sess, should_plot_laps_2d=False)\n",
    "\t\tcurr_laps_obj = a_sess.laps.as_epoch_obj() # set this to the laps object\n",
    "\t\tcurr_laps_obj = curr_laps_obj.get_non_overlapping()\n",
    "\t\tcurr_laps_obj = curr_laps_obj.filtered_by_duration(1.0, 10.0) # the lap must be at least 1 second long and at most 10 seconds long\n",
    "\t\t# curr_laps_obj = a_sess.estimate_laps().as_epoch_obj()\n",
    "\t\tcurr_active_pipeline.active_configs[a_name].computation_config.pf_params.computation_epochs = curr_laps_obj\n",
    "\t\tcurr_pf1D, curr_pf2D = a_result.pf1D, a_result.pf2D\n",
    "\n",
    "\t\tlap_filtered_curr_pf1D = deepcopy(curr_pf1D)\n",
    "\t\tlap_filtered_curr_pf1D = PfND(spikes_df=lap_filtered_curr_pf1D.spikes_df, position=lap_filtered_curr_pf1D.position, epochs=deepcopy(curr_laps_obj), config=lap_filtered_curr_pf1D.config, compute_on_init=True)\n",
    "\t\tlap_filtered_curr_pf2D = deepcopy(curr_pf2D)\n",
    "\t\tlap_filtered_curr_pf2D = PfND(spikes_df=lap_filtered_curr_pf2D.spikes_df, position=lap_filtered_curr_pf2D.position, epochs=deepcopy(curr_laps_obj), config=lap_filtered_curr_pf2D.config, compute_on_init=True)\n",
    "\t\ta_result.pf1D = lap_filtered_curr_pf1D\n",
    "\t\ta_result.pf2D = lap_filtered_curr_pf2D\n",
    "\t\treturn curr_active_pipeline\n",
    "\n",
    "curr_active_pipeline = constrain_to_laps(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f14325",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D  = [results_data.get('pf1D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "recalculate_anyway = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f54a9300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (13754,) should be less than time_window_edges: (35786,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (13754,) should be less than time_window_edges: (35786,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "self will be re-binned to match target_pf...\n",
      "done.\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "decoding_time_bin_size: 0.03333\n"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_position_decoding_computation'], computation_kwargs_list=[dict(ndim=1)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "# long_one_step_decoder_1D, short_one_step_decoder_1D  = [results_data.get('pf1D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D  = [deepcopy(results_data.get('pf1D_Decoder', None)) for results_data in (long_results, short_results)]\n",
    "# ds and Decoders conform between the long and the short epochs:\n",
    "short_one_step_decoder_1D, did_recompute = short_one_step_decoder_1D.conform_to_position_bins(long_one_step_decoder_1D, force_recompute=True)\n",
    "\n",
    "# ## Build or get the two-step decoders for both the long and short:\n",
    "# long_two_step_decoder_1D, short_two_step_decoder_1D  = [results_data.get('pf1D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "# if recalculate_anyway or did_recompute or (long_two_step_decoder_1D is None) or (short_two_step_decoder_1D is None):\n",
    "#     curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_two_step_position_decoding_computation'], computation_kwargs_list=[dict(ndim=1)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "#     long_two_step_decoder_1D, short_two_step_decoder_1D  = [results_data.get('pf1D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "#     assert (long_two_step_decoder_1D is not None and short_two_step_decoder_1D is not None)\n",
    "\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "# decoding_time_bin_size = 0.03 # 0.03333333333333333\n",
    "print(f'decoding_time_bin_size: {decoding_time_bin_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e20ceb",
   "metadata": {},
   "source": [
    "#### Get 2D Decoders for validation and comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26c39017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (13754,) should be less than time_window_edges: (35786,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (13754,) should be less than time_window_edges: (35786,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "np.sum(long_one_step_decoder_2D.marginal.x.p_x_given_n) =36142.00000000002,\t np.sum(long_one_step_decoder_1D.p_x_given_n) = 36142.00000000001\n"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_position_decoding_computation'], computation_kwargs_list=[dict(ndim=2)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "# Make the 2D Placefields and Decoders conform between the long and the short epochs:\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "long_one_step_decoder_2D, short_one_step_decoder_2D  = [results_data.get('pf2D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "short_one_step_decoder_2D, did_recompute = short_one_step_decoder_2D.conform_to_position_bins(long_one_step_decoder_2D)\n",
    "\n",
    "# ## Build or get the two-step decoders for both the long and short:\n",
    "# long_two_step_decoder_2D, short_two_step_decoder_2D  = [results_data.get('pf2D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "# if recalculate_anyway or did_recompute or (long_two_step_decoder_2D is None) or (short_two_step_decoder_2D is None):\n",
    "#     curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_two_step_position_decoding_computation'], computation_kwargs_list=[dict(ndim=2)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "#     long_two_step_decoder_2D, short_two_step_decoder_2D  = [results_data.get('pf2D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "#     assert (long_two_step_decoder_2D is not None and short_two_step_decoder_2D is not None)\n",
    "# Sums are similar:\n",
    "print(f'{np.sum(long_one_step_decoder_2D.marginal.x.p_x_given_n) =},\\t {np.sum(long_one_step_decoder_1D.p_x_given_n) = }') # 31181.999999999996 vs 31181.99999999999\n",
    "\n",
    "## Validate:\n",
    "assert long_one_step_decoder_2D.marginal.x.p_x_given_n.shape == long_one_step_decoder_1D.p_x_given_n.shape, f\"Must equal but: {long_one_step_decoder_2D.marginal.x.p_x_given_n.shape =} and {long_one_step_decoder_1D.p_x_given_n.shape =}\"\n",
    "assert long_one_step_decoder_2D.marginal.x.most_likely_positions_1D.shape == long_one_step_decoder_1D.most_likely_positions.shape, f\"Must equal but: {long_one_step_decoder_2D.marginal.x.most_likely_positions_1D.shape =} and {long_one_step_decoder_1D.most_likely_positions.shape =}\"\n",
    "\n",
    "## validate values:\n",
    "# assert np.allclose(long_one_step_decoder_2D.marginal.x.p_x_given_n, long_one_step_decoder_1D.p_x_given_n), f\"1D Decoder should have an x-posterior equal to its own posterior\"\n",
    "# assert np.allclose(curr_epoch_result['marginal_x']['most_likely_positions_1D'], curr_epoch_result['most_likely_positions']), f\"1D Decoder should have an x-posterior with most_likely_positions_1D equal to its own most_likely_positions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cee514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_time_dependent_placefield_computation'], enabled_filter_names=[long_epoch_name, short_epoch_name, global_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "\n",
    "# long_results.pf1D_dt.reset()\n",
    "# long_results.pf1D_dt._included_thresh_neurons_indx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a896c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE)\n",
    "\n",
    "# TypeError: cannot pickle 'MplMultiTab' object\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea54a0e7",
   "metadata": {},
   "source": [
    "#### 2023-04-13 - Clear Display Outputs from pipeline so it can be saved\n",
    "##### TODO: Ignore `curr_active_pipeline.display_output_history_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef7370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(curr_active_pipeline.display_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0615279",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display_output_history_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f9eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clear any hanging display outputs:\n",
    "# do I need to close them before I just remove them?\n",
    "for a_display_output_key in curr_active_pipeline.display_output_history_list:\n",
    "\t# a_display_output.close()\n",
    "\tdel curr_active_pipeline.display_output[a_display_output_key]\n",
    "\n",
    "curr_active_pipeline.display_output_history_list.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a3c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all matplotlib figures?\n",
    "from pyphocorehelpers.plotting.figure_management import PhoActiveFigureManager2D, capture_new_figures_decorator\n",
    "fig_man = PhoActiveFigureManager2D(name=f'fig_man') # Initialize a new figure manager\n",
    "fig_man.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import print_object_memory_usage\n",
    "print_object_memory_usage(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "%help %whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc727de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a116ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%who_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048000a",
   "metadata": {},
   "source": [
    "# 2023-04-11 - Review of Year's Progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50c94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5356d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for interactive\n",
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = curr_active_pipeline.plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dfc5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter._display_normal(active_session_configuration_context=long_epoch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d48a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_short_long_firing_rate_index_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0431c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot.display_short_long_firing_rate_index_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb313f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extended_computations_include_whitelist=None # do all\n",
    "extended_computations_include_whitelist=['jonathan_firing_rate_analysis', 'short_long_pf_overlap_analyses', 'long_short_fr_indicies_analyses'] # do only specifiedl\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_whitelist=extended_computations_include_whitelist, include_global_functions=True, fail_on_exception=True, progress_print=True, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac66a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_short_long_firing_rate_analyses'], fail_on_exception=True, debug_print=False) # fail_on_exception MUST be True or error handling is all messed up \n",
    "print(f'\\t done.')\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_index, y_frs_index = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c367e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis['neuron_replay_stats_df'], curr_jonathan_firing_rate_analysis['rdf']['rdf'], curr_jonathan_firing_rate_analysis['rdf']['aclu_to_idx'], curr_jonathan_firing_rate_analysis['irdf']['irdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b27a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_long_pf_overlap_analyses = curr_active_pipeline.global_computation_results.computed_data.short_long_pf_overlap_analyses\n",
    "conv_overlap_dict = short_long_pf_overlap_analyses['conv_overlap_dict']\n",
    "conv_overlap_scalars_df = short_long_pf_overlap_analyses['conv_overlap_scalars_df']\n",
    "prod_overlap_dict = short_long_pf_overlap_analyses['product_overlap_dict']\n",
    "relative_entropy_overlap_dict = short_long_pf_overlap_analyses['relative_entropy_overlap_dict']\n",
    "relative_entropy_overlap_scalars_df = short_long_pf_overlap_analyses['relative_entropy_overlap_scalars_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3640e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_index, y_frs_index = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']\n",
    "# long_short_fr_indicies_analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe59c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', active_identifying_session_ctx)\n",
    "fig, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['axs'], graphics_output_dict['plot_data']\n",
    "neuron_df, rdf, aclu_to_idx, irdf = plot_data['df'], plot_data['rdf'], plot_data['aclu_to_idx'], plot_data['irdf']\n",
    "# Grab the output axes:\n",
    "curr_axs_dict = axs[0]\n",
    "curr_firing_rate_ax, curr_lap_spikes_ax, curr_placefield_ax = curr_axs_dict['firing_rate'], curr_axs_dict['lap_spikes'], curr_axs_dict['placefield'] # Extract variables from the `curr_axs_dict` dictionary to the local workspace\n",
    "## TODO 2023-04-11 - Set Window Title for '_display_batch_pho_jonathan_replay_firing_rate_comparison'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc63487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot long|short firing rate index:\n",
    "fig_save_parent_path = Path(r'E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Pho-Kamran-Meetings\\Results from 2023-04-11')\n",
    "curr_active_pipeline.display('_display_short_long_firing_rate_index_comparison', curr_active_pipeline.sess.get_context(), fig_save_parent_path=fig_save_parent_path)\n",
    "# plt.close() # closes the current figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-04-11 - Debug why `_display_short_long_firing_rate_index_comparison` is empty\n",
    "# Plot long|short firing rate index:\n",
    "\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_index, y_frs_index = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']\n",
    "long_short_fr_indicies_analysis_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0826d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_short_long_firing_rate_index_comparison', curr_active_pipeline.sess.get_context(), fig_save_parent_path=fig_save_parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c230041",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_identifying_session_ctx, active_session_figures_out_path, active_out_figures_list = batch_programmatic_figures(curr_active_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc56f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_extended_programmatic_figures(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb79a73",
   "metadata": {},
   "source": [
    "## Explore display function documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c4d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276eeb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func.short_name, func.tags, func.creation_date, func.input_requires, func.output_provides, func.uses, func.used_by\n",
    "{a_fn_name:getattr(a_fn, 'tags', None) for a_fn_name, a_fn in curr_active_pipeline.registered_display_function_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6899c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_dict['_display_2d_placefield_result_plot_ratemaps_2D'].tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a92c8",
   "metadata": {},
   "source": [
    "# 2023-03-16 - Explore passing in long/short decoders specifically to `perform_full_session_leave_one_out_decoding_analysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f22b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get existing long/short decoders from the cell under \"# 2023-02-24 Decoders\"\n",
    "long_decoder, short_decoder = deepcopy(long_one_step_decoder_1D), deepcopy(short_one_step_decoder_1D)\n",
    "assert np.all(long_decoder.xbin == short_decoder.xbin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5408614",
   "metadata": {},
   "outputs": [],
   "source": [
    "## backup existing replay objects\n",
    "# long_session.replay_backup, short_session.replay_backup, global_session.replay_backup = [deepcopy(a_session.replay) for a_session in [long_session, short_session, global_session]]\n",
    "# null-out the replay objects\n",
    "# long_session.replay, short_session.replay, global_session.replay = [None, None, None]\n",
    "\n",
    "# Compute/estimate replays if missing from session:\n",
    "if not global_session.has_replays:\n",
    "    print(f'Replays missing from sessions. Computing replays...')\n",
    "    long_session.replay, short_session.replay, global_session.replay = [a_session.estimate_replay_epochs(min_epoch_included_duration=0.06, max_epoch_included_duration=None, maximum_speed_thresh=None, min_inclusion_fr_active_thresh=0.01, min_num_unique_aclu_inclusions=3).to_dataframe() for a_session in [long_session, short_session, global_session]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944f1fd",
   "metadata": {},
   "source": [
    "### Need to prune to only the cells active in both epochs ahead of time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f62debbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neurons = 37, neurons_colors_array.shape =(4, 37)\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder, BayesianPlacemapPositionDecoder\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import perform_full_session_leave_one_out_decoding_analysis\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import SurpriseAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import build_neurons_color_map # for plot_short_v_long_pf1D_comparison\n",
    "\n",
    "# Prune to the shared aclus in both epochs (short/long):\n",
    "long_shared_aclus_only_decoder, short_shared_aclus_only_decoder = [BasePositionDecoder.init_from_stateful_decoder(a_decoder) for a_decoder in (long_decoder, short_decoder)]\n",
    "shared_aclus, (long_shared_aclus_only_decoder, short_shared_aclus_only_decoder), long_short_pf_neurons_diff = BasePositionDecoder.prune_to_shared_aclus_only(long_shared_aclus_only_decoder, short_shared_aclus_only_decoder)\n",
    "n_neurons = len(shared_aclus)\n",
    "# for plotting purposes, build colors only for the common (present in both, the intersection) neurons:\n",
    "neurons_colors_array = build_neurons_color_map(n_neurons, sortby=None, cmap=None)\n",
    "print(f'{n_neurons = }, {neurons_colors_array.shape =}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b360bc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reusing extant decoder.\n",
      "Loading leave_one_out_result_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\output\\leave_one_out_results_long.pkl\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\output\\leave_one_out_results_long.pkl... done.\n",
      "(n_neurons = 37, n_all_epoch_timebins = 4834)\n",
      "reusing extant decoder.\n",
      "Loading leave_one_out_result_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\output\\leave_one_out_results_short.pkl\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\output\\leave_one_out_results_short.pkl... done.\n",
      "(n_neurons = 37, n_all_epoch_timebins = 4834)\n"
     ]
    }
   ],
   "source": [
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "long_results_obj = perform_full_session_leave_one_out_decoding_analysis(global_session, original_1D_decoder=long_shared_aclus_only_decoder, decoding_time_bin_size = 0.025, cache_suffix = '_long', perform_cache_load=True) # , perform_cache_load=False\n",
    "short_results_obj = perform_full_session_leave_one_out_decoding_analysis(global_session, original_1D_decoder=short_shared_aclus_only_decoder, decoding_time_bin_size = 0.025, cache_suffix = '_short', perform_cache_load=True) # , perform_cache_load=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69eed8a",
   "metadata": {},
   "source": [
    "## 2023-04-13 - Shuffled Surprise\n",
    "\"\"\" \n",
    "Relevant Functions:\n",
    "`perform_full_session_leave_one_out_decoding_analysis`:\n",
    "\t`perform_leave_one_aclu_out_decoding_analysis`:\tfrom pyphoplacecellanalysis.Analysis.Decoder.decoder_result import perform_leave_one_aclu_out_decoding_analysis\n",
    "\t`_analyze_leave_one_out_decoding_results`: from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.DefaultComputationFunctions import _analyze_leave_one_out_decoding_results\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff984d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## for each cell:\n",
    "# for i, left_out_aclu in enumerate(original_1D_decoder.neuron_IDs):\n",
    "# \t# aclu = original_1D_decoder.neuron_IDs[i]\n",
    "# \tleft_out_neuron_IDX = original_1D_decoder.neuron_IDXs[i] # should just be i, but just to be safe\n",
    "# \t## TODO: only look at bins where the cell fires (is_cell_firing_time_bin[i])\n",
    "# \tcurr_cell_pf_curve = original_1D_decoder.pf.ratemap.tuning_curves[left_out_neuron_IDX]\n",
    "# \t# curr_cell_spike_curve = original_1D_decoder.pf.ratemap.spikes_maps[unit_IDX] ## not occupancy weighted... is this the right one to use for computing the expected spike rate? NO... doesn't seem like it\n",
    "\n",
    "# \tshuffled_cell_pf_curve = original_1D_decoder.pf.ratemap.tuning_curves[shuffle_IDXs[i]]\n",
    "\n",
    "# \tleft_out_decoder_result = one_left_out_filter_epochs_decoder_result_dict[left_out_aclu]\n",
    "\n",
    "# active_epoch = results_obj.active_filter_epochs[epoch_idx]\n",
    "# # Get a conversion between the epoch indicies and the flat indicies\n",
    "# flat_bin_indicies = results_obj.split_by_epoch_reverse_flattened_time_bin_indicies[epoch_idx]\n",
    "\n",
    "\n",
    "# for decoded_epoch_idx in np.arange(n_epochs):\n",
    "# \tnum_curr_epoch_time_bins = [len(self.result.one_left_out_posterior_to_pf_surprises[aclu][decoded_epoch_idx]) for aclu in self.original_1D_decoder.neuron_IDs] # get the number of time bins in this epoch to build the reverse indexing array\n",
    "\n",
    "# for decoded_epoch_idx in np.arange(left_out_decoder_result.num_filter_epochs):\n",
    "# \tlong_results_obj.active_filter_epochs\n",
    "\n",
    "\n",
    "for decoded_epoch_idx in np.arange(left_out_decoder_result.num_filter_epochs):\n",
    "\tlong_results_obj.active_filter_epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd78c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_obj = deepcopy(long_results_obj)\n",
    "results_obj.all_included_filter_epochs_decoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c380066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract important things from the decoded data, like the time bins which are the same for all:\n",
    "n_epochs = results_obj.all_included_filter_epochs_decoder_result.num_filter_epochs\n",
    "n_timebins = np.sum(results_obj.all_included_filter_epochs_decoder_result.nbins)\n",
    "shared_timebin_containers = results_obj.all_included_filter_epochs_decoder_result.time_bin_containers\n",
    "# shared_timebin_\n",
    "n_timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18c1c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import define\n",
    "## 0. Precompute the active neurons in each timebin, and the epoch-timebin-flattened decoded posteriors makes it easier to compute for a given time bin:\n",
    "@define(slots=False, repr=False)\n",
    "class TimebinnedNeuronActivity:\n",
    "\t\"\"\" keeps track of which neurons are active and inactive in each decoded timebin \"\"\"\n",
    "\tn_timebins: int\n",
    "\tactive_IDXs: np.ndarray\n",
    "\tactive_aclus: np.ndarray\n",
    "\tinactive_IDXs: np.ndarray\n",
    "\tinactive_aclus: np.ndarray\n",
    "\n",
    "\t@classmethod\n",
    "\tdef init_from_results_obj(cls, results_obj: SurpriseAnalysisResult):\n",
    "\t\tn_timebins = np.sum(results_obj.all_included_filter_epochs_decoder_result.nbins)\n",
    "\t\t# a list of lists where each list contains the aclus that are active during that timebin:\n",
    "\t\ttimebins_active_neuron_IDXs = [np.array(results_obj.original_1D_decoder.neuron_IDXs)[a_timebin_is_cell_firing] for a_timebin_is_cell_firing in np.logical_not(results_obj.is_non_firing_time_bin).T]\n",
    "\t\ttimebins_active_aclus = [np.array(results_obj.original_1D_decoder.neuron_IDs)[an_IDX] for an_IDX in timebins_active_neuron_IDXs]\n",
    "\n",
    "\t\ttimebins_inactive_neuron_IDXs = [np.array(results_obj.original_1D_decoder.neuron_IDXs)[a_timebin_is_cell_firing] for a_timebin_is_cell_firing in results_obj.is_non_firing_time_bin.T]\n",
    "\t\ttimebins_inactive_aclus = [np.array(results_obj.original_1D_decoder.neuron_IDs)[an_IDX] for an_IDX in timebins_inactive_neuron_IDXs]\n",
    "\t\t# timebins_p_x_given_n = np.hstack(results_obj.all_included_filter_epochs_decoder_result.p_x_given_n_list) # # .shape: (239, 5) - (n_x_bins, n_epoch_time_bins)  --TO-->  .shape: (63, 4146) - (n_x_bins, n_flattened_all_epoch_time_bins)\n",
    "\t\treturn cls(n_timebins=n_timebins, active_IDXs=timebins_active_neuron_IDXs, active_aclus=timebins_active_aclus, inactive_IDXs=timebins_inactive_neuron_IDXs, inactive_aclus=timebins_inactive_aclus)\n",
    "\n",
    "long_results_obj.timebinned_neuron_info = TimebinnedNeuronActivity.init_from_results_obj(long_results_obj)\n",
    "short_results_obj.timebinned_neuron_info = TimebinnedNeuronActivity.init_from_results_obj(short_results_obj)\n",
    "assert long_results_obj.timebinned_neuron_info.n_timebins == short_results_obj.timebinned_neuron_info.n_timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e500fab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_bin_indices</th>\n",
       "      <th>posterior_to_pf_mean_surprise</th>\n",
       "      <th>posterior_to_scrambled_pf_mean_surprise</th>\n",
       "      <th>surprise_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch_IDX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.750000</td>\n",
       "      <td>9.742934</td>\n",
       "      <td>7.691168</td>\n",
       "      <td>-2.051766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.714286</td>\n",
       "      <td>7.943960</td>\n",
       "      <td>8.760642</td>\n",
       "      <td>0.816682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.833333</td>\n",
       "      <td>7.862401</td>\n",
       "      <td>9.011057</td>\n",
       "      <td>1.148655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.500000</td>\n",
       "      <td>8.475630</td>\n",
       "      <td>8.767957</td>\n",
       "      <td>0.292326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.500000</td>\n",
       "      <td>8.768528</td>\n",
       "      <td>9.397950</td>\n",
       "      <td>0.629422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>4799.000000</td>\n",
       "      <td>7.379266</td>\n",
       "      <td>10.311959</td>\n",
       "      <td>2.932693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>4807.000000</td>\n",
       "      <td>7.933791</td>\n",
       "      <td>8.196207</td>\n",
       "      <td>0.262415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>4816.888889</td>\n",
       "      <td>7.897295</td>\n",
       "      <td>7.792253</td>\n",
       "      <td>-0.105042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>4824.500000</td>\n",
       "      <td>8.684217</td>\n",
       "      <td>11.420520</td>\n",
       "      <td>2.736303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>4831.000000</td>\n",
       "      <td>10.729313</td>\n",
       "      <td>8.097513</td>\n",
       "      <td>-2.631799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time_bin_indices  posterior_to_pf_mean_surprise  \\\n",
       "epoch_IDX                                                    \n",
       "0                  3.750000                       9.742934   \n",
       "1                 13.714286                       7.943960   \n",
       "2                 21.833333                       7.862401   \n",
       "3                 29.500000                       8.475630   \n",
       "4                 36.500000                       8.768528   \n",
       "...                     ...                            ...   \n",
       "595             4799.000000                       7.379266   \n",
       "596             4807.000000                       7.933791   \n",
       "597             4816.888889                       7.897295   \n",
       "598             4824.500000                       8.684217   \n",
       "599             4831.000000                      10.729313   \n",
       "\n",
       "           posterior_to_scrambled_pf_mean_surprise  surprise_diff  \n",
       "epoch_IDX                                                          \n",
       "0                                         7.691168      -2.051766  \n",
       "1                                         8.760642       0.816682  \n",
       "2                                         9.011057       1.148655  \n",
       "3                                         8.767957       0.292326  \n",
       "4                                         9.397950       0.629422  \n",
       "...                                            ...            ...  \n",
       "595                                      10.311959       2.932693  \n",
       "596                                       8.196207       0.262415  \n",
       "597                                       7.792253      -0.105042  \n",
       "598                                      11.420520       2.736303  \n",
       "599                                       8.097513      -2.631799  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.DefaultComputationFunctions import LeaveOneOutDecodingResult\n",
    "from scipy.spatial import distance # for Jensen-Shannon distance in `_subfn_compute_leave_one_out_analysis`\n",
    "import random # for random.choice(mylist)\n",
    "from PendingNotebookCode import _scramble_curve\n",
    "\n",
    "# @define(slots=False, repr=False)\n",
    "# class PlacefieldPosteriorComputationHelper:\n",
    "\n",
    "# \tdef compute(self, curr_cell_pf_curve, curr_timebin_p_x_given_n):\n",
    "# \t\tresult.one_left_out_posterior_to_pf_surprises[timebin_IDX].append(distance.jensenshannon(curr_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "# \t\tresult.one_left_out_posterior_to_pf_correlations[timebin_IDX].append(distance.correlation(curr_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "\n",
    "\n",
    "# active_surprise_metric_fn = lambda pf, p_x_given_n: distance.jensenshannon(pf, p_x_given_n)\n",
    "# active_surprise_metric_fn = lambda pf, p_x_given_n: distance.correlation(pf, p_x_given_n)\n",
    "active_surprise_metric_fn = lambda pf, p_x_given_n: distance.sqeuclidean(pf, p_x_given_n)\n",
    "# active_surprise_metric_fn = lambda pf, p_x_given_n: weissinmeer_distance(pf, p_x_given_n) # Figure out the correct function for this, it's in my old notebooks\n",
    "\n",
    "#p_x_given_n_list\n",
    "#DecodedFilterEpochsResult\n",
    "timebinned_neuron_info = long_results_obj.timebinned_neuron_info\n",
    "result = LeaveOneOutDecodingResult(shuffle_IDXs=None)\n",
    "\n",
    "pf_shape = (len(long_results_obj.original_1D_decoder.pf.ratemap.xbin_centers),) # (59, )\n",
    "result.random_noise_curves = {}\n",
    "# result.random_noise_curves = np.random.uniform(low=0, high=1, size=(timebinned_neuron_info.n_timebins, *pf_shape))\n",
    "# result.random_noise_curves = (result.random_noise_curves.T / np.sum(result.random_noise_curves, axis=1)).T # normalize\n",
    "# result.random_noise_curves = (result.random_noise_curves.T / np.max(result.random_noise_curves, axis=1)).T # unit max normalization\n",
    "\n",
    "for index in np.arange(timebinned_neuron_info.n_timebins):\n",
    "\t# iterate through timebins\n",
    "\tif index not in result.one_left_out_posterior_to_pf_surprises:\n",
    "\t\tresult.one_left_out_posterior_to_pf_surprises[index] = []\n",
    "\tif index not in result.one_left_out_posterior_to_scrambled_pf_surprises:\n",
    "\t\tresult.one_left_out_posterior_to_scrambled_pf_surprises[index] = []\n",
    "\n",
    "\t## Pre loop: add empty array for accumulation\n",
    "\n",
    "\t# curr_random_not_firing_cell_pf_curve = np.random.uniform(low=0, high=1, size=curr_cell_pf_curve.shape) # generate one at a time\n",
    "\t# curr_random_not_firing_cell_pf_curve = curr_random_not_firing_cell_pf_curve / np.sum(curr_random_not_firing_cell_pf_curve) # normalize\n",
    "\t# result.random_noise_curves.append(curr_random_not_firing_cell_pf_curve)\n",
    "\n",
    "\t# curr_random_not_firing_cell_pf_curve = result.random_noise_curves[index]\n",
    "\n",
    "\tresult.random_noise_curves[index] = [] # list\n",
    "\n",
    "\tfor neuron_IDX, aclu in zip(timebinned_neuron_info.active_IDXs[index], timebinned_neuron_info.active_aclus[index]):\n",
    "\t\t# iterate through only the active cells\n",
    "\t\t# 1. Get set of cells active in a given time bin, for each compute the surprise of its placefield with the leave-one-out decoded posterior.\n",
    "\t\tleft_out_decoder_result = long_results_obj.one_left_out_filter_epochs_decoder_result_dict[aclu]\n",
    "\t\t# curr_cell_pf_curve = long_results_obj.original_1D_decoder.pf.ratemap.tuning_curves[neuron_IDX] # normalized pdf tuning curve\n",
    "\t\t# curr_cell_spike_curve = original_1D_decoder.pf.ratemap.spikes_maps[unit_IDX] ## not occupancy weighted... is this the right one to use for computing the expected spike rate? NO... doesn't seem like it\n",
    "\t\tcurr_cell_pf_curve = long_results_obj.original_1D_decoder.pf.ratemap.unit_max_tuning_curves[neuron_IDX] # Unit max tuning curve\n",
    "\n",
    "\t\t_, _, curr_timebins_p_x_given_n = left_out_decoder_result.flatten()\n",
    "\t\tcurr_timebin_p_x_given_n = curr_timebins_p_x_given_n[:, index] # .shape: (239, 5) - (n_x_bins, n_epoch_time_bins)\n",
    "\t\tassert curr_timebin_p_x_given_n.shape[0] == curr_cell_pf_curve.shape[0], f\"{curr_timebin_p_x_given_n.shape = } == {curr_cell_pf_curve.shape = }\"\n",
    "\t\t\n",
    "\t\t# if aclu not in result.one_left_out_posterior_to_pf_surprises:\n",
    "\t\t# \tresult.one_left_out_posterior_to_pf_surprises[aclu] = []\n",
    "\t\t# result.one_left_out_posterior_to_pf_surprises[aclu].append(distance.jensenshannon(curr_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "\n",
    "\t\tresult.one_left_out_posterior_to_pf_surprises[index].append(active_surprise_metric_fn(curr_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "\t\t# result.one_left_out_posterior_to_pf_correlations[timebin_IDX].append(distance.correlation(curr_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\t# 2. From the remainder of cells (those not active), randomly choose one to grab the placefield of and compute the surprise with that and the same posterior.\n",
    "\t\t# shuffled_cell_pf_curve = long_results_obj.original_1D_decoder.pf.ratemap.tuning_curves[shuffle_IDXs[i]]\n",
    "\n",
    "\t\t# a) Use a random non-firing cell's placefield:\n",
    "\t\trandom_not_firing_neuron_IDX = random.choice(timebinned_neuron_info.inactive_IDXs[index])\n",
    "\t\t# random_not_firing_aclu = random.choice(timebinned_neuron_info.inactive_aclus[i])\n",
    "\t\t# curr_random_not_firing_cell_pf_curve = long_results_obj.original_1D_decoder.pf.ratemap.tuning_curves[random_not_firing_neuron_IDX] # normalized pdf tuning curve\n",
    "\t\tcurr_random_not_firing_cell_pf_curve = long_results_obj.original_1D_decoder.pf.ratemap.unit_max_tuning_curves[random_not_firing_neuron_IDX] # Unit max tuning curve\n",
    "\n",
    "\t\t# b) Use a scrambled version of the real curve:\n",
    "\t\t# curr_random_not_firing_cell_pf_curve = _scramble_curve(curr_cell_pf_curve)\n",
    "\n",
    "\n",
    "\t\t## Save the curve for this neuron\n",
    "\t\tresult.random_noise_curves[index].append(curr_random_not_firing_cell_pf_curve)\n",
    "\n",
    "\t\t# if aclu not in result.one_left_out_posterior_to_scrambled_pf_surprises:\n",
    "\t\t# \tresult.one_left_out_posterior_to_scrambled_pf_surprises[aclu] = []\n",
    "\t\t# # The shuffled cell's placefield and the posterior from leaving a cell out:\n",
    "\t\t# result.one_left_out_posterior_to_scrambled_pf_surprises[aclu].append(distance.jensenshannon(curr_random_not_firing_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "\t\t\n",
    "\t\t# The shuffled cell's placefield and the posterior from leaving a cell out:\n",
    "\t\tresult.one_left_out_posterior_to_scrambled_pf_surprises[index].append(active_surprise_metric_fn(curr_random_not_firing_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "\t\t# result.one_left_out_posterior_to_scrambled_pf_correlations[timebin_IDX].append(distance.correlation(curr_random_not_firing_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "\n",
    "\t# END Neuron Loop\n",
    "\t## Post neuron loops: convert lists to np.arrays\n",
    "\tresult.one_left_out_posterior_to_pf_surprises[index] = np.array(result.one_left_out_posterior_to_pf_surprises[index])\n",
    "\tresult.one_left_out_posterior_to_scrambled_pf_surprises[index] = np.array(result.one_left_out_posterior_to_scrambled_pf_surprises[index])\n",
    "\tif len(result.random_noise_curves[index])>0:\n",
    "\t\tresult.random_noise_curves[index] = np.vstack(result.random_noise_curves[index]) # without this check np.vstack throws `ValueError: need at least one array to concatenate` for empty lists\n",
    "\telse:\n",
    "\t\tresult.random_noise_curves[index] = np.array(result.random_noise_curves[index]) \n",
    "\n",
    "\n",
    "\n",
    "# End Timebin Loop\n",
    "## Post timebin loops compute mean variables:\n",
    "result.one_left_out_posterior_to_pf_surprises_mean = {k:np.mean(v) for k, v in result.one_left_out_posterior_to_pf_surprises.items() if np.size(v) > 0}\n",
    "result.one_left_out_posterior_to_scrambled_pf_surprises_mean = {k:np.mean(v) for k, v in result.one_left_out_posterior_to_scrambled_pf_surprises.items() if np.size(v) > 0}\n",
    "assert len(result.one_left_out_posterior_to_scrambled_pf_surprises_mean) == len(result.one_left_out_posterior_to_pf_surprises_mean)\n",
    "assert list(result.one_left_out_posterior_to_scrambled_pf_surprises_mean.keys()) == list(result.one_left_out_posterior_to_pf_surprises_mean.keys())\n",
    "\n",
    "valid_time_bin_indicies = np.array(list(result.one_left_out_posterior_to_pf_surprises_mean.keys()))\n",
    "one_left_out_posterior_to_pf_surprises_mean = np.array(list(result.one_left_out_posterior_to_pf_surprises_mean.values()))\n",
    "one_left_out_posterior_to_scrambled_pf_surprises_mean = np.array(list(result.one_left_out_posterior_to_scrambled_pf_surprises_mean.values()))\n",
    "\n",
    "long_results_obj.all_epochs_reverse_flat_epoch_indicies_array\n",
    "\n",
    "# one_left_out_posterior_to_scrambled_pf_surprises_mean\n",
    "\n",
    "result_df = pd.DataFrame({'time_bin_indices': valid_time_bin_indicies, 'epoch_IDX': long_results_obj.all_epochs_reverse_flat_epoch_indicies_array[valid_time_bin_indicies], 'posterior_to_pf_mean_surprise': one_left_out_posterior_to_pf_surprises_mean, 'posterior_to_scrambled_pf_mean_surprise': one_left_out_posterior_to_scrambled_pf_surprises_mean})\n",
    "result_df['surprise_diff'] = result_df['posterior_to_scrambled_pf_mean_surprise'] - result_df['posterior_to_pf_mean_surprise']\n",
    "result_df\n",
    "\n",
    "# 24.9 seconds to compute\n",
    "\n",
    "## Compute Aggregate Dataframe for Epoch means:\n",
    "# Group by 'epoch_IDX' and compute means of all columns\n",
    "result_df_grouped = result_df.groupby('epoch_IDX').mean()\n",
    "result_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c107570f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ac777020184f5da46df45649a5baff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, description='Slider:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuron_IDX = array([ 2, 10, 14]), aclu = array([ 7, 20, 27])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([], dtype=int32), aclu = array([], dtype=int32)\n",
      "neuron_IDX = array([ 2, 10, 14]), aclu = array([ 7, 20, 27])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([], dtype=int32), aclu = array([], dtype=int32)\n",
      "neuron_IDX = array([24]), aclu = array([45])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([ 3, 34]), aclu = array([ 8, 63])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([], dtype=int32), aclu = array([], dtype=int32)\n",
      "neuron_IDX = array([35]), aclu = array([64])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([10, 17, 32]), aclu = array([20, 34, 60])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([ 7, 19, 21, 32, 34]), aclu = array([15, 39, 41, 60, 63])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([ 2, 18, 29]), aclu = array([ 7, 35, 53])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([], dtype=int32), aclu = array([], dtype=int32)\n",
      "neuron_IDX = array([15, 24, 33]), aclu = array([28, 45, 62])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([24, 28, 32, 34]), aclu = array([45, 52, 60, 63])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([], dtype=int32), aclu = array([], dtype=int32)\n",
      "neuron_IDX = array([15, 24, 33]), aclu = array([28, 45, 62])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([24, 28, 32, 34]), aclu = array([45, 52, 60, 63])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([], dtype=int32), aclu = array([], dtype=int32)\n",
      "neuron_IDX = array([24, 28, 32, 34]), aclu = array([45, 52, 60, 63])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([15, 24, 33]), aclu = array([28, 45, 62])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([], dtype=int32), aclu = array([], dtype=int32)\n",
      "neuron_IDX = array([15, 24, 33]), aclu = array([28, 45, 62])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([24, 28, 32, 34]), aclu = array([45, 52, 60, 63])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([], dtype=int32), aclu = array([], dtype=int32)\n",
      "neuron_IDX = array([24, 28, 32, 34]), aclu = array([45, 52, 60, 63])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([15, 24, 33]), aclu = array([28, 45, 62])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([24, 28, 32, 34]), aclu = array([45, 52, 60, 63])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([], dtype=int32), aclu = array([], dtype=int32)\n",
      "neuron_IDX = array([24, 28, 32, 34]), aclu = array([45, 52, 60, 63])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([17, 19, 32, 35]), aclu = array([34, 39, 60, 64])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([17, 29, 34]), aclu = array([34, 53, 63])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([32]), aclu = array([60])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([ 7, 10, 24, 28, 33]), aclu = array([15, 20, 45, 52, 62])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([28]), aclu = array([52])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([ 7, 10, 24, 28, 33]), aclu = array([15, 20, 45, 52, 62])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([28]), aclu = array([52])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([], dtype=int32), aclu = array([], dtype=int32)\n",
      "neuron_IDX = array([17, 30, 31, 32]), aclu = array([34, 55, 56, 60])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([18, 36]), aclu = array([35, 65])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([12]), aclu = array([25])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([15, 24]), aclu = array([28, 45])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([], dtype=int32), aclu = array([], dtype=int32)\n",
      "neuron_IDX = array([15, 24]), aclu = array([28, 45])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([12]), aclu = array([25])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n",
      "neuron_IDX = array([15, 24]), aclu = array([28, 45])\n",
      "curr_random_not_firing_cell_pf_curve.shape = (59,), curr_cell_pf_curve.shape = (59,), curr_timebin_p_x_given_n.shape = (59,)\n"
     ]
    }
   ],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "## Create a diagnostic plot that plots a stack of the three curves used for computations in the given epoch:\n",
    "\n",
    "def _add_plot(win: pg.GraphicsLayoutWidget, data, name:str):\n",
    "\tplot = win.addPlot() # PlotItem has to be built first?\n",
    "\tcurve = plot.plot(data, name=name, label=name)\n",
    "\tplot.setLabel('top', name)\n",
    "\treturn plot, curve\n",
    "\n",
    "win = pg.GraphicsLayoutWidget(show=True, title='diagnostic_plot')\n",
    "plot_data = {'curr_cell_pf_curve': curr_cell_pf_curve, 'curr_random_not_firing_cell_pf_curve': curr_random_not_firing_cell_pf_curve, 'curr_timebin_p_x_given_n': curr_timebin_p_x_given_n}\n",
    "plot_dict = {}\n",
    "\n",
    "def _initialize_plots(plot_data):\n",
    "\tfor i, (name, data) in enumerate(plot_data.items()):\n",
    "\t\tplot_item, curve = _add_plot(win, data=data, name=name)\n",
    "\t\tplot_dict[name] = {'plot_item':plot_item,'curve':curve}\n",
    "\t\tif i == 0:\n",
    "\t\t\tfirst_curve_name = name\n",
    "\t\telse:\n",
    "\t\t\tplot_dict[name]['plot_item'].setYLink(first_curve_name)  ## test linking by name\n",
    "\t\twin.nextRow()\n",
    "\treturn plot_dict\n",
    "\n",
    "\n",
    "def _update_plots(plot_dict, updated_plot_data):\n",
    "\t\"\"\" updates the plots created with `_initialize_plots`\"\"\"\n",
    "\tfor i, (name, data) in enumerate(updated_plot_data.items()):\n",
    "\t\tcurr_plot = plot_dict[name]['plot_item']\n",
    "\t\tcurr_curve = plot_dict[name]['curve']\n",
    "\t\tif data is not None:\n",
    "\t\t\tcurr_curve.setData(data)\n",
    "\t\telse:\n",
    "\t\t\t# curr_plot.clear() # will this mess up the plot by perminantly removing the curve? \n",
    "\t\t\t# curr_curve.clear()\n",
    "\t\t\tcurr_curve.setData([])\n",
    "\n",
    "def update_function(index):\n",
    "\t\"\"\" Define an update function that will be called with the current slider index \n",
    "\tCaptures plot_dict, and all data variables\n",
    "\t\"\"\"\n",
    "    # print(f'Slider index: {index}')\n",
    "\thardcoded_sub_epoch_item_idx = 0\n",
    "\n",
    "\tcurr_random_not_firing_cell_pf_curve = result.random_noise_curves[index]\n",
    "\tneuron_IDX, aclu = timebinned_neuron_info.active_IDXs[index], timebinned_neuron_info.active_aclus[index]\n",
    "\tprint(f'{neuron_IDX = }, {aclu = }')\n",
    "\tif len(neuron_IDX) > 0:\n",
    "\t\t# Get first index\n",
    "\t\tneuron_IDX = neuron_IDX[hardcoded_sub_epoch_item_idx]\n",
    "\t\taclu = aclu[hardcoded_sub_epoch_item_idx]\n",
    "\t\t# curr_cell_pf_curve = long_results_obj.original_1D_decoder.pf.ratemap.tuning_curves[neuron_IDX]\n",
    "\t\tcurr_cell_pf_curve = long_results_obj.original_1D_decoder.pf.ratemap.unit_max_tuning_curves[neuron_IDX]\n",
    "\n",
    "\t\tif curr_random_not_firing_cell_pf_curve.ndim > 1:\n",
    "\t\t\tcurr_random_not_firing_cell_pf_curve = curr_random_not_firing_cell_pf_curve[hardcoded_sub_epoch_item_idx]\n",
    "\n",
    "\t\tcurr_timebin_p_x_given_n = curr_timebins_p_x_given_n[:, index]\n",
    "\t\tprint(f'{curr_random_not_firing_cell_pf_curve.shape = }, {curr_cell_pf_curve.shape = }, {curr_timebin_p_x_given_n.shape = }')\n",
    "\t\t# result.one_left_out_posterior_to_pf_surprises[index]\n",
    "\t\t# result.one_left_out_posterior_to_scrambled_pf_surprises[index]\n",
    "\t\tnormal_surprise, random_surprise = result.one_left_out_posterior_to_pf_surprises[index][hardcoded_sub_epoch_item_idx], result.one_left_out_posterior_to_scrambled_pf_surprises[index][hardcoded_sub_epoch_item_idx]\n",
    "\n",
    "\t\tupdated_plot_data = {'curr_cell_pf_curve': curr_cell_pf_curve, 'curr_random_not_firing_cell_pf_curve': curr_random_not_firing_cell_pf_curve, 'curr_timebin_p_x_given_n': curr_timebin_p_x_given_n}\n",
    "\t\t_update_plots(plot_dict, updated_plot_data)\n",
    "\n",
    "\t\tplot_dict['curr_cell_pf_curve']['plot_item'].setLabel('bottom', f\"{normal_surprise}\")\n",
    "\t\tplot_dict['curr_random_not_firing_cell_pf_curve']['plot_item'].setLabel('bottom', f\"{random_surprise}\")\n",
    "\telse:\n",
    "\t\t# Invalid period\n",
    "\t\tplot_dict['curr_cell_pf_curve']['plot_item'].setLabel('bottom', f\"NO ACTIVITY\")\n",
    "\t\tplot_dict['curr_random_not_firing_cell_pf_curve']['plot_item'].setLabel('bottom', f\"NO ACTIVITY\")\n",
    "\t\tupdated_plot_data = {'curr_cell_pf_curve': None, 'curr_random_not_firing_cell_pf_curve': None, 'curr_timebin_p_x_given_n': None}\n",
    "\t\t_update_plots(plot_dict, updated_plot_data)\n",
    "\n",
    "plot_dict = _initialize_plots(plot_data=plot_data)\n",
    "\n",
    "# win.graphicsItem().setLabel(axis='left', text='Short v. Long - Expected vs. Observed # Spikes')\n",
    "# win.graphicsItem().setLabel(axis='bottom', text='time')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def integer_slider(update_func):\n",
    "    \"\"\" 2023-04-13 - WORKS!!!\n",
    "    Displays an integer slider that the user can adjust.\n",
    "\n",
    "    Args:\n",
    "        update_func (function): A user-provided update function that will be called with the current slider index.\n",
    "    \"\"\"\n",
    "    slider = widgets.IntSlider(description='Slider:', min=0, max=100, value=0)\n",
    "\n",
    "    def on_slider_change(change):\n",
    "        \"\"\"Callback function for slider value change.\"\"\"\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            # Call the user-provided update function with the current slider index\n",
    "            update_func(change['new'])\n",
    "\n",
    "    slider.observe(on_slider_change)\n",
    "    display(slider)\n",
    "\n",
    "# Define an update function that will be called with the current slider index\n",
    "# def update_function(index):\n",
    "#     print(f'Slider index: {index}')\n",
    "\n",
    "# Call the integer_slider function with the update function\n",
    "integer_slider(update_function)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54b239b9",
   "metadata": {},
   "source": [
    "## 2023-04-13 - Desired Plotting Interface Idea:\n",
    "```python\n",
    "# Rows of plots can be constructed trivially through lists:\n",
    "row_of_plots = [pg.plot(curr_cell_pf_curve, label='curr_cell_pf_curve'), pg.plot(curr_random_not_firing_cell_pf_curve, label='curr_random_not_firing_cell_pf_curve'), ...] \n",
    "\t# I'd guess behind the scenes they would be converted into a helper.row([...]) object\n",
    "\n",
    "# If you want a column instead, use helper.column\n",
    "column_of_plots = helper.column([pg.plot(curr_cell_pf_curve, label='curr_cell_pf_curve'), pg.plot(curr_random_not_firing_cell_pf_curve, label='curr_random_not_firing_cell_pf_curve'), ...])\n",
    "\n",
    "# The returned objects are composable:\n",
    "row_of_layouts = [row_of_plots, column_of_plots] # stacks the layout objects just like they were plot objects\n",
    "\n",
    "# Showing the result is easy, as is combining separate results in a new place:\n",
    "whole_figure_window = [row_of_layouts] \n",
    "whole_figure_window.show()\n",
    "```\n",
    "\n",
    "\"\"\" \n",
    "Relevant Functions:\n",
    "`perform_full_session_leave_one_out_decoding_analysis`:\n",
    "\t`perform_leave_one_aclu_out_decoding_analysis`:\tfrom pyphoplacecellanalysis.Analysis.Decoder.decoder_result import perform_leave_one_aclu_out_decoding_analysis\n",
    "\t`_analyze_leave_one_out_decoding_results`: from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.DefaultComputationFunctions import _analyze_leave_one_out_decoding_results\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Get set of cells active in a given time bin, for each compute the surprise of its placefield with the leave-one-out decoded posterior.\n",
    "\n",
    "# 2. From the remainder of cells (those not active), randomly choose one to grab the placefield of and compute the surprise with that and the same posterior.\n",
    "\n",
    "\n",
    "# Expectation: The cells that are included in the time bin are expected to have a lower surprise (be less correlated with) the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8ff50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "# 'time_bin_indices': valid_time_bin_indicies, 'posterior_to_pf_mean_surprise': one_left_out_posterior_to_pf_surprises_mean, 'posterior_to_scrambled_pf_mean_surprise': one_left_out_posterior_to_scrambled_pf_surprises_mean}\n",
    "\n",
    "# make a separate symbol_brush color for each cell:\n",
    "# cell_color_symbol_brush = [pg.intColor(i,hues=9, values=3, alpha=180) for i, aclu in enumerate(long_results_obj.original_1D_decoder.neuron_IDs)] # maxValue=128\n",
    "# All properties in common:\n",
    "win = pg.plot()\n",
    "win.setWindowTitle('Long Sanity Check - Leave-one-out Custom Surprise Plot')\n",
    "# legend_size = (80,60) # fixed size legend\n",
    "legend_size = None # auto-sizing legend to contents\n",
    "legend = pg.LegendItem(legend_size, offset=(-1,0)) # do this instead of # .addLegend\n",
    "legend.setParentItem(win.graphicsItem())\n",
    "\n",
    "plots = {}\n",
    "label_prefix_list = ['normal', 'scrambled']\n",
    "long_short_symbol_list = ['t', 'o'] # note: 's' is a square. 'o', 't1': triangle pointing upwards0\n",
    "\n",
    "\n",
    "# Use mean time_bin and surprise for each epoch\n",
    "# plots['normal'] = win.plot(x=valid_time_bin_indicies, y=one_left_out_posterior_to_pf_surprises_mean, pen=None, symbol='t', symbolBrush=pg.intColor(1,6,maxValue=128), name=f'normal', alpha=0.5) #  symbolBrush=pg.intColor(i,6,maxValue=128) , symbol=curr_symbol, symbolBrush=cell_color_symbol_brush[unit_IDX]\n",
    "# plots['scrambled'] = win.plot(x=valid_time_bin_indicies, y=one_left_out_posterior_to_scrambled_pf_surprises_mean, pen=None, symbol='t', symbolBrush=pg.intColor(2,6,maxValue=128), name=f'scrambled', alpha=0.5) #  symbolBrush=pg.intColor(i,6,maxValue=128) , symbol=curr_symbol, symbolBrush=cell_color_symbol_brush[unit_IDX]\n",
    "\n",
    "curr_surprise_difference = one_left_out_posterior_to_scrambled_pf_surprises_mean - one_left_out_posterior_to_pf_surprises_mean\n",
    "\n",
    "\n",
    "# x=valid_time_bin_indicies\n",
    "# y=curr_surprise_difference\n",
    "x=result_df_grouped.time_bin_indices.to_numpy()\n",
    "y=result_df_grouped['surprise_diff'].to_numpy()\n",
    "\n",
    "plots['difference'] = win.plot(x=x, y=y, pen=None, symbol='t', symbolBrush=pg.intColor(2,6,maxValue=128), name=f'difference', alpha=0.5) #  symbolBrush=pg.intColor(i,6,maxValue=128) , symbol=curr_symbol, symbolBrush=cell_color_symbol_brush[unit_IDX]\n",
    "\n",
    "\n",
    "for k, v in plots.items():\n",
    "\tlegend.addItem(v, f'{k}')\n",
    "\n",
    "win.graphicsItem().setLabel(axis='left', text='Normal v. Random - Surprise (Custom)')\n",
    "win.graphicsItem().setLabel(axis='bottom', text='time')\n",
    "# return win, plots_tuple, legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0111cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_time_bin_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f539736",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_left_out_posterior_to_pf_surprises_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f996fd9",
   "metadata": {},
   "source": [
    "## Pre 2023-04-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea08f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Fresh (don't load from cache)\n",
    "long_results_obj = perform_full_session_leave_one_out_decoding_analysis(global_session, original_1D_decoder=long_shared_aclus_only_decoder, decoding_time_bin_size = 0.025, cache_suffix = '_long', perform_cache_load=False, skip_cache_save=False)\n",
    "short_results_obj = perform_full_session_leave_one_out_decoding_analysis(global_session, original_1D_decoder=short_shared_aclus_only_decoder, decoding_time_bin_size = 0.025, cache_suffix = '_short', perform_cache_load=False, skip_cache_save=False)\n",
    "# # (time_bins, neurons), (epochs, neurons), (epochs)\n",
    "# all_epochs_computed_one_left_out_posterior_to_pf_surprises, all_epochs_computed_cell_one_left_out_posterior_to_pf_surprises_mean, all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33b6ac25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num pyramidal_only_all_aclus: 40\n",
      "pyramidal_only_all_aclus: [ 5  6  7  8 10 11 12 15 17 18 19 20 21 24 25 26 27 28 31 34 35 39 40 41\n",
      " 43 44 45 48 49 50 51 52 53 55 56 60 62 63 64 65]\n",
      "active_epoch_n_timebins = 7\n",
      "len(shared_aclus) = 40\n",
      "callout_flat_timebin_IDXs = array([28, 30, 32])\n",
      "plots_data.callout_time_bins: [array([66.669, 66.719, 66.769]), array([66.694, 66.744, 66.794])]\n",
      "start_ts: [66.669 66.719 66.769], end_ts: [66.694 66.744 66.794]\n",
      "setting region[28]: 66.66900000000024, 66.69400000000036 :: end_t - start_t = 0.02500000000011937\n",
      "setting region[30]: 66.71900000000048, 66.7440000000006 :: end_t - start_t = 0.02500000000011937\n",
      "setting region[32]: 66.76900000000072, 66.79400000000084 :: end_t - start_t = 0.02500000000011937\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import plot_kourosh_activity_style_figure\n",
    "\n",
    "from neuropy.core.neurons import NeuronType\n",
    "# # Include only pyramidal aclus:\n",
    "# print(f'all shared_aclus: {len(shared_aclus)}\\nshared_aclus: {shared_aclus}')\n",
    "# shared_aclu_neuron_type = long_session.neurons.neuron_type[np.isin(long_session.neurons.neuron_ids, shared_aclus)]\n",
    "# assert len(shared_aclu_neuron_type) == len(shared_aclus)\n",
    "# # Find only the aclus that are pyramidal:\n",
    "# is_shared_aclu_pyramidal = (shared_aclu_neuron_type == NeuronType.PYRAMIDAL)\n",
    "# pyramidal_only_shared_aclus = shared_aclus[is_shared_aclu_pyramidal]\n",
    "# print(f'num pyramidal_only_shared_aclus: {len(pyramidal_only_shared_aclus)}\\npyramidal_only_shared_aclus: {pyramidal_only_shared_aclus}')\n",
    "\n",
    "\n",
    "## Drop Pyramidal but don't use only shared aclus:\n",
    "all_aclus = deepcopy(long_session.neurons.neuron_ids)\n",
    "neuron_type = long_session.neurons.neuron_type\n",
    "assert len(neuron_type) == len(all_aclus)\n",
    "# Find only the aclus that are pyramidal:\n",
    "is_aclu_pyramidal = (neuron_type == NeuronType.PYRAMIDAL)\n",
    "pyramidal_only_all_aclus = all_aclus[is_aclu_pyramidal]\n",
    "print(f'num pyramidal_only_all_aclus: {len(pyramidal_only_all_aclus)}\\npyramidal_only_all_aclus: {pyramidal_only_all_aclus}')\n",
    "\n",
    "# app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, shared_aclus, epoch_idx=5, callout_epoch_IDXs=[0,1,2,3], skip_rendering_callouts=True)\n",
    "# app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_shared_aclus, epoch_idx=2, callout_epoch_IDXs=[0,4], skip_rendering_callouts=False)\n",
    "app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_all_aclus, epoch_idx=3, callout_epoch_IDXs=[2,4,6], skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea983fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_all_aclus, epoch_idx=11, callout_epoch_IDXs=[0,1,2, 3, 4, 5], skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3584cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f519e392",
   "metadata": {},
   "source": [
    "# 2023-04-13 Show Surprise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b417bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from PendingNotebookCode import plot_long_short, plot_long_short_any_values, plot_long_short_expected_vs_observed_firing_rates\n",
    "\n",
    "# plot_long_short(long_results_obj, short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fbd6593",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot_long_short_any_values() missing 2 required positional arguments: 'x' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_long_short_any_values(long_results_obj\u001b[39m=\u001b[39;49mlong_results_obj, short_results_obj\u001b[39m=\u001b[39;49mshort_results_obj)\n",
      "\u001b[1;31mTypeError\u001b[0m: plot_long_short_any_values() missing 2 required positional arguments: 'x' and 'y'"
     ]
    }
   ],
   "source": [
    "plot_long_short_any_values(long_results_obj=long_results_obj, short_results_obj=short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6b8a7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<pyphoplacecellanalysis.External.pyqtgraph.widgets.PlotWidget.PlotWidget at 0x1f1250f19d0>,\n",
       " ({5: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1250d1b80>,\n",
       "   6: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1250d1ee0>,\n",
       "   7: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1250f1c10>,\n",
       "   8: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1250c4160>,\n",
       "   10: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1250c44c0>,\n",
       "   11: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1250c4820>,\n",
       "   12: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1250c4b80>,\n",
       "   15: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1250c4ee0>,\n",
       "   17: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12630a280>,\n",
       "   18: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12630a5e0>,\n",
       "   20: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12630a940>,\n",
       "   24: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12630aca0>,\n",
       "   25: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263a1040>,\n",
       "   26: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263a13a0>,\n",
       "   27: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263a1700>,\n",
       "   28: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263a1a60>,\n",
       "   31: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263a1dc0>,\n",
       "   34: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263b2160>,\n",
       "   35: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263b24c0>,\n",
       "   39: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263b2820>,\n",
       "   40: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263b2b80>,\n",
       "   41: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263b2ee0>,\n",
       "   43: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f126385280>,\n",
       "   44: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263855e0>,\n",
       "   45: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f126385940>,\n",
       "   49: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f126385ca0>,\n",
       "   50: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263bb040>,\n",
       "   51: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263bb3a0>,\n",
       "   52: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263bb700>,\n",
       "   53: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263bba60>,\n",
       "   55: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263bbdc0>,\n",
       "   56: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f126460160>,\n",
       "   60: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1264604c0>,\n",
       "   62: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f126460820>,\n",
       "   63: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f126460b80>,\n",
       "   64: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f126460ee0>,\n",
       "   65: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263df280>},\n",
       "  {5: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263df5e0>,\n",
       "   6: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263df940>,\n",
       "   7: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1263dfca0>,\n",
       "   8: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12649a040>,\n",
       "   10: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12649a3a0>,\n",
       "   11: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12649a700>,\n",
       "   12: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12649aa60>,\n",
       "   15: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12649adc0>,\n",
       "   17: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1264a4160>,\n",
       "   18: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1264a44c0>,\n",
       "   20: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1264a4820>,\n",
       "   24: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1264a4b80>,\n",
       "   25: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1264a4ee0>,\n",
       "   26: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1264b3280>,\n",
       "   27: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1264b35e0>,\n",
       "   28: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1264b3940>,\n",
       "   31: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1264b3ca0>,\n",
       "   34: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12649f040>,\n",
       "   35: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12649f3a0>,\n",
       "   39: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12649f700>,\n",
       "   40: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12649fa60>,\n",
       "   41: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12649fdc0>,\n",
       "   43: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f126717160>,\n",
       "   44: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1267174c0>,\n",
       "   45: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f126717820>,\n",
       "   49: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f126717b80>,\n",
       "   50: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f126717ee0>,\n",
       "   51: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12671d280>,\n",
       "   52: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12671d5e0>,\n",
       "   53: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12671d940>,\n",
       "   55: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12671dca0>,\n",
       "   56: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12672c040>,\n",
       "   60: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12672c3a0>,\n",
       "   62: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12672c700>,\n",
       "   63: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12672ca60>,\n",
       "   64: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f12672cdc0>,\n",
       "   65: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x1f1267b3160>}),\n",
       " <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.LegendItem.LegendItem at 0x1f1250f1700>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_long_short_expected_vs_observed_firing_rates(long_results_obj=long_results_obj, short_results_obj=short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fn = lambda a_results_obj: a_results_obj.all_epochs_decoded_epoch_time_bins_mean[:,0]\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_scrambled_pf_surprises_mean\n",
    "y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_computed_one_left_out_posterior_to_pf_surprises\n",
    "\n",
    "# (time_bins, neurons), (epochs, neurons), (epochs)\n",
    "# all_epochs_computed_one_left_out_posterior_to_pf_surprises, all_epochs_computed_cell_one_left_out_posterior_to_pf_surprises_mean, all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "win, plots_tuple, legend = plot_long_short_any_values(long_results_obj, short_results_obj, x=x_fn, y=y_fn, limit_aclus=[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe80559",
   "metadata": {},
   "source": [
    "# 2023-04-13 - Find Good looking epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddbb6dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_labels: []\n",
      "a_slice_idx: 0\n",
      "a_slice_start_t: 49.117, a_slice_end_t: 49.321999999999996, a_slice_label: epoch[0]\n",
      "a_slice_idx: 1\n",
      "a_slice_start_t: 63.958999999999996, a_slice_end_t: 64.211, a_slice_label: epoch[1]\n",
      "a_slice_idx: 2\n",
      "a_slice_start_t: 64.758, a_slice_end_t: 64.971, a_slice_label: epoch[2]\n",
      "a_slice_idx: 3\n",
      "a_slice_start_t: 66.619, a_slice_end_t: 66.797, a_slice_label: epoch[3]\n",
      "a_slice_idx: 4\n",
      "a_slice_start_t: 67.935, a_slice_end_t: 68.169, a_slice_label: epoch[4]\n",
      "a_slice_idx: 5\n",
      "a_slice_start_t: 88.43599999999999, a_slice_end_t: 88.583, a_slice_label: epoch[5]\n",
      "a_slice_idx: 6\n",
      "a_slice_start_t: 91.182, a_slice_end_t: 91.44, a_slice_label: epoch[6]\n",
      "a_slice_idx: 7\n",
      "a_slice_start_t: 94.11, a_slice_end_t: 94.24, a_slice_label: epoch[7]\n",
      "a_slice_idx: 8\n",
      "a_slice_start_t: 95.277, a_slice_end_t: 95.42399999999999, a_slice_label: epoch[8]\n",
      "a_slice_idx: 9\n",
      "a_slice_start_t: 96.49499999999999, a_slice_end_t: 96.944, a_slice_label: epoch[9]\n",
      "a_slice_idx: 10\n",
      "a_slice_start_t: 97.0, a_slice_end_t: 97.142, a_slice_label: epoch[10]\n",
      "a_slice_idx: 11\n",
      "a_slice_start_t: 103.601, a_slice_end_t: 103.786, a_slice_label: epoch[11]\n",
      "a_slice_idx: 12\n",
      "a_slice_start_t: 107.073, a_slice_end_t: 107.243, a_slice_label: epoch[12]\n",
      "a_slice_idx: 13\n",
      "a_slice_start_t: 109.169, a_slice_end_t: 109.396, a_slice_label: epoch[13]\n",
      "a_slice_idx: 14\n",
      "a_slice_start_t: 112.09599999999999, a_slice_end_t: 112.226, a_slice_label: epoch[14]\n",
      "a_slice_idx: 15\n",
      "a_slice_start_t: 124.083, a_slice_end_t: 124.482, a_slice_label: epoch[15]\n",
      "a_slice_idx: 16\n",
      "a_slice_start_t: 142.206, a_slice_end_t: 142.339, a_slice_label: epoch[16]\n",
      "a_slice_idx: 17\n",
      "a_slice_start_t: 144.98, a_slice_end_t: 145.209, a_slice_label: epoch[17]\n",
      "a_slice_idx: 18\n",
      "a_slice_start_t: 172.541, a_slice_end_t: 172.69199999999998, a_slice_label: epoch[18]\n",
      "a_slice_idx: 19\n",
      "a_slice_start_t: 173.946, a_slice_end_t: 174.212, a_slice_label: epoch[19]\n",
      "a_slice_idx: 20\n",
      "a_slice_start_t: 204.34699999999998, a_slice_end_t: 204.47799999999998, a_slice_label: epoch[20]\n",
      "a_slice_idx: 21\n",
      "a_slice_start_t: 221.689, a_slice_end_t: 221.856, a_slice_label: epoch[21]\n",
      "a_slice_idx: 22\n",
      "a_slice_start_t: 222.06799999999998, a_slice_end_t: 222.219, a_slice_label: epoch[22]\n",
      "a_slice_idx: 23\n",
      "a_slice_start_t: 224.545, a_slice_end_t: 225.082, a_slice_label: epoch[23]\n",
      "a_slice_idx: 24\n",
      "a_slice_start_t: 236.249, a_slice_end_t: 236.54299999999998, a_slice_label: epoch[24]\n",
      "a_slice_idx: 25\n",
      "a_slice_start_t: 237.673, a_slice_end_t: 237.839, a_slice_label: epoch[25]\n",
      "a_slice_idx: 26\n",
      "a_slice_start_t: 238.34799999999998, a_slice_end_t: 238.50099999999998, a_slice_label: epoch[26]\n",
      "a_slice_idx: 27\n",
      "a_slice_start_t: 240.35, a_slice_end_t: 240.607, a_slice_label: epoch[27]\n",
      "a_slice_idx: 28\n",
      "a_slice_start_t: 273.638, a_slice_end_t: 273.844, a_slice_label: epoch[28]\n",
      "a_slice_idx: 29\n",
      "a_slice_start_t: 295.947, a_slice_end_t: 296.10699999999997, a_slice_label: epoch[29]\n",
      "a_slice_idx: 30\n",
      "a_slice_start_t: 301.858, a_slice_end_t: 301.991, a_slice_label: epoch[30]\n",
      "a_slice_idx: 31\n",
      "a_slice_start_t: 313.015, a_slice_end_t: 313.364, a_slice_label: epoch[31]\n",
      "i : 0, curr_posterior.shape: (59, 8)\n",
      "i : 1, curr_posterior.shape: (59, 10)\n",
      "i : 2, curr_posterior.shape: (59, 8)\n",
      "i : 3, curr_posterior.shape: (59, 7)\n",
      "i : 4, curr_posterior.shape: (59, 9)\n",
      "i : 5, curr_posterior.shape: (59, 5)\n",
      "i : 6, curr_posterior.shape: (59, 10)\n",
      "i : 7, curr_posterior.shape: (59, 5)\n",
      "i : 8, curr_posterior.shape: (59, 5)\n",
      "i : 9, curr_posterior.shape: (59, 17)\n",
      "i : 10, curr_posterior.shape: (59, 5)\n",
      "i : 11, curr_posterior.shape: (59, 7)\n",
      "i : 12, curr_posterior.shape: (59, 6)\n",
      "i : 13, curr_posterior.shape: (59, 9)\n",
      "i : 14, curr_posterior.shape: (59, 5)\n",
      "i : 15, curr_posterior.shape: (59, 15)\n",
      "i : 16, curr_posterior.shape: (59, 5)\n",
      "i : 17, curr_posterior.shape: (59, 9)\n",
      "i : 18, curr_posterior.shape: (59, 6)\n",
      "i : 19, curr_posterior.shape: (59, 10)\n",
      "i : 20, curr_posterior.shape: (59, 5)\n",
      "i : 21, curr_posterior.shape: (59, 6)\n",
      "i : 22, curr_posterior.shape: (59, 6)\n",
      "i : 23, curr_posterior.shape: (59, 21)\n",
      "i : 24, curr_posterior.shape: (59, 11)\n",
      "i : 25, curr_posterior.shape: (59, 6)\n",
      "i : 26, curr_posterior.shape: (59, 6)\n",
      "i : 27, curr_posterior.shape: (59, 10)\n",
      "i : 28, curr_posterior.shape: (59, 8)\n",
      "i : 29, curr_posterior.shape: (59, 6)\n",
      "i : 30, curr_posterior.shape: (59, 5)\n",
      "i : 31, curr_posterior.shape: (59, 13)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices\n",
    "\n",
    "laps_plot_tuple = plot_decoded_epoch_slices(long_results_obj.active_filter_epochs, long_results_obj.all_included_filter_epochs_decoder_result, global_pos_df=global_session.position.df, variable_name='lin_pos', xbin=long_results_obj.original_1D_decoder.xbin,\n",
    "                                                        name='stacked_epoch_slices_long_results_obj', debug_print=True, debug_test_max_num_slices=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed0656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[23, 27, 29, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pagination support for `plot_decoded_epoch_slices`\n",
    "from pyphocorehelpers.indexing_helpers import compute_paginated_grid_config\n",
    "\n",
    "n_epochs = long_results_obj.active_filter_epochs.n_epochs\n",
    "subplot_no_pagination_configuration, included_combined_indicies_pages, page_grid_sizes = compute_paginated_grid_config(n_epochs, max_num_columns=1, max_subplots_per_page=32, data_indicies=result_df_grouped.index.to_numpy(), last_figure_subplots_same_layout=True)\n",
    "num_pages = len(included_combined_indicies_pages)\n",
    "num_pages\n",
    "included_epoch_indicies_pages = [[curr_included_epoch_index for (a_linear_index, curr_row, curr_col, curr_included_epoch_index) in v] for page_idx, v in enumerate(included_combined_indicies_pages)] # a list of length `num_pages` containing up to 10 items"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
