{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b911237-bf80-4a81-936c-b3f3891f9481",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: pho\n",
    "\"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import time\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "# %gui qt\n",
    "# $env:QT_API=\"pyqt6\"\n",
    "%gui qt5\n",
    "# from PyQt5.Qt import QApplication\n",
    "# # start qt event loop\n",
    "# _instance = QApplication.instance()\n",
    "# if not _instance:\n",
    "#     _instance = QApplication([])\n",
    "# app = _instance\n",
    "import pyqtgraph as pg\n",
    "from pyqtgraph.Qt import QtCore, QtGui\n",
    "import pyqtgraph.opengl as gl # for 3D raster plot\n",
    "\n",
    "# ## Panel:\n",
    "import param\n",
    "# import panel as pn\n",
    "# from panel.interact import interact, interactive, fixed, interact_manual\n",
    "# from panel.viewable import Viewer\n",
    "# pn.extension()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import get_arguments_as_optional_dict, inspect_callable_arguments\n",
    "from pyphocorehelpers.function_helpers import compose_functions\n",
    "from pyphocorehelpers.indexing_helpers import partition, build_spanning_bins, compute_spanning_bins, compute_position_grid_size, compute_paginated_grid_config\n",
    "from pyphocorehelpers.print_helpers import PrettyPrintable, WrappingMessagePrinter\n",
    "from pyphocorehelpers.geometry_helpers import compute_data_extent, compute_data_aspect_ratio, corner_points_from_extents\n",
    "from pyphocorehelpers.DataStructure.dynamic_parameters import DynamicParameters\n",
    "from pyphocorehelpers.performance_timing_helpers import WrappingPerformanceTimer\n",
    "from pyphocorehelpers.gui.interaction_helpers import CallbackWrapper\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.SessionSelectionAndFiltering import batch_filter_session, build_custom_epochs_filters\n",
    "from pyphoplacecellanalysis.General.ComputationResults import ComputationResult\n",
    "from pyphoplacecellanalysis.General.KnownDataSessionTypeProperties import KnownDataSessionTypeProperties\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Display import DefaultDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.Ratemaps import DefaultRatemapDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import DefaultDecoderDisplayFunctions\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Spike3DRaster import Spike3DRaster\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_RasterPlot import plot_raster_plot, _display_pyqtgraph_raster_plot\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "try:\n",
    "    from neuropy import core\n",
    "\n",
    "    importlib.reload(core)\n",
    "except ImportError:\n",
    "    sys.path.append(r\"C:\\Users\\Pho\\repos\\NeuroPy\")  # Windows\n",
    "    # sys.path.append('/home/pho/repo/BapunAnalysis2021/NeuroPy') # Linux\n",
    "    # sys.path.append(r'/Users/pho/repo/Python Projects/NeuroPy') # MacOS\n",
    "    print(\"neuropy module not found, adding directory to sys.path. \\n >> Updated sys.path.\")\n",
    "    from neuropy import core\n",
    "\n",
    "# Neuropy:\n",
    "from neuropy.core.session.data_session_loader import DataSessionLoader\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.core.laps import Laps\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters, perform_compute_placefields\n",
    "from neuropy.analyses.laps import estimation_session_laps\n",
    "from neuropy.core.epoch import NamedTimerange\n",
    "\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters, perform_compute_placefields\n",
    "from neuropy.core.neuron_identities import NeuronIdentity, build_units_colormap, PlotStringBrevityModeEnum\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_spike_counts, debug_print_subsession_neuron_differences\n",
    "from neuropy.plotting.ratemaps import enumTuningMap2DPlotVariables\n",
    "# from neuropy.utils.mixins.time_slicing import verify_non_overlapping, add_PBE_identity\n",
    "from neuropy.utils.efficient_interval_search import get_non_overlapping_epochs, drop_overlapping\n",
    "\n",
    "known_data_session_type_dict = {'kdiba':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: DataSessionLoader.kdiba_old_format_session(a_base_dir)),\n",
    "                               basedir=Path(r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53')),\n",
    "                'bapun':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: DataSessionLoader.bapun_data_session(a_base_dir)),\n",
    "                               basedir=Path('R:\\data\\Bapun\\Day5TwoNovel'))\n",
    "               }\n",
    "known_data_session_type_dict['kdiba'].post_load_functions = [lambda a_loaded_sess: estimation_session_laps(a_loaded_sess)]\n",
    "\n",
    "# known_data_session_type_dict['kdiba'].name\n",
    "# from matplotlib.figure import Figure\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib qt\n",
    "# from matplotlib.transforms import IdentityTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28884090-444c-4c0a-a0a1-c7d5d09bf195",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "enable_saving_to_disk = False\n",
    "# common_parent_foldername = Path(r'R:\\Dropbox (Personal)\\Active\\Kamran Diba Lib\\Pho-Kamran-Meetings\\Final Placemaps 2021-01-14')\n",
    "common_parent_foldername = Path(r'R:\\Dropbox (Personal)\\Active\\Kamran Diba Lib\\Pho-Kamran-Meetings\\2022-01-16')\n",
    "\n",
    "def compute_position_grid_bin_size(x, y, num_bins=(64,64), debug_print=False):\n",
    "    \"\"\" Compute Required Bin size given a desired number of bins in each dimension\n",
    "    Usage:\n",
    "        active_grid_bin = compute_position_grid_bin_size(curr_kdiba_pipeline.sess.position.x, curr_kdiba_pipeline.sess.position.y, num_bins=(64, 64)\n",
    "    \"\"\"\n",
    "    out_grid_bin_size, out_bins, out_bins_infos = compute_position_grid_size(x, y, num_bins=num_bins)\n",
    "    active_grid_bin = tuple(out_grid_bin_size)\n",
    "    if debug_print:\n",
    "        print(f'active_grid_bin: {active_grid_bin}') # (3.776841861770752, 1.043326930905373)\n",
    "    return active_grid_bin\n",
    "\n",
    "# WARNING! TODO: Changing the smooth values from (1.5, 1.5) to (0.5, 0.5) was the difference between successful running and a syntax error!\n",
    "# try:\n",
    "#     active_grid_bin\n",
    "# except NameError as e:\n",
    "#     print('setting active_grid_bin = None')\n",
    "#     active_grid_bin = None\n",
    "# finally:\n",
    "#     # active_session_computation_config = PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=active_grid_bin, smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5) # if active_grid_bin is missing, figure out the name\n",
    "#     active_session_computation_config = PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=active_grid_bin, smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5) # if active_grid_bin is missing, figure out the name\n",
    "\n",
    "## Dynamic mode:\n",
    "def _build_active_computation_configs(sess):\n",
    "    \"\"\" _get_computation_configs(curr_kdiba_pipeline.sess)\n",
    "        # From Diba:\n",
    "        # (3.777, 1.043) # for (64, 64) bins\n",
    "        # (1.874, 0.518) # for (128, 128) bins\n",
    "\n",
    "    \"\"\"\n",
    "    # active_grid_bin = compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64))\n",
    "    # active_session_computation_config.computation_epochs = None # set the placefield computation epochs to None, using all epochs.\n",
    "    # return [PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64)), smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None)]\n",
    "    # return [PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(128, 128)), smooth=(2.0, 2.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None)]\n",
    "    return [PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64)), smooth=(2.0, 2.0), frate_thresh=0.2, time_bin_size=1.0, computation_epochs = None)]\n",
    "    # return [PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=(3.777, 1.043), smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None)]\n",
    "\n",
    "    # return [PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(32, 32)), smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None),\n",
    "    #         PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64)), smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None),\n",
    "    #         PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(128, 128)), smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None),\n",
    "    #        ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eceb354-7fa7-4064-ba26-4e989b9f3354",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bapun Format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20843de4-9a94-42f7-80a9-f2c8d5704b62",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# curr_bapun_pipeline = NeuropyPipeline(name='bapun_pipeline', session_data_type='bapun', basedir=known_data_session_type_dict['bapun'].basedir, load_function=known_data_session_type_dict['bapun'].load_function)\n",
    "curr_bapun_pipeline = NeuropyPipeline.init_from_known_data_session_type('bapun', known_data_session_type_dict['bapun'])\n",
    "active_session_computation_configs = _build_active_computation_configs(curr_bapun_pipeline.sess)\n",
    "# active_session_computation_config.grid_bin = compute_position_grid_bin_size(curr_bapun_pipeline.sess.position.x, curr_bapun_pipeline.sess.position.y, num_bins=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e0cc6c-4c19-4670-b685-bba16553e82c",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bapun/DataFrame style session filter functions:\n",
    "def build_bapun_any_epochs_filters(sess):\n",
    "    return build_custom_epochs_filters(sess)\n",
    "    \n",
    "def build_bapun_any_maze_epochs_filters(sess):\n",
    "    # all_filters = build_custom_epochs_filters(sess)\n",
    "    # # print(f'all_filters: {all_filters}')\n",
    "    # maze_only_filters = dict()\n",
    "    # for (name, filter_fcn) in all_filters.items():\n",
    "    #     if 'maze' in name:\n",
    "    #         maze_only_filters[name] = filter_fcn\n",
    "    # maze_only_filters = build_custom_epochs_filters(sess, included_epoch_labels=['maze1','maze2'])\n",
    "    # { key:value for (key,value) in dictOfNames.items() if key % 2 == 0}\n",
    "    # dict(filter(lambda elem: len(elem[1]) == 6,dictOfNames.items()))\n",
    "    # maze_only_name_filter_fn = lambda dict: dict(filter(lambda elem: 'maze' in elem[0], dict.items()))\n",
    "    maze_only_name_filter_fn = lambda names: list(filter(lambda elem: elem.startswith('maze'), names))\n",
    "    # print(f'callable(maze_only_name_filter_fn): {callable(maze_only_name_filter_fn)}')\n",
    "    # print(maze_only_name_filter_fn(['pre', 'maze1', 'post1', 'maze2', 'post2']))\n",
    "    # lambda elem: elem[0] % 2 == 0\n",
    "    maze_only_filters = build_custom_epochs_filters(sess, included_epoch_labels=maze_only_name_filter_fn)\n",
    "    # print(f'maze_only_filters: {maze_only_filters}')\n",
    "    return maze_only_filters\n",
    "\n",
    "# active_session_filter_configurations = build_bapun_any_epochs_filters(curr_bapun_pipeline.sess)\n",
    "active_session_filter_configurations = build_bapun_any_maze_epochs_filters(curr_bapun_pipeline.sess)\n",
    "# print(f'active_session_filter_configurations: {active_session_filter_configurations}')\n",
    "curr_bapun_pipeline.filter_sessions(active_session_filter_configurations)\n",
    "for i in np.arange(len(active_session_computation_configs)):\n",
    "    active_session_computation_configs[i].computation_epochs = None  # set the placefield computation epochs to None, using all epochs.\n",
    "curr_bapun_pipeline.perform_computations(active_session_computation_configs[0])\n",
    "curr_bapun_pipeline.prepare_for_display() # TODO: pass a display config\n",
    "# Set curr_active_pipeline for testing:\n",
    "curr_active_pipeline = curr_bapun_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4940269-23e4-46dc-a4ae-61d512ac5e41",
   "metadata": {
    "tags": []
   },
   "source": [
    "## KDiba Format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "506398f3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir is already Path object.\n",
      "\t basepath: R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\n",
      "\t session_name: 2006-6-07_11-26-53\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.epochs_info.mat... done.\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position_info.mat... done.\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Computing linear positions for all active epochs for session... Saving updated position results results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position.npy... 2006-6-07_11-26-53.position.npy saved\n",
      "done.\n",
      "\t Failure loading .interpolated_spike_positions.npy. Must recompute.\n",
      "\n",
      "\t Saving updated interpolated spike position results results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.interpolated_spike_positions.npy... 2006-6-07_11-26-53.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading success: .ripple.npy.\n",
      "Loading success: .mua.npy.\n",
      "Loading success: .pbe.npy.\n",
      "Computing added spike scISI column results to filepath?... done.\n",
      "desc_crossings_x: (24,), asc_crossings_x: (24,)\n"
     ]
    }
   ],
   "source": [
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "# R:\\data\\KDIBA\\gor01\\one\\IIDataMat_Export_ToPython_2021_11_23.m\n",
    "# From pre-computed .mat files:\n",
    "## 07: \n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53'\n",
    "# # ## 08:\n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15'\n",
    "# curr_kdiba_pipeline = NeuropyPipeline(name='kdiba_pipeline', session_data_type='kdiba', basedir=known_data_session_type_dict['kdiba'].basedir, load_function=known_data_session_type_dict['kdiba'].load_function)\n",
    "curr_kdiba_pipeline = NeuropyPipeline.init_from_known_data_session_type('kdiba', known_data_session_type_dict['kdiba'])\n",
    "# active_grid_bin = compute_position_grid_bin_size(curr_kdiba_pipeline.sess.position.x, curr_kdiba_pipeline.sess.position.y, num_bins=(64, 64))\n",
    "# active_session_computation_config.grid_bin = active_grid_bin\n",
    "active_session_computation_configs = _build_active_computation_configs(curr_kdiba_pipeline.sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f03a92-1685-41a6-b10c-88ea7dc55ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_any_maze_epochs_filters(sess):\n",
    "    sess.epochs.t_start = 22.26 # exclude the first short period where the animal isn't on the maze yet\n",
    "    active_session_filter_configurations = {'maze1': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')) } # just maze 1\n",
    "    # active_session_filter_configurations = {'maze1': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')),\n",
    "    #                                     'maze2': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze2')), x.epochs.get_named_timerange('maze2')),\n",
    "    #                                     'maze': lambda x: (x.filtered_by_epoch(NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]])), NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]]))\n",
    "    #                                    }\n",
    "    return active_session_filter_configurations\n",
    "\n",
    "active_session_filter_configurations = build_any_maze_epochs_filters(curr_kdiba_pipeline.sess)\n",
    "curr_kdiba_pipeline.filter_sessions(active_session_filter_configurations)\n",
    "for i in np.arange(len(active_session_computation_configs)):\n",
    "    active_session_computation_configs[i].computation_epochs = None # add the laps epochs to all of the computation configs.\n",
    "\n",
    "curr_kdiba_pipeline.perform_computations(active_session_computation_configs[0])\n",
    "curr_kdiba_pipeline.prepare_for_display() # TODO: pass a display config\n",
    "# set curr_active_pipeline for testing:\n",
    "curr_active_pipeline = curr_kdiba_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee23920e-5d46-4258-8a99-bb40056913f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['lap_id']] = laps_df[['lap_id']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['start_spike_index', 'end_spike_index']] = laps_df[['start_spike_index', 'end_spike_index']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['num_spikes'] = laps_df['end_spike_index'] - laps_df['start_spike_index']\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['lap_dir'] = laps_df['lap_dir'].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['label'] = laps_df['lap_id'].astype('str') # add the string \"label\" column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze1\"...\n",
      "Constraining to units with type: pyramidal\n",
      "Constraining to epoch with times (start: 22.26, end: 1739.1533641185379)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['lap_id']] = laps_df[['lap_id']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['start_spike_index', 'end_spike_index']] = laps_df[['start_spike_index', 'end_spike_index']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['num_spikes'] = laps_df['end_spike_index'] - laps_df['start_spike_index']\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['lap_dir'] = laps_df['lap_dir'].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['label'] = laps_df['lap_id'].astype('str') # add the string \"label\" column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze2\"...\n",
      "Constraining to units with type: pyramidal\n",
      "Constraining to epoch with times (start: 1739.1533641185379, end: 1932.4200048116618)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['lap_id']] = laps_df[['lap_id']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['start_spike_index', 'end_spike_index']] = laps_df[['start_spike_index', 'end_spike_index']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['num_spikes'] = laps_df['end_spike_index'] - laps_df['start_spike_index']\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['lap_dir'] = laps_df['lap_dir'].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['label'] = laps_df['lap_id'].astype('str') # add the string \"label\" column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze\"...\n",
      "Constraining to units with type: pyramidal\n",
      "Constraining to epoch with times (start: 22.26, end: 1932.4200048116618)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['lap_id']] = laps_df[['lap_id']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['start_spike_index', 'end_spike_index']] = laps_df[['start_spike_index', 'end_spike_index']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['num_spikes'] = laps_df['end_spike_index'] - laps_df['start_spike_index']\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['lap_dir'] = laps_df['lap_dir'].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['label'] = laps_df['lap_id'].astype('str') # add the string \"label\" column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing single_computation on filtered_session with filter named \"maze1\"...\n",
      "Recomputing active_epoch_placefields... pre speed filtering: 20202 spikes.\n",
      "post speed filtering: 13268 spikes.\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... pre speed filtering: 20202 spikes.\n",
      "post speed filtering: 13529 spikes.\n",
      "\t done.\n",
      "Performing perform_registered_computations(...) with 5 registered_computation_functions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:217: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing single_computation on filtered_session with filter named \"maze2\"...\n",
      "Recomputing active_epoch_placefields... pre speed filtering: 545 spikes.\n",
      "post speed filtering: 314 spikes.\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... pre speed filtering: 545 spikes.\n",
      "post speed filtering: 329 spikes.\n",
      "\t done.\n",
      "Performing perform_registered_computations(...) with 5 registered_computation_functions...\n",
      "Performing single_computation on filtered_session with filter named \"maze\"...\n",
      "Recomputing active_epoch_placefields... pre speed filtering: 20747 spikes.\n",
      "post speed filtering: 13582 spikes.\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... pre speed filtering: 20747 spikes.\n",
      "post speed filtering: 13858 spikes.\n",
      "\t done.\n",
      "Performing perform_registered_computations(...) with 5 registered_computation_functions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:177: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  C_tau_n = 1.0 / np.sum(un_normalized_result) # normalize the result\n",
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:178: RuntimeWarning: invalid value encountered in multiply\n",
      "  result = C_tau_n * un_normalized_result\n",
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:217: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return C * np.exp(numerator/denominator)\n",
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:217: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return C * np.exp(numerator/denominator)\n"
     ]
    }
   ],
   "source": [
    "def build_pyramidal_epochs_filters(sess):\n",
    "    sess.epochs.t_start = 22.26 # exclude the first short period where the animal isn't on the maze yet\n",
    "    active_session_filter_configurations = {'maze1': lambda x: (x.filtered_by_neuron_type('pyramidal').filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')),\n",
    "                                        'maze2': lambda x: (x.filtered_by_neuron_type('pyramidal').filtered_by_epoch(x.epochs.get_named_timerange('maze2')), x.epochs.get_named_timerange('maze2')),\n",
    "                                        'maze': lambda x: (x.filtered_by_neuron_type('pyramidal').filtered_by_epoch(NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]])), NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]]))\n",
    "                                       }\n",
    "    return active_session_filter_configurations\n",
    "\n",
    "active_session_filter_configurations = build_pyramidal_epochs_filters(curr_kdiba_pipeline.sess)\n",
    "\n",
    "\n",
    "is_non_overlapping_lap = get_non_overlapping_epochs(curr_kdiba_pipeline.sess.laps.to_dataframe()[['start','stop']].to_numpy())\n",
    "only_good_laps_df = curr_kdiba_pipeline.sess.laps.to_dataframe()[is_non_overlapping_lap]\n",
    "curr_kdiba_pipeline.sess.laps = Laps(only_good_laps_df) # replace the laps object with the filtered one\n",
    "\n",
    "\n",
    "lap_specific_epochs = curr_kdiba_pipeline.sess.laps.as_epoch_obj()\n",
    "any_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(len(curr_kdiba_pipeline.sess.laps.lap_id))])\n",
    "even_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(0, len(curr_kdiba_pipeline.sess.laps.lap_id), 2)])\n",
    "odd_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(1, len(curr_kdiba_pipeline.sess.laps.lap_id), 2)])\n",
    "\n",
    "\n",
    "# Copy the active session_computation_config:\n",
    "for i in np.arange(len(active_session_computation_configs)):\n",
    "    active_session_computation_configs[i].computation_epochs = any_lap_specific_epochs # add the laps epochs to all of the computation configs.\n",
    "\n",
    "curr_kdiba_pipeline.filter_sessions(active_session_filter_configurations)\n",
    "curr_kdiba_pipeline.perform_computations(active_session_computation_configs[0]) # Causes \"IndexError: index 59 is out of bounds for axis 0 with size 59\"\n",
    "curr_kdiba_pipeline.prepare_for_display() # TODO: pass a display config\n",
    "# set curr_active_pipeline for testing:\n",
    "curr_active_pipeline = curr_kdiba_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3136f4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Common: Optional Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5180c-facf-4882-944d-53d420313673",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_epoch_labels = list(curr_active_pipeline.sess.epochs.labels) # ['pre', 'maze1', 'post1', 'maze2', 'post2']\n",
    "curr_named_timeranges = [curr_active_pipeline.sess.epochs.get_named_timerange(a_label) for a_label in curr_epoch_labels]\n",
    "\n",
    "curr_named_timeranges\n",
    "\n",
    "all_filters_list = list(curr_active_pipeline.filtered_sessions.keys())\n",
    "all_filters_list\n",
    "\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# from pyphocorehelpers.print_helpers import debug_dump_object_member_shapes\n",
    "\n",
    "# curr_active_pipeline\n",
    "# debug_dump_object_member_shapes(curr_active_pipeline)\n",
    "# curr_active_pipeline.__dict__\n",
    "# debug_dump_object_member_shapes(curr_active_pipeline.computation_results)\n",
    "\n",
    "# curr_active_pipeline.filtered_sessions\n",
    "# curr_active_pipeline.computation_results\n",
    "\n",
    "# debug_dump_object_member_shapes(active_session_computation_configs.st)\n",
    "# curr_active_pipeline.computation_results.to_pickle('R:\\completed_pipeline.pkl', protocol=5)\n",
    "\n",
    "# pickle.dump(curr_active_pipeline.computation_results, open(\"R:\\completed_pipeline.pkl\", 'wb'), protocol=5)\n",
    "\n",
    "# pickle.dump(curr_active_pipeline.filtered_sessions, open(\"R:\\completed_pipeline_kdiba_sessions.pkl\", 'wb'), protocol=5)\n",
    "# pickle.dump(curr_active_pipeline.computation_results, open(\"R:\\completed_pipeline_kdiba.pkl\", 'wb'), protocol=5)\n",
    "\n",
    "# np.savez_compressed('completed_pipeline', curr_active_pipeline)\n",
    "\n",
    "# Saves out ['/spikes_df', '/sess/spikes_df', '/filtered_sessions/maze2/spikes_df', '/filtered_sessions/maze1/spikes_df', '/filtered_sessions/maze/spikes_df'] to a .h5 file which can be loaded with\n",
    "# with pd.HDFStore(finalized_spike_df_cache_file) as store:\n",
    "    # print(store.keys())\n",
    "    # reread = pd.read_hdf(finalized_spike_df_cache_file, key='spikes_df')\n",
    "    # reread\n",
    "\n",
    "\n",
    "finalized_spike_df_cache_file='./pipeline_cache_store.h5'\n",
    "    \n",
    "def save_spikes_data_to_h5(active_pipeline, finalized_spike_df_cache_file='./pipeline_cache_store.h5'):\n",
    "    \"\"\" \n",
    "    # Saves out ['/spikes_df', '/sess/spikes_df', '/filtered_sessions/maze2/spikes_df', '/filtered_sessions/maze1/spikes_df', '/filtered_sessions/maze/spikes_df'] to a .h5 file which can be loaded with\n",
    "    # with pd.HDFStore(finalized_spike_df_cache_file) as store:\n",
    "        # print(store.keys())\n",
    "        # reread = pd.read_hdf(finalized_spike_df_cache_file, key='spikes_df')\n",
    "        # reread\n",
    "    Usage:\n",
    "        save_spikes_data_to_h5(active_pipeline, finalized_spike_df_cache_file='./pipeline_cache_store.h5')\n",
    "    \"\"\"\n",
    "    curr_active_pipeline.sess.spikes_df.to_hdf(finalized_spike_df_cache_file, key='sess/spikes_df')\n",
    "\n",
    "    for (a_key, a_filtered_session) in curr_active_pipeline.filtered_sessions.items():\n",
    "        print(f'a_filtered_session: {a_filtered_session}')\n",
    "        a_filtered_session.spikes_df.to_hdf(finalized_spike_df_cache_file, key=f'filtered_sessions/{a_key}/spikes_df')\n",
    "\n",
    "\n",
    "save_spikes_data_to_h5(curr_active_pipeline, finalized_spike_df_cache_file='./pipeline_cache_store.h5')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d69d7fb-ec6d-4113-9ee8-a9b2c66e12f8",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# reread = pd.read_hdf(finalized_spike_df_cache_file, key='spikes_df')\n",
    "# reread\n",
    "\n",
    "\n",
    "# Load the saved .h5 spikes dataframe for testing:\n",
    "finalized_spike_df_cache_file='./pipeline_cache_store.h5'\n",
    "desired_spikes_df_key = '/filtered_sessions/maze1/spikes_df'\n",
    "spikes_df = pd.read_hdf(finalized_spike_df_cache_file, key=desired_spikes_df_key)\n",
    "spikes_df\n",
    "\n",
    "# with pd.HDFStore(finalized_spike_df_cache_file) as store:\n",
    "#     print(store.keys())\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea5352-ad3b-49fa-a665-85d5a0a17fb9",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze PBEs by looping through the filtered epochs:\n",
    "\n",
    "# curr_kdiba_pipeline.sess.spikes_df.spikes.time_variable_name # 't_rel_seconds' \n",
    "# active_timestamps = curr_kdiba_pipeline.sess.spikes_df[curr_kdiba_pipeline.sess.spikes_df.spikes.time_variable_name].copy().to_numpy() # get the timestamps column using the time_variable_name property. It's 't_rel_seconds' for kdiba-format data for example\n",
    "# active_timestamps\n",
    "\n",
    "curr_kdiba_pipeline.sess.spikes_df[curr_kdiba_pipeline.sess.spikes_df['PBE_id'] > -1]\n",
    "\n",
    "# curr_epoch_duration\n",
    "# determine_event_interval_is_included(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489dd43-ccc5-448f-8fdc-0756b4b7d9b7",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Testing burst detection\n",
    "# curr_active_pipeline.sess.spikes_df.spikes.neuron_ids\n",
    "\n",
    "# grouped = curr_active_pipeline.sess.spikes_df.groupby('aclu')\n",
    "\n",
    "# neuron_split_spike_dfs = [spk_df.groupby('aclu').get_group(neuron_id)[['t','x','y','lin_pos']] for neuron_id in active_epoch_session.neuron_ids] # dataframes split for each ID:\n",
    "# neuron_split_spike_dfs = curr_active_pipeline.sess.spikes_df.spikes.get_split_by_unit()\n",
    "\n",
    "# grouped['t_rel_seconds'].diff()\n",
    "\n",
    "# .diff()\n",
    "curr_active_pipeline.sess.spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ec6b4-ac9c-4543-81f8-21da195ce12a",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from vedo import *\n",
    "from vedo.pyplot import violin\n",
    "\n",
    "## Example Violin plot with 3 generated violins:\n",
    "# n = 1000\n",
    "# acts = [\n",
    "#     Text3D('gaussian', pos=(0,4.5), s=0.3, c='k', justify='center'),\n",
    "#     violin(np.random.randn(n)),\n",
    "\n",
    "#     Text3D('exponential', pos=(5,-1), s=0.3, c='k', justify='center'),\n",
    "#     violin(np.random.exponential(1, n), x=5, width=3, spline=False, centerline=False, c='t', lc='k'),\n",
    "\n",
    "#     Text3D('chisquare', pos=(10,11), s=0.3, c='k', justify='center'),\n",
    "#     violin(np.random.chisquare(9, n)/4, x=10, vlim=(0,10), c='lg', lc='dg'),\n",
    "# ]\n",
    "\n",
    "\n",
    "## Actual violin plot from each cell's spike ISIs:\n",
    "intra_unit_spacing = 5.0\n",
    "\n",
    "acts = []\n",
    "for (i, a_cell_id) in enumerate(curr_active_pipeline.sess.spikes_df.spikes.neuron_ids):\n",
    "        # loop through the cell_ids\n",
    "        curr_unit_x_offset = float(i) * intra_unit_spacing\n",
    "        curr_df = curr_active_pipeline.sess.spikes_df.groupby('aclu').get_group(a_cell_id)\n",
    "        # curr_active_pipeline.sess.spikes_df['scISI']\n",
    "        # ValueError: autodetected range of [nan, nan] is not finite\n",
    "        curr_v_text = Text3D(f'unit[{a_cell_id}]', pos=(curr_unit_x_offset,-1), s=0.3, c='k', justify='center')\n",
    "        acts.append(curr_v_text)\n",
    "        curr_v = violin(curr_df['scISI'].dropna(), x=curr_unit_x_offset)\n",
    "        # curr_v = violin(curr_df['scISI'])\n",
    "        acts.append(curr_v)\n",
    "\n",
    "\n",
    "show(acts, axes=dict(xtitle=False, ytitle='distribution')).close()\n",
    "\n",
    "## TODO: comes see https://github.com/marcomusy/vedo/blob/master/examples/pyplot/whiskers.py to implement a whisker's plot from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58151650-c6e9-4675-a766-bb20d7af7952",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.General.SpikesDataframeWindow import SpikesDataframeWindow, SpikesWindowOwningMixin\n",
    "# from pyphoplacecellanalysis.General.DataSeriesToSpatial import DataSeriesToSpatial\n",
    "# from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Spike3DRaster_Vedo import Spike3DRaster_Vedo\n",
    "\n",
    "# curr_epoch_name = 'maze1'\n",
    "# curr_epoch = curr_active_pipeline.filtered_epochs[curr_epoch_name] # <NamedTimerange: {'name': 'maze1', 'start_end_times': array([  22.26      , 1739.15336412])};>\n",
    "# curr_sess = curr_active_pipeline.filtered_sessions[curr_epoch_name]\n",
    "# curr_spikes_df = curr_sess.spikes_df\n",
    "\n",
    "# # Build the 3D Raster object:\n",
    "# spike_raster_plt = Spike3DRaster_Vedo(curr_spikes_df, window_duration=4.0, window_start_time=30.0, neuron_colors=None)\n",
    "# spike_raster_plt._update_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f391b1a5-0f1a-4a2e-840c-239f00366abf",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "axes = dict(xtitle='window time', ytitle='cell_id', ztitle=\"\")\n",
    "plt = show(spike_raster_plt.glyph, __doc__, axes=axes, interactive=False, bg='k8') # plt: <vedo.plotter.Plotter at 0x22eb25de370>\n",
    "\n",
    "# for i in range(50):\n",
    "#     spike_raster_plt.increase_animation_frame_val() # increment the animation frame value\n",
    "#     spike_raster_plt._update_plots() # since there's currently no internal connection to the window changed signal, manually call _update_plots to update the plots\n",
    "#     plt.render() # call render to display the changes\n",
    "#     if plt.escaped: break # if ESC is hit during the loop\n",
    "    # vd.addFrame()\n",
    "# vd.close()\n",
    "\n",
    "# plt.interactive().close() # apparently called to exit when finished with the animation\n",
    "\n",
    "\n",
    "# spike_raster_plt.n_cells # 40\n",
    "# cell_INDEXES\n",
    "# curr_spikes_df\n",
    "# np.unique(spike_raster_plt.active_windowed_df['unit_id'])\n",
    "# curr_num_dataseries = len(curr_spikes_df.spikes.neuron_ids)\n",
    "# y = build_data_series_range(curr_num_dataseries, center_mode='zero_centered', bin_position_mode='bin_center', side_bin_margins = 1.0)\n",
    "# y\n",
    "\n",
    "\n",
    "\n",
    "# # Get the times of all events/spikes in the current window from the dataframe.\n",
    "# curr_spike_t = curr_cell_df[curr_cell_df.spikes.time_variable_name].to_numpy() # this will map\n",
    "# curr_unit_n_spikes = len(curr_spike_t)\n",
    "\n",
    "# curr_x = np.interp(curr_spike_t, (self.spikes_window.active_window_start_time, self.spikes_window.active_window_end_time), (-self.half_temporal_axis_length, +self.half_temporal_axis_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8440e-ff79-4b3a-a19c-7f7f5752c188",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'spike_raster_plt.spikes_window.active_time_window: {spike_raster_plt.spikes_window.active_time_window}')\n",
    "# spike_raster_plt.spikes_window.active_window_start_time = 50.0\n",
    "spike_raster_plt.spikes_window.update_window_start(120.0)\n",
    "spike_raster_plt._update_plots()\n",
    "plt.render()\n",
    "# if plt.escaped: break # if ESC is hit during the loop\n",
    "print(f'spike_raster_plt.spikes_window.active_time_window: {spike_raster_plt.spikes_window.active_time_window}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f20a159-3434-4dbd-94a8-3d07af9998a1",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# note that this is very slow, but works\n",
    "included_cell_INDEXES = np.array([spike_raster_plt.get_neuron_id_and_idx(neuron_id=an_included_cell_ID)[0] for an_included_cell_ID in spike_raster_plt.spikes_df['aclu'].to_numpy()]) # get the indexes from the cellIDs\n",
    "spike_raster_plt.spikes_df['cell_idx'] = included_cell_INDEXES.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ac7aea-82ad-4250-b401-5f4e94ea66a5",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# spike_raster_plt.spikes_df\n",
    "np.unique(spike_raster_plt.spikes_df['cell_idx']) # array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055eb167-e81c-4b76-af36-4c2649ac0b1e",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = DataSeriesToSpatial.build_series_identity_axis(spike_raster_plt.n_cells, center_mode='zero_centered', bin_position_mode='bin_center', side_bin_margins = spike_raster_plt.params.side_bin_margins)\n",
    "# Compute the y for all windows, not just the current one:\n",
    "all_y = [y[a_cell_id] for a_cell_id in spike_raster_plt.spikes_df['cell_idx'].to_numpy()]\n",
    "spike_raster_plt.spikes_df['visualization_raster_y_location'] = all_y # adds as a column to the dataframe. Only needs to be updated when the number of active units changes\n",
    "spike_raster_plt.spikes_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa57540-9a1d-494f-9515-0cefb10c5cdf",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ## Vedo-based Spike3D\n",
    "# ## UNFINISHED\n",
    "\n",
    "# from vedo import Cone, Glyph, show\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# const_z = 0.0\n",
    "# curr_x = np.interp(spike_raster_plt.active_windowed_df[spike_raster_plt.active_windowed_df.spikes.time_variable_name].to_numpy(), (spike_raster_plt.spikes_window.active_window_start_time, spike_raster_plt.spikes_window.active_window_end_time), (-spike_raster_plt.half_temporal_axis_length, +spike_raster_plt.half_temporal_axis_length))\n",
    "# pts = np.c_[curr_x, spike_raster_plt.active_windowed_df['visualization_raster_y_location'].to_numpy(), np.full_like(curr_x, const_z)]\n",
    "# # vecs= np.c_[df['u'], df['v'],df['w']]\n",
    "\n",
    "\n",
    "# # pts = np.c_[df['x'], df['y'], df['z']]\n",
    "# # vecs= np.c_[df['u'], df['v'],df['w']]\n",
    "\n",
    "# # Create a mesh to be used like a symbol (a \"glyph\") to be attached to each point\n",
    "# cone = Cone().scale(0.3) # make it smaller and orient tip to positive x\n",
    "# # .rotateY(90) # orient tip to positive x\n",
    "# glyph = Glyph(pts, cone)\n",
    "# # glyph = Glyph(pts, cone, vecs, scaleByVectorSize=True, colorByVectorSize=True)\n",
    "\n",
    "# glyph.lighting('ambient').cmap('Blues').addScalarBar(title='wind speed')\n",
    "\n",
    "# show(glyph, __doc__, axes=True).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f6bd4-bc92-4f9c-86f8-6237b6d68118",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import print_dataframe_memory_usage\n",
    "\n",
    "print_dataframe_memory_usage(curr_active_pipeline.sess.spikes_df)\n",
    "# curr_active_pipeline.sess.spikes_df.dtypes\n",
    "# each_columns_usage_bytes = curr_active_pipeline.sess.spikes_df.memory_usage(deep=True)  # memory usage in bytes\n",
    "# # each_columns_usage.index\n",
    "\n",
    "# # each_columns_usage.add_suffix('bytes')\n",
    "# # each_columns_usage.nbytes\n",
    "\n",
    "# each_columns_usage_MB = each_columns_usage_bytes.apply(lambda x: x/(1024*1024))\n",
    "# each_columns_usage_MB\n",
    "\n",
    "# each_columns_usage_MB_string = each_columns_usage_MB.apply(lambda x: f'{x:.2f} MB') # Round to 2 decimal places (the nearest 0.01 MB)\n",
    "# print(f'{each_columns_usage_MB_string}')\n",
    "\n",
    "\n",
    "# total_df_usage_MB = each_columns_usage_MB.sum()\n",
    "# total_df_usage_MB_string = f'{total_df_usage_MB:.3f} MB' # round the total to 3 decimal places.\n",
    "# total_df_usage_MB_string\n",
    "\n",
    "# size_MB = each_columns_usage_bytes.values/(1024*1024)\n",
    "# object_size_string_MB = f'{size_MB} MB'\n",
    "# object_size_string_MB  \n",
    "\n",
    "# def debug_print_dataframe_memory_usage(df):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc333190-9c70-4780-acad-73da1f3f5fe6",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# out_figs = curr_active_pipeline.sess.spikes_df.plot.hist(by='aclu', column='scISI', bins=12, sharex=True, alpha=0.5, figsize=(40, 120))\n",
    "# out_figs = curr_active_pipeline.sess.spikes_df.plot.hist(by='aclu', column='scISI', bins=12, alpha=0.5, figsize=(40, 120))\n",
    "# out_figs = curr_active_pipeline.sess.spikes_df.plot.hist(column='scISI', bins=12, alpha=0.5, figsize=(40, 120))\n",
    "# out_figs = curr_active_pipeline.sess.spikes_df.plot.box(column=['scISI'], by='aclu', figsize=(40, 120)) # boxplots side-by-side\n",
    "\n",
    "# out_figs = curr_active_pipeline.sess.spikes_df.plot.kde(column=['scISI'], by='aclu', figsize=(40, 120)) # Not working\n",
    "out_figs = curr_active_pipeline.sess.spikes_df.plot(column=['scISI'], by='aclu', figsize=(40, 120)) # boxplots side-by-side\n",
    "# .plot(xlabel=\"new x\", ylabel=\"new y\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b44895",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_pbes</th>\n",
       "      <th>mean_pbe_durations</th>\n",
       "      <th>cummulative_pbe_durations</th>\n",
       "      <th>epoch_total_duration</th>\n",
       "      <th>pbe_occurance_rate</th>\n",
       "      <th>pbe_percent_duration</th>\n",
       "      <th>mean_num_pbe_spikes</th>\n",
       "      <th>stddev_num_pbe_spikes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maze1</th>\n",
       "      <td>206</td>\n",
       "      <td>0.220995</td>\n",
       "      <td>45.525</td>\n",
       "      <td>1716.893364</td>\n",
       "      <td>8.334434</td>\n",
       "      <td>37.713199</td>\n",
       "      <td>30.611650</td>\n",
       "      <td>12.159325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maze2</th>\n",
       "      <td>31</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>7.409</td>\n",
       "      <td>193.266641</td>\n",
       "      <td>6.234408</td>\n",
       "      <td>26.085388</td>\n",
       "      <td>38.322581</td>\n",
       "      <td>15.740613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maze</th>\n",
       "      <td>237</td>\n",
       "      <td>0.223350</td>\n",
       "      <td>52.934</td>\n",
       "      <td>1910.160005</td>\n",
       "      <td>8.059747</td>\n",
       "      <td>36.085692</td>\n",
       "      <td>31.620253</td>\n",
       "      <td>12.949076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_pbes  mean_pbe_durations  cummulative_pbe_durations  \\\n",
       "maze1     206            0.220995                     45.525   \n",
       "maze2      31            0.239000                      7.409   \n",
       "maze      237            0.223350                     52.934   \n",
       "\n",
       "       epoch_total_duration  pbe_occurance_rate  pbe_percent_duration  \\\n",
       "maze1           1716.893364            8.334434             37.713199   \n",
       "maze2            193.266641            6.234408             26.085388   \n",
       "maze            1910.160005            8.059747             36.085692   \n",
       "\n",
       "       mean_num_pbe_spikes  stddev_num_pbe_spikes  \n",
       "maze1            30.611650              12.159325  \n",
       "maze2            38.322581              15.740613  \n",
       "maze             31.620253              12.949076  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Works, but need to convert into the computation function format or find a new place to put it. It operates on the entire pipeline while currently computation functions are limited to operating on one stage at a time.\n",
    "def _perform_PBE_stats(active_pipeline, debug_print = False):\n",
    "    \"\"\" # Analyze PBEs by looping through the filtered epochs:\n",
    "        This whole implementation seems silly and inefficient        \n",
    "        Can't I use .agg(['count', 'mean']) or something? \n",
    "    \"\"\"\n",
    "    all_epochs_labels = []\n",
    "    all_epochs_total_durations = []\n",
    "    all_epochs_n_pbes = []\n",
    "    all_epochs_pbe_duration_lists = []\n",
    "    all_epochs_cummulative_pbe_durations = []\n",
    "    all_epochs_mean_pbe_durations = []\n",
    "    all_epochs_full_pbe_spiketrain_lists = []\n",
    "    all_epochs_pbe_num_spikes_lists = []\n",
    "    all_epochs_intra_pbe_interval_lists = []\n",
    "    \n",
    "    for (name, filtered_sess) in active_pipeline.filtered_sessions.items():\n",
    "        # interested in analyzing both the filtered_sess.pbe and the filtered_sess.spikes_df (as they relate to the PBEs)\n",
    "        all_epochs_labels.append(name)\n",
    "        curr_named_time_range = active_pipeline.sess.epochs.get_named_timerange(name) # for 'maze' key, the total duration is being set to array([], dtype=float64) for some reason. all_epochs_total_durations: [1716.8933641185379, 193.26664069312392, array([], dtype=float64)]\n",
    "        \n",
    "        if not np.isscalar(curr_named_time_range.duration):\n",
    "            # for 'maze' key, the total duration is being set to array([], dtype=float64) for some reason. all_epochs_total_durations: [1716.8933641185379, 193.26664069312392, array([], dtype=float64)]\n",
    "            curr_named_time_range = NamedTimerange(name='maze', start_end_times=[active_pipeline.sess.epochs['maze1'][0], active_pipeline.sess.epochs['maze2'][1]])\n",
    "        \n",
    "        curr_epoch_duration = curr_named_time_range.duration\n",
    "        all_epochs_total_durations.append(curr_epoch_duration) # TODO: this should be in seconds (or at least the same units as the PBE durations)... actually this might be right.\n",
    "        # Computes the intervals between each PBE:\n",
    "        curr_intra_pbe_intervals = filtered_sess.pbe.starts[1:] - filtered_sess.pbe.stops[:-1]\n",
    "        all_epochs_intra_pbe_interval_lists.append(curr_intra_pbe_intervals)\n",
    "        all_epochs_n_pbes.append(filtered_sess.pbe.n_epochs)\n",
    "        all_epochs_pbe_duration_lists.append(filtered_sess.pbe.durations)\n",
    "        all_epochs_cummulative_pbe_durations.append(np.sum(filtered_sess.pbe.durations))\n",
    "        all_epochs_mean_pbe_durations.append(np.nanmean(filtered_sess.pbe.durations))\n",
    "        # filtered_sess.spikes_df.PBE_id\n",
    "        curr_pbe_only_spikes_df = filtered_sess.spikes_df[filtered_sess.spikes_df.PBE_id > -1].copy()\n",
    "        unique_PBE_ids = np.unique(curr_pbe_only_spikes_df['PBE_id'])\n",
    "        flat_PBE_ids = [int(id) for id in unique_PBE_ids]\n",
    "        num_unique_PBE_ids = len(flat_PBE_ids)\n",
    "        # groups the spikes_df by PBEs:\n",
    "        curr_pbe_grouped_spikes_df = curr_pbe_only_spikes_df.groupby(['PBE_id'])\n",
    "        curr_spiketrains = list()\n",
    "        curr_PBE_spiketrain_num_spikes = list()\n",
    "        for i in np.arange(num_unique_PBE_ids):\n",
    "            curr_PBE_id = flat_PBE_ids[i] # actual cell ID\n",
    "            #curr_flat_cell_indicies = (flat_spikes_out_dict['aclu'] == curr_cell_id) # the indicies where the cell_id matches the current one\n",
    "            curr_PBE_dataframe = curr_pbe_grouped_spikes_df.get_group(curr_PBE_id)\n",
    "            curr_PBE_num_spikes = np.shape(curr_PBE_dataframe)[0] # the number of spikes in this PBE\n",
    "            curr_PBE_spiketrain_num_spikes.append(curr_PBE_num_spikes)\n",
    "            curr_spiketrains.append(curr_PBE_dataframe['t'].to_numpy())\n",
    "\n",
    "        curr_PBE_spiketrain_num_spikes = np.array(curr_PBE_spiketrain_num_spikes)\n",
    "        all_epochs_pbe_num_spikes_lists.append(curr_PBE_spiketrain_num_spikes)\n",
    "        curr_spiketrains = np.array(curr_spiketrains, dtype='object')\n",
    "        all_epochs_full_pbe_spiketrain_lists.append(curr_spiketrains)\n",
    "        if debug_print:\n",
    "            print(f'name: {name}, filtered_sess.pbe: {filtered_sess.pbe}')\n",
    "\n",
    "    if debug_print:\n",
    "        print(f'all_epochs_n_pbes: {all_epochs_n_pbes}, all_epochs_mean_pbe_durations: {all_epochs_mean_pbe_durations}, all_epochs_cummulative_pbe_durations: {all_epochs_cummulative_pbe_durations}, all_epochs_total_durations: {all_epochs_total_durations}')\n",
    "        # all_epochs_n_pbes: [3152, 561, 1847, 832, 4566], all_epochs_mean_pbe_durations: [0.19560881979695527, 0.22129233511594312, 0.19185056848946497, 0.2333112980769119, 0.1987152869032212]\n",
    "\n",
    "    all_epochs_pbe_occurance_rate = [(float(all_epochs_total_durations[i]) / float(all_epochs_n_pbes[i])) for i in np.arange(len(all_epochs_n_pbes))]\n",
    "    all_epochs_pbe_percent_duration = [(float(all_epochs_total_durations[i]) / float(all_epochs_cummulative_pbe_durations[i])) for i in np.arange(len(all_epochs_n_pbes))]    \n",
    "    all_epoch_mean_num_pbe_spikes = [np.nanmean(pbe_spike_counts) for pbe_spike_counts in all_epochs_pbe_num_spikes_lists] # [3151, 561, 1847, 831, 4563]\n",
    "    all_epoch_std_num_pbe_spikes = [np.nanstd(pbe_spike_counts) for pbe_spike_counts in all_epochs_pbe_num_spikes_lists] # [11.638970035733648, 15.013817202645336, 15.5123897729991, 15.113395025612247, 11.473087401691878]\n",
    "    # [20.429704855601397, 27.338680926916222, 23.748781808337846, 25.673886883273166, 20.38614946307254]\n",
    "    # Build the final output result dataframe:\n",
    "    pbe_analyses_result_df = pd.DataFrame({'n_pbes':all_epochs_n_pbes, 'mean_pbe_durations': all_epochs_mean_pbe_durations, 'cummulative_pbe_durations':all_epochs_cummulative_pbe_durations, 'epoch_total_duration':all_epochs_total_durations,\n",
    "                'pbe_occurance_rate':all_epochs_pbe_occurance_rate, 'pbe_percent_duration':all_epochs_pbe_percent_duration,\n",
    "                'mean_num_pbe_spikes':all_epoch_mean_num_pbe_spikes, 'stddev_num_pbe_spikes':all_epoch_std_num_pbe_spikes}, index=all_epochs_labels)\n",
    "    # temporary: this isn't how the returns work for other computation functions:\n",
    "    all_epochs_info = [all_epochs_full_pbe_spiketrain_lists, all_epochs_pbe_num_spikes_lists, all_epochs_intra_pbe_interval_lists] # list version\n",
    "    # all_epochs_info = {'all_epochs_full_pbe_spiketrain_lists':all_epochs_full_pbe_spiketrain_lists, 'all_epochs_pbe_num_spikes_lists':all_epochs_pbe_num_spikes_lists, 'all_epochs_intra_pbe_interval_lists':all_epochs_intra_pbe_interval_lists} # dict version\n",
    "    return pbe_analyses_result_df, all_epochs_info\n",
    "\n",
    "pbe_analyses_result_df, [all_epochs_full_pbe_spiketrain_lists, all_epochs_pbe_num_spikes_lists, all_epochs_intra_pbe_interval_lists] = _perform_PBE_stats(curr_active_pipeline, debug_print=False) # all_epochs_n_pbes: [206, 31, 237], all_epochs_mean_pbe_durations: [0.2209951456310722, 0.23900000000001073, 0.22335021097046923], all_epochs_cummulative_pbe_durations: [45.52500000000087, 7.409000000000333, 52.934000000001205], all_epochs_total_durations: [1716.8933641185379, 193.26664069312392, 1910.1600048116618]\n",
    "\n",
    "pbe_analyses_result_df\n",
    "# pbe_analyses_result_df.to_clipboard(sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee40f53-70cd-4b54-8fa1-71117a9a200c",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_SimplePlot import plot_simple_graph\n",
    "\n",
    "[p1], win, app = plot_simple_graph(all_epochs_intra_pbe_interval_lists[0])\n",
    "\n",
    "for (idx, named_range) in enumerate(curr_named_timeranges):\n",
    "    # interested in analyzing both the filtered_sess.pbe and the filtered_sess.spikes_df (as they relate to the PBEs)\n",
    "    p1.plot(all_epochs_intra_pbe_interval_lists[idx] + (300 * idx), pen=(255,0,0), name=named_range.name)\n",
    "\n",
    "# p1.plot(np.random.normal(size=100), pen=(255,0,0), name=\"Red curve\")\n",
    "# p1.plot(np.random.normal(size=110)+5, pen=(0,255,0), name=\"Green curve\")\n",
    "# p1.plot(np.random.normal(size=120)+10, pen=(0,0,255), name=\"Blue curve\")\n",
    "\n",
    "# def plot_simple_graph(y=np.random.normal(size=100))\n",
    "#     app = pg.mkQApp(\"Plotting Example\")\n",
    "#     #mw = QtGui.QMainWindow()\n",
    "#     #mw.resize(800,800)\n",
    "#     \n",
    "#     win = pg.GraphicsLayoutWidget(show=True, title=\"Basic plotting examples\")\n",
    "#     win.resize(1000,600)\n",
    "#     win.setWindowTitle('pyqtgraph example: Plotting')\n",
    "#     \n",
    "#     # Enable antialiasing for prettier plots\n",
    "#     pg.setConfigOptions(antialias=True)\n",
    "#     \n",
    "#     p1 = win.addPlot(title=\"Basic array plotting\", y=y)\n",
    "#     \n",
    "#     return app, win, [p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9795cd4-6968-4458-9442-3e38701ad1e8",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Find all spikes that occur during both a PBE & a lap on the track:\n",
    "\n",
    "# curr_active_pipeline.sess.spikes_df[(curr_active_pipeline.sess.spikes_df['PBE_id'] > -1)] # & (curr_active_pipeline.sess.spikes_df['lap'] != -1)\n",
    "during_lap_and_PBE_spikes_df = curr_active_pipeline.sess.spikes_df[(curr_active_pipeline.sess.spikes_df['PBE_id'] > -1) & (curr_active_pipeline.sess.spikes_df['lap'] != -1)]\n",
    "# curr_active_pipeline.sess.spikes_df[(curr_active_pipeline.sess.spikes_df['lap'] > -1)]\n",
    "during_lap_and_PBE_spikes_df\n",
    "\n",
    "# updated_spikes_df = curr_active_pipeline.sess.compute_PBEs_spikes_df(curr_active_pipeline.sess.spikes_df, curr_active_pipeline.sess.pbe.to_dataframe())\n",
    "# updated_spikes_df[(updated_spikes_df['PBE_id'] > -1)]\n",
    "# curr_active_pipeline.sess.spikes_df[(curr_active_pipeline.sess.spikes_df['PBE_id'] > -1)]\n",
    "# curr_active_pipeline.sess.spikes_df\n",
    "\n",
    "# group by Team, get mean, min, and max value of Age for each value of Team.\n",
    "grouped_single = during_lap_and_PBE_spikes_df.groupby('lap').agg({'PBE_id': ['mean', 'min', 'max']})\n",
    "grouped_single = grouped_single.reset_index()\n",
    "print(grouped_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f267090-739d-45ec-a414-bc93b289e358",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## 2D Spike Train Visualization\n",
    "# import pyqtgraph.opengl as gl # for 3D raster plot\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterBase import SpikeRasterBase\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Spike3DRaster import Spike3DRaster\n",
    "\n",
    "curr_epoch_name = 'maze1'\n",
    "curr_epoch = curr_active_pipeline.filtered_epochs[curr_epoch_name] # <NamedTimerange: {'name': 'maze1', 'start_end_times': array([  22.26      , 1739.15336412])};>\n",
    "curr_sess = curr_active_pipeline.filtered_sessions[curr_epoch_name]\n",
    "curr_spikes_df = curr_sess.spikes_df\n",
    "\n",
    "# spike_raster_plt_2d = Spike2DRaster(curr_spikes_df, window_duration=15.0 * 60.0, window_start_time=30.0, neuron_colors=None)\n",
    "spike_raster_plt_3d = Spike3DRaster(curr_spikes_df, window_duration=1.0, window_start_time=30.0, neuron_colors=None)\n",
    "# spike_raster_plt = Spike2DRaster(curr_spikes_df, window_duration=1.0, window_start_time=30.0, neuron_colors=None)\n",
    "\n",
    "# spike_raster_plt.animation()\n",
    "# spike_raster_plt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "676686b8-d075-43da-8067-464cd9786de9",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spike_raster_plt_2d = Spike2DRaster(curr_spikes_df, window_duration=1.0, window_start_time=30.0, neuron_colors=None)\n",
    "# Connect the 2D window scrolled signal to the 3D plot's spikes_window.update_window_start_end function\n",
    "spike_3d_to_2d_window_connection = spike_raster_plt_2d.window_scrolled.connect(spike_raster_plt_3d.spikes_window.update_window_start_end)\n",
    "spike_raster_plt_3d.disable_render_window_controls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5428fbf5-7822-4cb0-8030-f5a6ec053ca6",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disable_render_window_controls(): called but do not seem to have RenderWindowControls enabled: err: {e}\n"
     ]
    }
   ],
   "source": [
    "## You can align the two separate windows (for the 3D Raster Plot and the 2D Raster plot that controls it) using code similar to below:\n",
    "\n",
    "# # to put it into the upper left corner for example:\n",
    "# mngr.window.setGeometry(50,100,640, 545)\n",
    "# # If one doesn't know the x- and y-width one can read them out first, like so:\n",
    "# # get the QTCore PyRect object\n",
    "# geom = mngr.window.geometry()\n",
    "# x,y,dx,dy = geom.getRect()\n",
    "# # and then set the new position with the same size:\n",
    "# mngr.window.setGeometry(newX, newY, dx, dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1242cca9-49cb-47f6-af0a-a27e69f7a91b",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# spike_raster_plt.ui.main_plot_widget.setXRange(0.0, +spike_raster_plt.render_window_duration)\n",
    "\n",
    "# spike_raster_plt.ui.scatter_plot.enableAutoRange('xy', False)  ## stop auto-scaling after the first data set is plotted\n",
    "# spike_raster_plt.ui.scatter_plot.dataBounds()\n",
    "# spike_raster_plt.ui.scatter_plot.flags()\n",
    "# spike_raster_plt.ui.scatter_plot.setPointsVisible\n",
    "# spike_raster_plt.ui.main_plot_widget.addScrollBarWidget()\n",
    "\n",
    "# print(f'{spike_raster_plt.ui.main_plot_widget.contentsMargins()}')\n",
    "# spike_raster_plt.ui.scatter_plot.points()\n",
    "\n",
    "# spike_raster_plt.ui.main_plot_widget.setXRange\n",
    "# spike_raster_plt.ui.main_plot_widget.setLimits()\n",
    "# spike_raster_plt.ui.main_plot_widget # PlotItem\n",
    "\n",
    "min_x, max_x = spike_raster_plt_2d.ui.scroll_window_region.getRegion() # (59.62061245756003, 76.83228787177144)\n",
    "scroll_window_width = max_x - min_x\n",
    "spike_raster_plt_2d_old_time_window = spike_raster_plt_2d.spikes_window.active_time_window # (30.0, 930.0)\n",
    "print(f'spike_raster_plt_2d: min_x: {min_x}, max_x: {max_x}, scroll_window_width: {scroll_window_width}, spike_raster_plt_2d_old_time_window: {spike_raster_plt_2d_old_time_window}') # spike_raster_plt_2d: min_x: 111.72696109457753, max_x: 149.92210657285403, scroll_window_width: 38.1951454782765, spike_raster_plt_2d_old_time_window: (111.72696109457753, 149.92210657285403)\n",
    "\n",
    "# def _debug_print_spike_raster_plot_window(\n",
    "spike_raster_plt_3d_old_time_window = spike_raster_plt_3d.spikes_window.active_time_window # (30.0, 930.0)\n",
    "print(f'spike_raster_plt_3d: spike_raster_plt_3d_old_time_window: {spike_raster_plt_3d_old_time_window}') # spike_raster_plt_3d: spike_raster_plt_3d_old_time_window: (47.599999999999625, 62.599999999999625)\n",
    "\n",
    "# Update the 3D Time window from the 2D one:\n",
    "# spike_raster_plt_3d.spikes_window.active_time_window = spike_raster_plt_2d_old_time_window\n",
    "spike_raster_plt_3d.spikes_window.update_window_start_end(spike_raster_plt_2d_old_time_window[0], spike_raster_plt_2d_old_time_window[1])\n",
    "\n",
    "# spike_raster_plt.render_window_duration = \n",
    "# spike_raster_plt.spikes_window\n",
    "# spike_raster_plt.temporal_zoom_factor\n",
    "# # self.spikes_window.update_window_start(next_start_timestamp)\n",
    "\n",
    "# spike_raster_plt.ui.spinTemporalZoomFactor.setValue(1.0)\n",
    "# spike_raster_plt.ui.spinRenderWindowDuration.setValue(scroll_window_width)\n",
    "# spike_raster_plt.spikes_window.update_window_start(min_x)\n",
    "\n",
    "# curr_plot_item = spike_raster_plt.ui.main_plot_widget.getPlotItem()\n",
    "# curr_view_box = curr_plot_item.getViewBox()\n",
    "# # curr_view_box.autoRangeEnabled()\n",
    "# # curr_view_box.setAutoPan(False)\n",
    "\n",
    "# curr_view_box.setDefaultPadding(0.0)\n",
    "# spike_raster_plt.ui.main_plot_widget.viewRect()\n",
    "# spike_raster_plt.ui.scatter_plot.opts\n",
    "# spike_raster_plt._update_plot_ranges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3732bc-45c2-485d-b98d-8b3038ab3360",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# @pyqtSlot(float, float)\n",
    "def _test_on_2d_window_scrolled(start_v, end_v):\n",
    "    print(f'_test_on_2d_window_scrolled(start_v: {start_v}, end_v: {end_v})')\n",
    "    spike_raster_plt_3d.spikes_window.update_window_start_end(start_v, end_v)\n",
    "\n",
    "spike_raster_plt_2d.window_scrolled.connect(_test_on_2d_window_scrolled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af4591b-f462-4255-9309-ca3b6c69e065",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24900b6f-2c69-4f73-9ef7-27d6d8dcafc6",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spike_raster_plt_3d.ui.spinRenderWindowDuration.setValue(scroll_window_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede1f8e-903d-4054-ac26-624ea7355a8c",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spike_raster_plt_3d.ui.spinTemporalZoomFactor.setValue(10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd4b16-630d-4a6b-b254-0f4e06fe9edd",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spike_raster_plt_3d.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c11766-4358-488d-9677-c045a9711bb1",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lower_edge = spike_raster_plt.y / spike_raster_plt.n_cells\n",
    "upper_edge = (spike_raster_plt.y + 1.0)/spike_raster_plt.n_cells\n",
    "\n",
    "print(f'lower_edge: {lower_edge}\\n upper_edge: {upper_edge}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4667a4-f485-417e-b74a-d075ac24c47a",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lower_y = DataSeriesToSpatial.build_series_identity_axis(spike_raster_plt.n_cells, center_mode=spike_raster_plt.params.center_mode, bin_position_mode='left_edges', side_bin_margins = spike_raster_plt.params.side_bin_margins) / spike_raster_plt.n_cells\n",
    "upper_y = DataSeriesToSpatial.build_series_identity_axis(spike_raster_plt.n_cells, center_mode=spike_raster_plt.params.center_mode, bin_position_mode='right_edges', side_bin_margins = spike_raster_plt.params.side_bin_margins) / spike_raster_plt.n_cells\n",
    "\n",
    "print(f'lower_y: {lower_y}\\n upper_y: {upper_y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18877c55-11a6-48ed-96af-52b6d96ae673",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## 3D Spike Train Visualization\n",
    "# import pyqtgraph.opengl as gl # for 3D raster plot\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Spike3DRaster import Spike3DRaster\n",
    "\n",
    "# importlib.reload(pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_RasterPlot)\n",
    "\n",
    "curr_epoch_name = 'maze1'\n",
    "curr_epoch = curr_active_pipeline.filtered_epochs[curr_epoch_name] # <NamedTimerange: {'name': 'maze1', 'start_end_times': array([  22.26      , 1739.15336412])};>\n",
    "curr_sess = curr_active_pipeline.filtered_sessions[curr_epoch_name]\n",
    "curr_spikes_df = curr_sess.spikes_df\n",
    "\n",
    "spike_raster_plt = Spike3DRaster(curr_spikes_df, window_duration=1.0, window_start_time=30.0, neuron_colors=None)\n",
    "# spike_raster_plt = Spike3DRaster(curr_spikes_df, window_duration=4.0, window_start_time=30.0, neuron_colors=None)\n",
    "# spike_raster_plt = Spike3DRaster(curr_spikes_df, window_duration=0.2, window_start_time=30.0)\n",
    "\n",
    "# spike_raster_plt.animation()\n",
    "# spike_raster_plt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a90f5-d145-406c-a97e-e6dd7a0536ac",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'spike_raster_plt.spikes_window.active_time_window: {spike_raster_plt.spikes_window.active_time_window}')\n",
    "# spike_raster_plt.spikes_window.active_window_start_time = 50.0\n",
    "spike_raster_plt.spikes_window.update_window_start(90.0)\n",
    "print(f'spike_raster_plt.spikes_window.active_time_window: {spike_raster_plt.spikes_window.active_time_window}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9312d-1f9d-4201-a987-f4f76712eca5",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spike_raster_plt.animation_time_step # 0.03 (seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d372e540-825e-4331-b191-43ddd41cd6a6",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# spike_raster_plt.render_window_duration # 4.0 (seconds)\n",
    "# spike_raster_plt.spikes_window.window_duration = 1.0\n",
    "\n",
    "spike_raster_plt.temporal_zoom_factor # 40.0\n",
    "spike_raster_plt.temporal_zoom_factor = 80.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225cd3f6-96cd-40df-853d-563c22c15275",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spike_raster_plt.on_adjust_temporal_spatial_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d69e2b-b8c6-47fb-8c18-b6eea8e9fc84",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# curr_transform = spike_raster_plt.ui.gz.transform() # PyQt5.QtGui.QMatrix4x4(1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, -10.0, 0.0, 0.0, 0.0, 1.0)\n",
    "curr_transform = spike_raster_plt.ui.gx.transform() # PyQt5.QtGui.QMatrix4x4(0.0, 0.0, 1.0, -20.0, 0.0, 1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0)\n",
    "print(curr_transform)\n",
    "\n",
    "curr_transform.matrix()\n",
    "# spike_raster_plt.ui.gx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2beb484-0b58-4da9-ae53-27b94d54560b",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spike_raster_plt.params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d278473-b6e9-4962-ba85-192575a5d42c",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# spike_raster_plt.params.spike_start_z # -10\n",
    "spike_raster_plt.params.spike_end_z = -8.0 # -6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d987938-b257-4075-b2fe-33c91dc0f545",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spike_raster_plt.animation_time_step = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6217bb9-a229-48f7-9b5b-c06db732c0e7",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spike_raster_plt.shift_animation_frame_val(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d135972-db54-4e14-9cd7-67e0b5631378",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _test_display_pyqtgraph_raster_plot(curr_spikes_df):    \n",
    "    curr_unit_id = curr_spikes_df['unit_id'].to_numpy() # this will map to the y position\n",
    "    curr_spike_t = curr_spikes_df[curr_spikes_df.spikes.time_variable_name].to_numpy() # this will map to the depth dimension in 3D or x-pos in 2D\n",
    "\n",
    "    print(f'_test_display_pyqtgraph_raster_plot(np.shape(curr_unit_id): {np.shape(curr_unit_id)}, np.shape(curr_spike_t): {np.shape(curr_spike_t)})')\n",
    "    # print(f'\\t curr_unit_id: {curr_unit_id}\\n curr_spike_t: {curr_spike_t}')\n",
    "    \n",
    "    # For the unit Ids, perform a transformation:\n",
    "    normalized_unit_ids = curr_unit_id / np.max(curr_unit_id)\n",
    "    upper_unit_bounds = (normalized_unit_ids*0.9) + 0.05 # 0.05 to 0.95\n",
    "    lower_unit_bounds = upper_unit_bounds - 0.05 # 0.00 to 0.90\n",
    "\n",
    "    # curr_unit_id_repeats = curr_unit_id.copy()\n",
    "    curr_spike_t_repeats = curr_spike_t.copy()\n",
    "\n",
    "    curr_spike_t_repeats = np.atleast_2d(curr_spike_t.copy())\n",
    "    \n",
    "    lower_unit_bounds = np.atleast_2d(lower_unit_bounds)\n",
    "    upper_unit_bounds = np.atleast_2d(upper_unit_bounds)\n",
    "    print(f'np.atleast_2d(lower_unit_bounds): {np.shape(np.atleast_2d(lower_unit_bounds))}') # (1, 819170)\n",
    "    # end_points = np.atleast_2d(end_points)\n",
    "    \n",
    "    # the paired arrays should be twice as long as the original arrays and are to be used with the connected='pair' argument\n",
    "    # curr_paired_unit_id = interleave_elements(curr_unit_id, curr_unit_id_repeats)\n",
    "    curr_paired_unit_id = np.squeeze(interleave_elements(lower_unit_bounds.T, upper_unit_bounds.T)) # use the computed ranges instead\n",
    "    curr_paired_spike_t = np.squeeze(interleave_elements(curr_spike_t_repeats.T, curr_spike_t_repeats.T))\n",
    "    \n",
    "    print(f'curr_paired_unit_id: {np.shape(curr_paired_unit_id)}, curr_paired_spike_t: {np.shape(curr_paired_spike_t)}')\n",
    "    # out_q_path = pg.arrayToQPath(curr_paired_spike_t, curr_paired_unit_id, connect='pairs', finiteCheck=True) # connect='pairs' details how to connect points in the path\n",
    "    \n",
    "    return plot_raster_plot(x=curr_paired_spike_t, y=curr_paired_unit_id)    \n",
    "    \n",
    "\n",
    "# _display_pyqtgraph_raster_plot(curr_spikes_df)\n",
    "\n",
    "_test_display_pyqtgraph_raster_plot(curr_spikes_df)\n",
    "\n",
    "\n",
    "# _display_pyqtgraph_raster_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8963f93-a2be-4a59-8f31-f4d408cd6ff9",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Matplotlib 2D Raster Plot:\n",
    "\n",
    "# Eventplot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import EventCollection\n",
    "# import numpy as np\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "# create random data\n",
    "xdata = np.random.random([2, 10])\n",
    "\n",
    "# split the data into two parts\n",
    "xdata1 = xdata[0, :]\n",
    "xdata2 = xdata[1, :]\n",
    "\n",
    "# sort the data so it makes clean curves\n",
    "xdata1.sort()\n",
    "xdata2.sort()\n",
    "\n",
    "# create some y data points\n",
    "ydata1 = xdata1 ** 2\n",
    "ydata2 = 1 - xdata2 ** 3\n",
    "\n",
    "# plot the data\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(xdata1, ydata1, color='tab:blue')\n",
    "ax.plot(xdata2, ydata2, color='tab:orange')\n",
    "\n",
    "# create the events marking the x data points\n",
    "xevents1 = EventCollection(xdata1, color='tab:blue', linelength=0.05)\n",
    "xevents2 = EventCollection(xdata2, color='tab:orange', linelength=0.05)\n",
    "\n",
    "# create the events marking the y data points\n",
    "yevents1 = EventCollection(ydata1, color='tab:blue', linelength=0.05,\n",
    "                           orientation='vertical')\n",
    "yevents2 = EventCollection(ydata2, color='tab:orange', linelength=0.05,\n",
    "                           orientation='vertical')\n",
    "\n",
    "# add the events to the axis\n",
    "ax.add_collection(xevents1)\n",
    "ax.add_collection(xevents2)\n",
    "ax.add_collection(yevents1)\n",
    "ax.add_collection(yevents2)\n",
    "\n",
    "# set the limits\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "ax.set_title('line plot with data points')\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f3900-3e70-4d66-9aaf-a9a77db841de",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5450b0ce-d15a-48ae-9d33-f6c007dca4de",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.SpikesDataframeWindow import SpikesDataframeWindow, SpikesWindowOwningMixin\n",
    "from pyphoplacecellanalysis.General.DataSeriesToSpatial import DataSeriesToSpatial\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "# np.random.seed(19680801)\n",
    "\n",
    "\n",
    "# create random data\n",
    "# data1 = np.random.random([6, 50])\n",
    "\n",
    "# set different colors for each set of positions\n",
    "# colors1 = ['C{}'.format(i) for i in range(6)]\n",
    "\n",
    "unit_ids = np.unique(curr_spikes_df['unit_id'].to_numpy())\n",
    "cell_ids = np.unique(curr_spikes_df['aclu'].to_numpy()) \n",
    "n_cells = len(unit_ids)\n",
    "\n",
    "print(f'unit_ids: {unit_ids}, n_cells: {n_cells}')\n",
    "y = DataSeriesToSpatial.build_series_identity_axis(n_cells, center_mode='zero_centered', bin_position_mode='left_edges', side_bin_margins=0.0)\n",
    "y_unit_id_map = dict(zip(unit_ids, y))\n",
    "\n",
    "# Compute the y for all windows, not just the current one:\n",
    "# all_y = [y[i] for i, a_cell_id in enumerate(curr_spikes_df['unit_id'].to_numpy())]\n",
    "all_y = [y_unit_id_map[a_cell_id] for a_cell_id in curr_spikes_df['unit_id'].to_numpy()]\n",
    " # for i, cell_id in enumerate(self.unit_ids)] \n",
    "curr_spikes_df['visualization_raster_y_location'] = all_y # adds as a column to the dataframe. Only needs to be updated when the number of active units changes\n",
    "curr_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf1423-5160-4583-8059-c8662c82e287",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(y)\n",
    "\n",
    "# # Plot each unit one at a time:\n",
    "# for i, cell_id in enumerate(unit_ids):    \n",
    "#     # Filter the dataframe using that column and value from the list\n",
    "#     curr_cell_df = curr_spikes_df[curr_spikes_df['unit_id']==cell_id]\n",
    "#     curr_spike_t = curr_cell_df[curr_cell_df.spikes.time_variable_name].to_numpy() # this will map\n",
    "#     # efficiently get curr_spike_t by filtering for unit and column at the same time\n",
    "#     # curr_spike_t = curr_spikes_df.loc[curr_spikes_df.spikes.time_variable_name, (curr_spikes_df['unit_id']==cell_id)].values # .to_numpy()\n",
    "#     curr_unit_n_spikes = len(curr_spike_t)\n",
    "#     yi = y[i] # get the correct y-position for all spikes of this cell\n",
    "#     # map the current spike times back onto the range of the window's (-half_render_window_duration, +half_render_window_duration) so they represent the x coordinate\n",
    "#     # curr_x = np.interp(curr_spike_t, (self.spikes_window.active_window_start_time, self.spikes_window.active_window_end_time), (-self.half_render_window_duration, +self.half_render_window_duration))\n",
    "#     curr_x = np.interp(curr_spike_t, (self.spikes_window.active_window_start_time, self.spikes_window.active_window_end_time), (-self.half_temporal_axis_length, +self.half_temporal_axis_length))\n",
    "#     # curr_paired_x = np.squeeze(interleave_elements(np.atleast_2d(curr_x).T, np.atleast_2d(curr_x).T))        \n",
    "#     curr_paired_x = curr_x.repeat(2)\n",
    "\n",
    "#     # Z-positions:\n",
    "#     # spike_bottom_zs = np.full_like(curr_x, self.params.spike_start_z)\n",
    "#     # spike_top_zs = np.full_like(curr_x, self.params.spike_end_z)\n",
    "#     # curr_paired_spike_zs = np.squeeze(interleave_elements(np.atleast_2d(spike_bottom_zs).T, np.atleast_2d(spike_top_zs).T)) # alternating top and bottom z-positions\n",
    "#     curr_paired_spike_zs = np.squeeze(np.tile(np.array([self.params.spike_start_z, self.params.spike_end_z]), curr_unit_n_spikes)) # repeat pair of z values once for each spike\n",
    "\n",
    "#     # Build lines:\n",
    "#     pts = np.column_stack([curr_paired_x, np.full_like(curr_paired_x, yi), curr_paired_spike_zs]) # the middle coordinate is the size of the x array with the value given by yi. yi must be the scalar for this cell.\n",
    "#     # plt = gl.GLLinePlotItem(pos=pts, color=curr_color, width=0.5, antialias=True, mode='lines') # mode='lines' means that each pair of vertexes draws a single line segement\n",
    "#     self.ui.gl_line_plots[i].setData(pos=pts, mode='lines') # update the current data\n",
    "\n",
    "#     # self.ui.main_gl_widget.addItem(plt)\n",
    "#     # self.ui.gl_line_plots.append(plt) # append to the gl_line_plots array\n",
    "            \n",
    "\n",
    "# set different line properties for each set of positions\n",
    "# note that some overlap\n",
    "# lineoffsets1 = [-15, -3, 1, 1.5, 6, 10]\n",
    "# linelengths1 = [5, 2, 1, 1, 3, 1.5]\n",
    "\n",
    "data1 = curr_spikes_df[curr_spikes_df.spikes.time_variable_name].to_numpy() # this will map\n",
    "lineoffsets1 = all_y\n",
    "linelengths1 = np.full_like(all_y, 1.0)\n",
    "\n",
    "print(f'data1: {np.shape(data1)}, lineoffsets1: {np.shape(lineoffsets1)}, linelengths1: {np.shape(linelengths1)}')\n",
    "\n",
    "fig, axs = plt.subplots(1,1)\n",
    "\n",
    "# create a horizontal plot\n",
    "axs.eventplot(data1, lineoffsets=lineoffsets1)\n",
    "# axs.eventplot(data1, lineoffsets=lineoffsets1, linelengths=linelengths1)\n",
    "# axs.eventplot(data1, colors=colors1, lineoffsets=lineoffsets1, linelengths=linelengths1)\n",
    "\n",
    "# create a vertical plot\n",
    "# axs[1, 0].eventplot(data1, colors=colors1, lineoffsets=lineoffsets1,\n",
    "#                     linelengths=linelengths1, orientation='vertical')\n",
    "\n",
    "\n",
    "# create the events marking the x data points\n",
    "xevents1 = EventCollection(xdata1, color='tab:blue', linelength=0.05)\n",
    "xevents2 = EventCollection(xdata2, color='tab:orange', linelength=0.05)\n",
    "\n",
    "\n",
    "# # create another set of random data.\n",
    "# # the gamma distribution is only used for aesthetic purposes\n",
    "# data2 = np.random.gamma(4, size=[60, 50])\n",
    "\n",
    "# # use individual values for the parameters this time\n",
    "# # these values will be used for all data sets (except lineoffsets2, which\n",
    "# # sets the increment between each data set in this usage)\n",
    "# colors2 = 'black'\n",
    "# lineoffsets2 = 1\n",
    "# linelengths2 = 1\n",
    "\n",
    "# # create a horizontal plot\n",
    "# axs[0, 1].eventplot(data2, colors=colors2, lineoffsets=lineoffsets2,\n",
    "#                     linelengths=linelengths2)\n",
    "\n",
    "\n",
    "# # create a vertical plot\n",
    "# axs[1, 1].eventplot(data2, colors=colors2, lineoffsets=lineoffsets2,\n",
    "#                     linelengths=linelengths2, orientation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf076a-13c1-4150-bbc2-29e972561f6d",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_computation_function_names\n",
    "# ['_perform_placefield_overlap_computation',\n",
    "#  '_perform_firing_rate_trends_computation',\n",
    "#  '_perform_extended_statistics_computation',\n",
    "#  '_perform_two_step_position_decoding_computation',\n",
    "#  '_perform_position_decoding_computation']\n",
    "\n",
    "\n",
    "curr_active_pipeline.registered_display_function_names\n",
    "# ['_display_1d_placefield_validations',\n",
    "#  '_display_2d_placefield_result_plot_ratemaps_2D',\n",
    "#  '_display_2d_placefield_result_plot_raw',\n",
    "#  '_display_3d_image_plotter',\n",
    "#  '_display_3d_interactive_custom_data_explorer',\n",
    "#  '_display_3d_interactive_spike_and_behavior_browser',\n",
    "#  '_display_3d_interactive_tuning_curves_plotter',\n",
    "#  '_display_normal',\n",
    "#  '_display_placemaps_pyqtplot_2D',\n",
    "#  '_display_decoder_result',\n",
    "#  '_display_plot_most_likely_position_comparisons',\n",
    "#  '_display_two_step_decoder_prediction_error_2D',\n",
    "#  '_display_two_step_decoder_prediction_error_animated_2D']\n",
    "\n",
    "\n",
    "# all_fcn_tuples[0]\n",
    "# [a_name for (a_name, a_fn) in all_fcn_tuples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cbbfa0",
   "metadata": {},
   "source": [
    "# Common: Display\n",
    "Common visualization and display functions for both forms of data/pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28864994-db95-4b51-8c68-092828a42ce9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list(curr_active_pipeline.computation_results.keys()) # ['maze1', 'maze2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4917da1-a0b3-4b77-a34e-73f87c41a1ef",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "active_config_name = 'maze1'\n",
    "# active_config_name = 'maze'\n",
    "\n",
    "# Get relevant variables:\n",
    "# curr_active_pipeline is set above, and usable here\n",
    "sess: DataSession = curr_active_pipeline.filtered_sessions[active_config_name]\n",
    "pf = curr_active_pipeline.computation_results[active_config_name].computed_data['pf1D']\n",
    "active_one_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data['pf2D_Decoder']\n",
    "active_two_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_TwoStepDecoder', None)\n",
    "active_measured_positions = curr_active_pipeline.computation_results[active_config_name].sess.position.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd23e683-c624-4726-8d09-bdd92331e0bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compare curr_active_pipeline.filtered_sessions[active_config_name] and \n",
    "# from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_DataTreeWidget import plot_dataTreeWidget\n",
    "#\n",
    "# print(f'curr_active_pipeline.filtered_sessions[active_config_name]: {curr_active_pipeline.filtered_sessions[active_config_name]}')\n",
    "# print(f'curr_active_pipeline.computation_results[active_config_name].sess: {curr_active_pipeline.computation_results[active_config_name].sess}')\n",
    "#\n",
    "# filtered_sessions_tree, filtered_sessions_app = plot_dataTreeWidget(data={'filtered_sessions[active_config_name]':curr_active_pipeline.filtered_sessions[active_config_name].to_dict()}, title='PhoOutputDataTreeApp - filtered_sessions[active_config_name]')\n",
    "# tree, app = plot_dataTreeWidget(data={'computation_results[active_config_name].sess':curr_active_pipeline.computation_results[active_config_name].sess.to_dict()}, title='PhoOutputDataTreeApp- curr_active_pipeline.computation_results[active_config_name].sess')\n",
    "\n",
    "# pg.exec()\n",
    "\n",
    "# sess.ripple\n",
    "# sess.mua\n",
    "if sess.pbe is None:\n",
    "    sess.pbe = DataSession.compute_pbe_epochs(sess, save_on_compute=False)\n",
    "    \n",
    "sess.pbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a3b3c-999e-486c-8e48-0e16096a0419",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if curr_active_pipeline.filtered_sessions['maze2'].pbe is None:\n",
    "    curr_active_pipeline.filtered_sessions['maze2'].pbe = DataSession.compute_pbe_epochs(curr_active_pipeline.filtered_sessions['maze2'], save_on_compute=False)\n",
    "    \n",
    "curr_active_pipeline.filtered_sessions['maze2'].pbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df1291",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_output = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d8d3a5-526a-4053-b395-b6e7e2def33d",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pActiveTuningCurvesPlotter = None\n",
    "display_output = curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_tuning_curves_plotter, active_config_name, extant_plotter=display_output.get('plotter', None)) # Works now!\n",
    "# display_output = curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_tuning_curves_plotter, active_config_name, extant_plotter=pActiveTuningCurvesPlotter) # Works now!\n",
    "# pActiveTuningCurvesPlotter = display_output['plotter']\n",
    "display_output['pane'] # doesn't seem to work to control the output anymore!\n",
    "# display_output['ipcDataExplorer'].debug_logging = True\n",
    "# InteractivePlaceCellDataExplorer.debug_logging = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06173e1a-69cc-4240-874f-4f37060c2f6d",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# display_output['ipcDataExplorer'].change_unit_spikes_included(cell_IDXs=[0, 1, 2, 3], are_included=[True, True, True, True])\n",
    "# display_output['ipcDataExplorer'].test_toggle_cell_spikes_visibility()\n",
    "# display_output['ipcDataExplorer']._show_all_tuning_curves()\n",
    "# display_output['ipcDataExplorer'].update_active_placefields([])\n",
    "\n",
    "\n",
    "# display_output['ipcDataExplorer'].active_neuron_render_configs # .isVisible is wrong for every value in this array.\n",
    "display_output['ipcDataExplorer'].apply_tuning_curve_configs()\n",
    "# \"\"\" display_output['ipcDataExplorer'].active_neuron_render_configs:\n",
    "        # [SingleNeuronPlottingExtended(color='#843c39', extended_values_dictionary={}, isVisible=True, name='2', spikesVisible=False),\n",
    "        #  SingleNeuronPlottingExtended(color='#9d514e', extended_values_dictionary={}, isVisible=True, name='3', spikesVisible=False),\n",
    "        # ...\n",
    "        # ]\n",
    "# \"\"\"\n",
    "# display_output['ipcDataExplorer'].active_tuning_curve_render_configs\n",
    "# \"\"\" display_output['ipcDataExplorer'].active_tuning_curve_render_configs:\n",
    "#     [SingleNeuronPlottingExtended(color='#843c39', extended_values_dictionary={}, isVisible=True, name='2', spikesVisible=False),\n",
    "#      SingleNeuronPlottingExtended(color='#9d514e', extended_values_dictionary={}, isVisible=True, name='3', spikesVisible=False),\n",
    "#      ...\n",
    "#      ]\n",
    "# \"\"\"\n",
    "\n",
    "# display_output['ipcDataExplorer']._show_tuning_curve(5)\n",
    "\n",
    "# debug_disable_all_gui_controls \n",
    "\n",
    "# display_output['ipcDataExplorer'].active_tuning_curve_render_configs # [SingleNeuronPlottingExtended(color='#843c39', extended_values_dictionary={}, isVisible=False, name='2', spikesVisible=False), ... ]\n",
    "# display_output['ipcDataExplorer'].cell_ids\n",
    "# display_output['ipcDataExplorer'].clear_spikes_exclusion_mask()\n",
    "# display_output['ipcDataExplorer'].pf_names\n",
    "\n",
    "# display_output['ipcDataExplorer'].change_unit_spikes_included(cell_IDs=display_output['ipcDataExplorer'].cell_ids, are_included=np.full_like(display_output['ipcDataExplorer'].cell_ids, True))\n",
    "# display_output['ipcDataExplorer'].perform_plot_location_point()\n",
    "# neuron_config_indicies: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
    "#        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
    "#        34, 35, 36, 37, 38])\n",
    "# display_output['ipcDataExplorer'].unmask_spikes_from_render([2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.qt_placefield import build_all_placefield_output_panels\n",
    "# display_output = curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_tuning_curves_plotter, active_config_name, extant_plotter=display_output.get('pActiveTuningCurvesPlotter', None)) # Works now!\n",
    "\n",
    "# pActiveTuningCurvesPlotter\n",
    "# display_output['ipcDataExplorer'].active_tuning_curve_render_configs # array of SingleNeuronPlottingExtended objects\n",
    "\n",
    "## TODO: try to build these UI elements in the ipcDataExplorer itself instead of externally. Maybe it's a run loop issue.\n",
    "\n",
    "# build the output panels\n",
    "placefieldControlsContainerWidget, pf_widgets = build_all_placefield_output_panels(display_output['ipcDataExplorer'])\n",
    "placefieldControlsContainerWidget.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40404570",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_spike_and_behavior_browser, active_config_name) # this works now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0073ab-9e27-45e8-b3a0-ff5e34b4cd11",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_custom_data_explorer, active_config_name) # does not work, missing color info?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6497b-f442-4096-afe0-12ce9b41612b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plots = curr_active_pipeline.display(DefaultDisplayFunctions._display_1d_placefield_validations, active_config_name) # works, but generates a TON of plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fab03e-809e-441c-a235-7469147604cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(plots) # 39\n",
    "type(plots[0]) # matplotlib.figure.Figure\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(10, 4))\n",
    "subfigs = fig.subfigures(1, 2, wspace=0.07)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb39bbd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here we look at the population burst events for each epoch ('maze1' vs. 'maze2')\n",
    "# curr_active_pipeline.sess.\n",
    "\n",
    "# get only the spikes that occur during PBEs:\n",
    "pbe_only_spikes_df = sess.spikes_df[(sess.spikes_df.PBE_id > -1)]\n",
    "pbe_only_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e889d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.pbe #[10960 rows x 4 columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b1549-6a5f-493f-98f2-3b3f367cc43b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDecoderDisplayFunctions._display_two_step_decoder_prediction_error_2D, active_config_name, variable_name='p_x_given_n') # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d1ff7-73fa-44b3-a351-6ce01510320b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDecoderDisplayFunctions._display_two_step_decoder_prediction_error_2D, active_config_name, variable_name='p_x_given_n_and_x_prev') # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c49ccf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDecoderDisplayFunctions._display_two_step_decoder_prediction_error_animated_2D, active_config_name, variable_name='p_x_given_n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de2901-e7ea-40fe-8807-d5bfb57b01bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "app, win, w = curr_active_pipeline.display(DefaultRatemapDisplayFunctions._display_placemaps_pyqtplot_2D, active_config_name)\n",
    "win.show(); pg.exec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abc004f-a5d9-4979-8cde-f202597ba1ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "### Old Individual Plotting Functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5422763d-b961-4dab-810d-8e27b091dffe",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "filter_name = 'maze1'\n",
    "# curr_bapun_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, subplots=(20, 8), max_screen_figure_size=(2256, 2048), enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=0) # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, subplots=(20, 8), max_screen_figure_size=(2256, 2048), enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=10) # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca71727-a5cc-48df-88e7-782bbccdef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_name = 'maze2'\n",
    "# curr_bapun_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, subplots=(20, 8), max_screen_figure_size=(2256, 2048), enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=0) # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, subplots=(20, 8), max_screen_figure_size=(2256, 2048), enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=11) # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c4f39-412d-42e7-9b3d-8417993ee562",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_result(curr_active_pipeline.computation_results['maze1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c4907-c242-4908-80dd-0c7d49e89b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_result(curr_active_pipeline.computation_results['maze2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c3eb8a-d963-4d60-ab39-721de81a34fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_name = 'maze1'\n",
    "# curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=0, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=1, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ad5c3-328d-41a9-b7c2-2bc6f7aaf2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_name = 'maze2'\n",
    "# curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=0, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=1, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c849eb9-e7c4-476d-b17c-d197d2f80983",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_name = 'maze'\n",
    "# curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=0, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=1, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c4ecf-15c2-4197-927f-8f1a63c7ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_custom_data_explorer, 'maze1') # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_tuning_curves_plotter, 'maze1') # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2f3bb-49a9-4053-9fd4-03c8796e7bf2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_1d_placefield_validations, 'maze1') # works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c4171-ea23-4f0f-bcc0-a7ab3544dfbe",
   "metadata": {},
   "source": [
    "\n",
    "# Testing: Position Decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b04bc40",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# win.close()\n",
    "app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37445b3-c614-4b68-b6ab-ee7a26c29af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stock Decoder:\n",
    "from neuropy.analyses.decoders import Decode1d\n",
    "\n",
    "def stock_1d_decoder(sess, pf, curr_result_label):\n",
    "    maze1 = sess.paradigm[curr_result_label]\n",
    "    # rpls = sess.ripple.time_slice(maze1[0], maze1[1])\n",
    "    rpls = None\n",
    "    pf_neurons = sess.neurons.get_by_id(pf.ratemap.neuron_ids)\n",
    "    decode = Decode1d(neurons=pf_neurons, ratemap = pf.ratemap, epochs=rpls, bin_size=0.02)\n",
    "    return decode\n",
    "\n",
    "def validate_stock_1d_decoder(sess, decode):\n",
    "    # Plot to validate decoder:\n",
    "    np.shape(decode.decoded_position) # (85845,)\n",
    "    plt.plot(decode.decoded_position)\n",
    "    ax = plt.gca()\n",
    "    # ax.xlim() # (-4292.2, 90136.2)\n",
    "    ax.set_xlim(10000, 12000)\n",
    "\n",
    "np.shape(decode.posterior) # (48, 85845)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c545afc1-63d6-4f45-a186-5acae5b2dab3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- % $$\\int_{a}^b f(x)dx$$ -->\n",
    "<!-- Euler's identity: $ e^{i \\pi} + 1 = 0 $ -->\n",
    "\n",
    "## One-step Bayesian Decoder:\n",
    "$$P(\\overrightarrow{x}_{t}|\\overrightarrow{n}_{t})$$\n",
    "\n",
    "$$P(\\overrightarrow{n}|\\overrightarrow{x})$$ : probability for the numbers of spikes $\\overrightarrow{n}$ to occur given we know the animal is at location $\\overrightarrow{x}$\n",
    "\n",
    "## Two-step Bayesian Decoder:\n",
    "$$P(\\overrightarrow{x}_{t}|\\overrightarrow{n}_{t}, \\overrightarrow{x}_{t-1}) = k P(\\overrightarrow{x}_{t}|\\overrightarrow{n}_{t}) P(\\overrightarrow{x}_{t-1}|\\overrightarrow{x}_{t})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b8e04-3f5d-49e9-af1b-786326567330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# active_two_step_decoder['most_likely_positions'].shape # (2, 1717)\n",
    "\n",
    "active_two_step_decoder['most_likely_position_indicies'].shape # (2, 1717)\n",
    "np.max(active_two_step_decoder['most_likely_position_indicies'], axis=1) # array([0, 1])\n",
    "active_two_step_decoder['most_likely_position_indicies']\n",
    "# active_two_step_decoder['p_x_given_n_and_x_prev'].shape # (59, 21, 1717)\n",
    "\n",
    "# np.nanmax(active_two_step_decoder['p_x_given_n_and_x_prev'], axis=(1, 2)) # (59,)\n",
    "# np.nanmax(active_two_step_decoder['p_x_given_n_and_x_prev'], axis=-1).shape # (59, 21)\n",
    "\n",
    "# np.nanmax(active_two_step_decoder['p_x_given_n_and_x_prev'], axis=-1)\n",
    "# np.max(active_two_step_decoder['most_likely_positions'], axis=1) # array([ 36.30101033, 128.49991842])\n",
    "\n",
    "\n",
    "# np.max(active_one_step_decoder.most_likely_positions, axis=0) # array([244.02731273, 148.3231301 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be34e2-9062-4e08-bedb-0d7ec4ceca9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PyQtPlot Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d4e875-52e9-4bf4-b742-db1bfaab77d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array, pyqtplot_plot_image\n",
    "\n",
    "# test single image plot:\n",
    "curr_im = np.squeeze(active_one_step_decoder.ratemap.normalized_tuning_curves[0,:,:]) # (43, 63, 63)\n",
    "app, win, imv = pyqtplot_plot_image(active_one_step_decoder.xbin, active_one_step_decoder.ybin, curr_im)\n",
    "win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1263931-3967-4eff-a766-2be9b275566d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataTree Widget that displays a nested hierarchy of data:\n",
    "d = {\n",
    "    'active_sess_config':curr_active_pipeline.active_sess_config.__dict__,\n",
    "    'active_configs':curr_active_pipeline.active_configs,\n",
    "    'active_session_computation_configs':active_session_computation_configs[0].__dict__\n",
    "}\n",
    "# d = {\n",
    "#     'active_two_step_decoder': active_two_step_decoder,\n",
    "#     'active_extended_stats': active_extended_stats\n",
    "# }\n",
    "# d = {\n",
    "#     'active_session_computation_configs':active_session_computation_configs,\n",
    "#     'active_two_step_decoder': active_two_step_decoder,\n",
    "#     'active_extended_stats': active_extended_stats\n",
    "# }\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_DataTreeWidget import plot_dataTreeWidget\n",
    "tree, app = plot_dataTreeWidget(data=d, title='PhoOutputDataTreeApp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6943e136",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Params.pyqtplot_ParamTreeWidget import plot_paramTreeWidget\n",
    "param_tree, param_tree_app = plot_paramTreeWidget(title='PhoMainParamTreeApp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ddf63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Flowchart.pyqtplot_Flowchart import plot_flowchartWidget\n",
    "pipeline_flowchart_window, pipeline_flowchart_app = plot_flowchartWidget(title='PhoMainPipelineFlowchartApp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8f405-a15b-4e58-a281-c56fc6cb9c93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pg.mkQApp()\n",
    "# Create ScatterPlotWidget and configure its fields\n",
    "spw = pg.ScatterPlotWidget()\n",
    "# spw.setFields([\n",
    "    # ('x_pos', {'units': 'm'}),\n",
    "#     ('y_pos', {'units': 'm'}),\n",
    "#     ('count', {}),\n",
    "#     ('amplitude', {'units': 'V'}),\n",
    "#     ('decay', {'units': 's'}),    \n",
    "#     ('type', {'mode': 'enum', 'values': strings}),\n",
    "#     ])\n",
    "\n",
    "spw.setFields([\n",
    "    ('x', {'units': 'm'}),\n",
    "    ('y', {'units': 'm'}),\n",
    "    ('lin_pos', {'units': 'm'}),\n",
    "    ('speed', {'units': 'm/s'}),\n",
    "    ('binned_x', {}),\n",
    "    ('binned_y', {}),\n",
    "    # ('type', {'mode': 'enum', 'values': strings}),\n",
    "])\n",
    "    \n",
    "spw.setData(time_binned_pos_df)\n",
    "spw.show()\n",
    "\n",
    "\n",
    "# ## Multiple Line Plots:\n",
    "# plotWidget = pg.plot(title='PhoTest PyQtPlot Widget')\n",
    "# for i in range(3):\n",
    "#     plotWidget.plot(x, y[i], pen=(i,3))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6710ea4d-d80b-4e39-ba21-a3f9a3466ee2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check Placefield Normalizations:\n",
    "Conclusion: neither the normalized_tuning_curves nor tuning_curves are normalized in any way! They give different firing rates across time.\n",
    "NOTE: For the pyramidal-only and lap-epoch filtered Diba data, the np.nanmax of normalized_tuning_curves actually does appear to be scaled to a maximum of 1.0 across all units, meaning only the relative difference between units in firing rate is preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0938f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad417c9-8b38-4a08-a8f1-6ca254064f55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sum(active_one_step_decoder.pf.ratemap.normalized_tuning_curves, axis=(1,2)) # ERROR: the normalized_tuning_curves are NOT normalized in any way!\n",
    "np.nanmax(active_one_step_decoder.pf.ratemap.normalized_tuning_curves, axis=(1,2)) # Not even by having their maximum value scaled to one!\n",
    "\n",
    "# np.sum(active_one_step_decoder.pf.ratemap.tuning_curves, axis=(1,2))\n",
    "# np.nanmax(active_one_step_decoder.pf.ratemap.tuning_curves, axis=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb1fd1f-9bff-42b3-a3c5-5dfbd56ede80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Placefield Firing Rate Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18873548-010d-44fd-808f-f6c5dabdd545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# debug_dump_object_member_shapes(active_one_step_decoder)\n",
    "# computation_result.computed_data['pf2D_Decoder']\n",
    "# active_one_step_decoder.time_window_edges\n",
    "\n",
    "def _display_firing_rate_trends(cell_firing_rate_samples):    \n",
    "    # Incoming data is (C,N): where C is the number of cells and N is the number of datapoints.\n",
    "    num_cells = np.shape(cell_firing_rate_samples)[0]\n",
    "    num_samples = np.shape(cell_firing_rate_samples)[1]\n",
    "    assert (num_samples >= num_cells), f'num_samples should be greater than num_cells, but num_samples: {num_samples} and num_cells: {num_cells}! You probably meant the transpose of the data you passed in.'\n",
    "    \n",
    "    win = pg.plot()\n",
    "    win.setWindowTitle('pyqtgraph beeswarm: Firing Rate Trends')\n",
    "\n",
    "    print(f'np.shape(cell_firing_rate_samples): {np.shape(cell_firing_rate_samples)}, num_cells: {num_cells}, num_samples: {num_samples}')\n",
    "    # data = np.random.normal(size=(4,20))\n",
    "    # data[0] += 5\n",
    "    # data[1] += 7\n",
    "    # data[2] += 5\n",
    "    # data[3] = 10 + data[3] * 2\n",
    "\n",
    "    ## Make bar graph\n",
    "    #bar = pg.BarGraphItem(x=range(4), height=data.mean(axis=1), width=0.5, brush=0.4)\n",
    "    #win.addItem(bar)\n",
    "\n",
    "    ## add scatter plots on top\n",
    "    for i in np.arange(num_cells):\n",
    "        curr_cell_samples = cell_firing_rate_samples.loc[i,:].to_numpy()\n",
    "        print(f'i: {i} - np.shape(curr_cell_samples): {np.shape(curr_cell_samples)}')\n",
    "        xvals = pg.pseudoScatter(curr_cell_samples, spacing=0.4, bidir=True) * 0.2\n",
    "        win.plot(x=xvals+i, y=curr_cell_samples, pen=None, symbol='o', symbolBrush=pg.intColor(i,6,maxValue=128))\n",
    "\n",
    "    ## Make error bars\n",
    "    err = pg.ErrorBarItem(x=np.arange(num_cells), y=cell_firing_rate_samples.mean(axis=1), height=cell_firing_rate_samples.std(axis=1), beam=0.5, pen={'color':'w', 'width':2})\n",
    "    win.addItem(err)\n",
    "    return err, win\n",
    "\n",
    "\n",
    "# active_one_step_decoder.time_window_center_binning_info\n",
    "# position_time_delta = pd.to_timedelta(active_pos_df[active_pos_df.position.time_variable_name], unit=\"sec\")\n",
    "# active_pos_df['time_delta_sec'] = position_time_delta\n",
    "# active_pos_df = active_pos_df.set_index('time_delta_sec')\n",
    "# window_resampled_pos_df = active_pos_df.resample(f'{time_bin_size}S', base=0)#.nearest() # '0.02S' 0.02 second bins\n",
    "\n",
    "# np.shape(active_one_step_decoder.active_time_windows) # (2892, 2)\n",
    "\n",
    "active_firing_rate_trends = curr_active_pipeline.computation_results[active_config_name].computed_data['firing_rate_trends']\n",
    "\n",
    "active_rolling_window_times = active_firing_rate_trends['active_rolling_window_times']\n",
    "mean_firing_rates = active_firing_rate_trends['mean_firing_rates']\n",
    "moving_mean_firing_rates_df = active_firing_rate_trends['moving_mean_firing_rates_df']\n",
    "moving_mean_firing_rates_df # 3969 rows x 43 columns\n",
    "\n",
    "# mean_firing_rates\n",
    "# pg.plot(mean_firing_rates)\n",
    "\n",
    "np.shape(moving_mean_firing_rates_df) # (3969, 43)\n",
    "good_only_moving_mean_firing_rates_df = moving_mean_firing_rates_df.dropna() # 3910 rows x 43 columns\n",
    "good_only_moving_mean_firing_rates_df.T\n",
    "err, win = _display_firing_rate_trends(good_only_moving_mean_firing_rates_df.T)\n",
    "win.show()\n",
    "\n",
    "# active_rolling_window_times # dtype='timedelta64[ns]', name='time_delta_sec', length=2900, freq='S'\n",
    "# pg.plot(moving_mean_firing_rates_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ac6af-9c53-4d2d-9b3e-32a939acb346",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Placefield Overlap Detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9150b-f478-4a56-b645-73eaa9c9def0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Placefield Overlap Detection:\n",
    "def compute_placefield_overlap(pf):\n",
    "    return np.squeeze(np.prod(pf, axis=0))\n",
    "\n",
    "\n",
    "active_pf_overlap_results = curr_active_pipeline.computation_results[active_config_name].computed_data['placefield_overlap']\n",
    "all_pairwise_neuron_IDs_combinations = active_pf_overlap_results['all_pairwise_neuron_IDs_combinations']\n",
    "total_pairwise_overlaps = active_pf_overlap_results['total_pairwise_overlaps']\n",
    "all_pairwise_overlaps = active_pf_overlap_results['all_pairwise_overlaps']\n",
    "\n",
    "active_placefield_overlap\n",
    "total_pairwise_overlaps\n",
    "all_pairwise_overlaps\n",
    "\n",
    "\n",
    "# top_pairwise_overlaps = all_pairwise_overlaps[0:9,:,:]\n",
    "\n",
    "top_pairwise_overlaps = np.squeeze(all_pairwise_overlaps[2,:,:])\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_Matrix import MatrixRenderingWindow\n",
    "print(f'np.shape(top_pairwise_overlaps): {np.shape(top_pairwise_overlaps)}')\n",
    "pg.mkQApp(\"Correlation matrix display\")\n",
    "main_window = MatrixRenderingWindow(matrix=top_pairwise_overlaps, columns=[f'{i}' for i in np.arange(np.shape(top_pairwise_overlaps)[-1])])\n",
    "\n",
    "# compute_placefield_overlap(active_one_step_decoder.pf.ratemap.normalized_tuning_curves)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7357706-f14c-413b-9020-496db9ed63cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Position Dataframe Binning in Time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e39c8-6842-4ac4-8711-3fff06436690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aligned_active_pos_df = active_pos_df.copy()\n",
    "\n",
    "time_window_edges_time_delta = pd.to_timedelta(active_one_step_decoder.time_window_edges, unit=\"sec\") # convert the windows to timedeltas as well to allow efficient comparison\n",
    "time_window_edges_time_delta # length=1718\n",
    "\n",
    "# aligned_active_pos_df.between_time\n",
    "\n",
    "# aligned_active_pos_df.at_time(pho_custom_decoder.time_window_edges)\n",
    "\n",
    "# pho_custom_decoder.time_window_edges\n",
    "# aligned_active_pos_df.align(time_window_edges_time_delta, fill_value=np.nan)\n",
    "\n",
    "# build_position_df_time_window_idx(active_pos_df, pho_custom_decoder.active_time_window_centers)\n",
    "\n",
    "# pho_custom_decoder.active_time_window_centers\n",
    "# pho_custom_decoder.time_window_edges\n",
    "\n",
    "# s21, s22 = ts_2.align(ts_1, fill_value=0)\n",
    "\n",
    "# active_sess.position.df\n",
    "# aligned_active_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d0c686-f861-4f42-9897-d4344ed691c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pho_custom_decoder = curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D_Decoder']\n",
    "enable_plots = True\n",
    "\n",
    "print(f'most_likely_positions: {np.shape(pho_custom_decoder.most_likely_positions)}') # most_likely_positions: (3434, 2)\n",
    "\n",
    "\n",
    "def spike_count_and_firing_rate_normalizations(pho_custom_decoder, enable_plots=True):\n",
    "    \"\"\" Computes several different normalizations of binned firing rate and spike counts, optionally plotting them. \n",
    "    \n",
    "    Usage:\n",
    "        pho_custom_decoder = curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D_Decoder']\n",
    "        enable_plots = True\n",
    "        unit_specific_time_binned_outputs = spike_count_and_firing_rate_normalizations(pho_custom_decoder, enable_plots=enable_plots)\n",
    "        spike_proportion_global_fr_normalized, firing_rate, firing_rate_global_fr_normalized = unit_specific_time_binned_outputs # unwrap the output tuple:\n",
    "    \"\"\"\n",
    "    # produces a fraction which indicates which proportion of the window's firing belonged to each unit (accounts for global changes in firing rate (each window is scaled by the toial spikes of all cells in that window)\n",
    "    unit_specific_time_binned_spike_proportion_global_fr_normalized = pho_custom_decoder.unit_specific_time_binned_spike_counts / pho_custom_decoder.total_spike_counts_per_window\n",
    "    if enable_plots:\n",
    "        plt.figure(num=5)\n",
    "        plt.imshow(unit_specific_time_binned_spike_proportion_global_fr_normalized, cmap='turbo', aspect='auto')\n",
    "        plt.title('Unit Specific Proportion of Window Spikes')\n",
    "        plt.xlabel('Binned Time Window')\n",
    "        plt.ylabel('Neuron Proportion Activity')\n",
    "\n",
    "    # print(pho_custom_decoder.time_window_edges_binning_info.step)\n",
    "    # print(f'pho_custom_decoder: {pho_custom_decoder}')\n",
    "    # np.shape(pho_custom_decoder.F) # (1856, 64)\n",
    "\n",
    "    unit_specific_time_binned_firing_rate = pho_custom_decoder.unit_specific_time_binned_spike_counts / pho_custom_decoder.time_window_edges_binning_info.step\n",
    "    # print(unit_specific_time_binned_firing_rate)\n",
    "    if enable_plots:\n",
    "        plt.figure(num=6)\n",
    "        plt.imshow(unit_specific_time_binned_firing_rate, cmap='turbo', aspect='auto')\n",
    "        plt.title('Unit Specific Binned Firing Rates')\n",
    "        plt.xlabel('Binned Time Window')\n",
    "        plt.ylabel('Neuron Firing Rate')\n",
    "\n",
    "\n",
    "    # produces a unit firing rate for each window that accounts for global changes in firing rate (each window is scaled by the firing rate of all cells in that window\n",
    "    unit_specific_time_binned_firing_rate_global_fr_normalized = unit_specific_time_binned_spike_proportion_global_fr_normalized / pho_custom_decoder.time_window_edges_binning_info.step\n",
    "    if enable_plots:\n",
    "        plt.figure(num=7)\n",
    "        plt.imshow(unit_specific_time_binned_firing_rate_global_fr_normalized, cmap='turbo', aspect='auto')\n",
    "        plt.title('Unit Specific Binned Firing Rates (Global Normalized)')\n",
    "        plt.xlabel('Binned Time Window')\n",
    "        plt.ylabel('Neuron Proportion Firing Rate')\n",
    "        \n",
    "        \n",
    "    # Special:\n",
    "    # pho_custom_decoder.unit_specific_time_binned_spike_counts\n",
    "    # unit_specific_binned_spike_count_mean = np.nanmean(pho_custom_decoder.unit_specific_time_binned_spike_counts, axis=1)\n",
    "    \n",
    "\n",
    "    # Return the computed values, leaving the original data unchanged.\n",
    "    return unit_specific_time_binned_spike_proportion_global_fr_normalized, unit_specific_time_binned_firing_rate, unit_specific_time_binned_firing_rate_global_fr_normalized\n",
    "\n",
    "\n",
    "unit_specific_time_binned_outputs = spike_count_and_firing_rate_normalizations(pho_custom_decoder, enable_plots=enable_plots)\n",
    "spike_proportion_global_fr_normalized, firing_rate, firing_rate_global_fr_normalized = unit_specific_time_binned_outputs # unwrap the output tuple:\n",
    "\n",
    "# pho_custom_decoder.unit_specific_time_binned_spike_counts.shape # (64, 1717)\n",
    "unit_specific_binned_spike_count_mean = np.nanmean(pho_custom_decoder.unit_specific_time_binned_spike_counts, axis=1)\n",
    "unit_specific_binned_spike_count_var = np.nanvar(pho_custom_decoder.unit_specific_time_binned_spike_counts, axis=1)\n",
    "unit_specific_binned_spike_count_median = np.nanmedian(pho_custom_decoder.unit_specific_time_binned_spike_counts, axis=1)\n",
    "\n",
    "unit_specific_binned_spike_count_mean\n",
    "unit_specific_binned_spike_count_median\n",
    "# unit_specific_binned_spike_count_mean.shape # (64, )\n",
    "\n",
    "\n",
    "# pho_custom_decoder.unit_specific_time_binned_spike_counts\n",
    "# pho_custom_decoder.time_window_edges\n",
    "# pho_custom_decoder.time_window_edges_binning_info\n",
    "# pho_custom_decoder.total_spike_counts_per_window\n",
    "# curr_kdiba_pipeline.pf.xbin\n",
    "\n",
    "\n",
    "# active_pos_df = curr_kdiba_pipeline.filtered_sessions['maze1'].position.to_dataframe()\n",
    "# time_window_edges, time_window_edges_binning_info = compute_spanning_bins(active_pos_df['x'].to_numpy(), bin_size=max_time_bin_size) # np.shape(out_digitized_variable_bins)[0] == np.shape(spikes_df)[0]\n",
    "# assert np.shape(time_window_edges)[0] < np.shape(spikes_df)[0], f'spikes_df[time_variable_name]: {np.shape(spikes_df[time_variable_name])} should be less than time_window_edges: {np.shape(time_window_edges)}!'\n",
    "\n",
    "# active_sess.position.df\n",
    "\n",
    "# active_aligned_pos_df = align_data(pho_custom_decoder.active_time_window_centers, active_pos_df['t'].to_numpy(), active_pos_df[['x','y']].to_numpy())\n",
    "# active_aligned_pos_df = align_data(pho_custom_decoder.active_time_window_centers, active_pos_df.index, active_pos_df['x'])\n",
    "# active_aligned_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fa335-d725-41ba-a8cd-2921eb85de71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.General.Decoder.decoder_result import DecoderResultDisplayingPlot2D\n",
    "# def _display_decoder_result():\n",
    "#     renderer = DecoderResultDisplayingPlot2D(pho_custom_decoder, active_pos_df)\n",
    "#     def animate(i):\n",
    "#         # print(f'animate({i})')\n",
    "#         return renderer.display(i)\n",
    "#     interact(animate, i=(0, pho_custom_decoder.num_time_windows, 10))\n",
    "\n",
    "curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_decoder_result, 'maze1', show_posterior=True) # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b6e96-0231-4829-a895-bfd14249b4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @pn.interact(i=(0,pho_custom_decoder.num_time_windows,1,0))\n",
    "# @interact(i=pn.widgets.IntSlider(start=0,end=pho_custom_decoder.num_time_windows,step=1,value=0))\n",
    "\n",
    "# ani = FuncAnimation(renderer.fig, animate, interval=300)\n",
    "# interact(animate, i=(0, pho_custom_decoder.num_time_windows, 10))\n",
    "\n",
    "# pn.Column('**A custom interact layout**', pn.Row(layout[0], layout[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c981e-7259-4a8e-acfd-5d9146e6b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_kdiba_pipeline.computation_results['maze2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc9a4b0-0474-4f57-a5bb-e76a1fdee8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_result(curr_kdiba_pipeline.computation_results['maze1'])\n",
    "_display_result(curr_kdiba_pipeline.computation_results['maze2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58555225-e9c9-45b2-afb5-d303cabb9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from neuropy.utils.misc import is_iterable\n",
    "from neuropy.plotting.figure import pretty_plot\n",
    "from scipy.ndimage import gaussian_filter, gaussian_filter1d, interpolation\n",
    "\n",
    "from pyphoplacecellanalysis.Analysis.reliability import compute_lap_to_lap_reliability\n",
    "\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "\n",
    "\n",
    "def _test_plotRaw_v_time(active_pf, cellind, speed_thresh=False, alpha=0.5, ax=None):\n",
    "        \"\"\" Builds one subplot for each dimension of the position data\n",
    "        \n",
    "        Updated to work with both 1D and 2D Placefields \"\"\"   \n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(active_pf.ndim, 1, sharex=True)\n",
    "            fig.set_size_inches([23, 9.7])\n",
    "        \n",
    "        if not is_iterable(ax):\n",
    "            ax = [ax]\n",
    "            \n",
    "        # plot trajectories\n",
    "        if active_pf.ndim < 2:\n",
    "            variable_array = [active_pf.x]\n",
    "            label_array = [\"X position (cm)\"]\n",
    "        else:\n",
    "            variable_array = [active_pf.x, active_pf.y]\n",
    "            label_array = [\"X position (cm)\", \"Y position (cm)\"]\n",
    "            \n",
    "        for a, pos, ylabel in zip(ax, variable_array, label_array):\n",
    "            a.plot(active_pf.t, pos)\n",
    "            a.set_xlabel(\"Time (seconds)\")\n",
    "            a.set_ylabel(ylabel)\n",
    "            pretty_plot(a)\n",
    "\n",
    "        # Grab correct spike times/positions\n",
    "        if speed_thresh:\n",
    "            spk_pos_, spk_t_ = active_pf.run_spk_pos, active_pf.run_spk_t\n",
    "        else:\n",
    "            spk_pos_, spk_t_ = active_pf.spk_pos, active_pf.spk_t\n",
    "\n",
    "        # plot spikes on trajectory\n",
    "        for a, pos in zip(ax, spk_pos_[cellind]):\n",
    "            a.plot(spk_t_[cellind], pos, \".\", color=[0, 0, 0.8, alpha])\n",
    "\n",
    "        # Put info on title\n",
    "        ax[0].set_title(\n",
    "            \"Cell \"\n",
    "            + str(active_pf.cell_ids[cellind])\n",
    "            + \":, speed_thresh=\"\n",
    "            + str(active_pf.speed_thresh)\n",
    "        )\n",
    "        return ax\n",
    "\n",
    "\n",
    "def compute_reliability_metrics(out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap, debug_print=False, plot_results=False):\n",
    "    \"\"\" Takes input from compute_lap_to_lap_reliability(...) to build the actual reliability metrics \"\"\"\n",
    "    # Actual Computations of Reliability:\n",
    "    out_pairwise_pair_results = np.zeros_like(out_within_lap_spikes_overlap)\n",
    "    \n",
    "    # do simple diff:\n",
    "    laps_spikes_overlap_diff = np.diff(out_within_lap_spikes_overlap, axis=1) # the element-wise diff of the overlap. Shows changes.\n",
    "    out_pairwise_pair_results[:, 1:] = laps_spikes_overlap_diff\n",
    "    # out_pairwise_pair_results[:, -1] = np.zeros_like(out_within_lap_spikes_overlap[:,0])\n",
    "    \n",
    "    # do custom pairwise operation:\n",
    "#     for first_item_lap_idx, next_item_lap_idx in list(out_pairwise_flat_lap_indicies):\n",
    "#         first_item = out_within_lap_spikes_overlap[:, first_item_lap_idx]\n",
    "#         next_item = out_within_lap_spikes_overlap[:, next_item_lap_idx]\n",
    "#         out_pairwise_pair_results[:, next_item_lap_idx] = (first_item * next_item) # the result should be stored in the index of the second item, if we're doing the typical backwards style differences.\n",
    "#         # print(f'np.max(out_pairwise_pair_results[:, next_item_lap_idx]): {np.max(out_pairwise_pair_results[:, next_item_lap_idx])}')\n",
    "\n",
    "    if debug_print: \n",
    "        print(f'max out: {np.max(out_pairwise_pair_results)}')\n",
    "        \n",
    "    lap_ids \n",
    "    flat_lap_idxs = np.arange(len(lap_ids))\n",
    "    \n",
    "    \n",
    "    # add to the extant plot as a new color:\n",
    "    if plot_results:\n",
    "        for lap_idx, lap_ID in zip(flat_lap_idxs, lap_ids):\n",
    "            # curr_lap_alt_ax = axs[lap_idx]\n",
    "            if plot_horizontal:\n",
    "                curr_lap_alt_ax = axs[lap_idx].twiny()\n",
    "                curr_lap_alt_ax.plot(out_pairwise_pair_results[:, lap_idx], out_digitized_position_bins, '--r')\n",
    "            else:\n",
    "                # vertical\n",
    "                curr_lap_alt_ax = axs[lap_idx].twinx()\n",
    "                curr_lap_alt_ax.plot(out_digitized_position_bins, out_pairwise_pair_results[:, lap_idx], '--r')\n",
    "            \n",
    "    cum_laps_reliability = np.cumprod(out_within_lap_spikes_overlap, axis=1)\n",
    "    all_laps_reliability = np.prod(out_within_lap_spikes_overlap, axis=1, keepdims=True)\n",
    "    \n",
    "    if plot_results:\n",
    "        fig_result, axs_result = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(24, 40))\n",
    "        axs_result[0].plot(out_digitized_position_bins, all_laps_reliability, 'r')\n",
    "        axs_result[1].plot(out_digitized_position_bins, cum_laps_reliability, 'r')\n",
    "\n",
    "curr_result_label = 'maze1'\n",
    "sess = curr_kdiba_pipeline.filtered_sessions[curr_result_label]\n",
    "sess = curr_kdiba_pipeline.sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340e1ae-1165-4a55-b35a-73de562df226",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_laps_df = sess.laps.to_dataframe()\n",
    "curr_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00bc5e4-11cc-456f-994e-d4ae3ece2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "position_obj = sess.position\n",
    "position_obj.compute_higher_order_derivatives()\n",
    "pos_df = position_obj.compute_smoothed_position_info(N=20) ## Smooth the velocity curve to apply meaningful logic to it\n",
    "pos_df = position_obj.to_dataframe()\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58644ddd-6efe-40b7-a9c5-5971a1bc1bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, out_axes_list = plot_laps_2d(sess, legacy_plotting_mode=True)\n",
    "fig, out_axes_list = plot_laps_2d(sess, legacy_plotting_mode=False)\n",
    "out_axes_list[0].set_title('New Pho Position Thresholding Estimated Laps')\n",
    "\n",
    "curr_cell_idx = 2 \n",
    "# curr_cell_idx = 3 # good for end platform analysis\n",
    "curr_cell_ID = sess.spikes_df.spikes.neuron_ids[curr_cell_idx]\n",
    "print(f'curr_cell_idx: {curr_cell_idx}, curr_cell_ID: {curr_cell_ID}')\n",
    "\n",
    "# pre-filter by spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "filtered_spikes_df = sess.spikes_df.copy()\n",
    "time_variable_name = filtered_spikes_df.spikes.time_variable_name # 't_rel_seconds'\n",
    "\n",
    "lap_ids = sess.laps.lap_id\n",
    "# lap_flat_idxs = sess.laps.get_lap_flat_indicies(lap_ids)\n",
    "\n",
    "out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap = compute_lap_to_lap_reliability(curr_kdiba_pipeline.computation_results[curr_result_label].computed_data['pf2D'], filtered_spikes_df, lap_ids, curr_cell_idx, debug_print=False, plot_results=True);\n",
    "\n",
    "# compute_reliability_metrics(out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap, debug_print=False, plot_results=False)\n",
    "\n",
    "# # curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D'].plotRaw_v_time(curr_cell_idx)\n",
    "# _test_plotRaw_v_time(curr_kdiba_pipeline.computation_results[curr_result_label].computed_data['pf2D'], curr_cell_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e8e317-9b3c-4895-ac55-13600e8ccc47",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3D Lap Plotting Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752016f-67d4-4351-a61d-defc8a1bff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice # for Pagination class\n",
    "import pyvista as pv\n",
    "import pyvistaqt as pvqt\n",
    "from PhoGui.InteractivePlotter.Mixins.LapsVisualizationMixin import LapsVisualizationMixin\n",
    "from PhoGui.PhoCustomVtkWidgets import PhoWidgetHelper\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.spikeAndPositions import perform_plot_flat_arena, _build_flat_arena_data\n",
    "\n",
    "\"\"\" Test Drawing Spike Lines \"\"\"\n",
    "# from pyphoplacecellanalysis.Pho3D.spikes import draw_line_spike, lines_from_points\n",
    "from pyphoplacecellanalysis.Pho3D.points import interlieve_points\n",
    "\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.spikeAndPositions import build_active_spikes_plot_pointdata_df\n",
    "\n",
    "def _plot_all_lap_spikes(p, sess, included_cell_IDXs, included_lap_IDXs, debug_print=True, lap_start_z=0.0, lap_id_dependent_z_offset=10.0):\n",
    "    should_reinterpolate_spike_positions = False\n",
    "        \n",
    "    def _plot_single_spikes(p, cell_specific_spikes_dfs, placefield_cell_index):\n",
    "        curr_cell_spike_df = cell_specific_spikes_dfs[placefield_cell_index]\n",
    "        # curr_cell_spike_df['z_fixed'] = np.full_like(active_flat_df['x'].values, 1.1)\n",
    "        pdata = build_active_spikes_plot_pointdata_df(curr_cell_spike_df)\n",
    "\n",
    "        # curr_cell_spike_times = curr_cell_spike_df[curr_cell_spike_df.spikes.time_variable_name].to_numpy()  # (271,)\n",
    "        # curr_cell_spike_positions = curr_cell_spike_df['x','y'].to_numpy()  # (271,)\n",
    "\n",
    "        # lines_from_points(\n",
    "        # p[0,0].add_points(pdata, name='plot_single_spikes_points', render_points_as_spheres=True, point_size=5.0)\n",
    "\n",
    "        # Build offset points and spike data:\n",
    "        spike_height = max((lap_id_dependent_z_offset * 0.6), 0.5) # half the line height\n",
    "\n",
    "        # start_points = pdata.points.copy()\n",
    "        # end_points = start_points.copy()\n",
    "        # # end_points[:,2] # get z values\n",
    "        # end_points[:,2] = end_points[:,2] + spike_height\n",
    "        # all_points = interlieve_points(start_points, end_points)\n",
    "        # lines_poly_data = pv.PolyData()\n",
    "        # lines_poly_data.points = all_points\n",
    "        # # cells = np.hstack(([2, 0, 1],[2, 1, 2]))\n",
    "        # num_lines = np.shape(start_points)[0]\n",
    "        # cells = [[2, 2*i, 2*i+1] for i in np.arange(num_lines)]\n",
    "        # lines_poly_data.lines = cells\n",
    "        \n",
    "        p[0,0].add_mesh(pdata, name=f'plot_single_spikes_points[{placefield_cell_index}]', render_points_as_spheres=True, point_size=5.0, color='white')        \n",
    "        \n",
    "        # p[0,0].add_points(pdata, name=f'plot_single_spikes_points[{placefield_cell_index}]', render_points_as_spheres=True, point_size=5.0)\n",
    "        # p[0,0].add_mesh(lines_poly_data, name=f'plot_single_spikes_lines[{placefield_cell_index}]', render_points_as_spheres=False, point_size=5.0)\n",
    "        # return {'pdata':pdata, 'lines_poly_data':lines_poly_data}\n",
    "        \n",
    "        return {'pdata':pdata}\n",
    "    \n",
    "    time_variable_name = sess.spikes_df.spikes.time_variable_name # 't_rel_seconds'\n",
    "    # sets the 'z_fixed' value for all spikes in sess.spikes_df, which will be used to plot them as points\n",
    "    sess.spikes_df['z'] = lap_start_z + (lap_id_dependent_z_offset * sess.spikes_df.lap.to_numpy())\n",
    "\n",
    "    if debug_print:\n",
    "        print(f'sess.laps.lap_id: {sess.laps.lap_id}')\n",
    "        \n",
    "    included_cell_IDXs = np.array(included_cell_IDXs)\n",
    "    included_lap_IDXs = np.array(included_lap_IDXs)\n",
    "    \n",
    "    # ensure that only lap_ids included in this session are used:\n",
    "    included_lap_ids = sess.laps.lap_id[included_lap_IDXs]\n",
    "    possible_included_lap_ids = np.unique(sess.spikes_df.lap.values)\n",
    "    if debug_print:\n",
    "        print(f'np.unique(sess.spikes_df.lap.values): {np.unique(sess.spikes_df.lap.values)}')\n",
    "    included_lap_ids = included_lap_ids[np.isin(included_lap_ids, possible_included_lap_ids)]\n",
    "    if debug_print:\n",
    "        print(f'included_lap_ids: {included_lap_ids}')\n",
    "    \n",
    "    # get the included cell IDs\n",
    "    included_cell_IDs = np.array(sess.spikes_df.spikes.neuron_ids)[included_cell_IDXs]\n",
    "        \n",
    "    # print(np.isin(['R','G','B','render_opacity'], sess.spikes_df.columns).all())\n",
    "\n",
    "    # POSITIONS:\n",
    "    curr_position_df, lap_specific_position_dfs, lap_specific_time_ranges, lap_specific_position_traces = LapsVisualizationMixin._compute_laps_position_data(sess)\n",
    "    \n",
    "    # SPIKES:\n",
    "    # # grouped by lap\n",
    "    # lap_grouped_spikes_df = sess.spikes_df.groupby('lap')\n",
    "    # lap_specific_spikes_dfs = [lap_grouped_spikes_df.get_group(i)[[time_variable_name,'aclu','lap','flat_spike_idx','cell_type','x','y','lin_pos','z']] for i in included_lap_ids] # dataframes split for each ID:\n",
    "\n",
    "    # grouped by cell:\n",
    "    # pre-filter by spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "    filtered_spikes_df = sess.spikes_df.copy()\n",
    "    filtered_spikes_df = filtered_spikes_df[np.isin(filtered_spikes_df['lap'], included_lap_ids)] # get only the spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "    \n",
    "    \n",
    "    # Interpolate the spikes positions again:\n",
    "    if should_reinterpolate_spike_positions:\n",
    "        print('Re-interpolating spike positions...')\n",
    "        filtered_spikes_df = filtered_spikes_df.spikes.interpolate_spike_positions(curr_position_df['t'].to_numpy(), curr_position_df['x'].to_numpy(), curr_position_df['y'].to_numpy())\n",
    "        # filtered_spikes_df = FlattenedSpiketrains.interpolate_spike_positions(filtered_spikes_df, session.position.time, session.position.x, session.position.y, spike_timestamp_column_name=time_variable_name)\n",
    "    \n",
    "    cell_grouped_spikes_df = filtered_spikes_df.groupby('aclu')\n",
    "    cell_specific_spikes_dfs = [cell_grouped_spikes_df.get_group(i)[[time_variable_name,'aclu','lap','flat_spike_idx','cell_type','x','y','lin_pos','z']] for i in included_cell_IDs] # dataframes split for each ID:\n",
    "\n",
    "    # lap_specific_position_dfs = _compute_laps_position_data(sess)\n",
    "\n",
    "    # # Positions:\n",
    "    # curr_position_df = sess.compute_position_laps()\n",
    "    # included_pos_lap_ids = np.unique(curr_position_df.lap.values)\n",
    "    # print(f'np.unique(curr_position_df.lap.values): {np.unique(curr_position_df.lap.values)}')\n",
    "    # included_pos_lap_ids = included_pos_lap_ids[np.isin(included_pos_lap_ids, sess.laps.lap_id)]\n",
    "    # included_pos_lap_ids\n",
    "\n",
    "    # print(f'included_pos_lap_ids: {included_pos_lap_ids}')\n",
    "\n",
    "    # lap_grouped_position_df = curr_position_df.groupby('lap')\n",
    "    # lap_specific_position_dfs = [lap_grouped_position_df.get_group(i)[['t','aclu','x','y','lin_pos']] for i in included_lap_ids] # dataframes split for each ID:\n",
    "\n",
    "    for i, curr_cell_ID in enumerate(included_cell_IDs):\n",
    "        plot_data_dict = _plot_single_spikes(p, cell_specific_spikes_dfs, i)\n",
    "\n",
    "\n",
    "# sess = curr_kdiba_pipeline.filtered_sessions['maze']\n",
    "# included_cell_IDXs = [6]\n",
    "# included_lap_IDXs = [2, 3]\n",
    "# _plot_all_lap_spikes(pActiveInteractiveLapsPlotter, sess, included_cell_IDXs, included_lap_IDXs)\n",
    "\n",
    "from PhoGui.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer\n",
    "\n",
    "lap_start_z = 0.0\n",
    "# lap_id_dependent_z_offset = 0.0\n",
    "lap_id_dependent_z_offset = 3.0\n",
    "# curr_kdiba_pipeline.active_configs['maze1'].lap_id_dependent_z_offset = 3.0\n",
    "\n",
    "def _display_testing(sess, computation_result, active_config, extant_plotter=None):\n",
    "    \"\"\" Testing of plot_lap_trajectories_2d \"\"\"\n",
    "    print(f'active_config.plotting_config: {active_config.plotting_config}')\n",
    "    single_combined_plot=True\n",
    "    if single_combined_plot:\n",
    "        default_plotting = True\n",
    "    else:\n",
    "        default_plotting = False\n",
    "    active_config.plotting_config.plotter_type = 'MultiPlotter'\n",
    "    print(f'active_config.plotting_config: {active_config.plotting_config}')\n",
    "    iplapsDataExplorer = InteractiveCustomDataExplorer(active_config, sess, extant_plotter=extant_plotter)\n",
    "    pActiveInteractiveLapsPlotter = iplapsDataExplorer.plot(pActivePlotter=extant_plotter, default_plotting=default_plotting)\n",
    "    # included_cell_idxs = None\n",
    "    included_cell_idxs = [0, 1]\n",
    "    # included_lap_idxs = [2, 5, 9, 12]\n",
    "    included_lap_idxs = [2]\n",
    "    # All\n",
    "    # included_cell_idxs = np.arange(len(sess.spikes_df.spikes.neuron_ids))\n",
    "    # included_lap_idxs = np.arange(len(sess.laps.lap_id))\n",
    "    from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_3d\n",
    "    pActiveInteractiveLapsPlotter, laps_pages = plot_lap_trajectories_3d(sess, curr_num_subplots=5, active_page_index=0, included_lap_idxs=included_lap_idxs, single_combined_plot=single_combined_plot, \n",
    "                                                                         lap_start_z = lap_start_z, lap_id_dependent_z_offset = lap_id_dependent_z_offset,\n",
    "                                                                         existing_plotter=pActiveInteractiveLapsPlotter)\n",
    "\n",
    "    # add the spikes for the curves:\n",
    "    _plot_all_lap_spikes(pActiveInteractiveLapsPlotter, sess, included_cell_idxs, included_lap_idxs, lap_start_z=lap_start_z, lap_id_dependent_z_offset=lap_id_dependent_z_offset)\n",
    "    return iplapsDataExplorer, pActiveInteractiveLapsPlotter\n",
    "\n",
    "\n",
    "# curr_kdiba_pipeline.computation_results['maze1'].computation_config\n",
    "# curr_kdiba_pipeline.computation_results['maze1'].sess.config\n",
    "# curr_kdiba_pipeline.active_configs['maze1']\n",
    "\n",
    "curr_result_label = 'maze1'\n",
    "sess = curr_active_pipeline.filtered_sessions[curr_result_label]\n",
    "sess = curr_active_pipeline.sess\n",
    "\n",
    "pActiveInteractiveLapsPlotter = None\n",
    "try: pActiveInteractiveLapsPlotter\n",
    "except NameError: pActiveInteractiveLapsPlotter = None # Checks variable p's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "iplapsDataExplorer, pActiveInteractiveLapsPlotter = _display_testing(sess, curr_active_pipeline.computation_results[curr_result_label], curr_active_pipeline.active_configs[curr_result_label],\n",
    "                                                                     extant_plotter=pActiveInteractiveLapsPlotter)\n",
    "pActiveInteractiveLapsPlotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e5881e-3e37-4d8b-b5c3-0c8837cbd1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines_from_points(pdata.points)\n",
    "\n",
    "np.shape(all_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580c6e6-38b1-4d6e-bf09-6b60842a922a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a0d93-16ac-4240-a373-7bd9f337f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, laps_pages = _plot_lap_trajectories_combined_plot_3d(curr_kdiba_pipeline.sess, curr_num_subplots=5, single_combined_plot=False)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86802581-69ea-4aca-a673-e4e306d6e17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phoviz_ultimate]",
   "language": "python",
   "name": "conda-env-phoviz_ultimate-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
