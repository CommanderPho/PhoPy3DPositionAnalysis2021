{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ce022a",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from attrs import define, field, fields, Factory\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T16:05:43.785201Z",
     "start_time": "2023-07-29T16:05:34.880381100Z"
    },
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "WARNING: changed_filters_names_list > 0!: ['maze1', 'maze2', 'maze'] but these filters are in the changed_filters_ignore_list: ['maze1', 'maze2', 'maze']\n",
      "ignored_changed_filters_list: ['maze1', 'maze2', 'maze']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\global_computation_results.pkl... done.\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis already computed.\n",
      "long_short_fr_indicies_analyses already computed.\n",
      "long_short_decoding_analyses already computed.\n",
      "long_short_post_decoding already computed.\n",
      "long_short_inst_spike_rate_groups already computed.\n",
      "done with all batch_extended_computations(...).\n",
      "no changes in global results.\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "from pyphocorehelpers.print_helpers import CapturedException\n",
    "\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # DONE. Very good. Many good Pfs, many good replays.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # DONE, might be the BEST SESSION, good example session with lots of place cells, clean replays, and clear bar graphs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD, 2023-07-14, unsure why still.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays!\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE, Added replay selections. Very \"jumpy\" between the starts and ends of the track.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # DONE, Added replay selections. A TON of putative replays in general, most bad, but some good.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # DONE, added replay selections. Very few (like 12) replays each.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3') # DONE, Good Pfs, no good epochs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') # DONE, okay replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # DONE, very few replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # DONE, one replay each (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # BAD, Good Pfs strangely despite horrible map, no good epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # DONE, good. Many good pfs, many good replays.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE, good?, replays selected, few\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE, very few replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # DONE, replays selected, quite a few replays but few are very good.\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # # Force write:\n",
    "# # # saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=[#'_perform_estimated_epochs_computation',  # AL:WAYS OFF\n",
    "                                            '_perform_baseline_placefield_computation',\n",
    "                                        # '_perform_time_dependent_placefield_computation', # AL:WAYS OFF\n",
    "                                        '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        # '_perform_time_dependent_pf_sequential_surprise_computation' # AL:WAYS OFF\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding' # AL:WAYS OFF\n",
    "                                    ]\n",
    "# active_computation_functions_name_includelist=['_perform_baseline_placefield_computation']\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=False) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        curr_active_pipeline.load_pickled_global_computation_results()\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "# 6m 1.1s\n",
    "# 12m 15.6s\n",
    "\n",
    "try:\n",
    "    ## Post Compute Validate 2023-05-16:\n",
    "    was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated\n",
    "    if was_updated:\n",
    "        try:\n",
    "            curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "        except Exception as e:\n",
    "            ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "    curr_active_pipeline.reload_default_computation_functions()\n",
    "    extended_computations_include_includelist=['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', \n",
    "    #  'long_short_rate_remapping',\n",
    "     'long_short_inst_spike_rate_groups'\n",
    "    ] # do only specifiedl , 'long_short_rate_remapping'\n",
    "    force_recompute_global = force_reload\n",
    "    # force_recompute_global = True\n",
    "    newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=force_recompute_global, debug_print=False)\n",
    "    if (len(newly_computed_values) > 0) and (saving_mode.value != 'skip_saving'):\n",
    "        print(f'newly_computed_values: {newly_computed_values}. Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'no changes in global results.')\n",
    "\n",
    "except Exception as e:\n",
    "    exception_info = sys.exc_info()\n",
    "    e = CapturedException(e, exception_info)\n",
    "    print(f'second half threw: {e}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c850782f",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87dc7ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n"
     ]
    }
   ],
   "source": [
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "## Extract variables from results object:\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global\n",
    "\n",
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result.Flat_epoch_time_bins_mean, expected_v_observed_result.Flat_decoder_time_bin_centers, expected_v_observed_result.num_neurons, expected_v_observed_result.num_timebins_in_epoch, expected_v_observed_result.num_total_flat_timebins, expected_v_observed_result.is_short_track_epoch, expected_v_observed_result.is_long_track_epoch, expected_v_observed_result.short_short_diff, expected_v_observed_result.long_long_diff\n",
    "\n",
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.rdf.rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaef94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_Converter\n",
    "\n",
    "# Generate the unique aclus\n",
    "_neuron_replay_stats_df = deepcopy(jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "_neuron_replay_stats_df\n",
    "\n",
    "# _neuron_replay_stats_df = prepare_neuron_indexed_dataframe_for_hdf(_neuron_replay_stats_df, active_context=curr_active_pipeline.get_session_context(), aclu_column_name=None)\n",
    "\n",
    "\n",
    "_neuron_replay_stats_df = HDF_Converter.prepare_neuron_indexed_dataframe_for_hdf(_neuron_replay_stats_df, active_context=curr_active_pipeline.get_session_context(), aclu_column_name=None)\n",
    "\n",
    "\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context()\n",
    "# sess_specific_aclus = list(_neuron_replay_stats_df.index.to_numpy())\n",
    "# session_ctxt_key:str = active_context.get_description(separator='|', subset_includelist=IdentifyingContext._get_session_context_keys())\n",
    "\n",
    "# # Adds column columns=['neuron_uid', 'session_uid', 'aclu']\n",
    "# _neuron_replay_stats_df['aclu'] = sess_specific_aclus # _neuron_replay_stats_df.index.to_numpy() # add explicit 'aclu' column from index\n",
    "# _neuron_replay_stats_df['session_uid'] = session_ctxt_key # add fixed 'session_uid' column \n",
    "# _neuron_replay_stats_df['neuron_uid'] = [f\"{session_ctxt_key}|{aclu}\" for aclu in sess_specific_aclus]\n",
    "_neuron_replay_stats_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3725c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# _out = curr_active_pipeline.last_added_display_output\n",
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_out = curr_active_pipeline.display('_display_long_short_expected_v_observed_firing_rate')\n",
    "# a_fig = _out.figures[0]\n",
    "# a_fig.show()\n",
    "# .show()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline._export_global_computations_to_hdf(file_path='output/test_global_computations_result.h5', key='test')\n",
    "\n",
    "# Export the pipeline's HDF5:\n",
    "hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('pipeline_results.h5').resolve()\n",
    "print(f'pipeline hdf5_output_path: {hdf5_output_path}')\n",
    "curr_active_pipeline.to_hdf(file_path=hdf5_output_path, key='/')\n",
    "\n",
    "# jonathan_firing_rate_analysis_result.to_hdf(file_path='output/test_jonathan_firing_rate_analysis_result.h5', key='test_jonathan_firing_rate_analysis_result')\n",
    "\n",
    "# curr_active_pipeline.get_ou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d317ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pathlib\n",
    "from pyphoplacecellanalysis.General.Batch.BatchFilesystemFinders import find_externally_computed_session_h5_files\n",
    "# pipeline_results.h5\n",
    "\n",
    "# Find all previously computed ripple data:\n",
    "\n",
    "\n",
    "global_data_root_parent_path\n",
    "find_externally_computed_session_h5_files(global_data_root_parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99853912",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to get those Fork\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bee8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_v_observed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff1bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_remapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the `long_short_decoding_analyses` global result to access `long_results_obj.active_filter_epochs`:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratemap\n",
    "# ratemap = deepcopy(long_pf1D.ratemap)\n",
    "\n",
    "ratemap: Ratemap = deepcopy(long_pf2D.ratemap)\n",
    "ratemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f004da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "\n",
    "\n",
    "# ratemap.to_hdf('output/test_ratemap.h5', key='ratemap', file_mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3eb175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot long|short firing rate index:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_index, y_frs_index = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']\n",
    "\n",
    "# final_context = active_context.adding_context('display_fn', display_fn_name='display_long_short_laps')\n",
    "# fig = _plot_long_short_firing_rate_indicies(x_frs_index, y_frs_index, final_context, debug_print=debug_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf62bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_fr_indicies_analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_test_file_path = Path(f'output/test_long_short_fr_indicies_analysis_results.h5').resolve()\n",
    "h5_test_file_path\n",
    "long_short_fr_indicies_analysis_results.to_hdf(h5_test_file_path, key='long_short_fr_indicies_analysis_results')\n",
    "\n",
    "# jonathan_firing_rate_analysis_result.is_hdf_serializable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h5_test_file_path = Path(f'output/test_long_short_decoding_analyses.h5').resolve()\n",
    "h5_test_file_path\n",
    "curr_long_short_decoding_analyses.to_hdf(h5_test_file_path, key='long_short_decoding_analyses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import LeaveOneOutDecodingResult, LeaveOneOutDecodingAnalysisResult, TimebinnedNeuronActivity, _convert_dict_to_hdf_attrs_fn\n",
    "\n",
    "# curr_long_short_decoding_analyses.long_results_obj.new_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a593865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'type(curr_long_short_decoding_analyses.long_results_obj): {type(curr_long_short_decoding_analyses.long_results_obj)}')\n",
    "h5_test_file_path = Path(f'output/test_LeaveOneOutDecodingAnalysisResult.h5').resolve()\n",
    "curr_long_short_decoding_analyses.long_results_obj.to_hdf(h5_test_file_path, key='long_results_obj')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe4a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_long_short_decoding_analyses.short_results_obj.to_hdf(h5_test_file_path, key='short_results_obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4985e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_obj = deepcopy(curr_long_short_decoding_analyses.long_results_obj.timebinned_neuron_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.hstack((_obj.active_IDXs, _obj.inactive_IDXs))\n",
    "\n",
    "[np.hstack((a_v, i_v)) for a_v, i_v in zip(_obj.active_IDXs, _obj.inactive_IDXs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90541e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimebinnedNeuronActivity\n",
    "h5_test_file_path = Path(f'output/test_TimebinnedNeuronActivity.h5').resolve()\n",
    "curr_long_short_decoding_analyses.long_results_obj.timebinned_neuron_info.to_hdf(h5_test_file_path, key='timebinned_neuron_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'type(curr_long_short_decoding_analyses.long_results_obj.new_result): {type(curr_long_short_decoding_analyses.long_results_obj.new_result)}')\n",
    "h5_test_file_path = Path(f'output/test_LeaveOneOutDecodingResult.h5').resolve()\n",
    "curr_long_short_decoding_analyses.long_results_obj.new_result.to_hdf(h5_test_file_path, key='new_result', file_mode='r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_long_short_decoding_analyses.short_results_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.rdf.rdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a028cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from neuropy.core.neurons import NeuronType\n",
    "\n",
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "\n",
    "h5_test_file_path = Path(f'output/test_jonathan_firing_rate_analysis_result.h5').resolve()\n",
    "h5_test_file_path\n",
    "jonathan_firing_rate_analysis_result.to_hdf(h5_test_file_path, key='jonathan_firing_rate_analysis_result')\n",
    "\n",
    "# jonathan_firing_rate_analysis_result.is_hdf_serializable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4506ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "aclu_to_idx = jonathan_firing_rate_analysis_result.rdf.aclu_to_idx\n",
    "aclu_to_idx_df: pd.DataFrame = pd.DataFrame({'aclu': list(aclu_to_idx.keys()), 'fragile_linear_idx': list(aclu_to_idx.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a867b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# I wanna look at the suprise metrics again please.\n",
    "\n",
    "# can align each of the sessions (across days) to the track transition point (the \"Delta\") as the zero.\n",
    "\n",
    "# print_keys_if_possible(\"global_computation_results\", curr_active_pipeline.global_computation_results, max_depth=2)\n",
    "\n",
    "# computed_data: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "# \t\t│   ├── jonathan_firing_rate_analysis: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "# \t\t│   ├── long_short_fr_indicies_analysis: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "# \t\t│   ├── long_short_leave_one_out_decoding_analysis: pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.LeaveOneOutDecodingAnalysis\n",
    "# \t\t│   ├── long_short_post_decoding: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "\n",
    "\n",
    "print_keys_if_possible(\"global_computation_results\", curr_active_pipeline.global_computation_results.computed_data, max_depth=3)\n",
    "\n",
    "# jonathan_firing_rate_analysis_result.rdf\n",
    "\n",
    "# long_short_leave_one_out_decoding_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d775a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data.long_short_fr_indicies_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbef865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCRATCH.PhoObjectBrowser_JupyterWidget import ObjectBrowser\n",
    "\n",
    "browser = ObjectBrowser(object_to_browse=curr_active_pipeline.global_computation_results.computed_data)\n",
    "browser.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data.long_short_post_decoding.expected_v_observed_result\n",
    "# curr_active_pipeline.global_computation_results.computed_data.long_short_post_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab6f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed529276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative partition\n",
    "curr_active_pipeline.global_computation_results.computed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1267131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data.long_short_post_decoding.expected_v_observed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data.long_short_post_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f26386",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data.long_short_post_decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ccd8f7",
   "metadata": {},
   "source": [
    "# 2023-08-11 - Use `asdict(...)` like interface to provide conversion from various pipeline results to HDF5\n",
    "\tAllows user to providee a `def value_serializer(obj, field, value)` callback that is used to convert each leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import custom_tree_formatter, debug_dump_object_member_shapes\n",
    "from attrs import asdict, astuple\n",
    "# from attr._funcs import _asdict_anything\n",
    "from neuropy.core.session.Formats.SessionSpecifications import ParametersContainer\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "\n",
    "\n",
    "def value_serializer(obj, field, value):\n",
    "    \"\"\" called for each key. Takes a value, and returns an updated value \"\"\"\n",
    "    print(f'value_serializer(obj, field: \"{field}\", value)')\n",
    "    return value\n",
    "    # if value is None:\n",
    "    #     return None\n",
    "    # else:\n",
    "    #     ## Non-None value\n",
    "    #     if isinstance(value, DynamicContainer):\n",
    "    #         return value.to_dict()\n",
    "    #     else:\n",
    "    #         return value # return value unchanged\n",
    "\n",
    "\n",
    "def custom_asdict(inst, recurse=True, filter=None, dict_factory=dict, retain_collection_types=False, value_serializer=None):\n",
    "    def _custom_asdict_asdict_anything(v, filter, dict_factory, retain_collection_types, value_serializer):\n",
    "        if isinstance(v, dict):\n",
    "            df = dict_factory\n",
    "            return df(\n",
    "                (\n",
    "                    _custom_asdict_asdict_anything(kk, filter, dict_factory, retain_collection_types, value_serializer),\n",
    "                    _custom_asdict_asdict_anything(vv, filter, dict_factory, retain_collection_types, value_serializer),\n",
    "                )\n",
    "                for kk, vv in v.items()\n",
    "            )\n",
    "        elif isinstance(v, (tuple, list, set, frozenset)):\n",
    "            cf = v.__class__ if retain_collection_types is True else list\n",
    "            return cf(\n",
    "                _custom_asdict_asdict_anything(i, filter, dict_factory, retain_collection_types, value_serializer)\n",
    "                for i in v\n",
    "            )\n",
    "        elif hasattr(v, \"__dict__\") and recurse:\n",
    "            return custom_asdict(v, recurse, filter, dict_factory, retain_collection_types, value_serializer)\n",
    "        else:\n",
    "            return v\n",
    "\n",
    "    rv = dict_factory()\n",
    "    if isinstance(inst, dict):\n",
    "        attrs = inst.items()\n",
    "    elif hasattr(inst, \"__dict__\"):\n",
    "        attrs = inst.__dict__.items()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported object type.\")\n",
    "\n",
    "    for k, v in attrs:\n",
    "        if filter is not None and not filter(k, v):\n",
    "            continue\n",
    "\n",
    "        if value_serializer is not None:\n",
    "            v = value_serializer(inst, k, v)\n",
    "\n",
    "        rv[k] = _custom_asdict_asdict_anything(v, filter, dict_factory, retain_collection_types, value_serializer)\n",
    "\n",
    "    return rv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "global_computations_results = curr_active_pipeline.global_computation_results.computed_data\n",
    "# global_computations_results_dict: dict = custom_asdict(global_computations_results, recurse=True, value_serializer=value_serializer)\n",
    "\n",
    "\n",
    "a_sess_config = curr_active_pipeline.sess.config # SessionConfig\n",
    "\n",
    "custom_preprocessing_parameters_dict: dict = custom_asdict(a_sess_config.preprocessing_parameters, recurse=True, value_serializer=value_serializer)\n",
    "custom_preprocessing_parameters_dict\n",
    "\n",
    "preprocessing_parameters_dict: dict = asdict(a_sess_config.preprocessing_parameters, recurse=True, value_serializer=value_serializer)\n",
    "preprocessing_parameters_dict\n",
    "# print_object_memory_usage(global_computations_results) # 9237.906241 MB\n",
    "\n",
    "global_computations_results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6817eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(obj, parent_key='', separator='_'):\n",
    "\titems = {}\n",
    "\tif isinstance(obj, dict):\n",
    "\t\tattributes = obj.items()\n",
    "\telif hasattr(obj, 'to_dict'):\n",
    "\t\tattributes = obj.to_dict().items() # convert to dict using the to_dict() method.\n",
    "\telif hasattr(obj, \"__dict__\"):\n",
    "\t\tattributes = obj.__dict__.items()\n",
    "\telse:\n",
    "\t\t# print(f'unhandled object type: {type(obj)} for parent_key: {parent_key}')\n",
    "\t\t# raise ValueError(\"Unsupported object type.\")\n",
    "\t\t# return {}\n",
    "\t\treturn {parent_key:obj} # return a dict containing no items? Or the scalar?\n",
    "\n",
    "\tfor k, v in attributes:\n",
    "\t\tnew_key = f\"{parent_key}{separator}{k}\" if parent_key else k\n",
    "\t\tif isinstance(v, (dict, object)) and not isinstance(v, (str, bytes)):\n",
    "\t\t\titems.update(flatten(v, new_key, separator=separator))\n",
    "\t\telse:\n",
    "\t\t\titems[new_key] = v\n",
    "\n",
    "\treturn items\n",
    "\n",
    "\n",
    "# flatten(a_sess_config.preprocessing_parameters, parent_key='preprocessing_parameters', separator='/')\n",
    "flatten(global_computations_results, parent_key='global_computations_results', separator='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ead80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('global_computations_results', global_computations_results.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fecad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter\n",
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=Path('EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation'), doc_name='global_computations_results_data')\n",
    "doc_printer.save_documentation('global_computations_results_data', global_computations_results, non_expanded_item_keys=['_reverse_cellID_index_map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28565fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_leave_one_out_decoding_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d513e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for `_display_long_and_short_firing_rate_replays_v_laps`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "jonathan_firing_rate_analysis_result\n",
    "# (fig_L, ax_L, active_display_context_L), (fig_S, ax_S, active_display_context_S), _perform_write_to_file_callback = _plot_session_long_short_track_firing_rate_figures(curr_active_pipeline, jonathan_firing_rate_analysis_result, defer_render=defer_render)\n",
    "\n",
    "\n",
    "# JonathanFiringRateAnalysisResult\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f045216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytree as ipyt\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.print_helpers import build_tree\n",
    "\n",
    "# Assume curr_computations_results is the root of the data structure you want to explore\n",
    "root_data = jonathan_firing_rate_analysis_result.__dict__\n",
    "root_node = ipyt.Node('jonathan_firing_rate_analysis_result')\n",
    "build_tree(root_node, root_data)\n",
    "\n",
    "tree = ipyt.Tree()\n",
    "tree.add_node(root_node)\n",
    "display(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dce4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import custom_tree_formatter, debug_dump_object_member_shapes\n",
    "\n",
    "from attrs import asdict, astuple\n",
    "\n",
    "\n",
    "# LeaveOneOutDecodingAnalysis\n",
    "\n",
    "\n",
    "# asdict(jonathan_firing_rate_analysis_result, )\n",
    "\n",
    "# debug_dump_object_member_shapes(asdict(jonathan_firing_rate_analysis_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d9f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible(\"jonathan_firing_rate_analysis_result\", jonathan_firing_rate_analysis_result.__dict__, custom_item_formatter=custom_tree_formatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d9c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_fr_indicies_analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Surprise revisited:\n",
    "# _display_short_long_firing_rate_index_comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757eeafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = curr_active_pipeline.__dict__.copy()\n",
    "state = curr_active_pipeline.__getstate__()\n",
    "print_object_memory_usage(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd6024",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_file_path = Path('output/test_all_neuron_identities_out.h5')\n",
    "print(f'common_file_path: {common_file_path}')\n",
    "session_context = curr_active_pipeline.get_session_context() \n",
    "session_group_key: str = \"/\" + session_context.get_description(separator=\"/\", include_property_names=False) # 'kdiba/gor01/one/2006-6-08_14-26-15'\n",
    "session_uid: str = session_context.get_description(separator=\"|\", include_property_names=False)\n",
    "\n",
    "AcrossSessionsResults.build_neuron_identity_table_to_hdf(common_file_path, key=session_group_key, spikes_df=curr_active_pipeline.sess.spikes_df, session_uid=session_uid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccdbb13",
   "metadata": {
    "tags": [
     "NOW",
     "across_sessions",
     "table"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, InstantaneousFiringRatesDataframeAccessor, InstantaneousSpikeRateGroupsComputation, trackMembershipTypesEnum, trackExclusiveToMembershipTypeDict, trackExclusiveToMembershipTypeReverseDict\n",
    "\n",
    "# ## Specify the output file:\n",
    "# common_file_path = Path('output/test_across_session_scatter_plot_new.h5')\n",
    "# print(f'common_file_path: {common_file_path}')\n",
    "# InstantaneousFiringRatesDataframeAccessor.add_results_to_inst_fr_results_table(curr_active_pipeline, common_file_path, file_mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d33a7c",
   "metadata": {
    "tags": [
     "NOW",
     "load",
     "plot"
    ]
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pyphocorehelpers.indexing_helpers import partition, safe_pandas_get_group\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor, AcrossSessionsVisualizations\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import SingleBarResult\n",
    "\n",
    "common_file_path = Path('output/active_across_session_scatter_plot_results.h5')\n",
    "print(f'common_file_path: {common_file_path}')\n",
    "\n",
    "# InstantaneousSpikeRateGroupsComputation, : pd.DataFrame\n",
    "_shell_obj, loaded_result_df = InstantaneousFiringRatesDataframeAccessor.load_and_prepare_for_plot(common_file_path)\n",
    "# Perform the actual plotting:\n",
    "AcrossSessionsVisualizations.across_sessions_bar_graphs(_shell_obj, num_sessions=13, save_figure=False, enable_tiny_point_labels=False, enable_hover_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeaf036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88b5c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e464234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print_object_memory_usage(curr_active_pipeline) # 8857.609407 MB\n",
    "print_object_memory_usage(jonathan_firing_rate_analysis_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31180478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output structure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c3eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_man: FileOutputManager = curr_active_pipeline.get_output_manager()\n",
    "out_man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb580a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "maximum_timedelta: timedelta = timedelta(1, 0, 0) # 1 Day maximum time\n",
    "delta_since_last_compute: timedelta = curr_active_pipeline.get_time_since_last_computation()\n",
    "print(f'delta_since_last_compute: {delta_since_last_compute}')\n",
    "needs_recompute: bool = delta_since_last_compute > maximum_timedelta\n",
    "print(f'\\tneeds_recompute: {needs_recompute}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea2e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_inst_fr_comps\n",
    "\n",
    "long_pf1D.neuron_extended_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c0e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the pipeline's HDF5:\n",
    "hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('pipeline_results.h5').resolve()\n",
    "print(f'pipeline hdf5_output_path: {hdf5_output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f70df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AcrossSessionsResults.build_session_pipeline_to_hdf(hdf5_output_path, \"/\", curr_active_pipeline, debug_print=False) # coulduse key of \"/{curr_session_context}\" with context properly expanded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e75f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "inst_fr_groups_result: InstantaneousSpikeRateGroupsComputation = curr_active_pipeline.global_computation_results.computed_data.long_short_inst_spike_rate_groups\n",
    "inst_fr_groups_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf9baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove computation times containing this function:\n",
    "\n",
    "\n",
    "# curr_active_pipeline.global_computation_results.computation_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da69537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_perform_long_short_instantaneous_spike_rate_groups_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864f9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the result\n",
    "del curr_active_pipeline.global_computation_results.computed_data['long_short_inst_spike_rate_groups']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0218599",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_global_computation_function_dict['_perform_long_short_instantaneous_spike_rate_groups_analysis']\n",
    "\n",
    "'_perform_long_short_instantaneous_spike_rate_groups_analysis'\n",
    "\n",
    "# curr_active_pipeline.registered_global_computation_function_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53647867",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results\n",
    "# curr_active_pipeline.save_global_computation_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "from neuropy.utils.mixins.print_helpers import ProgressMessagePrinter\n",
    "# import dill as pickle # requires mamba install dill -c conda-forge\n",
    "\n",
    "# db = deepcopy(curr_active_pipeline.global_computation_results)\n",
    "# db = curr_active_pipeline.global_computation_results.to_dict().copy()\n",
    "db = curr_active_pipeline.global_computation_results.computed_data.to_dict().copy() # ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analysis', 'long_short_leave_one_out_decoding_analysis', 'long_short_post_decoding']\n",
    "del db['long_short_leave_one_out_decoding_analysis']  # PicklingError: Can't pickle .set_closure_cell at 0x000001EE71B0BA60>: it's not found as attr._compat.make_set_closure_cell..set_closure_cell\n",
    "# del db['long_short_post_decoding']\n",
    "pkl_path = Path('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/test_global_computation_results.pkl').resolve()\n",
    "file_mode = 'w+b' # 'w+b' opens and truncates the file to 0 bytes (overwritting)\n",
    "with ProgressMessagePrinter(pkl_path, f\"Saving (file mode '{file_mode}')\", 'saved session pickle file'):\n",
    "\twith open(pkl_path, file_mode) as dbfile: \n",
    "\t\t# source, destination\n",
    "\t\tdill.dump(db, dbfile)\n",
    "\t\tdbfile.close()\n",
    "\n",
    "# dill.extend(use_dill=True)\n",
    "\n",
    "# dill.extend\n",
    "# dill.pickles(db['computation_times'].to_dict()) # tests if object will pickle before trying it\n",
    "# dill.pickles(db['computation_config'].to_dict()) # tests if object will pickle before trying it\n",
    "# dill.pickles(db) # FAILS\n",
    "\n",
    "# dill.detect.baditems(db)\n",
    "# dill.detect.badobjects(db['long_short_post_decoding'], depth=0) \n",
    "# dill.detect.badtypes(db, depth=0) # dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = curr_active_pipeline.global_computation_results.computed_data.to_dict().copy()\n",
    "# db = curr_active_pipeline.global_computation_results.computed_data\n",
    "print(list(db.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the pipeline's HDF5:\n",
    "hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('pipeline_results.h5').resolve()\n",
    "print(f'pipeline hdf5_output_path: {hdf5_output_path}')\n",
    "AcrossSessionsResults.build_session_pipeline_to_hdf(hdf5_output_path, \"/\", curr_active_pipeline, debug_print=False) # coulduse key of \"/{curr_session_context}\" with context properly expanded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ead428",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_context = curr_active_pipeline.get_session_context() \n",
    "session_group_key: str = \"/\" + session_context.get_description(separator=\"/\", include_property_names=False) # 'kdiba/gor01/one/2006-6-08_14-26-15'\n",
    "session_uid: str = session_context.get_description(separator=\"|\", include_property_names=False)\n",
    "print(f'session_group_key: {session_group_key}')\n",
    "print(f'session_uid: {session_uid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cdee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to get the outputs produced on GreatLakes as a filelist\n",
    "\n",
    "\n",
    "## Session folder .h5 exports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc84e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.session.Formats.SessionSpecifications import ParametersContainer\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "\n",
    "from attrs import asdict\n",
    "\n",
    "# a_sess_config.preprocessing_parameters.to_dict()\n",
    "\n",
    "def value_serializer(obj, field, value):\n",
    "    \"\"\" called for each key. Takes a value, and returns an updated value \"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "    else:\n",
    "        ## Non-None value\n",
    "        if isinstance(value, DynamicContainer):\n",
    "            return value.to_dict()\n",
    "        else:\n",
    "            return value # return value unchanged\n",
    "\n",
    "\n",
    "preprocessing_parameters_dict: dict = asdict(a_sess_config.preprocessing_parameters, recurse=True, value_serializer=value_serializer)\n",
    "preprocessing_parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd1d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['laps', 'PBEs', 'replays']\n",
    "list(preprocessing_parameters_dict[\"epoch_estimation_parameters\"].keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742b1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays',{}).get(\"min_inclusion_fr_active_thresh\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de6f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays',{}).get(\"max_epoch_included_duration\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624326b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Serialization of preprocessing parameters test\n",
    "file_path = 'output/preprocessing_parameters.h5'\n",
    "\n",
    "with h5py.File(file_path, \"w\") as f:\n",
    "\tpreprocessing_group = f.create_group(\"preprocessing_parameters\")\n",
    "\n",
    "\t# Serialize epoch_estimation_parameters\n",
    "\tepoch_estimation_group = preprocessing_group.create_group(\"epoch_estimation_parameters\")\n",
    "\n",
    "\tlaps_group = epoch_estimation_group.create_group(\"laps\")\n",
    "\tlaps_group.attrs[\"N\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"laps\"][\"N\"]\n",
    "\tlaps_group.attrs[\"should_backup_extant_laps_obj\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"laps\"][\"should_backup_extant_laps_obj\"]\n",
    "\n",
    "\tPBEs_group = epoch_estimation_group.create_group(\"PBEs\")\n",
    "\tPBEs_group.attrs[\"thresh\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"thresh\"]\n",
    "\tPBEs_group.attrs[\"min_dur\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"min_dur\"]\n",
    "\tPBEs_group.attrs[\"merge_dur\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"merge_dur\"]\n",
    "\tPBEs_group.attrs[\"max_dur\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"max_dur\"]\n",
    "\n",
    "\treplays_group = epoch_estimation_group.create_group(\"replays\")\n",
    "\treplay_data = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"replays\"]\n",
    "\t# replay_dataframe = pd.DataFrame(replay_data)\n",
    "\t# replay_data.to_hdf(f, \"/preprocessing_parameters/epoch_estimation_parameters/replays\")\n",
    "\t## TODO: add the data here using Epoch's .to_hdf\n",
    "\t\n",
    "\t# Check for \"None\" values before setting attributes\n",
    "\tdef check_and_set(key, value):\n",
    "\t\tif value is not None:\n",
    "\t\t\treplays_group.attrs[key] = value\n",
    "\n",
    "\t# Set attributes if not \"None\", otherwise skip writing\n",
    "\tcheck_and_set(\"min_epoch_included_duration\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"min_epoch_included_duration\"))\n",
    "\tcheck_and_set(\"max_epoch_included_duration\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"max_epoch_included_duration\"))\n",
    "\tcheck_and_set(\"maximum_speed_thresh\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"maximum_speed_thresh\"))\n",
    "\tcheck_and_set(\"min_inclusion_fr_active_thresh\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"min_inclusion_fr_active_thresh\"))\n",
    "\tcheck_and_set(\"min_num_unique_aclu_inclusions\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"min_num_unique_aclu_inclusions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc30a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_default_neptune_plots = False\n",
    "# enable_default_neptune_plots = True\n",
    "\n",
    "## To file only:\n",
    "with matplotlib_file_only():\n",
    "\t# Perform non-interactive Matplotlib operations with 'AGG' backend\n",
    "\tmain_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=enable_default_neptune_plots, save_figures_only=True, save_figure=True)\n",
    "\n",
    "## Clear the Programmatically open figures:\n",
    "plt.close('all') # this takes care of the matplotlib-backed figures.\n",
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44783dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_out_figures = main_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=False, save_figures_only=False, save_figure=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "943b8f18",
   "metadata": {},
   "source": [
    "# Common Display Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef70fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# configure backend here\n",
    "matplotlib.use('Qt5Agg')\n",
    "# backend_qt5agg\n",
    "# %matplotlib qt5\n",
    "# %matplotlib qt\n",
    "# matplotlib.use('AGG') # non-interactive backend ## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# mpl.rcParams['toolbar'] = 'None' # disable toolbars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9e59bdb",
   "metadata": {},
   "source": [
    "# Figure 1) pf1D Ratemaps, Active set, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77377ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEBUG: new_all_aclus_sort_indicies: [69 83 52 66  4 39 24 78 13 58 36 28 76 31 55 32 74 62 86 48 75 56 16 61  3 77 29 65 18 53 34 73 11 20 80 22  1 10 82 21 40 23 60 19 35  7 72 49 46 64 59 54 57 30 68 67  5  0 38 81 84 71 12 44 70 33 25 41 50 85 45 79 27 14 26  8 42  6 47 15 17 43  2 63 37 51  9]\n",
      "\t saved C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\2023-08-29\\kdiba\\gor01\\one\\2006-6-08_14-26-15\\display_short_long_pf1D_comparison_long.png\n",
      "\t saved C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\2023-08-29\\kdiba\\gor01\\one\\2006-6-08_14-26-15\\display_short_long_pf1D_comparison_short.png\n",
      "merged_kwargs: {'name': 'spikeRasterOverviewWindowScatterPlotItem', 'pxMode': True, 'symbol': <PyQt5.QtGui.QPainterPath object at 0x000001AA0C8AB0B0>, 'size': 6, 'pen': {'color': 'white', 'width': 1}, 'hoverable': True}\n",
      "exported plot to C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\2023-08-29\\kdiba\\gor01\\one\\2006-6-08_14-26-15\\plot_multiple_raster_plot_1_long_example_replays_plot_multiple_raster_plot.png\n",
      "\t saved C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\2023-08-29\\kdiba\\gor01\\one\\2006-6-08_14-26-15\\plot_multiple_raster_plot_1_long_example_replays_plot_multiple_raster_plot.png\n",
      "merged_kwargs: {'name': 'spikeRasterOverviewWindowScatterPlotItem', 'pxMode': True, 'symbol': <PyQt5.QtGui.QPainterPath object at 0x000001AA0C8AB0B0>, 'size': 6, 'pen': {'color': 'white', 'width': 1}, 'hoverable': True}\n",
      "exported plot to C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\2023-08-29\\kdiba\\gor01\\one\\2006-6-08_14-26-15\\plot_multiple_raster_plot_1_short_example_replays_plot_multiple_raster_plot.png\n",
      "\t saved C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\2023-08-29\\kdiba\\gor01\\one\\2006-6-08_14-26-15\\plot_multiple_raster_plot_1_short_example_replays_plot_multiple_raster_plot.png\n",
      "\t saved C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\2023-08-29\\kdiba\\gor01\\one\\2006-6-08_14-26-15\\DecodedEpochSlices_replays_long_results_obj.png\n",
      "\t saved C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\2023-08-29\\kdiba\\gor01\\one\\2006-6-08_14-26-15\\DecodedEpochSlices_replays_short_results_obj.png\n",
      "WARNING: shared_aclus is empty, so not adding kwargs for these.\n",
      "include_includelist: ['maze1', 'maze2', 'maze']\n",
      "long_epoch_name: maze1, short_epoch_name: maze2, global_epoch_name: maze\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "WARNING: aclu 2 is not present in the `pf1D_all` ratemaps. Which contain aclus: [3, 4, 5, 7, 8, 9, 10, 11, 14, 15, 16, 17, 19, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 107, 108, 109]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NeuronExtendedIdentityTuple' object has no attribute 'quality'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyphoplacecellanalysis\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mPho2D\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvisualize_heatmap\u001b[39;00m \u001b[39mimport\u001b[39;00m visualize_heatmap_pyqtgraph \u001b[39m# used in `plot_kourosh_activity_style_figure`\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyphoplacecellanalysis\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mGeneral\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mBatch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mPhoDiba2023Paper\u001b[39;00m \u001b[39mimport\u001b[39;00m PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_1_add_replay_epoch_rasters\n\u001b[1;32m----> 5\u001b[0m pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics \u001b[39m=\u001b[39m PAPER_FIGURE_figure_1_full(curr_active_pipeline) \u001b[39m# did not display the pf1\u001b[39;00m\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\PhoDiba2023Paper.py:626\u001b[0m, in \u001b[0;36mPAPER_FIGURE_figure_1_full\u001b[1;34m(curr_active_pipeline, defer_show, save_figure, should_plot_pf1d_compare, should_plot_example_rasters, should_plot_stacked_epoch_slices, should_plot_pho_jonathan_figures)\u001b[0m\n\u001b[0;32m    623\u001b[0m neuron_replay_stats_df, rdf, aclu_to_idx, irdf \u001b[39m=\u001b[39m curr_jonathan_firing_rate_analysis\u001b[39m.\u001b[39mneuron_replay_stats_df, curr_jonathan_firing_rate_analysis\u001b[39m.\u001b[39mrdf\u001b[39m.\u001b[39mrdf, curr_jonathan_firing_rate_analysis\u001b[39m.\u001b[39mrdf\u001b[39m.\u001b[39maclu_to_idx, curr_jonathan_firing_rate_analysis\u001b[39m.\u001b[39mirdf\u001b[39m.\u001b[39mirdf\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m should_plot_pho_jonathan_figures:\n\u001b[1;32m--> 626\u001b[0m     fig_1c_figures_out_dict \u001b[39m=\u001b[39m BatchPhoJonathanFiguresHelper\u001b[39m.\u001b[39;49mrun(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs\u001b[39m=\u001b[39;49mXOR_subset\u001b[39m.\u001b[39;49mtrack_exclusive_aclus, n_max_page_rows\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, write_vector_format\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, write_png\u001b[39m=\u001b[39;49msave_figure) \u001b[39m# active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     fig_1c_figures_out_dict \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\NonInteractiveProcessing.py:457\u001b[0m, in \u001b[0;36mBatchPhoJonathanFiguresHelper.run\u001b[1;34m(cls, curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs, n_max_page_rows, write_vector_format, write_png, progress_print, debug_print)\u001b[0m\n\u001b[0;32m    454\u001b[0m active_identifying_session_ctx \u001b[39m=\u001b[39m curr_active_pipeline\u001b[39m.\u001b[39msess\u001b[39m.\u001b[39mget_context() \u001b[39m# 'bapun_RatN_Day4_2019-10-15_11-30-06'\u001b[39;00m\n\u001b[0;32m    456\u001b[0m _batch_plot_kwargs_list \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_build_batch_plot_kwargs(long_only_aclus, short_only_aclus, shared_aclus, active_identifying_session_ctx, n_max_page_rows\u001b[39m=\u001b[39mn_max_page_rows)\n\u001b[1;32m--> 457\u001b[0m active_out_figures_dict \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_perform_batch_plot(curr_active_pipeline, _batch_plot_kwargs_list, write_vector_format\u001b[39m=\u001b[39;49mwrite_vector_format, write_png\u001b[39m=\u001b[39;49mwrite_png, progress_print\u001b[39m=\u001b[39;49mprogress_print, debug_print\u001b[39m=\u001b[39;49mdebug_print)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m active_out_figures_dict\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\NonInteractiveProcessing.py:558\u001b[0m, in \u001b[0;36mBatchPhoJonathanFiguresHelper._perform_batch_plot\u001b[1;34m(cls, curr_active_pipeline, active_kwarg_list, subset_includelist, subset_excludelist, write_vector_format, write_png, progress_print, debug_print)\u001b[0m\n\u001b[0;32m    555\u001b[0m final_figure_file_path \u001b[39m=\u001b[39m fig_man\u001b[39m.\u001b[39mget_figure_save_file_path(curr_active_identifying_ctx, make_folder_if_needed\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m# complete file path without extension: e.g. '/ProgrammaticDisplayFunctionTesting/2023-06-15/kdiba_pin01_one_11-03_12-3-25_BatchPhoJonathanReplayFRC_short_only_[13, 22, 28]'\u001b[39;00m\n\u001b[0;32m    557\u001b[0m \u001b[39m# Perform the plotting:\u001b[39;00m\n\u001b[1;32m--> 558\u001b[0m a_fig \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_subfn_batch_plot_automated(curr_active_pipeline, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcurr_batch_plot_kwargs)\n\u001b[0;32m    559\u001b[0m active_out_figures_dict[curr_active_identifying_ctx] \u001b[39m=\u001b[39m a_fig\n\u001b[0;32m    561\u001b[0m \u001b[39m# One plot at a time to PDF:\u001b[39;00m\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\NonInteractiveProcessing.py:475\u001b[0m, in \u001b[0;36mBatchPhoJonathanFiguresHelper._subfn_batch_plot_automated\u001b[1;34m(cls, curr_active_pipeline, included_unit_neuron_IDs, active_identifying_ctx, fignum, fig_idx, n_max_page_rows)\u001b[0m\n\u001b[0;32m    473\u001b[0m desired_figure_size_inches \u001b[39m=\u001b[39m single_subfigure_size_inches\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    474\u001b[0m desired_figure_size_inches[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m desired_figure_size_inches[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m num_cells\n\u001b[1;32m--> 475\u001b[0m graphics_output_dict \u001b[39m=\u001b[39m curr_active_pipeline\u001b[39m.\u001b[39;49mdisplay(\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_display_fn_name, active_identifying_ctx,\n\u001b[0;32m    476\u001b[0m                                                     n_max_plot_rows\u001b[39m=\u001b[39;49mn_max_page_rows, included_unit_neuron_IDs\u001b[39m=\u001b[39;49mincluded_unit_neuron_IDs,\n\u001b[0;32m    477\u001b[0m                                                     show_inter_replay_frs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, spikes_color\u001b[39m=\u001b[39;49m(\u001b[39m0.1\u001b[39;49m, \u001b[39m0.0\u001b[39;49m, \u001b[39m0.1\u001b[39;49m), spikes_alpha\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m, fignum\u001b[39m=\u001b[39;49mfignum, fig_idx\u001b[39m=\u001b[39;49mfig_idx, figsize\u001b[39m=\u001b[39;49mdesired_figure_size_inches, save_figure\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, defer_render\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39m# save_figure will be false because we're saving afterwards\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \u001b[39m# fig, subfigs, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['subfigs'], graphics_output_dict['axs'], graphics_output_dict['plot_data']\u001b[39;00m\n\u001b[0;32m    479\u001b[0m fig, subfigs, axs, plot_data \u001b[39m=\u001b[39m graphics_output_dict\u001b[39m.\u001b[39mfigures[\u001b[39m0\u001b[39m], graphics_output_dict\u001b[39m.\u001b[39msubfigs, graphics_output_dict\u001b[39m.\u001b[39maxes, graphics_output_dict\u001b[39m.\u001b[39mplot_data\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Display.py:409\u001b[0m, in \u001b[0;36mPipelineWithDisplayPipelineStageMixin.display\u001b[1;34m(self, display_function, active_session_configuration_context, **kwargs)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(active_session_configuration_context, \u001b[39m'\u001b[39m\u001b[39mfilter_name\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    404\u001b[0m     \u001b[39m## Global session-level context (not filtered, so not corresponding to a specific config name):\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     \u001b[39m## For a global-style display function, pass ALL of the computation_results and active_configs just to preserve the argument style.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[39m# NOTE: global-style display functions have re-arranged arguments of the form (owning_pipeline_reference, global_computation_results, computation_results, active_configs, **kwargs). This differs from standard ones.\u001b[39;00m\n\u001b[0;32m    407\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mgetattr\u001b[39m(display_function, \u001b[39m'\u001b[39m\u001b[39mis_global\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdisplay_function must be global if `active_session_configuration_context` does not have a `filter_name` property, but it is not!\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mdisplay_function:\u001b[39m\u001b[39m{\u001b[39;00mdisplay_function\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mactive_session_configuration_context: \u001b[39m\u001b[39m{\u001b[39;00mactive_session_configuration_context\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 409\u001b[0m     curr_display_output \u001b[39m=\u001b[39m display_function(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_computation_results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomputation_results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactive_configs, active_config_name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m# CALL GLOBAL DISPLAY FUNCTION\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    412\u001b[0m     \u001b[39m## Non-global display functions: The expected filtered context:\u001b[39;00m\n\u001b[0;32m    413\u001b[0m     \u001b[39mif\u001b[39;00m active_session_configuration_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\DisplayFunctions\\MultiContextComparingDisplayFunctions\\LongShortTrackComparingDisplayFunctions.py:206\u001b[0m, in \u001b[0;36mLongShortTrackComparingDisplayFunctions._display_batch_pho_jonathan_replay_firing_rate_comparison\u001b[1;34m(owning_pipeline_reference, global_computation_results, computation_results, active_configs, include_includelist, defer_render, save_figure, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     curr_fig_num \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlong|short fr indicies_\u001b[39m\u001b[39m{\u001b[39;00mactive_context\u001b[39m.\u001b[39mget_description(separator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    204\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mfignum\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m curr_fig_num\n\u001b[1;32m--> 206\u001b[0m graphics_output_dict: MatplotlibRenderPlots \u001b[39m=\u001b[39m _make_pho_jonathan_batch_plots(t_split, time_bins, neuron_replay_stats_df, time_binned_unit_specific_binned_spike_rate, pf1D_all, aclu_to_idx, rdf, irdf,\n\u001b[0;32m    207\u001b[0m     show_inter_replay_frs\u001b[39m=\u001b[39mshow_inter_replay_frs, n_max_plot_rows\u001b[39m=\u001b[39mn_max_plot_rows, included_unit_neuron_IDs\u001b[39m=\u001b[39mincluded_unit_neuron_IDs, cell_spikes_dfs_dict\u001b[39m=\u001b[39mcell_spikes_dfs_dict, time_variable_name\u001b[39m=\u001b[39mtime_variable_name, defer_render\u001b[39m=\u001b[39mdefer_render, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    209\u001b[0m final_context \u001b[39m=\u001b[39m active_context\n\u001b[0;32m    210\u001b[0m graphics_output_dict[\u001b[39m'\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m final_context\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\DisplayFunctions\\MultiContextComparingDisplayFunctions\\LongShortTrackComparingDisplayFunctions.py:1313\u001b[0m, in \u001b[0;36m_make_pho_jonathan_batch_plots\u001b[1;34m(t_split, time_bins, neuron_replay_stats_df, unit_specific_time_binned_firing_rates, pf1D_all, aclu_to_idx, rdf, irdf, show_inter_replay_frs, included_unit_neuron_IDs, marker_split_mode, n_max_plot_rows, debug_print, defer_render, **kwargs)\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1310\u001b[0m     \u001b[39m# Unhandled exception\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m-> 1313\u001b[0m curr_single_cell_out_dict \u001b[39m=\u001b[39m _plot_pho_jonathan_batch_plot_single_cell(t_split, time_bins, unit_specific_time_binned_firing_rates, pf1D_all, aclu_to_idx, rdf, irdf, show_inter_replay_frs, _temp_aclu_to_fragile_linear_neuron_IDX, aclu, curr_fig, colors, debug_print\u001b[39m=\u001b[39mdebug_print, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1315\u001b[0m \u001b[39m# output the axes created:\u001b[39;00m\n\u001b[0;32m   1316\u001b[0m axs_list\u001b[39m.\u001b[39mappend(curr_single_cell_out_dict)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\DisplayFunctions\\MultiContextComparingDisplayFunctions\\LongShortTrackComparingDisplayFunctions.py:1164\u001b[0m, in \u001b[0;36m_plot_pho_jonathan_batch_plot_single_cell\u001b[1;34m(t_split, time_bins, unit_specific_time_binned_firing_rates, pf1D_all, rdf_aclu_to_idx, rdf, irdf, show_inter_replay_frs, pf1D_aclu_to_idx, aclu, curr_fig, colors, debug_print, **kwargs)\u001b[0m\n\u001b[0;32m   1161\u001b[0m cell_neuron_extended_ids \u001b[39m=\u001b[39m pf1D_all\u001b[39m.\u001b[39mratemap\u001b[39m.\u001b[39mneuron_extended_ids[cell_linear_fragile_IDX]\n\u001b[0;32m   1162\u001b[0m \u001b[39m# print(f'aclu: {aclu}, cell_neuron_extended_ids: {cell_neuron_extended_ids}')\u001b[39;00m\n\u001b[0;32m   1163\u001b[0m \u001b[39m# subtitle_string = f'(shk <size:10><weight:bold>{cell_neuron_extended_ids.shank}</></>, clu <size:10><weight:bold>{cell_neuron_extended_ids.cluster}</></>)'\u001b[39;00m\n\u001b[1;32m-> 1164\u001b[0m subtitle_string \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mshk <size:10><weight:bold>\u001b[39m\u001b[39m{\u001b[39;00mcell_neuron_extended_ids\u001b[39m.\u001b[39mshank\u001b[39m}\u001b[39;00m\u001b[39m</></>, clu <size:10><weight:bold>\u001b[39m\u001b[39m{\u001b[39;00mcell_neuron_extended_ids\u001b[39m.\u001b[39mcluster\u001b[39m}\u001b[39;00m\u001b[39m</></>\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mqclu <size:10><weight:bold>\u001b[39m\u001b[39m{\u001b[39;00mcell_neuron_extended_ids\u001b[39m.\u001b[39;49mquality\u001b[39m}\u001b[39;00m\u001b[39m</></>\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mtype <size:10><weight:bold>\u001b[39m\u001b[39m{\u001b[39;00mcell_neuron_extended_ids\u001b[39m.\u001b[39mcell_type\u001b[39m}\u001b[39;00m\u001b[39m</></>\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1165\u001b[0m \u001b[39m# print(f'\\tsubtitle_string: {subtitle_string}')\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m formatted_cell_label_string \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mformatted_cell_label_string\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m<size:9>\u001b[39m\u001b[39m{\u001b[39;00msubtitle_string\u001b[39m}\u001b[39;00m\u001b[39m</>\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NeuronExtendedIdentityTuple' object has no attribute 'quality'"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_1_add_replay_epoch_rasters\n",
    "\n",
    "pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics = PAPER_FIGURE_figure_1_full(curr_active_pipeline) # did not display the pf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3877d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1d_compare_fig_L, pf1d_compare_fig_S = pf1d_compare_graphics.figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46626313",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1d_compare_fig_L.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999442a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ffa57",
   "metadata": {
    "tags": [
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import build_shared_sorted_neuronIDs\n",
    "\n",
    "ratemap = long_pf1D.ratemap\n",
    "included_unit_neuron_IDs = EITHER_subset.track_exclusive_aclus\n",
    "rediculous_final_sorted_all_included_neuron_ID, rediculous_final_sorted_all_included_pfmap = build_shared_sorted_neuronIDs(ratemap, included_unit_neuron_IDs, sort_ind=new_all_aclus_sort_indicies.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(rediculous_final_sorted_all_included_pfmap, show_yticks=False, title=f\"pf1D Sorted Visualization\", defer_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66369f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_curves_sorted = long_pf1D.ratemap.normalized_tuning_curves[is_included][included_new_all_aclus_sort_indicies]\n",
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(active_curves_sorted, show_yticks=False, title=f\"pf1D Sorted Visualization\", defer_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f0066",
   "metadata": {
    "tags": [
     "unwrap_figure_output",
     "interactive"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "## Stacked Epoch Plot\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=True)\n",
    "pagination_controller_L, pagination_controller_S = example_stacked_epoch_graphics.plot_data['controllers']\n",
    "ax_L, ax_S = example_stacked_epoch_graphics.axes\n",
    "final_figure_context_L, final_context_S = example_stacked_epoch_graphics.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b8b4b",
   "metadata": {
    "tags": [
     "selections",
     "user_annotations"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Mixins.PaginationMixins import SelectionsObject\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "\n",
    "user_annotations = UserAnnotationsManager.get_user_annotations()\n",
    "user_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Capture current user selection\n",
    "saved_selection_L: SelectionsObject = pagination_controller_L.save_selection()\n",
    "saved_selection_S: SelectionsObject = pagination_controller_S.save_selection()\n",
    "user_annotations_L_context = saved_selection_L.figure_ctx.adding_context_if_missing(user_annotation='selections')\n",
    "user_annotations_S_context = saved_selection_S.figure_ctx.adding_context_if_missing(user_annotation='selections')\n",
    "user_annotations[user_annotations_L_context] = saved_selection_L.flat_all_data_indicies[saved_selection_L.is_selected]\n",
    "user_annotations[user_annotations_S_context] = saved_selection_S.flat_all_data_indicies[saved_selection_S.is_selected]\n",
    "# Updates the context. Needs to generate the code.\n",
    "\n",
    "## Generate code to insert int user_annotations:\n",
    "print('Add the following code to UserAnnotationsManager.get_user_annotations() function body:')\n",
    "print(f\"\\t\\tuser_annotations[{user_annotations_L_context.get_initialization_code_string()}] = np.array({list(saved_selection_L.flat_all_data_indicies[saved_selection_L.is_selected])})\")\n",
    "print(f\"\\t\\tuser_annotations[{user_annotations_S_context.get_initialization_code_string()}] = np.array({list(saved_selection_S.flat_all_data_indicies[saved_selection_S.is_selected])})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e130b",
   "metadata": {
    "tags": [
     "selections",
     "user_annotations"
    ]
   },
   "outputs": [],
   "source": [
    "## Update the currently displayed selections with the user annotations:\n",
    "\n",
    "\n",
    "## Capture current user selection\n",
    "saved_selection_L = pagination_controller_L.save_selection()\n",
    "saved_selection_S = pagination_controller_S.save_selection()\n",
    "\n",
    "saved_selection_L = saved_selection_L.update_selections_from_annotations(user_annotations_dict=user_annotations)\n",
    "saved_selection_S = saved_selection_S.update_selections_from_annotations(user_annotations_dict=user_annotations)\n",
    "## re-apply the selections:\n",
    "pagination_controller_L.restore_selections(saved_selection_L)\n",
    "pagination_controller_S.restore_selections(saved_selection_S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8858abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit_colors_list = None # default rainbow of colors for the raster plots\n",
    "neuron_qcolors_list = [pg.mkColor('black') for aclu in EITHER_subset.track_exclusive_aclus] # solid green for all\n",
    "unit_colors_list = DataSeriesColorHelpers.qColorsList_to_NDarray(neuron_qcolors_list, is_255_array=True)\n",
    "\n",
    "# Copy and modify the colors for the cells that are long/short exclusive:\n",
    "unit_colors_list_L = deepcopy(unit_colors_list)\n",
    "is_L_exclusive = np.isin(EITHER_subset.track_exclusive_aclus, long_exclusive.track_exclusive_aclus) # get long exclusive\n",
    "unit_colors_list_L[0, is_L_exclusive] = 255 # [1.0, 0.0, 0.0, 1.0]\n",
    "unit_colors_list_L[1, is_L_exclusive] = 0.0\n",
    "unit_colors_list_L[2, is_L_exclusive] = 0.0\n",
    "\n",
    "unit_colors_list_S = deepcopy(unit_colors_list)\n",
    "is_S_exclusive = np.isin(EITHER_subset.track_exclusive_aclus, short_exclusive.track_exclusive_aclus) # get short exclusive\n",
    "unit_colors_list_S[0, is_S_exclusive] = 0.0 # [1.0, 0.0, 0.0, 1.0]\n",
    "unit_colors_list_S[1, is_S_exclusive] = 0.0\n",
    "unit_colors_list_S[2, is_S_exclusive] = 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spikes_df = an_epoch_spikes_df.copy()\n",
    "scatterplot_tooltips_kwargs = Render2DScrollWindowPlotMixin._build_spike_data_tuples_from_spikes_df(spikes_df)\n",
    "override_scatter_plot_kwargs = {**scatterplot_tooltips_kwargs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e594d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "override_scatter_plot_kwargs = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vtick = _build_default_tick(tick_width=1.0)\n",
    "\n",
    "# pxMode: If True, spots are always the same size regardless of scaling, and size is given in px. Otherwise, size is in scene coordinates and the spots scale with the view. To ensure effective caching, QPen and QBrush objects should be reused as much as possible. Default is True\n",
    "\n",
    "# size: The size (or list of sizes) of spots. If pxMode is True, this value is in pixels. Otherwise, it is in the item’s local coordinate system.\n",
    "\n",
    "override_scatter_plot_kwargs = dict(pxMode=True, symbol=vtick, size=10, pen={'color': 'w', 'width': 1.0})\n",
    "\n",
    "# override_scatter_plot_kwargs = dict(pxMode=False, symbol=vtick, size=1, pen={'color': 'w', 'width': 1.0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the symbol properties\n",
    "# symbol = pg.mkPen('w', width=1)  # Pen for the lines\n",
    "size = 1.0  # Fixed x-width\n",
    "symbol_brush = None  # No brush for the symbol (transparent fill)\n",
    "\n",
    "# override_scatter_plot_kwargs = dict(pxMode=False, symbol='|', size=size, pen={'color': 'w', 'width': 1.0}) # , brush=symbol_brush\n",
    "\n",
    "override_scatter_plot_kwargs = dict(pxMode=False, symbol='arrow_up', size=1.0, pen={'color': 'w', 'width': 1.0}, hoverable=True) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bb530",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epoch_spikes_df_L.spikes.rebuild_fragile_linear_neuron_IDXs();\n",
    "filter_epoch_spikes_df_S.spikes.rebuild_fragile_linear_neuron_IDXs();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_L, win_L, plots_L, plots_data_L = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "\t\t\t\t\t\t\t\t\t\tepoch_id_key_name='replay_epoch_id', scatter_app_name=\"Long Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee132b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_S, win_S, plots_S, plots_data_S = plot_multiple_raster_plot(epochs_df_S, filter_epoch_spikes_df_S, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                 epoch_id_key_name='replay_epoch_id', scatter_app_name=\"Short Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26dd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single `plot_raster_plot` calls\n",
    "an_epoch = list(epochs_df_L.itertuples())[0]\n",
    "an_epoch_spikes_df = filter_epoch_spikes_df_L[filter_epoch_spikes_df_L['replay_epoch_id'] == an_epoch.Index]\n",
    "\n",
    "_out_single_raster_plot = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test1\")\n",
    "_out_single_raster_plot2 = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6071c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_alt, win_alt, plots_alt, plots_data_alt = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                         epoch_id_key_name='replay_epoch_id', scatter_app_name=\"ALT Long Decoded Example Replays\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d20407c",
   "metadata": {},
   "source": [
    "### Testing `plot_kourosh_activity_style_figure` for debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69512447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import plot_kourosh_activity_style_figure\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.helpers import _helper_make_scatterplot_clickable\n",
    "\n",
    "plot_aclus = EITHER_subset.track_exclusive_aclus.copy()\n",
    "# plot_aclus = EITHER_subset.track_exclusive_aclus[new_all_aclus_sort_indicies].copy()\n",
    "_out_A = plot_kourosh_activity_style_figure(long_results_obj, long_session, plot_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_idx=13, callout_epoch_IDXs=None, skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, plots, plots_data = _out_A\n",
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d4092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 2023-06-27 10:42: - [ ] Desperitely need a class that \"explodes\" the important variables and their types out of a DynamicParameters (dict-like) or other object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_n = plot_kourosh_activity_style_figure(long_results_obj, long_session, EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_idx=49, callout_epoch_IDXs=np.arange(6), skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af748f5c",
   "metadata": {},
   "source": [
    "# 2023-07-14 - LxC and SxC PhoJonathanSession plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_display_BatchPhoJonathanFiguresHelper_PlusPDF_20.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\n",
    "print(f'active_out_figures_dict: {active_out_figures_dict}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.display(display_function='_display_2d_placefield_result_plot_ratemaps_2D', active_session_configuration_context=long_epoch_context)\n",
    "\n",
    "\n",
    "# curr_active_pipeline.display(display_function='_display_placemaps_pyqtplot_2D', active_session_configuration_context=long_epoch_context)\n",
    "curr_active_pipeline.display(display_function='_display_1d_placefields', active_session_configuration_context=long_epoch_context)\n",
    "# curr_active_pipeline.display(display_function='_display_2d_placefield_occupancy', active_session_configuration_context=long_epoch_context)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d12ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() # new figure to hold the result\n",
    "# can show the figures by looping through and calling\n",
    "for a_ctxt, a_fig in active_out_figures_dict.items():\n",
    "    print(f'showing: {a_ctxt}')\n",
    "    a_fig.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea9f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_active_pipeline.registered_output_files_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a7c05d1",
   "metadata": {},
   "source": [
    "# Figure 2) Firing Rate Bar Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cf1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantaneous versions:\n",
    "from pyphocorehelpers.mixins.serialized import SerializedAttributesAllowBlockSpecifyingClass\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # 10ms\n",
    "_out_fig_2.compute(curr_active_pipeline=curr_active_pipeline, active_context=curr_active_pipeline.sess.get_context())\n",
    "\n",
    "_out_fig_2_figs = {}\n",
    "\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_out_fig_2_figs = _out_fig_2.display(defer_show=True, save_figure=True, active_context=curr_active_pipeline.sess.get_context())\n",
    "\n",
    "## Extract for debugging/checking:\n",
    "_out_inst_fr_comps = _out_fig_2.computation_result\n",
    "LxC_ReplayDeltaMinus, LxC_ReplayDeltaPlus, SxC_ReplayDeltaMinus, SxC_ReplayDeltaPlus = _out_inst_fr_comps.LxC_ReplayDeltaMinus, _out_inst_fr_comps.LxC_ReplayDeltaPlus, _out_inst_fr_comps.SxC_ReplayDeltaMinus, _out_inst_fr_comps.SxC_ReplayDeltaPlus\n",
    "LxC_ThetaDeltaMinus, LxC_ThetaDeltaPlus, SxC_ThetaDeltaMinus, SxC_ThetaDeltaPlus = _out_inst_fr_comps.LxC_ThetaDeltaMinus, _out_inst_fr_comps.LxC_ThetaDeltaPlus, _out_inst_fr_comps.SxC_ThetaDeltaMinus, _out_inst_fr_comps.SxC_ThetaDeltaPlus\n",
    "# LxC_ThetaDeltaMinus # cell_agg_inst_fr_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_inst_fr_comps = InstantaneousSpikeRateGroupsComputation(instantaneous_time_bin_size_seconds=0.01) # 10ms\n",
    "_out_inst_fr_comps.compute(curr_active_pipeline=curr_active_pipeline, active_context=curr_active_pipeline.sess.get_context())\n",
    "LxC_ReplayDeltaMinus, LxC_ReplayDeltaPlus, SxC_ReplayDeltaMinus, SxC_ReplayDeltaPlus = _out_inst_fr_comps.LxC_ReplayDeltaMinus, _out_inst_fr_comps.LxC_ReplayDeltaPlus, _out_inst_fr_comps.SxC_ReplayDeltaMinus, _out_inst_fr_comps.SxC_ReplayDeltaPlus\n",
    "LxC_ThetaDeltaMinus, LxC_ThetaDeltaPlus, SxC_ThetaDeltaMinus, SxC_ThetaDeltaPlus = _out_inst_fr_comps.LxC_ThetaDeltaMinus, _out_inst_fr_comps.LxC_ThetaDeltaPlus, _out_inst_fr_comps.SxC_ThetaDeltaMinus, _out_inst_fr_comps.SxC_ThetaDeltaPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f34b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_fr_output_filename = 'long_short_inst_firing_rates.pkl'\n",
    "inst_fr_output_path = curr_active_pipeline.get_output_path().joinpath(inst_fr_output_filename).resolve()\n",
    "inst_fr_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ed1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "\n",
    "# saveData(inst_fr_output_path, _out_fig_2)\n",
    "saveData(inst_fr_output_path, _out_fig_2.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de48d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "\n",
    "srt1 = PaperFigureTwo(**loadData(inst_fr_output_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61bee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "srt2 = loadData(inst_fr_output_path)\n",
    "\n",
    "# When combining two `SpikeRateTrends` objects, they may differ in any/all (n_timebins, n_epochs, n_cells) making it difficult to safely concatenate them. \n",
    "# `LxC_ThetaDeltaMinus`\n",
    "# srt1: SpikeRateTrends = deepcopy(LxC_ThetaDeltaMinus) # SpikeRateTrends(...)\n",
    "# srt2: SpikeRateTrends = deepcopy(LxC_ThetaDeltaMinus) # SpikeRateTrends(...)\n",
    "# concatenated = srt1 + srt2\n",
    "# concatenated = srt1.concatenate(srt2)\n",
    "concatenated = SpikeRateTrends.concatenate(srt1, srt2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edea79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]] # only uses global_session\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d085cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ab296",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exclusive.track_exclusive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exclusive.track_exclusive_df['lap_delta_minus_inst_fr'] = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n",
    "long_exclusive.track_exclusive_df['lap_delta_plus_inst_fr'] = LxC_ThetaDeltaPlus.cell_agg_inst_fr_list # (n_cells, )\n",
    "long_exclusive.track_exclusive_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3077438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = LxC_ThetaDeltaMinus.epoch_agg_inst_fr_list # (n_epochs, n_cells)\n",
    "# d = d[:,1]\n",
    "d = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n",
    "d\n",
    "long_exclusive.track_exclusive_df['lap_delta_minus_inst_fr'] = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop out the very low (inactive) Epochs... I guess? But we want it to be influenced by the inactive epochs.\n",
    "curr_active_pipeline.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(LxC_ThetaDeltaMinus.inst_fr_signals_list) # n_epochs\n",
    "d = LxC_ThetaDeltaMinus.inst_fr_df_list\n",
    "d[0]\n",
    "# (n_epochs, n_cells)\n",
    "# print(f'{d.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfd716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LxC_ThetaDeltaPlus\n",
    "# Look at percent change\n",
    "(LxC_ThetaDeltaPlus.cell_agg_inst_fr_list - LxC_ThetaDeltaMinus.cell_agg_inst_fr_list) / LxC_ThetaDeltaMinus.cell_agg_inst_fr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b2901",
   "metadata": {},
   "source": [
    "## NOW: 2023-07-11 - Testing Batch-computed inst_firing_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "\n",
    "## Load the saved across-session results:\n",
    "inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=num_sessions) # some global context across all of the sessions, not sure what to put here.\n",
    "\n",
    "# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\n",
    "\n",
    "## Display the aggregate across sessions:\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn't save this info\n",
    "_out_fig_2.computation_result = across_session_inst_fr_computation\n",
    "_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\n",
    "# Set callback, the only self-specific property\n",
    "_out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f71cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\n",
    "\t\n",
    "_out_fig_2.perform_save()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d7b230c",
   "metadata": {},
   "source": [
    "# Figure 3) `PAPER_FIGURE_figure_3`: Firing Rate Index and Long/Short Firing Rate Replays v. Laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6008da8",
   "metadata": {
    "tags": [
     "figure_3",
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import FormattedFigureText\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _plot_long_short_firing_rate_indicies\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out, _out2 = PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd3546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out2.figures\n",
    "_out.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c49f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0-0.090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd17dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = _out.figures\n",
    "fig\n",
    "# Computed long ($L$)|short($S$) firing rate indicies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14388eec",
   "metadata": {},
   "source": [
    "# 2023-07-07 - `batch_extended_programmatic_figures` Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "neptuner = batch_perform_all_plots(curr_active_pipeline, enable_neptune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126028b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_extended_programmatic_figures(curr_active_pipeline, write_vector_format=False, write_png=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a0f86",
   "metadata": {},
   "source": [
    "# 2023-07-19 - Validation with 3D tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecde32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.plot.\n",
    "\n",
    "display_output = {}\n",
    "active_config_name = long_epoch_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80672dec",
   "metadata": {},
   "source": [
    "# 3D Plotters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd240080",
   "metadata": {},
   "source": [
    "## 🪟 ipcDataExplorer - 3D Interactive Tuning Curves Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "pActiveTuningCurvesPlotter = None\n",
    "\n",
    "zScalingFactor = 2000.0 # worked well before with default params\n",
    "# zScalingFactor = 50.0 # worked well before with default params\n",
    "display_output = display_output | curr_active_pipeline.display('_display_3d_interactive_tuning_curves_plotter', active_config_name, extant_plotter=display_output.get('pActiveTuningCurvesPlotter', None), panel_controls_mode='Qt', should_nan_non_visited_elements=False, zScalingFactor=zScalingFactor, separate_window=False)\n",
    "ipcDataExplorer = display_output['ipcDataExplorer']\n",
    "display_output['pActiveTuningCurvesPlotter'] = display_output.pop('plotter') # rename the key from the generic \"plotter\" to \"pActiveSpikesBehaviorPlotter\" to avoid collisions with others\n",
    "pActiveTuningCurvesPlotter = display_output['pActiveTuningCurvesPlotter']\n",
    "root_dockAreaWindow, placefieldControlsContainerWidget, pf_widgets = display_output['pane'] # for Qt mode:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9bf7ee",
   "metadata": {},
   "source": [
    "## 🪟 ipspikesDataExplorer - 3D Interactive Spike and Behavior Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c48fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pActiveSpikesBehaviorPlotter = None\n",
    "display_output = display_output | curr_active_pipeline.display('_display_3d_interactive_spike_and_behavior_browser', active_config_name, extant_plotter=display_output.get('pActiveSpikesBehaviorPlotter', None)) # Works now!\n",
    "ipspikesDataExplorer = display_output['ipspikesDataExplorer']\n",
    "display_output['pActiveSpikesBehaviorPlotter'] = display_output.pop('plotter') # rename the key from the generic \"plotter\" to \"pActiveSpikesBehaviorPlotter\" to avoid collisions with others\n",
    "pActiveSpikesBehaviorPlotter = display_output['pActiveSpikesBehaviorPlotter']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b9f4bd",
   "metadata": {},
   "source": [
    "### ✅ Test adding the nearest predicted/decoded position as a red point to the 3D plotter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41895eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "_debug_print = False\n",
    "\n",
    "def _update_nearest_decoded_most_likely_position_callback(start_t, end_t):\n",
    "    \"\"\" Only uses end_t\n",
    "    Implicitly captures: ipspikesDataExplorer, _get_nearest_decoded_most_likely_position_callback\n",
    "    \n",
    "    Usage:\n",
    "        _update_nearest_decoded_most_likely_position_callback(0.0, ipspikesDataExplorer.t[0])\n",
    "        _conn = ipspikesDataExplorer.sigOnUpdateMeshes.connect(_update_nearest_decoded_most_likely_position_callback)\n",
    "\n",
    "    \"\"\"\n",
    "    def _get_nearest_decoded_most_likely_position_callback(t):\n",
    "        \"\"\" A callback that when passed a visualization timestamp (the current time to render) returns the most likely predicted position provided by the active_two_step_decoder\n",
    "        Implicitly captures:\n",
    "            active_one_step_decoder, active_two_step_decoder\n",
    "        Usage:\n",
    "            _get_nearest_decoded_most_likely_position_callback(9000.1)\n",
    "        \"\"\"\n",
    "        active_time_window_variable = active_one_step_decoder.time_window_centers # get time window centers (n_time_window_centers,) # (4060,)\n",
    "        active_most_likely_positions = active_one_step_decoder.most_likely_positions.T # (4060, 2) NOTE: the most_likely_positions for the active_one_step_decoder are tranposed compared to the active_two_step_decoder\n",
    "        # active_most_likely_positions = active_two_step_decoder.most_likely_positions # (2, 4060)\n",
    "        assert np.shape(active_time_window_variable)[0] == np.shape(active_most_likely_positions)[1], f\"timestamps and num positions must be the same but np.shape(active_time_window_variable): {np.shape(active_time_window_variable)} and np.shape(active_most_likely_positions): {np.shape(active_most_likely_positions)}!\"\n",
    "        last_window_index = np.searchsorted(active_time_window_variable, t, side='left') # side='left' ensures that no future values (later than 't') are ever returned\n",
    "        # TODO: CORRECTNESS: why is it returning an index that corresponds to a time later than the current time?\n",
    "        # for current time t=9000.0\n",
    "        #     last_window_index: 1577\n",
    "        #     last_window_time: 9000.5023\n",
    "        # EH: close enough\n",
    "        last_window_time = active_time_window_variable[last_window_index] # If there is no suitable index, return either 0 or N (where N is the length of `a`).\n",
    "        displayed_time_offset = t - last_window_time # negative value if the window time being displayed is in the future\n",
    "        if _debug_print:\n",
    "            print(f'for current time t={t}\\n\\tlast_window_index: {last_window_index}\\n\\tlast_window_time: {last_window_time}\\n\\tdisplayed_time_offset: {displayed_time_offset}')\n",
    "        return (last_window_time, *list(np.squeeze(active_most_likely_positions[:, last_window_index]).copy()))\n",
    "\n",
    "    t = end_t # the t under consideration should always be the end_t. This is written this way just for compatibility with the ipspikesDataExplorer.sigOnUpdateMeshes (float, float) signature\n",
    "    curr_t, curr_x, curr_y = _get_nearest_decoded_most_likely_position_callback(t)\n",
    "    curr_debug_point = [curr_x, curr_y, ipspikesDataExplorer.z_fixed[-1]]\n",
    "    if _debug_print:\n",
    "        print(f'tcurr_debug_point: {curr_debug_point}') # \\n\\tlast_window_time: {last_window_time}\\n\\tdisplayed_time_offset: {displayed_time_offset}\n",
    "    ipspikesDataExplorer.perform_plot_location_point('debug_point_plot', curr_debug_point, color='r', render=True)\n",
    "    return curr_debug_point\n",
    "\n",
    "_update_nearest_decoded_most_likely_position_callback(0.0, ipspikesDataExplorer.t[0])\n",
    "# _conn = pg.SignalProxy(ipspikesDataExplorer.sigOnUpdateMeshes, rateLimit=14, slot=_update_nearest_decoded_most_likely_position_callback)\n",
    "_conn = ipspikesDataExplorer.sigOnUpdateMeshes.connect(_update_nearest_decoded_most_likely_position_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b9bfa9",
   "metadata": {},
   "source": [
    "# 2023-08-29 - Add extended flexitext labels to pf1D Placefields Figure:\n",
    "`neuropy.plotting.ratemaps.plot_ratemap_1D`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "add31ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatplotlibRenderPlots({'name': 'MatplotlibRenderPlots', 'context': IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-08_14-26-15', 'maze1', '1d_placefields')>, 'figures': [<Figure size 550x1100 with 1 Axes>], 'axes': [(<Axes: title={'center': '1D Placemaps Placemaps (79 good cells)'}, xlabel='Position'>, array([61, 75, 45, 34,  3, 58, 70, 20, 11, 51, 68, 32, 24, 66, 27, 48, 28, 55, 78, 42, 67, 54,  2, 13, 49, 69, 25, 57, 14, 46, 30, 65,  9, 16, 72,  1, 18,  8, 74, 17, 53, 19, 35, 15, 31,  6, 64, 43, 40, 47, 50, 52, 56, 60, 26, 59,  4,  0, 33, 76, 73, 38, 62, 63, 29, 10, 77, 36, 44, 21, 39, 71, 23, 22, 12,  7,  5, 37, 41], dtype=int64), array([[0.517647, 0.561497, 0.605348, 0.649198, 0.693048, 0.736898, 0.780749, 0.824599, 0.868449, 0.912299, 0.95615, 1, 0.698039, 0.72549, 0.752941, 0.780392, 0.835294, 0.862745, 0.890196, 0.917647, 0.945098, 0.972549, 1, 0.54902, 0.590018, 0.631016, 0.672014, 0.713012, 0.754011, 0.795009, 0.836007, 0.877005, 0.959002, 1, 0.388235, 0.431874, 0.476345, 0.521649, 0.567786, 0.614756, 0.662558, 0.711193, 0.760661, 0.810962, 0.862096, 0.914062, 0.223529, 0.258706, 0.336671, 0.379458, 0.424782, 0.472643, 0.523041, 0.575976, 0.631447, 0.689455, 0.75, 0.223529, 0.259277, 0.297447, 0.33804, 0.381056, 0.426494, 0.474355, 0.577345, 0.632474, 0.690026, 0.75, 0.482353, 0.529412, 0.576471, 0.623529, 0.670588, 0.717647, 0.764706, 0.811765, 0.858824, 0.905882, 0.952941],\n",
       "       [0.235294, 0.270818, 0.308777, 0.349172, 0.392002, 0.437267, 0.484968, 0.535103, 0.587675, 0.642681, 0.700123, 0.76, 0.345098, 0.383236, 0.423233, 0.465089, 0.554378, 0.601811, 0.651104, 0.702255, 0.755266, 0.810135, 0.866864, 0.427451, 0.46668, 0.506925, 0.548185, 0.590461, 0.633753, 0.678061, 0.723384, 0.769723, 0.865449, 0.914835, 0.47451, 0.522282, 0.570053, 0.617825, 0.665597, 0.713369, 0.761141, 0.808913, 0.856684, 0.904456, 0.952228, 1, 0.439216, 0.480753, 0.565857, 0.609424, 0.653667, 0.698587, 0.744183, 0.790456, 0.837405, 0.885031, 0.933333, 0.231373, 0.267496, 0.305966, 0.346783, 0.389948, 0.435459, 0.483317, 0.586074, 0.640973, 0.698219, 0.757812, 0.254902, 0.290433, 0.32786, 0.367182, 0.4084, 0.451513, 0.496522, 0.543426, 0.592226, 0.642922, 0.695513],\n",
       "       [0.223529, 0.258706, 0.29642, 0.336671, 0.379458, 0.424782, 0.472643, 0.523041, 0.575976, 0.631447, 0.689455, 0.75, 0.0352941, 0.0828126, 0.133822, 0.188322, 0.307796, 0.372769, 0.441234, 0.513189, 0.588635, 0.667572, 0.75, 0.192157, 0.227961, 0.266748, 0.308516, 0.353265, 0.400997, 0.45171, 0.505404, 0.562081, 0.684379, 0.75, 0.223529, 0.259277, 0.297447, 0.33804, 0.381056, 0.426494, 0.474355, 0.524639, 0.577345, 0.632474, 0.690026, 0.75, 0.517647, 0.561497, 0.649198, 0.693048, 0.736898, 0.780749, 0.824599, 0.868449, 0.912299, 0.95615, 1, 0.47451, 0.522282, 0.570053, 0.617825, 0.665597, 0.713369, 0.761141, 0.856684, 0.904456, 0.952228, 1, 0.45098, 0.496449, 0.542179, 0.588171, 0.634424, 0.680939, 0.727715, 0.774753, 0.822052, 0.869612, 0.917434],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]))]})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuropy.plotting.ratemaps import plot_ratemap_1D\n",
    "# Uses using `ax.set_yticklabels(list(sorted_neuron_id_labels))` to label each cell's tuning curve and offsets to plot them.\n",
    "\n",
    "_out = curr_active_pipeline.display(display_function='_display_1d_placefields', active_session_configuration_context=long_epoch_context)\n",
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "20739d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ytick_locations: [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5, 12.5, 13.5, 14.5, 15.5, 16.5, 17.5, 18.5, 19.5, 20.5, 21.5, 22.5, 23.5, 24.5, 25.5, 26.5, 27.5, 28.5, 29.5, 30.5, 31.5, 32.5, 33.5, 34.5, 35.5, 36.5, 37.5, 38.5, 39.5, 40.5, 41.5, 42.5, 43.5, 44.5, 45.5, 46.5, 47.5, 48.5, 49.5, 50.5, 51.5, 52.5, 53.5, 54.5, 55.5, 56.5, 57.5, 58.5, 59.5, 60.5, 61.5, 62.5, 63.5, 64.5, 65.5, 66.5, 67.5, 68.5, 69.5, 70.5, 71.5, 72.5, 73.5, 74.5, 75.5, 76.5, 77.5, 78.5]\n",
      "ytick_location_fraction: [0.00632911 0.0189873 0.0316456 0.0443038 0.056962 0.0696203 0.0822785 0.0949367 0.107595 0.120253 0.132911 0.14557 0.158228 0.170886 0.183544 0.196203 0.208861 0.221519 0.234177 0.246835 0.259494 0.272152 0.28481 0.297468 0.310127 0.322785 0.335443 0.348101 0.360759 0.373418 0.386076 0.398734 0.411392 0.424051 0.436709 0.449367 0.462025 0.474684 0.487342 0.5 0.512658 0.525316 0.537975 0.550633 0.563291 0.575949 0.588608 0.601266 0.613924 0.626582 0.639241 0.651899 0.664557 0.677215 0.689873 0.702532 0.71519 0.727848 0.740506 0.753165 0.765823 0.778481 0.791139 0.803797 0.816456 0.829114 0.841772 0.85443 0.867089 0.879747 0.892405 0.905063 0.917722 0.93038 0.943038 0.955696 0.968354 0.981013 0.993671]\n",
      "y_baselines_fraction: [0 0.0126582 0.0253165 0.0379747 0.0506329 0.0632911 0.0759494 0.0886076 0.101266 0.113924 0.126582 0.139241 0.151899 0.164557 0.177215 0.189873 0.202532 0.21519 0.227848 0.240506 0.253165 0.265823 0.278481 0.291139 0.303797 0.316456 0.329114 0.341772 0.35443 0.367089 0.379747 0.392405 0.405063 0.417722 0.43038 0.443038 0.455696 0.468354 0.481013 0.493671 0.506329 0.518987 0.531646 0.544304 0.556962 0.56962 0.582278 0.594937 0.607595 0.620253 0.632911 0.64557 0.658228 0.670886 0.683544 0.696203 0.708861 0.721519 0.734177 0.746835 0.759494 0.772152 0.78481 0.797468 0.810127 0.822785 0.835443 0.848101 0.860759 0.873418 0.886076 0.898734 0.911392 0.924051 0.936709 0.949367 0.962025 0.974684 0.987342]\n",
      "points_in_fig_coords_list: [array([68.75, 121]), array([68.75, 131.722]), array([68.75, 142.443]), array([68.75, 153.165]), array([68.75, 163.886]), array([68.75, 174.608]), array([68.75, 185.329]), array([68.75, 196.051]), array([68.75, 206.772]), array([68.75, 217.494]), array([68.75, 228.215]), array([68.75, 238.937]), array([68.75, 249.658]), array([68.75, 260.38]), array([68.75, 271.101]), array([68.75, 281.823]), array([68.75, 292.544]), array([68.75, 303.266]), array([68.75, 313.987]), array([68.75, 324.709]), array([68.75, 335.43]), array([68.75, 346.152]), array([68.75, 356.873]), array([68.75, 367.595]), array([68.75, 378.316]), array([68.75, 389.038]), array([68.75, 399.759]), array([68.75, 410.481]), array([68.75, 421.203]), array([68.75, 431.924]), array([68.75, 442.646]), array([68.75, 453.367]), array([68.75, 464.089]), array([68.75, 474.81]), array([68.75, 485.532]), array([68.75, 496.253]), array([68.75, 506.975]), array([68.75, 517.696]), array([68.75, 528.418]), array([68.75, 539.139]), array([68.75, 549.861]), array([68.75, 560.582]), array([68.75, 571.304]), array([68.75, 582.025]), array([68.75, 592.747]), array([68.75, 603.468]), array([68.75, 614.19]), array([68.75, 624.911]), array([68.75, 635.633]), array([68.75, 646.354]), array([68.75, 657.076]), array([68.75, 667.797]), array([68.75, 678.519]), array([68.75, 689.241]), array([68.75, 699.962]), array([68.75, 710.684]), array([68.75, 721.405]), array([68.75, 732.127]), array([68.75, 742.848]), array([68.75, 753.57]), array([68.75, 764.291]), array([68.75, 775.013]), array([68.75, 785.734]), array([68.75, 796.456]), array([68.75, 807.177]), array([68.75, 817.899]), array([68.75, 828.62]), array([68.75, 839.342]), array([68.75, 850.063]), array([68.75, 860.785]), array([68.75, 871.506]), array([68.75, 882.228]), array([68.75, 892.949]), array([68.75, 903.671]), array([68.75, 914.392]), array([68.75, 925.114]), array([68.75, 935.835]), array([68.75, 946.557]), array([68.75, 957.278])]\n",
      "points_in_fig_fraction_list: [array([0.125, 0.11]), array([0.125, 0.119747]), array([0.125, 0.129494]), array([0.125, 0.139241]), array([0.125, 0.148987]), array([0.125, 0.158734]), array([0.125, 0.168481]), array([0.125, 0.178228]), array([0.125, 0.187975]), array([0.125, 0.197722]), array([0.125, 0.207468]), array([0.125, 0.217215]), array([0.125, 0.226962]), array([0.125, 0.236709]), array([0.125, 0.246456]), array([0.125, 0.256203]), array([0.125, 0.265949]), array([0.125, 0.275696]), array([0.125, 0.285443]), array([0.125, 0.29519]), array([0.125, 0.304937]), array([0.125, 0.314684]), array([0.125, 0.32443]), array([0.125, 0.334177]), array([0.125, 0.343924]), array([0.125, 0.353671]), array([0.125, 0.363418]), array([0.125, 0.373165]), array([0.125, 0.382911]), array([0.125, 0.392658]), array([0.125, 0.402405]), array([0.125, 0.412152]), array([0.125, 0.421899]), array([0.125, 0.431646]), array([0.125, 0.441392]), array([0.125, 0.451139]), array([0.125, 0.460886]), array([0.125, 0.470633]), array([0.125, 0.48038]), array([0.125, 0.490127]), array([0.125, 0.499873]), array([0.125, 0.50962]), array([0.125, 0.519367]), array([0.125, 0.529114]), array([0.125, 0.538861]), array([0.125, 0.548608]), array([0.125, 0.558354]), array([0.125, 0.568101]), array([0.125, 0.577848]), array([0.125, 0.587595]), array([0.125, 0.597342]), array([0.125, 0.607089]), array([0.125, 0.616835]), array([0.125, 0.626582]), array([0.125, 0.636329]), array([0.125, 0.646076]), array([0.125, 0.655823]), array([0.125, 0.66557]), array([0.125, 0.675316]), array([0.125, 0.685063]), array([0.125, 0.69481]), array([0.125, 0.704557]), array([0.125, 0.714304]), array([0.125, 0.724051]), array([0.125, 0.733797]), array([0.125, 0.743544]), array([0.125, 0.753291]), array([0.125, 0.763038]), array([0.125, 0.772785]), array([0.125, 0.782532]), array([0.125, 0.792278]), array([0.125, 0.802025]), array([0.125, 0.811772]), array([0.125, 0.821519]), array([0.125, 0.831266]), array([0.125, 0.841013]), array([0.125, 0.850759]), array([0.125, 0.860506]), array([0.125, 0.870253])]\n"
     ]
    }
   ],
   "source": [
    "from neuropy.analyses.placefields import PfND\n",
    "from neuropy.plotting.ratemaps import plot_ratemap_1D\n",
    "from neuropy.core.neuron_identities import PlotStringBrevityModeEnum\n",
    "\n",
    "\n",
    "# `_display_1d_placefields` kwargs = {'active_config_name': 'maze1'}\n",
    "active_context = long_epoch_context\n",
    "active_display_fn_identifying_ctx = active_context.adding_context('display_fn', display_fn_name='1d_placefields') # using short name instead of full name here\n",
    "# _build_safe_kwargs\n",
    "# curr_active_pipeline.computation_results[\n",
    "# pf1D: PfND = computation_result.computed_data['pf1D']\n",
    "pf1D: PfND = deepcopy(long_pf1D)\n",
    "# ax_pf_1D = pf1D.plot_ratemaps_1D(**{'active_config_name': 'maze1'})\n",
    "\n",
    "\n",
    "ax, sort_ind, neurons_colors_array = plot_ratemap_1D(pf1D.ratemap, ax=None, pad=1, normalize_tuning_curve=True, sortby=None, cmap=None, brev_mode=PlotStringBrevityModeEnum.MINIMAL, active_context=active_context, use_flexitext_titles=True, **{'active_config_name': 'maze1'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "03ff52ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax.get_position()\n",
    "\n",
    "ax.get_clip_box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4eab133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f\"Cell {ratemap.neuron_ids[cell]} - {ratemap.get_extended_neuron_id_string(neuron_i=cell)} \\n{round(np.nanmax(pfmap),2)} Hz\"\n",
    "a_label = '87-s10, c10\\n1.0 Hz'\n",
    "neuron_extended_id = pf1D.ratemap.neuron_extended_ids[0]\n",
    "a_label_lines = a_label.splitlines()\n",
    "# if len(a_label_lines) == 2:\n",
    "\n",
    "\n",
    "# a_label_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e30ca2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m a_label_subset \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m87-s10, c10\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      2\u001b[0m a_label_subset \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m87\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m aclu, remainder \u001b[39m=\u001b[39m a_label_subset\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m remainder\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# ['s10,', 'c10']\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "a_label_subset = '87-s10, c10'\n",
    "a_label_subset = '87'\n",
    "try:\n",
    "\taclu, remainder = a_label_subset.split('-')\n",
    "\tremainder.split(' ') # ['s10,', 'c10']\n",
    "except ValueError:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12827e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<size:12><weight:bold>2</></><size:8><weight:bold>s</></><size:7>1</>|<size:8><weight:bold>c</></><size:7>6</>'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f'(shank {neuron_extended_id.shank}, cluster {neuron_extended_id.cluster})'\n",
    "# f's{neuron_extended_id.shank}, c{neuron_extended_id.cluster}'\n",
    "\n",
    "def _build_flexitext_neuron_extended_id_sublabel(label:str='s', value:str=666):\n",
    "\treturn f'<size:8><weight:bold>{label}</></><size:7>{value}</>'\n",
    "\n",
    "final_label_str = f'<size:12><weight:bold>{neuron_extended_id.id}</></>'\n",
    "final_label_str = final_label_str + '|'.join([ # _build_flexitext_neuron_extended_id_sublabel('aclu', neuron_extended_id.id),\n",
    "_build_flexitext_neuron_extended_id_sublabel('s', neuron_extended_id.shank),\n",
    "_build_flexitext_neuron_extended_id_sublabel('c', neuron_extended_id.cluster),\n",
    "])\n",
    "\n",
    "final_label_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2a27e2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclu: 87, shank: 10, cluster: 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "# Define the Python regex pattern based on the provided regex\n",
    "pattern = r'(?P<aclu>\\d+)-(?:s(?P<shank>\\d+))(?:, c(?P<cluster>\\d+))?'\n",
    "\n",
    "# Example usage\n",
    "text = '87-s10, c10' # \"1234-s567, c89\"\n",
    "match = re.search(pattern, text)\n",
    "\n",
    "if match:\n",
    "    aclu = match.group('aclu')\n",
    "    shank = match.group('shank')\n",
    "    cluster = match.group('cluster')\n",
    "    print(f\"aclu: {aclu}, shank: {shank}, cluster: {cluster}\")\n",
    "else:\n",
    "    print(\"No match found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed3b4bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NeuronExtendedIdentityTuple(shank=1, cluster=6, id=2),\n",
       " NeuronExtendedIdentityTuple(shank=1, cluster=9, id=3),\n",
       " NeuronExtendedIdentityTuple(shank=1, cluster=11, id=5),\n",
       " NeuronExtendedIdentityTuple(shank=2, cluster=4, id=7),\n",
       " NeuronExtendedIdentityTuple(shank=2, cluster=6, id=8),\n",
       " NeuronExtendedIdentityTuple(shank=2, cluster=7, id=9),\n",
       " NeuronExtendedIdentityTuple(shank=2, cluster=8, id=10),\n",
       " NeuronExtendedIdentityTuple(shank=2, cluster=9, id=11),\n",
       " NeuronExtendedIdentityTuple(shank=2, cluster=13, id=14),\n",
       " NeuronExtendedIdentityTuple(shank=2, cluster=14, id=15),\n",
       " NeuronExtendedIdentityTuple(shank=2, cluster=17, id=16),\n",
       " NeuronExtendedIdentityTuple(shank=2, cluster=19, id=17),\n",
       " NeuronExtendedIdentityTuple(shank=2, cluster=22, id=19),\n",
       " NeuronExtendedIdentityTuple(shank=3, cluster=2, id=22),\n",
       " NeuronExtendedIdentityTuple(shank=3, cluster=5, id=24),\n",
       " NeuronExtendedIdentityTuple(shank=3, cluster=7, id=25),\n",
       " NeuronExtendedIdentityTuple(shank=3, cluster=8, id=26),\n",
       " NeuronExtendedIdentityTuple(shank=3, cluster=15, id=31),\n",
       " NeuronExtendedIdentityTuple(shank=3, cluster=16, id=32),\n",
       " NeuronExtendedIdentityTuple(shank=3, cluster=17, id=33),\n",
       " NeuronExtendedIdentityTuple(shank=3, cluster=18, id=34),\n",
       " NeuronExtendedIdentityTuple(shank=3, cluster=19, id=35),\n",
       " NeuronExtendedIdentityTuple(shank=3, cluster=20, id=36),\n",
       " NeuronExtendedIdentityTuple(shank=3, cluster=21, id=37),\n",
       " NeuronExtendedIdentityTuple(shank=4, cluster=2, id=38),\n",
       " NeuronExtendedIdentityTuple(shank=4, cluster=3, id=39),\n",
       " NeuronExtendedIdentityTuple(shank=7, cluster=2, id=41),\n",
       " NeuronExtendedIdentityTuple(shank=7, cluster=8, id=45),\n",
       " NeuronExtendedIdentityTuple(shank=7, cluster=11, id=46),\n",
       " NeuronExtendedIdentityTuple(shank=7, cluster=13, id=48),\n",
       " NeuronExtendedIdentityTuple(shank=7, cluster=14, id=49),\n",
       " NeuronExtendedIdentityTuple(shank=7, cluster=15, id=50),\n",
       " NeuronExtendedIdentityTuple(shank=7, cluster=18, id=51),\n",
       " NeuronExtendedIdentityTuple(shank=8, cluster=3, id=53),\n",
       " NeuronExtendedIdentityTuple(shank=8, cluster=4, id=54),\n",
       " NeuronExtendedIdentityTuple(shank=8, cluster=6, id=55),\n",
       " NeuronExtendedIdentityTuple(shank=8, cluster=7, id=56),\n",
       " NeuronExtendedIdentityTuple(shank=8, cluster=9, id=57),\n",
       " NeuronExtendedIdentityTuple(shank=8, cluster=11, id=59),\n",
       " NeuronExtendedIdentityTuple(shank=8, cluster=15, id=60),\n",
       " NeuronExtendedIdentityTuple(shank=8, cluster=16, id=61),\n",
       " NeuronExtendedIdentityTuple(shank=8, cluster=19, id=62),\n",
       " NeuronExtendedIdentityTuple(shank=8, cluster=21, id=63),\n",
       " NeuronExtendedIdentityTuple(shank=8, cluster=22, id=64),\n",
       " NeuronExtendedIdentityTuple(shank=8, cluster=25, id=66),\n",
       " NeuronExtendedIdentityTuple(shank=8, cluster=28, id=68),\n",
       " NeuronExtendedIdentityTuple(shank=9, cluster=2, id=69),\n",
       " NeuronExtendedIdentityTuple(shank=9, cluster=3, id=70),\n",
       " NeuronExtendedIdentityTuple(shank=9, cluster=4, id=71),\n",
       " NeuronExtendedIdentityTuple(shank=9, cluster=5, id=72),\n",
       " NeuronExtendedIdentityTuple(shank=9, cluster=7, id=73),\n",
       " NeuronExtendedIdentityTuple(shank=9, cluster=8, id=74),\n",
       " NeuronExtendedIdentityTuple(shank=9, cluster=9, id=75),\n",
       " NeuronExtendedIdentityTuple(shank=9, cluster=13, id=76),\n",
       " NeuronExtendedIdentityTuple(shank=9, cluster=15, id=78),\n",
       " NeuronExtendedIdentityTuple(shank=9, cluster=17, id=79),\n",
       " NeuronExtendedIdentityTuple(shank=10, cluster=2, id=82),\n",
       " NeuronExtendedIdentityTuple(shank=10, cluster=3, id=83),\n",
       " NeuronExtendedIdentityTuple(shank=10, cluster=4, id=84),\n",
       " NeuronExtendedIdentityTuple(shank=10, cluster=7, id=85),\n",
       " NeuronExtendedIdentityTuple(shank=10, cluster=9, id=86),\n",
       " NeuronExtendedIdentityTuple(shank=10, cluster=10, id=87),\n",
       " NeuronExtendedIdentityTuple(shank=10, cluster=11, id=88),\n",
       " NeuronExtendedIdentityTuple(shank=10, cluster=12, id=89),\n",
       " NeuronExtendedIdentityTuple(shank=10, cluster=13, id=90),\n",
       " NeuronExtendedIdentityTuple(shank=10, cluster=14, id=91),\n",
       " NeuronExtendedIdentityTuple(shank=10, cluster=15, id=92),\n",
       " NeuronExtendedIdentityTuple(shank=10, cluster=16, id=93),\n",
       " NeuronExtendedIdentityTuple(shank=11, cluster=4, id=95),\n",
       " NeuronExtendedIdentityTuple(shank=11, cluster=6, id=96),\n",
       " NeuronExtendedIdentityTuple(shank=11, cluster=7, id=97),\n",
       " NeuronExtendedIdentityTuple(shank=11, cluster=14, id=98),\n",
       " NeuronExtendedIdentityTuple(shank=12, cluster=2, id=99),\n",
       " NeuronExtendedIdentityTuple(shank=12, cluster=6, id=100),\n",
       " NeuronExtendedIdentityTuple(shank=12, cluster=7, id=101),\n",
       " NeuronExtendedIdentityTuple(shank=12, cluster=9, id=102),\n",
       " NeuronExtendedIdentityTuple(shank=12, cluster=20, id=107),\n",
       " NeuronExtendedIdentityTuple(shank=12, cluster=21, id=108),\n",
       " NeuronExtendedIdentityTuple(shank=12, cluster=24, id=109)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf1D.neuron_extended_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67825e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2649587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Ratemap: {'_filename': None, '_metadata': None, 'spikes_maps': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), 'tuning_curves': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1.50787e-05, ..., 0, 0, 0],\n",
       "       [0.00579237, 0.0145675, 0.0348897, ..., 0.0010523, 0.000202749, 3.10925e-05],\n",
       "       ...,\n",
       "       [0.000395469, 0.00131676, 0.00402519, ..., 0.0192256, 0.00459469, 0.000978111],\n",
       "       [0, 0, 0, ..., 0.906613, 0.559553, 0.347484],\n",
       "       [0.0202213, 0.0378727, 0.0686763, ..., 0, 0, 0]]), 'unsmoothed_tuning_maps': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]]), '_neuron_ids': [2, 3, 5, 7, 8, 9, 10, 11, 14, 15, 16, 17, 19, 22, 24, 25, 26, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 107, 108, 109], '_neuron_extended_ids': [NeuronExtendedIdentityTuple(shank=1, cluster=6, id=2), NeuronExtendedIdentityTuple(shank=1, cluster=9, id=3), NeuronExtendedIdentityTuple(shank=1, cluster=11, id=5), NeuronExtendedIdentityTuple(shank=2, cluster=4, id=7), NeuronExtendedIdentityTuple(shank=2, cluster=6, id=8), NeuronExtendedIdentityTuple(shank=2, cluster=7, id=9), NeuronExtendedIdentityTuple(shank=2, cluster=8, id=10), NeuronExtendedIdentityTuple(shank=2, cluster=9, id=11), NeuronExtendedIdentityTuple(shank=2, cluster=13, id=14), NeuronExtendedIdentityTuple(shank=2, cluster=14, id=15), NeuronExtendedIdentityTuple(shank=2, cluster=17, id=16), NeuronExtendedIdentityTuple(shank=2, cluster=19, id=17), NeuronExtendedIdentityTuple(shank=2, cluster=22, id=19), NeuronExtendedIdentityTuple(shank=3, cluster=2, id=22), NeuronExtendedIdentityTuple(shank=3, cluster=5, id=24), NeuronExtendedIdentityTuple(shank=3, cluster=7, id=25), NeuronExtendedIdentityTuple(shank=3, cluster=8, id=26), NeuronExtendedIdentityTuple(shank=3, cluster=15, id=31), NeuronExtendedIdentityTuple(shank=3, cluster=16, id=32), NeuronExtendedIdentityTuple(shank=3, cluster=17, id=33), NeuronExtendedIdentityTuple(shank=3, cluster=18, id=34), NeuronExtendedIdentityTuple(shank=3, cluster=19, id=35), NeuronExtendedIdentityTuple(shank=3, cluster=20, id=36), NeuronExtendedIdentityTuple(shank=3, cluster=21, id=37), NeuronExtendedIdentityTuple(shank=4, cluster=2, id=38), NeuronExtendedIdentityTuple(shank=4, cluster=3, id=39), NeuronExtendedIdentityTuple(shank=7, cluster=2, id=41), NeuronExtendedIdentityTuple(shank=7, cluster=8, id=45), NeuronExtendedIdentityTuple(shank=7, cluster=11, id=46), NeuronExtendedIdentityTuple(shank=7, cluster=13, id=48), NeuronExtendedIdentityTuple(shank=7, cluster=14, id=49), NeuronExtendedIdentityTuple(shank=7, cluster=15, id=50), NeuronExtendedIdentityTuple(shank=7, cluster=18, id=51), NeuronExtendedIdentityTuple(shank=8, cluster=3, id=53), NeuronExtendedIdentityTuple(shank=8, cluster=4, id=54), NeuronExtendedIdentityTuple(shank=8, cluster=6, id=55), NeuronExtendedIdentityTuple(shank=8, cluster=7, id=56), NeuronExtendedIdentityTuple(shank=8, cluster=9, id=57), NeuronExtendedIdentityTuple(shank=8, cluster=11, id=59), NeuronExtendedIdentityTuple(shank=8, cluster=15, id=60), NeuronExtendedIdentityTuple(shank=8, cluster=16, id=61), NeuronExtendedIdentityTuple(shank=8, cluster=19, id=62), NeuronExtendedIdentityTuple(shank=8, cluster=21, id=63), NeuronExtendedIdentityTuple(shank=8, cluster=22, id=64), NeuronExtendedIdentityTuple(shank=8, cluster=25, id=66), NeuronExtendedIdentityTuple(shank=8, cluster=28, id=68), NeuronExtendedIdentityTuple(shank=9, cluster=2, id=69), NeuronExtendedIdentityTuple(shank=9, cluster=3, id=70), NeuronExtendedIdentityTuple(shank=9, cluster=4, id=71), NeuronExtendedIdentityTuple(shank=9, cluster=5, id=72), NeuronExtendedIdentityTuple(shank=9, cluster=7, id=73), NeuronExtendedIdentityTuple(shank=9, cluster=8, id=74), NeuronExtendedIdentityTuple(shank=9, cluster=9, id=75), NeuronExtendedIdentityTuple(shank=9, cluster=13, id=76), NeuronExtendedIdentityTuple(shank=9, cluster=15, id=78), NeuronExtendedIdentityTuple(shank=9, cluster=17, id=79), NeuronExtendedIdentityTuple(shank=10, cluster=2, id=82), NeuronExtendedIdentityTuple(shank=10, cluster=3, id=83), NeuronExtendedIdentityTuple(shank=10, cluster=4, id=84), NeuronExtendedIdentityTuple(shank=10, cluster=7, id=85), NeuronExtendedIdentityTuple(shank=10, cluster=9, id=86), NeuronExtendedIdentityTuple(shank=10, cluster=10, id=87), NeuronExtendedIdentityTuple(shank=10, cluster=11, id=88), NeuronExtendedIdentityTuple(shank=10, cluster=12, id=89), NeuronExtendedIdentityTuple(shank=10, cluster=13, id=90), NeuronExtendedIdentityTuple(shank=10, cluster=14, id=91), NeuronExtendedIdentityTuple(shank=10, cluster=15, id=92), NeuronExtendedIdentityTuple(shank=10, cluster=16, id=93), NeuronExtendedIdentityTuple(shank=11, cluster=4, id=95), NeuronExtendedIdentityTuple(shank=11, cluster=6, id=96), NeuronExtendedIdentityTuple(shank=11, cluster=7, id=97), NeuronExtendedIdentityTuple(shank=11, cluster=14, id=98), NeuronExtendedIdentityTuple(shank=12, cluster=2, id=99), NeuronExtendedIdentityTuple(shank=12, cluster=6, id=100), NeuronExtendedIdentityTuple(shank=12, cluster=7, id=101), NeuronExtendedIdentityTuple(shank=12, cluster=9, id=102), NeuronExtendedIdentityTuple(shank=12, cluster=20, id=107), NeuronExtendedIdentityTuple(shank=12, cluster=21, id=108), NeuronExtendedIdentityTuple(shank=12, cluster=24, id=109)], 'xbin': array([29.16, 31.16, 33.16, 35.16, 37.16, 39.16, 41.16, 43.16, 45.16, 47.16, 49.16, 51.16, 53.16, 55.16, 57.16, 59.16, 61.16, 63.16, 65.16, 67.16, 69.16, 71.16, 73.16, 75.16, 77.16, 79.16, 81.16, 83.16, 85.16, 87.16, 89.16, 91.16, 93.16, 95.16, 97.16, 99.16, 101.16, 103.16, 105.16, 107.16, 109.16, 111.16, 113.16, 115.16, 117.16, 119.16, 121.16, 123.16, 125.16, 127.16, 129.16, 131.16, 133.16, 135.16, 137.16, 139.16, 141.16, 143.16, 145.16, 147.16, 149.16, 151.16, 153.16, 155.16, 157.16, 159.16, 161.16, 163.16, 165.16, 167.16, 169.16, 171.16, 173.16, 175.16, 177.16, 179.16, 181.16, 183.16, 185.16, 187.16, 189.16, 191.16, 193.16, 195.16, 197.16, 199.16, 201.16, 203.16, 205.16, 207.16, 209.16, 211.16, 213.16, 215.16, 217.16, 219.16, 221.16, 223.16, 225.16, 227.16, 229.16, 231.16, 233.16, 235.16, 237.16, 239.16, 241.16, 243.16, 245.16, 247.16, 249.16, 251.16, 253.16, 255.16, 257.16, 259.16, 261.16, 263.16]), 'ybin': None, 'occupancy': array([0, 0.0667339, 0.166835, 0.266936, 1.76845, 1.90192, 6.70676, 9.04244, 7.00706, 6.87359, 4.4378, 4.63801, 4.07077, 2.80282, 3.00303, 3.77046, 2.16885, 3.06976, 2.43579, 2.36905, 2.00202, 1.46815, 2.26895, 2.33569, 2.43579, 3.13649, 1.43478, 1.73508, 1.90192, 2.96966, 2.36905, 1.76845, 2.26895, 2.93629, 0.266936, 2.00202, 1.63498, 2.03538, 2.10212, 1.73508, 2.20222, 1.70171, 1.80182, 2.03538, 1.63498, 1.76845, 1.70171, 1.83518, 1.66835, 1.83518, 2.00202, 1.40141, 1.70171, 1.80182, 1.13448, 1.90192, 1.66835, 1.56825, 1.73508, 1.66835, 1.53488, 1.30131, 3.23659, 1.76845, 1.96865, 1.80182, 1.96865, 2.03538, 2.26895, 1.13448, 1.86855, 1.06774, 1.86855, 2.50252, 1.70171, 1.23458, 3.10313, 1.60161, 2.06875, 1.76845, 2.23559, 1.96865, 1.80182, 1.43478, 1.13448, 0, 0.133468, 1.70171, 2.96966, 3.00303, 2.40242, 2.80282, 2.50252, 2.66936, 2.80282, 2.73609, 2.53589, 3.87057, 9.04244, 11.912, 9.47621, 4.17087, 4.30434, 3.5369, 2.96966, 3.50353, 5.90595, 10.911, 4.30434, 1.76845, 0.533871, 0.300303, 0.533871, 0.43377, 0.500504, 0.0333669, 0])};>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf1D.ratemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50c63733",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Ratemap' object has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pf1D\u001b[39m.\u001b[39;49mratemap\u001b[39m.\u001b[39;49mconfig\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Ratemap' object has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "pf1D.ratemap.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0b513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_config = deepcopy(pf1D.config)\n",
    "is_2D = False\n",
    "subtitle_string = '\\n'.join([f'{active_config.str_for_display(is_2D)}'])\n",
    "subtitle_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99581c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexitext import flexitext ## flexitext version\n",
    "from neuropy.utils.matplotlib_helpers import FormattedFigureText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae3013e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Text(0, 0.5, '87')\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "cannot remove artist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 17\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i, a_tick_label \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(ax\u001b[39m.\u001b[39mget_yticklabels()):\n\u001b[0;32m      7\u001b[0m \t\u001b[39m# color = neurons_colors_array[:, i]\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \t\u001b[39m# ## Cell color is stroke color mode: black text with stroke colored with cell-specific color:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \t\u001b[39m# a_flexi_tick_label = flexitext(pos_x, pos_y, f'<size:10><weight:bold>{label_text}</></>\\t<size:8>small</>', va=\"bottom\", xycoords=\"figure fraction\")\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \t\u001b[39m# y_tick_label_objects.append(a_flexi_tick_label)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \t\u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00ma_tick_label\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \ta_tick_label\u001b[39m.\u001b[39;49mremove()\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\matplotlib\\artist.py:259\u001b[0m, in \u001b[0;36mArtist.remove\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 259\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcannot remove artist\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: cannot remove artist"
     ]
    }
   ],
   "source": [
    "\n",
    "# ytick_locations = list(np.arange(len(sort_ind)) + 0.5)\n",
    "# ax.set_yticks(ytick_locations) # OLD: ax.set_yticks(list(np.arange(len(sort_ind)) + 0.5))\n",
    "# ax.set_yticklabels(list(sorted_neuron_id_labels))\n",
    "# Set the neuron id labels on the y-axis to the color of their cell:\n",
    "y_tick_label_objects = []\n",
    "for i, a_tick_label in enumerate(ax.get_yticklabels()):\n",
    "\t# color = neurons_colors_array[:, i]\n",
    "\t# ## Cell color is stroke color mode: black text with stroke colored with cell-specific color:\n",
    "\t# a_tick_label.set_color('black')\n",
    "\t# strokewidth = 0.5\n",
    "\t# a_tick_label.set_path_effects([withStroke(foreground=color, linewidth=strokewidth)])\n",
    "\t# label_text = a_tick_label.get_text()\n",
    "\t# pos_x, pos_y = a_tick_label.get_position()\n",
    "\t# a_flexi_tick_label = flexitext(pos_x, pos_y, f'<size:10><weight:bold>{label_text}</></>\\t<size:8>small</>', va=\"bottom\", xycoords=\"figure fraction\")\n",
    "\t# y_tick_label_objects.append(a_flexi_tick_label)\n",
    "\tprint(f'{i}: {a_tick_label}')\n",
    "\ta_tick_label.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66e7cb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c51940>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c17c40>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c17310>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c159a0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c15d00>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c02dc0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c021c0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c91dac10>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7bfd400>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c075e0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c077f0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c23730>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c21160>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c21b20>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c62580>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c21b80>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c68970>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c753d0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c75d90>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c7b7c0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c84220>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c84be0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c8e640>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c84c70>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c96a30>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c9f490>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7c9fe50>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7ca9880>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7cb32e0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7cb3ca0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7cbc700>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7cc4130>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7cc4af0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7cce550>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7ccef10>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7cd6940>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7cdf3a0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7cdfd60>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7ce9790>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7cf31f0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7cf3bb0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7cfb610>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7cf3c10>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7d03a00>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7d10460>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7d10e20>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7d18850>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7d222b0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7d22c70>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c7d2b6d0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c9803040>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c9803ac0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c980d520>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c980de80>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c9816910>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c9820370>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c9820d30>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c9827820>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c98311c0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c9831b80>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c983d5e0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c983df70>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c98459d0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c984f430>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c984fdf0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c9858820>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c9862280>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c9862c40>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c986b6a0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c98730d0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c9873a90>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c987e4f0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c987eeb0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c98878e0>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c9891340>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c9891d00>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c989a850>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c98a3190>,\n",
       " <matplotlib.offsetbox.AnnotationBbox at 0x1a9c98a3b50>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tick_label_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef734561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'62'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_text = a_tick_label.get_text()\n",
    "pos_x, pos_y = a_tick_label.get_position()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4ed6f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'black'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a_tick_label.get_position()\n",
    "a_tick_label.get_color()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13e8d5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.patheffects.withStroke at 0x1a9c790e3d0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tick_label.get_path_effects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_flexi_tick_label = flexitext(text_formatter.left_margin, 0.90, f'<size:22><weight:bold>{title_string}</></>\\n<size:10>{subtitle_string}</>', va=\"bottom\", xycoords=\"figure fraction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c190bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "use_flexitext_titles = kwargs.get('use_flexitext_titles', True) # use fancy flexitext titles if this is true\n",
    "        \n",
    "active_pf_occupancy_identifier_string = ' - '.join([active_pf_occupancy_identifier_string] + identifier_details_list)\n",
    "title_string = ' '.join([active_pf_occupancy_identifier_string])\n",
    "subtitle_string = ' '.join([f'{self.config.str_for_display(is_2D)}'])    \n",
    "\n",
    "occupancy_fig, occupancy_ax = plot_placefield_occupancy(self, fig=fig, ax=ax, **kwargs)\n",
    "\n",
    "occupancy_fig.canvas.manager.set_window_title(title_string) # sets the window's title\n",
    "\n",
    "\n",
    "if (active_context is None) or (not use_flexitext_titles):\n",
    "\toccupancy_fig.suptitle(title_string, fontsize='14', wrap=True)\n",
    "\toccupancy_ax.set_title(subtitle_string, fontsize='10', wrap=True)\n",
    "else:\n",
    "\tfrom flexitext import flexitext ## flexitext version\n",
    "\t# Clear the normal text:\n",
    "\toccupancy_fig.suptitle('')\n",
    "\toccupancy_ax.set_title('')\n",
    "\ttext_formatter = FormattedFigureText()\n",
    "\ttext_formatter.setup_margins(occupancy_fig)\n",
    "\tactive_config = deepcopy(self.config)\n",
    "\t# active_config.float_precision = 1\n",
    "\t\n",
    "\tsubtitle_string = '\\n'.join([f'{active_config.str_for_display(is_2D)}'])\n",
    "\theader_text_obj = flexitext(text_formatter.left_margin, 0.90, f'<size:22><weight:bold>{title_string}</></>\\n<size:10>{subtitle_string}</>', va=\"bottom\", xycoords=\"figure fraction\")\n",
    "\tfooter_text_obj = text_formatter.add_flexitext_context_footer(active_context=active_context) # flexitext((text_formatter.left_margin*0.1), (text_formatter.bottom_margin*0.25), text_formatter._build_footer_string(active_context=active_context), va=\"top\", xycoords=\"figure fraction\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
