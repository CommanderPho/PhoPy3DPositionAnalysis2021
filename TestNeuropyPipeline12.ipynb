{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a832c382-7f3e-42e3-91db-828709729862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      \n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.0.min.js\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/widgets.css\"];\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\");\\n      max-height: 400px;\\n    }\\n    \");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, js_modules, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      \n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.0.min.js\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/widgets.css\"];\n  var inline_js = [\n    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\");\\n      max-height: 400px;\\n    }\\n    \");\n    },\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: pho\n",
    "\"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## Panel:\n",
    "import param\n",
    "import panel as pn\n",
    "from panel.interact import interact, interactive, fixed, interact_manual\n",
    "from panel.viewable import Viewer\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import get_arguments_as_optional_dict, inspect_callable_arguments\n",
    "from pyphocorehelpers.function_helpers import compose_functions\n",
    "from pyphocorehelpers.indexing_helpers import partition, build_spanning_bins, compute_spanning_bins, compute_position_grid_size\n",
    "from pyphocorehelpers.print_helpers import PrettyPrintable, WrappingMessagePrinter\n",
    "from pyphocorehelpers.geometry_helpers import compute_data_extent, compute_data_aspect_ratio, corner_points_from_extents\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import * # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.SessionSelectionAndFiltering import batch_filter_session\n",
    "from pyphoplacecellanalysis.General.ComputationResults import ComputationResult\n",
    "# from PendingNotebookCode import estimation_session_laps\n",
    "\n",
    "\n",
    "from neuropy.analyses.laps import estimation_session_laps\n",
    "from neuropy.core.epoch import NamedTimerange\n",
    "\n",
    "# Neuropy:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters, perform_compute_placefields\n",
    "from neuropy.core.neuron_identities import NeuronIdentity, build_units_colormap, PlotStringBrevityModeEnum\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_spike_counts, debug_print_subsession_neuron_differences\n",
    "\n",
    "# def estimate_session_laps_load_function(regular_load_function, a_base_dir):\n",
    "#     session = regular_load_function(a_base_dir)\n",
    "#     ## Estimate the Session's Laps data using my algorithm from the loaded position data.\n",
    "#     session = estimation_session_laps(session)\n",
    "#     return session\n",
    "\n",
    "known_data_session_type_dict = {'kdiba':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: DataSessionLoader.kdiba_old_format_session(a_base_dir)),\n",
    "                               basedir=Path(r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53')),\n",
    "                'bapun':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: DataSessionLoader.bapun_data_session(a_base_dir)),\n",
    "                               basedir=Path('R:\\data\\Bapun\\Day5TwoNovel'))\n",
    "               }\n",
    "\n",
    "known_data_session_type_dict['kdiba'].post_load_functions = [lambda a_loaded_sess: estimation_session_laps(a_loaded_sess)]\n",
    "# known_data_session_type_dict = {'kdiba':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: estimation_session_laps(DataSessionLoader.kdiba_old_format_session(a_base_dir))),\n",
    "#                                basedir=Path(r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53')),\n",
    "#                 'bapun':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: DataSessionLoader.bapun_data_session(a_base_dir)),\n",
    "#                                basedir=Path('R:\\data\\Bapun\\Day5TwoNovel'))\n",
    "#                }\n",
    "\n",
    "# known_data_session_type_dict['kdiba'].name\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "from matplotlib.transforms import IdentityTransform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff2b27e-8b58-4e47-8efd-b634d70034ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Common Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b3e2f6e-f8c5-495e-b1ab-081e85bd4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_position_grid_bin_size(x, y, num_bins=(64,64), debug_print=False):\n",
    "    \"\"\" Compute Required Bin size given a desired number of bins in each dimension\n",
    "    Usage:\n",
    "        active_grid_bin = compute_position_grid_bin_size(curr_kdiba_pipeline.sess.position.x, curr_kdiba_pipeline.sess.position.y, num_bins=(64, 64)\n",
    "    \"\"\"\n",
    "    out_grid_bin_size, out_bins, out_bins_infos = compute_position_grid_size(x, y, num_bins=num_bins)\n",
    "    active_grid_bin = tuple(out_grid_bin_size)\n",
    "    if debug_print:\n",
    "        print(f'active_grid_bin: {active_grid_bin}') # (3.776841861770752, 1.043326930905373)\n",
    "    return active_grid_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c20a2-aacf-4db5-b6d7-782bab58d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import multivariate_normal\n",
    "\n",
    "# multivariate_normal.pdf()\n",
    "\n",
    "\n",
    "# from sklearn.neighbors import KernelDensity\n",
    "\n",
    "# kde = KernelDensity(kernel='gaussian', bandwidth=1.0).fix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2853f01-d2f5-4950-9c3d-679e0cfaea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.background_helpers import build_image_from_text\n",
    "\n",
    "fig = plt.figure()\n",
    "rgba1 = build_image_from_text(r\"IQ: $\\sigma_i=15$\", color=\"blue\", fontsize=20, dpi=200)\n",
    "rgba2 = build_image_from_text(r\"some other string\", color=\"red\", fontsize=20, dpi=200)\n",
    "# One can then draw such text images to a Figure using `.Figure.figimage`.\n",
    "fig.figimage(rgba1, 100, 50)\n",
    "fig.figimage(rgba2, 100, 150)\n",
    "\n",
    "# One can also directly draw texts to a figure with positioning\n",
    "# in pixel coordinates by using `.Figure.text` together with\n",
    "# `.transforms.IdentityTransform`.\n",
    "fig.text(100, 250, r\"IQ: $\\sigma_i=15$\", color=\"blue\", fontsize=20,\n",
    "        transform=IdentityTransform())\n",
    "fig.text(100, 350, r\"some other string\", color=\"red\", fontsize=20,\n",
    "        transform=IdentityTransform())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eceb354-7fa7-4064-ba26-4e989b9f3354",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Bapun Format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20843de4-9a94-42f7-80a9-f2c8d5704b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_bapun_pipeline = NeuropyPipeline(name='bapun_pipeline', session_data_type='bapun', basedir=known_data_session_type_dict['bapun'].basedir, load_function=known_data_session_type_dict['bapun'].load_function)\n",
    "curr_bapun_pipeline = NeuropyPipeline.init_from_known_data_session_type('bapun', known_data_session_type_dict['bapun'])\n",
    "curr_bapun_pipeline.is_loaded\n",
    "size_bytes = curr_bapun_pipeline.sess.__sizeof__() # 1753723032\n",
    "f'object size: {size_bytes/(1024*1024)} MB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06847783-f934-43d9-bd7d-4206629ff737",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_bapun_pipeline.sess.spikes_df.spikes.time_variable_name # 't_rel_seconds'\n",
    "curr_bapun_pipeline.sess.position.to_dataframe().position.time_variable_name # t\n",
    "# .spikes.time_variable_name # 't_rel_seconds'\n",
    "# spk_df.spikes.time_variable_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20143ab-1ba2-4943-894d-9513e9c1ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bapun/DataFrame style session filter functions:\n",
    "def build_bapun_any_maze_epochs_filters(sess):\n",
    "    def _temp_filter_session_by_epoch1(sess):\n",
    "        \"\"\" \n",
    "        Usage:\n",
    "            active_session, active_epoch = _temp_filter_session(curr_bapun_pipeline.sess)\n",
    "        \"\"\"\n",
    "        active_epoch = sess.epochs.get_named_timerange('maze1')\n",
    "        ## All Spikes:\n",
    "        # active_epoch_session = sess.filtered_by_epoch(active_epoch) # old\n",
    "        active_session = batch_filter_session(sess, sess.position, sess.spikes_df, active_epoch.to_Epoch())\n",
    "        return active_session, active_epoch\n",
    "\n",
    "    def _temp_filter_session_by_epoch2(sess):\n",
    "        \"\"\" \n",
    "        Usage:\n",
    "            active_session, active_epoch = _temp_filter_session(curr_bapun_pipeline.sess)\n",
    "        \"\"\"\n",
    "        active_epoch = sess.epochs.get_named_timerange('maze2')\n",
    "        ## All Spikes:\n",
    "        # active_epoch_session = sess.filtered_by_epoch(active_epoch) # old\n",
    "        active_session = batch_filter_session(sess, sess.position, sess.spikes_df, active_epoch.to_Epoch())\n",
    "        return active_session, active_epoch\n",
    "\n",
    "    return {'maze1':_temp_filter_session_by_epoch1}\n",
    "    # return {'maze1':_temp_filter_session_by_epoch1,\n",
    "    #         'maze2':_temp_filter_session_by_epoch2\n",
    "    #        }\n",
    "\n",
    "    # return {'maze1': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')),\n",
    "    #         'maze2': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze2')), x.epochs.get_named_timerange('maze2'))\n",
    "    #        }\n",
    "\n",
    "active_session_filter_configurations = build_bapun_any_maze_epochs_filters(curr_bapun_pipeline.sess)\n",
    "curr_bapun_pipeline.filter_sessions(active_session_filter_configurations)\n",
    "active_grid_bin = compute_position_grid_bin_size(curr_bapun_pipeline.sess.position.x, curr_bapun_pipeline.sess.position.y, num_bins=(64, 64))\n",
    "active_session_computation_config = PlacefieldComputationParameters(speed_thresh=0.0, grid_bin=active_grid_bin, smooth=(1.5, 1.5), frate_thresh=0.1, time_bin_size=0.5)\n",
    "curr_bapun_pipeline.perform_computations(active_session_computation_config)\n",
    "curr_bapun_pipeline.prepare_for_display() # TODO: pass a display config\n",
    "curr_bapun_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, 'maze1') # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c4f39-412d-42e7-9b3d-8417993ee562",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_result(curr_bapun_pipeline.computation_results['maze1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c4907-c242-4908-80dd-0c7d49e89b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_result(curr_bapun_pipeline.computation_results['maze2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4940269-23e4-46dc-a4ae-61d512ac5e41",
   "metadata": {
    "tags": []
   },
   "source": [
    "# KDiba Format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69a69581-2f38-4d64-bc21-d38041e2b068",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir is already Path object.\n",
      "\t basepath: R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\n",
      "\t session_name: 2006-6-07_11-26-53\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.epochs_info.mat... done.\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position_info.mat... done.\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Computing linear positions for all active epochs for session... Saving updated position results results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position.npy... 2006-6-07_11-26-53.position.npy saved\n",
      "done.\n",
      "\t Failure loading .interpolated_spike_positions.npy. Must recompute.\n",
      "\n",
      "\t Saving updated interpolated spike position results results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.interpolated_spike_positions.npy... 2006-6-07_11-26-53.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "desc_crossings_x: (24,), asc_crossings_x: (24,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'object size: 144.8962745666504 MB'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "# R:\\data\\KDIBA\\gor01\\one\\IIDataMat_Export_ToPython_2021_11_23.m\n",
    "# From pre-computed .mat files:\n",
    "## 07: \n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53'\n",
    "# # ## 08:\n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15'\n",
    "# curr_kdiba_pipeline = NeuropyPipeline(name='kdiba_pipeline', session_data_type='kdiba', basedir=known_data_session_type_dict['kdiba'].basedir, load_function=known_data_session_type_dict['kdiba'].load_function)\n",
    "curr_kdiba_pipeline = NeuropyPipeline.init_from_known_data_session_type('kdiba', known_data_session_type_dict['kdiba'])\n",
    "\n",
    "# curr_bapun_pipeline\n",
    "curr_kdiba_pipeline.is_loaded\n",
    "size_bytes = curr_kdiba_pipeline.sess.__sizeof__() # 1753723032\n",
    "f'object size: {size_bytes/(1024*1024)} MB'\n",
    "# ## Estimate the Session's Laps data using my algorithm from the loaded position data.\n",
    "# curr_kdiba_pipeline.sess = estimation_session_laps(curr_kdiba_pipeline.sess)\n",
    "# curr_kdiba_pipeline.sess.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efd21e72-a207-4fdd-8bc0-be9313b408e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 22.26, end: 1739.1533641185379)\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 1739.1533641185379, end: 1932.4200048116618)\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 22.26, end: 1932.4200048116618)\n",
      "Performing single_computation on filtered_session with filter named \"maze1\"...\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Performing perform_registered_computations(...) with 1 registered_computation_functions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:170: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  C_tau_n = 1.0 / np.sum(un_normalized_result) # normalize the result\n",
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:171: RuntimeWarning: invalid value encountered in multiply\n",
      "  result = C_tau_n * un_normalized_result\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing single_computation on filtered_session with filter named \"maze2\"...\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Performing perform_registered_computations(...) with 1 registered_computation_functions...\n",
      "Performing single_computation on filtered_session with filter named \"maze\"...\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Performing perform_registered_computations(...) with 1 registered_computation_functions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:170: RuntimeWarning: overflow encountered in double_scalars\n",
      "  C_tau_n = 1.0 / np.sum(un_normalized_result) # normalize the result\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The specified cmap supports less colors than n_neurons (supports 7, n_neurons: 64). An extended colormap will be built.\n",
      "The specified cmap supports less colors than n_neurons (supports 7, n_neurons: 64). An extended colormap will be built.\n",
      "The specified cmap supports less colors than n_neurons (supports 7, n_neurons: 64). An extended colormap will be built.\n"
     ]
    }
   ],
   "source": [
    "def build_any_maze_epochs_filters(sess):\n",
    "    ## All Spikes:\n",
    "    sess.epochs.t_start = 22.26 # exclude the first short period where the animal isn't on the maze yet\n",
    "    active_session_filter_configurations = {'maze1': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')),\n",
    "                                        'maze2': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze2')), x.epochs.get_named_timerange('maze2')),\n",
    "                                        'maze': lambda x: (x.filtered_by_epoch(NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]])), NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]]))\n",
    "                                       }\n",
    "    return active_session_filter_configurations\n",
    "\n",
    "active_session_filter_configurations = build_any_maze_epochs_filters(curr_kdiba_pipeline.sess)\n",
    "curr_kdiba_pipeline.filter_sessions(active_session_filter_configurations)\n",
    "active_grid_bin = compute_position_grid_bin_size(curr_kdiba_pipeline.sess.position.x, curr_kdiba_pipeline.sess.position.y, num_bins=(64, 64))\n",
    "active_session_computation_config = PlacefieldComputationParameters(speed_thresh=2.0, grid_bin=active_grid_bin, smooth=(1.5, 1.5), frate_thresh=0.1, time_bin_size=0.5)\n",
    "curr_kdiba_pipeline.perform_computations(active_session_computation_config)\n",
    "curr_kdiba_pipeline.prepare_for_display() # TODO: pass a display config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d2b141-433e-41a7-8722-8b1cdc5da776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lap_epochs_filters(sess):\n",
    "    lap_specific_epochs = sess.laps.as_epoch_obj()\n",
    "    any_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(len(sess.laps.lap_id))])\n",
    "    even_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(0, len(sess.laps.lap_id), 2)])\n",
    "    odd_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(1, len(sess.laps.lap_id), 2)])\n",
    "    ## All Spikes:\n",
    "    sess.epochs.t_start = 22.26 # exclude the first short period where the animal isn't on the maze yet\n",
    "    active_session_filter_configurations = {'maze1': lambda x: (x.filtered_by_neuron_type('pyramidal').filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')),\n",
    "                                        'maze2': lambda x: (x.filtered_by_neuron_type('pyramidal').filtered_by_epoch(x.epochs.get_named_timerange('maze2')), x.epochs.get_named_timerange('maze2')),\n",
    "                                        'maze': lambda x: (x.filtered_by_neuron_type('pyramidal').filtered_by_epoch(NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]])), NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]]))\n",
    "                                       }\n",
    "    return active_session_filter_configurations\n",
    "\n",
    "active_session_filter_configurations = build_lap_epochs_filters(curr_kdiba_pipeline.sess)\n",
    "curr_kdiba_pipeline.filter_sessions(active_session_filter_configurations)\n",
    "active_grid_bin = compute_position_grid_bin_size(curr_kdiba_pipeline.sess.position.x, curr_kdiba_pipeline.sess.position.y, num_bins=(64, 64))\n",
    "active_session_computation_config = PlacefieldComputationParameters(speed_thresh=0.0, grid_bin=active_grid_bin, smooth=(0.5, 0.5), frate_thresh=0.1, time_bin_size=0.25)\n",
    "curr_kdiba_pipeline.perform_computations(active_session_computation_config)\n",
    "curr_kdiba_pipeline.prepare_for_display() # TODO: pass a display config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009f713-62ba-49fe-80f4-6fc47e6c4516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeb5f781-6cab-419c-944d-7b6a2d1ad2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_aspect_ratio: (7.988962073389786, Width_Height_Tuple(width=241.7178791533281, height=30.256480996256016))\n",
      "Pagination is disabled because one of the subplots values is None. Output will be in a single figure/page.\n",
      "page_grid_sizes: [RowColTuple(num_rows=22, num_columns=3)]\n",
      "resolution_multiplier: 1.0, required_figure_size: (24.0, 22.0)\n",
      "page_idx: 0\n"
     ]
    }
   ],
   "source": [
    "from neuropy.plotting.ratemaps import enumTuningMap2DPlotVariables\n",
    "curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, 'maze1', enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=1) # works!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e45fb89d-3616-4271-9a26-fa4d60a7ed67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_aspect_ratio: (7.988962073389786, Width_Height_Tuple(width=241.7178791533281, height=30.256480996256016))\n",
      "Pagination is disabled because one of the subplots values is None. Output will be in a single figure/page.\n",
      "page_grid_sizes: [RowColTuple(num_rows=22, num_columns=3)]\n",
      "resolution_multiplier: 1.0, required_figure_size: (24.0, 22.0)\n",
      "page_idx: 0\n"
     ]
    }
   ],
   "source": [
    "curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, 'maze1', enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=2) # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "837df2fd-11c6-4552-9cc8-66c5874ed0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Sample')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import signal\n",
    "window = signal.parzen(51)\n",
    "plt.plot(window)\n",
    "plt.title(\"Parzen window\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlabel(\"Sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c4ecf-15c2-4197-927f-8f1a63c7ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_custom_data_explorer, 'maze1') # works!\n",
    "curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_tuning_curves_plotter, 'maze1') # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2988fc6a-007d-4145-8258-dc5449ccf8fc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_1d_placefield_validations, 'maze1') # works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c4171-ea23-4f0f-bcc0-a7ab3544dfbe",
   "metadata": {},
   "source": [
    "## Position Decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37445b3-c614-4b68-b6ab-ee7a26c29af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stock Decoder:\n",
    "from neuropy.analyses.decoders import Decode1d\n",
    "\n",
    "curr_result_label = 'maze1'\n",
    "sess = curr_kdiba_pipeline.filtered_sessions[curr_result_label]\n",
    "pf = curr_kdiba_pipeline.computation_results[curr_result_label].computed_data['pf1D']\n",
    "\n",
    "def stock_1d_decoder(sess, pf, curr_result_label):\n",
    "    maze1 = sess.paradigm[curr_result_label]\n",
    "    # rpls = sess.ripple.time_slice(maze1[0], maze1[1])\n",
    "    rpls = None\n",
    "    pf_neurons = sess.neurons.get_by_id(pf.ratemap.neuron_ids) \n",
    "    decode = Decode1d(neurons=pf_neurons, ratemap = pf.ratemap, epochs=rpls, bin_size=0.02)\n",
    "    return decode\n",
    "    \n",
    "def validate_stock_1d_decoder(sess, decode):\n",
    "    # Plot to validate decoder:\n",
    "    np.shape(decode.decoded_position) # (85845,)\n",
    "    plt.plot(decode.decoded_position)\n",
    "    ax = plt.gca()\n",
    "    # ax.xlim() # (-4292.2, 90136.2)\n",
    "    ax.set_xlim(10000, 12000)\n",
    "\n",
    "np.shape(decode.posterior) # (48, 85845)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3be4111c-585c-4797-b028-245f80d1b2e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        nan,         nan,         nan, ...,         nan,\n",
       "                nan,  0.        ],\n",
       "       [        nan,         nan, 15.08023389, ...,         nan,\n",
       "                nan,  0.        ],\n",
       "       [        nan,         nan, 11.43465014, ...,         nan,\n",
       "                nan,  0.        ],\n",
       "       ...,\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,  0.        ],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Zhang Velocity/Position For 2-step Bayesian Decoder:\n",
    "from neuropy.analyses.placefields import PfND\n",
    "from pyphoplacecellanalysis.General.Decoder.decoder_result import build_position_df_discretized_binned_positions\n",
    "\n",
    "##TODO: compute the average speed at each position x:\n",
    "active_sess = curr_kdiba_pipeline.filtered_sessions['maze1']\n",
    "active_position_df = active_sess.position.to_dataframe()\n",
    "active_computation_config = curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D'].config\n",
    "\n",
    "\n",
    "def _compute_avg_speed_at_each_position_bin(active_position_df, active_computation_config, show_plots=False, debug_print=False):\n",
    "    \"\"\" compute the average speed at each position x: \"\"\"\n",
    "    ## Non-working attempt to use edges instead of bins:\n",
    "    # xbin_edges = xbin + [(xbin[-1] + (xbin[1] - xbin[0]))] # add an additional (right) edge to the end of the xbin array for use with pd.cut\n",
    "    # ybin_edges = ybin + [(ybin[-1] + (ybin[1] - ybin[0]))] # add an additional (right) edge to the end of the ybin array for use with pd.cut\n",
    "    # print(f'xbin_edges: {np.shape(xbin_edges)}\\n ybin_edges: {np.shape(ybin_edges)}, np.shape(np.arange(len(xbin_edges))): {np.shape(np.arange(len(xbin_edges)))}')\n",
    "    # active_position_df['binned_x'] = pd.cut(active_position_df['x'].to_numpy(), bins=xbin_edges, include_lowest=True, labels=np.arange(start=1, stop=len(xbin_edges))) # same shape as the input data \n",
    "    # active_position_df['binned_y'] = pd.cut(active_position_df['y'].to_numpy(), bins=ybin_edges, include_lowest=True, labels=np.arange(start=1, stop=len(ybin_edges))) # same shape as the input data \n",
    "\n",
    "    def _compute_group_stats_for_var(active_position_df, variable_name:str = 'speed'):\n",
    "        # For each unique binned_x and binned_y value, what is the average velocity_x at that point?\n",
    "        position_bin_dependent_specific_average_velocities = active_position_df.groupby(['binned_x','binned_y'])[variable_name].agg([np.nansum, np.nanmean, np.nanmin, np.nanmax]).reset_index() #.apply(lambda g: g.mean(skipna=True)) #.agg((lambda x: x.mean(skipna=False)))\n",
    "        # position_bin_dependent_specific_average_velocities # 1856 rows\n",
    "        output = np.zeros((len(xbin), len(ybin))) # (65, 30)\n",
    "        # np.shape(output)\n",
    "        output[position_bin_dependent_specific_average_velocities['binned_x'].to_numpy()-1, position_bin_dependent_specific_average_velocities['binned_y'].to_numpy()-1] = position_bin_dependent_specific_average_velocities['nanmean'].to_numpy() # ValueError: shape mismatch: value array of shape (1856,) could not be broadcast to indexing result of shape (1856,2,30)\n",
    "        return output\n",
    "\n",
    "    outputs = dict()\n",
    "    outputs['speed'] = _compute_group_stats_for_var(active_position_df, 'speed')\n",
    "    if show_plots:\n",
    "        plt.figure(num=8)\n",
    "        plt.imshow(outputs['speed'])\n",
    "        plt.title('speed')\n",
    "\n",
    "    outputs['velocity_x'] = _compute_group_stats_for_var(active_position_df, 'velocity_x')\n",
    "    if show_plots:\n",
    "        plt.figure(num=9)\n",
    "        plt.imshow(outputs['velocity_x'])\n",
    "        plt.title('velocity_x')\n",
    "\n",
    "    outputs['acceleration_x'] = _compute_group_stats_for_var(active_position_df, 'acceleration_x')\n",
    "    if show_plots:\n",
    "        plt.figure(num=10)\n",
    "        plt.imshow(outputs['acceleration_x'])\n",
    "        plt.title('acceleration_x')\n",
    "\n",
    "    return outputs['speed']\n",
    "\n",
    "\n",
    "active_sess.position.df = build_position_df_discretized_binned_positions(active_sess.position.df, active_computation_config, debug_print=False) # update the session's position dataframe with the new columns.\n",
    "avg_speed_per_pos = _compute_avg_speed_at_each_position_bin(active_sess.position.to_dataframe(), active_computation_config)\n",
    "avg_speed_per_pos\n",
    "\n",
    "# non_empty_position_bin_dependent_specific_average_velocities = position_bin_dependent_specific_average_velocities[position_bin_dependent_specific_average_velocities['nansum'].to_numpy() > 0.001]\n",
    "# non_empty_position_bin_dependent_specific_average_velocities # 790 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a3a7a38f-674f-4a4f-beac-269e1630c65a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        nan,         nan,         nan, ...,         nan,\n",
       "                nan,  0.        ],\n",
       "       [        nan,         nan, 15.08023389, ...,         nan,\n",
       "                nan,  0.        ],\n",
       "       [        nan,         nan, 11.43465014, ...,         nan,\n",
       "                nan,  0.        ],\n",
       "       ...,\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,  0.        ],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_speed_per_pos # called U_x in the paper.\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "class Zhang_Two_Step:\n",
    "    @classfunc\n",
    "    def sigma_t(cls, v_t, K, V, d:float=1.0):\n",
    "        \"\"\" The standard deviation of the Gaussian prior for position. Once computed and normalized, can be used such that it only requires the current position (x_t) to return the correct std_dev at a given timestamp.\n",
    "        K, V are constants\n",
    "        d is 0.5 for random walks and 1.0 for linear movements. \n",
    "        \"\"\"\n",
    "        return K * np.power((v_t / V), d)\n",
    "    \n",
    "    @classfunc\n",
    "    def compute_conditional_probability_x_prev_given_x_t(cls, C, x_prev, t):\n",
    "        \"\"\" Should return a value for all possible current locations x_t. x_prev should be a concrete position, not a matrix of them. \"\"\"\n",
    "        # multivariate_normal.pdf()\n",
    "        \n",
    "        return C * np.exp(-np.square(np.norm(x - x_prev))/(2.0*np.square(sigma_t)))\n",
    "        \n",
    "        # output = multivariate_normal.pdf()\n",
    "        \n",
    "    @classfunc\n",
    "    def compute_bayesian_two_step_prob_single_timestep(cls, one_step_p_x_given_n, t, x_prev, C, k):\n",
    "        return k * one_step_p_x_given_n * cls.compute_conditional_probability_x_prev_given_x_t(C, x_prev, t)\n",
    "    \n",
    "\n",
    "def v_t(window_t):\n",
    "    # get position during that window step\n",
    "    \n",
    "    # use that position x_t to get the velocity during this window.\n",
    "    \n",
    "\n",
    "# .apply(lambda g: g.mean(skipna=False))\n",
    "# # --- occupancy map calculation -----------\n",
    "# if (position.ndim > 1):\n",
    "#     occupancy, xedges, yedges = Pf2D._compute_occupancy(self.x, self.y, xbin, ybin, self.position_srate, smooth)\n",
    "# else:\n",
    "#     occupancy, xedges = Pf1D._compute_occupancy(self.x, xbin, self.position_srate, smooth[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c545afc1-63d6-4f45-a186-5acae5b2dab3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- % $$\\int_{a}^b f(x)dx$$ -->\n",
    "<!-- Euler's identity: $ e^{i \\pi} + 1 = 0 $ -->\n",
    "\n",
    "## One-step Bayesian Decoder:\n",
    "$$P(\\overrightarrow{x}_{t}|\\overrightarrow{n}_{t})$$\n",
    "\n",
    "$$P(\\overrightarrow{n}|\\overrightarrow{x})$$ : probability for the numbers of spikes $\\overrightarrow{n}$ to occur given we know the animal is at location $\\overrightarrow{x}$\n",
    "\n",
    "## Two-step Bayesian Decoder:\n",
    "$$P(\\overrightarrow{x}_{t}|\\overrightarrow{n}_{t}, \\overrightarrow{x}_{t-1}) = k P(\\overrightarrow{x}_{t}|\\overrightarrow{n}_{t}) P(\\overrightarrow{x}_{t-1}|\\overrightarrow{x}_{t})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eff8ed9-3363-48a8-ae20-a1a51443aec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_plot_most_likely_position_comparisons, 'maze1') # works!\n",
    "\n",
    "# fig, axs = plot_most_likely_position_comparsions(pho_custom_decoder, sess.position.to_dataframe())\n",
    "\n",
    "\n",
    "# axs[0].set_xlim(500, 550)\n",
    "# plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7357706-f14c-413b-9020-496db9ed63cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Position Dataframe Binning in Time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "deae0262-15cd-47e0-9202-d1b836cb5d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>lin_pos</th>\n",
       "      <th>speed</th>\n",
       "      <th>dt</th>\n",
       "      <th>velocity_x</th>\n",
       "      <th>acceleration_x</th>\n",
       "      <th>velocity_y</th>\n",
       "      <th>acceleration_y</th>\n",
       "      <th>x_smooth</th>\n",
       "      <th>y_smooth</th>\n",
       "      <th>velocity_x_smooth</th>\n",
       "      <th>acceleration_x_smooth</th>\n",
       "      <th>velocity_y_smooth</th>\n",
       "      <th>acceleration_y_smooth</th>\n",
       "      <th>binned_x</th>\n",
       "      <th>binned_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_delta_sec</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 days 00:00:22.267855</th>\n",
       "      <td>22.267855</td>\n",
       "      <td>228.503636</td>\n",
       "      <td>145.468764</td>\n",
       "      <td>-46.089873</td>\n",
       "      <td>4.527751</td>\n",
       "      <td>0.033407</td>\n",
       "      <td>-1.892589</td>\n",
       "      <td>-0.363896</td>\n",
       "      <td>4.107252</td>\n",
       "      <td>0.789719</td>\n",
       "      <td>229.101522</td>\n",
       "      <td>144.171245</td>\n",
       "      <td>-1.887591</td>\n",
       "      <td>-0.071637</td>\n",
       "      <td>4.096405</td>\n",
       "      <td>0.155464</td>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 days 00:00:22.301320</th>\n",
       "      <td>22.301320</td>\n",
       "      <td>228.440530</td>\n",
       "      <td>145.605714</td>\n",
       "      <td>-46.027268</td>\n",
       "      <td>4.519148</td>\n",
       "      <td>0.033465</td>\n",
       "      <td>-1.885719</td>\n",
       "      <td>0.205287</td>\n",
       "      <td>4.092343</td>\n",
       "      <td>-0.445509</td>\n",
       "      <td>229.038607</td>\n",
       "      <td>144.307781</td>\n",
       "      <td>-1.888068</td>\n",
       "      <td>-0.071449</td>\n",
       "      <td>4.097439</td>\n",
       "      <td>0.155057</td>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 days 00:00:22.334963</th>\n",
       "      <td>22.334963</td>\n",
       "      <td>228.377562</td>\n",
       "      <td>145.742365</td>\n",
       "      <td>-45.964681</td>\n",
       "      <td>4.509270</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>-1.871642</td>\n",
       "      <td>0.418426</td>\n",
       "      <td>4.061793</td>\n",
       "      <td>-0.908058</td>\n",
       "      <td>228.975675</td>\n",
       "      <td>144.444355</td>\n",
       "      <td>-1.888121</td>\n",
       "      <td>-0.058911</td>\n",
       "      <td>4.097555</td>\n",
       "      <td>0.127846</td>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 days 00:00:22.367647</th>\n",
       "      <td>22.367647</td>\n",
       "      <td>228.314608</td>\n",
       "      <td>145.878987</td>\n",
       "      <td>-45.902119</td>\n",
       "      <td>4.508311</td>\n",
       "      <td>0.032684</td>\n",
       "      <td>-1.926149</td>\n",
       "      <td>-1.667703</td>\n",
       "      <td>4.180084</td>\n",
       "      <td>3.619208</td>\n",
       "      <td>228.912721</td>\n",
       "      <td>144.580977</td>\n",
       "      <td>-1.885664</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>4.092224</td>\n",
       "      <td>-0.050176</td>\n",
       "      <td>55</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 days 00:00:22.401755</th>\n",
       "      <td>22.401755</td>\n",
       "      <td>228.251478</td>\n",
       "      <td>146.015989</td>\n",
       "      <td>-45.839591</td>\n",
       "      <td>4.520871</td>\n",
       "      <td>0.034108</td>\n",
       "      <td>-1.850876</td>\n",
       "      <td>2.206925</td>\n",
       "      <td>4.016726</td>\n",
       "      <td>-4.789417</td>\n",
       "      <td>228.849758</td>\n",
       "      <td>144.717616</td>\n",
       "      <td>-1.887591</td>\n",
       "      <td>-0.101013</td>\n",
       "      <td>4.096404</td>\n",
       "      <td>0.219215</td>\n",
       "      <td>55</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 days 00:28:58.997945</th>\n",
       "      <td>1738.997945</td>\n",
       "      <td>211.383281</td>\n",
       "      <td>138.712202</td>\n",
       "      <td>-28.953781</td>\n",
       "      <td>15.351718</td>\n",
       "      <td>0.031953</td>\n",
       "      <td>-15.635207</td>\n",
       "      <td>-24.437137</td>\n",
       "      <td>3.540465</td>\n",
       "      <td>5.533591</td>\n",
       "      <td>215.388793</td>\n",
       "      <td>137.166853</td>\n",
       "      <td>-9.927697</td>\n",
       "      <td>-17.447514</td>\n",
       "      <td>3.928886</td>\n",
       "      <td>6.108043</td>\n",
       "      <td>50</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 days 00:28:59.031413</th>\n",
       "      <td>1739.031413</td>\n",
       "      <td>210.881820</td>\n",
       "      <td>138.825754</td>\n",
       "      <td>-28.475727</td>\n",
       "      <td>15.409162</td>\n",
       "      <td>0.033468</td>\n",
       "      <td>-14.983303</td>\n",
       "      <td>19.478434</td>\n",
       "      <td>3.392847</td>\n",
       "      <td>-4.410733</td>\n",
       "      <td>215.039589</td>\n",
       "      <td>137.304090</td>\n",
       "      <td>-10.476674</td>\n",
       "      <td>-16.326759</td>\n",
       "      <td>4.122275</td>\n",
       "      <td>5.904925</td>\n",
       "      <td>50</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 days 00:28:59.064597</th>\n",
       "      <td>1739.064597</td>\n",
       "      <td>210.375746</td>\n",
       "      <td>138.940351</td>\n",
       "      <td>-28.043462</td>\n",
       "      <td>15.550918</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>-15.250553</td>\n",
       "      <td>-8.053578</td>\n",
       "      <td>3.453364</td>\n",
       "      <td>1.823667</td>\n",
       "      <td>214.671762</td>\n",
       "      <td>137.447850</td>\n",
       "      <td>-11.046550</td>\n",
       "      <td>-16.946740</td>\n",
       "      <td>4.317797</td>\n",
       "      <td>5.970330</td>\n",
       "      <td>50</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 days 00:28:59.099261</th>\n",
       "      <td>1739.099261</td>\n",
       "      <td>209.868561</td>\n",
       "      <td>139.055199</td>\n",
       "      <td>-27.704419</td>\n",
       "      <td>15.585046</td>\n",
       "      <td>0.034664</td>\n",
       "      <td>-14.631461</td>\n",
       "      <td>17.859780</td>\n",
       "      <td>3.313175</td>\n",
       "      <td>-4.044202</td>\n",
       "      <td>214.285218</td>\n",
       "      <td>137.598141</td>\n",
       "      <td>-11.571283</td>\n",
       "      <td>-15.611819</td>\n",
       "      <td>4.507992</td>\n",
       "      <td>5.820545</td>\n",
       "      <td>50</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 days 00:28:59.131656</th>\n",
       "      <td>1739.131656</td>\n",
       "      <td>209.364227</td>\n",
       "      <td>139.169401</td>\n",
       "      <td>-27.514988</td>\n",
       "      <td>15.497439</td>\n",
       "      <td>0.032395</td>\n",
       "      <td>-15.568266</td>\n",
       "      <td>-28.918178</td>\n",
       "      <td>3.525307</td>\n",
       "      <td>6.548286</td>\n",
       "      <td>213.880086</td>\n",
       "      <td>137.754927</td>\n",
       "      <td>-12.154122</td>\n",
       "      <td>-17.390048</td>\n",
       "      <td>4.707457</td>\n",
       "      <td>6.108537</td>\n",
       "      <td>50</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51455 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  t           x           y    lin_pos  \\\n",
       "time_delta_sec                                                           \n",
       "0 days 00:00:22.267855    22.267855  228.503636  145.468764 -46.089873   \n",
       "0 days 00:00:22.301320    22.301320  228.440530  145.605714 -46.027268   \n",
       "0 days 00:00:22.334963    22.334963  228.377562  145.742365 -45.964681   \n",
       "0 days 00:00:22.367647    22.367647  228.314608  145.878987 -45.902119   \n",
       "0 days 00:00:22.401755    22.401755  228.251478  146.015989 -45.839591   \n",
       "...                             ...         ...         ...        ...   \n",
       "0 days 00:28:58.997945  1738.997945  211.383281  138.712202 -28.953781   \n",
       "0 days 00:28:59.031413  1739.031413  210.881820  138.825754 -28.475727   \n",
       "0 days 00:28:59.064597  1739.064597  210.375746  138.940351 -28.043462   \n",
       "0 days 00:28:59.099261  1739.099261  209.868561  139.055199 -27.704419   \n",
       "0 days 00:28:59.131656  1739.131656  209.364227  139.169401 -27.514988   \n",
       "\n",
       "                            speed        dt  velocity_x  acceleration_x  \\\n",
       "time_delta_sec                                                            \n",
       "0 days 00:00:22.267855   4.527751  0.033407   -1.892589       -0.363896   \n",
       "0 days 00:00:22.301320   4.519148  0.033465   -1.885719        0.205287   \n",
       "0 days 00:00:22.334963   4.509270  0.033643   -1.871642        0.418426   \n",
       "0 days 00:00:22.367647   4.508311  0.032684   -1.926149       -1.667703   \n",
       "0 days 00:00:22.401755   4.520871  0.034108   -1.850876        2.206925   \n",
       "...                           ...       ...         ...             ...   \n",
       "0 days 00:28:58.997945  15.351718  0.031953  -15.635207      -24.437137   \n",
       "0 days 00:28:59.031413  15.409162  0.033468  -14.983303       19.478434   \n",
       "0 days 00:28:59.064597  15.550918  0.033184  -15.250553       -8.053578   \n",
       "0 days 00:28:59.099261  15.585046  0.034664  -14.631461       17.859780   \n",
       "0 days 00:28:59.131656  15.497439  0.032395  -15.568266      -28.918178   \n",
       "\n",
       "                        velocity_y  acceleration_y    x_smooth    y_smooth  \\\n",
       "time_delta_sec                                                               \n",
       "0 days 00:00:22.267855    4.107252        0.789719  229.101522  144.171245   \n",
       "0 days 00:00:22.301320    4.092343       -0.445509  229.038607  144.307781   \n",
       "0 days 00:00:22.334963    4.061793       -0.908058  228.975675  144.444355   \n",
       "0 days 00:00:22.367647    4.180084        3.619208  228.912721  144.580977   \n",
       "0 days 00:00:22.401755    4.016726       -4.789417  228.849758  144.717616   \n",
       "...                            ...             ...         ...         ...   \n",
       "0 days 00:28:58.997945    3.540465        5.533591  215.388793  137.166853   \n",
       "0 days 00:28:59.031413    3.392847       -4.410733  215.039589  137.304090   \n",
       "0 days 00:28:59.064597    3.453364        1.823667  214.671762  137.447850   \n",
       "0 days 00:28:59.099261    3.313175       -4.044202  214.285218  137.598141   \n",
       "0 days 00:28:59.131656    3.525307        6.548286  213.880086  137.754927   \n",
       "\n",
       "                        velocity_x_smooth  acceleration_x_smooth  \\\n",
       "time_delta_sec                                                     \n",
       "0 days 00:00:22.267855          -1.887591              -0.071637   \n",
       "0 days 00:00:22.301320          -1.888068              -0.071449   \n",
       "0 days 00:00:22.334963          -1.888121              -0.058911   \n",
       "0 days 00:00:22.367647          -1.885664               0.023121   \n",
       "0 days 00:00:22.401755          -1.887591              -0.101013   \n",
       "...                                   ...                    ...   \n",
       "0 days 00:28:58.997945          -9.927697             -17.447514   \n",
       "0 days 00:28:59.031413         -10.476674             -16.326759   \n",
       "0 days 00:28:59.064597         -11.046550             -16.946740   \n",
       "0 days 00:28:59.099261         -11.571283             -15.611819   \n",
       "0 days 00:28:59.131656         -12.154122             -17.390048   \n",
       "\n",
       "                        velocity_y_smooth  acceleration_y_smooth binned_x  \\\n",
       "time_delta_sec                                                              \n",
       "0 days 00:00:22.267855           4.096405               0.155464       55   \n",
       "0 days 00:00:22.301320           4.097439               0.155057       55   \n",
       "0 days 00:00:22.334963           4.097555               0.127846       55   \n",
       "0 days 00:00:22.367647           4.092224              -0.050176       55   \n",
       "0 days 00:00:22.401755           4.096404               0.219215       55   \n",
       "...                                   ...                    ...      ...   \n",
       "0 days 00:28:58.997945           3.928886               6.108043       50   \n",
       "0 days 00:28:59.031413           4.122275               5.904925       50   \n",
       "0 days 00:28:59.064597           4.317797               5.970330       50   \n",
       "0 days 00:28:59.099261           4.507992               5.820545       50   \n",
       "0 days 00:28:59.131656           4.707457               6.108537       50   \n",
       "\n",
       "                       binned_y  \n",
       "time_delta_sec                   \n",
       "0 days 00:00:22.267855       21  \n",
       "0 days 00:00:22.301320       21  \n",
       "0 days 00:00:22.334963       21  \n",
       "0 days 00:00:22.367647       22  \n",
       "0 days 00:00:22.401755       22  \n",
       "...                         ...  \n",
       "0 days 00:28:58.997945       15  \n",
       "0 days 00:28:59.031413       15  \n",
       "0 days 00:28:59.064597       15  \n",
       "0 days 00:28:59.099261       15  \n",
       "0 days 00:28:59.131656       15  \n",
       "\n",
       "[51455 rows x 18 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuropy.utils.align_util import align_data\n",
    "from pyphoplacecellanalysis.General.Decoder.decoder_result import build_position_df_resampled_to_time_windows, build_position_df_time_window_idx\n",
    "\n",
    "active_pos_df = build_position_df_resampled_to_time_windows(curr_kdiba_pipeline.filtered_sessions['maze1'].position.to_dataframe(), time_bin_size=active_session_computation_config.time_bin_size)\n",
    "\n",
    "def add_timedelta_column_to_pos_df(active_pos_df):\n",
    "    position_time_delta = pd.to_timedelta(active_pos_df[active_pos_df.position.time_variable_name], unit=\"sec\")\n",
    "    active_pos_df['time_delta_sec'] = position_time_delta\n",
    "    return active_pos_df\n",
    "\n",
    "# Update the position dataframe with a time_delta column\n",
    "curr_kdiba_pipeline.filtered_sessions['maze1'].position.df = add_timedelta_column_to_pos_df(curr_kdiba_pipeline.filtered_sessions['maze1'].position.df)\n",
    "\n",
    "active_pos_df = curr_kdiba_pipeline.filtered_sessions['maze1'].position.df.copy() # don't change the index of the actual position df, make a copy\n",
    "active_pos_df = active_pos_df.set_index('time_delta_sec')\n",
    "\n",
    "active_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e39c8-6842-4ac4-8711-3fff06436690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aligned_active_pos_df = active_pos_df.copy()\n",
    "\n",
    "time_window_edges_time_delta = pd.to_timedelta(pho_custom_decoder.time_window_edges, unit=\"sec\") # convert the windows to timedeltas as well to allow efficient comparison\n",
    "time_window_edges_time_delta\n",
    "# aligned_active_pos_df.between_time\n",
    "\n",
    "# aligned_active_pos_df.at_time(pho_custom_decoder.time_window_edges)\n",
    "\n",
    "# pho_custom_decoder.time_window_edges\n",
    "# aligned_active_pos_df.align(time_window_edges_time_delta, fill_value=np.nan)\n",
    "\n",
    "# build_position_df_time_window_idx(active_pos_df, pho_custom_decoder.active_time_window_centers)\n",
    "\n",
    "# pho_custom_decoder.active_time_window_centers\n",
    "# pho_custom_decoder.time_window_edges\n",
    "\n",
    "# s21, s22 = ts_2.align(ts_1, fill_value=0)\n",
    "\n",
    "# active_sess.position.df\n",
    "# aligned_active_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d4d0c686-f861-4f42-9897-d4344ed691c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most_likely_positions: (3434, 2)\n"
     ]
    }
   ],
   "source": [
    "pho_custom_decoder = curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D_Decoder']\n",
    "enable_plots = True\n",
    "\n",
    "print(f'most_likely_positions: {np.shape(pho_custom_decoder.most_likely_positions)}') # most_likely_positions: (3434, 2)\n",
    "\n",
    "\n",
    "def spike_count_and_firing_rate_normalizations(pho_custom_decoder, enable_plots=True):\n",
    "    \"\"\" Computes several different normalizations of binned firing rate and spike counts, optionally plotting them. \n",
    "    \n",
    "    Usage:\n",
    "        pho_custom_decoder = curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D_Decoder']\n",
    "        enable_plots = True\n",
    "        unit_specific_time_binned_outputs = spike_count_and_firing_rate_normalizations(pho_custom_decoder, enable_plots=enable_plots)\n",
    "        spike_proportion_global_fr_normalized, firing_rate, firing_rate_global_fr_normalized = unit_specific_time_binned_outputs # unwrap the output tuple:\n",
    "    \"\"\"\n",
    "    # produces a fraction which indicates which proportion of the window's firing belonged to each unit (accounts for global changes in firing rate (each window is scaled by the toial spikes of all cells in that window)\n",
    "    unit_specific_time_binned_spike_proportion_global_fr_normalized = pho_custom_decoder.unit_specific_time_binned_spike_counts / pho_custom_decoder.total_spike_counts_per_window\n",
    "    if enable_plots:\n",
    "        plt.figure(num=5)\n",
    "        plt.imshow(unit_specific_time_binned_spike_proportion_global_fr_normalized, cmap='turbo', aspect='auto')\n",
    "        plt.title('Unit Specific Proportion of Window Spikes')\n",
    "        plt.xlabel('Binned Time Window')\n",
    "        plt.ylabel('Neuron Proportion Activity')\n",
    "\n",
    "    # print(pho_custom_decoder.time_window_edges_binning_info.step)\n",
    "    # print(f'pho_custom_decoder: {pho_custom_decoder}')\n",
    "    # np.shape(pho_custom_decoder.F) # (1856, 64)\n",
    "\n",
    "    unit_specific_time_binned_firing_rate = pho_custom_decoder.unit_specific_time_binned_spike_counts / pho_custom_decoder.time_window_edges_binning_info.step\n",
    "    # print(unit_specific_time_binned_firing_rate)\n",
    "    if enable_plots:\n",
    "        plt.figure(num=6)\n",
    "        plt.imshow(unit_specific_time_binned_firing_rate, cmap='turbo', aspect='auto')\n",
    "        plt.title('Unit Specific Binned Firing Rates')\n",
    "        plt.xlabel('Binned Time Window')\n",
    "        plt.ylabel('Neuron Firing Rate')\n",
    "\n",
    "\n",
    "    # produces a unit firing rate for each window that accounts for global changes in firing rate (each window is scaled by the firing rate of all cells in that window\n",
    "    unit_specific_time_binned_firing_rate_global_fr_normalized = unit_specific_time_binned_spike_proportion_global_fr_normalized / pho_custom_decoder.time_window_edges_binning_info.step\n",
    "    if enable_plots:\n",
    "        plt.figure(num=7)\n",
    "        plt.imshow(unit_specific_time_binned_firing_rate_global_fr_normalized, cmap='turbo', aspect='auto')\n",
    "        plt.title('Unit Specific Binned Firing Rates (Global Normalized)')\n",
    "        plt.xlabel('Binned Time Window')\n",
    "        plt.ylabel('Neuron Proportion Firing Rate')\n",
    "\n",
    "    # Return the computed values, leaving the original data unchanged.\n",
    "    return unit_specific_time_binned_spike_proportion_global_fr_normalized, unit_specific_time_binned_firing_rate, unit_specific_time_binned_firing_rate_global_fr_normalized\n",
    "\n",
    "\n",
    "    unit_specific_time_binned_outputs = spike_count_and_firing_rate_normalizations(pho_custom_decoder, enable_plots=enable_plots)\n",
    "    spike_proportion_global_fr_normalized, firing_rate, firing_rate_global_fr_normalized = unit_specific_time_binned_outputs # unwrap the output tuple:\n",
    "\n",
    "    # pho_custom_decoder.unit_specific_time_binned_spike_counts\n",
    "    # pho_custom_decoder.time_window_edges\n",
    "    # pho_custom_decoder.time_window_edges_binning_info\n",
    "    # pho_custom_decoder.total_spike_counts_per_window\n",
    "    # curr_kdiba_pipeline.pf.xbin\n",
    "\n",
    "\n",
    "    # active_pos_df = curr_kdiba_pipeline.filtered_sessions['maze1'].position.to_dataframe()\n",
    "    # time_window_edges, time_window_edges_binning_info = compute_spanning_bins(active_pos_df['x'].to_numpy(), bin_size=max_time_bin_size) # np.shape(out_digitized_variable_bins)[0] == np.shape(spikes_df)[0]\n",
    "    # assert np.shape(time_window_edges)[0] < np.shape(spikes_df)[0], f'spikes_df[time_variable_name]: {np.shape(spikes_df[time_variable_name])} should be less than time_window_edges: {np.shape(time_window_edges)}!'\n",
    "\n",
    "    active_sess.position.df\n",
    "\n",
    "    # active_aligned_pos_df = align_data(pho_custom_decoder.active_time_window_centers, active_pos_df['t'].to_numpy(), active_pos_df[['x','y']].to_numpy())\n",
    "    # active_aligned_pos_df = align_data(pho_custom_decoder.active_time_window_centers, active_pos_df.index, active_pos_df['x'])\n",
    "    # active_aligned_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b8fa335-d725-41ba-a8cd-2921eb85de71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.General.Decoder.decoder_result import DecoderResultDisplayingPlot2D\n",
    "# def _display_decoder_result():\n",
    "#     renderer = DecoderResultDisplayingPlot2D(pho_custom_decoder, active_pos_df)\n",
    "#     def animate(i):\n",
    "#         # print(f'animate({i})')\n",
    "#         return renderer.display(i)\n",
    "#     interact(animate, i=(0, pho_custom_decoder.num_time_windows, 10))\n",
    "\n",
    "curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_decoder_result, 'maze1') # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b6e96-0231-4829-a895-bfd14249b4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @pn.interact(i=(0,pho_custom_decoder.num_time_windows,1,0))\n",
    "# @interact(i=pn.widgets.IntSlider(start=0,end=pho_custom_decoder.num_time_windows,step=1,value=0))\n",
    "\n",
    "# ani = FuncAnimation(renderer.fig, animate, interval=300)\n",
    "# interact(animate, i=(0, pho_custom_decoder.num_time_windows, 10))\n",
    "\n",
    "# pn.Column('**A custom interact layout**', pn.Row(layout[0], layout[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96637cdd-8aa7-4a83-9bab-eedcb5363dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_plot_filtered_subsession_neuron_differences(sess, filtered_sess):\n",
    "    print_subsession_neuron_differences(sess.neurons, active_epoch_session.neurons)\n",
    "\n",
    "[debug_plot_filtered_subsession_neuron_differences(curr_kdiba_pipeline.sess, a_filtered_sess) for a_filtered_sess in curr_kdiba_pipeline.filtered_sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c981e-7259-4a8e-acfd-5d9146e6b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_kdiba_pipeline.computation_results['maze2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cace13-54be-40a7-bb8c-05d6bb25ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_result(curr_kdiba_pipeline.computation_results['maze1'])\n",
    "_display_result(curr_kdiba_pipeline.computation_results['maze2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75820aec-6942-4a38-adc0-4f6da16212d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58555225-e9c9-45b2-afb5-d303cabb9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from neuropy.utils.misc import is_iterable\n",
    "from neuropy.plotting.figure import pretty_plot\n",
    "from scipy.ndimage import gaussian_filter, gaussian_filter1d, interpolation\n",
    "\n",
    "from pyphoplacecellanalysis.Analysis.reliability import compute_lap_to_lap_reliability\n",
    "\n",
    "from PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "\n",
    "\n",
    "def _test_plotRaw_v_time(active_pf, cellind, speed_thresh=False, alpha=0.5, ax=None):\n",
    "        \"\"\" Builds one subplot for each dimension of the position data\n",
    "        \n",
    "        Updated to work with both 1D and 2D Placefields \"\"\"   \n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(active_pf.ndim, 1, sharex=True)\n",
    "            fig.set_size_inches([23, 9.7])\n",
    "        \n",
    "        if not is_iterable(ax):\n",
    "            ax = [ax]\n",
    "            \n",
    "        # plot trajectories\n",
    "        if active_pf.ndim < 2:\n",
    "            variable_array = [active_pf.x]\n",
    "            label_array = [\"X position (cm)\"]\n",
    "        else:\n",
    "            variable_array = [active_pf.x, active_pf.y]\n",
    "            label_array = [\"X position (cm)\", \"Y position (cm)\"]\n",
    "            \n",
    "        for a, pos, ylabel in zip(ax, variable_array, label_array):\n",
    "            a.plot(active_pf.t, pos)\n",
    "            a.set_xlabel(\"Time (seconds)\")\n",
    "            a.set_ylabel(ylabel)\n",
    "            pretty_plot(a)\n",
    "\n",
    "        # Grab correct spike times/positions\n",
    "        if speed_thresh:\n",
    "            spk_pos_, spk_t_ = active_pf.run_spk_pos, active_pf.run_spk_t\n",
    "        else:\n",
    "            spk_pos_, spk_t_ = active_pf.spk_pos, active_pf.spk_t\n",
    "\n",
    "        # plot spikes on trajectory\n",
    "        for a, pos in zip(ax, spk_pos_[cellind]):\n",
    "            a.plot(spk_t_[cellind], pos, \".\", color=[0, 0, 0.8, alpha])\n",
    "\n",
    "        # Put info on title\n",
    "        ax[0].set_title(\n",
    "            \"Cell \"\n",
    "            + str(active_pf.cell_ids[cellind])\n",
    "            + \":, speed_thresh=\"\n",
    "            + str(active_pf.speed_thresh)\n",
    "        )\n",
    "        return ax\n",
    "\n",
    "\n",
    "def compute_reliability_metrics(out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap, debug_print=False, plot_results=False):\n",
    "    \"\"\" Takes input from compute_lap_to_lap_reliability(...) to build the actual reliability metrics \"\"\"\n",
    "    # Actual Computations of Reliability:\n",
    "    out_pairwise_pair_results = np.zeros_like(out_within_lap_spikes_overlap)\n",
    "    \n",
    "    # do simple diff:\n",
    "    laps_spikes_overlap_diff = np.diff(out_within_lap_spikes_overlap, axis=1) # the element-wise diff of the overlap. Shows changes.\n",
    "    out_pairwise_pair_results[:, 1:] = laps_spikes_overlap_diff\n",
    "    # out_pairwise_pair_results[:, -1] = np.zeros_like(out_within_lap_spikes_overlap[:,0])\n",
    "    \n",
    "    # do custom pairwise operation:\n",
    "#     for first_item_lap_idx, next_item_lap_idx in list(out_pairwise_flat_lap_indicies):\n",
    "#         first_item = out_within_lap_spikes_overlap[:, first_item_lap_idx]\n",
    "#         next_item = out_within_lap_spikes_overlap[:, next_item_lap_idx]\n",
    "#         out_pairwise_pair_results[:, next_item_lap_idx] = (first_item * next_item) # the result should be stored in the index of the second item, if we're doing the typical backwards style differences.\n",
    "#         # print(f'np.max(out_pairwise_pair_results[:, next_item_lap_idx]): {np.max(out_pairwise_pair_results[:, next_item_lap_idx])}')\n",
    "\n",
    "    if debug_print: \n",
    "        print(f'max out: {np.max(out_pairwise_pair_results)}')\n",
    "        \n",
    "    lap_ids \n",
    "    flat_lap_idxs = np.arange(len(lap_ids))\n",
    "    \n",
    "    \n",
    "    # add to the extant plot as a new color:\n",
    "    if plot_results:\n",
    "        for lap_idx, lap_ID in zip(flat_lap_idxs, lap_ids):\n",
    "            # curr_lap_alt_ax = axs[lap_idx]\n",
    "            if plot_horizontal:\n",
    "                curr_lap_alt_ax = axs[lap_idx].twiny()\n",
    "                curr_lap_alt_ax.plot(out_pairwise_pair_results[:, lap_idx], out_digitized_position_bins, '--r')\n",
    "            else:\n",
    "                # vertical\n",
    "                curr_lap_alt_ax = axs[lap_idx].twinx()\n",
    "                curr_lap_alt_ax.plot(out_digitized_position_bins, out_pairwise_pair_results[:, lap_idx], '--r')\n",
    "            \n",
    "    cum_laps_reliability = np.cumprod(out_within_lap_spikes_overlap, axis=1)\n",
    "    all_laps_reliability = np.prod(out_within_lap_spikes_overlap, axis=1, keepdims=True)\n",
    "    \n",
    "    if plot_results:\n",
    "        fig_result, axs_result = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(24, 40))\n",
    "        axs_result[0].plot(out_digitized_position_bins, all_laps_reliability, 'r')\n",
    "        axs_result[1].plot(out_digitized_position_bins, cum_laps_reliability, 'r')\n",
    "\n",
    "curr_result_label = 'maze1'\n",
    "sess = curr_kdiba_pipeline.filtered_sessions[curr_result_label]\n",
    "sess = curr_kdiba_pipeline.sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340e1ae-1165-4a55-b35a-73de562df226",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_laps_df = sess.laps.to_dataframe()\n",
    "curr_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00bc5e4-11cc-456f-994e-d4ae3ece2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "position_obj = sess.position\n",
    "position_obj.compute_higher_order_derivatives()\n",
    "pos_df = position_obj.compute_smoothed_position_info(N=20) ## Smooth the velocity curve to apply meaningful logic to it\n",
    "pos_df = position_obj.to_dataframe()\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58644ddd-6efe-40b7-a9c5-5971a1bc1bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, out_axes_list = plot_laps_2d(sess, legacy_plotting_mode=True)\n",
    "fig, out_axes_list = plot_laps_2d(sess, legacy_plotting_mode=False)\n",
    "out_axes_list[0].set_title('New Pho Position Thresholding Estimated Laps')\n",
    "\n",
    "curr_cell_idx = 2 \n",
    "# curr_cell_idx = 3 # good for end platform analysis\n",
    "curr_cell_ID = sess.spikes_df.spikes.neuron_ids[curr_cell_idx]\n",
    "print(f'curr_cell_idx: {curr_cell_idx}, curr_cell_ID: {curr_cell_ID}')\n",
    "\n",
    "# pre-filter by spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "filtered_spikes_df = sess.spikes_df.copy()\n",
    "time_variable_name = filtered_spikes_df.spikes.time_variable_name # 't_rel_seconds'\n",
    "\n",
    "lap_ids = sess.laps.lap_id\n",
    "# lap_flat_idxs = sess.laps.get_lap_flat_indicies(lap_ids)\n",
    "\n",
    "out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap = compute_lap_to_lap_reliability(curr_kdiba_pipeline.computation_results[curr_result_label].computed_data['pf2D'], filtered_spikes_df, lap_ids, curr_cell_idx, debug_print=False, plot_results=True);\n",
    "\n",
    "# compute_reliability_metrics(out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap, debug_print=False, plot_results=False)\n",
    "\n",
    "# # curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D'].plotRaw_v_time(curr_cell_idx)\n",
    "# _test_plotRaw_v_time(curr_kdiba_pipeline.computation_results[curr_result_label].computed_data['pf2D'], curr_cell_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e8e317-9b3c-4895-ac55-13600e8ccc47",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3D Lap Plotting Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752016f-67d4-4351-a61d-defc8a1bff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice # for Pagination class\n",
    "import pyvista as pv\n",
    "import pyvistaqt as pvqt\n",
    "from PhoGui.InteractivePlotter.LapsVisualizationMixin import LapsVisualizationMixin\n",
    "from PhoGui.PhoCustomVtkWidgets import PhoWidgetHelper\n",
    "from PhoPositionalData.plotting.spikeAndPositions import perform_plot_flat_arena, _build_flat_arena_data\n",
    "\n",
    "\"\"\" Test Drawing Spike Lines \"\"\"\n",
    "# from pyphoplacecellanalysis.Pho3D.spikes import draw_line_spike, lines_from_points\n",
    "from pyphoplacecellanalysis.Pho3D.points import interlieve_points\n",
    "\n",
    "from PhoPositionalData.plotting.spikeAndPositions import build_active_spikes_plot_pointdata_df\n",
    "\n",
    "def _plot_all_lap_spikes(p, sess, included_cell_IDXs, included_lap_IDXs, debug_print=True, lap_start_z=0.0, lap_id_dependent_z_offset=10.0):\n",
    "    should_reinterpolate_spike_positions = False\n",
    "        \n",
    "    def _plot_single_spikes(p, cell_specific_spikes_dfs, placefield_cell_index):\n",
    "        curr_cell_spike_df = cell_specific_spikes_dfs[placefield_cell_index]\n",
    "        # curr_cell_spike_df['z_fixed'] = np.full_like(active_flat_df['x'].values, 1.1)\n",
    "        pdata = build_active_spikes_plot_pointdata_df(curr_cell_spike_df)\n",
    "\n",
    "        # curr_cell_spike_times = curr_cell_spike_df[curr_cell_spike_df.spikes.time_variable_name].to_numpy()  # (271,)\n",
    "        # curr_cell_spike_positions = curr_cell_spike_df['x','y'].to_numpy()  # (271,)\n",
    "\n",
    "        # lines_from_points(\n",
    "        # p[0,0].add_points(pdata, name='plot_single_spikes_points', render_points_as_spheres=True, point_size=5.0)\n",
    "\n",
    "        # Build offset points and spike data:\n",
    "        spike_height = max((lap_id_dependent_z_offset * 0.6), 0.5) # half the line height\n",
    "\n",
    "        # start_points = pdata.points.copy()\n",
    "        # end_points = start_points.copy()\n",
    "        # # end_points[:,2] # get z values\n",
    "        # end_points[:,2] = end_points[:,2] + spike_height\n",
    "        # all_points = interlieve_points(start_points, end_points)\n",
    "        # lines_poly_data = pv.PolyData()\n",
    "        # lines_poly_data.points = all_points\n",
    "        # # cells = np.hstack(([2, 0, 1],[2, 1, 2]))\n",
    "        # num_lines = np.shape(start_points)[0]\n",
    "        # cells = [[2, 2*i, 2*i+1] for i in np.arange(num_lines)]\n",
    "        # lines_poly_data.lines = cells\n",
    "        \n",
    "        p[0,0].add_mesh(pdata, name=f'plot_single_spikes_points[{placefield_cell_index}]', render_points_as_spheres=True, point_size=5.0, color='white')        \n",
    "        \n",
    "        # p[0,0].add_points(pdata, name=f'plot_single_spikes_points[{placefield_cell_index}]', render_points_as_spheres=True, point_size=5.0)\n",
    "        # p[0,0].add_mesh(lines_poly_data, name=f'plot_single_spikes_lines[{placefield_cell_index}]', render_points_as_spheres=False, point_size=5.0)\n",
    "        # return {'pdata':pdata, 'lines_poly_data':lines_poly_data}\n",
    "        \n",
    "        return {'pdata':pdata}\n",
    "    \n",
    "    time_variable_name = sess.spikes_df.spikes.time_variable_name # 't_rel_seconds'\n",
    "    # sets the 'z_fixed' value for all spikes in sess.spikes_df, which will be used to plot them as points\n",
    "    sess.spikes_df['z'] = lap_start_z + (lap_id_dependent_z_offset * sess.spikes_df.lap.to_numpy())\n",
    "\n",
    "    if debug_print:\n",
    "        print(f'sess.laps.lap_id: {sess.laps.lap_id}')\n",
    "        \n",
    "    included_cell_IDXs = np.array(included_cell_IDXs)\n",
    "    included_lap_IDXs = np.array(included_lap_IDXs)\n",
    "    \n",
    "    # ensure that only lap_ids included in this session are used:\n",
    "    included_lap_ids = sess.laps.lap_id[included_lap_IDXs]\n",
    "    possible_included_lap_ids = np.unique(sess.spikes_df.lap.values)\n",
    "    if debug_print:\n",
    "        print(f'np.unique(sess.spikes_df.lap.values): {np.unique(sess.spikes_df.lap.values)}')\n",
    "    included_lap_ids = included_lap_ids[np.isin(included_lap_ids, possible_included_lap_ids)]\n",
    "    if debug_print:\n",
    "        print(f'included_lap_ids: {included_lap_ids}')\n",
    "    \n",
    "    # get the included cell IDs\n",
    "    included_cell_IDs = np.array(sess.spikes_df.spikes.neuron_ids)[included_cell_IDXs]\n",
    "        \n",
    "    # print(np.isin(['R','G','B','render_opacity'], sess.spikes_df.columns).all())\n",
    "\n",
    "    # POSITIONS:\n",
    "    curr_position_df, lap_specific_position_dfs, lap_specific_time_ranges, lap_specific_position_traces = LapsVisualizationMixin._compute_laps_position_data(sess)\n",
    "    \n",
    "    # SPIKES:\n",
    "    # # grouped by lap\n",
    "    # lap_grouped_spikes_df = sess.spikes_df.groupby('lap')\n",
    "    # lap_specific_spikes_dfs = [lap_grouped_spikes_df.get_group(i)[[time_variable_name,'aclu','lap','flat_spike_idx','cell_type','x','y','lin_pos','z']] for i in included_lap_ids] # dataframes split for each ID:\n",
    "\n",
    "    # grouped by cell:\n",
    "    # pre-filter by spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "    filtered_spikes_df = sess.spikes_df.copy()\n",
    "    filtered_spikes_df = filtered_spikes_df[np.isin(filtered_spikes_df['lap'], included_lap_ids)] # get only the spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "    \n",
    "    \n",
    "    # Interpolate the spikes positions again:\n",
    "    if should_reinterpolate_spike_positions:\n",
    "        print('Re-interpolating spike positions...')\n",
    "        filtered_spikes_df = filtered_spikes_df.spikes.interpolate_spike_positions(curr_position_df['t'].to_numpy(), curr_position_df['x'].to_numpy(), curr_position_df['y'].to_numpy())\n",
    "        # filtered_spikes_df = FlattenedSpiketrains.interpolate_spike_positions(filtered_spikes_df, session.position.time, session.position.x, session.position.y, spike_timestamp_column_name=time_variable_name)\n",
    "    \n",
    "    cell_grouped_spikes_df = filtered_spikes_df.groupby('aclu')\n",
    "    cell_specific_spikes_dfs = [cell_grouped_spikes_df.get_group(i)[[time_variable_name,'aclu','lap','flat_spike_idx','cell_type','x','y','lin_pos','z']] for i in included_cell_IDs] # dataframes split for each ID:\n",
    "\n",
    "    # lap_specific_position_dfs = _compute_laps_position_data(sess)\n",
    "\n",
    "    # # Positions:\n",
    "    # curr_position_df = sess.compute_position_laps()\n",
    "    # included_pos_lap_ids = np.unique(curr_position_df.lap.values)\n",
    "    # print(f'np.unique(curr_position_df.lap.values): {np.unique(curr_position_df.lap.values)}')\n",
    "    # included_pos_lap_ids = included_pos_lap_ids[np.isin(included_pos_lap_ids, sess.laps.lap_id)]\n",
    "    # included_pos_lap_ids\n",
    "\n",
    "    # print(f'included_pos_lap_ids: {included_pos_lap_ids}')\n",
    "\n",
    "    # lap_grouped_position_df = curr_position_df.groupby('lap')\n",
    "    # lap_specific_position_dfs = [lap_grouped_position_df.get_group(i)[['t','aclu','x','y','lin_pos']] for i in included_lap_ids] # dataframes split for each ID:\n",
    "\n",
    "    for i, curr_cell_ID in enumerate(included_cell_IDs):\n",
    "        plot_data_dict = _plot_single_spikes(p, cell_specific_spikes_dfs, i)\n",
    "\n",
    "\n",
    "# sess = curr_kdiba_pipeline.filtered_sessions['maze']\n",
    "# included_cell_IDXs = [6]\n",
    "# included_lap_IDXs = [2, 3]\n",
    "# _plot_all_lap_spikes(pActiveInteractiveLapsPlotter, sess, included_cell_IDXs, included_lap_IDXs)\n",
    "\n",
    "from PhoGui.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer\n",
    "\n",
    "lap_start_z = 0.0\n",
    "# lap_id_dependent_z_offset = 0.0\n",
    "lap_id_dependent_z_offset = 3.0\n",
    "# curr_kdiba_pipeline.active_configs['maze1'].lap_id_dependent_z_offset = 3.0\n",
    "\n",
    "def _display_testing(sess, computation_result, active_config, extant_plotter=None):\n",
    "    \"\"\" Testing of plot_lap_trajectories_2d \"\"\"\n",
    "    print(f'active_config.plotting_config: {active_config.plotting_config}')\n",
    "    single_combined_plot=True\n",
    "    if single_combined_plot:\n",
    "        default_plotting = True\n",
    "    else:\n",
    "        default_plotting = False\n",
    "    active_config.plotting_config.plotter_type = 'MultiPlotter'\n",
    "    print(f'active_config.plotting_config: {active_config.plotting_config}')\n",
    "    iplapsDataExplorer = InteractiveCustomDataExplorer(active_config, sess, extant_plotter=extant_plotter)\n",
    "    pActiveInteractiveLapsPlotter = iplapsDataExplorer.plot(pActivePlotter=extant_plotter, default_plotting=default_plotting)\n",
    "    # included_cell_idxs = None\n",
    "    included_cell_idxs = [0, 1]\n",
    "    # included_lap_idxs = [2, 5, 9, 12]\n",
    "    included_lap_idxs = [2]\n",
    "    # All\n",
    "    # included_cell_idxs = np.arange(len(sess.spikes_df.spikes.neuron_ids))\n",
    "    # included_lap_idxs = np.arange(len(sess.laps.lap_id))\n",
    "    from PhoPositionalData.plotting.laps import plot_lap_trajectories_3d\n",
    "    pActiveInteractiveLapsPlotter, laps_pages = plot_lap_trajectories_3d(sess, curr_num_subplots=5, active_page_index=0, included_lap_idxs=included_lap_idxs, single_combined_plot=single_combined_plot, \n",
    "                                                                         lap_start_z = lap_start_z, lap_id_dependent_z_offset = lap_id_dependent_z_offset,\n",
    "                                                                         existing_plotter=pActiveInteractiveLapsPlotter)\n",
    "\n",
    "    # add the spikes for the curves:\n",
    "    _plot_all_lap_spikes(pActiveInteractiveLapsPlotter, sess, included_cell_idxs, included_lap_idxs, lap_start_z=lap_start_z, lap_id_dependent_z_offset=lap_id_dependent_z_offset)\n",
    "    return iplapsDataExplorer, pActiveInteractiveLapsPlotter\n",
    "\n",
    "\n",
    "# curr_kdiba_pipeline.computation_results['maze1'].computation_config\n",
    "# curr_kdiba_pipeline.computation_results['maze1'].sess.config\n",
    "# curr_kdiba_pipeline.active_configs['maze1']\n",
    "\n",
    "curr_result_label = 'maze1'\n",
    "sess = curr_kdiba_pipeline.filtered_sessions[curr_result_label]\n",
    "sess = curr_kdiba_pipeline.sess\n",
    "\n",
    "pActiveInteractiveLapsPlotter = None\n",
    "try: pActiveInteractiveLapsPlotter\n",
    "except NameError: pActiveInteractiveLapsPlotter = None # Checks variable p's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "iplapsDataExplorer, pActiveInteractiveLapsPlotter = _display_testing(sess, curr_kdiba_pipeline.computation_results[curr_result_label], curr_kdiba_pipeline.active_configs[curr_result_label],\n",
    "                                                                     extant_plotter=pActiveInteractiveLapsPlotter)\n",
    "pActiveInteractiveLapsPlotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e5881e-3e37-4d8b-b5c3-0c8837cbd1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines_from_points(pdata.points)\n",
    "\n",
    "\n",
    "np.shape(all_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580c6e6-38b1-4d6e-bf09-6b60842a922a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a0d93-16ac-4240-a373-7bd9f337f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, laps_pages = _plot_lap_trajectories_combined_plot_3d(curr_kdiba_pipeline.sess, curr_num_subplots=5, single_combined_plot=False)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86802581-69ea-4aca-a673-e4e306d6e17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
