{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6088dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: pho\n",
    "\"\"\"\n",
    "import sys\n",
    "from threading import Thread\n",
    "import time # for time.sleep\n",
    "from ipygany import PolyMesh, Scene, IsoColor, WarpByScalar\n",
    "import pyvista as pv\n",
    "import pyvistaqt as pvqt\n",
    "import colorcet as cc # Colormaps:\n",
    "import numpy as np\n",
    "import h5py\n",
    "import hdf5storage # conda install hdf5storage\n",
    "from pathlib import Path\n",
    "import bqplot.scales\n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "# import mplcursors\n",
    "import math # For color map generation\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.cm import hsv\n",
    "\n",
    "import ipywidgets as widgets\n",
    "# from PyQt5 import QtWidgets, uic\n",
    "from pyvistaqt import QtInteractor, MainWindow\n",
    "# from pyqt6 import QApplication\n",
    "from IPython.external.qt_for_kernel import QtGui\n",
    "from PyQt5.QtWidgets import QApplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313eba69-5c27-4e2d-8563-2220af614aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PhoPositionalData as pdp\n",
    "# from PhoPositionalData import load_exported, process_data\n",
    "from PhoPositionalData.load_exported import *\n",
    "# from PhoPositionalData.process_data import process_positionalAnalysis_data, gen_2d_histrogram, get_heatmap_color_vectors, process_chunk_equal_poritions_data, extract_spike_timeseries\n",
    "from PhoPositionalData.process_data import *\n",
    "from PhoPositionalData.plot_data import *\n",
    "from PhoPositionalData.plotting.animations import * # make_mp4_from_plotter, apply_close_overhead_zoomed_camera_view\n",
    "from PhoPositionalData.import_data import * # build_spike_positions_list, build_cellID_reverse_lookup_map\n",
    "from PhoPositionalData.analysis.interactive_placeCell_config import InteractivePlaceCellConfig, VideoOutputModeConfig, PlottingConfig  # VideoOutputModeConfig, InteractivePlaceCellConfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7773a93a-d1a0-4403-93dd-755468f86751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "try:\n",
    "    from neuropy import core\n",
    "except ImportError:\n",
    "    sys.path.append(r'C:\\Users\\Pho\\repos\\NeuroPy') # Windows\n",
    "    # sys.path.append('/home/pho/repo/BapunAnalysis2021/NeuroPy') # Linux\n",
    "    # sys.path.append(r'/Users/pho/repo/Python Projects/NeuroPy') # MacOS\n",
    "    print('neuropy module not found, adding directory to sys.path. \\n >> Updated sys.path.')\n",
    "    from neuropy import core\n",
    "from neuropy.core.dataSession import DataSessionLoader, DataSession, processDataSession\n",
    "\n",
    "# basedir = '/media/share/data/Bapun/Day5TwoNovel' # Linux\n",
    "# basedir = 'R:\\data\\Bapun\\Day5TwoNovel' # Windows\n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15' # Windows\n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53' # Windows\n",
    "# basedir = '/Volumes/iNeo/Data/Bapun/Day5TwoNovel' # MacOS\n",
    "\n",
    "# from neuropy.io.neuroscopeio import NeuroscopeIO\n",
    "\n",
    "## No Pre-processing required\n",
    "# base_neuroscope_xml_file = Path(basedir).joinpath('2006-6-08_14-26-15.xml')\n",
    "\n",
    "# From pre-computed .mat files:\n",
    "## 07: \n",
    "basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53'\n",
    "spike_file = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.spikeII.mat'\n",
    "neuroscope_xml_file = Path(basedir).joinpath('2006-6-07_11-26-53.xml')\n",
    "\n",
    "# ## 08:\n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15'\n",
    "# spike_file = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\2006-6-08_14-26-15.spikeII.mat' # '2006-6-08_14-26-15.spikeII.mat' # Contains 'spike' flat structure\n",
    "# neuroscope_xml_file = Path(basedir).joinpath('2006-6-08_14-26-15.xml')\n",
    "\n",
    "# sess = core.processDataSession(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ab3ca17-6979-427e-a1a6-f352813f25e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t basepath: R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\n",
      "\t session_name: 2006-6-07_11-26-53\n",
      "Loading matlab import file: R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.spikeII.mat...\n",
      "done.\n",
      "Loading matlab import file: R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position_info.mat...\n",
      "done.\n",
      "Loading matlab import file: R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.epochs_info.mat...\n",
      "done.\n",
      "computing linear positions for all active epochs for session...\n",
      "session.position linear positions could not be computed due to error Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required.. Skipping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataSession(2006-6-07_11-26-53.xml)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_args_dict = dict()\n",
    "curr_args_dict['basepath'] = basedir\n",
    "curr_args_dict['session_obj'] = DataSession()\n",
    "# curr_session = DataSessionLoader.default_load_bapun_npy_session_folder(curr_args_dict)\n",
    "sess = DataSessionLoader.default_load_kamran_flat_spikes_mat_session_folder(curr_args_dict)\n",
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb5aec9c-f343-4e9f-81dd-2e5f8ca94b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading matlab import file: R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position_info.mat...\n",
      "done.\n",
      "np.shape(t): (59308,)\n",
      "np.shape(x): (59308,)\n",
      "np.shape(y): (59308,)\n",
      "type(position_sampling_rate_Hz): <class 'float'>\n",
      "type(microseconds_to_seconds_conversion_factor): <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "session_name = Path(basedir).parts[-1]\n",
    "session_position_mat_file_path = Path(basedir).joinpath('{}.position_info.mat'.format(session_name))\n",
    "position_mat_file = import_mat_file(mat_import_file=session_position_mat_file_path)\n",
    "# ['microseconds_to_seconds_conversion_factor','samplingRate', 'timestamps', 'x', 'y']\n",
    "t = position_mat_file['timestamps'].squeeze() # 1, 63192\n",
    "print('np.shape(t): {}'.format(np.shape(t))) # np.shape(t): (59308,)\n",
    "x = position_mat_file['x'].squeeze() # 10 x 63192\n",
    "print('np.shape(x): {}'.format(np.shape(x))) # np.shape(x): (59308,)\n",
    "y = position_mat_file['y'].squeeze() # 10 x 63192\n",
    "print('np.shape(y): {}'.format(np.shape(y))) # np.shape(y): (59308,)\n",
    "position_sampling_rate_Hz = position_mat_file['samplingRate'].item() # In Hz, returns 29.969777\n",
    "# print('np.shape(position_sampling_rate_Hz): {}'.format(np.shape(position_sampling_rate_Hz))) # np.shape(position_sampling_rate_Hz): (59308,)\n",
    "print('type(position_sampling_rate_Hz): {}'.format(type(position_sampling_rate_Hz))) # np.shape(position_sampling_rate_Hz): (59308,)\n",
    "microseconds_to_seconds_conversion_factor = position_mat_file['microseconds_to_seconds_conversion_factor'].item()\n",
    "print('type(microseconds_to_seconds_conversion_factor): {}'.format(type(microseconds_to_seconds_conversion_factor))) # np.shape(microseconds_to_seconds_conversion_factor): (59308,)\n",
    "# print('np.shape(microseconds_to_seconds_conversion_factor): {}'.format(np.shape(microseconds_to_seconds_conversion_factor))) # np.shape(microseconds_to_seconds_conversion_factor): (59308,)\n",
    "\n",
    "t_rel = t - t[0] # relative to start of position file timestamps\n",
    "num_samples = len(t)\n",
    "\n",
    "# active_t_start = t[0] # absolute t_start\n",
    "active_t_start = 0.0 # relative t_start\n",
    "# active_t_start = (spikes_df.t.loc[spikes_df.x.first_valid_index()] * timestamp_scale_factor) # actual start time in seconds\n",
    "temp_position = core.Position(traces=np.vstack((x, y)), computed_traces=np.full([1, num_samples], np.nan), t_start=active_t_start, sampling_rate=position_sampling_rate_Hz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75b9b105-0a43-4edd-85df-6c929ea150e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>506917.636049</td>\n",
       "      <td>508656.789413</td>\n",
       "      <td>maze1</td>\n",
       "      <td>1739.153364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>508656.789413</td>\n",
       "      <td>508850.056054</td>\n",
       "      <td>maze2</td>\n",
       "      <td>193.266641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           start           stop  label     duration\n",
       "0  506917.636049  508656.789413  maze1  1739.153364\n",
       "1  508656.789413  508850.056054  maze2   193.266641"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.epochs.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3912985-25d6-4602-baea-6e7ff0ed5395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.shape(sess.position.traces): (2, 59308)\n",
      "sess.position.time: [0.00000000e+00 3.33675232e-02 6.67350464e-02 ... 1.97886096e+03\n",
      " 1.97889433e+03 1.97892770e+03]\n",
      " sess.position.duration: 1978.9276969605419\n",
      " sess.position.time[-1]: 1978.9276969605419\n",
      " sess.position.time[0]: 0.0\n",
      " sess.position.sampling_rate: 29.96976599553983\n",
      " sess.position.t_start: 0.0\n",
      " sess.position.t_stop: 1978.9276969605419\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>lin_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>104.287278</td>\n",
       "      <td>100.981569</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033368</td>\n",
       "      <td>104.287278</td>\n",
       "      <td>100.981569</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.066735</td>\n",
       "      <td>104.287278</td>\n",
       "      <td>100.981569</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100103</td>\n",
       "      <td>104.287278</td>\n",
       "      <td>100.981569</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133470</td>\n",
       "      <td>104.287278</td>\n",
       "      <td>100.981569</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59303</th>\n",
       "      <td>1978.794227</td>\n",
       "      <td>75.767781</td>\n",
       "      <td>140.059733</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59304</th>\n",
       "      <td>1978.827594</td>\n",
       "      <td>75.766816</td>\n",
       "      <td>140.106978</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59305</th>\n",
       "      <td>1978.860962</td>\n",
       "      <td>75.735555</td>\n",
       "      <td>140.106496</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59306</th>\n",
       "      <td>1978.894329</td>\n",
       "      <td>75.593275</td>\n",
       "      <td>140.042007</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59307</th>\n",
       "      <td>1978.927697</td>\n",
       "      <td>75.367949</td>\n",
       "      <td>139.998930</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59308 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 t           x           y  lin_pos\n",
       "0         0.000000  104.287278  100.981569      NaN\n",
       "1         0.033368  104.287278  100.981569      NaN\n",
       "2         0.066735  104.287278  100.981569      NaN\n",
       "3         0.100103  104.287278  100.981569      NaN\n",
       "4         0.133470  104.287278  100.981569      NaN\n",
       "...            ...         ...         ...      ...\n",
       "59303  1978.794227   75.767781  140.059733      NaN\n",
       "59304  1978.827594   75.766816  140.106978      NaN\n",
       "59305  1978.860962   75.735555  140.106496      NaN\n",
       "59306  1978.894329   75.593275  140.042007      NaN\n",
       "59307  1978.927697   75.367949  139.998930      NaN\n",
       "\n",
       "[59308 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sess.position.traces) # (2, 1014937)\n",
    "print('np.shape(sess.position.traces): {}'.format(np.shape(sess.position.traces))) # (2, 59308)\n",
    "print('sess.position.time: {}\\n sess.position.duration: {}\\n sess.position.time[-1]: {}\\n sess.position.time[0]: {}\\n sess.position.sampling_rate: {}\\n sess.position.t_start: {}\\n sess.position.t_stop: {}\\n'.format(\n",
    "    sess.position.time,\n",
    "    sess.position.duration,\n",
    "    sess.position.time[-1],\n",
    "    sess.position.time[0],\n",
    "    sess.position.sampling_rate,\n",
    "    sess.position.t_start,\n",
    "    sess.position.t_stop))\n",
    "\n",
    "# sess.position.time\n",
    "# sess.position.to_dict()\n",
    "sess.position.time # [603785.449121, ..., 605893.97363495]\n",
    "# d = {\"t\": sess.position.time.flatten(), \"x\": sess.position.x.flatten(), \"y\": sess.position.y.flatten(), \"lin_pos\": sess.position.linear_pos.flatten()}\n",
    "df = pd.DataFrame({\"t\": sess.position.time.flatten(), \"x\": sess.position.x.flatten(), \"y\": sess.position.y.flatten(), \"lin_pos\": sess.position.linear_pos.flatten()})\n",
    "df\n",
    "# 42305.\n",
    "# sess.position.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2372f346-14c5-4f92-9761-bd74a2ae52f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_epoch_times: [506917.636049   508656.78941312]\n",
      "active_epoch_times[0]: 506917.63604899996, active_epoch_times[1]: 508656.7894131185\n",
      "acitve_epoch_timeslice_indicies: [False False False ... False False False]\n",
      "active_epoch_pos: <neuropy.core.position.Position object at 0x0000019934590D00>\n"
     ]
    }
   ],
   "source": [
    "# sess.epochs['maze1'] # array([506917.636049  , 508656.78941312])\n",
    "active_epochLabelName = 'maze1'\n",
    "active_epoch_times = sess.epochs[active_epochLabelName] # array([11070, 13970], dtype=int64)\n",
    "print('active_epoch_times: {}'.format(active_epoch_times))\n",
    "acitve_epoch_timeslice_indicies = sess.position.time_slice_indicies(active_epoch_times[0], active_epoch_times[1])\n",
    "print('active_epoch_times[0]: {}, active_epoch_times[1]: {}'.format(active_epoch_times[0], active_epoch_times[1]))\n",
    "print('acitve_epoch_timeslice_indicies: {}'.format(acitve_epoch_timeslice_indicies))\n",
    "active_epoch_pos = sess.position.time_slice(active_epoch_times[0], active_epoch_times[1])\n",
    "print('active_epoch_pos: {}'.format(active_epoch_pos))        \n",
    "# sess.neurons.t_start # 0\n",
    "# sess.neurons.t_stop # 68624338; 68,624,338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc9fba3-d3a4-4d53-890b-bf661097328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition importepochsCA\n",
    "from sklearn.manifold import Isomap\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def linearize_position(position: core.Position, sample_sec=3, method=\"isomap\", sigma=2):\n",
    "    \"\"\"linearize trajectory. Use method='PCA' for off-angle linear track, method='ISOMAP' for any non-linear track.\n",
    "    ISOMAP is more versatile but also more computationally expensive.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    track_names: list of track names, each must match an epoch in epochs class.\n",
    "    sample_sec : int, optional\n",
    "        sample a point every sample_sec seconds for training ISOMAP, by default 3. Lower it if inaccurate results\n",
    "    method : str, optional\n",
    "        by default 'ISOMAP' (for any continuous track, untested on t-maze as of 12/22/2020) or\n",
    "        'PCA' (for straight tracks)\n",
    "\n",
    "    \"\"\"\n",
    "    xpos = position.x\n",
    "    ypos = position.y\n",
    "\n",
    "    xy_pos = np.vstack((xpos, ypos)).T\n",
    "    xlinear = None\n",
    "    if method.lower() == \"pca\":\n",
    "        pca = PCA(n_components=1)\n",
    "        xlinear = pca.fit_transform(xy_pos).squeeze()\n",
    "    elif method.lower() == \"isomap\":\n",
    "        imap = Isomap(n_neighbors=5, n_components=2)\n",
    "        # downsample points to reduce memory load and time\n",
    "        pos_ds = xy_pos[0 : -1 : np.round(int(position.sampling_rate) * sample_sec)]\n",
    "        imap.fit(pos_ds)\n",
    "        iso_pos = imap.transform(xy_pos)\n",
    "        # Keep iso_pos here in case we want to use 2nd dimension (transverse to track) in future...\n",
    "        if iso_pos.std(axis=0)[0] < iso_pos.std(axis=0)[1]:\n",
    "            iso_pos[:, [0, 1]] = iso_pos[:, [1, 0]]\n",
    "        xlinear = iso_pos[:, 0]\n",
    "    else:\n",
    "        print('ERROR: invalid method name: {}'.format(method))\n",
    "    xlinear = gaussian_filter1d(xlinear, sigma=sigma)\n",
    "    return core.Position(\n",
    "        traces=xlinear, t_start=position.t_start, sampling_rate=position.sampling_rate\n",
    "    )\n",
    "\n",
    "def compute_linearized_position(session, epochLabelName='maze1', method='isomap'):\n",
    "        # returns Position objects for active_epoch_pos and linear_pos\n",
    "        active_epoch_times = session.epochs[epochLabelName] # array([11070, 13970], dtype=int64)\n",
    "        acitve_epoch_timeslice_indicies = session.position.time_slice_indicies(active_epoch_times[0], active_epoch_times[1])\n",
    "        active_epoch_pos = session.position.time_slice(active_epoch_times[0], active_epoch_times[1])\n",
    "        linear_pos = linearize_position(active_epoch_pos, method=method)\n",
    "        return acitve_epoch_timeslice_indicies, active_epoch_pos, linear_pos\n",
    "\n",
    "print('computing linear positions for all active epochs for session...')\n",
    "# end result will be session.computed_traces of the same length as session.traces in terms of frames, with all non-maze times holding NaN values\n",
    "sess.position.computed_traces = np.full([1, sess.position.traces.shape[1]], np.nan)\n",
    "# acitve_epoch_timeslice_indicies1, active_positions_maze1, linearized_positions_maze1 = DataSession.compute_linearized_position(session, epochLabelName='maze', method='pca')\n",
    "# session.position.computed_traces[0,  acitve_epoch_timeslice_indicies1] = linearized_positions_maze1.traces\n",
    "acitve_epoch_timeslice_indicies1, active_positions_maze1, linearized_positions_maze1 = compute_linearized_position(sess, epochLabelName='maze1', method='pca')\n",
    "acitve_epoch_timeslice_indicies2, active_positions_maze2, linearized_positions_maze2 = compute_linearized_position(sess, epochLabelName='maze2', method='pca')\n",
    "sess.position.computed_traces[0,  acitve_epoch_timeslice_indicies1] = linearized_positions_maze1.traces\n",
    "sess.position.computed_traces[0,  acitve_epoch_timeslice_indicies2] = linearized_positions_maze2.traces\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f948b0-b828-44cf-9f12-ed87b9aab3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: The only place that I need to be careful with indexing is with sess.position properties, as these appear to be represented in terms of the number of 60Hz samples instead of in seconds like the Neurons and other classes.\n",
    "# active_epoch_name = 'maze1'\n",
    "active_epoch_name = 'maze'\n",
    "active_subplots_shape = (1,1) # Single subplot\n",
    "# active_subplots_shape = '1|2' # 1 subplot on left, two on right\n",
    "active_config = InteractivePlaceCellConfig(active_epoch_name,\n",
    "                    VideoOutputModeConfig(active_frame_range=np.arange(11070.0, 13970.0), video_output_parent_dir=Path('output', active_epoch_name), active_is_video_output_mode=False),\n",
    "                    PlottingConfig(output_subplots_shape=active_subplots_shape, output_parent_dir=Path('output', active_epoch_name))) # '3|1\n",
    "active_epoch_times = sess.epochs[active_config.active_epochs] \n",
    "# active_epoch_times = sess.epochs['maze2']  # np.arange(15200.0, 18000.0)\n",
    "# active_epoch_times = sess.epochs['maze1']  # array([11070, 13970], dtype=int64)\n",
    "print('Constraining to epoch with times (start: {}, end: {})'.format(active_epoch_times[0], active_epoch_times[1]))\n",
    "\n",
    "# (start: 603785449121.0, end: 603785451229.5245); (start: 603,785,449,121.0, end: 603,785,451,229.5245)\n",
    "# active_epoch_session_Neurons = sess.neurons.get_neuron_type('pyramidal')\n",
    "# active_epoch_session_Neurons = sess.neurons.time_slice(active_epoch_times[0], active_epoch_times[1]) # Filter by pyramidal cells only, returns a core.Neurons object with its spiketrains filtered for the provided start/end times\n",
    "active_epoch_session_Neurons = sess.neurons.get_neuron_type('pyramidal').time_slice(active_epoch_times[0], active_epoch_times[1]) # Filter by pyramidal cells only, returns a core.Neurons object with its spiketrains filtered for the provided start/end times\n",
    "active_epoch_position_times_index_mask = sess.position.time_slice_indicies(active_epoch_times[0], active_epoch_times[1]) # a Boolean selection mask\n",
    "active_epoch_position_times = sess.position.time[active_epoch_position_times_index_mask] # The actual times\n",
    "active_epoch_relative_position_times = active_epoch_position_times - active_epoch_position_times[0] # Subtract off the first index, so that it becomes zero\n",
    "active_epoch_pos = sess.position.time_slice(active_epoch_times[0], active_epoch_times[1]) # active_epoch_pos's .time and start/end are all valid\n",
    "# have active_epoch_position_times: the actual times each position sample occured in seconds, active_epoch_relative_position_times: the same as active_epoch_position_times but starting at zero. Finally, have a complete active_epoch_pos object\n",
    "\n",
    "print(active_epoch_pos)\n",
    "str(active_epoch_pos.linear_pos_obj)\n",
    "\n",
    "active_epoch_session_Neurons.n_spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e911b9-8b4e-451b-a064-e5a04c61e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Placefields if needed:\n",
    "from neuropy.analyses import Pf1D, Pf2D\n",
    "from neuropy.plotting.spikes import get_neuron_colors\n",
    "\n",
    "should_force_recompute_placefields = True\n",
    "\n",
    "try: active_epoch_placefields\n",
    "except NameError: active_epoch_placefields = None # Checks variable active_epoch_placefields's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "if ((active_epoch_placefields is None) or should_force_recompute_placefields):\n",
    "    print('Recomputing active_epoch_placefields...')\n",
    "    active_epoch_placefields1D = Pf1D(neurons=active_epoch_session_Neurons, position=active_epoch_pos.linear_pos_obj, speed_thresh=4, grid_bin=4)\n",
    "    ax_pf_1D = active_epoch_placefields1D.plot_ratemaps()\n",
    "    active_pf_1D_identifier_string = '1D Placefields - {}'.format(active_epoch_name)\n",
    "    plt.title(active_pf_1D_identifier_string)\n",
    "    active_pf_1D_output_filename = '{}.pdf'.format(active_pf_1D_identifier_string)\n",
    "    active_pf_1D_output_filepath = active_config.plotting_config.active_output_parent_dir.joinpath(active_pf_1D_output_filename)\n",
    "    print('Saving 1D Placefield image out to \"{}\"...'.format(active_pf_1D_output_filepath))\n",
    "    plt.savefig(active_pf_1D_output_filepath)          \n",
    "    # active_epoch_placefields = active_epoch_placefields1D\n",
    "    print('done.')\n",
    "else:\n",
    "    print('active_epoch_placefields already exists, reusing it')\n",
    "    \n",
    "try: active_epoch_placefields2D\n",
    "except NameError: active_epoch_placefields2D = None # Checks variable active_epoch_placefields's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "if ((active_epoch_placefields2D is None) or should_force_recompute_placefields):\n",
    "    print('Recomputing active_epoch_placefields2D...')\n",
    "    active_epoch_placefields2D = Pf2D(neurons=active_epoch_session_Neurons, position=active_epoch_pos, speed_thresh=4, grid_bin=4)\n",
    "    # active_epoch_placefields2D.plotMap(subplots=(1, 1),figsize=(10,10))\n",
    "    # active_pf_2D_figures, active_pf_2D_gs = active_epoch_placefields2D.plotMap(subplots=(4, 4),figsize=(10, 10))\n",
    "    # active_epoch_placefields2D.occupancy # (37, 38) = (len(active_epoch_placefields2D.ratemap.xbin_centers), len(active_epoch_placefields2D.ratemap.ybin_centers))\n",
    "    active_pf_occupancy_2D_identifier_string = '2D Occupancy - {}'.format(active_epoch_name)\n",
    "    occupancy_fig = plt.figure()\n",
    "    occupancy_ax = occupancy_fig.gca()\n",
    "    im = occupancy_ax.pcolorfast(\n",
    "        active_epoch_placefields2D.ratemap.xbin_centers,\n",
    "        active_epoch_placefields2D.ratemap.ybin_centers,\n",
    "        np.rot90(np.fliplr(active_epoch_placefields2D.occupancy)) / np.max(active_epoch_placefields2D.occupancy),\n",
    "        cmap=\"jet\",\n",
    "        vmin=0,\n",
    "    )  # rot90(flipud... is necessary to match plotRaw configuration.\n",
    "    plt.title(active_pf_occupancy_2D_identifier_string)\n",
    "    plt.show()\n",
    "    # Save ocupancy figure out to disk:\n",
    "    active_pf_occupancy_2D_output_filename = '{}.pdf'.format(active_pf_occupancy_2D_identifier_string)\n",
    "    active_pf_occupancy_2D_output_filepath = active_config.plotting_config.active_output_parent_dir.joinpath(active_pf_occupancy_2D_output_filename)\n",
    "    print('Saving 2D Placefield image out to \"{}\"...'.format(active_pf_occupancy_2D_output_filepath))\n",
    "    occupancy_fig.savefig(active_pf_occupancy_2D_output_filepath)\n",
    "    print('done.')\n",
    "    ## 2D Tuning Curves Figure:\n",
    "    active_pf_2D_figures, active_pf_2D_gs = active_epoch_placefields2D.plotMap(subplots=(7, 7),figsize=(10, 10))\n",
    "    # active_epoch_placefields2D.plotRaw()\n",
    "    active_pf_2D_identifier_string = '2D Placefields - {}'.format(active_epoch_name)\n",
    "    # plt.title(active_pf_2D_identifier_string)\n",
    "    active_pf_2D_output_filename = '{}.pdf'.format(active_pf_2D_identifier_string)\n",
    "    active_pf_2D_output_filepath = active_config.plotting_config.active_output_parent_dir.joinpath(active_pf_2D_output_filename)\n",
    "    print('Saving 2D Placefield image out to \"{}\"...'.format(active_pf_2D_output_filepath))\n",
    "    for aFig in active_pf_2D_figures:\n",
    "        aFig.savefig(active_pf_2D_output_filepath)\n",
    "    print('done.')\n",
    "else:\n",
    "    print('active_epoch_placefields already exists, reusing it')\n",
    "    \n",
    "active_epoch_placefields = active_epoch_placefields2D\n",
    "\n",
    "# Get the cell IDs that have a good place field mapping:\n",
    "good_placefield_neuronIDs = np.array(active_epoch_placefields.ratemap.neuron_ids) # in order of ascending ID\n",
    "good_placefield_neuronIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5658e0b-4de2-481d-8c5a-2faa5024052c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Plots the tuning curves one at a time, and also can plot them without very low probabilitiy entries (by setting these entries to np.nan)\n",
    "curr_tuning_curves = active_epoch_placefields.ratemap.tuning_curves\n",
    "# curr_tuning_curves = active_epoch_placefields.ratemap.normalized_tuning_curves\n",
    "curr_index = 5\n",
    "curr_unitID = active_epoch_placefields2D.cell_ids[curr_index]\n",
    "curr_identifier_string = '2D Placemap - {} - Unit[{}] (ID {})'.format(active_epoch_name, curr_index, curr_unitID)\n",
    "curr_data = curr_tuning_curves[curr_index]\n",
    "curr_data_min_val = np.min(curr_data)\n",
    "curr_data_max_val = np.max(curr_data)\n",
    "curr_data[curr_data < 0.01] = np.nan\n",
    "print('curr_data_min_val: {}; curr_data_max_val: {}'.format(curr_data_min_val, curr_data_max_val))\n",
    "curr_fig = plt.figure()\n",
    "curr_ax = curr_fig.gca()\n",
    "im = curr_ax.pcolorfast(\n",
    "    active_epoch_placefields2D.ratemap.xbin_centers,\n",
    "    active_epoch_placefields2D.ratemap.ybin_centers,\n",
    "    np.rot90(np.fliplr(curr_data)),\n",
    "    cmap=\"jet\",\n",
    "    vmin=0,\n",
    ")  # rot90(flipud... is necessary to match plotRaw configuration.\n",
    "plt.title(curr_identifier_string)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2611563-244e-4c04-823f-25d9013458bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pf_ax, pf_sort_ind, pf_colors = active_epoch_placefields.plot_ratemaps()\n",
    "# from neuropy.utils import mathutil\n",
    "# curr_tuning_curves = mathutil.min_max_scaler(active_epoch_placefields.ratemap.tuning_curves) # 37x25x27 ndarray\n",
    "# curr_tuning_curves = active_epoch_placefields.ratemap.tuning_curves\n",
    "curr_tuning_curves = active_epoch_placefields.ratemap.normalized_tuning_curves\n",
    "# sort_ind = np.argsort(np.argmax(curr_tuning_curves, axis=1))\n",
    "# ind = np.unravel_index(np.argsort(curr_tuning_curves, axis=None), curr_tuning_curves.shape)\n",
    "num_curr_tuning_curves = len(curr_tuning_curves)\n",
    "pf_sort_ind = np.arange(num_curr_tuning_curves)\n",
    "pf_colors = get_neuron_colors(pf_sort_ind)\n",
    "pf_sort_ind = np.array([int(pf_sort_ind[i]) for i in np.arange(len(pf_sort_ind))]) # convert to integer scalar array\n",
    "pf_sorted_good_placefield_neuronIDs = good_placefield_neuronIDs[pf_sort_ind]\n",
    "reverse_color_sort_indices = np.argsort(pf_sort_ind)\n",
    "pf_colors = pf_colors[:, reverse_color_sort_indices] # pf_colors shape is still (4, 31)\n",
    "active_epoch_session_Neurons = active_epoch_session_Neurons.get_by_id(good_placefield_neuronIDs) # Filter by good placefields only\n",
    "\n",
    "# Unpacking final values into separate variables:\n",
    "# Spike variables:\n",
    "num_cells = active_epoch_session_Neurons.n_neurons\n",
    "spike_list = active_epoch_session_Neurons.spiketrains\n",
    "cell_ids = active_epoch_session_Neurons.neuron_ids\n",
    "flattened_spikes = active_epoch_session_Neurons.get_flattened_spikes() # get_flattened_spikes(..) returns a FlattenedSpiketrains object\n",
    "# Position variables: t, x, y\n",
    "t = active_epoch_pos.time\n",
    "x = active_epoch_pos.x\n",
    "y = active_epoch_pos.y\n",
    "linear_pos = active_epoch_pos.linear_pos\n",
    "# speeds = active_epoch_pos.speed # note this has 1 less element than active_epoch_pos.x\n",
    "# Determine the x and y positions each spike occured for each cell\n",
    "spike_positions_list = build_spike_positions_list(spike_list, t, x, y)\n",
    "reverse_cellID_idx_lookup_map = build_cellID_reverse_lookup_map(cell_ids)\n",
    "print('num_cells: {}'.format(num_cells))\n",
    "print('cell_ids: {}'.format(cell_ids)) # cell_ids is now a regular python list with 57 elements\n",
    "\n",
    "active_cells_colormap = pf_colors.T # Make the colormap from the listed colors\n",
    "active_cells_listed_colormap = ListedColormap(active_cells_colormap)\n",
    "\n",
    "# Gets the flattened spikes, sorted in ascending timestamp for all cells.\n",
    "num_flattened_spikes = np.size(flattened_spikes.flattened_spike_times)\n",
    "print('num_flattened_spikes: {}'.format(num_flattened_spikes))\n",
    "# Build the Active UnitIDs\n",
    "flattened_spike_active_unitIdentities = np.array([int(reverse_cellID_idx_lookup_map[original_cellID]) for original_cellID in flattened_spikes.flattened_spike_identities]) # since flattened_spikes.flattened_spike_identities is already sorted, don't double sort\n",
    "## Build the flattened spike positions list\n",
    "flattened_spike_positions_list = np.concatenate(tuple(spike_positions_list), axis=1) # needs tuple(...) to conver the list into a tuple, which is the format it expects\n",
    "flattened_spike_positions_list = flattened_spike_positions_list[:, flattened_spikes.flattened_sort_indicies] # ensure the positions are ordered the same as the other flattened items so they line up\n",
    "print('flattened_spike_positions_list: {}'.format(np.shape(flattened_spike_positions_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b3d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have active_epoch_position_times: the actual times each position sample occured in seconds, active_epoch_relative_position_times: the same as active_epoch_position_times but starting at zero\n",
    "# describe the movement\n",
    "\n",
    "from PhoPositionalData.plotting.visualization_window import VisualizationWindow # Used to build \"Windows\" into the data points such as the window defining the fixed time period preceeding the current time where spikes had recently fired, etc.\n",
    "\n",
    "# Split the position data into equal sized chunks to be displayed at a single time. These will look like portions of the trajectory and be used to animate. # Chunk the data to create the animation.\n",
    "curr_plot_update_step = 1 # Update every frame\n",
    "curr_plot_update_frequency = curr_plot_update_step * active_epoch_pos.sampling_rate # number of updates per second (Hz)\n",
    "num_time_points = active_epoch_pos.n_frames / curr_plot_update_step\n",
    "print('active_epoch_pos.sampling_rate (Hz): {}'.format(active_epoch_pos.sampling_rate))\n",
    "\n",
    "# curr_window_duration = 2.5 # in seconds\n",
    "# curr_view_window_length_samples = int(np.floor(curr_window_duration * active_epoch_pos.sampling_rate)) # number of samples the window should last\n",
    "# recent_spikes_window = VisualizationWindow(duration_seconds=curr_window_duration, duration_num_frames=curr_view_window_length_samples)\n",
    "\n",
    "# curr_recently_window_duration = 0.5 # in seconds\n",
    "# curr_view_window_length_samples = int(np.floor(curr_window_duration * active_epoch_pos.sampling_rate)) # number of samples the window should last\n",
    "\n",
    "## Simplified with just two windows:\n",
    "longer_spikes_window = VisualizationWindow(duration_seconds=1024.0, sampling_rate=active_epoch_pos.sampling_rate) # have it start clearing spikes more than 30 seconds old\n",
    "curr_view_window_length_samples = longer_spikes_window.duration_num_frames # number of samples the window should last\n",
    "print('longer_spikes_window - curr_view_window_length_samples - {}'.format(curr_view_window_length_samples))\n",
    "\n",
    "recent_spikes_window = VisualizationWindow(duration_seconds=1.0, sampling_rate=active_epoch_pos.sampling_rate)\n",
    "curr_view_window_length_samples = recent_spikes_window.duration_num_frames # number of samples the window should last\n",
    "print('recent_spikes_window - curr_view_window_length_samples - {}'.format(curr_view_window_length_samples))\n",
    "\n",
    "## Build the sliding windows:\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "# build a sliding window to be able to retreive the correct flattened indicies for any given timestep\n",
    "active_epoch_position_linear_indicies = np.arange(np.size(active_epoch_position_times))\n",
    "pre_computed_window_sample_indicies = recent_spikes_window.build_sliding_windows(active_epoch_position_linear_indicies)\n",
    "# print('pre_computed_window_sample_indicies: {}\\n shape: {}'.format(pre_computed_window_sample_indicies, np.shape(pre_computed_window_sample_indicies)))\n",
    "\n",
    "## New Pre Computed Indicies Way:\n",
    "z_fixed = np.full((recent_spikes_window.duration_num_frames,), 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a014c-ae46-4e43-8095-91dbc11d3ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ICA and PCA Analysis\n",
    "should_show_2D_ICA_plots = False\n",
    "from PhoPositionalData.analysis.neuronal_dimensionality_reduction import runAnalysis_PCAandICA\n",
    "active_session_ensembles, template, zsc_template, pca_data = runAnalysis_PCAandICA(active_epoch_session_Neurons, bin_size=0.250, frate_thresh=0.1, should_plot=should_show_2D_ICA_plots, active_cells_colormap=active_cells_colormap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bca1e4-77d4-4a42-9883-57f0ff6431d4",
   "metadata": {},
   "source": [
    "## Main Spike/Placemap plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d92bd2e-138f-4df6-8731-12fbdd3c950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PhoPositionalData.plotting.gui import customize_default_pyvista_theme, print_controls_helper_text\n",
    "customize_default_pyvista_theme() # Sets the default theme values to those specified in my imported file\n",
    "# This defines the position of the vertical/horizontal splitting, in this case 40% of the vertical/horizontal dimension of the window\n",
    "# pv.global_theme.multi_rendering_splitting_position = 0.40\n",
    "pv.global_theme.multi_rendering_splitting_position = 0.80\n",
    "\n",
    "from PhoPositionalData.plotting.spikeAndPositions import build_active_spikes_plot_data, build_flat_map_plot_data, build_spike_spawn_effect_light_actor, spike_geom_circle, spike_geom_box, spike_geom_cone, animal_location_circle, animal_location_trail_circle\n",
    "from PhoPositionalData.plotting.spikeAndPositions import InteractiveSliderWrapper # for wrapping the slider\n",
    "num_time_points = active_epoch_pos.n_frames / curr_plot_update_step\n",
    "# print('num_time_points: {}\\n'.format(num_time_points))\n",
    "\n",
    "## Opacity Helpers:\n",
    "last_only_opacity_values = np.zeros([curr_view_window_length_samples,])\n",
    "last_only_opacity_values[-1] = 1.0\n",
    "# gradually_fading_opacity_values = np.arange(curr_view_window_length_samples)\n",
    "gradually_fading_opacity_values = np.linspace(0.0, 1.0, curr_view_window_length_samples)\n",
    "long_gradually_fading_opacity_values = np.linspace(0.0, 1.0, longer_spikes_window.duration_num_frames)\n",
    "sharply_fading_opacity_values = np.linspace(0.0, 0.6, curr_view_window_length_samples)\n",
    "# sharply_fading_opacity_values[-1] = 0.1 # last element (corresponding to current position) is set to 1.0\n",
    "\n",
    "# active_trail_opacity_values = last_only_opacity_values.copy()\n",
    "# active_trail_opacity_values = gradually_fading_opacity_values.copy()\n",
    "active_trail_opacity_values = sharply_fading_opacity_values.copy()\n",
    "# print('active_trail_opacity_values: {}\\n'.format(np.shape(active_trail_opacity_values)))\n",
    "# active_trail_size_values = np.full([curr_view_window_length_samples,], 0.6) # all have a scale of 0.6\n",
    "active_trail_size_values = np.linspace(0.2, 0.6, curr_view_window_length_samples) # fade from a scale of 0.2 to 0.6\n",
    "# active_trail_size_values[-1] = 6.0 # except for the end (current) point, which has a scale of 1.0\n",
    "# active_trail_size_values = sharply_fading_opacity_values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce9fd90-e85c-470c-be21-a258d16c8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PhoPositionalData.plotting.spikeAndPositions import plot_placefields2D, update_plotVisiblePlacefields2D\n",
    "pActiveTuningCurvesPlotter = pvqt.BackgroundPlotter(window_size=(1920, 1080), shape=(1,1), off_screen=False) # Use just like you would a pv.Plotter() instance\n",
    "pActiveTuningCurvesPlotter.clear()\n",
    "# Plot the flat arena\n",
    "pdata_maze, pc_maze = build_flat_map_plot_data(x, y)\n",
    "pActiveTuningCurvesPlotter.add_mesh(pc_maze, name='maze_bg', label='maze', color=\"black\", render=True)\n",
    "pActiveTuningCurvesPlotter, tuningCurvePlotActors, tuningCurvePlotLegendActor = plot_placefields2D(pActiveTuningCurvesPlotter, active_epoch_placefields, pf_colors, zScalingFactor=10.0)    \n",
    "\n",
    "# tuningCurvePlotActors[1].VisibilityOn()\n",
    "# legendActor = pTuningCurves.add_legend(name='tuningCurvesLegend', origin=[0.9, 0.0], size=[0.1, 1.0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d00ce8-56fc-447a-9826-aff66e7b215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_legendNumberOfEntries = tuningCurvePlotLegendActor.GetNumberOfEntries()\n",
    "# print('tuningCurvePlotLegendActor.GetPosition(): {}; tuningCurvePlotLegendActor.GetPosition2(): {};'.format(tuningCurvePlotLegendActor.GetPosition(), tuningCurvePlotLegendActor.GetPosition2()))\n",
    "# # print('tuningCurvePlotLegendActor.GetPositionCoordinate(): {}; tuningCurvePlotLegendActor.GetPosition2Coordinate(): {}'.format(tuningCurvePlotLegendActor.GetPositionCoordinate(), tuningCurvePlotLegendActor.GetPosition2Coordinate()))\n",
    "# print('tuningCurvePlotLegendActor.GetHeight(): {}; tuningCurvePlotLegendActor.GetWidth(): {};'.format(tuningCurvePlotLegendActor.GetHeight(), tuningCurvePlotLegendActor.GetWidth()))\n",
    "# print('temp_legendNumberOfEntries: {}'.format(temp_legendNumberOfEntries))\n",
    "# # tuningCurvePlotLegendActor.GetPropertyKeys()\n",
    "# for i in np.arange(temp_legendNumberOfEntries):    \n",
    "#     temp_legendEntryString = tuningCurvePlotLegendActor.GetEntryString(i)\n",
    "#     temp_legendEntrySymbol = tuningCurvePlotLegendActor.GetEntrySymbol(i)\n",
    "    \n",
    "#     # temp_legendActors = tuningCurvePlotLegendActor.GetActors(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6826c-5d97-45af-b35d-cbbf81b5dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Interactively Adjusting Visibility:\n",
    "curr_is_visible = np.full([len(tuningCurvePlotActors), 1], False)\n",
    "curr_is_visible[12] = True\n",
    "update_plotVisiblePlacefields2D(tuningCurvePlotActors, curr_is_visible)\n",
    "# pActiveTuningCurvesPlotter.disable_depth_peeling()\n",
    "pActiveTuningCurvesPlotter.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab61be64-3491-48d0-8e9e-35cd6017a631",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Slider with Callback Function Example:\n",
    "\n",
    "######################\n",
    "# General Plotting Method:    \n",
    "def on_slider_update_mesh(value):\n",
    "    curr_i = int(value)    \n",
    "    active_window_sample_indicies = np.squeeze(pre_computed_window_sample_indicies[curr_i,:]) # Get the current precomputed indicies for this curr_i\n",
    "    \n",
    "    ## Spike Plotting:\n",
    "    # Get the times that fall within the current plot window:\n",
    "    curr_time_fixedSegments = t[active_window_sample_indicies] # New Way\n",
    "    t_start = curr_time_fixedSegments[0]\n",
    "    t_stop = curr_time_fixedSegments[-1]\n",
    "    # print('Constraining to curr_time_fixedSegments with times (start: {}, end: {})'.format(t_start, t_stop))\n",
    "    # print('curr_time_fixedSegments: {}'.format(curr_time_fixedSegments))\n",
    "    curr_text_rendering_string = 'curr_i: {:d}; (t_start: {:.2f}, t_stop: {:.2f})'.format(curr_i, t_start, t_stop) # :.3f\n",
    "    p.add_text(curr_text_rendering_string, name='lblCurrent_spike_range', position='lower_right', color='white', shadow=True, font_size=10)\n",
    "\n",
    "    ## Historical Spikes:\n",
    "    # active_included_all_historical_indicies = (flattened_spikes.flattened_spike_times < t_stop) # Accumulate Spikes mode. All spikes occuring prior to the end of the frame (meaning the current time) are plotted\n",
    "    historical_t_start = (t_stop - longer_spikes_window.duration_seconds) # Get the earliest time that will be included in the search\n",
    "    active_included_all_historical_indicies = ((flattened_spikes.flattened_spike_times > historical_t_start) & (flattened_spikes.flattened_spike_times < t_stop)) # Two Sided Range Mode\n",
    "    historical_spikes_pdata, historical_spikes_pc = build_active_spikes_plot_data(flattened_spikes.flattened_spike_times[active_included_all_historical_indicies],\n",
    "                                                                                  flattened_spike_active_unitIdentities[active_included_all_historical_indicies],\n",
    "                                                                                  flattened_spike_positions_list[:, active_included_all_historical_indicies],\n",
    "                                                                                  spike_geom=spike_geom_box.copy())\n",
    "    if historical_spikes_pc.n_points >= 1:\n",
    "        historical_main_spikes_mesh = p.add_mesh(historical_spikes_pc, name='historical_spikes_main', scalars='cellID', cmap=active_cells_listed_colormap, show_scalar_bar=False, lighting=True, render=False)\n",
    "\n",
    "    ## Actively Firing Spikes:\n",
    "    recent_spikes_t_start = (t_stop - recent_spikes_window.duration_seconds) # Get the earliest time that will be included in the recent spikes\n",
    "    # print('recent_spikes_t_start: {}; t_start: {}'.format(recent_spikes_t_start, t_start))\n",
    "    active_included_recent_only_indicies = ((flattened_spikes.flattened_spike_times > recent_spikes_t_start) & (flattened_spikes.flattened_spike_times < t_stop)) # Two Sided Range Mode\n",
    "    # active_included_recent_only_indicies = ((flattened_spikes.flattened_spike_times > t_start) & (flattened_spikes.flattened_spike_times < t_stop)) # Two Sided Range Mode\n",
    "    recent_only_spikes_pdata, recent_only_spikes_pc = build_active_spikes_plot_data(flattened_spikes.flattened_spike_times[active_included_recent_only_indicies],\n",
    "                                                                                    flattened_spike_active_unitIdentities[active_included_recent_only_indicies],\n",
    "                                                                                    flattened_spike_positions_list[:, active_included_recent_only_indicies],\n",
    "                                                                                    spike_geom=spike_geom_cone.copy())\n",
    "    if recent_only_spikes_pc.n_points >= 1:\n",
    "        recent_only_main_spikes_mesh = p.add_mesh(recent_only_spikes_pc, name='recent_only_spikes_main', scalars='cellID', cmap=active_cells_listed_colormap, show_scalar_bar=False, lighting=False, render=False) # color='white'\n",
    "        \n",
    "    ## Animal Position and Location Trail Plotting:\n",
    "    point_cloud_fixedSegements_positionTrail = np.column_stack((x[active_window_sample_indicies], y[active_window_sample_indicies], z_fixed))\n",
    "    pdata_positionTrail = pv.PolyData(point_cloud_fixedSegements_positionTrail.copy()) # a mesh\n",
    "    pdata_positionTrail.point_data['pho_fade_values'] = active_trail_opacity_values\n",
    "    pdata_positionTrail.point_data['pho_size_values'] = active_trail_size_values\n",
    "    # create many spheres from the point cloud\n",
    "    pc_positionTrail = pdata_positionTrail.glyph(scale='pho_size_values', geom=animal_location_trail_circle)\n",
    "    animal_location_trail_mesh = p.add_mesh(pc_positionTrail, name='animal_location_trail', ambient=0.6, opacity='linear_r', scalars='pho_fade_values', nan_opacity=0.0,\n",
    "                                            show_edges=False, render_lines_as_tubes=True, show_scalar_bar=False, use_transparency=True, render=False) # works to render a heat colored (most recent==hotter) position\n",
    "\n",
    "    ## Animal Current Position:\n",
    "    curr_animal_point = point_cloud_fixedSegements_positionTrail[-1,:].copy() # Get the last point\n",
    "    pdata_current_point = pv.PolyData(curr_animal_point) # a mesh\n",
    "    pc_current_point = pdata_current_point.glyph(scale=False, geom=animal_location_circle)\n",
    "    animal_current_location_point_mesh = p.add_mesh(pc_current_point, name='animal_location', color='green', ambient=0.6, opacity=0.5,\n",
    "                                                    show_edges=True, edge_color=[0.05, 0.8, 0.08], line_width=3.0, nan_opacity=0.0, render_lines_as_tubes=True,\n",
    "                                                    show_scalar_bar=False, use_transparency=True, render=False) # works to render a heat colored (most recent==hotter) position\n",
    "    \n",
    "    p.render() # renders to ensure it's updated after changing the ScalarVisibility above\n",
    "    # p.update()\n",
    "    # p.app.processEvents() # not needed probably\n",
    "    return\n",
    "\n",
    "\n",
    "################################################\n",
    "### Build Appropriate Plotter and set it up:\n",
    "#####################\n",
    "# Only Create a new BackgroundPlotter if it's needed:\n",
    "if (active_config.video_output_config.active_is_video_output_mode):\n",
    "    ## Video mode should use a regular plotter object\n",
    "    p = pv.Plotter(notebook=False, shape=active_config.plotting_config.subplots_shape, window_size=([1280, 720]), off_screen=True) # , line_smoothing=True, polygon_smoothing=True, multi_samples=8\n",
    "else:\n",
    "    try: p\n",
    "    except NameError: p = None # Checks variable p's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "    if (p is not None):\n",
    "        if isinstance(p, pvqt.BackgroundPlotter):\n",
    "            if p.app_window.isHidden():\n",
    "                print('No open BackgroundPlotter')\n",
    "                p.close() # Close it to start over fresh\n",
    "                p = None\n",
    "                needs_create_new_backgroundPlotter = True\n",
    "            else:\n",
    "                print('BackgroundPlotter already open, reusing it.. NOT Forcing creation of a new one!')\n",
    "                # p.app_window.window().show()\n",
    "                # p.clear()\n",
    "                # needs_create_new_backgroundPlotter = False                \n",
    "                p.close() # Close it to start over fresh\n",
    "                p = None\n",
    "                needs_create_new_backgroundPlotter = True\n",
    "                \n",
    "        else:\n",
    "            print('No open BackgroundPlotter, p is a Plotter object')\n",
    "            p.close()\n",
    "            p = None\n",
    "            needs_create_new_backgroundPlotter = True\n",
    "    else:\n",
    "        print('No extant BackgroundPlotter')\n",
    "        needs_create_new_backgroundPlotter = True\n",
    "    if needs_create_new_backgroundPlotter:\n",
    "        print('Creating a new BackgroundPlotter')\n",
    "        p = pvqt.BackgroundPlotter(window_size=(1920, 1080), shape=active_config.plotting_config.subplots_shape, off_screen=False) # Use just like you would a pv.Plotter() instance\n",
    "        print('done.')\n",
    "\n",
    "# p.background_color = 'black'\n",
    "\n",
    "if (not active_config.video_output_config.active_is_video_output_mode):\n",
    "    #Interactive Mode: Enable interactive controls:\n",
    "    interactive_timestamp_slider_actor = p.add_slider_widget(on_slider_update_mesh, [0, (num_time_points-1)], title='Trajectory Timestep', event_type='always', style='modern', pointa=(0.025, 0.1), pointb=(0.98, 0.1), fmt='%0.2f') # fmt=\"%0.2f\"\n",
    "    interactive_timestamp_slider_wrapper = InteractiveSliderWrapper(interactive_timestamp_slider_actor)    \n",
    "    # interactive_checkbox_actor = p.add_checkbox_button_widget(toggle_animation, value=False, color_on='green')\n",
    "    helper_controls_text = print_controls_helper_text()\n",
    "    p.add_text(helper_controls_text, position='upper_left', name='lblControlsHelperText', color='grey', font_size=8.0)\n",
    "    \n",
    "    \n",
    "# Plot the flat arena\n",
    "pdata_maze, pc_maze = build_flat_map_plot_data(x, y)\n",
    "p.add_mesh(pc_maze, name='maze_bg', color=\"black\", render=False)\n",
    "# p.show_grid()\n",
    "# p.add_axes(line_width=5, labels_off=True)\n",
    "p.enable_depth_peeling(number_of_peels=4, occlusion_ratio=0) # Supposedly helps with translucency\n",
    "p.hide_axes()\n",
    "# p.camera_position = 'xy' # Overhead (top) view\n",
    "# apply_close_overhead_zoomed_camera_view(p)\n",
    "apply_close_perspective_camera_view(p)\n",
    "\n",
    "p.render() # manually render when needed\n",
    "\n",
    "if active_config.video_output_config.active_is_video_output_mode:\n",
    "    print('Writing video to {}...'.format(active_config.video_output_config.active_video_output_fullpath))\n",
    "    p.show(auto_close=False)\n",
    "    make_mp4_from_plotter(p, active_config.video_output_config.active_frame_range, on_slider_update_mesh, filename=active_config.video_output_config.active_video_output_fullpath, framerate=60) # 60fps\n",
    "    p.close()\n",
    "    p = None\n",
    "\n",
    "# p.show()\n",
    "                  \n",
    "print('all done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b037df-4a74-4130-9884-b592f81ab6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Playback animation:\n",
    "\n",
    "# ## Testing Updating the Timestamp Slider Programmatically:\n",
    "# interactive_timestamp_slider_wrapper.curr_index\n",
    "# interactive_timestamp_slider_wrapper.step_index(15)\n",
    "\n",
    "class InterfaceProperties(object):\n",
    "    def __init__(self, active_timestamp_slider_wrapper):\n",
    "        # self.curr_plot_update_step = 1 # Update every frame\n",
    "        # self.curr_plot_update_frequency = self.curr_plot_update_step * active_epoch_pos.sampling_rate # number of updates per second (Hz)\n",
    "        # self.num_time_points = active_epoch_pos.n_frames / self.curr_plot_update_step        \n",
    "        # self.position_trail_max_duration = 0\n",
    "        # self.max_historical_spikes_age = 0 # How long ago the historical spikes could have been plotted and still not be removed.\n",
    "        self.active_timestamp_slider_wrapper = active_timestamp_slider_wrapper # Used to actually update the slider when it's appropriate\n",
    "        self.animation_state = False # Whether it's playing or not\n",
    "\n",
    "    def __call__(self):\n",
    "        if self.animation_state:\n",
    "            # only if animation is currently active:\n",
    "            self.active_timestamp_slider_wrapper.step_index(15) # TODO: allow variable step size\n",
    "            pass\n",
    "\n",
    "        \n",
    "animate = InterfaceProperties(interactive_timestamp_slider_wrapper)\n",
    "# define the animation switch\n",
    "def toggle_animation(state):\n",
    "    animate.animation_state = state # updates the animation state to the new value\n",
    "\n",
    "# An unused constant-time callback that calls back every so often to perform updates\n",
    "p.add_callback(animate, interval=16)  # to be smooth on 60Hz\n",
    "\n",
    "# A checkbox that decides whether we're playing back at a constant rate or not.\n",
    "interactive_checkbox_actor = p.add_checkbox_button_widget(toggle_animation, value=False, color_on='green')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "fde6e68fa8f5f4f0920a88ee99edd8d4121f14a57a7800ceb19ed197f25c05dc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
