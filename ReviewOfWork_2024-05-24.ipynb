{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:20.608442900Z",
     "start_time": "2023-11-16T23:21:20.217442100Z"
    },
    "collapsed": true,
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "doc_output_parent_folder: C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\DEVELOPER_NOTES\\DataStructureDocumentation\n",
      "DAY_DATE_STR: 2024-05-24, DAY_DATE_TO_USE: 2024-05-24\n",
      "NOW_DATETIME: 2024-05-24_0705AM, NOW_DATETIME_TO_USE: 2024-05-24_0705AM\n",
      "global_data_root_parent_path changed to W:\\Data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4256f53e99b46f1972bb8d0fc2a5b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Data Root:', layout=Layout(width='auto'), options=(WindowsPath('W:/Data'),), style=ToggleButtonsStyle(button_width='max-content'), tooltip='global_data_root_parent_path', value=WindowsPath('W:/Data'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "# %xmode Verbose\n",
    "# %xmode context\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "from attrs import define, field, fields, Factory, make_class\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "import builtins\n",
    "\n",
    "import IPython\n",
    "from IPython.core.formatters import PlainTextFormatter\n",
    "from IPython import get_ipython\n",
    "\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "# Jupyter-lab enable printing for any line on its own (instead of just the last one in the cell)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# BEGIN PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "\n",
    "## IPython pprint\n",
    "from pyphocorehelpers.pprint import wide_pprint, wide_pprint_ipython, wide_pprint_jupyter, MAX_LINE_LENGTH\n",
    "\n",
    "# Override default pprint\n",
    "builtins.pprint = wide_pprint\n",
    "\n",
    "text_formatter: PlainTextFormatter = IPython.get_ipython().display_formatter.formatters['text/plain']\n",
    "text_formatter.max_width = MAX_LINE_LENGTH\n",
    "text_formatter.for_type(object, wide_pprint_jupyter)\n",
    "\n",
    "\n",
    "# END PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "from pyphocorehelpers.print_helpers import get_now_time_str, get_now_day_str\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path, file_uri_from_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "import pyphocorehelpers.programming_helpers as programming_helpers\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field, custom_define\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin, HDF_Converter\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_subsession_neuron_differences, debug_print_ratemap, debug_print_spike_counts, debug_plot_2d_binning, print_aligned_columns, parameter_sweeps, _plot_parameter_sweep, compare_placefields_info\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies, paired_incremental_sorting\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, document_active_variables\n",
    "\n",
    "## Pho Programming Helpers:\n",
    "import inspect\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter, TypePrintMode, print_keys_if_possible, debug_dump_object_member_shapes, print_value_overview_only, document_active_variables\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers, PythonDictionaryDefinitionFormat, MemoryManagement, inspect_callable_arguments, get_arguments_as_optional_dict, GeneratedClassDefinitionType, CodeConversion\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper, print_widget_hierarchy\n",
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative, dict_to_full_array\n",
    "doc_output_parent_folder: Path = Path('EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation').resolve() # ../.\n",
    "print(f\"doc_output_parent_folder: {doc_output_parent_folder}\")\n",
    "assert doc_output_parent_folder.exists()\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_evaluate_required_computations, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphocorehelpers.exception_helpers import ExceptionPrintingContext, CapturedException\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsResult, TrackTemplates, DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions,  RankOrderComputationsContainer, RankOrderResult, RankOrderAnalyses\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ComputationFunctionRegistryHolder import ComputationFunctionRegistryHolder, computation_precidence_specifying_function, global_function\n",
    "\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "# %matplotlib inline\n",
    "# %matplotlib auto\n",
    "\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "# from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget, render_colors\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "\n",
    "DAY_DATE_STR: str = date.today().strftime(\"%Y-%m-%d\")\n",
    "DAY_DATE_TO_USE = f'{DAY_DATE_STR}' # used for filenames throught the notebook\n",
    "print(f'DAY_DATE_STR: {DAY_DATE_STR}, DAY_DATE_TO_USE: {DAY_DATE_TO_USE}')\n",
    "\n",
    "NOW_DATETIME: str = get_now_rounded_time_str()\n",
    "NOW_DATETIME_TO_USE = f'{NOW_DATETIME}' # used for filenames throught the notebook\n",
    "print(f'NOW_DATETIME: {NOW_DATETIME}, NOW_DATETIME_TO_USE: {NOW_DATETIME_TO_USE}')\n",
    "\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import build_global_data_root_parent_path_selection_widget\n",
    "all_paths = [Path('/Volumes/SwapSSD/Data'), Path('/Users/pho/data'), Path(r'/Users/pho/cloud/turbo/Data'), Path(r'/media/halechr/MAX/Data'), Path(r'/home/halechr/FastData'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')] # Path('/Volumes/FedoraSSD/FastData'), \n",
    "global_data_root_parent_path = None\n",
    "def on_user_update_path_selection(new_path: Path):\n",
    "\tglobal global_data_root_parent_path\n",
    "\tnew_global_data_root_parent_path = new_path.resolve()\n",
    "\tglobal_data_root_parent_path = new_global_data_root_parent_path\n",
    "\tprint(f'global_data_root_parent_path changed to {global_data_root_parent_path}')\n",
    "\tassert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "\t\t\t\n",
    "global_data_root_parent_path_widget = build_global_data_root_parent_path_selection_widget(all_paths, on_user_update_path_selection)\n",
    "global_data_root_parent_path_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db844b",
   "metadata": {},
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f07773d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir: W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\n",
      "Computing loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\loadedSessPickle.pkl... W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\loadedSessPickle.pkl... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:==========================================================================================\n",
      "========== Logger INIT \"2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40\" ==============================\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:NeuropyPipeline.__setstate__(state=\"{'pipeline_name': 'kdiba_pipeline', 'session_data_type': 'kdiba', '_stage': <pyphoplacecellanalysis.General.Pipeline.Stages.Display.DisplayPipelineStage object at 0x000001DE9E11E1C0>}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_logger(full_logger_string=\"2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40\", file_logging_dir: None):\n",
      "done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\loadedSessPickle.pkl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:select_filters(...) with: []\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing global computations...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:select_filters(...) with: []\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing global computations...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:select_filters(...) with: []\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:Performing global computations...\n",
      "INFO:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:NeuropyPipeline.on_stage_changed(new_stage=\"PipelineStage.Displayed\")\n",
      "WARNING:2024-05-24_07-05-18.Apogee.pipeline.kdiba.gor01.two.2006-6-09_22-24-40:WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # 2024-04-30 - Completely cleaned.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # DONE, might be the BEST SESSION, good example session with lots of place cells, clean replays, and clear bar graphs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays ---- VERY weird effect of the replays, a sharp drop to strongly negative values more than 3/4 through the experiment.\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD, 2023-07-14, unsure why still.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays! Interesting see-saw!\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE, Added replay selections. Very \"jumpy\" between the starts and ends of the track.\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # 2024-01-10 new RANKORDER APOGEE | DONE, Added replay selections. A TON of putative replays in general, most bad, but some good. LOOKIN GOOD!\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='twolong_LR_pf1Dsession_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # BAD: Confirmed frequent jumping off of the track in this session. DONE, good. Many good pfs, many good replays. Noticed very strange jumping off the track in the 3D behavior/spikes viewer. Is there something wrong with this session?\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE, good?, replays selected, few  # BAD: Seems like in 3D view there's also jumping off of the track in this session.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE, very few replays\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3') ### KeyError: 'maze1_odd'\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5') ### \n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # NEWDONE, replays selected, quite a few replays but few are very good.\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25')\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# \n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination', 'pf_computation',\n",
    "                                            #    'pfdt_computation',\n",
    "                                                'firing_rate_trends',\n",
    "                                                # 'pf_dt_sequential_surprise', \n",
    "                                            #    'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                # 'position_decoding_two_step', \n",
    "                                            #    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                            #     'long_short_inst_spike_rate_groups',\n",
    "                                            #     'long_short_endcap_analysis',\n",
    "                                            # 'split_to_directional_laps',\n",
    "]\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "\n",
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ed6fa",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_GL'\n",
    "BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_Apogee' # TODO: Change this as needed, templating isn't actually doing anything rn.\n",
    "\n",
    "known_collected_output_paths = [Path(v).resolve() for v in ['/nfs/turbo/umms-kdiba/Data/Output/collected_outputs', '/home/halechr/FastData/collected_outputs/',\n",
    "                                                           '/home/halechr/cloud/turbo/Data/Output/collected_outputs',\n",
    "                                                           r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\output\\collected_outputs',\n",
    "                                                          'output/gen_scripts/']]\n",
    "collected_outputs_path = find_first_extant_path(known_collected_output_paths)\n",
    "assert collected_outputs_path.exists(), f\"collected_outputs_path: {collected_outputs_path} does not exist! Is the right computer's config commented out above?\"\n",
    "# fullwidth_path_widget(scripts_output_path, file_name_label='Scripts Output Path:')\n",
    "print(f'collected_outputs_path: {collected_outputs_path}')\n",
    "# collected_outputs_path.mkdir(exist_ok=True)\n",
    "# assert collected_outputs_path.exists()\n",
    "\n",
    "## Build the output prefix from the session context:\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: \"{CURR_BATCH_OUTPUT_PREFIX}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122bf3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "list(curr_active_pipeline.global_computation_results.computed_data.keys())\n",
    "\n",
    "\n",
    "# 2024-01-22 ERROR: when the pipeline is manually saved, its global_computations seem to be saved to the pickle too. After modifying how global computations are loaded from pickle, the following global computations code block no longer appropriately overwrites the existing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_problem_result_names = ['directional_decoders_evaluate_epochs', 'directional_decoders_decode_continuous']\n",
    "pickle_problem_global_result_key_names = ['DirectionalDecodersDecoded', 'DirectionalDecodersEpochsEvaluations']\n",
    "# pickle_problem_global_result_key_names = ['DirectionalLaps', 'DirectionalMergedDecoders', 'RankOrder', 'DirectionalDecodersDecoded']\n",
    "global_dropped_keys, local_dropped_keys = curr_active_pipeline.perform_drop_computed_result(computed_data_keys_to_drop=pickle_problem_global_result_key_names, debug_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acba46b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:40.574268400Z",
     "start_time": "2023-11-16T23:21:35.966373700Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "#### GLOBAL COMPUTE via `batch_extended_computations(...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b6c927",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# extended_computations_include_includelist = ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation',\n",
    "#     'extended_stats',\n",
    "#     # 'pf_dt_sequential_surprise',\n",
    "#     #  'ratemap_peaks_prominence2d',\n",
    "#     'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', \n",
    "#     'long_short_post_decoding', # #TODO 2024-01-19 05:49: - [ ] `'long_short_post_decoding' is broken for some reason `AttributeError: 'NoneType' object has no attribute 'active_filter_epochs'``\n",
    "#     # 'long_short_rate_remapping',\n",
    "#     'long_short_inst_spike_rate_groups',\n",
    "#     'long_short_endcap_analysis',\n",
    "#     # 'spike_burst_detection',\n",
    "#     'split_to_directional_laps',\n",
    "#     'merged_directional_placefields',\n",
    "#     # 'rank_order_shuffle_analysis',\n",
    "#     # 'directional_train_test_split',\n",
    "#     # 'directional_decoders_decode_continuous',\n",
    "#     # 'directional_decoders_evaluate_epochs',\n",
    "#     # 'directional_decoders_epoch_heuristic_scoring',\n",
    "# ] # do only specified\n",
    "\n",
    "\n",
    "extended_computations_include_includelist = ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation',\n",
    "    'extended_stats',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "     'ratemap_peaks_prominence2d',\n",
    "    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', \n",
    "    'long_short_post_decoding', # #TODO 2024-01-19 05:49: - [ ] `'long_short_post_decoding' is broken for some reason `AttributeError: 'NoneType' object has no attribute 'active_filter_epochs'``\n",
    "    # 'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    # 'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'merged_directional_placefields',\n",
    "    'rank_order_shuffle_analysis',\n",
    "    'directional_train_test_split',\n",
    "    'directional_decoders_decode_continuous',\n",
    "    'directional_decoders_evaluate_epochs',\n",
    "    'directional_decoders_epoch_heuristic_scoring',\n",
    "] # do only specified\n",
    "\n",
    "\n",
    "\n",
    "# extended_computations_include_includelist = ['lap_direction_determination', # needs to be first. Directly changes the laps\n",
    "# \t\t\t\t\t\t\t\t\t\t\t  'pf_computation',\n",
    "#     'split_to_directional_laps', # must come after `lap_direction_determination`\n",
    "#     'merged_directional_placefields',\n",
    "# \t] # do only specified\n",
    "\n",
    "\n",
    "\n",
    "force_recompute_override_computations_includelist = None\n",
    "# force_recompute_override_computations_includelist = ['merged_directional_placefields']\n",
    "# force_recompute_override_computations_includelist = ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis'] # , 'directional_decoders_decode_continuous'\n",
    "# force_recompute_override_computations_includelist = ['directional_decoders_decode_continuous'] # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb47e03a",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation', 'extended_stats', 'ratemap_peaks_prominence2d', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_train_test_split', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "WARNING: FIXME TODO 2024-05-08 08:20: - [ ] Disabled checking for 'combined_best_direction_indicies', which is missing from both the laps and ripple dataframes after fresh computation for some reason.\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "Pre-load global computations: needs_computation_output_dict: []\n"
     ]
    }
   ],
   "source": [
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Pre-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# valid_computed_results_output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28cf10d2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\output\\global_computation_results.pkl... W:\\Data\\KDIBA\\gor01\\two\\2006-6-09_22-24-40\\output\\global_computation_results.pkl... done.\n",
      "sucessfully_updated_keys: ['DirectionalLaps', 'DirectionalMergedDecoders', 'RankOrder', 'DirectionalDecodersEpochsEvaluations', 'long_short_leave_one_out_decoding_analysis', 'short_long_pf_overlap_analyses', 'long_short_fr_indicies_analysis', 'jonathan_firing_rate_analysis', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap', 'TrainTestSplit', 'DirectionalDecodersDecoded']\n",
      "successfully_loaded_keys: ['DirectionalLaps', 'DirectionalMergedDecoders', 'RankOrder', 'DirectionalDecodersEpochsEvaluations', 'long_short_leave_one_out_decoding_analysis', 'short_long_pf_overlap_analyses', 'long_short_fr_indicies_analysis', 'jonathan_firing_rate_analysis', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap', 'TrainTestSplit', 'DirectionalDecodersDecoded']\n"
     ]
    }
   ],
   "source": [
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # curr_active_pipeline.load_pickled_global_computation_results()\n",
    "        sucessfully_updated_keys, successfully_loaded_keys = curr_active_pipeline.load_pickled_global_computation_results(allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist) # is new\n",
    "        print(f'sucessfully_updated_keys: {sucessfully_updated_keys}\\nsuccessfully_loaded_keys: {successfully_loaded_keys}')\n",
    "    except FileNotFoundError as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results because pickle file does not exist! Maybe it has never been created? {e}')\n",
    "    except BaseException as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'Unhandled exception: cannot load global results: {e}')\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0d5ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_most_likely_result_tuple, curr_active_pipeline.global_computation_results.computed_data['RankOrder'].laps_most_likely_result_tuple = RankOrderAnalyses.most_likely_directional_rank_order_shuffling(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02cdcca0",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation', 'extended_stats', 'ratemap_peaks_prominence2d', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_train_test_split', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "WARNING: FIXME TODO 2024-05-08 08:20: - [ ] Disabled checking for 'combined_best_direction_indicies', which is missing from both the laps and ripple dataframes after fresh computation for some reason.\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "Post-load global computations: needs_computation_output_dict: []\n"
     ]
    }
   ],
   "source": [
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81782608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['split_to_directional_laps', 'rank_order_shuffle_analysis', 'extended_stats', 'pfdt_computation']\n",
    "# ['split_to_directional_laps', 'extended_stats', 'pfdt_computation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76313826",
   "metadata": {},
   "outputs": [],
   "source": [
    "needs_computation_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0fe66c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation', 'extended_stats', 'ratemap_peaks_prominence2d', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_train_test_split', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze_any\"\n",
      "WARNING: FIXME TODO 2024-05-08 08:20: - [ ] Disabled checking for 'combined_best_direction_indicies', which is missing from both the laps and ripple dataframes after fresh computation for some reason.\n",
      "done with all batch_extended_computations(...).\n",
      "no changes in global results.\n"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# except Exception as e:\n",
    "#     exception_info = sys.exc_info()\n",
    "#     e = CapturedException(e, exception_info)\n",
    "#     print(f'second half threw: {e}')\n",
    "\n",
    "# 4m 5.2s for inst fr computations\n",
    "\n",
    "#34m 6.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b4793f3",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation', 'extended_stats', 'ratemap_peaks_prominence2d', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_train_test_split', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "WARNING: FIXME TODO 2024-05-08 08:20: - [ ] Disabled checking for 'combined_best_direction_indicies', which is missing from both the laps and ripple dataframes after fresh computation for some reason.\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "Post-compute validation: needs_computation_output_dict: []\n"
     ]
    }
   ],
   "source": [
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=True)\n",
    "print(f'Post-compute validation: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e0148",
   "metadata": {},
   "source": [
    "## Specific Recomputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_most_recent_computation_time, each_epoch_latest_computation_time, each_epoch_each_result_computation_completion_times, (global_computations_latest_computation_time, global_computation_completion_times) = curr_active_pipeline.get_computation_times(debug_print=False)\n",
    "# each_epoch_latest_computation_time\n",
    "each_epoch_each_result_computation_completion_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d4f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_config.instantaneous_time_bin_size_seconds = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47820977",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_computations_include_includelist=['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "    #  'ratemap_peaks_prominence2d',\n",
    "    'extended_stats',\n",
    "    'long_short_decoding_analyses',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    # 'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    # 'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'merged_directional_placefields',\n",
    "    # 'rank_order_shuffle_analysis',\n",
    "    # 'directional_decoders_decode_continuous',\n",
    "    # 'directional_decoders_evaluate_epochs',\n",
    "    # 'directional_decoders_epoch_heuristic_scoring',\n",
    "] # do only specified\n",
    "\n",
    "force_recompute_override_computations_includelist = [\n",
    "    # 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',\n",
    "    # 'lap_direction_determination', 'DirectionalLaps',\n",
    "    # 'merged_directional_placefields',\n",
    "    # 'directional_decoders_decode_continuous',\n",
    "]\n",
    "# force_recompute_override_computations_includelist = None\n",
    "\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "newly_computed_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_recompute_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.reload_default_computation_functions()\n",
    "# force_recompute_override_computations_includelist = ['_decode_continuous_using_directional_decoders']\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_decode_continuous_using_directional_decoders'], force_recompute_override_computations_includelist=force_recompute_override_computations_includelist,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_decode_continuous_using_directional_decoders'], computation_kwargs_list=[{'time_bin_size': 0.025}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(extended_computations_include_includelist=['_decode_continuous_using_directional_decoders'], computation_kwargs_list=[{'time_bin_size': 0.02}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.20}, {'time_bin_size': 0.20}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.025}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "# 2024-04-20 - HACK -- FIXME: Invert the 'is_LR_dir' column since it is clearly reversed. No clue why.\n",
    "# fails due to some types thing?\n",
    "# \terr: Length of values (82) does not match length of index (80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f748deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_evaluate_epochs'], computation_kwargs_list=[{'should_skip_radon_transform': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe380f10",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_epoch_heuristic_scoring'], enabled_filter_names=None, fail_on_exception=True, debug_print=False) # OK FOR PICKLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f372737e",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39417243",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['lap_direction_determination'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89757a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['extended_stats'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.2}, {'time_bin_size': 0.025}, {'should_skip_radon_transform': False}, {}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62493eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['long_short_decoding_analyses',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    ], enabled_filter_names=None, fail_on_exception=True, debug_print=False) # , computation_kwargs_list=[{'should_skip_radon_transform': False}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c267dae5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# directional_merged_decoders_result = deepcopy(directional_decoders_epochs_decode_result)\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "spikes_df = deepcopy(curr_active_pipeline.sess.spikes_df)\n",
    "\n",
    "global_computation_results = curr_active_pipeline.global_computation_results\n",
    "\n",
    " # spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "rank_order_results = global_computation_results.computed_data['RankOrder'] # : \"RankOrderComputationsContainer\"\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "# included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "directional_laps_results: DirectionalLapsResult = global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "# print(f'included_qclu_values: {included_qclu_values}')\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "# pos_bin_size = _recover_position_bin_size(track_templates.get_decoders()[0]) # 3.793023081021702\n",
    "# print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "# pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "\n",
    "## Simple Pearson Correlation\n",
    "assert spikes_df is not None\n",
    "(laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names = directional_merged_decoders_result.compute_simple_spike_time_v_pf_peak_x_by_epoch(track_templates=track_templates, spikes_df=deepcopy(spikes_df))\n",
    "## OUTPUTS: (laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names\n",
    "## Computes the highest-valued decoder for this score:\n",
    "best_decoder_index_col_name: str = 'best_decoder_index'\n",
    "laps_simple_pf_pearson_merged_df[best_decoder_index_col_name] = laps_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n",
    "ripple_simple_pf_pearson_merged_df[best_decoder_index_col_name] = ripple_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a452a66",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(active_epochs_df): 707\n",
      "min_num_unique_aclu_inclusions: 12\n",
      "len(active_epochs_df): 405\n",
      "pos_bin_size: 3.8632841399651463\n",
      "ripple_decoding_time_bin_size: 0.025\n",
      "laps_decoding_time_bin_size: 0.25\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "print(f'pos_bin_size: {pos_bin_size}')\n",
    "print(f'ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}')\n",
    "\n",
    "# Radon Transforms:\n",
    "decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "# Weighted correlations:\n",
    "laps_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "ripple_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "decoder_laps_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "decoder_ripple_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "# Pearson's correlations:\n",
    "laps_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "ripple_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# laps_simple_pf_pearson_merged_df\n",
    "# ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "## Drop rows where all are missing\n",
    "corr_column_names = ['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr']\n",
    "# ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='all') # 350/412 rows\n",
    "filtered_laps_simple_pf_pearson_merged_df: pd.DataFrame = laps_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "filtered_ripple_simple_pf_pearson_merged_df: pd.DataFrame = ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "\n",
    "## Update the `decoder_ripple_filter_epochs_decoder_result_dict` with the included epochs:\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_ripple_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_laps_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed38171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData\n",
    "\n",
    "# directional_decoders_epochs_decode_result\n",
    "# save_path = Path(\"/Users/pho/data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-04-25_CustomDecodingResults.pkl\").resolve()\n",
    "# save_path = curr_active_pipeline.get_output_path().joinpath(\"2024-04-28_CustomDecodingResults.pkl\").resolve()\n",
    "save_path = curr_active_pipeline.get_output_path().joinpath(f\"{DAY_DATE_TO_USE}_CustomDecodingResults.pkl\").resolve()\n",
    "\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "xbin_centers = deepcopy(long_pf2D.xbin_centers)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "ybin_centers = deepcopy(long_pf2D.ybin_centers)\n",
    "\n",
    "print(xbin_centers)\n",
    "save_dict = {\n",
    "'directional_decoders_epochs_decode_result': directional_decoders_epochs_decode_result.__getstate__(),\n",
    "'xbin': xbin, 'xbin_centers': xbin_centers}\n",
    "\n",
    "saveData(save_path, save_dict)\n",
    "print(f'save_path: {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b4531",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# 💾 Export CSVs: \n",
    "## INPUTS: directional_decoders_epochs_decode_result,\n",
    "\n",
    "extracted_merged_scores_df = directional_decoders_epochs_decode_result.build_complete_all_scores_merged_df()\n",
    "# extracted_merged_scores_df\n",
    "\n",
    "print(f'\\tAll scores df CSV exporting...')\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "export_df_dict = {'ripple_all_scores_merged_df': extracted_merged_scores_df}\n",
    "_csv_export_paths = directional_decoders_epochs_decode_result.perform_export_dfs_dict_to_csvs(extracted_dfs_dict=export_df_dict, parent_output_path=collected_outputs_path.resolve(), active_context=active_context, session_name=curr_session_name, curr_session_t_delta=t_delta,\n",
    "                                                                            #   user_annotation_selections={'ripple': any_good_selected_epoch_times},\n",
    "                                                                            #   valid_epochs_selections={'ripple': filtered_valid_epoch_times},\n",
    "                                                                            )\n",
    "\n",
    "print(f'\\t\\tsuccessfully exported ripple_all_scores_merged_df to {collected_outputs_path}!')\n",
    "_output_csv_paths_info_str: str = '\\n'.join([f'{a_name}: \"{file_uri_from_path(a_path)}\"' for a_name, a_path in _csv_export_paths.items()])\n",
    "print(f'\\t\\t\\tCSV Paths: {_output_csv_paths_info_str}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a98fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extracted_merged_scores_df.to_csv('test_(ripple_all_scores_merged_df).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a860a1",
   "metadata": {},
   "outputs": [],
   "source": [
    " decoder_ripple_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_extras_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbf34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ripple_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_extras_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbcbb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_laps_simple_pf_pearson_merged_df\n",
    "# filtered_ripple_simple_pf_pearson_merged_df\n",
    "# decoder_ripple_weighted_corr_df_dict\n",
    "ripple_weighted_corr_merged_df['ripple_start_t']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a95450",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcorr_column_names = ['wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL']\n",
    "filtered_ripple_simple_pf_pearson_merged_df.label = filtered_ripple_simple_pf_pearson_merged_df.label.astype('int64')\n",
    "ripple_weighted_corr_merged_df['label'] = ripple_weighted_corr_merged_df['ripple_idx'].astype('int64')\n",
    "\n",
    "filtered_ripple_simple_pf_pearson_merged_df.join(ripple_weighted_corr_merged_df[wcorr_column_names], on='start') # , on='label'\n",
    "# filtered_ripple_simple_pf_pearson_merged_df.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac433aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(ripple_weighted_corr_merged_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "a_decoded_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3599f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window.save_selections()\n",
    "\n",
    "a_decoded_filter_epochs_decoder_result_dict.epochs.find_data_indicies_from_epoch_times([380.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77babf98",
   "metadata": {},
   "source": [
    "## 💾 Continue Saving/Exporting stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results() # newly_computed_values: [('pfdt_computation', 'maze_any')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7af96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_save_folder, split_save_paths, split_save_output_types, failed_keys = curr_active_pipeline.save_split_global_computation_results(debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a869b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f06d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE) ## #TODO 2024-02-16 14:25: - [ ] PicklingError: Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x7fd35e66b700>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10989b4",
   "metadata": {},
   "source": [
    "#### Get computation times/info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31cab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_most_recent_computation_time, each_epoch_latest_computation_time, each_epoch_each_result_computation_completion_times, (global_computations_latest_computation_time, global_computation_completion_times) = curr_active_pipeline.get_computation_times(debug_print=False)\n",
    "# each_epoch_latest_computation_time\n",
    "# each_epoch_each_result_computation_completion_times\n",
    "# global_computation_completion_times\n",
    "\n",
    "# curr_active_pipeline.get_merged_computation_function_validators()\n",
    "# Get the names of the global and non-global computations:\n",
    "all_validators_dict = curr_active_pipeline.get_merged_computation_function_validators()\n",
    "global_only_validators_dict = {k:v for k, v in all_validators_dict.items() if v.is_global}\n",
    "non_global_only_validators_dict = {k:v for k, v in all_validators_dict.items() if (not v.is_global)}\n",
    "non_global_comp_names: List[str] = [v.short_name for k, v in non_global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))] # ['firing_rate_trends', 'spike_burst_detection', 'pf_dt_sequential_surprise', 'extended_stats', 'placefield_overlap', 'ratemap_peaks_prominence2d', 'velocity_vs_pf_simplified_count_density', 'EloyAnalysis', '_perform_specific_epochs_decoding', 'recursive_latent_pf_decoding', 'position_decoding_two_step', 'position_decoding', 'lap_direction_determination', 'pfdt_computation', 'pf_computation']\n",
    "global_comp_names: List[str] = [v.short_name for k, v in global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))] # ['long_short_endcap_analysis', 'long_short_inst_spike_rate_groups', 'long_short_post_decoding', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_decoding_analyses', 'PBE_stats', 'rank_order_shuffle_analysis', 'directional_decoders_epoch_heuristic_scoring', 'directional_decoders_evaluate_epochs', 'directional_decoders_decode_continuous', 'merged_directional_placefields', 'split_to_directional_laps']\n",
    "\n",
    "# mappings between the long computation function names and their short names:\n",
    "non_global_comp_names_map: Dict[str, str] = {v.computation_fn_name:v.short_name for k, v in non_global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))}\n",
    "global_comp_names_map: Dict[str, str] = {v.computation_fn_name:v.short_name for k, v in global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))} # '_perform_long_short_endcap_analysis': 'long_short_endcap_analysis', '_perform_long_short_instantaneous_spike_rate_groups_analysis': 'long_short_inst_spike_rate_groups', ...}\n",
    "\n",
    "# convert long function names to short-names:\n",
    "each_epoch_each_result_computation_completion_times = {an_epoch:{non_global_comp_names_map.get(k, k):v for k,v in a_results_dict.items()} for an_epoch, a_results_dict in each_epoch_each_result_computation_completion_times.items()}\n",
    "global_computation_completion_times = {global_comp_names_map.get(k, k):v for k,v in global_computation_completion_times.items()}\n",
    "\n",
    "each_epoch_each_result_computation_completion_times\n",
    "global_computation_completion_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967369f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_evaluate_required_computations\n",
    "\n",
    "force_recompute_global = force_reload\n",
    "\n",
    "active_probe_includelist = extended_computations_include_includelist\n",
    "# active_probe_includelist = ['lap_direction_determination']\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=active_probe_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "needs_computation_output_dict\n",
    "# valid_computed_results_output_list\n",
    "# remaining_include_function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59374622",
   "metadata": {},
   "outputs": [],
   "source": [
    "'lap_direction_determination'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3799ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recompute_earlier_than_date = datetime(2024, 4, 1, 0, 0, 0)\n",
    "recompute_earlier_than_date\n",
    "\n",
    "each_epoch_needing_recompute = [an_epoch for an_epoch, last_computed_datetime in each_epoch_latest_computation_time.items() if (last_computed_datetime < recompute_earlier_than_date)]\n",
    "each_epoch_needing_recompute\n",
    "each_epoch_each_result_needing_recompute = {an_epoch:{a_computation_name:last_computed_datetime for a_computation_name, last_computed_datetime in last_computed_datetimes_dict.items() if (last_computed_datetime < recompute_earlier_than_date)} for an_epoch, last_computed_datetimes_dict in each_epoch_each_result_computation_completion_times.items()}\n",
    "each_epoch_each_result_needing_recompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ffa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_times\n",
    "curr_active_pipeline.global_computation_results\n",
    "# curr_active_pipeline.try_load_split_pickled_global_computation_results\n",
    "\n",
    "global_computation_times = deepcopy(curr_active_pipeline.global_computation_results.computation_times.to_dict()) # DynamicParameters({'perform_rank_order_shuffle_analysis': datetime.datetime(2024, 4, 3, 5, 41, 31, 287680), '_decode_continuous_using_directional_decoders': datetime.datetime(2024, 4, 3, 5, 12, 7, 337326), '_perform_long_short_decoding_analyses': datetime.datetime(2024, 4, 3, 5, 43, 10, 361685), '_perform_long_short_pf_overlap_analyses': datetime.datetime(2024, 4, 3, 5, 43, 10, 489296), '_perform_long_short_firing_rate_analyses': datetime.datetime(2024, 4, 3, 5, 45, 3, 73472), '_perform_jonathan_replay_firing_rate_analyses': datetime.datetime(2024, 4, 3, 5, 45, 5, 168790), '_perform_long_short_post_decoding_analysis': datetime.datetime(2024, 2, 16, 18, 13, 4, 734621), '_perform_long_short_endcap_analysis': datetime.datetime(2024, 4, 3, 5, 45, 24, 274261), '_decode_and_evaluate_epochs_using_directional_decoders': datetime.datetime(2024, 4, 3, 5, 14, 37, 935482), '_perform_long_short_instantaneous_spike_rate_groups_analysis': datetime.datetime(2024, 4, 3, 5, 45, 24, 131955), '_split_to_directional_laps': datetime.datetime(2024, 4, 3, 5, 11, 22, 627789), '_build_merged_directional_placefields': datetime.datetime(2024, 4, 3, 5, 11, 28, 376078)})\n",
    "global_computation_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693db067",
   "metadata": {},
   "source": [
    "# Pho Interactive Pipeline Jupyter Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e275e3bb",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7a5b1151214ac9943cbd826bc4a051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Box(children=(Label(value='session path:', layout=Layout(width='auto')), HTML(value=\"<b style='font-size: larger;'>W:\\\\Data\\\\KDIBA\\\\gor01\\\\two\\\\2006-6-09_22-24-40\\\\output</b>\", layout=Layout(flex='1 1 auto', margin='2px', width='auto')), Button(button_style='info', description='Copy', icon='clipboard', layout=Layout(flex='0 1 auto', margin='1px', width='auto'), style=ButtonStyle(), tooltip='Copy to Clipboard'), Button(button_style='info', description='Reveal', icon='folder-open-o', layout=Layout(flex='0 1 auto', margin='1px', width='auto'), style=ButtonStyle(), tooltip='Reveal in System Explorer')), layout=Layout(align_items='center', display='flex', flex_flow='row nowrap', justify_content='flex-start', width='70%')), HBox(children=(Button(description='Output Folder', style=ButtonStyle()), Button(description='global pickle', style=ButtonStyle()), Button(description='pipeline pickle', style=ButtonStyle()), Button(description='.h5 export', style=ButtonStyle()), Button(description='TEST - Dialog', style=ButtonStyle()), Button(description='Save Pipeline', style=ButtonStyle()))), HBox(children=(Button(description='Reload display functions...', style=ButtonStyle()), Button(description='Reload computation functions...', style=ButtonStyle()))), ToggleButton(value=True, description='Figures Displaying')))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "\n",
    "_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\n",
    "# display(_pipeline_jupyter_widget)\n",
    "_pipeline_jupyter_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe54599",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a533ba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:40.700275900Z",
     "start_time": "2023-11-16T23:21:40.584273Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 911.6011600069469, 2573.457162000006)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "\n",
    "assert short_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "assert long_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "t_start, t_delta, t_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_epoch_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b35196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have several python variables I want to print: t_start, t_delta, t_end\n",
    "# I want to generate a print statement that explicitly lists the variable name prior to its value like `print(f't_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')`\n",
    "# Currently I have to t_start, t_delta, t_end\n",
    "curr_active_pipeline.get_session_context()\n",
    "\n",
    "print(f'{curr_active_pipeline.session_name}:\\tt_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9071e94f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:43.601382Z",
     "start_time": "2023-11-16T23:21:40.702275600Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "WARNING: PAPER_FIGURE_figure_1_add_replay_epoch_rasters(...): no user-assigned manually labeled replay epochs. Reeturning all epochs.\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n"
     ]
    }
   ],
   "source": [
    "## long_short_decoding_analyses:\n",
    "from attrs import astuple\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import LeaveOneOutDecodingAnalysis\n",
    "\n",
    "curr_long_short_decoding_analyses: LeaveOneOutDecodingAnalysis = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global \n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "## Get global `long_short_fr_indicies_analysis`:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n",
    "long_short_fr_indicies_df = long_short_fr_indicies_analysis_results['long_short_fr_indicies_df']\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result.Flat_epoch_time_bins_mean, expected_v_observed_result.Flat_decoder_time_bin_centers, expected_v_observed_result.num_neurons, expected_v_observed_result.num_timebins_in_epoch, expected_v_observed_result.num_total_flat_timebins, expected_v_observed_result.is_short_track_epoch, expected_v_observed_result.is_long_track_epoch, expected_v_observed_result.short_short_diff, expected_v_observed_result.long_long_diff\n",
    "\n",
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.05)\n",
    "\n",
    "## Update long_exclusive/short_exclusive properties with `long_short_fr_indicies_df`\n",
    "# long_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n",
    "# short_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c49f5d4f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Most popular\n",
    "# long_LR_name, short_LR_name, long_RL_name, short_RL_name, global_any_name\n",
    "\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7104fc37",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum_inclusion_fr_Hz: 5.0\n",
      "included_qclu_values: [1, 2]\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult, DirectionalLapsResult, DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']   \n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "included_qclu_values: float = rank_order_results.included_qclu_values\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93346114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.BatchCompletionHandler import BatchSessionCompletionHandler\n",
    "\n",
    "BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(directional_laps_results.directional_lap_specific_configs.keys()) # ['maze1_odd', 'maze1_even', 'maze2_odd', 'maze2_even']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912656a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "\n",
    "## UNPACK HERE via direct property access:\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "ripple_decoding_time_bin_size = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "# New items:\n",
    "decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "# Weighted correlations:\n",
    "laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "# Pearson's correlations:\n",
    "laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "238f67cb",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previously_decoded time_bin_sizes: [0.025]\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "if 'DirectionalDecodersDecoded' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "    all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "    spikes_df = directional_decoders_decode_result.spikes_df\n",
    "    continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "    previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "    print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "\n",
    "most_recent_time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# most_recent_time_bin_size\n",
    "most_recent_continuously_decoded_dict = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\n",
    "# most_recent_continuously_decoded_dict\n",
    "\n",
    "## Adds in the 'pseudo2D' decoder in:\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# time_bin_size: float = 0.01\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict = continuously_decoded_result_cache_dict[time_bin_size]\n",
    "pseudo2D_decoder_continuously_decoded_result = continuously_decoded_dict.get('pseudo2D', None)\n",
    "if pseudo2D_decoder_continuously_decoded_result is None:\n",
    "\t# compute here...\n",
    "\t## Currently used for both cases to decode:\n",
    "\tt_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\tsingle_global_epoch_df: pd.DataFrame = pd.DataFrame({'start': [t_start], 'stop': [t_end], 'label': [0]}) # Build an Epoch object containing a single epoch, corresponding to the global epoch for the entire session:\n",
    "\tsingle_global_epoch: Epoch = Epoch(single_global_epoch_df)\n",
    "\tspikes_df = directional_decoders_decode_result.spikes_df\n",
    "\tpseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = pseudo2D_decoder.decode_specific_epochs(spikes_df=deepcopy(spikes_df), filter_epochs=single_global_epoch, decoding_time_bin_size=time_bin_size, debug_print=False)\n",
    "\tcontinuously_decoded_dict['pseudo2D'] = pseudo2D_decoder_continuously_decoded_result\n",
    "\tcontinuously_decoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa2dc5fe",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# NEW 2023-11-22 method: Get the templates (which can be filtered by frate first) and the from those get the decoders):        \n",
    "# track_templates: TrackTemplates = directional_laps_results.get_shared_aclus_only_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # shared-only\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only\n",
    "long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = track_templates.get_decoders()\n",
    "\n",
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n",
    "\n",
    "# `LongShortStatsItem` form (2024-01-02):\n",
    "# LR_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "# RL_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n",
    "LR_results_long_short_z_diffs = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "RL_results_long_short_z_diff = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c260739a4f36c662",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrainTestSplitResult\n",
    "\n",
    "directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data.get('TrainTestSplit', None)\n",
    "training_data_portion: float = directional_train_test_split_result.training_data_portion\n",
    "test_data_portion: float = directional_train_test_split_result.test_data_portion\n",
    "test_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.test_epochs_dict\n",
    "train_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.train_epochs_dict\n",
    "train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_train_test_split_result.train_lap_specific_pf1D_Decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_burst_intervals = curr_active_pipeline.computation_results[global_epoch_name].computed_data['burst_detection']['burst_intervals']\n",
    "# active_burst_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_extended_stats = global_results['extended_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a1c6006aba5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Entropy/Surprise Results:\n",
    "active_extended_stats = global_results['extended_stats']\n",
    "active_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise'] # DynamicParameters\n",
    "historical_snapshots = active_relative_entropy_results['historical_snapshots']\n",
    "post_update_times: np.ndarray = active_relative_entropy_results['post_update_times'] # (4152,) = (n_post_update_times,)\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals: np.ndarray = active_relative_entropy_results['time_intervals']\n",
    "surprise_time_bin_duration = (post_update_times[2]-post_update_times[1])\n",
    "long_short_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "flat_relative_entropy_results: np.ndarray = active_relative_entropy_results['flat_relative_entropy_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_results: np.ndarray = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_across_all_positions: np.ndarray = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "flat_surprise_across_all_positions: np.ndarray = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\n",
    "## Get the placefield dt matrix:\n",
    "if 'snapshot_occupancy_weighted_tuning_maps' not in active_relative_entropy_results:\n",
    "\t## Compute it if missing:\n",
    "\toccupancy_weighted_tuning_maps_over_time = np.stack([placefield_snapshot.occupancy_weighted_tuning_maps_matrix for placefield_snapshot in historical_snapshots.values()])\n",
    "\tactive_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] = occupancy_weighted_tuning_maps_over_time\n",
    "else:\n",
    "\toccupancy_weighted_tuning_maps_over_time = active_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] # (n_post_update_times, n_neurons, n_xbins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554d3bf5955d9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8624c62d5c18c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "## long_short_endcap_analysis: checks for cells localized to the endcaps that have their placefields truncated after shortening the track\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "# disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "# trivially_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "# significant_distant_remapping_endcap_aclus\n",
    "appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n",
    "# appearing_aclus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec24467335a760",
   "metadata": {},
   "source": [
    "# POST-Compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "728c46e6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    },
    "tags": [
     "unwrap"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum_inclusion_fr_Hz: 5.0\n",
      "included_qclu_values: [1, 2]\n",
      "laps_decoding_time_bin_size: 0.25, ripple_decoding_time_bin_size: 0.025\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multi_sort_raster_browser\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import paired_separately_sort_neurons, paired_incremental_sort_neurons # _display_directional_template_debugger\n",
    "from neuropy.utils.indexing_helpers import paired_incremental_sorting, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ScrollBarWithSpinBox.ScrollBarWithSpinBox import ScrollBarWithSpinBox\n",
    "\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_SerializationMixin\n",
    "from pyphoplacecellanalysis.General.Model.ComputationResults import ComputedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses, RankOrderResult, ShuffleHelper, Zscorer, LongShortStatsTuple, DirectionalRankOrderLikelihoods, DirectionalRankOrderResult, RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "## Display Testing\n",
    "# from pyphoplacecellanalysis.External.pyqtgraph import QtGui\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import pyqtplot_build_image_bounds_extent, pyqtplot_plot_image\n",
    "\n",
    "spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "ripple_result_tuple, laps_result_tuple = rank_order_results.ripple_most_likely_result_tuple, rank_order_results.laps_most_likely_result_tuple\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')\n",
    "# ripple_result_tuple\n",
    "\n",
    "## Unpacks `rank_order_results`: \n",
    "# global_replays = Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# global_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# active_replay_epochs, active_epochs_df, active_selected_spikes_df = combine_rank_order_results(rank_order_results, global_replays, track_templates=track_templates)\n",
    "# active_epochs_df\n",
    "\n",
    "# ripple_result_tuple.directional_likelihoods_tuple.long_best_direction_indices\n",
    "dir_index_to_direction_name_map: Dict[int, str] = {0:'LR', 1:\"RL\"}\n",
    "\n",
    "\n",
    "## All three DataFrames are the same number of rows, each with one row corresponding to an Epoch:\n",
    "active_replay_epochs_df = deepcopy(rank_order_results.LR_ripple.epochs_df)\n",
    "# active_replay_epochs_df\n",
    "\n",
    "# Change column type to int8 for columns: 'long_best_direction_indices', 'short_best_direction_indices'\n",
    "# directional_likelihoods_df = pd.DataFrame.from_dict(ripple_result_tuple.directional_likelihoods_tuple._asdict()).astype({'long_best_direction_indices': 'int8', 'short_best_direction_indices': 'int8'})\n",
    "directional_likelihoods_df = ripple_result_tuple.directional_likelihoods_df\n",
    "# directional_likelihoods_df\n",
    "\n",
    "# 2023-12-15 - Newest method:\n",
    "# laps_combined_epoch_stats_df = rank_order_results.laps_combined_epoch_stats_df\n",
    "\n",
    "# ripple_combined_epoch_stats_df: pd.DataFrame  = rank_order_results.ripple_combined_epoch_stats_df\n",
    "# ripple_combined_epoch_stats_df\n",
    "\n",
    "\n",
    "# # Concatenate the three DataFrames along the columns axis:\n",
    "# # Assert that all DataFrames have the same number of rows:\n",
    "# assert len(active_replay_epochs_df) == len(directional_likelihoods_df) == len(ripple_combined_epoch_stats_df), \"DataFrames have different numbers of rows.\"\n",
    "# # Assert that all DataFrames have at least one row:\n",
    "# assert len(active_replay_epochs_df) > 0, \"active_replay_epochs_df is empty.\"\n",
    "# assert len(directional_likelihoods_df) > 0, \"directional_likelihoods_df is empty.\"\n",
    "# assert len(ripple_combined_epoch_stats_df) > 0, \"ripple_combined_epoch_stats_df is empty.\"\n",
    "# merged_complete_epoch_stats_df: pd.DataFrame = pd.concat([active_replay_epochs_df.reset_index(drop=True, inplace=False), directional_likelihoods_df.reset_index(drop=True, inplace=False), ripple_combined_epoch_stats_df.reset_index(drop=True, inplace=False)], axis=1)\n",
    "# merged_complete_epoch_stats_df = merged_complete_epoch_stats_df.set_index(active_replay_epochs_df.index, inplace=False)\n",
    "\n",
    "# merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "# merged_complete_epoch_stats_df.to_csv('output/2023-12-21_merged_complete_epoch_stats_df.csv')\n",
    "# merged_complete_epoch_stats_df\n",
    "\n",
    "laps_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.laps_merged_complete_epoch_stats_df ## New method\n",
    "ripple_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "all_directional_decoder_dict_value = directional_merged_decoders_result.all_directional_decoder_dict\n",
    "all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "# long_directional_pf1D_Decoder_value = directional_merged_decoders_result.long_directional_pf1D_Decoder\n",
    "# long_directional_decoder_dict_value = directional_merged_decoders_result.long_directional_decoder_dict\n",
    "# short_directional_pf1D_Decoder_value = directional_merged_decoders_result.short_directional_pf1D_Decoder\n",
    "# short_directional_decoder_dict_value = directional_merged_decoders_result.short_directional_decoder_dict\n",
    "\n",
    "all_directional_laps_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "all_directional_ripple_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\n",
    "\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = directional_merged_decoders_result.laps_track_identity_marginals_tuple\n",
    "ripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.ripple_directional_marginals_tuple\n",
    "ripple_track_identity_marginals, ripple_track_identity_all_epoch_bins_marginal, ripple_most_likely_track_identity_from_decoder, ripple_is_most_likely_track_identity_Long = directional_merged_decoders_result.ripple_track_identity_marginals_tuple\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "\n",
    "laps_all_epoch_bins_marginals_df = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "ripple_all_epoch_bins_marginals_df = directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "753ca336",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(active_epochs_df): 707\n",
      "min_num_unique_aclu_inclusions: 12\n",
      "len(active_epochs_df): 405\n",
      "df_column_names: [['start', 'stop', 'label', 'duration', 'score', 'velocity', 'intercept', 'speed', 'wcorr', 'P_decoder', 'pearsonr', 'is_user_annotated_epoch', 'is_valid_epoch', 'travel', 'coverage', 'jump', 'sequential_correlation', 'monotonicity_score', 'laplacian_smoothness', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff'], ['start', 'stop', 'label', 'duration', 'score', 'velocity', 'intercept', 'speed', 'wcorr', 'P_decoder', 'pearsonr', 'is_user_annotated_epoch', 'is_valid_epoch', 'travel', 'coverage', 'jump', 'sequential_correlation', 'monotonicity_score', 'laplacian_smoothness', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff'], ['start', 'stop', 'label', 'duration', 'score', 'velocity', 'intercept', 'speed', 'wcorr', 'P_decoder', 'pearsonr', 'is_user_annotated_epoch', 'is_valid_epoch', 'travel', 'coverage', 'jump', 'sequential_correlation', 'monotonicity_score', 'laplacian_smoothness', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff'], ['start', 'stop', 'label', 'duration', 'score', 'velocity', 'intercept', 'speed', 'wcorr', 'P_decoder', 'pearsonr', 'is_user_annotated_epoch', 'is_valid_epoch', 'travel', 'coverage', 'jump', 'sequential_correlation', 'monotonicity_score', 'laplacian_smoothness', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "      <th>n_unique_aclus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>373.508345</td>\n",
       "      <td>373.754474</td>\n",
       "      <td>42</td>\n",
       "      <td>0.246129</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>391.894747</td>\n",
       "      <td>392.162533</td>\n",
       "      <td>54</td>\n",
       "      <td>0.267786</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550.845107</td>\n",
       "      <td>551.033758</td>\n",
       "      <td>72</td>\n",
       "      <td>0.188651</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>551.871707</td>\n",
       "      <td>552.327684</td>\n",
       "      <td>73</td>\n",
       "      <td>0.455977</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>565.161234</td>\n",
       "      <td>565.416732</td>\n",
       "      <td>82</td>\n",
       "      <td>0.255498</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600.243947</td>\n",
       "      <td>600.767907</td>\n",
       "      <td>100</td>\n",
       "      <td>0.523960</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>616.347732</td>\n",
       "      <td>616.665438</td>\n",
       "      <td>109</td>\n",
       "      <td>0.317706</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>919.581379</td>\n",
       "      <td>919.691694</td>\n",
       "      <td>163</td>\n",
       "      <td>0.110315</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start        stop label  duration  n_unique_aclus\n",
       "0  373.508345  373.754474    42  0.246129              20\n",
       "1  391.894747  392.162533    54  0.267786              18\n",
       "2  550.845107  551.033758    72  0.188651              23\n",
       "3  551.871707  552.327684    73  0.455977              27\n",
       "4  565.161234  565.416732    82  0.255498              20\n",
       "5  600.243947  600.767907   100  0.523960              28\n",
       "6  616.347732  616.665438   109  0.317706              19\n",
       "7  919.581379  919.691694   163  0.110315              12"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "# from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import HeuristicReplayScoring\n",
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size)\n",
    "filtered_epochs_df\n",
    "# filtered_ripple_all_epoch_bins_marginals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae6e077",
   "metadata": {},
   "source": [
    "### 2024-02-29 - 4pm - Filter the events for those meeting wcorr criteria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_wcorr_threshold: float = 0.33\n",
    "min_wcorr_diff_threshold: float = 0.2\n",
    "\n",
    "is_included_large_wcorr_diff = np.any((filtered_ripple_all_epoch_bins_marginals_df[['wcorr_abs_diff']].abs() > min_wcorr_diff_threshold), axis=1)\n",
    "# is_included_large_wcorr_diff\n",
    "is_included_high_wcorr = np.any((filtered_ripple_all_epoch_bins_marginals_df[['long_best_wcorr', 'short_best_wcorr']].abs() > min_wcorr_threshold), axis=1)\n",
    "\n",
    "df = filtered_ripple_all_epoch_bins_marginals_df[is_included_large_wcorr_diff]\n",
    "# df = filtered_ripple_all_epoch_bins_marginals_df[is_included_high_wcorr]\n",
    "df\n",
    "\n",
    "# delta_aligned_start_t\n",
    "\n",
    "significant_epochs_start_ts = np.squeeze(df['ripple_start_t'].to_numpy()) ## for filtering\n",
    "\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(significant_epochs_start_ts) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "filtered_decoder_filter_epochs_decoder_result_dict\n",
    "filtered_epochs_df = filtered_epochs_df.epochs.matching_epoch_times_slice(significant_epochs_start_ts)\n",
    "# filtered_ripple_all_epoch_bins_marginals_df = filtered_ripple_all_epoch_bins_marginals_df.epochs.matching_epoch_times_slice(significant_epochs_start_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15332e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "included_qclu_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35edc67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import plot_quantile_diffs\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "global_epoch = curr_active_pipeline.filtered_epochs[global_epoch_name]\n",
    "short_epoch = curr_active_pipeline.filtered_epochs[short_epoch_name]\n",
    "split_time_t: float = short_epoch.t_start\n",
    "active_context = curr_active_pipeline.sess.get_context()\n",
    "\n",
    "collector = plot_quantile_diffs(filtered_ripple_all_epoch_bins_marginals_df, t_split=split_time_t, active_context=active_context)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b53c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ripple_merged_complete_epoch_stats_df\n",
    "laps_merged_complete_epoch_stats_df\n",
    "['long_best_direction_indices', 'short_best_direction_indices', 'combined_best_direction_indicies', 'long_relative_direction_likelihoods', 'short_relative_direction_likelihoods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the time series of Long-likely events\n",
    "# type(long_RL_results) # DynamicParameters\n",
    "long_LR_pf1D_Decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_directional_decoder_dict_value)\n",
    "list(all_directional_decoder_dict_value.keys()) # ['long_LR', 'long_RL', 'short_LR', 'short_RL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_all_epoch_bins_marginals_df\n",
    "laps_most_likely_direction_from_decoder\n",
    "long_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdabd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ripple_result_tuple) # pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations.DirectionalRankOrderResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "\n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15629dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots \n",
    "\n",
    "# @register_type_display(DirectionalRankOrderResult)\n",
    "def plot_histograms(self: DirectionalRankOrderResult, **kwargs) -> \"MatplotlibRenderPlots\":\n",
    "\t\"\"\" \n",
    "\tnum='RipplesRankOrderZscore'\n",
    "\t\"\"\"\n",
    "\tprint(f'.plot_histograms(..., kwargs: {kwargs})')\n",
    "\tfig = plt.figure(layout=\"constrained\", **kwargs)\n",
    "\tax_dict = fig.subplot_mosaic(\n",
    "\t\t[\n",
    "\t\t\t[\"long_short_best_z_score_diff\", \"long_short_best_z_score_diff\"],\n",
    "\t\t\t[\"long_best_z_scores\", \"short_best_z_scores\"],\n",
    "\t\t],\n",
    "\t)\n",
    "\tplots = (pd.DataFrame({'long_best_z_scores': self.long_best_dir_z_score_values}).hist(ax=ax_dict['long_best_z_scores'], bins=21, alpha=0.8),\n",
    "\t\tpd.DataFrame({'short_best_z_scores': self.short_best_dir_z_score_values}).hist(ax=ax_dict['short_best_z_scores'], bins=21, alpha=0.8),\n",
    "\t\tpd.DataFrame({'long_short_best_z_score_diff': self.long_short_best_dir_z_score_diff_values}).hist(ax=ax_dict['long_short_best_z_score_diff'], bins=21, alpha=0.8),\n",
    "\t)\n",
    "\treturn MatplotlibRenderPlots(name='plot_histogram_figure', figures=[fig], axes=ax_dict)\n",
    "\n",
    "\n",
    "register_type_display(plot_histograms, DirectionalRankOrderResult)\n",
    "## Call the newly added `plot_histograms` function on the `ripple_result_tuple` object which is of type `DirectionalRankOrderResult`:\n",
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c291690",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_result_tuple.plot_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b30bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💾 CSVs \n",
    "print(f'\\t try saving to CSV...')\n",
    "merged_complete_epoch_stats_df = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "merged_complete_epoch_stats_df\n",
    "merged_complete_ripple_epoch_stats_df_output_path = curr_active_pipeline.get_output_path().joinpath(f'{DAY_DATE_TO_USE}_merged_complete_epoch_stats_df.csv').resolve()\n",
    "merged_complete_epoch_stats_df.to_csv(merged_complete_ripple_epoch_stats_df_output_path)\n",
    "print(f'\\t saving to CSV: {merged_complete_ripple_epoch_stats_df_output_path} done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732743e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_combined_epoch_stats_df = deepcopy(merged_complete_epoch_stats_df)\n",
    "\n",
    "# Filter rows based on columns: 'Long_BestDir_quantile', 'Short_BestDir_quantile'\n",
    "quantile_significance_threshold: float = 0.95\n",
    "significant_BestDir_quantile_stats_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['Long_BestDir_quantile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['Short_BestDir_quantile'] > quantile_significance_threshold)]\n",
    "LR_likely_active_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['combined_best_direction_indicies']==0) & ((ripple_combined_epoch_stats_df['LR_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['LR_Short_rank_percentile'] > quantile_significance_threshold))]\n",
    "RL_likely_active_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['combined_best_direction_indicies']==1) & ((ripple_combined_epoch_stats_df['RL_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['RL_Short_rank_percentile'] > quantile_significance_threshold))]\n",
    "\n",
    "# significant_ripple_combined_epoch_stats_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['LR_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['LR_Short_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['RL_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['RL_Short_rank_percentile'] > quantile_significance_threshold)]\n",
    "# significant_ripple_combined_epoch_stats_df\n",
    "is_epoch_significant = np.isin(ripple_combined_epoch_stats_df.index, significant_BestDir_quantile_stats_df.index)\n",
    "active_replay_epochs_df = rank_order_results.LR_ripple.epochs_df\n",
    "significant_ripple_epochs: Epoch = Epoch(deepcopy(active_replay_epochs_df).epochs.get_valid_df()).boolean_indicies_slice(is_epoch_significant)\n",
    "epoch_identifiers = significant_ripple_epochs._df.label.astype({'label': RankOrderAnalyses._label_column_type}).values #.labels\n",
    "x_values = significant_ripple_epochs.midtimes\n",
    "x_axis_name_suffix = 'Mid-time (Sec)'\n",
    "\n",
    "# significant_ripple_epochs_df = significant_ripple_epochs.to_dataframe()\n",
    "# significant_ripple_epochs_df\n",
    "\n",
    "significant_BestDir_quantile_stats_df['midtimes'] = significant_ripple_epochs.midtimes\n",
    "significant_BestDir_quantile_stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee47f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import reorder_columns\n",
    "\n",
    "dict(zip(['Long_LR_evidence', 'Long_RL_evidence', 'Short_LR_evidence', 'Short_RL_evidence'], np.arange(4)+4))\n",
    "reorder_columns(merged_complete_epoch_stats_df, column_name_desired_index_dict=dict(zip(['Long_LR_evidence', 'Long_RL_evidence', 'Short_LR_evidence', 'Short_RL_evidence'], np.arange(4)+4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import plot_quantile_diffs\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "global_epoch = curr_active_pipeline.filtered_epochs[global_epoch_name]\n",
    "short_epoch = curr_active_pipeline.filtered_epochs[short_epoch_name]\n",
    "split_time_t: float = short_epoch.t_start\n",
    "active_context = curr_active_pipeline.sess.get_context()\n",
    "\n",
    "collector = plot_quantile_diffs(ripple_merged_complete_epoch_stats_df, t_split=split_time_t, active_context=active_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43327521",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logical_not(np.isnan(rank_order_results.ripple_combined_epoch_stats_df.index).any())\n",
    "# ripple_combined_epoch_stats_df.label.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_combined_epoch_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3cedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(ripple_combined_epoch_stats_df.label).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31224e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(ripple_combined_epoch_stats_df.index).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60749347",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tdone. building global result.\n"
     ]
    }
   ],
   "source": [
    "print(f'\\tdone. building global result.')\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "selected_spikes_df = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.selected_spikes_df)\n",
    "# active_epochs = global_computation_results.computed_data['RankOrder'].ripple_most_likely_result_tuple.active_epochs\n",
    "active_epochs = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.epochs_df)\n",
    "track_templates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ab4052",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_combined_epoch_stats_df, ripple_new_output_tuple = RankOrderAnalyses.pandas_df_based_correlation_computations(selected_spikes_df=selected_spikes_df, active_epochs_df=active_epochs, track_templates=track_templates, num_shuffles=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313886d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_output_tuple (output_active_epoch_computed_values, valid_stacked_arrays, real_stacked_arrays, n_valid_shuffles) = ripple_new_output_tuple\n",
    "curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_combined_epoch_stats_df, curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_new_output_tuple = ripple_combined_epoch_stats_df, ripple_new_output_tuple\n",
    "print(f'done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc018065",
   "metadata": {},
   "source": [
    "# Call perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6522e",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "from attrs import make_class\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=10)\n",
    "save_hdf: bool = False\n",
    "\n",
    "SimpleBatchComputationDummy = make_class('SimpleBatchComputationDummy', attrs=['BATCH_DATE_TO_USE', 'collected_outputs_path'])\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path)\n",
    "\n",
    "_across_session_results_extended_dict = {}\n",
    "## Combine the output of `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tacross_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=save_hdf, return_full_decoding_results=return_full_decoding_results,\n",
    "                                                desired_shared_decoding_time_bin_sizes=desired_shared_decoding_time_bin_sizes,\n",
    "                                                )\n",
    "if return_full_decoding_results:\n",
    "    # with `return_full_decoding_results == True`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_full_directional_merged_decoders_result, output_directional_decoders_epochs_decode_results_dict = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    # validate the result:\n",
    "    {k:v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size for k,v in output_full_directional_merged_decoders_result.items()}\n",
    "    assert np.all([np.isclose(dict(k)['desired_shared_decoding_time_bin_size'], v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size) for k,v in output_full_directional_merged_decoders_result.items()]), f\"the desired time_bin_size in the parameters should match the one used that will appear in the decoded result\"\n",
    "\n",
    "else:\n",
    "    # with `return_full_decoding_results == False`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    output_full_directional_merged_decoders_result = None\n",
    "\n",
    "\n",
    "(several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb39d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "v: DecoderDecodedEpochsResult = list(output_directional_decoders_epochs_decode_results_dict.values())[0]\n",
    "type(v)\n",
    "\n",
    "_out = v.export_csvs(parent_output_path=collected_outputs_path, active_context=curr_active_pipeline.get_session_context(), session_name=curr_active_pipeline.session_name, curr_session_t_delta=t_delta)\n",
    "\n",
    "# assert self.collected_outputs_path.exists()\n",
    "# curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "# CURR_BATCH_OUTPUT_PREFIX: str = f\"{self.BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "# print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_computations\n",
    "# curr_active_pipeline.reload_default_computation_functions()\n",
    "# batch_extended_computations(curr_active_pipeline, include_includelist=['merged_directional_placefields'], include_global_functions=True, fail_on_exception=True, force_recompute=False)\n",
    "# directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context()\n",
    "# _out = directional_merged_decoders_result.compute_and_export_marginals_df_csvs(parent_output_path=self.collected_outputs_path, active_context=active_context)\n",
    "# print(f'successfully exported marginals_df_csvs to {self.collected_outputs_path}!')\n",
    "# (laps_marginals_df, laps_out_path), (ripple_marginals_df, ripple_out_path) = _out\n",
    "(laps_marginals_df, laps_out_path, laps_time_bin_marginals_df, laps_time_bin_marginals_out_path), (ripple_marginals_df, ripple_out_path, ripple_time_bin_marginals_df, ripple_time_bin_marginals_out_path) = _out\n",
    "print(f'\\tlaps_out_path: {laps_out_path}\\n\\tripple_out_path: {ripple_out_path}\\n\\tdone.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take extra computations from `_decode_and_evaluate_epochs_using_directional_decoders` and integrate into the multi-time-bin results from `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_all_df_score_metrics\n",
    "\n",
    "should_skip_radon_transform = True\n",
    "## Recompute the epoch scores/metrics such as radon transform and wcorr:\n",
    "\n",
    "a_sweep_tuple, a_pseudo_2D_result = list(output_full_directional_merged_decoders_result.items())[0]\n",
    "a_decoder_laps_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result)\n",
    "a_decoder_ripple_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_ripple_filter_epochs_decoder_result)\n",
    "\n",
    "(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict), merged_df_outputs_tuple, raw_dict_outputs_tuple = _compute_all_df_score_metrics(directional_merged_decoders_result, track_templates,\n",
    "                                                                                                                                                                                    decoder_laps_filter_epochs_decoder_result_dict=a_decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict=a_decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                                                                    spikes_df=deepcopy(curr_active_pipeline.sess.spikes_df),\n",
    "                                                                                                                                                                                    should_skip_radon_transform=should_skip_radon_transform)\n",
    "laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df, laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df = merged_df_outputs_tuple\n",
    "decoder_laps_radon_transform_df_dict, decoder_ripple_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict, decoder_ripple_radon_transform_extras_dict, decoder_laps_weighted_corr_df_dict, decoder_ripple_weighted_corr_df_dict = raw_dict_outputs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a3ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_sweep_tuple, a_pseudo_2D_result in output_full_directional_merged_decoders_result.items():\n",
    "    a_pseudo_2D_result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfda868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `_perform_compute_custom_epoch_decoding`\n",
    "\n",
    "a_sweep_tuple\n",
    "# a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result\n",
    "# a_pseudo_2D_result\n",
    "# a_pseudo_2D_result.short_directional_decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9603a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_keys_if_possible('several_time_bin_sizes_laps_df', several_time_bin_sizes_laps_df)\n",
    "print_keys_if_possible('output_full_directional_merged_decoders_result', output_full_directional_merged_decoders_result, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a71abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_file_pat\n",
    "collected_outputs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_laps_decoding_accuracy_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd970d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_histograms( data_type: str, session_spec: str, data_results_df: pd.DataFrame, time_bin_duration_str: str ) -> None:\n",
    "#     # get the pre-delta epochs\n",
    "#     pre_delta_df = data_results_df[data_results_df['delta_aligned_start_t'] <= 0]\n",
    "#     post_delta_df = data_results_df[data_results_df['delta_aligned_start_t'] > 0]\n",
    "\n",
    "#     descriptor_str: str = '|'.join([data_type, session_spec, time_bin_duration_str])\n",
    "    \n",
    "#     # plot pre-delta histogram\n",
    "#     pre_delta_df.hist(column='P_Long')\n",
    "#     plt.title(f'{descriptor_str} - pre-$\\Delta$ time bins')\n",
    "#     plt.show()\n",
    "\n",
    "#     # plot post-delta histogram\n",
    "#     post_delta_df.hist(column='P_Long')\n",
    "#     plt.title(f'{descriptor_str} - post-$\\Delta$ time bins')\n",
    "#     plt.show()\n",
    "    \n",
    "\n",
    "def plot_histograms(data_type: str, session_spec: str, data_results_df: pd.DataFrame, time_bin_duration_str: str) -> None:\n",
    "    \"\"\" plots a stacked histogram of the many time-bin sizes \"\"\"\n",
    "    # get the pre-delta epochs\n",
    "    pre_delta_df = data_results_df[data_results_df['delta_aligned_start_t'] <= 0]\n",
    "    post_delta_df = data_results_df[data_results_df['delta_aligned_start_t'] > 0]\n",
    "\n",
    "    descriptor_str: str = '|'.join([data_type, session_spec, time_bin_duration_str])\n",
    "    \n",
    "    # plot pre-delta histogram\n",
    "    time_bin_sizes = pre_delta_df['time_bin_size'].unique()\n",
    "    \n",
    "    figure_identifier: str = f\"{descriptor_str}_preDelta\"\n",
    "    plt.figure(num=figure_identifier, clear=True, figsize=(6, 2))\n",
    "    for time_bin_size in time_bin_sizes:\n",
    "        df_tbs = pre_delta_df[pre_delta_df['time_bin_size']==time_bin_size]\n",
    "        df_tbs['P_Long'].hist(alpha=0.5, label=str(time_bin_size)) \n",
    "    \n",
    "    plt.title(f'{descriptor_str} - pre-$\\Delta$ time bins')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # plot post-delta histogram\n",
    "    time_bin_sizes = post_delta_df['time_bin_size'].unique()\n",
    "    figure_identifier: str = f\"{descriptor_str}_postDelta\"\n",
    "    plt.figure(num=figure_identifier, clear=True, figsize=(6, 2))\n",
    "    for time_bin_size in time_bin_sizes:\n",
    "        df_tbs = post_delta_df[post_delta_df['time_bin_size']==time_bin_size]\n",
    "        df_tbs['P_Long'].hist(alpha=0.5, label=str(time_bin_size)) \n",
    "    \n",
    "    plt.title(f'{descriptor_str} - post-$\\Delta$ time bins')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# # You can use it like this:\n",
    "# plot_histograms('Laps', 'All Sessions', all_sessions_laps_time_bin_df, \"75 ms\")\n",
    "# plot_histograms('Ripples', 'All Sessions', all_sessions_ripple_time_bin_df, \"75 ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd6f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from neuropy.utils.matplotlib_helpers import pho_jointplot\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import pho_jointplot\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# def pho_jointplot(*args, **kwargs):\n",
    "# \t\"\"\" wraps sns.jointplot to allow adding titles/axis labels/etc.\"\"\"\n",
    "# \ttitle = kwargs.pop('title', None)\n",
    "# \t_out = sns.jointplot(*args, **kwargs)\n",
    "# \tif title is not None:\n",
    "# \t\tplt.suptitle(title)\n",
    "# \treturn _out\n",
    "\n",
    "common_kwargs = dict(ylim=(0,1), hue='time_bin_size') # , marginal_kws=dict(bins=25, fill=True)\n",
    "# sns.jointplot(data=a_laps_all_epoch_bins_marginals_df, x='lap_start_t', y='P_Long', kind=\"scatter\", color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per epoch') #color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per epoch')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per time bin')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per time bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43311ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_histograms\n",
    "\n",
    "# You can use it like this:\n",
    "plot_histograms('Laps', 'One Session', several_time_bin_sizes_time_bin_laps_df, \"several\")\n",
    "plot_histograms('Ripples', 'One Session', several_time_bin_sizes_time_bin_ripple_df, \"several\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "several_time_bin_sizes_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(\n",
    "#     several_time_bin_sizes_laps_df, x=\"P_Long\", col=\"species\", row=\"time_bin_size\",\n",
    "#     binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    "# )\n",
    "\n",
    "sns.displot(\n",
    "    several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', row=\"time_bin_size\",\n",
    "    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be351c18",
   "metadata": {},
   "source": [
    "# 2024-01-31 - Reinvestigation regarding remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "911d7495",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncationCheckingResults(_VersionedResultMixin_version='2024.01.10_0', disappearing_endcap_aclus=Int64Index([15, 32], dtype='int64'), non_disappearing_endcap_aclus=Int64Index([4, 8, 9, 13, 19, 20, 21, 23, 33, 38, 41, 43, 50, 53, 54, 64, 68, 76, 79, 81, 84, 85, 94, 97], dtype='int64'), significant_distant_remapping_endcap_aclus=Int64Index([8, 9, 13, 19, 20, 23, 33, 38, 41, 43, 50, 54, 64, 76, 79, 84, 85, 94, 97], dtype='int64'), minor_remapping_endcap_aclus=Int64Index([4, 21, 53, 68, 81], dtype='int64'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## long_short_endcap_analysis:\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "truncation_checking_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d9b54",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "## From Jonathan Long/Short Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3641aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "neuron_replay_stats_df = deepcopy(jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "\n",
    "## try to add the 2D peak information to the cells in `neuron_replay_stats_df`:\n",
    "neuron_replay_stats_df['long_pf2D_peak_x'] = pd.NA\n",
    "neuron_replay_stats_df['short_pf2D_peak_x'] = pd.NA\n",
    "neuron_replay_stats_df['long_pf2D_peak_y'] = pd.NA\n",
    "neuron_replay_stats_df['short_pf2D_peak_y'] = pd.NA\n",
    "\n",
    "# flat_peaks_df: pd.DataFrame = deepcopy(active_peak_prominence_2d_results['flat_peaks_df']).reset_index(drop=True)\n",
    "long_filtered_flat_peaks_df: pd.DataFrame = deepcopy(curr_active_pipeline.computation_results[long_any_name].computed_data['RatemapPeaksAnalysis']['PeakProminence2D']['filtered_flat_peaks_df']).reset_index(drop=True)\n",
    "short_filtered_flat_peaks_df: pd.DataFrame = deepcopy(curr_active_pipeline.computation_results[short_any_name].computed_data['RatemapPeaksAnalysis']['PeakProminence2D']['filtered_flat_peaks_df']).reset_index(drop=True)\n",
    "\n",
    "neuron_replay_stats_df.loc[np.isin(neuron_replay_stats_df['aclu'].to_numpy(), long_filtered_flat_peaks_df.neuron_id.to_numpy()), ['long_pf2D_peak_x', 'long_pf2D_peak_y']] = long_filtered_flat_peaks_df[['peak_center_x', 'peak_center_y']].to_numpy()\n",
    "neuron_replay_stats_df.loc[np.isin(neuron_replay_stats_df['aclu'].to_numpy(), short_filtered_flat_peaks_df.neuron_id.to_numpy()), ['short_pf2D_peak_x', 'short_pf2D_peak_y']] = short_filtered_flat_peaks_df[['peak_center_x', 'peak_center_y']].to_numpy()\n",
    "\n",
    "both_included_neuron_stats_df = deepcopy(neuron_replay_stats_df[neuron_replay_stats_df['LS_pf_peak_x_diff'].notnull()]).drop(columns=['track_membership', 'neuron_type'])\n",
    "both_included_neuron_stats_df\n",
    "# both_included_neuron_stats_df['LS_pf_peak_x_diff'].plot()\n",
    "\n",
    "# both_included_neuron_stats_df['LS_pf_peak_x_diff'].plot()\n",
    "\n",
    "# _out_scatter = sns.scatterplot(both_included_neuron_stats_df, x='LS_pf_peak_x_diff', y='aclu') # , hue='aclu'\n",
    "# _out_scatter.show()\n",
    "# _out_hist = sns.histplot(both_included_neuron_stats_df, x='LS_pf_peak_x_diff', bins=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1325198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(jonathan_firing_rate_analysis_result) # pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.JonathanFiringRateAnalysisResult\n",
    "\n",
    "rdf_df: pd.DataFrame = deepcopy(jonathan_firing_rate_analysis_result.rdf.rdf)\n",
    "rdf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d371a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to JSON\n",
    "output_path = Path('output/rdf_df.json').resolve()\n",
    "rdf_df.to_json(output_path, orient='records', lines=True) ## This actually looks pretty good!\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b794a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_columns = ['start', 'end']\n",
    "invalid_columns = ['active_aclus', 'is_neuron_active', 'firing_rates']\n",
    "invalid_df_subset = rdf_df[join_columns + invalid_columns]\n",
    "invalid_df_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db8e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload DataFrame from JSON\n",
    "df_read: pd.DataFrame = pd.read_json(output_path, orient='records', lines=True)\n",
    "df_read\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6170689",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rdf_df.convert_dtypes().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429bb6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_df.dtypes\n",
    "\n",
    "# firing_rates                            object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b50ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf_aclus = both_included_neuron_stats_df.aclu[both_included_neuron_stats_df.has_long_pf].to_numpy()\n",
    "short_pf_aclus = both_included_neuron_stats_df.aclu[both_included_neuron_stats_df.has_short_pf].to_numpy()\n",
    "\n",
    "long_pf_aclus, short_pf_aclus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d18cfba",
   "metadata": {},
   "source": [
    "## 2024-02-06 - `directional_compute_trial_by_trial_correlation_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383e8ea",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent\n",
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "\n",
    "\n",
    "## INPUTS: curr_active_pipeline, track_templates, global_epoch_name, (long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj)\n",
    "any_decoder_neuron_IDs = deepcopy(track_templates.any_decoder_neuron_IDs)\n",
    "any_decoder_neuron_IDs\n",
    "\n",
    "# track_templates.shared_LR_aclus_only_neuron_IDs\n",
    "# track_templates.shared_RL_aclus_only_neuron_IDs\n",
    "\n",
    "## Directional Trial-by-Trial Activity:\n",
    "if 'pf1D_dt' not in curr_active_pipeline.computation_results[global_epoch_name].computed_data:\n",
    "\t# if `KeyError: 'pf1D_dt'` recompute\n",
    "\tcurr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['pfdt_computation'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "active_pf_1D_dt: PfND_TimeDependent = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf1D_dt'])\n",
    "active_pf_2D_dt: PfND_TimeDependent = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf2D_dt'])\n",
    "\n",
    "active_pf_dt: PfND_TimeDependent = deepcopy(active_pf_1D_dt)\n",
    "# active_pf_dt.res\n",
    "# Limit only to the placefield aclus:\n",
    "active_pf_dt = active_pf_dt.get_by_id(ids=any_decoder_neuron_IDs)\n",
    "\n",
    "# active_pf_dt: PfND_TimeDependent = deepcopy(active_pf_2D_dt) # 2D\n",
    "long_LR_name, long_RL_name, short_LR_name, short_RL_name = track_templates.get_decoder_names()\n",
    "\n",
    "directional_lap_epochs_dict = dict(zip((long_LR_name, long_RL_name, short_LR_name, short_RL_name), (long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj)))\n",
    "directional_active_lap_pf_results_dicts: Dict[str, TrialByTrialActivity] = TrialByTrialActivity.directional_compute_trial_by_trial_correlation_matrix(active_pf_dt=active_pf_dt, directional_lap_epochs_dict=directional_lap_epochs_dict, included_neuron_IDs=any_decoder_neuron_IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c34fd9",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "# 2024-04-09 - Maximum peaks only for each template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbcdfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import NumpyHelpers\n",
    "from neuropy.utils.indexing_helpers import intersection_of_arrays, union_of_arrays\n",
    "from neuropy.utils.indexing_helpers import unwrap_single_item\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing import NewType\n",
    "from typing_extensions import TypeAlias\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "DecoderName = NewType('DecoderName', str)\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "\n",
    "# from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _get_directional_pf_peaks_dfs\n",
    "\n",
    "# (LR_only_decoder_aclu_MAX_peak_maps_df, RL_only_decoder_aclu_MAX_peak_maps_df), AnyDir_decoder_aclu_MAX_peak_maps_df = _get_directional_pf_peaks_dfs(track_templates, drop_aclu_if_missing_long_or_short=False)\n",
    "\n",
    "(LR_only_decoder_aclu_MAX_peak_maps_df, RL_only_decoder_aclu_MAX_peak_maps_df), AnyDir_decoder_aclu_MAX_peak_maps_df = track_templates.get_directional_pf_maximum_peaks_dfs(drop_aclu_if_missing_long_or_short=False)\n",
    "\n",
    "\n",
    "AnyDir_decoder_aclu_MAX_peak_maps_df\n",
    "# LR_only_decoder_aclu_MAX_peak_maps_df\n",
    "# RL_only_decoder_aclu_MAX_peak_maps_df\n",
    "\n",
    "long_peak_x = LR_only_decoder_aclu_MAX_peak_maps_df['long_LR'].to_numpy()\n",
    "short_peak_x = LR_only_decoder_aclu_MAX_peak_maps_df['short_LR'].to_numpy()\n",
    "peak_x_diff = LR_only_decoder_aclu_MAX_peak_maps_df['peak_diff'].to_numpy()\n",
    "# decoder_aclu_peak_maps_dict\n",
    "\n",
    "## OUTPUTS: AnyDir_decoder_aclu_MAX_peak_maps_df,\n",
    "## OUTPUTS: LR_only_decoder_aclu_MAX_peak_maps_df, long_peak_x, long_peak_x, peak_x_diff\n",
    "## OUTPUTS: RL_only_decoder_aclu_MAX_peak_maps_df, long_peak_x, long_peak_x, peak_x_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03fe1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_track_remapping_diagram(track_templates, grid_bin_bounds, active_context=None, perform_write_to_file_callback=None, defer_render: bool=False, **kwargs):    \n",
    "    \"\"\" Based off of `plot_bidirectional_track_remapping_diagram`\n",
    "    Usage:\n",
    "    \n",
    "        from pyphoplacecellanalysis.Pho2D.track_shape_drawing import plot_bidirectional_track_remapping_diagram\n",
    "\n",
    "        collector = plot_combined_track_remapping_diagram(track_templates, grid_bin_bounds=long_pf2D.config.grid_bin_bounds, active_context=curr_active_pipeline.build_display_context_for_session(display_fn_name='plot_bidirectional_track_remapping_diagram'))\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.pyplot as plt\n",
    "    from flexitext import flexitext ## flexitext for formatted matplotlib text\n",
    "\n",
    "    from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import FigureCollector\n",
    "    from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import PlottingHelpers\n",
    "    from neuropy.utils.matplotlib_helpers import FormattedFigureText\n",
    "\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "    from neuropy.utils.matplotlib_helpers import build_or_reuse_figure, perform_update_title_subtitle\n",
    "    from pyphoplacecellanalysis.Pho2D.track_shape_drawing import _plot_track_remapping_diagram\n",
    "\n",
    "    use_separate_plot_for_each_direction: bool = True\n",
    "\n",
    "    if active_context is not None:\n",
    "            display_context = active_context.adding_context('display_fn', display_fn_name='bidir_track_remap')\n",
    "        \n",
    "    with mpl.rc_context({'figure.figsize': (10, 4), 'figure.dpi': '220', 'savefig.transparent': True, 'ps.fonttype': 42, }):\n",
    "        # Create a FigureCollector instance\n",
    "        with FigureCollector(name='plot_bidirectional_track_remapping_diagram', base_context=display_context) as collector:\n",
    "\n",
    "            ## Define common operations to do after making the figure:\n",
    "            def setup_common_after_creation(a_collector, fig, axes, sub_context, title=f'<size:22>Track <weight:bold>Remapping</></>'):\n",
    "                \"\"\" Captures:\n",
    "\n",
    "                t_split\n",
    "                \"\"\"\n",
    "                a_collector.contexts.append(sub_context)\n",
    "                \n",
    "                # `flexitext` version:\n",
    "                text_formatter = FormattedFigureText()\n",
    "                # ax.set_title('')\n",
    "                fig.suptitle('')\n",
    "                text_formatter.setup_margins(fig)\n",
    "                title_text_obj = flexitext(text_formatter.left_margin, text_formatter.top_margin,\n",
    "                                        title,\n",
    "                                        va=\"bottom\", xycoords=\"figure fraction\")\n",
    "                footer_text_obj = flexitext((text_formatter.left_margin * 0.1), (text_formatter.bottom_margin * 0.25),\n",
    "                                            text_formatter._build_footer_string(active_context=sub_context),\n",
    "                                            va=\"top\", xycoords=\"figure fraction\")\n",
    "            \n",
    "                if ((perform_write_to_file_callback is not None) and (sub_context is not None)):\n",
    "                    perform_write_to_file_callback(sub_context, fig)\n",
    "\n",
    "\n",
    "            # BEGIN FUNCTION BODY\n",
    "            drop_aclu_if_missing_long_or_short=True\n",
    "            # LR_only_decoder_aclu_MAX_peak_maps_df, RL_only_decoder_aclu_MAX_peak_maps_df = _get_directional_pf_peaks_dfs(track_templates, drop_aclu_if_missing_long_or_short=drop_aclu_if_missing_long_or_short)\n",
    "            # drop_aclu_if_missing_long_or_short =False\n",
    "            (LR_only_decoder_aclu_MAX_peak_maps_df, RL_only_decoder_aclu_MAX_peak_maps_df), AnyDir_decoder_aclu_MAX_peak_maps_df = track_templates.get_directional_pf_maximum_peaks_dfs(drop_aclu_if_missing_long_or_short=drop_aclu_if_missing_long_or_short)\n",
    "\n",
    "            ## Make a single figure for both LR/RL remapping cells:\n",
    "            # kwargs = dict(draw_point_aclu_labels=True, enable_interactivity=True)\n",
    "            kwargs = dict(draw_point_aclu_labels=True, enable_interactivity=False)\n",
    "\n",
    "            if use_separate_plot_for_each_direction:\n",
    "                fig, axs = collector.subplots(nrows=2, ncols=1, sharex=True, sharey=True, num='Track Remapping', figsize=kwargs.pop('figsize', (10, 4)), dpi=kwargs.pop('dpi', None), constrained_layout=True, clear=True)\n",
    "                assert len(axs) == 2, f\"{len(axs)}\"\n",
    "                ax_dict = {'ax_LR': axs[0], 'ax_RL': axs[1]}\n",
    "\n",
    "                fig, ax_LR, _outputs_tuple_LR = _plot_track_remapping_diagram(LR_only_decoder_aclu_MAX_peak_maps_df, grid_bin_bounds=grid_bin_bounds, long_column_name='long_LR', short_column_name='short_LR', ax=ax_dict['ax_LR'], defer_render=defer_render, **kwargs)\n",
    "                perform_update_title_subtitle(fig=fig, ax=ax_LR, title_string=None, subtitle_string=f\"LR Track Remapping - {len(LR_only_decoder_aclu_MAX_peak_maps_df)} aclus\")\n",
    "                fig, ax_RL, _outputs_tuple_RL = _plot_track_remapping_diagram(RL_only_decoder_aclu_MAX_peak_maps_df, grid_bin_bounds=grid_bin_bounds, long_column_name='long_RL', short_column_name='short_RL', ax=ax_dict['ax_RL'], defer_render=defer_render, **kwargs)\n",
    "                perform_update_title_subtitle(fig=fig, ax=ax_RL, title_string=None, subtitle_string=f\"RL Track Remapping - {len(RL_only_decoder_aclu_MAX_peak_maps_df)} aclus\")\n",
    "\n",
    "                setup_common_after_creation(collector, fig=fig, axes=[ax_LR, ax_RL], sub_context=display_context.adding_context('subplot', subplot_name='Track Remapping'))\n",
    "            else:\n",
    "                fig, axs = collector.subplots(nrows=1, ncols=1, sharex=True, sharey=True, num='Track Remapping', figsize=kwargs.pop('figsize', (10, 4)), dpi=kwargs.pop('dpi', None), constrained_layout=True, clear=True)\n",
    "                # assert len(axs) == 1, f\"{len(axs)}\"\n",
    "                ax = axs\n",
    "\n",
    "                fig, ax, _outputs_tuple = _plot_track_remapping_diagram(AnyDir_decoder_aclu_MAX_peak_maps_df, grid_bin_bounds=grid_bin_bounds, long_column_name='long_LR', short_column_name='short_LR', ax=ax, defer_render=defer_render, **kwargs)\n",
    "                perform_update_title_subtitle(fig=fig, ax=ax, title_string=None, subtitle_string=f\"LR+RL Track Remapping - {len(LR_only_decoder_aclu_MAX_peak_maps_df)} aclus\")\n",
    "\n",
    "                setup_common_after_creation(collector, fig=fig, axes=[ax, ], sub_context=display_context.adding_context('subplot', subplot_name='Track Remapping'))\n",
    "\n",
    "\n",
    "    return collector\n",
    "\n",
    "\n",
    "collector = plot_combined_track_remapping_diagram(track_templates, grid_bin_bounds=long_pf2D.config.grid_bin_bounds, active_context=curr_active_pipeline.build_display_context_for_session(display_fn_name='plot_bidirectional_track_remapping_diagram'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.color_helpers import ColorFormatConverter, build_adjusted_color, debug_print_color\n",
    "\n",
    "selection_color = (1, 0, 0, 1)  # Red color in RGBA format\n",
    "\n",
    "\n",
    "# pg.QtGui.QColor(selection_color)\n",
    "selection_qcolor = pg.mkColor(*selection_color[:-1])\n",
    "selection_qcolor.setAlphaF(selection_color[-1])\n",
    "\n",
    "ColorFormatConverter.qColor_to_hexstring(qcolor=selection_qcolor, include_alpha=True)\n",
    "\n",
    "\n",
    "debug_print_color(selection_qcolor)\n",
    "curr_color_copy = build_adjusted_color(selection_qcolor, hue_shift=0.0, saturation_scale=1.00, value_scale=0.35) # darker\n",
    "debug_print_color(curr_color_copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba55093",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OLD METHOD:\n",
    "decoder_aclu_peak_location_df_merged = deepcopy(track_templates.get_decoders_aclu_peak_location_df(width=None)).drop(columns=['series_idx', 'LR_peak_diff', 'RL_peak_diff'])\n",
    "# decoder_aclu_peak_location_df_merged[np.isin(decoder_aclu_peak_location_df_merged['aclu'], both_included_neuron_stats_df.aclu.to_numpy())]\n",
    "decoder_aclu_peak_location_df_merged\n",
    "\n",
    "## OUTPUTS: directional_lap_epochs_dict, directional_active_lap_pf_results_dicts: Dict[str, TrialByTrialActivity], decoder_aclu_peak_location_df_merged\n",
    "## INPUTS: decoder_aclu_peak_location_df_merged\n",
    "decoder_aclu_MAX_peak_location_df_merged: pd.DataFrame = decoder_aclu_peak_location_df_merged[decoder_aclu_peak_location_df_merged['subpeak_idx'] == 0].drop(columns=['subpeak_idx']).reset_index(drop=True)\n",
    "decoder_aclu_MAX_peak_location_df_merged\n",
    "# decoder_aclu_MAX_peak_location_df_merged.columns # ['aclu', 'subpeak_idx', 'long_LR_peak', 'long_RL_peak', 'short_LR_peak', 'short_RL_peak', 'long_LR_peak_height', 'long_RL_peak_height', 'short_LR_peak_height', 'short_RL_peak_height', 'LR_peak_diff', 'RL_peak_diff']\n",
    "\n",
    "old_method_unique_aclus = np.unique(decoder_aclu_MAX_peak_location_df_merged.aclu)\n",
    "old_method_unique_aclus\n",
    "len(old_method_unique_aclus)\n",
    "\n",
    "\n",
    "common_drop_column_names = ['subpeak_idx', 'LR_peak_diff', 'RL_peak_diff']\n",
    "RL_column_names = [col for col in list(decoder_aclu_MAX_peak_location_df_merged.columns) if (str(col).find('RL_') != -1)] # ['long_RL_peak', 'short_RL_peak', 'long_RL_peak_height', 'short_RL_peak_height', 'RL_peak_diff']\n",
    "LR_column_names = [col for col in list(decoder_aclu_MAX_peak_location_df_merged.columns) if (str(col).find('LR_') != -1)] # ['long_LR_peak', 'short_LR_peak', 'long_LR_peak_height', 'short_LR_peak_height', 'LR_peak_diff']\n",
    "\n",
    "LR_only_decoder_aclu_MAX_peak_location_df_merged: pd.DataFrame = decoder_aclu_MAX_peak_location_df_merged.drop(columns=(RL_column_names+common_drop_column_names), inplace=False, errors='ignore').dropna(axis='index')\n",
    "LR_only_decoder_aclu_MAX_peak_location_df_merged\n",
    "\n",
    "RL_only_decoder_aclu_MAX_peak_location_df_merged: pd.DataFrame = decoder_aclu_MAX_peak_location_df_merged.drop(columns=(LR_column_names+common_drop_column_names), inplace=False, errors='ignore').dropna(axis='index')\n",
    "RL_only_decoder_aclu_MAX_peak_location_df_merged\n",
    "\n",
    "\n",
    "## OUTPUTS: decoder_aclu_MAX_peak_location_df_merged, LR_only_decoder_aclu_MAX_peak_location_df_merged, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximal_peak_only_decoder_aclu_peak_location_df_merged = deepcopy(decoder_aclu_peak_location_df_merged)[decoder_aclu_peak_location_df_merged['long_LR_peak_height'] == 1.0]\n",
    "\n",
    "LR_height_column_names = ['long_LR_peak_height', 'short_LR_peak_height']\n",
    "\n",
    "# [decoder_aclu_peak_location_df_merged[a_name] == 1.0 for a_name in LR_height_column_names]\n",
    "\n",
    "LR_max_peak_dfs = [deepcopy(decoder_aclu_peak_location_df_merged)[decoder_aclu_peak_location_df_merged[a_name] == 1.0].drop(columns=['subpeak_idx', 'series_idx', 'LR_peak_diff', 'RL_peak_diff', a_name], errors='ignore') for a_name in LR_height_column_names]\n",
    "\n",
    "aclus_with_LR_peaks = intersection_of_arrays(*[a_df.aclu.unique() for a_df in LR_max_peak_dfs])\n",
    "aclus_with_LR_peaks\n",
    "\n",
    "\n",
    "## Align them now:\n",
    "LR_max_peak_dfs = [a_df[a_df.aclu.isin(aclus_with_LR_peaks)] for a_df in LR_max_peak_dfs]\n",
    "LR_max_peak_dfs\n",
    "\n",
    "# aclus_with_LR_peaks = aclu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4643d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Explore all subpeaks interactively via a slider:\n",
    "\n",
    "# decoder_aclu_peak_location_df_merged\n",
    "\n",
    "valid_aclus = deepcopy(decoder_aclu_peak_location_df_merged.aclu.unique())\n",
    "peaks_df_subset: pd.DataFrame = decoder_aclu_peak_location_df_merged.copy()\n",
    "\n",
    "# active_IDX = 1\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def integer_slider(update_func):\n",
    "    \"\"\" Captures: valid_aclus\n",
    "    \"\"\"\n",
    "    slider = widgets.IntSlider(description='cell_IDX:', min=0, max=len(valid_aclus)-1, value=0)\n",
    "    def on_slider_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            # Call the user-provided update function with the current slider index\n",
    "            update_func(change['new'])\n",
    "    slider.observe(on_slider_change)\n",
    "    display(slider)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def update_function(index):\n",
    "    \"\"\" Define an update function that will be called with the current slider index \n",
    "    Captures decoder_aclu_peak_location_df_merged, valid_aclus\n",
    "    \"\"\"\n",
    "    global peaks_df_subset\n",
    "    print(f'Slider index: {index}')\n",
    "    active_aclu = int(valid_aclus[int(index)])\n",
    "    peaks_df_subset = decoder_aclu_peak_location_df_merged[decoder_aclu_peak_location_df_merged.aclu == active_aclu].copy()\n",
    "    display(peaks_df_subset)\n",
    "\n",
    "\n",
    "# timebinned_neuron_info = long_results_obj.timebinned_neuron_info\n",
    "# active_fig_obj, update_function = DiagnosticDistanceMetricFigure.build_interactive_diagnostic_distance_metric_figure(long_results_obj, timebinned_neuron_info, result)\n",
    "\n",
    "\n",
    "# Call the integer_slider function with the update function\n",
    "integer_slider(update_function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5583584",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_df_subset[['long_LR_peak', 'short_LR_peak']]\n",
    "peaks_df_subset[['long_LR_peak_height', 'short_LR_peak_height']]\n",
    "peaks_df_subset['LR_peak_diff']\n",
    "\n",
    "\n",
    "## #TODO 2024-02-16 06:50: - [ ] ERROR discovered in `decoder_aclu_peak_location_df_merged` - the columns 'LR_peak_diff', 'RL_peak_diff' are incorrect as they aren't comparing the maximum peak (supposed to be at `subpeak_idx == 0`, but better given by `height == 1.0`) of long decoder to maximum peak of short. The comparison logic is wrong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximal_peak_only_decoder_aclu_peak_location_df_merged = deepcopy(decoder_aclu_peak_location_df_merged)[decoder_aclu_peak_location_df_merged[LR_height_column_names] == 1.0]\n",
    "maximal_peak_only_decoder_aclu_peak_location_df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604b90dc",
   "metadata": {},
   "source": [
    "## 2024-02-08 - Filter to find only the clear remap examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "from pyphocorehelpers.indexing_helpers import dict_to_full_array\n",
    "\n",
    "any_decoder_neuron_IDs = deepcopy(track_templates.any_decoder_neuron_IDs)\n",
    "any_decoder_neuron_IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0cf56",
   "metadata": {},
   "source": [
    "### Get num peaks exclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c849dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: `directional_active_lap_pf_results_dicts`, not sure why\n",
    "\n",
    "neuron_ids_dict = {k:v.neuron_ids for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "neuron_ids_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec42a8d",
   "metadata": {},
   "source": [
    "### Get stability for each cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ec2d7",
   "metadata": {},
   "source": [
    "#### 2024-02-08 - 3pm - new stability dataframe to look at stability of each cell across decoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57869e27",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# for k,v in directional_active_lap_pf_results_dicts.items():\n",
    "# stability_dict = {k:v.aclu_to_stability_score_dict for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "# stability_dict = {k:dict_to_full_array(v.aclu_to_stability_score_dict, full_indicies=any_decoder_neuron_IDs, fill_value=0.0) for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "# stability_dict\n",
    "\n",
    "\n",
    "# list(stability_dict.values())\n",
    "\n",
    "stability_dict = {k:list(v.aclu_to_stability_score_dict.values()) for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "# stability_dict\n",
    "## all the same size hopefully!\n",
    "# [len(v) for v in list(stability_dict.values())]\n",
    "\n",
    "stability_df: pd.DataFrame = pd.DataFrame({'aclu': any_decoder_neuron_IDs, **stability_dict})\n",
    "# stability_df.rename(dict(zip([], [])))\n",
    "stability_df\n",
    "\n",
    "## OUTPUTS: stability_df, stability_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef13541",
   "metadata": {},
   "source": [
    "# 2024-02-02 - napari_plot_directional_trial_by_trial_activity_viz Trial-by-trial Correlation Matrix C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddd735e",
   "metadata": {},
   "source": [
    "### 🎨 Show Trial-by-trial Correlation Matrix C in `napari`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad72df59",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import napari\n",
    "# import afinder\n",
    "from pyphoplacecellanalysis.GUI.Napari.napari_helpers import napari_plot_directional_trial_by_trial_activity_viz, napari_trial_by_trial_activity_viz, napari_export_image_sequence\n",
    "\n",
    "## Directional\n",
    "directional_viewer, directional_image_layer_dict, custom_direction_split_layers_dict = napari_plot_directional_trial_by_trial_activity_viz(directional_active_lap_pf_results_dicts, include_trial_by_trial_correlation_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9934d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global:\n",
    "viewer, image_layer_dict = napari_trial_by_trial_activity_viz(z_scored_tuning_map_matrix, C_trial_by_trial_correlation_matrix, title='Trial-by-trial Correlation Matrix C', axis_labels=('aclu', 'lap', 'xbin')) # GLOBAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b4ec86",
   "metadata": {},
   "source": [
    "# 2023-09-07 - Track Graphics Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07993325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.placefields import compute_grid_bin_bounds\n",
    "from pyphocorehelpers.geometry_helpers import map_value\n",
    "\n",
    "pos_df = deepcopy(global_session.position).to_dataframe()\n",
    "# xlinear = deepcopy(global_session.position.linear_pos_obj.x)\n",
    "xlinear = deepcopy(global_session.position.to_dataframe()['lin_pos'].to_numpy())\n",
    "# xlinear = -1.0 * xlinear # flip over the y-axis first\n",
    "lin_pos_bounds = compute_grid_bin_bounds(xlinear)[0]\n",
    "x_bounds = compute_grid_bin_bounds(pos_df['x'].to_numpy())[0]\n",
    "print(f'lin_pos_bounds: {lin_pos_bounds}, x_bounds: {x_bounds}')\n",
    "xlinear = map_value(xlinear, lin_pos_bounds, x_bounds) # map xlinear from its current bounds range to the xbounds range\n",
    "\n",
    "## Confirmed they match: lin_pos_bounds: (20.53900014070859, 260.280278480539), x_bounds: (20.53900014070859, 260.280278480539)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b53254",
   "metadata": {},
   "source": [
    "## 🟢🟢🔝🖼️🎨 2024-02-16 - NOW - Working Track Remapping Diagram Figure!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import plot_bidirectional_track_remapping_diagram, _plot_track_remapping_diagram\n",
    "\n",
    "collector = plot_bidirectional_track_remapping_diagram(track_templates, grid_bin_bounds=long_pf2D.config.grid_bin_bounds, active_context=curr_active_pipeline.build_display_context_for_session(display_fn_name='plot_bidirectional_track_remapping_diagram'), enable_adjust_overlapping_text=False, draw_point_aclu_labels=False, enable_interactivity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d1e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "curr_active_pipeline.display('_display_directional_track_remapping_diagram', save_figure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a9a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS:\n",
    "neuron_replay_stats_df\n",
    "\n",
    "_active_LR_aclus = np.array(list(_output_by_aclu_dict_LR.keys()))\n",
    "_active_LR_aclus\n",
    "\n",
    "is_active_LR_aclus = np.isin(neuron_replay_stats_df.aclu, _active_LR_aclus)\n",
    "_temp_neuron_replay_stats_df = neuron_replay_stats_df[is_active_LR_aclus]\n",
    "\n",
    "is_active_LR_long_peak_either_cap_dict = _temp_neuron_replay_stats_df['is_long_peak_either_cap'].to_dict()\n",
    "is_active_LR_long_peak_either_cap_dict\n",
    "\n",
    "\n",
    "# either_cap_aclu = {k:v for k,v in is_active_LR_long_peak_either_cap_dict.items() if (v is True)}\n",
    "\n",
    "active_LR_either_cap_aclus = np.array([k for k,v in is_active_LR_long_peak_either_cap_dict.items() if (v is True)])\n",
    "active_LR_either_cap_aclus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dac9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Selected ACLUS manually:\n",
    "\n",
    "## `FakePickEvent` is used to highlight specified aclus by emulating a selection event.\n",
    "#  matplotlib.backend_bases.PickEvent\n",
    "import attrs\n",
    "FakePickEvent = attrs.make_class(\"FakePickEvent\", {k:field() for k in (\"ind\", )})\n",
    "\n",
    "included_aclus = [45, 24, 17, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1689f191",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: included_aclus, LR_only_decoder_aclu_MAX_peak_maps_df, RL_only_decoder_aclu_MAX_peak_maps_df, _outputs_tuple_LR, _outputs_tuple_RL\n",
    "included_aclus = active_LR_either_cap_aclus\n",
    "# LR:\n",
    "LR_included_indicies = np.where(np.isin(LR_only_decoder_aclu_MAX_peak_maps_df.index, included_aclus))[0] # LR_included_indicies # [ 6,  9, 22, 36]\n",
    "LR_fake_event: FakePickEvent = FakePickEvent(ind=np.array(LR_included_indicies))\n",
    "_output_dict_LR, _output_by_aclu_dict_LR = _outputs_tuple_LR\n",
    "scatter_select_function_LR = _output_dict_LR['scatter_select_function']\n",
    "scatter_select_function_LR(LR_fake_event)\n",
    "\n",
    "## RL:\n",
    "RL_included_indicies = np.where(np.isin(RL_only_decoder_aclu_MAX_peak_maps_df.index, included_aclus))[0]\n",
    "RL_fake_event: FakePickEvent = FakePickEvent(ind=np.array(RL_included_indicies))\n",
    "_output_dict_RL, _output_by_aclu_dict_RL = _outputs_tuple_RL\n",
    "scatter_select_function_RL = _output_dict_RL['scatter_select_function']\n",
    "scatter_select_function_RL(RL_fake_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6fcb1",
   "metadata": {},
   "source": [
    "# 🎨 2024-02-06 - Other Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5623a2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "\n",
    "#  Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "curr_active_pipeline.prepare_for_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2fa1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _directional_laps_overview = curr_active_pipeline.plot._display_directional_laps_overview(curr_active_pipeline.computation_results, a)\n",
    "# _directional_laps_overview = curr_active_pipeline.display('_display_directional_laps_overview')\n",
    "# _directional_laps_overview = curr_active_pipeline.display('_display_grid_bin_bounds_validation')\n",
    "_directional_laps_overview = curr_active_pipeline.display('_display_long_short_pf1D_comparison')\n",
    "\n",
    "_directional_laps_overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e0072",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea83decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea764b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.MainApplicationWindows.LauncherWidget.LauncherWidget import LauncherWidget\n",
    "\n",
    "widget = LauncherWidget()\n",
    "treeWidget = widget.mainTreeWidget # QTreeWidget\n",
    "widget.build_for_pipeline(curr_active_pipeline=curr_active_pipeline)\n",
    "widget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_fcn = widget._perform_get_display_function_code(a_fcn_name='_display_two_step_decoder_prediction_error_2D')\n",
    "print(str(curr_fcn.__code__.co_varnames))\n",
    "fcn_defn_str: str = inspect.getsource(curr_fcn)\n",
    "print(fcn_defn_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc3078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out_graphics_dict = curr_active_pipeline.display('_display_two_step_decoder_prediction_error_2D', 'maze_any') # 'maze_any'\n",
    "\n",
    "update_fn = _out_graphics_dict.plot_data['draw_update_fn']\n",
    "num_frames = _out_graphics_dict.plot_data['num_frames']\n",
    "\n",
    "print(f'num_frames: {num_frames}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b374e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "all_save_paths = {}\n",
    "\n",
    "ani = animation.FuncAnimation(_out_graphics_dict.figures[0], update_fn, frames=num_frames, blit=False, repeat=False, interval=20, save_count=50)\n",
    "\n",
    "# ani.to_html5_video()\n",
    "\n",
    "# # To save the animation using Pillow as a gif\n",
    "# _temp_gif_save_path = Path('scatter.gif').resolve()\n",
    "# writer = animation.PillowWriter(fps=15, metadata=dict(artist='Pho Hale'), bitrate=1800)\n",
    "# ani.save(_temp_gif_save_path, writer=writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f69ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.pause()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c2cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.show()\n",
    "\n",
    "# # Save the animation to a BytesIO buffer\n",
    "# buf = io.BytesIO()\n",
    "# ani.save(buf, codec='gif', writer='imagemagick', fps=10)\n",
    "# buf.seek(0)\n",
    "\n",
    "# # Display the GIF\n",
    "# display(Image(data=buf.getvalue(), format='gif'))\n",
    "# Display the GIF\n",
    "# assert _temp_gif_save_path.exists()\n",
    "# Image(_temp_gif_save_path)\n",
    "\n",
    "\n",
    "# for i in np.arange(num_frames):\n",
    "#     update_fn(i) ## Adjust the slider, using its callbacks as well to update the displayed epoch.\n",
    "    \n",
    "#     # _out_rank_order_event_raster_debugger.on_update_epoch_IDX(an_epoch_idx=i)\n",
    "#     active_epoch_label = self.active_epoch_label\n",
    "\n",
    "#     save_paths = []\n",
    "\n",
    "#     for a_decoder, a_plot in self.root_plots_dict.items():\n",
    "#         curr_filename_prefix = f'Epoch{active_epoch_label}_{a_decoder}'\n",
    "#         # a_plot.setYRange(-0.5, float(self.max_n_neurons))\n",
    "#         out_path = export_path.joinpath(f'{curr_filename_prefix}_plot.png').resolve()\n",
    "#         export_pyqtgraph_plot(a_plot, savepath=out_path, background=pg.mkColor(0, 0, 0, 0))\n",
    "#         save_paths.append(out_path)\n",
    "\n",
    "#     all_save_paths[active_epoch_label] = save_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77194b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bbd956",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_display_long_short_laps', '_display_long_short_pf1D_comparison', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b267e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_display_two_step_decoder_prediction_error_2D'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8adcd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import Image, display\n",
    "import io\n",
    "from pyphocorehelpers.plotting.media_output_helpers import fig_to_clipboard\n",
    "\n",
    "\n",
    "# Generate the frames for the animation\n",
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "line, = ax.plot(x, np.sin(x))\n",
    "\n",
    "def update(frame):\n",
    "    line.set_ydata(np.sin(x + frame / 10.0))\n",
    "    return line,\n",
    "\n",
    "frames = len(x) - 1\n",
    "ani = animation.FuncAnimation(fig, update, frames=frames, blit=True, repeat=True, interval=50)\n",
    "\n",
    "# To save the animation using Pillow as a gif\n",
    "_temp_gif_save_path = Path('scatter.gif').resolve()\n",
    "writer = animation.PillowWriter(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "ani.save(_temp_gif_save_path, writer=writer)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# # Save the animation to a BytesIO buffer\n",
    "# buf = io.BytesIO()\n",
    "# ani.save(buf, codec='gif', writer='imagemagick', fps=10)\n",
    "# buf.seek(0)\n",
    "\n",
    "# # Display the GIF\n",
    "# display(Image(data=buf.getvalue(), format='gif'))\n",
    "# Display the GIF\n",
    "assert _temp_gif_save_path.exists()\n",
    "Image(_temp_gif_save_path)\n",
    "\n",
    "\n",
    "# fig_to_clipboard(fig, format='gif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7be129",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_long_short_laps')\n",
    "graphics_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedac3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['axs'], graphics_output_dict['plot_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_grid_bin_bounds_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68008d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_long_short_laps()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685113bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "# active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\n",
    "\n",
    "_out_graphics_dict = curr_active_pipeline.display('_display_spike_rasters_pyqtplot_2D', 'maze_any') # 'maze_any'\n",
    "assert isinstance(_out_graphics_dict, dict)\n",
    "active_2d_plot, active_3d_plot, spike_raster_window = _out_graphics_dict['spike_raster_plt_2d'], _out_graphics_dict['spike_raster_plt_3d'], _out_graphics_dict['spike_raster_window']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.SessionEpochs']\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5650ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(add_renderables_menu.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a83aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('add_renderables_menu', add_renderables_menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfbad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d_interactive_tuning_curves_plotter\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "active_config_modifiying_kwargs = {\n",
    "    'plotting_config': {'should_use_linear_track_geometry': True, \n",
    "                        't_start': t_start, 't_delta': t_delta, 't_end': t_end,\n",
    "                        }\n",
    "}\n",
    "_out_graphics_dict = curr_active_pipeline.display('_display_3d_interactive_tuning_curves_plotter', active_session_configuration_context=global_epoch_context,\n",
    "                                            active_config_modifiying_kwargs=active_config_modifiying_kwargs,\n",
    "                                            params_kwargs=dict(should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                           )\n",
    "ipcDataExplorer = _out_graphics_dict['ipcDataExplorer'] # InteractivePlaceCellTuningCurvesDataExplorer \n",
    "p = _out_graphics_dict['plotter']\n",
    "pane = _out_graphics_dict['pane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=global_epoch_context) # , computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.025}]\n",
    "ipspikesDataExplorer = _out['ipspikesDataExplorer']\n",
    "p = _out['plotter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "iplapsDataExplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "\n",
    "an_image_file_path = Path('an_image.png').resolve()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_image_plotter', active_session_configuration_context=global_epoch_context, image_file=an_image_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ce93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_config in curr_active_pipeline.active_configs.items():\n",
    "    print(f'a_config.plotting_config.should_use_linear_track_geometry: {a_config.plotting_config.should_use_linear_track_geometry}')\n",
    "    a_config.plotting_config.should_use_linear_track_geometry = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d560b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "\n",
    "\n",
    "_out = TemplateDebugger.init_templates_debugger(track_templates) # , included_any_context_neuron_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1323cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "\n",
    "\n",
    "_out = batch_perform_all_plots(curr_active_pipeline=curr_active_pipeline, enable_neptune=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 2D matrix\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import pv\n",
    "\n",
    "matrix = np.random.rand(10, 10)\n",
    "\n",
    "# Coordinates\n",
    "x, y = np.meshgrid(np.arange(matrix.shape[1]), np.arange(matrix.shape[0]))\n",
    "z = matrix.flatten()\n",
    "\n",
    "# Colors based on recency of updates (for example purposes, random values)\n",
    "colors = np.random.rand(matrix.size)\n",
    "\n",
    "# Create the plotter\n",
    "plotter = pv.Plotter()\n",
    "\n",
    "# Add points (dots)\n",
    "points = np.column_stack((x.flatten(), y.flatten(), z))\n",
    "point_cloud = pv.PolyData(points)\n",
    "point_cloud['colors'] = colors\n",
    "plotter.add_mesh(point_cloud, render_points_as_spheres=True, point_size=10, scalars='colors', cmap='viridis')\n",
    "\n",
    "# Add stems\n",
    "for i in range(len(z)):\n",
    "    line = pv.Line([x.flatten()[i], y.flatten()[i], 0], [x.flatten()[i], y.flatten()[i], z[i]])\n",
    "    plotter.add_mesh(line, color='black')\n",
    "\n",
    "# Show plot\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23611eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot.display_function_items\n",
    "\n",
    "# '_display_directional_template_debugger'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "directional_laps_overview = curr_active_pipeline.display(display_function='_display_directional_laps_overview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36ee6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_pic_placefields = curr_active_pipeline.display('_display_1d_placefields', long_LR_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_pic_placefields_short_LR = curr_active_pipeline.display('_display_1d_placefields', short_LR_context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c334080",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eafe14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f93040",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3285686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_display_directional_laps_overview'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd15f5",
   "metadata": {},
   "source": [
    "# 🎨 2024-04-23 - 3D Posterior Plot\n",
    "<!-- t_delta -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba7ac95",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer\n",
    "\n",
    "curr_active_pipeline.prepare_for_display()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_interactive_custom_data_explorer', active_session_configuration_context=global_epoch_context,\n",
    "                                    params_kwargs=dict(should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                    )\n",
    "iplapsDataExplorer: InteractiveCustomDataExplorer = _out['iplapsDataExplorer']\n",
    "pActiveInteractiveLapsPlotter = _out['plotter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "pActiveInteractiveLapsPlotter[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "iplapsDataExplorer.active_config.plotting_config.subplots_shape # '1|5'\n",
    "iplapsDataExplorer.active_config.plotting_config.plotter_type # 'BackgroundPlotter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subplots_shape_str: str = '1|5'\n",
    "subplots_shape_arr_strs = subplots_shape_str.split('|')\n",
    "\n",
    "subplots_shape = [int(k) for k in subplots_shape_arr_strs]\n",
    "subplots_shape\n",
    "\n",
    "total_n_plots: int = np.prod(subplots_shape)\n",
    "if total_n_plots > 1:\n",
    "    iplapsDataExplorer.active_config.plotting_config.plotter_type = 'BackgroundPlotter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iplapsDataExplorer.p.\n",
    "\n",
    "p = iplapsDataExplorer.p[0,0]\n",
    "p\n",
    "# p = self.p[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_global = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=global_epoch_context) # , config_override_kwargs={'plotting_config': {'should_use_linear_track_geometry': True}}\n",
    "# ipspikesDataExplorer = _out_global['ipspikesDataExplorer']\n",
    "# p = _out_global['plotter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: active_config\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "active_config_modifiying_kwargs = {\n",
    "    'plotting_config': {'should_use_linear_track_geometry': True, \n",
    "                        't_start': t_start, 't_delta': t_delta, 't_end': t_end,\n",
    "                        }\n",
    "}\n",
    "_out_global = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=global_epoch_context,\n",
    "                                            active_config_modifiying_kwargs=active_config_modifiying_kwargs,\n",
    "                                            params_kwargs=dict(enable_historical_spikes=False, enable_recent_spikes=False, should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                           )\n",
    "ipspikesDataExplorer = _out_global['ipspikesDataExplorer']\n",
    "p = _out_global['plotter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k, v in active_config_modifiying_kwargs.items():\n",
    "    curr_subdict = active_config.get(k, {})\n",
    "    for sub_k, sub_v in v.items():\n",
    "        try:\n",
    "            curr_subdict[sub_k] = sub_v # apply the update\n",
    "        except TypeError as err:\n",
    "            # TypeError: 'PlottingConfig' object does not support item assignment\n",
    "            setattr(curr_subdict, sub_k, sub_v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27140db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_config.plotting_config.should_use_linear_track_geometry\n",
    "active_config.plotting_config.t_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.time_animations import TrackConfigurationTimeAnimationRoutine\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "custom_track_animatior: TrackConfigurationTimeAnimationRoutine = TrackConfigurationTimeAnimationRoutine(t_start=t_start, t_delta=t_delta, t_end=t_end, \n",
    "        long_maze_bg=ipspikesDataExplorer.plots['long_maze_bg'], short_maze_bg=ipspikesDataExplorer.plots['short_maze_bg'],\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveSliderWrapper import InteractiveSliderWrapper\n",
    "\n",
    "# interactive_plotter = ipspikesDataExplorer.ui.interactive_plotter # PhoInteractivePlotter\n",
    "\n",
    "active_timestamp_slider_wrapper: InteractiveSliderWrapper = ipspikesDataExplorer.ui.interactive_plotter.interface_properties.active_timestamp_slider_wrapper # InteractiveSliderWrapper \n",
    "active_timestamp_slider_wrapper.curr_value # 17659.517659\n",
    "active_timestamp_slider_wrapper.curr_index # 17659\n",
    "\n",
    "\n",
    "curr_i: int = int(active_timestamp_slider_wrapper.curr_index)\n",
    "active_window_sample_indicies = np.squeeze(ipspikesDataExplorer.params.pre_computed_window_sample_indicies[curr_i,:]) # Get the current precomputed indicies for this curr_i\n",
    "\n",
    "## Spike Plotting:\n",
    "# Get the times that fall within the current plot window:\n",
    "curr_time_fixedSegments = ipspikesDataExplorer.t[active_window_sample_indicies] # New Way\n",
    "t_start = curr_time_fixedSegments[0]\n",
    "t_stop = curr_time_fixedSegments[-1]\n",
    "\n",
    "# \n",
    "t_start, t_stop\n",
    "# custom_track_animatior.on_update_current_window(t_start=t_start, t_stop=t_stop)\n",
    "# curr_index\n",
    "active_timestamp_slider_wrapper.slider_obj.SetEnabled(False) # hide the typical timestamp slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b5cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_one_step_decoder = deepcopy(global_results.pf2D_Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _update_nearest_decoded_most_likely_position_callback, _conn = add_nearest_decoded_position_indicator_circle(self, active_one_step_decoder, _debug_print = False)\n",
    "\n",
    "_update_nearest_decoded_most_likely_position_callback, _conn = ipspikesDataExplorer.add_nearest_decoded_position_indicator_circle(active_one_step_decoder=active_one_step_decoder, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d5529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryPyVistaPlotter\n",
    "\n",
    "## plots a decoder posterior viewer with two sliders: one for epoch_idx and another for epoch_time_bin_idx within that epoch\n",
    "active_one_step_decoder = deepcopy(global_results.pf2D_Decoder) # just used for position binning info\n",
    "# a_result: DecodedFilterEpochsResult = deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'])\n",
    "a_result: DecodedFilterEpochsResult = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'])\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = ipspikesDataExplorer.add_decoded_posterior_bars(a_result=a_result,\n",
    "                                                                                                                         xbin=active_one_step_decoder.xbin, xbin_centers=active_one_step_decoder.xbin_centers, ybin=active_one_step_decoder.ybin, ybin_centers=active_one_step_decoder.ybin_centers,\n",
    "                                                                                                                         enable_plot_all_time_bins_in_epoch_mode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df7c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer.params.curr_view_window_length_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79651414",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer.clear_all_added_decoded_posterior_plots()\n",
    "ipspikesDataExplorer.p.clear_slider_widgets() # does not actually clear the added sliders\n",
    "ipspikesDataExplorer.on_slider_update_mesh(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ipspikesDataExplorer.params.curr_view_window_length_samples # 299\n",
    "ipspikesDataExplorer.params.curr_view_window_length_samples = 60.0 * 5.0 * ipspikesDataExplorer.active_session.position.sampling_rate # 5 minutes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_interactions.widgets import RangeSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acebce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipspikesDataExplorer.add_grid_bin_bounds_box(\n",
    "ipspikesDataExplorer.on_slider_update_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f59bafd",
   "metadata": {},
   "source": [
    "# 🖼️🎨 2024-02-28 - WE gotta see the replays on the 3D track. Or the 2D track.\n",
    "2024-04-28 - This is working in both 3D and 2D!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ad549",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: directional_laps_results, global_replays, decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "# global_pf1D\n",
    "# long_replays\n",
    "# direction_max_indices = ripple_all_epoch_bins_marginals_df[['P_Long', 'P_Short']].values.argmax(axis=1)\n",
    "# track_identity_max_indices = ripple_all_epoch_bins_marginals_df[['P_Long', 'P_Short']].values.argmax(axis=1)\n",
    "\n",
    "## How do I get the replays?\n",
    "# long_replay_df: pd.DataFrame = long_replays.to_dataframe() ## These work.\n",
    "# global_replay_df: pd.DataFrame = global_replays.to_dataframe() ## These work.\n",
    "# global_replay_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1D version:\n",
    "## INPUTS: directional_laps_results, decoder_ripple_filter_epochs_decoder_result_dict\n",
    "xbin = deepcopy(directional_laps_results.get_decoders()[0].xbin)\n",
    "xbin_centers = deepcopy(directional_laps_results.get_decoders()[0].xbin_centers)\n",
    "ybin_centers = None\n",
    "ybin = None\n",
    "\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "# a_decoded_filter_epochs_decoder_result_dict\n",
    "\n",
    "## 1D:\n",
    "a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long_LR'] # 1D\n",
    "\n",
    "## OUTPUTS: a_decoded_filter_epochs_decoder_result_dict, xbin_centers, ybin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31cdc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2D version:\n",
    "from neuropy.analyses.placefields import PfND\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BayesianPlacemapPositionDecoder\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_lap_and_ripple_epochs_decoding_for_decoder\n",
    "\n",
    "## INPUTS: long_results, short_results\n",
    "# long_one_step_decoder_2D\n",
    "\n",
    "long_one_step_decoder_2D, short_one_step_decoder_2D  = [results_data.get('pf2D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "one_step_decoder_dict_2D: Dict[str, BayesianPlacemapPositionDecoder] = dict(zip(('long', 'short'), (long_one_step_decoder_2D, short_one_step_decoder_2D)))\n",
    "long_pf2D = long_results.pf2D\n",
    "# short_pf2D = short_results.pf2D\n",
    "\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "xbin_centers = deepcopy(long_pf2D.xbin_centers)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "ybin_centers = deepcopy(long_pf2D.ybin_centers)\n",
    "\n",
    "## OUTPUTS: one_step_decoder_dict_2D, xbin_centers, ybin_centers\n",
    "\n",
    "## INPUTS: one_step_decoder_dict_2D\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "pos_bin_size: Tuple[float, float] = list(one_step_decoder_dict_2D.values())[0].pos_bin_size\n",
    "\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "\n",
    "## Decode epochs for the two decoders ('long', 'short'):\n",
    "LS_decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {}\n",
    "LS_decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {}\n",
    "\n",
    "for a_name, a_decoder in one_step_decoder_dict_2D.items():\n",
    "    LS_decoder_laps_filter_epochs_decoder_result_dict[a_name], LS_decoder_ripple_filter_epochs_decoder_result_dict[a_name] = _compute_lap_and_ripple_epochs_decoding_for_decoder(a_decoder, curr_active_pipeline, desired_laps_decoding_time_bin_size=laps_decoding_time_bin_size, desired_ripple_decoding_time_bin_size=ripple_decoding_time_bin_size)\n",
    "\n",
    "# LS_decoder_ripple_filter_epochs_decoder_result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e591738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2D:\n",
    "# Choose the ripple epochs to plot:\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(LS_decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long'] # 2D\n",
    "# Choose the laps epochs to plot:\n",
    "# a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(LS_decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# a_decoded_filter_epochs_decoder_result_dict\n",
    "\n",
    "\n",
    "# a_result: DecodedFilterEpochsResult = LS_decoder_laps_filter_epochs_decoder_result_dict['long'] # 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryMatplotlibPlotter\n",
    "\n",
    "## INPUTS: a_result: DecodedFilterEpochsResult, an_epoch_idx: int = 18\n",
    "# e.g. `a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long_LR']`\n",
    "\n",
    "# a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long_LR'] # 1D\n",
    "\n",
    "## Convert to plottable posteriors\n",
    "# an_epoch_idx: int = 0\n",
    "\n",
    "# valid_aclus = deepcopy(decoder_aclu_peak_location_df_merged.aclu.unique())\n",
    "num_filter_epochs: int = a_result.num_filter_epochs\n",
    "a_decoded_traj_plotter = DecodedTrajectoryMatplotlibPlotter(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers)\n",
    "fig, axs, laps_pages = a_decoded_traj_plotter.plot_decoded_trajectories_2d(global_session, curr_num_subplots=8, active_page_index=0, plot_actual_lap_lines=False, use_theoretical_tracks_instead=True)\n",
    "\n",
    "integer_slider = a_decoded_traj_plotter.plot_epoch_with_slider_widget(an_epoch_idx=6)\n",
    "integer_slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f60583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(laps_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff87b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps[0].remove()\n",
    "\n",
    "# an_ax.remove(heatmaps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd94ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_ax = axs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plotActors, data_dict = plot_3d_stem_points(pCustom, active_epoch_placefields2D.ratemap.xbin, active_epoch_placefields2D.ratemap.ybin, active_epoch_placefields2D.ratemap.occupancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4627224",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_plot(value=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9cfc42",
   "metadata": {},
   "source": [
    "## add to 3D plotter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12058a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryPyVistaPlotter\n",
    "from pyphoplacecellanalysis.Pho3D.PyVista.graphs import plot_3d_stem_points, plot_3d_binned_bars\n",
    "\n",
    "curr_active_pipeline.prepare_for_display()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_interactive_custom_data_explorer', active_session_configuration_context=global_epoch_context,\n",
    "                                    params_kwargs=dict(should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                    )\n",
    "iplapsDataExplorer: InteractiveCustomDataExplorer = _out['iplapsDataExplorer']\n",
    "pActiveInteractiveLapsPlotter = _out['plotter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b011ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## INPUTS: a_result, xbin_centers, ybin_centers, iplapsDataExplorer\n",
    "# a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = DecodedTrajectoryPyVistaPlotter(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, p=iplapsDataExplorer.p)\n",
    "# a_decoded_trajectory_pyvista_plotter.build_ui()\n",
    "# a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = iplapsDataExplorer.add_decoded_posterior_bars(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, enable_plot_all_time_bins_in_epoch_mode=True)\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = iplapsDataExplorer.add_decoded_posterior_bars(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, enable_plot_all_time_bins_in_epoch_mode=False, active_plot_fn=plot_3d_stem_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24cd81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = iplapsDataExplorer.add_decoded_posterior_bars(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, enable_plot_all_time_bins_in_epoch_mode=False, active_plot_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf0e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "iplapsDataExplorer.clear_all_added_decoded_posterior_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968821ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d6646",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_plot_fn = a_decoded_trajectory_pyvista_plotter.data_dict['plot_3d_binned_bars[55.63197815967686]']['update_plot_fn']\n",
    "# update_plot_fn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_posterior_p_x_given_n, n_epoch_timebins = a_decoded_trajectory_pyvista_plotter._perform_get_curr_posterior(a_result=a_result, an_epoch_idx=a_decoded_trajectory_pyvista_plotter.curr_epoch_idx, time_bin_index=np.arange(a_decoded_trajectory_pyvista_plotter.curr_n_time_bins))\n",
    "# np.shape(a_posterior_p_x_given_n)\n",
    "\n",
    "\n",
    "a_posterior_p_x_given_n, n_epoch_timebins = a_decoded_trajectory_pyvista_plotter.get_curr_posterior(an_epoch_idx=a_decoded_trajectory_pyvista_plotter.curr_epoch_idx, time_bin_index=np.arange(a_decoded_trajectory_pyvista_plotter.curr_n_time_bins))\n",
    "np.shape(a_posterior_p_x_given_n)\n",
    "\n",
    "n_epoch_timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9878ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = a_decoded_trajectory_pyvista_plotter.plotActors['plot_3d_binned_bars[49.11980797704307]']\n",
    "# v['main'].remove()\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter.p.remove_actor(v['main'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6dc498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho3D.PyVista.graphs import clear_3d_binned_bars_plots\n",
    "\n",
    "clear_3d_binned_bars_plots(p=a_decoded_trajectory_pyvista_plotter.p, plotActors=a_decoded_trajectory_pyvista_plotter.plotActors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.plotActors_CenterLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.perform_update_plot_epoch_time_bin_range(value=None) # select all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e721a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.perform_clear_existing_decoded_trajectory_plots()\n",
    "iplapsDataExplorer.p.update()\n",
    "iplapsDataExplorer.p.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bin_index = np.arange(a_decoded_trajectory_pyvista_plotter.curr_n_time_bins)\n",
    "type(time_bin_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7059eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.slider_epoch.RemoveAllObservers()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch.Off()\n",
    "# a_decoded_trajectory_pyvista_plotter.slider_epoch.FastDelete()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch = None\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin.RemoveAllObservers()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin.Off()\n",
    "# a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin.FastDelete()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin = None\n",
    "iplapsDataExplorer.p.clear_slider_widgets()\n",
    "iplapsDataExplorer.p.update()\n",
    "iplapsDataExplorer.p.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66de9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecoderRenderingPyVistaMixin\n",
    "\n",
    "(plotActors, data_dict), (plotActors_CenterLabels, data_dict_CenterLabels) = DecoderRenderingPyVistaMixin.perform_plot_posterior_bars(iplapsDataExplorer.p, xbin=xbin, ybin=ybin, xbin_centers=xbin_centers, ybin_centers=ybin_centers,\n",
    "                                               posterior_p_x_given_n=a_posterior_p_x_given_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d46f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.20720657697753883 * 24.130508176591324"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293adac0",
   "metadata": {},
   "source": [
    "# 🖼️🎨 Rasters Debugger (via `RankOrderRastersDebugger`)\n",
    "<!-- ![image.png|350](attachment:image.png) -->\n",
    "![image.png](attachment:image.png){ width=300; max-width: 300px; }\n",
    "<!-- <img src=\"path_to_your_image.png\" style=\"max-width: 300px;\" /> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c0898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff576652",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "\n",
    "RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "_out_laps_rasters: RankOrderRastersDebugger = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, global_laps_epochs_df, track_templates, rank_order_results, RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict)\n",
    "_out_laps_rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a586d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "# global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "# global_laps_epochs_df = global_laps.to_dataframe()\n",
    "global_ripple_epochs_df = global_replays.to_dataframe()\n",
    "\n",
    "RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "_out_ripple_rasters: RankOrderRastersDebugger = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, global_ripple_epochs_df, track_templates, rank_order_results, RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict)\n",
    "_out_ripple_rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01a20ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict = None\n",
    "# rank_order_results\n",
    "# used_rank_order_results = deepcopy(rank_order_results)\n",
    "used_rank_order_results = None\n",
    "_out_ripple_rasters: RankOrderRastersDebugger = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, deepcopy(filtered_ripple_simple_pf_pearson_merged_df),\n",
    "                                                                                                   track_templates, used_rank_order_results,\n",
    "                                                                                                    RL_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, LR_active_epoch_selected_spikes_fragile_linear_neuron_IDX_dict)\n",
    "_out_ripple_rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff2177",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "_out_ripple_rasters: RankOrderRastersDebugger = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, deepcopy(filtered_ripple_simple_pf_pearson_merged_df),\n",
    "                                                                                                   track_templates, None,\n",
    "                                                                                                    None, None,\n",
    "                                                                                                    dock_add_locations = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'), (['right'], ['right'], ['right'], ['right']))),\n",
    "                                                                                                    )\n",
    "_out_ripple_rasters.set_top_info_bar_visibility(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e4ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_ripple_rasters.set_top_info_bar_visibility(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700afa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide top info bar:\n",
    "LongShortColumnsInfo_dock_layout, LongShortColumnsInfo_dock_Dock = _out_ripple_rasters.plots.dock_widgets['LongShortColumnsInfo_dock']\n",
    "# LongShortColumnsInfo_dock_layout.hide() # No use\n",
    "# _out_ripple_rasters.ui.long_short_info_layout.hide() # No use\n",
    "LongShortColumnsInfo_dock_Dock.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95532207",
   "metadata": {},
   "outputs": [],
   "source": [
    "LongShortColumnsInfo_dock_Dock.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174f3c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# found_IDX = _out_ripple_rasters.find_nearest_time_index(193.65)\n",
    "# if found_IDX is not None:\n",
    "#     print(f'found_IDX: {found_IDX}')\n",
    "#     _out_ripple_rasters.programmatically_update_epoch_IDX(found_IDX)\n",
    "\n",
    "\n",
    "_out_ripple_rasters.programmatically_update_epoch_IDX_from_epoch_start_time(193.65)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965556b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_ripple_rasters.on_update_epoch_IDX(45)\n",
    "# on_update_epoch_IDX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_a_ScrollBarWithSpinBox = _out_ripple_rasters.ui.ctrls_widget # ScrollBarWithSpinBox \n",
    "_a_ScrollBarWithSpinBox.setValue(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521bba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_directional_template_debugger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_template_debugger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_track_template_pf1Ds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_two_step_decoder_prediction_error_2D', global_epoch_context, variable_name='p_x_given_n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_plot_most_likely_position_comparisons', global_epoch_context) # , variable_name='p_x_given_n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddebd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d805c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_display_directional_laps_overview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_display_directional_merged_pfs'\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pfs', plot_all_directions=False, plot_long_directional=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47076a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_display_1d_placefield_occupancy'\n",
    "'_display_placemaps_pyqtplot_2D'\n",
    " '_display_2d_placefield_occupancy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481df233",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_2d_placefield_occupancy', global_any_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_grid_bin_bounds_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58951b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import add_rectangular_selector, add_range_selector\n",
    "\n",
    "\n",
    "# epoch_name = global_any_name\n",
    "epoch_name = short_epoch_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = computation_result.computation_config['pf_params'].grid_bin_bounds\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n",
    "            \n",
    "fig, ax = computation_result.computed_data.pf2D.plot_occupancy(identifier_details_list=[epoch_name], active_context=epoch_context) \n",
    "\n",
    "# rect_selector, set_extents, reset_extents = add_rectangular_selector(fig, ax, initial_selection=grid_bin_bounds) # (24.82, 257.88), (125.52, 149.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines\n",
    "\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b862a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.peak_location_representing import compute_placefield_center_of_mass_positions\n",
    "\n",
    "\n",
    "epoch_name = global_any_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = deepcopy(computation_result.computation_config['pf_params'].grid_bin_bounds)\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_pf2D.xbin\n",
    "long_pf2D.ybin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc3d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0416d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage # used for `compute_placefield_center_of_masses`\n",
    "from neuropy.utils.mixins.peak_location_representing import compute_occupancy_center_of_mass_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6352663",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_x_center_dict # {'long_LR': 162.99271603199625, 'long_RL': 112.79866056603696, 'short_LR': 138.45611791646, 'short_RL': 130.78889937230684}\n",
    "\n",
    "occupancy_mask_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.visited_occupancy_mask, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_mask_x_center_dict # {'long_LR': 135.66781520875904, 'long_RL': 130.0042755113645, 'short_LR': 133.77996864296085, 'short_RL': 143.21920147195175}\n",
    "\n",
    "\n",
    "# {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb029d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "\n",
    "# masked_nonzero_occupancy = deepcopy(long_pf2D.nan_never_visited_occupancy)\n",
    "\n",
    "masked_nonzero_occupancy = deepcopy(long_pf2D.visited_occupancy_mask)\n",
    "\n",
    "# occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin)\n",
    "occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(masked_nonzero_occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin) # array([127.704, 145.63])\n",
    "occupancy_CoM_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e7e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf2D.nan_never_visited_occupancy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4caa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict\n",
    "\n",
    "\n",
    "'_display_grid_bin_bounds_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f963a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting on 2024-02-06 to display the LR/RL directions instead of the All/Long/Short pfs:\n",
    "def _display_directional_merged_pfs(owning_pipeline_reference, global_computation_results, computation_results, active_configs, include_includelist=None, save_figure=True, included_any_context_neuron_ids=None,\n",
    "\t\t\t\t\t\t\t\t\tplot_all_directions=True, plot_long_directional=False, plot_short_directional=False, **kwargs):\n",
    "\t\"\"\" Plots the merged pseduo-2D pfs/ratemaps. Plots: All-Directions, Long-Directional, Short-Directional in seperate windows. \n",
    "\t\n",
    "\tHistory: this is the Post 2022-10-22 display_all_pf_2D_pyqtgraph_binned_image_rendering-based method:\n",
    "\t\"\"\"\n",
    "\tfrom pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array, display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "\tfrom pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow \n",
    "\tfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import LayoutScrollability\n",
    "\n",
    "\tdefer_render = kwargs.pop('defer_render', False)\n",
    "\tdirectional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\tactive_merged_pf_plots_data_dict = {} #empty dict\n",
    "\t\n",
    "\tif plot_all_directions:\n",
    "\t\tactive_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='All-Directions', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.all_directional_pf1D_Decoder.pf # all-directions\n",
    "\tif plot_long_directional:\n",
    "\t\tactive_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Long-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.long_directional_pf1D_Decoder.pf # Long-only\n",
    "\tif plot_short_directional:\n",
    "\t\tactive_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Short-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.short_directional_pf1D_Decoder.pf # Short-only\n",
    "\n",
    "\tout_plots_dict = {}\n",
    "\t\n",
    "\tfor active_context, active_pf_2D in active_merged_pf_plots_data_dict.items():\n",
    "\t\t# figure_format_config = {} # empty dict for config\n",
    "\t\tfigure_format_config = {'scrollability_mode': LayoutScrollability.NON_SCROLLABLE} # kwargs # kwargs as default figure_format_config\n",
    "\t\tout_all_pf_2D_pyqtgraph_binned_image_fig: BasicBinnedImageRenderingWindow  = display_all_pf_2D_pyqtgraph_binned_image_rendering(active_pf_2D, figure_format_config) # output is BasicBinnedImageRenderingWindow\n",
    "\t\n",
    "\t\t# Set the window title from the context\n",
    "\t\tout_all_pf_2D_pyqtgraph_binned_image_fig.setWindowTitle(f'{active_context.get_description()}')\n",
    "\t\tout_plots_dict[active_context] = out_all_pf_2D_pyqtgraph_binned_image_fig\n",
    "\n",
    "\t\t# Tries to update the display of the item:\n",
    "\t\tnames_list = [v for v in list(out_all_pf_2D_pyqtgraph_binned_image_fig.plots.keys()) if v not in ('name', 'context')]\n",
    "\t\tfor a_name in names_list:\n",
    "\t\t\t# Adjust the size of the text for the item by passing formatted text\n",
    "\t\t\ta_plot: pg.PlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem # PlotItem \n",
    "\t\t\t# no clue why 2 is a good value for this...\n",
    "\t\t\ta_plot.titleLabel.setMaximumHeight(2)\n",
    "\t\t\ta_plot.layout.setRowFixedHeight(0, 2)\n",
    "\t\t\t\n",
    "\n",
    "\t\tif not defer_render:\n",
    "\t\t\tout_all_pf_2D_pyqtgraph_binned_image_fig.show()\n",
    "\n",
    "\treturn out_plots_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e434945",
   "metadata": {},
   "source": [
    "# 2023-12-18 - Simpily detect bimodal cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cd3ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.peak_location_representing import ContinuousPeakLocationRepresentingMixin\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from scipy.signal import find_peaks\n",
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# curr_active_pipeline.display('_display_1d_placefields', 'maze1_any', sortby=None)\n",
    "\n",
    "# active_ratemap = deepcopy(long_pf1D.ratemap)\n",
    "active_ratemap: Ratemap = deepcopy(long_LR_pf1D.ratemap)\n",
    "peaks_dict, aclu_n_peaks_dict, peaks_results_df = active_ratemap.compute_tuning_curve_modes(height=0.2, width=None)\n",
    "\n",
    "\n",
    "included_columns = ['pos', 'peak_heights'] # the columns of interest that you want in the final dataframe.\n",
    "included_columns_renamed = dict(zip(included_columns, ['peak', 'peak_height']))\n",
    "decoder_peaks_results_dfs = [a_decoder.pf.ratemap.get_tuning_curve_peak_df(height=0.2, width=None) for a_decoder in (track_templates.long_LR_decoder, track_templates.long_RL_decoder, track_templates.short_LR_decoder, track_templates.short_RL_decoder)]\n",
    "prefix_names = [f'{a_decoder_name}_' for a_decoder_name in track_templates.get_decoder_names()]\n",
    "all_included_columns = ['aclu', 'series_idx', 'subpeak_idx'] + included_columns # Used to filter out the unwanted columns from the output\n",
    "\n",
    "# [['aclu', 'series_idx', 'subpeak_idx', 'pos']]\n",
    "\n",
    "# rename_list_fn = lambda a_prefix: {'pos': f\"{a_prefix}pos\"}\n",
    "rename_list_fn = lambda a_prefix: {a_col_name:f\"{a_prefix}{included_columns_renamed[a_col_name]}\" for a_col_name in included_columns}\n",
    "\n",
    "# column_names = [f'{a_decoder_name}_peak' for a_decoder_name in track_templates.get_decoder_names()]\n",
    "\n",
    "# dataFrames = decoder_peaks_results_dfs\n",
    "# names = self.get_decoder_names()\n",
    "\n",
    "# rename 'pos' column in each dataframe and then reduce to perform cumulative outer merge\n",
    "result_df = decoder_peaks_results_dfs[0][all_included_columns].rename(columns=rename_list_fn(prefix_names[0]))\n",
    "for df, a_prefix in zip(decoder_peaks_results_dfs[1:], prefix_names[1:]):\n",
    "    result_df = pd.merge(result_df, df[all_included_columns].rename(columns=rename_list_fn(a_prefix)), on=['aclu', 'series_idx', 'subpeak_idx'], how='outer')\n",
    "\n",
    "# result = reorder_columns(result, column_name_desired_index_dict=dict(zip(['Long_LR_evidence', 'Long_RL_evidence', 'Short_LR_evidence', 'Short_RL_evidence'], np.arange(4)+4)))\n",
    "\n",
    "## Move the \"height\" columns to the end\n",
    "# list(filter(lambda column: column.endswith('_peak_heights'), result.columns))\n",
    "# result_df = reorder_columns(result_df, column_name_desired_index_dict=dict(zip(list(filter(lambda column: column.endswith('_peak_heights'), result_df.columns)), np.arange(len(result_df.columns)-4, len(result_df.columns)))))\n",
    "# result_df\n",
    "\n",
    "# print(list(result.columns))\n",
    "\n",
    "## Move the \"height\" columns to the end\n",
    "result_df: pd.DataFrame = reorder_columns_relative(result_df, column_names=list(filter(lambda column: column.endswith('_peak_heights'), result_df.columns)), relative_mode='end').sort_values(['aclu', 'series_idx', 'subpeak_idx']).reset_index(drop=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a292dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually Excluded endcap aclus:\n",
    "IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43')\n",
    "excluded_endcap_aclus: NDArray = np.array(list(set([40, 60, 85, 102, 52, 6] + [83, 60, 52, 102, 40] + [59, 67, 95, 28, 101] + [14, 15, 87, 71] + [43, 84, 87, 19, 33, 51, 53])))\n",
    "excluded_endcap_aclus\n",
    "\n",
    "\n",
    "np.array([  6,  14,  15,  19,  28,  33,  40,  43,  51,  52,  53,  59,  60,  67,  71,  83,  84,  85,  87,  95, 101, 102])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_results_df = track_templates.get_decoders_aclu_peak_location_df().sort_values(['aclu', 'series_idx', 'subpeak_idx']).reset_index(drop=True) ## Does not seem to merge entries as I would expect via intution. It keeps LR/RL peaks distinct and leaves pd.NA values for the entries.\n",
    "peaks_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c29838",
   "metadata": {},
   "outputs": [],
   "source": [
    "aclu_n_peaks_dict: Dict = peaks_results_df.groupby(['aclu']).agg(subpeak_idx_count=('subpeak_idx', 'count')).reset_index().set_index('aclu').to_dict()['subpeak_idx_count'] # number of peaks (\"models\" for each aclu)\n",
    "aclu_n_peaks_dict\n",
    "\n",
    "# peaks_results_df = peaks_results_df.groupby(['aclu']).agg(subpeak_idx_count=('subpeak_idx', 'count')).reset_index()\n",
    "\n",
    "# peaks_results_df[peaks_results_df.aclu == 5]\n",
    "# peaks_results_df.aclu.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e14bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_ratemap.n_neurons\n",
    "curr_active_pipeline.display('_display_1d_placefields', 'maze1_any', included_unit_neuron_IDs=active_ratemap.neuron_ids, sortby=np.arange(active_ratemap.n_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aclu_n_peaks_dict\n",
    "unimodal_only_aclus = np.array(list(unimodal_peaks_dict.keys()))\n",
    "unimodal_only_aclus\n",
    "curr_active_pipeline.display('_display_1d_placefields', 'maze1_any', included_unit_neuron_IDs=unimodal_only_aclus, sortby=np.arange(active_ratemap.n_neurons))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c9e39",
   "metadata": {},
   "source": [
    "# 🖼️🎨 2024-02-08 - `PhoPaginatedMultiDecoderDecodedEpochsWindow` - Plot Ripple Metrics like Radon Transforms, WCorr, Simple Pearson, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf989bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions failed: Traceback (most recent call last):\n",
      "  File \"k:\\FastSwap\\AppData\\VSCode\\yellow\\.venv_yellow\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 274, in check\n",
      "    superreload(m, reload, self.old_objects, self.shell)\n",
      "  File \"k:\\FastSwap\\AppData\\VSCode\\yellow\\.venv_yellow\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"k:\\FastSwap\\AppData\\VSCode\\yellow\\.venv_yellow\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"k:\\FastSwap\\AppData\\VSCode\\yellow\\.venv_yellow\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"k:\\FastSwap\\AppData\\VSCode\\yellow\\.venv_yellow\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 323, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: can't apply this __setattr__ to ComputationFunctionRegistryHolder object\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(active_epochs_df): 707\n",
      "min_num_unique_aclu_inclusions: 12\n",
      "len(active_epochs_df): 405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'long_LR':      longest_sequence_length  longest_sequence_length_ratio  direction_change_bin_ratio  congruent_dir_bins_ratio  total_congruent_direction_change  total_variation  integral_second_derivative  stddev_of_diff\n",
       " 0                          4                       0.571429                    0.333333                  0.500000                        351.558857       494.500370               101101.708481      110.807358\n",
       " 1                          3                       0.333333                    0.625000                  0.375000                        235.660333       452.004244               100519.634871       70.231528\n",
       " 2                          6                       0.461538                    0.166667                  0.583333                        374.738562       548.586348               140772.263712       76.462018\n",
       " 3                          7                       0.350000                    0.421053                  0.631579                        540.859780       869.238931               173711.660024       62.355277\n",
       " 4                          4                       0.363636                    0.500000                  0.300000                        262.703322       521.543359               118623.616623       79.201094\n",
       " 5                          6                       0.375000                    0.200000                  0.333333                        216.343912       394.054982                72177.127578       50.797249\n",
       " ..                       ...                            ...                         ...                       ...                               ...              ...                         ...             ...\n",
       " 399                        4                       0.666667                    0.200000                  0.800000                        208.617344       235.660333                34924.416570       52.210109\n",
       " 400                        2                       0.250000                    0.571429                  0.428571                        421.097971       764.930260               379646.318072      132.199957\n",
       " 401                        4                       0.500000                    0.428571                  0.428571                        208.617344       235.660333                49938.930702       55.129031\n",
       " 402                        8                       1.000000                    0.000000                  0.714286                        189.300923       189.300923                29491.729548       39.935436\n",
       " 403                        4                       0.400000                    0.555556                  0.444444                        394.054982       780.383396               347766.594229      106.125567\n",
       " 404                        5                       0.500000                    0.333333                  0.444444                          0.000000       355.422141                78191.888209       73.368502\n",
       " \n",
       " [405 rows x 8 columns],\n",
       " 'long_RL':      longest_sequence_length  longest_sequence_length_ratio  direction_change_bin_ratio  congruent_dir_bins_ratio  total_congruent_direction_change  total_variation  integral_second_derivative  stddev_of_diff\n",
       " 0                          2                       0.285714                    0.666667                  0.666667                        413.371403       629.715315               165443.229777      105.700424\n",
       " 1                          4                       0.444444                    0.500000                  0.625000                        486.773802       768.793544               284648.920009      114.211145\n",
       " 2                          5                       0.384615                    0.250000                  0.416667                        370.875277       722.434134               179607.020941       95.838240\n",
       " 3                          7                       0.350000                    0.421053                  0.473684                        780.383396      1352.149449               537985.264820      102.299414\n",
       " 4                          4                       0.363636                    0.300000                  0.300000                        216.343912       421.097971                57908.861663       67.071108\n",
       " 5                          8                       0.500000                    0.133333                  0.400000                        417.234687       633.578599               175562.355603       79.822926\n",
       " ..                       ...                            ...                         ...                       ...                               ...              ...                         ...             ...\n",
       " 399                        4                       0.666667                    0.400000                  0.600000                        336.105720       544.723064               193860.361892      139.241250\n",
       " 400                        2                       0.250000                    0.571429                  0.571429                        533.133211       873.102216               442644.592577      143.684325\n",
       " 401                        8                       1.000000                    0.000000                  0.714286                        154.531366       154.531366                21954.622553       37.211170\n",
       " 402                        3                       0.375000                    0.571429                  0.571429                        305.199447       482.910517               143055.783257       91.017960\n",
       " 403                        4                       0.400000                    0.555556                  0.444444                        312.926015       618.125462               274290.994753       93.834918\n",
       " 404                        3                       0.300000                    0.555556                  0.444444                        367.011993       656.758304               208680.851487       99.011647\n",
       " \n",
       " [405 rows x 8 columns],\n",
       " 'short_LR':      longest_sequence_length  longest_sequence_length_ratio  direction_change_bin_ratio  congruent_dir_bins_ratio  total_congruent_direction_change  total_variation  integral_second_derivative  stddev_of_diff\n",
       " 0                          4                       0.571429                    0.166667                  0.500000                        193.164207       343.832288                27775.358648       78.302352\n",
       " 1                          2                       0.222222                    0.625000                  0.500000                        169.984502       324.515868                66147.441982       52.652750\n",
       " 2                          6                       0.461538                    0.250000                  0.583333                        243.386901       394.054982                37581.060223       42.932891\n",
       " 3                          5                       0.250000                    0.421053                  0.315789                        440.414392       846.059227               219202.951351       64.734582\n",
       " 4                          5                       0.454545                    0.300000                  0.300000                        131.351661       224.070480                27521.634254       35.365407\n",
       " 5                          6                       0.375000                    0.333333                  0.400000                        397.918266       749.477123               338990.715193       89.876519\n",
       " ..                       ...                            ...                         ...                       ...                               ...              ...                         ...             ...\n",
       " 399                        3                       0.500000                    0.400000                  0.800000                        227.933764       309.062731                43043.597174       60.966492\n",
       " 400                        4                       0.500000                    0.285714                  0.428571                        146.804797       285.883026                34625.917283       50.654472\n",
       " 401                        4                       0.500000                    0.285714                  0.428571                        185.437639       231.797048                19447.228543       40.171180\n",
       " 402                        5                       0.625000                    0.285714                  0.714286                        227.933764       301.336163                57923.786627       55.437571\n",
       " 403                        4                       0.400000                    0.333333                  0.333333                          0.000000       502.226938               118877.341017       75.923336\n",
       " 404                        4                       0.400000                    0.555556                  0.222222                          0.000000       579.492621               169965.493973       74.690160\n",
       " \n",
       " [405 rows x 8 columns],\n",
       " 'short_RL':      longest_sequence_length  longest_sequence_length_ratio  direction_change_bin_ratio  congruent_dir_bins_ratio  total_congruent_direction_change  total_variation  integral_second_derivative  stddev_of_diff\n",
       " 0                          3                       0.428571                    0.500000                  0.666667                        297.472879       544.723064               129638.240310       98.151158\n",
       " 1                          2                       0.222222                    0.625000                  0.625000                        394.054982       784.246680               321856.856124      117.218011\n",
       " 2                          6                       0.461538                    0.333333                  0.333333                        204.754059       339.969004                29969.328407       38.681102\n",
       " 3                          5                       0.250000                    0.473684                  0.421053                        521.543359      1039.223434               378183.671566       81.592146\n",
       " 4                          5                       0.454545                    0.400000                  0.200000                        212.480628       421.097971               129593.465417       68.598047\n",
       " 5                         10                       0.625000                    0.266667                  0.266667                        479.047233       842.195943               311095.956830       92.986716\n",
       " ..                       ...                            ...                         ...                       ...                               ...              ...                         ...             ...\n",
       " 399                        3                       0.500000                    0.600000                  0.400000                        131.351661       204.754059                27178.360074       46.423753\n",
       " 400                        3                       0.375000                    0.285714                  0.285714                          0.000000       409.508119               156040.502239       86.976001\n",
       " 401                        6                       0.750000                    0.142857                  0.714286                         77.265683        84.992251                 4477.489304       15.842445\n",
       " 402                        3                       0.375000                    0.428571                  0.428571                        185.437639       289.746310                49819.530987       51.666590\n",
       " 403                        4                       0.400000                    0.222222                  0.444444                        208.617344       417.234687                83430.550695       65.130688\n",
       " 404                        5                       0.500000                    0.222222                  0.444444                        193.164207       320.652584                82788.777228       53.358854\n",
       " \n",
       " [405 rows x 8 columns]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_user_selected_times: 41\n",
      "adding user annotation column!\n",
      "len(active_epochs_df): 707\n",
      "min_num_unique_aclu_inclusions: 12\n",
      "len(active_epochs_df): 405\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import RadonTransformPlotDataProvider\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "\n",
    "## INPUTS: decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "\n",
    "## filter the epochs by something and only show those:\n",
    "# INPUTS: filtered_epochs_df\n",
    "# filtered_ripple_simple_pf_pearson_merged_df = filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(active_epochs_df[['start', 'stop']].to_numpy())\n",
    "## Update the `decoder_ripple_filter_epochs_decoder_result_dict` with the included epochs:\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "# print(f\"any_good_selected_epoch_times.shape: {any_good_selected_epoch_times.shape}\") # (142, 2)\n",
    "\n",
    "pre_cols = {a_name:set(a_result.filter_epochs.columns) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()}\n",
    "\n",
    "# 🟪 2024-02-29 - `compute_pho_heuristic_replay_scores`\n",
    "filtered_decoder_filter_epochs_decoder_result_dict, _out_new_scores = HeuristicReplayScoring.compute_all_heuristic_scores(track_templates=track_templates, a_decoded_filter_epochs_decoder_result_dict=filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "_out_new_scores\n",
    "## 2024-03-08 - Also constrain the user-selected ones (just to try it):\n",
    "decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline, track_templates=track_templates)\n",
    "# ## Constrain again now by the user selections\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(any_good_selected_epoch_times) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()}\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "## Instead, add in the 'is_user_annotated_epoch' column instead of filtering\n",
    "## INPUTS: any_good_selected_epoch_times\n",
    "num_user_selected_times: int = len(any_good_selected_epoch_times)\n",
    "print(f'num_user_selected_times: {num_user_selected_times}')\n",
    "any_good_selected_epoch_indicies = None\n",
    "print(f'adding user annotation column!')\n",
    "\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "\n",
    "## OUT: filtered_decoder_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc04fc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import ensure_dataframe\n",
    "\n",
    "filter_epochs: pd.DataFrame = deepcopy(ensure_dataframe(filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs))\n",
    "filter_epochs\n",
    "\n",
    "# np.sum(filter_epochs['pearsonr'].isna())\n",
    "\n",
    "new_heuristic_checking_columns = ['total_variation', 'integral_second_derivative', 'stddev_of_diff', 'score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79929f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs.groupby('is_user_annotated_epoch').agg(['mean', 'std', 'var', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaaf5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs.to_csv('output/2024-05-10_new_heuristics_for_ripples.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd98310",
   "metadata": {},
   "source": [
    "### 2024-05-09 - get the most-likely decoder for each epoch using the sequenceless probabilities and used this to selected the appopriate column for each of the heuristic measures.\n",
    "Modifies `extracted_merged_scores_df`, adding \"*_BEST\" columns for each specified heuristic score column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d65f4853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "      <th>is_user_annotated_epoch</th>\n",
       "      <th>is_valid_epoch</th>\n",
       "      <th>P_LR</th>\n",
       "      <th>P_RL</th>\n",
       "      <th>P_Long</th>\n",
       "      <th>P_Short</th>\n",
       "      <th>P_Long_LR</th>\n",
       "      <th>score_long_LR</th>\n",
       "      <th>velocity_long_LR</th>\n",
       "      <th>intercept_long_LR</th>\n",
       "      <th>speed_long_LR</th>\n",
       "      <th>wcorr_long_LR</th>\n",
       "      <th>pearsonr_long_LR</th>\n",
       "      <th>travel_long_LR</th>\n",
       "      <th>coverage_long_LR</th>\n",
       "      <th>jump_long_LR</th>\n",
       "      <th>longest_sequence_length_ratio_long_LR</th>\n",
       "      <th>direction_change_bin_ratio_long_LR</th>\n",
       "      <th>congruent_dir_bins_ratio_long_LR</th>\n",
       "      <th>total_congruent_direction_change_long_LR</th>\n",
       "      <th>total_variation_long_LR</th>\n",
       "      <th>integral_second_derivative_long_LR</th>\n",
       "      <th>stddev_of_diff_long_LR</th>\n",
       "      <th>P_Long_RL</th>\n",
       "      <th>score_long_RL</th>\n",
       "      <th>velocity_long_RL</th>\n",
       "      <th>intercept_long_RL</th>\n",
       "      <th>speed_long_RL</th>\n",
       "      <th>wcorr_long_RL</th>\n",
       "      <th>pearsonr_long_RL</th>\n",
       "      <th>travel_long_RL</th>\n",
       "      <th>coverage_long_RL</th>\n",
       "      <th>jump_long_RL</th>\n",
       "      <th>longest_sequence_length_ratio_long_RL</th>\n",
       "      <th>direction_change_bin_ratio_long_RL</th>\n",
       "      <th>congruent_dir_bins_ratio_long_RL</th>\n",
       "      <th>total_congruent_direction_change_long_RL</th>\n",
       "      <th>total_variation_long_RL</th>\n",
       "      <th>integral_second_derivative_long_RL</th>\n",
       "      <th>stddev_of_diff_long_RL</th>\n",
       "      <th>P_Short_LR</th>\n",
       "      <th>score_short_LR</th>\n",
       "      <th>velocity_short_LR</th>\n",
       "      <th>intercept_short_LR</th>\n",
       "      <th>speed_short_LR</th>\n",
       "      <th>wcorr_short_LR</th>\n",
       "      <th>pearsonr_short_LR</th>\n",
       "      <th>travel_short_LR</th>\n",
       "      <th>coverage_short_LR</th>\n",
       "      <th>jump_short_LR</th>\n",
       "      <th>longest_sequence_length_ratio_short_LR</th>\n",
       "      <th>direction_change_bin_ratio_short_LR</th>\n",
       "      <th>congruent_dir_bins_ratio_short_LR</th>\n",
       "      <th>total_congruent_direction_change_short_LR</th>\n",
       "      <th>total_variation_short_LR</th>\n",
       "      <th>integral_second_derivative_short_LR</th>\n",
       "      <th>stddev_of_diff_short_LR</th>\n",
       "      <th>P_Short_RL</th>\n",
       "      <th>score_short_RL</th>\n",
       "      <th>velocity_short_RL</th>\n",
       "      <th>intercept_short_RL</th>\n",
       "      <th>speed_short_RL</th>\n",
       "      <th>wcorr_short_RL</th>\n",
       "      <th>pearsonr_short_RL</th>\n",
       "      <th>travel_short_RL</th>\n",
       "      <th>coverage_short_RL</th>\n",
       "      <th>jump_short_RL</th>\n",
       "      <th>longest_sequence_length_ratio_short_RL</th>\n",
       "      <th>direction_change_bin_ratio_short_RL</th>\n",
       "      <th>congruent_dir_bins_ratio_short_RL</th>\n",
       "      <th>total_congruent_direction_change_short_RL</th>\n",
       "      <th>total_variation_short_RL</th>\n",
       "      <th>integral_second_derivative_short_RL</th>\n",
       "      <th>stddev_of_diff_short_RL</th>\n",
       "      <th>ripple_start_t</th>\n",
       "      <th>long_best_P_decoder</th>\n",
       "      <th>short_best_P_decoder</th>\n",
       "      <th>P_decoder_diff</th>\n",
       "      <th>long_best_score</th>\n",
       "      <th>short_best_score</th>\n",
       "      <th>score_diff</th>\n",
       "      <th>long_best_velocity</th>\n",
       "      <th>short_best_velocity</th>\n",
       "      <th>velocity_diff</th>\n",
       "      <th>long_best_intercept</th>\n",
       "      <th>short_best_intercept</th>\n",
       "      <th>intercept_diff</th>\n",
       "      <th>long_best_speed</th>\n",
       "      <th>short_best_speed</th>\n",
       "      <th>speed_diff</th>\n",
       "      <th>long_best_wcorr</th>\n",
       "      <th>short_best_wcorr</th>\n",
       "      <th>wcorr_diff</th>\n",
       "      <th>long_best_pearsonr</th>\n",
       "      <th>short_best_pearsonr</th>\n",
       "      <th>pearsonr_diff</th>\n",
       "      <th>long_best_travel</th>\n",
       "      <th>short_best_travel</th>\n",
       "      <th>travel_diff</th>\n",
       "      <th>long_best_coverage</th>\n",
       "      <th>short_best_coverage</th>\n",
       "      <th>coverage_diff</th>\n",
       "      <th>long_best_jump</th>\n",
       "      <th>short_best_jump</th>\n",
       "      <th>jump_diff</th>\n",
       "      <th>long_best_longest_sequence_length_ratio</th>\n",
       "      <th>short_best_longest_sequence_length_ratio</th>\n",
       "      <th>longest_sequence_length_ratio_diff</th>\n",
       "      <th>long_best_direction_change_bin_ratio</th>\n",
       "      <th>short_best_direction_change_bin_ratio</th>\n",
       "      <th>direction_change_bin_ratio_diff</th>\n",
       "      <th>long_best_congruent_dir_bins_ratio</th>\n",
       "      <th>short_best_congruent_dir_bins_ratio</th>\n",
       "      <th>congruent_dir_bins_ratio_diff</th>\n",
       "      <th>long_best_total_congruent_direction_change</th>\n",
       "      <th>short_best_total_congruent_direction_change</th>\n",
       "      <th>total_congruent_direction_change_diff</th>\n",
       "      <th>long_best_total_variation</th>\n",
       "      <th>short_best_total_variation</th>\n",
       "      <th>total_variation_diff</th>\n",
       "      <th>long_best_integral_second_derivative</th>\n",
       "      <th>short_best_integral_second_derivative</th>\n",
       "      <th>integral_second_derivative_diff</th>\n",
       "      <th>long_best_stddev_of_diff</th>\n",
       "      <th>short_best_stddev_of_diff</th>\n",
       "      <th>stddev_of_diff_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.469478</td>\n",
       "      <td>55.668144</td>\n",
       "      <td>1</td>\n",
       "      <td>0.198666</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.279922</td>\n",
       "      <td>0.720078</td>\n",
       "      <td>0.747300</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.209186</td>\n",
       "      <td>0.218418</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>13108.185152</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>-0.176375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.385125</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>351.558857</td>\n",
       "      <td>494.500370</td>\n",
       "      <td>101101.708481</td>\n",
       "      <td>110.807358</td>\n",
       "      <td>0.538114</td>\n",
       "      <td>0.177541</td>\n",
       "      <td>566.615007</td>\n",
       "      <td>31672.957977</td>\n",
       "      <td>566.615007</td>\n",
       "      <td>-0.423041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.490432</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>413.371403</td>\n",
       "      <td>629.715315</td>\n",
       "      <td>165443.229777</td>\n",
       "      <td>105.700424</td>\n",
       "      <td>0.070736</td>\n",
       "      <td>0.199763</td>\n",
       "      <td>309.062731</td>\n",
       "      <td>17248.23328</td>\n",
       "      <td>309.062731</td>\n",
       "      <td>-0.076130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.397954</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>343.832288</td>\n",
       "      <td>27775.358648</td>\n",
       "      <td>78.302352</td>\n",
       "      <td>0.181964</td>\n",
       "      <td>0.202055</td>\n",
       "      <td>1287.76138</td>\n",
       "      <td>71768.577533</td>\n",
       "      <td>1287.76138</td>\n",
       "      <td>-0.059093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630467</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>297.472879</td>\n",
       "      <td>544.723064</td>\n",
       "      <td>129638.240310</td>\n",
       "      <td>98.151158</td>\n",
       "      <td>55.469478</td>\n",
       "      <td>0.209186</td>\n",
       "      <td>0.070736</td>\n",
       "      <td>0.138450</td>\n",
       "      <td>0.218418</td>\n",
       "      <td>0.199763</td>\n",
       "      <td>0.018655</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>309.062731</td>\n",
       "      <td>-77.265683</td>\n",
       "      <td>13108.185152</td>\n",
       "      <td>17248.23328</td>\n",
       "      <td>-4140.048128</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>309.062731</td>\n",
       "      <td>-77.265683</td>\n",
       "      <td>-0.176375</td>\n",
       "      <td>-0.076130</td>\n",
       "      <td>0.100245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.385125</td>\n",
       "      <td>0.397954</td>\n",
       "      <td>-0.012829</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>-0.001016</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>351.558857</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>158.394650</td>\n",
       "      <td>494.500370</td>\n",
       "      <td>343.832288</td>\n",
       "      <td>150.668081</td>\n",
       "      <td>101101.708481</td>\n",
       "      <td>27775.358648</td>\n",
       "      <td>73326.349832</td>\n",
       "      <td>110.807358</td>\n",
       "      <td>78.302352</td>\n",
       "      <td>32.505007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.728617</td>\n",
       "      <td>70.977971</td>\n",
       "      <td>2</td>\n",
       "      <td>0.249354</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.723395</td>\n",
       "      <td>0.276605</td>\n",
       "      <td>0.292040</td>\n",
       "      <td>0.707960</td>\n",
       "      <td>0.211260</td>\n",
       "      <td>0.235102</td>\n",
       "      <td>96.582103</td>\n",
       "      <td>7072.225651</td>\n",
       "      <td>96.582103</td>\n",
       "      <td>-0.280497</td>\n",
       "      <td>-0.203513</td>\n",
       "      <td>0.264021</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>235.660333</td>\n",
       "      <td>452.004244</td>\n",
       "      <td>100519.634871</td>\n",
       "      <td>70.231528</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.188198</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>1614.091544</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>-0.380997</td>\n",
       "      <td>-0.157490</td>\n",
       "      <td>0.449062</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>486.773802</td>\n",
       "      <td>768.793544</td>\n",
       "      <td>284648.920009</td>\n",
       "      <td>114.211145</td>\n",
       "      <td>0.512135</td>\n",
       "      <td>0.278974</td>\n",
       "      <td>38.632841</td>\n",
       "      <td>2938.060587</td>\n",
       "      <td>38.632841</td>\n",
       "      <td>-0.124122</td>\n",
       "      <td>0.101345</td>\n",
       "      <td>0.281698</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>169.984502</td>\n",
       "      <td>324.515868</td>\n",
       "      <td>66147.441982</td>\n",
       "      <td>52.652750</td>\n",
       "      <td>0.195825</td>\n",
       "      <td>0.256928</td>\n",
       "      <td>38.632841</td>\n",
       "      <td>2945.787156</td>\n",
       "      <td>38.632841</td>\n",
       "      <td>0.143256</td>\n",
       "      <td>0.106136</td>\n",
       "      <td>0.680770</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>394.054982</td>\n",
       "      <td>784.246680</td>\n",
       "      <td>321856.856124</td>\n",
       "      <td>117.218011</td>\n",
       "      <td>70.728617</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.195825</td>\n",
       "      <td>-0.115046</td>\n",
       "      <td>0.188198</td>\n",
       "      <td>0.256928</td>\n",
       "      <td>-0.06873</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>38.632841</td>\n",
       "      <td>-19.316421</td>\n",
       "      <td>1614.091544</td>\n",
       "      <td>2945.787156</td>\n",
       "      <td>-1331.695612</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>38.632841</td>\n",
       "      <td>-19.316421</td>\n",
       "      <td>-0.380997</td>\n",
       "      <td>0.143256</td>\n",
       "      <td>0.237741</td>\n",
       "      <td>-0.157490</td>\n",
       "      <td>0.106136</td>\n",
       "      <td>0.051354</td>\n",
       "      <td>0.449062</td>\n",
       "      <td>0.680770</td>\n",
       "      <td>-0.231708</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>-0.002699</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>486.773802</td>\n",
       "      <td>394.054982</td>\n",
       "      <td>92.718819</td>\n",
       "      <td>768.793544</td>\n",
       "      <td>784.246680</td>\n",
       "      <td>-15.453137</td>\n",
       "      <td>284648.920009</td>\n",
       "      <td>321856.856124</td>\n",
       "      <td>-37207.936115</td>\n",
       "      <td>114.211145</td>\n",
       "      <td>117.218011</td>\n",
       "      <td>-3.006866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.394746</td>\n",
       "      <td>72.503556</td>\n",
       "      <td>3</td>\n",
       "      <td>0.108810</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.880846</td>\n",
       "      <td>0.119154</td>\n",
       "      <td>0.306491</td>\n",
       "      <td>0.693509</td>\n",
       "      <td>0.269971</td>\n",
       "      <td>0.57873</td>\n",
       "      <td>412.083642</td>\n",
       "      <td>30085.467842</td>\n",
       "      <td>412.083642</td>\n",
       "      <td>-0.230807</td>\n",
       "      <td>-0.207987</td>\n",
       "      <td>0.066193</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>38.632841</td>\n",
       "      <td>42.496126</td>\n",
       "      <td>1074.597433</td>\n",
       "      <td>10.927018</td>\n",
       "      <td>0.036520</td>\n",
       "      <td>0.386116</td>\n",
       "      <td>103.02091</td>\n",
       "      <td>7707.086742</td>\n",
       "      <td>103.02091</td>\n",
       "      <td>-0.589925</td>\n",
       "      <td>-0.195767</td>\n",
       "      <td>0.300879</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>32969.246241</td>\n",
       "      <td>85.594972</td>\n",
       "      <td>0.610874</td>\n",
       "      <td>0.485492</td>\n",
       "      <td>257.552276</td>\n",
       "      <td>18857.644451</td>\n",
       "      <td>257.552276</td>\n",
       "      <td>-0.438456</td>\n",
       "      <td>-0.138087</td>\n",
       "      <td>0.053657</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.179705</td>\n",
       "      <td>23.179705</td>\n",
       "      <td>74.624822</td>\n",
       "      <td>3.154358</td>\n",
       "      <td>0.082635</td>\n",
       "      <td>0.435554</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>3938.723717</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>-0.605130</td>\n",
       "      <td>-0.062250</td>\n",
       "      <td>0.366654</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>158.394650</td>\n",
       "      <td>158.394650</td>\n",
       "      <td>25088.865066</td>\n",
       "      <td>74.667954</td>\n",
       "      <td>72.394746</td>\n",
       "      <td>0.036520</td>\n",
       "      <td>0.082635</td>\n",
       "      <td>-0.046115</td>\n",
       "      <td>0.386116</td>\n",
       "      <td>0.435554</td>\n",
       "      <td>-0.049438</td>\n",
       "      <td>103.02091</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>7707.086742</td>\n",
       "      <td>3938.723717</td>\n",
       "      <td>3768.363025</td>\n",
       "      <td>103.02091</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>-0.589925</td>\n",
       "      <td>-0.605130</td>\n",
       "      <td>-0.015205</td>\n",
       "      <td>-0.195767</td>\n",
       "      <td>-0.062250</td>\n",
       "      <td>0.133517</td>\n",
       "      <td>0.300879</td>\n",
       "      <td>0.366654</td>\n",
       "      <td>-0.065775</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>-0.035714</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>-0.001099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>158.394650</td>\n",
       "      <td>34.769557</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>158.394650</td>\n",
       "      <td>34.769557</td>\n",
       "      <td>32969.246241</td>\n",
       "      <td>25088.865066</td>\n",
       "      <td>7880.381175</td>\n",
       "      <td>85.594972</td>\n",
       "      <td>74.667954</td>\n",
       "      <td>10.927018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.619121</td>\n",
       "      <td>93.966626</td>\n",
       "      <td>4</td>\n",
       "      <td>0.347504</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.792060</td>\n",
       "      <td>0.207940</td>\n",
       "      <td>0.744123</td>\n",
       "      <td>0.255877</td>\n",
       "      <td>0.589390</td>\n",
       "      <td>0.23715</td>\n",
       "      <td>721.146373</td>\n",
       "      <td>67881.765729</td>\n",
       "      <td>721.146373</td>\n",
       "      <td>-0.514662</td>\n",
       "      <td>0.009979</td>\n",
       "      <td>0.213624</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>374.738562</td>\n",
       "      <td>548.586348</td>\n",
       "      <td>140772.263712</td>\n",
       "      <td>76.462018</td>\n",
       "      <td>0.154733</td>\n",
       "      <td>0.267651</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>4881.332889</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>-0.371648</td>\n",
       "      <td>-0.488452</td>\n",
       "      <td>0.281322</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>370.875277</td>\n",
       "      <td>722.434134</td>\n",
       "      <td>179607.020941</td>\n",
       "      <td>95.838240</td>\n",
       "      <td>0.202670</td>\n",
       "      <td>0.261441</td>\n",
       "      <td>115.898524</td>\n",
       "      <td>11068.486835</td>\n",
       "      <td>115.898524</td>\n",
       "      <td>-0.315231</td>\n",
       "      <td>-0.190859</td>\n",
       "      <td>0.228041</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>243.386901</td>\n",
       "      <td>394.054982</td>\n",
       "      <td>37581.060223</td>\n",
       "      <td>42.932891</td>\n",
       "      <td>0.053207</td>\n",
       "      <td>0.296643</td>\n",
       "      <td>25.755228</td>\n",
       "      <td>2624.360536</td>\n",
       "      <td>25.755228</td>\n",
       "      <td>-0.006129</td>\n",
       "      <td>-0.614204</td>\n",
       "      <td>0.196741</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>204.754059</td>\n",
       "      <td>339.969004</td>\n",
       "      <td>29969.328407</td>\n",
       "      <td>38.681102</td>\n",
       "      <td>93.619121</td>\n",
       "      <td>0.154733</td>\n",
       "      <td>0.053207</td>\n",
       "      <td>0.101526</td>\n",
       "      <td>0.267651</td>\n",
       "      <td>0.296643</td>\n",
       "      <td>-0.028992</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>25.755228</td>\n",
       "      <td>25.755228</td>\n",
       "      <td>4881.332889</td>\n",
       "      <td>2624.360536</td>\n",
       "      <td>2256.972353</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>25.755228</td>\n",
       "      <td>25.755228</td>\n",
       "      <td>-0.371648</td>\n",
       "      <td>-0.006129</td>\n",
       "      <td>0.365519</td>\n",
       "      <td>-0.488452</td>\n",
       "      <td>-0.614204</td>\n",
       "      <td>-0.125752</td>\n",
       "      <td>0.281322</td>\n",
       "      <td>0.196741</td>\n",
       "      <td>0.084580</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>-0.089286</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>370.875277</td>\n",
       "      <td>204.754059</td>\n",
       "      <td>166.121218</td>\n",
       "      <td>722.434134</td>\n",
       "      <td>339.969004</td>\n",
       "      <td>382.465130</td>\n",
       "      <td>179607.020941</td>\n",
       "      <td>29969.328407</td>\n",
       "      <td>149637.692534</td>\n",
       "      <td>95.838240</td>\n",
       "      <td>38.681102</td>\n",
       "      <td>57.157137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96.403550</td>\n",
       "      <td>96.927111</td>\n",
       "      <td>5</td>\n",
       "      <td>0.523561</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.729156</td>\n",
       "      <td>0.270844</td>\n",
       "      <td>0.713900</td>\n",
       "      <td>0.286100</td>\n",
       "      <td>0.520545</td>\n",
       "      <td>0.181495</td>\n",
       "      <td>641.899519</td>\n",
       "      <td>62140.905745</td>\n",
       "      <td>641.899519</td>\n",
       "      <td>-0.184619</td>\n",
       "      <td>-0.505225</td>\n",
       "      <td>0.213782</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>540.859780</td>\n",
       "      <td>869.238931</td>\n",
       "      <td>173711.660024</td>\n",
       "      <td>62.355277</td>\n",
       "      <td>0.193355</td>\n",
       "      <td>0.271203</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>42.872316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.287724</td>\n",
       "      <td>-0.328897</td>\n",
       "      <td>0.332550</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>780.383396</td>\n",
       "      <td>1352.149449</td>\n",
       "      <td>537985.264820</td>\n",
       "      <td>102.299414</td>\n",
       "      <td>0.208611</td>\n",
       "      <td>0.204776</td>\n",
       "      <td>529.821825</td>\n",
       "      <td>51307.774233</td>\n",
       "      <td>529.821825</td>\n",
       "      <td>-0.056180</td>\n",
       "      <td>-0.326396</td>\n",
       "      <td>0.309232</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>440.414392</td>\n",
       "      <td>846.059227</td>\n",
       "      <td>219202.951351</td>\n",
       "      <td>64.734582</td>\n",
       "      <td>0.077488</td>\n",
       "      <td>0.273612</td>\n",
       "      <td>24.399689</td>\n",
       "      <td>2561.515198</td>\n",
       "      <td>24.399689</td>\n",
       "      <td>-0.173196</td>\n",
       "      <td>-0.354183</td>\n",
       "      <td>0.379833</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>521.543359</td>\n",
       "      <td>1039.223434</td>\n",
       "      <td>378183.671566</td>\n",
       "      <td>81.592146</td>\n",
       "      <td>96.403550</td>\n",
       "      <td>0.193355</td>\n",
       "      <td>0.077488</td>\n",
       "      <td>0.115867</td>\n",
       "      <td>0.271203</td>\n",
       "      <td>0.273612</td>\n",
       "      <td>-0.00241</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>24.399689</td>\n",
       "      <td>-24.399689</td>\n",
       "      <td>42.872316</td>\n",
       "      <td>2561.515198</td>\n",
       "      <td>-2518.642882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.399689</td>\n",
       "      <td>-24.399689</td>\n",
       "      <td>-0.287724</td>\n",
       "      <td>-0.173196</td>\n",
       "      <td>0.114528</td>\n",
       "      <td>-0.328897</td>\n",
       "      <td>-0.354183</td>\n",
       "      <td>-0.025286</td>\n",
       "      <td>0.332550</td>\n",
       "      <td>0.379833</td>\n",
       "      <td>-0.047283</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>-0.053571</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>-0.000715</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>780.383396</td>\n",
       "      <td>521.543359</td>\n",
       "      <td>258.840037</td>\n",
       "      <td>1352.149449</td>\n",
       "      <td>1039.223434</td>\n",
       "      <td>312.926015</td>\n",
       "      <td>537985.264820</td>\n",
       "      <td>378183.671566</td>\n",
       "      <td>159801.593254</td>\n",
       "      <td>102.299414</td>\n",
       "      <td>81.592146</td>\n",
       "      <td>20.707268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>97.562339</td>\n",
       "      <td>97.859862</td>\n",
       "      <td>6</td>\n",
       "      <td>0.297523</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.339263</td>\n",
       "      <td>0.660737</td>\n",
       "      <td>0.727668</td>\n",
       "      <td>0.272332</td>\n",
       "      <td>0.246871</td>\n",
       "      <td>0.19915</td>\n",
       "      <td>185.437639</td>\n",
       "      <td>18333.947462</td>\n",
       "      <td>185.437639</td>\n",
       "      <td>-0.444081</td>\n",
       "      <td>-0.189396</td>\n",
       "      <td>0.243712</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>262.703322</td>\n",
       "      <td>521.543359</td>\n",
       "      <td>118623.616623</td>\n",
       "      <td>79.201094</td>\n",
       "      <td>0.480797</td>\n",
       "      <td>0.230922</td>\n",
       "      <td>216.343912</td>\n",
       "      <td>21349.622071</td>\n",
       "      <td>216.343912</td>\n",
       "      <td>-0.463511</td>\n",
       "      <td>-0.146215</td>\n",
       "      <td>0.196775</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>216.343912</td>\n",
       "      <td>421.097971</td>\n",
       "      <td>57908.861663</td>\n",
       "      <td>67.071108</td>\n",
       "      <td>0.092392</td>\n",
       "      <td>0.190514</td>\n",
       "      <td>-46.35941</td>\n",
       "      <td>-4322.244948</td>\n",
       "      <td>46.35941</td>\n",
       "      <td>-0.198911</td>\n",
       "      <td>-0.114868</td>\n",
       "      <td>0.155605</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>131.351661</td>\n",
       "      <td>224.070480</td>\n",
       "      <td>27521.634254</td>\n",
       "      <td>35.365407</td>\n",
       "      <td>0.179940</td>\n",
       "      <td>0.2616</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>1712.967554</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>-0.216538</td>\n",
       "      <td>-0.174607</td>\n",
       "      <td>0.292429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>212.480628</td>\n",
       "      <td>421.097971</td>\n",
       "      <td>129593.465417</td>\n",
       "      <td>68.598047</td>\n",
       "      <td>97.562339</td>\n",
       "      <td>0.246871</td>\n",
       "      <td>0.092392</td>\n",
       "      <td>0.154479</td>\n",
       "      <td>0.19915</td>\n",
       "      <td>0.190514</td>\n",
       "      <td>0.008636</td>\n",
       "      <td>185.437639</td>\n",
       "      <td>-46.35941</td>\n",
       "      <td>139.078229</td>\n",
       "      <td>18333.947462</td>\n",
       "      <td>-4322.244948</td>\n",
       "      <td>14011.702514</td>\n",
       "      <td>185.437639</td>\n",
       "      <td>46.35941</td>\n",
       "      <td>139.078229</td>\n",
       "      <td>-0.444081</td>\n",
       "      <td>-0.198911</td>\n",
       "      <td>0.245170</td>\n",
       "      <td>-0.189396</td>\n",
       "      <td>-0.114868</td>\n",
       "      <td>0.074528</td>\n",
       "      <td>0.243712</td>\n",
       "      <td>0.155605</td>\n",
       "      <td>0.088107</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>-0.017857</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>262.703322</td>\n",
       "      <td>131.351661</td>\n",
       "      <td>131.351661</td>\n",
       "      <td>521.543359</td>\n",
       "      <td>224.070480</td>\n",
       "      <td>297.472879</td>\n",
       "      <td>118623.616623</td>\n",
       "      <td>27521.634254</td>\n",
       "      <td>91101.982369</td>\n",
       "      <td>79.201094</td>\n",
       "      <td>35.365407</td>\n",
       "      <td>43.835687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>2528.653666</td>\n",
       "      <td>2528.769788</td>\n",
       "      <td>730</td>\n",
       "      <td>0.116122</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.201323</td>\n",
       "      <td>0.798677</td>\n",
       "      <td>0.455818</td>\n",
       "      <td>0.544182</td>\n",
       "      <td>0.091767</td>\n",
       "      <td>0.560355</td>\n",
       "      <td>206.041821</td>\n",
       "      <td>521250.880835</td>\n",
       "      <td>206.041821</td>\n",
       "      <td>-0.503169</td>\n",
       "      <td>-0.292843</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>23.179705</td>\n",
       "      <td>432.823966</td>\n",
       "      <td>7.938294</td>\n",
       "      <td>0.364051</td>\n",
       "      <td>0.364052</td>\n",
       "      <td>-463.594097</td>\n",
       "      <td>-1172081.166916</td>\n",
       "      <td>463.594097</td>\n",
       "      <td>-0.063607</td>\n",
       "      <td>-0.422195</td>\n",
       "      <td>0.108316</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>46.359410</td>\n",
       "      <td>69.539115</td>\n",
       "      <td>3880.490730</td>\n",
       "      <td>27.499058</td>\n",
       "      <td>0.109556</td>\n",
       "      <td>0.694673</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>130457.875507</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>-0.332933</td>\n",
       "      <td>-0.034595</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>14.924964</td>\n",
       "      <td>1.821170</td>\n",
       "      <td>0.434625</td>\n",
       "      <td>0.595968</td>\n",
       "      <td>257.552276</td>\n",
       "      <td>651480.446388</td>\n",
       "      <td>257.552276</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>-0.327778</td>\n",
       "      <td>0.035771</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>29.849929</td>\n",
       "      <td>1.821170</td>\n",
       "      <td>2528.653666</td>\n",
       "      <td>0.091767</td>\n",
       "      <td>0.109556</td>\n",
       "      <td>-0.017790</td>\n",
       "      <td>0.560355</td>\n",
       "      <td>0.694673</td>\n",
       "      <td>-0.134318</td>\n",
       "      <td>206.041821</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>154.531366</td>\n",
       "      <td>521250.880835</td>\n",
       "      <td>130457.875507</td>\n",
       "      <td>390793.005328</td>\n",
       "      <td>206.041821</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>154.531366</td>\n",
       "      <td>-0.503169</td>\n",
       "      <td>-0.332933</td>\n",
       "      <td>0.170236</td>\n",
       "      <td>-0.292843</td>\n",
       "      <td>-0.034595</td>\n",
       "      <td>0.258249</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>0.027163</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>23.179705</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>432.823966</td>\n",
       "      <td>14.924964</td>\n",
       "      <td>417.899002</td>\n",
       "      <td>7.938294</td>\n",
       "      <td>1.821170</td>\n",
       "      <td>6.117125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>2530.589578</td>\n",
       "      <td>2530.846366</td>\n",
       "      <td>731</td>\n",
       "      <td>0.256788</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.485588</td>\n",
       "      <td>0.514412</td>\n",
       "      <td>0.247997</td>\n",
       "      <td>0.752003</td>\n",
       "      <td>0.120425</td>\n",
       "      <td>0.369944</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>130596.228055</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>0.268528</td>\n",
       "      <td>-0.403955</td>\n",
       "      <td>0.343002</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>339.969004</td>\n",
       "      <td>660.621588</td>\n",
       "      <td>284753.394759</td>\n",
       "      <td>103.472426</td>\n",
       "      <td>0.127573</td>\n",
       "      <td>0.189032</td>\n",
       "      <td>103.02091</td>\n",
       "      <td>260952.556302</td>\n",
       "      <td>103.02091</td>\n",
       "      <td>0.432141</td>\n",
       "      <td>-0.276293</td>\n",
       "      <td>0.246721</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>258.840037</td>\n",
       "      <td>475.183949</td>\n",
       "      <td>120981.760990</td>\n",
       "      <td>87.790534</td>\n",
       "      <td>0.365163</td>\n",
       "      <td>0.346028</td>\n",
       "      <td>17.170152</td>\n",
       "      <td>43655.951904</td>\n",
       "      <td>17.170152</td>\n",
       "      <td>0.063218</td>\n",
       "      <td>-0.311708</td>\n",
       "      <td>0.351750</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>262.703322</td>\n",
       "      <td>455.867529</td>\n",
       "      <td>106131.421465</td>\n",
       "      <td>67.235451</td>\n",
       "      <td>0.386839</td>\n",
       "      <td>0.235762</td>\n",
       "      <td>68.680607</td>\n",
       "      <td>174016.143436</td>\n",
       "      <td>68.680607</td>\n",
       "      <td>0.226795</td>\n",
       "      <td>-0.137310</td>\n",
       "      <td>0.217608</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>150.668081</td>\n",
       "      <td>282.019742</td>\n",
       "      <td>62237.101323</td>\n",
       "      <td>51.738884</td>\n",
       "      <td>2530.589578</td>\n",
       "      <td>0.120425</td>\n",
       "      <td>0.365163</td>\n",
       "      <td>-0.244739</td>\n",
       "      <td>0.369944</td>\n",
       "      <td>0.346028</td>\n",
       "      <td>0.023917</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>17.170152</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>130596.228055</td>\n",
       "      <td>43655.951904</td>\n",
       "      <td>86940.27615</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>17.170152</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>0.268528</td>\n",
       "      <td>0.063218</td>\n",
       "      <td>0.205310</td>\n",
       "      <td>-0.403955</td>\n",
       "      <td>-0.311708</td>\n",
       "      <td>0.092247</td>\n",
       "      <td>0.343002</td>\n",
       "      <td>0.351750</td>\n",
       "      <td>-0.008748</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>-0.053571</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>-0.001315</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>339.969004</td>\n",
       "      <td>262.703322</td>\n",
       "      <td>77.265683</td>\n",
       "      <td>660.621588</td>\n",
       "      <td>455.867529</td>\n",
       "      <td>204.754059</td>\n",
       "      <td>284753.394759</td>\n",
       "      <td>106131.421465</td>\n",
       "      <td>178621.973294</td>\n",
       "      <td>103.472426</td>\n",
       "      <td>67.235451</td>\n",
       "      <td>36.236975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>2531.245726</td>\n",
       "      <td>2531.531176</td>\n",
       "      <td>732</td>\n",
       "      <td>0.285450</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.750465</td>\n",
       "      <td>0.249535</td>\n",
       "      <td>0.567721</td>\n",
       "      <td>0.432279</td>\n",
       "      <td>0.426055</td>\n",
       "      <td>0.438314</td>\n",
       "      <td>-46.35941</td>\n",
       "      <td>-117115.463869</td>\n",
       "      <td>46.35941</td>\n",
       "      <td>-0.274683</td>\n",
       "      <td>0.139567</td>\n",
       "      <td>0.184138</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>394.054982</td>\n",
       "      <td>131876.984962</td>\n",
       "      <td>73.117181</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.272908</td>\n",
       "      <td>-30.906273</td>\n",
       "      <td>-77995.721549</td>\n",
       "      <td>30.906273</td>\n",
       "      <td>-0.399121</td>\n",
       "      <td>0.260018</td>\n",
       "      <td>0.353834</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>382.465130</td>\n",
       "      <td>757.203691</td>\n",
       "      <td>268485.183622</td>\n",
       "      <td>98.643194</td>\n",
       "      <td>0.324410</td>\n",
       "      <td>0.40341</td>\n",
       "      <td>-15.453137</td>\n",
       "      <td>-38910.748786</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>-0.200046</td>\n",
       "      <td>-0.014375</td>\n",
       "      <td>0.195847</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>142.941513</td>\n",
       "      <td>282.019742</td>\n",
       "      <td>31670.774342</td>\n",
       "      <td>38.534202</td>\n",
       "      <td>0.107869</td>\n",
       "      <td>0.309856</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>208.993534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.474011</td>\n",
       "      <td>0.068312</td>\n",
       "      <td>0.375597</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>328.379152</td>\n",
       "      <td>540.859780</td>\n",
       "      <td>150234.691108</td>\n",
       "      <td>75.289451</td>\n",
       "      <td>2531.245726</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.107869</td>\n",
       "      <td>0.033798</td>\n",
       "      <td>0.272908</td>\n",
       "      <td>0.309856</td>\n",
       "      <td>-0.036948</td>\n",
       "      <td>-30.906273</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>30.906273</td>\n",
       "      <td>-77995.721549</td>\n",
       "      <td>208.993534</td>\n",
       "      <td>77786.728015</td>\n",
       "      <td>30.906273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.906273</td>\n",
       "      <td>-0.399121</td>\n",
       "      <td>-0.474011</td>\n",
       "      <td>-0.074890</td>\n",
       "      <td>0.260018</td>\n",
       "      <td>0.068312</td>\n",
       "      <td>0.191706</td>\n",
       "      <td>0.353834</td>\n",
       "      <td>0.375597</td>\n",
       "      <td>-0.021764</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>-0.001608</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>382.465130</td>\n",
       "      <td>328.379152</td>\n",
       "      <td>54.085978</td>\n",
       "      <td>757.203691</td>\n",
       "      <td>540.859780</td>\n",
       "      <td>216.343912</td>\n",
       "      <td>268485.183622</td>\n",
       "      <td>150234.691108</td>\n",
       "      <td>118250.492514</td>\n",
       "      <td>98.643194</td>\n",
       "      <td>75.289451</td>\n",
       "      <td>23.353743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>2533.065332</td>\n",
       "      <td>2533.145388</td>\n",
       "      <td>734</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.721732</td>\n",
       "      <td>0.278268</td>\n",
       "      <td>0.784716</td>\n",
       "      <td>0.215284</td>\n",
       "      <td>0.566355</td>\n",
       "      <td>0.670564</td>\n",
       "      <td>-77.265683</td>\n",
       "      <td>-195487.815048</td>\n",
       "      <td>77.265683</td>\n",
       "      <td>0.025602</td>\n",
       "      <td>-0.167074</td>\n",
       "      <td>0.009026</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>14.924964</td>\n",
       "      <td>1.931642</td>\n",
       "      <td>0.218361</td>\n",
       "      <td>0.582913</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>587399.864669</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>-0.414762</td>\n",
       "      <td>0.037655</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.589852</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>238.799430</td>\n",
       "      <td>7.726568</td>\n",
       "      <td>0.155377</td>\n",
       "      <td>0.65263</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>205.13025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.054841</td>\n",
       "      <td>0.143237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059906</td>\n",
       "      <td>0.683487</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>205.13025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.074826</td>\n",
       "      <td>0.543460</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.726568</td>\n",
       "      <td>59.699857</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>2533.065332</td>\n",
       "      <td>0.218361</td>\n",
       "      <td>0.059906</td>\n",
       "      <td>0.158455</td>\n",
       "      <td>0.582913</td>\n",
       "      <td>0.683487</td>\n",
       "      <td>-0.100574</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>587399.864669</td>\n",
       "      <td>205.13025</td>\n",
       "      <td>587194.734419</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>-0.414762</td>\n",
       "      <td>-0.074826</td>\n",
       "      <td>0.339935</td>\n",
       "      <td>0.037655</td>\n",
       "      <td>0.543460</td>\n",
       "      <td>-0.505805</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.589852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.589852</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>7.726568</td>\n",
       "      <td>7.726568</td>\n",
       "      <td>238.799430</td>\n",
       "      <td>59.699857</td>\n",
       "      <td>179.099572</td>\n",
       "      <td>7.726568</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>3.863284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>2534.629471</td>\n",
       "      <td>2534.717361</td>\n",
       "      <td>735</td>\n",
       "      <td>0.087890</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.999041</td>\n",
       "      <td>0.744875</td>\n",
       "      <td>0.255125</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.34638</td>\n",
       "      <td>-386.328414</td>\n",
       "      <td>-979006.808985</td>\n",
       "      <td>386.328414</td>\n",
       "      <td>-0.651693</td>\n",
       "      <td>0.065094</td>\n",
       "      <td>0.315923</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>127.488377</td>\n",
       "      <td>135.214945</td>\n",
       "      <td>18283.081324</td>\n",
       "      <td>67.607472</td>\n",
       "      <td>0.744161</td>\n",
       "      <td>0.616999</td>\n",
       "      <td>695.391145</td>\n",
       "      <td>1762753.39663</td>\n",
       "      <td>695.391145</td>\n",
       "      <td>-0.835117</td>\n",
       "      <td>-0.151596</td>\n",
       "      <td>0.081237</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.769557</td>\n",
       "      <td>34.769557</td>\n",
       "      <td>134.324679</td>\n",
       "      <td>5.794926</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.327176</td>\n",
       "      <td>77.265683</td>\n",
       "      <td>196011.203226</td>\n",
       "      <td>77.265683</td>\n",
       "      <td>-0.177017</td>\n",
       "      <td>0.138727</td>\n",
       "      <td>0.295112</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>81.128967</td>\n",
       "      <td>84.992251</td>\n",
       "      <td>7223.682744</td>\n",
       "      <td>42.496126</td>\n",
       "      <td>0.254881</td>\n",
       "      <td>0.681812</td>\n",
       "      <td>386.328414</td>\n",
       "      <td>979382.299928</td>\n",
       "      <td>386.328414</td>\n",
       "      <td>-0.806843</td>\n",
       "      <td>-0.279302</td>\n",
       "      <td>0.067071</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>134.324679</td>\n",
       "      <td>5.794926</td>\n",
       "      <td>2534.629471</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.34638</td>\n",
       "      <td>0.327176</td>\n",
       "      <td>0.019204</td>\n",
       "      <td>-386.328414</td>\n",
       "      <td>77.265683</td>\n",
       "      <td>309.062731</td>\n",
       "      <td>-979006.808985</td>\n",
       "      <td>196011.203226</td>\n",
       "      <td>782995.605759</td>\n",
       "      <td>386.328414</td>\n",
       "      <td>77.265683</td>\n",
       "      <td>309.062731</td>\n",
       "      <td>-0.651693</td>\n",
       "      <td>-0.177017</td>\n",
       "      <td>0.474676</td>\n",
       "      <td>0.065094</td>\n",
       "      <td>0.138727</td>\n",
       "      <td>-0.073633</td>\n",
       "      <td>0.315923</td>\n",
       "      <td>0.295112</td>\n",
       "      <td>0.020811</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>-0.017857</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>127.488377</td>\n",
       "      <td>81.128967</td>\n",
       "      <td>46.359410</td>\n",
       "      <td>135.214945</td>\n",
       "      <td>84.992251</td>\n",
       "      <td>50.222694</td>\n",
       "      <td>18283.081324</td>\n",
       "      <td>7223.682744</td>\n",
       "      <td>11059.398580</td>\n",
       "      <td>67.607472</td>\n",
       "      <td>42.496126</td>\n",
       "      <td>25.111347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>2549.650222</td>\n",
       "      <td>2549.918746</td>\n",
       "      <td>736</td>\n",
       "      <td>0.268523</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.524635</td>\n",
       "      <td>0.475365</td>\n",
       "      <td>0.660308</td>\n",
       "      <td>0.339692</td>\n",
       "      <td>0.346421</td>\n",
       "      <td>0.336876</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>87784.501574</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>-0.246209</td>\n",
       "      <td>-0.341970</td>\n",
       "      <td>0.184539</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>355.422141</td>\n",
       "      <td>78191.888209</td>\n",
       "      <td>73.368502</td>\n",
       "      <td>0.313887</td>\n",
       "      <td>0.22545</td>\n",
       "      <td>171.701517</td>\n",
       "      <td>438016.994619</td>\n",
       "      <td>171.701517</td>\n",
       "      <td>-0.158380</td>\n",
       "      <td>-0.344914</td>\n",
       "      <td>0.340996</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>367.011993</td>\n",
       "      <td>656.758304</td>\n",
       "      <td>208680.851487</td>\n",
       "      <td>99.011647</td>\n",
       "      <td>0.178214</td>\n",
       "      <td>0.244281</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>87757.458585</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>-0.109581</td>\n",
       "      <td>-0.355186</td>\n",
       "      <td>0.447139</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>579.492621</td>\n",
       "      <td>169965.493973</td>\n",
       "      <td>74.690160</td>\n",
       "      <td>0.161478</td>\n",
       "      <td>0.353176</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>87761.321869</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>-0.178466</td>\n",
       "      <td>-0.173398</td>\n",
       "      <td>0.247417</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>320.652584</td>\n",
       "      <td>82788.777228</td>\n",
       "      <td>53.358854</td>\n",
       "      <td>2549.650222</td>\n",
       "      <td>0.313887</td>\n",
       "      <td>0.161478</td>\n",
       "      <td>0.152410</td>\n",
       "      <td>0.22545</td>\n",
       "      <td>0.353176</td>\n",
       "      <td>-0.127726</td>\n",
       "      <td>171.701517</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>137.361214</td>\n",
       "      <td>438016.994619</td>\n",
       "      <td>87761.321869</td>\n",
       "      <td>350255.67275</td>\n",
       "      <td>171.701517</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>137.361214</td>\n",
       "      <td>-0.158380</td>\n",
       "      <td>-0.178466</td>\n",
       "      <td>-0.020085</td>\n",
       "      <td>-0.344914</td>\n",
       "      <td>-0.173398</td>\n",
       "      <td>0.171516</td>\n",
       "      <td>0.340996</td>\n",
       "      <td>0.247417</td>\n",
       "      <td>0.093579</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>367.011993</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>173.847786</td>\n",
       "      <td>656.758304</td>\n",
       "      <td>320.652584</td>\n",
       "      <td>336.105720</td>\n",
       "      <td>208680.851487</td>\n",
       "      <td>82788.777228</td>\n",
       "      <td>125892.074259</td>\n",
       "      <td>99.011647</td>\n",
       "      <td>53.358854</td>\n",
       "      <td>45.652793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           start         stop label  duration  is_user_annotated_epoch  is_valid_epoch      P_LR      P_RL    P_Long   P_Short  P_Long_LR score_long_LR velocity_long_LR intercept_long_LR speed_long_LR  wcorr_long_LR  pearsonr_long_LR  travel_long_LR  coverage_long_LR  jump_long_LR  longest_sequence_length_ratio_long_LR  direction_change_bin_ratio_long_LR  congruent_dir_bins_ratio_long_LR  total_congruent_direction_change_long_LR  total_variation_long_LR  integral_second_derivative_long_LR  stddev_of_diff_long_LR  P_Long_RL score_long_RL velocity_long_RL intercept_long_RL speed_long_RL  wcorr_long_RL  pearsonr_long_RL  travel_long_RL  coverage_long_RL  jump_long_RL  longest_sequence_length_ratio_long_RL  direction_change_bin_ratio_long_RL  congruent_dir_bins_ratio_long_RL  total_congruent_direction_change_long_RL  total_variation_long_RL  integral_second_derivative_long_RL  stddev_of_diff_long_RL  P_Short_LR score_short_LR velocity_short_LR intercept_short_LR speed_short_LR  \\\n",
       "0      55.469478    55.668144     1  0.198666                    False            True  0.279922  0.720078  0.747300  0.252700   0.209186      0.218418       231.797048      13108.185152    231.797048      -0.176375               NaN        0.385125          0.464286      0.003908                               0.571429                            0.333333                          0.500000                                351.558857               494.500370                       101101.708481              110.807358   0.538114      0.177541       566.615007      31672.957977    566.615007      -0.423041               NaN        0.490432          0.339286      0.003314                               0.285714                            0.666667                          0.666667                                413.371403               629.715315                       165443.229777              105.700424    0.070736       0.199763        309.062731        17248.23328     309.062731   \n",
       "1      70.728617    70.977971     2  0.249354                    False            True  0.723395  0.276605  0.292040  0.707960   0.211260      0.235102        96.582103       7072.225651     96.582103      -0.280497         -0.203513        0.264021          0.392857      0.003229                               0.333333                            0.625000                          0.375000                                235.660333               452.004244                       100519.634871               70.231528   0.080780      0.188198        19.316421       1614.091544     19.316421      -0.380997         -0.157490        0.449062          0.339286      0.003993                               0.444444                            0.500000                          0.625000                                486.773802               768.793544                       284648.920009              114.211145    0.512135       0.278974         38.632841        2938.060587      38.632841   \n",
       "2      72.394746    72.503556     3  0.108810                    False           False  0.880846  0.119154  0.306491  0.693509   0.269971       0.57873       412.083642      30085.467842    412.083642      -0.230807         -0.207987        0.066193          0.214286      0.000425                               1.000000                            0.000000                          0.666667                                 38.632841                42.496126                         1074.597433               10.927018   0.036520      0.386116        103.02091       7707.086742     103.02091      -0.589925         -0.195767        0.300879          0.196429      0.004078                               1.000000                            0.000000                          1.000000                                193.164207               193.164207                        32969.246241               85.594972    0.610874       0.485492        257.552276       18857.644451     257.552276   \n",
       "3      93.619121    93.966626     4  0.347504                    False            True  0.792060  0.207940  0.744123  0.255877   0.589390       0.23715       721.146373      67881.765729    721.146373      -0.514662          0.009979        0.213624          0.267857      0.003823                               0.461538                            0.166667                          0.583333                                374.738562               548.586348                       140772.263712               76.462018   0.154733      0.267651        51.510455       4881.332889     51.510455      -0.371648         -0.488452        0.281322          0.196429      0.004248                               0.384615                            0.250000                          0.416667                                370.875277               722.434134                       179607.020941               95.838240    0.202670       0.261441        115.898524       11068.486835     115.898524   \n",
       "4      96.403550    96.927111     5  0.523561                    False            True  0.729156  0.270844  0.713900  0.286100   0.520545      0.181495       641.899519      62140.905745    641.899519      -0.184619         -0.505225        0.213782          0.410714      0.003314                               0.350000                            0.421053                          0.631579                                540.859780               869.238931                       173711.660024               62.355277   0.193355      0.271203             -0.0         42.872316           0.0      -0.287724         -0.328897        0.332550          0.250000      0.004588                               0.350000                            0.421053                          0.473684                                780.383396              1352.149449                       537985.264820              102.299414    0.208611       0.204776        529.821825       51307.774233     529.821825   \n",
       "5      97.562339    97.859862     6  0.297523                    False            True  0.339263  0.660737  0.727668  0.272332   0.246871       0.19915       185.437639      18333.947462    185.437639      -0.444081         -0.189396        0.243712          0.267857      0.003653                               0.363636                            0.500000                          0.300000                                262.703322               521.543359                       118623.616623               79.201094   0.480797      0.230922       216.343912      21349.622071    216.343912      -0.463511         -0.146215        0.196775          0.321429      0.003653                               0.363636                            0.300000                          0.300000                                216.343912               421.097971                        57908.861663               67.071108    0.092392       0.190514         -46.35941       -4322.244948       46.35941   \n",
       "..           ...          ...   ...       ...                      ...             ...       ...       ...       ...       ...        ...           ...              ...               ...           ...            ...               ...             ...               ...           ...                                    ...                                 ...                               ...                                       ...                      ...                                 ...                     ...        ...           ...              ...               ...           ...            ...               ...             ...               ...           ...                                    ...                                 ...                               ...                                       ...                      ...                                 ...                     ...         ...            ...               ...                ...            ...   \n",
       "701  2528.653666  2528.769788   730  0.116122                    False           False  0.201323  0.798677  0.455818  0.544182   0.091767      0.560355       206.041821     521250.880835    206.041821      -0.503169         -0.292843        0.036105          0.196429      0.000340                               1.000000                            0.000000                          0.666667                                 19.316421                23.179705                          432.823966                7.938294   0.364051      0.364052      -463.594097   -1172081.166916    463.594097      -0.063607         -0.422195        0.108316          0.267857      0.001020                               0.500000                            0.333333                          0.333333                                 46.359410                69.539115                         3880.490730               27.499058    0.109556       0.694673         51.510455      130457.875507      51.510455   \n",
       "702  2530.589578  2530.846366   731  0.256788                    False           False  0.485588  0.514412  0.247997  0.752003   0.120425      0.369944        51.510455     130596.228055     51.510455       0.268528         -0.403955        0.343002          0.178571      0.003483                               0.400000                            0.444444                          0.555556                                339.969004               660.621588                       284753.394759              103.472426   0.127573      0.189032        103.02091     260952.556302     103.02091       0.432141         -0.276293        0.246721          0.303571      0.004673                               0.500000                            0.444444                          0.333333                                258.840037               475.183949                       120981.760990               87.790534    0.365163       0.346028         17.170152       43655.951904      17.170152   \n",
       "703  2531.245726  2531.531176   732  0.285450                    False           False  0.750465  0.249535  0.567721  0.432279   0.426055      0.438314        -46.35941    -117115.463869      46.35941      -0.274683          0.139567        0.184138          0.142857      0.003568                               0.272727                            0.500000                          0.200000                                  0.000000               394.054982                       131876.984962               73.117181   0.141667      0.272908       -30.906273     -77995.721549     30.906273      -0.399121          0.260018        0.353834          0.232143      0.003568                               0.363636                            0.500000                          0.500000                                382.465130               757.203691                       268485.183622               98.643194    0.324410        0.40341        -15.453137      -38910.748786      15.453137   \n",
       "704  2533.065332  2533.145388   734  0.080056                    False           False  0.721732  0.278268  0.784716  0.215284   0.566355      0.670564       -77.265683    -195487.815048     77.265683       0.025602         -0.167074        0.009026          0.142857      0.000085                               1.000000                            0.000000                          0.500000                                  3.863284                 3.863284                           14.924964                1.931642   0.218361      0.582913       231.797048     587399.864669    231.797048      -0.414762          0.037655        0.036105          0.178571      0.000255                               1.000000                            0.000000                          0.500000                                 11.589852                15.453137                          238.799430                7.726568    0.155377        0.65263              -0.0          205.13025            0.0   \n",
       "705  2534.629471  2534.717361   735  0.087890                    False           False  0.000959  0.999041  0.744875  0.255125   0.000714       0.34638      -386.328414    -979006.808985    386.328414      -0.651693          0.065094        0.315923          0.178571      0.002804                               0.666667                            0.500000                          0.500000                                127.488377               135.214945                        18283.081324               67.607472   0.744161      0.616999       695.391145     1762753.39663    695.391145      -0.835117         -0.151596        0.081237          0.232143      0.000510                               1.000000                            0.000000                          1.000000                                 34.769557                34.769557                          134.324679                5.794926    0.000245       0.327176         77.265683      196011.203226      77.265683   \n",
       "706  2549.650222  2549.918746   736  0.268523                    False            True  0.524635  0.475365  0.660308  0.339692   0.346421      0.336876        34.340303      87784.501574     34.340303      -0.246209         -0.341970        0.184539          0.196429      0.003483                               0.500000                            0.333333                          0.444444                                  0.000000               355.422141                        78191.888209               73.368502   0.313887       0.22545       171.701517     438016.994619    171.701517      -0.158380         -0.344914        0.340996          0.250000      0.004163                               0.300000                            0.555556                          0.444444                                367.011993               656.758304                       208680.851487               99.011647    0.178214       0.244281         34.340303       87757.458585      34.340303   \n",
       "\n",
       "     wcorr_short_LR  pearsonr_short_LR  travel_short_LR  coverage_short_LR  jump_short_LR  longest_sequence_length_ratio_short_LR  direction_change_bin_ratio_short_LR  congruent_dir_bins_ratio_short_LR  total_congruent_direction_change_short_LR  total_variation_short_LR  integral_second_derivative_short_LR  stddev_of_diff_short_LR  P_Short_RL score_short_RL velocity_short_RL intercept_short_RL speed_short_RL  wcorr_short_RL  pearsonr_short_RL  travel_short_RL  coverage_short_RL  jump_short_RL  longest_sequence_length_ratio_short_RL  direction_change_bin_ratio_short_RL  congruent_dir_bins_ratio_short_RL  total_congruent_direction_change_short_RL  total_variation_short_RL  integral_second_derivative_short_RL  stddev_of_diff_short_RL  ripple_start_t  long_best_P_decoder  short_best_P_decoder  P_decoder_diff long_best_score short_best_score score_diff long_best_velocity short_best_velocity velocity_diff long_best_intercept short_best_intercept intercept_diff long_best_speed  \\\n",
       "0         -0.076130                NaN         0.397954           0.428571       0.004924                                0.571429                             0.166667                           0.500000                                 193.164207                343.832288                         27775.358648                78.302352    0.181964       0.202055        1287.76138       71768.577533     1287.76138       -0.059093                NaN         0.630467           0.410714       0.004924                                0.428571                             0.500000                           0.666667                                 297.472879                544.723064                        129638.240310                98.151158       55.469478             0.209186              0.070736        0.138450        0.218418         0.199763   0.018655         231.797048          309.062731    -77.265683        13108.185152          17248.23328   -4140.048128      231.797048   \n",
       "1         -0.124122           0.101345         0.281698           0.285714       0.003409                                0.222222                             0.625000                           0.500000                                 169.984502                324.515868                         66147.441982                52.652750    0.195825       0.256928         38.632841        2945.787156      38.632841        0.143256           0.106136         0.680770           0.267857       0.006692                                0.222222                             0.625000                           0.625000                                 394.054982                784.246680                        321856.856124               117.218011       70.728617             0.080780              0.195825       -0.115046        0.188198         0.256928   -0.06873          19.316421           38.632841    -19.316421         1614.091544          2945.787156   -1331.695612       19.316421   \n",
       "2         -0.438456          -0.138087         0.053657           0.250000       0.000379                                1.000000                             0.000000                           1.000000                                  23.179705                 23.179705                            74.624822                 3.154358    0.082635       0.435554         51.510455        3938.723717      51.510455       -0.605130          -0.062250         0.366654           0.232143       0.005177                                1.000000                             0.000000                           0.333333                                 158.394650                158.394650                         25088.865066                74.667954       72.394746             0.036520              0.082635       -0.046115        0.386116         0.435554  -0.049438          103.02091           51.510455     51.510455         7707.086742          3938.723717    3768.363025       103.02091   \n",
       "3         -0.315231          -0.190859         0.228041           0.375000       0.002778                                0.461538                             0.250000                           0.583333                                 243.386901                394.054982                         37581.060223                42.932891    0.053207       0.296643         25.755228        2624.360536      25.755228       -0.006129          -0.614204         0.196741           0.285714       0.002652                                0.461538                             0.333333                           0.333333                                 204.754059                339.969004                         29969.328407                38.681102       93.619121             0.154733              0.053207        0.101526        0.267651         0.296643  -0.028992          51.510455           25.755228     25.755228         4881.332889          2624.360536    2256.972353       51.510455   \n",
       "4         -0.056180          -0.326396         0.309232           0.321429       0.006187                                0.250000                             0.421053                           0.315789                                 440.414392                846.059227                        219202.951351                64.734582    0.077488       0.273612         24.399689        2561.515198      24.399689       -0.173196          -0.354183         0.379833           0.303571       0.005303                                0.250000                             0.473684                           0.421053                                 521.543359               1039.223434                        378183.671566                81.592146       96.403550             0.193355              0.077488        0.115867        0.271203         0.273612   -0.00241               -0.0           24.399689    -24.399689           42.872316          2561.515198   -2518.642882             0.0   \n",
       "5         -0.198911          -0.114868         0.155605           0.285714       0.003157                                0.454545                             0.300000                           0.300000                                 131.351661                224.070480                         27521.634254                35.365407    0.179940         0.2616         15.453137        1712.967554      15.453137       -0.216538          -0.174607         0.292429           0.285714       0.004924                                0.454545                             0.400000                           0.200000                                 212.480628                421.097971                        129593.465417                68.598047       97.562339             0.246871              0.092392        0.154479         0.19915         0.190514   0.008636         185.437639           -46.35941    139.078229        18333.947462         -4322.244948   14011.702514      185.437639   \n",
       "..              ...                ...              ...                ...            ...                                     ...                                  ...                                ...                                        ...                       ...                                  ...                      ...         ...            ...               ...                ...            ...             ...                ...              ...                ...            ...                                     ...                                  ...                                ...                                        ...                       ...                                  ...                      ...             ...                  ...                   ...             ...             ...              ...        ...                ...                 ...           ...                 ...                  ...            ...             ...   \n",
       "701       -0.332933          -0.034595         0.008943           0.125000       0.000126                                1.000000                             0.000000                           0.333333                                   3.863284                  3.863284                            14.924964                 1.821170    0.434625       0.595968        257.552276      651480.446388     257.552276        0.075822          -0.327778         0.035771           0.160714       0.000253                                1.000000                             0.000000                           1.000000                                  15.453137                 15.453137                            29.849929                 1.821170     2528.653666             0.091767              0.109556       -0.017790        0.560355         0.694673  -0.134318         206.041821           51.510455    154.531366       521250.880835        130457.875507  390793.005328      206.041821   \n",
       "702        0.063218          -0.311708         0.351750           0.232143       0.004798                                0.400000                             0.444444                           0.555556                                 262.703322                455.867529                        106131.421465                67.235451    0.386839       0.235762         68.680607      174016.143436      68.680607        0.226795          -0.137310         0.217608           0.250000       0.003914                                0.400000                             0.444444                           0.444444                                 150.668081                282.019742                         62237.101323                51.738884     2530.589578             0.120425              0.365163       -0.244739        0.369944         0.346028   0.023917          51.510455           17.170152     34.340303       130596.228055         43655.951904    86940.27615       51.510455   \n",
       "703       -0.200046          -0.014375         0.195847           0.196429       0.003030                                0.545455                             0.200000                           0.500000                                 142.941513                282.019742                         31670.774342                38.534202    0.107869       0.309856              -0.0         208.993534            0.0       -0.474011           0.068312         0.375597           0.142857       0.005177                                0.363636                             0.500000                           0.600000                                 328.379152                540.859780                        150234.691108                75.289451     2531.245726             0.141667              0.107869        0.033798        0.272908         0.309856  -0.036948         -30.906273                -0.0     30.906273       -77995.721549           208.993534   77786.728015       30.906273   \n",
       "704       -0.054841           0.143237         0.000000           0.142857       0.000000                                1.000000                             0.000000                           1.500000                                   0.000000                  0.000000                             0.000000                 0.000000    0.059906       0.683487              -0.0          205.13025            0.0       -0.074826           0.543460         0.026828           0.125000       0.000126                                1.000000                             0.000000                           0.500000                                   0.000000                  7.726568                            59.699857                 3.863284     2533.065332             0.218361              0.059906        0.158455        0.582913         0.683487  -0.100574         231.797048                -0.0    231.797048       587399.864669            205.13025  587194.734419      231.797048   \n",
       "705       -0.177017           0.138727         0.295112           0.196429       0.002652                                1.000000                             0.000000                           0.500000                                  81.128967                 84.992251                          7223.682744                42.496126    0.254881       0.681812        386.328414      979382.299928     386.328414       -0.806843          -0.279302         0.067071           0.178571       0.000505                                1.000000                             0.000000                           1.000000                                  19.316421                 19.316421                           134.324679                 5.794926     2534.629471             0.000714              0.000245        0.000470         0.34638         0.327176   0.019204        -386.328414           77.265683    309.062731      -979006.808985        196011.203226  782995.605759      386.328414   \n",
       "706       -0.109581          -0.355186         0.447139           0.214286       0.003535                                0.400000                             0.555556                           0.222222                                   0.000000                579.492621                        169965.493973                74.690160    0.161478       0.353176         34.340303       87761.321869      34.340303       -0.178466          -0.173398         0.247417           0.178571       0.004040                                0.500000                             0.222222                           0.444444                                 193.164207                320.652584                         82788.777228                53.358854     2549.650222             0.313887              0.161478        0.152410         0.22545         0.353176  -0.127726         171.701517           34.340303    137.361214       438016.994619         87761.321869   350255.67275      171.701517   \n",
       "\n",
       "    short_best_speed  speed_diff  long_best_wcorr  short_best_wcorr  wcorr_diff  long_best_pearsonr  short_best_pearsonr  pearsonr_diff  long_best_travel  short_best_travel  travel_diff  long_best_coverage  short_best_coverage  coverage_diff  long_best_jump  short_best_jump  jump_diff  long_best_longest_sequence_length_ratio  short_best_longest_sequence_length_ratio  longest_sequence_length_ratio_diff  long_best_direction_change_bin_ratio  short_best_direction_change_bin_ratio  direction_change_bin_ratio_diff  long_best_congruent_dir_bins_ratio  short_best_congruent_dir_bins_ratio  congruent_dir_bins_ratio_diff  long_best_total_congruent_direction_change  short_best_total_congruent_direction_change  total_congruent_direction_change_diff  long_best_total_variation  short_best_total_variation  total_variation_diff  long_best_integral_second_derivative  short_best_integral_second_derivative  integral_second_derivative_diff  long_best_stddev_of_diff  short_best_stddev_of_diff  \\\n",
       "0         309.062731  -77.265683        -0.176375         -0.076130    0.100245                 NaN                  NaN            NaN          0.385125           0.397954    -0.012829            0.464286             0.428571       0.035714        0.003908         0.004924  -0.001016                                 0.571429                                  0.571429                            0.000000                              0.333333                               0.166667                         0.166667                            0.500000                             0.500000                       0.000000                                  351.558857                                   193.164207                             158.394650                 494.500370                  343.832288            150.668081                         101101.708481                           27775.358648                     73326.349832                110.807358                  78.302352   \n",
       "1          38.632841  -19.316421        -0.380997          0.143256    0.237741           -0.157490             0.106136       0.051354          0.449062           0.680770    -0.231708            0.339286             0.267857       0.071429        0.003993         0.006692  -0.002699                                 0.444444                                  0.222222                            0.222222                              0.500000                               0.625000                        -0.125000                            0.625000                             0.625000                       0.000000                                  486.773802                                   394.054982                              92.718819                 768.793544                  784.246680            -15.453137                         284648.920009                          321856.856124                    -37207.936115                114.211145                 117.218011   \n",
       "2          51.510455   51.510455        -0.589925         -0.605130   -0.015205           -0.195767            -0.062250       0.133517          0.300879           0.366654    -0.065775            0.196429             0.232143      -0.035714        0.004078         0.005177  -0.001099                                 1.000000                                  1.000000                            0.000000                              0.000000                               0.000000                         0.000000                            1.000000                             0.333333                       0.666667                                  193.164207                                   158.394650                              34.769557                 193.164207                  158.394650             34.769557                          32969.246241                           25088.865066                      7880.381175                 85.594972                  74.667954   \n",
       "3          25.755228   25.755228        -0.371648         -0.006129    0.365519           -0.488452            -0.614204      -0.125752          0.281322           0.196741     0.084580            0.196429             0.285714      -0.089286        0.004248         0.002652   0.001597                                 0.384615                                  0.461538                           -0.076923                              0.250000                               0.333333                        -0.083333                            0.416667                             0.333333                       0.083333                                  370.875277                                   204.754059                             166.121218                 722.434134                  339.969004            382.465130                         179607.020941                           29969.328407                    149637.692534                 95.838240                  38.681102   \n",
       "4          24.399689  -24.399689        -0.287724         -0.173196    0.114528           -0.328897            -0.354183      -0.025286          0.332550           0.379833    -0.047283            0.250000             0.303571      -0.053571        0.004588         0.005303  -0.000715                                 0.350000                                  0.250000                            0.100000                              0.421053                               0.473684                        -0.052632                            0.473684                             0.421053                       0.052632                                  780.383396                                   521.543359                             258.840037                1352.149449                 1039.223434            312.926015                         537985.264820                          378183.671566                    159801.593254                102.299414                  81.592146   \n",
       "5           46.35941  139.078229        -0.444081         -0.198911    0.245170           -0.189396            -0.114868       0.074528          0.243712           0.155605     0.088107            0.267857             0.285714      -0.017857        0.003653         0.003157   0.000497                                 0.363636                                  0.454545                           -0.090909                              0.500000                               0.300000                         0.200000                            0.300000                             0.300000                       0.000000                                  262.703322                                   131.351661                             131.351661                 521.543359                  224.070480            297.472879                         118623.616623                           27521.634254                     91101.982369                 79.201094                  35.365407   \n",
       "..               ...         ...              ...               ...         ...                 ...                  ...            ...               ...                ...          ...                 ...                  ...            ...             ...              ...        ...                                      ...                                       ...                                 ...                                   ...                                    ...                              ...                                 ...                                  ...                            ...                                         ...                                          ...                                    ...                        ...                         ...                   ...                                   ...                                    ...                              ...                       ...                        ...   \n",
       "701        51.510455  154.531366        -0.503169         -0.332933    0.170236           -0.292843            -0.034595       0.258249          0.036105           0.008943     0.027163            0.196429             0.125000       0.071429        0.000340         0.000126   0.000214                                 1.000000                                  1.000000                            0.000000                              0.000000                               0.000000                         0.000000                            0.666667                             0.333333                       0.333333                                   19.316421                                     3.863284                              15.453137                  23.179705                    3.863284             19.316421                            432.823966                              14.924964                       417.899002                  7.938294                   1.821170   \n",
       "702        17.170152   34.340303         0.268528          0.063218    0.205310           -0.403955            -0.311708       0.092247          0.343002           0.351750    -0.008748            0.178571             0.232143      -0.053571        0.003483         0.004798  -0.001315                                 0.400000                                  0.400000                            0.000000                              0.444444                               0.444444                         0.000000                            0.555556                             0.555556                       0.000000                                  339.969004                                   262.703322                              77.265683                 660.621588                  455.867529            204.754059                         284753.394759                          106131.421465                    178621.973294                103.472426                  67.235451   \n",
       "703              0.0   30.906273        -0.399121         -0.474011   -0.074890            0.260018             0.068312       0.191706          0.353834           0.375597    -0.021764            0.232143             0.142857       0.089286        0.003568         0.005177  -0.001608                                 0.363636                                  0.363636                            0.000000                              0.500000                               0.500000                         0.000000                            0.500000                             0.600000                      -0.100000                                  382.465130                                   328.379152                              54.085978                 757.203691                  540.859780            216.343912                         268485.183622                          150234.691108                    118250.492514                 98.643194                  75.289451   \n",
       "704              0.0  231.797048        -0.414762         -0.074826    0.339935            0.037655             0.543460      -0.505805          0.036105           0.026828     0.009277            0.178571             0.125000       0.053571        0.000255         0.000126   0.000129                                 1.000000                                  1.000000                            0.000000                              0.000000                               0.000000                         0.000000                            0.500000                             0.500000                       0.000000                                   11.589852                                     0.000000                              11.589852                  15.453137                    7.726568              7.726568                            238.799430                              59.699857                       179.099572                  7.726568                   3.863284   \n",
       "705        77.265683  309.062731        -0.651693         -0.177017    0.474676            0.065094             0.138727      -0.073633          0.315923           0.295112     0.020811            0.178571             0.196429      -0.017857        0.002804         0.002652   0.000152                                 0.666667                                  1.000000                           -0.333333                              0.500000                               0.000000                         0.500000                            0.500000                             0.500000                       0.000000                                  127.488377                                    81.128967                              46.359410                 135.214945                   84.992251             50.222694                          18283.081324                            7223.682744                     11059.398580                 67.607472                  42.496126   \n",
       "706        34.340303  137.361214        -0.158380         -0.178466   -0.020085           -0.344914            -0.173398       0.171516          0.340996           0.247417     0.093579            0.250000             0.178571       0.071429        0.004163         0.004040   0.000123                                 0.300000                                  0.500000                           -0.200000                              0.555556                               0.222222                         0.333333                            0.444444                             0.444444                       0.000000                                  367.011993                                   193.164207                             173.847786                 656.758304                  320.652584            336.105720                         208680.851487                           82788.777228                    125892.074259                 99.011647                  53.358854   \n",
       "\n",
       "     stddev_of_diff_diff  \n",
       "0              32.505007  \n",
       "1              -3.006866  \n",
       "2              10.927018  \n",
       "3              57.157137  \n",
       "4              20.707268  \n",
       "5              43.835687  \n",
       "..                   ...  \n",
       "701             6.117125  \n",
       "702            36.236975  \n",
       "703            23.353743  \n",
       "704             3.863284  \n",
       "705            25.111347  \n",
       "706            45.652793  \n",
       "\n",
       "[707 rows x 130 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_score_col_decoder_col_names: ['total_variation_long_LR', 'total_variation_long_RL', 'total_variation_short_LR', 'total_variation_short_RL']\n",
      "curr_score_col_decoder_col_names: ['integral_second_derivative_long_LR', 'integral_second_derivative_long_RL', 'integral_second_derivative_short_LR', 'integral_second_derivative_short_RL']\n",
      "curr_score_col_decoder_col_names: ['stddev_of_diff_long_LR', 'stddev_of_diff_long_RL', 'stddev_of_diff_short_LR', 'stddev_of_diff_short_RL']\n",
      "curr_score_col_decoder_col_names: ['score_long_LR', 'score_long_RL', 'score_short_LR', 'score_short_RL']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "      <th>is_user_annotated_epoch</th>\n",
       "      <th>is_valid_epoch</th>\n",
       "      <th>P_LR</th>\n",
       "      <th>P_RL</th>\n",
       "      <th>P_Long</th>\n",
       "      <th>P_Short</th>\n",
       "      <th>P_Long_LR</th>\n",
       "      <th>score_long_LR</th>\n",
       "      <th>velocity_long_LR</th>\n",
       "      <th>intercept_long_LR</th>\n",
       "      <th>speed_long_LR</th>\n",
       "      <th>wcorr_long_LR</th>\n",
       "      <th>pearsonr_long_LR</th>\n",
       "      <th>travel_long_LR</th>\n",
       "      <th>coverage_long_LR</th>\n",
       "      <th>jump_long_LR</th>\n",
       "      <th>longest_sequence_length_ratio_long_LR</th>\n",
       "      <th>direction_change_bin_ratio_long_LR</th>\n",
       "      <th>congruent_dir_bins_ratio_long_LR</th>\n",
       "      <th>total_congruent_direction_change_long_LR</th>\n",
       "      <th>total_variation_long_LR</th>\n",
       "      <th>integral_second_derivative_long_LR</th>\n",
       "      <th>stddev_of_diff_long_LR</th>\n",
       "      <th>P_Long_RL</th>\n",
       "      <th>score_long_RL</th>\n",
       "      <th>velocity_long_RL</th>\n",
       "      <th>intercept_long_RL</th>\n",
       "      <th>speed_long_RL</th>\n",
       "      <th>wcorr_long_RL</th>\n",
       "      <th>pearsonr_long_RL</th>\n",
       "      <th>travel_long_RL</th>\n",
       "      <th>coverage_long_RL</th>\n",
       "      <th>jump_long_RL</th>\n",
       "      <th>longest_sequence_length_ratio_long_RL</th>\n",
       "      <th>direction_change_bin_ratio_long_RL</th>\n",
       "      <th>congruent_dir_bins_ratio_long_RL</th>\n",
       "      <th>total_congruent_direction_change_long_RL</th>\n",
       "      <th>total_variation_long_RL</th>\n",
       "      <th>integral_second_derivative_long_RL</th>\n",
       "      <th>stddev_of_diff_long_RL</th>\n",
       "      <th>P_Short_LR</th>\n",
       "      <th>score_short_LR</th>\n",
       "      <th>velocity_short_LR</th>\n",
       "      <th>intercept_short_LR</th>\n",
       "      <th>speed_short_LR</th>\n",
       "      <th>wcorr_short_LR</th>\n",
       "      <th>pearsonr_short_LR</th>\n",
       "      <th>travel_short_LR</th>\n",
       "      <th>coverage_short_LR</th>\n",
       "      <th>jump_short_LR</th>\n",
       "      <th>longest_sequence_length_ratio_short_LR</th>\n",
       "      <th>direction_change_bin_ratio_short_LR</th>\n",
       "      <th>congruent_dir_bins_ratio_short_LR</th>\n",
       "      <th>total_congruent_direction_change_short_LR</th>\n",
       "      <th>total_variation_short_LR</th>\n",
       "      <th>integral_second_derivative_short_LR</th>\n",
       "      <th>stddev_of_diff_short_LR</th>\n",
       "      <th>P_Short_RL</th>\n",
       "      <th>score_short_RL</th>\n",
       "      <th>velocity_short_RL</th>\n",
       "      <th>intercept_short_RL</th>\n",
       "      <th>speed_short_RL</th>\n",
       "      <th>wcorr_short_RL</th>\n",
       "      <th>pearsonr_short_RL</th>\n",
       "      <th>travel_short_RL</th>\n",
       "      <th>coverage_short_RL</th>\n",
       "      <th>jump_short_RL</th>\n",
       "      <th>longest_sequence_length_ratio_short_RL</th>\n",
       "      <th>direction_change_bin_ratio_short_RL</th>\n",
       "      <th>congruent_dir_bins_ratio_short_RL</th>\n",
       "      <th>total_congruent_direction_change_short_RL</th>\n",
       "      <th>total_variation_short_RL</th>\n",
       "      <th>integral_second_derivative_short_RL</th>\n",
       "      <th>stddev_of_diff_short_RL</th>\n",
       "      <th>ripple_start_t</th>\n",
       "      <th>long_best_P_decoder</th>\n",
       "      <th>short_best_P_decoder</th>\n",
       "      <th>P_decoder_diff</th>\n",
       "      <th>long_best_score</th>\n",
       "      <th>short_best_score</th>\n",
       "      <th>score_diff</th>\n",
       "      <th>long_best_velocity</th>\n",
       "      <th>short_best_velocity</th>\n",
       "      <th>velocity_diff</th>\n",
       "      <th>long_best_intercept</th>\n",
       "      <th>short_best_intercept</th>\n",
       "      <th>intercept_diff</th>\n",
       "      <th>long_best_speed</th>\n",
       "      <th>short_best_speed</th>\n",
       "      <th>speed_diff</th>\n",
       "      <th>long_best_wcorr</th>\n",
       "      <th>short_best_wcorr</th>\n",
       "      <th>wcorr_diff</th>\n",
       "      <th>long_best_pearsonr</th>\n",
       "      <th>short_best_pearsonr</th>\n",
       "      <th>pearsonr_diff</th>\n",
       "      <th>long_best_travel</th>\n",
       "      <th>short_best_travel</th>\n",
       "      <th>travel_diff</th>\n",
       "      <th>long_best_coverage</th>\n",
       "      <th>short_best_coverage</th>\n",
       "      <th>coverage_diff</th>\n",
       "      <th>long_best_jump</th>\n",
       "      <th>short_best_jump</th>\n",
       "      <th>jump_diff</th>\n",
       "      <th>long_best_longest_sequence_length_ratio</th>\n",
       "      <th>short_best_longest_sequence_length_ratio</th>\n",
       "      <th>longest_sequence_length_ratio_diff</th>\n",
       "      <th>long_best_direction_change_bin_ratio</th>\n",
       "      <th>short_best_direction_change_bin_ratio</th>\n",
       "      <th>direction_change_bin_ratio_diff</th>\n",
       "      <th>long_best_congruent_dir_bins_ratio</th>\n",
       "      <th>short_best_congruent_dir_bins_ratio</th>\n",
       "      <th>congruent_dir_bins_ratio_diff</th>\n",
       "      <th>long_best_total_congruent_direction_change</th>\n",
       "      <th>short_best_total_congruent_direction_change</th>\n",
       "      <th>total_congruent_direction_change_diff</th>\n",
       "      <th>long_best_total_variation</th>\n",
       "      <th>short_best_total_variation</th>\n",
       "      <th>total_variation_diff</th>\n",
       "      <th>long_best_integral_second_derivative</th>\n",
       "      <th>short_best_integral_second_derivative</th>\n",
       "      <th>integral_second_derivative_diff</th>\n",
       "      <th>long_best_stddev_of_diff</th>\n",
       "      <th>short_best_stddev_of_diff</th>\n",
       "      <th>stddev_of_diff_diff</th>\n",
       "      <th>total_variation_BEST</th>\n",
       "      <th>integral_second_derivative_BEST</th>\n",
       "      <th>stddev_of_diff_BEST</th>\n",
       "      <th>score_BEST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.469478</td>\n",
       "      <td>55.668144</td>\n",
       "      <td>1</td>\n",
       "      <td>0.198666</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.279922</td>\n",
       "      <td>0.720078</td>\n",
       "      <td>0.747300</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.209186</td>\n",
       "      <td>0.218418</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>13108.185152</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>-0.176375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.385125</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>351.558857</td>\n",
       "      <td>494.500370</td>\n",
       "      <td>101101.708481</td>\n",
       "      <td>110.807358</td>\n",
       "      <td>0.538114</td>\n",
       "      <td>0.177541</td>\n",
       "      <td>566.615007</td>\n",
       "      <td>31672.957977</td>\n",
       "      <td>566.615007</td>\n",
       "      <td>-0.423041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.490432</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>413.371403</td>\n",
       "      <td>629.715315</td>\n",
       "      <td>165443.229777</td>\n",
       "      <td>105.700424</td>\n",
       "      <td>0.070736</td>\n",
       "      <td>0.199763</td>\n",
       "      <td>309.062731</td>\n",
       "      <td>17248.23328</td>\n",
       "      <td>309.062731</td>\n",
       "      <td>-0.076130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.397954</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>343.832288</td>\n",
       "      <td>27775.358648</td>\n",
       "      <td>78.302352</td>\n",
       "      <td>0.181964</td>\n",
       "      <td>0.202055</td>\n",
       "      <td>1287.76138</td>\n",
       "      <td>71768.577533</td>\n",
       "      <td>1287.76138</td>\n",
       "      <td>-0.059093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630467</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>297.472879</td>\n",
       "      <td>544.723064</td>\n",
       "      <td>129638.240310</td>\n",
       "      <td>98.151158</td>\n",
       "      <td>55.469478</td>\n",
       "      <td>0.209186</td>\n",
       "      <td>0.070736</td>\n",
       "      <td>0.138450</td>\n",
       "      <td>0.218418</td>\n",
       "      <td>0.199763</td>\n",
       "      <td>0.018655</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>309.062731</td>\n",
       "      <td>-77.265683</td>\n",
       "      <td>13108.185152</td>\n",
       "      <td>17248.23328</td>\n",
       "      <td>-4140.048128</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>309.062731</td>\n",
       "      <td>-77.265683</td>\n",
       "      <td>-0.176375</td>\n",
       "      <td>-0.076130</td>\n",
       "      <td>0.100245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.385125</td>\n",
       "      <td>0.397954</td>\n",
       "      <td>-0.012829</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>-0.001016</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>351.558857</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>158.394650</td>\n",
       "      <td>494.500370</td>\n",
       "      <td>343.832288</td>\n",
       "      <td>150.668081</td>\n",
       "      <td>101101.708481</td>\n",
       "      <td>27775.358648</td>\n",
       "      <td>73326.349832</td>\n",
       "      <td>110.807358</td>\n",
       "      <td>78.302352</td>\n",
       "      <td>32.505007</td>\n",
       "      <td>629.715315</td>\n",
       "      <td>165443.229777</td>\n",
       "      <td>105.700424</td>\n",
       "      <td>0.177541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.728617</td>\n",
       "      <td>70.977971</td>\n",
       "      <td>2</td>\n",
       "      <td>0.249354</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.723395</td>\n",
       "      <td>0.276605</td>\n",
       "      <td>0.292040</td>\n",
       "      <td>0.707960</td>\n",
       "      <td>0.211260</td>\n",
       "      <td>0.235102</td>\n",
       "      <td>96.582103</td>\n",
       "      <td>7072.225651</td>\n",
       "      <td>96.582103</td>\n",
       "      <td>-0.280497</td>\n",
       "      <td>-0.203513</td>\n",
       "      <td>0.264021</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>235.660333</td>\n",
       "      <td>452.004244</td>\n",
       "      <td>100519.634871</td>\n",
       "      <td>70.231528</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.188198</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>1614.091544</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>-0.380997</td>\n",
       "      <td>-0.157490</td>\n",
       "      <td>0.449062</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>486.773802</td>\n",
       "      <td>768.793544</td>\n",
       "      <td>284648.920009</td>\n",
       "      <td>114.211145</td>\n",
       "      <td>0.512135</td>\n",
       "      <td>0.278974</td>\n",
       "      <td>38.632841</td>\n",
       "      <td>2938.060587</td>\n",
       "      <td>38.632841</td>\n",
       "      <td>-0.124122</td>\n",
       "      <td>0.101345</td>\n",
       "      <td>0.281698</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>169.984502</td>\n",
       "      <td>324.515868</td>\n",
       "      <td>66147.441982</td>\n",
       "      <td>52.652750</td>\n",
       "      <td>0.195825</td>\n",
       "      <td>0.256928</td>\n",
       "      <td>38.632841</td>\n",
       "      <td>2945.787156</td>\n",
       "      <td>38.632841</td>\n",
       "      <td>0.143256</td>\n",
       "      <td>0.106136</td>\n",
       "      <td>0.680770</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>394.054982</td>\n",
       "      <td>784.246680</td>\n",
       "      <td>321856.856124</td>\n",
       "      <td>117.218011</td>\n",
       "      <td>70.728617</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.195825</td>\n",
       "      <td>-0.115046</td>\n",
       "      <td>0.188198</td>\n",
       "      <td>0.256928</td>\n",
       "      <td>-0.06873</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>38.632841</td>\n",
       "      <td>-19.316421</td>\n",
       "      <td>1614.091544</td>\n",
       "      <td>2945.787156</td>\n",
       "      <td>-1331.695612</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>38.632841</td>\n",
       "      <td>-19.316421</td>\n",
       "      <td>-0.380997</td>\n",
       "      <td>0.143256</td>\n",
       "      <td>0.237741</td>\n",
       "      <td>-0.157490</td>\n",
       "      <td>0.106136</td>\n",
       "      <td>0.051354</td>\n",
       "      <td>0.449062</td>\n",
       "      <td>0.680770</td>\n",
       "      <td>-0.231708</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>-0.002699</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>486.773802</td>\n",
       "      <td>394.054982</td>\n",
       "      <td>92.718819</td>\n",
       "      <td>768.793544</td>\n",
       "      <td>784.246680</td>\n",
       "      <td>-15.453137</td>\n",
       "      <td>284648.920009</td>\n",
       "      <td>321856.856124</td>\n",
       "      <td>-37207.936115</td>\n",
       "      <td>114.211145</td>\n",
       "      <td>117.218011</td>\n",
       "      <td>-3.006866</td>\n",
       "      <td>324.515868</td>\n",
       "      <td>66147.441982</td>\n",
       "      <td>52.652750</td>\n",
       "      <td>0.278974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.394746</td>\n",
       "      <td>72.503556</td>\n",
       "      <td>3</td>\n",
       "      <td>0.108810</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.880846</td>\n",
       "      <td>0.119154</td>\n",
       "      <td>0.306491</td>\n",
       "      <td>0.693509</td>\n",
       "      <td>0.269971</td>\n",
       "      <td>0.57873</td>\n",
       "      <td>412.083642</td>\n",
       "      <td>30085.467842</td>\n",
       "      <td>412.083642</td>\n",
       "      <td>-0.230807</td>\n",
       "      <td>-0.207987</td>\n",
       "      <td>0.066193</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>38.632841</td>\n",
       "      <td>42.496126</td>\n",
       "      <td>1074.597433</td>\n",
       "      <td>10.927018</td>\n",
       "      <td>0.036520</td>\n",
       "      <td>0.386116</td>\n",
       "      <td>103.02091</td>\n",
       "      <td>7707.086742</td>\n",
       "      <td>103.02091</td>\n",
       "      <td>-0.589925</td>\n",
       "      <td>-0.195767</td>\n",
       "      <td>0.300879</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>32969.246241</td>\n",
       "      <td>85.594972</td>\n",
       "      <td>0.610874</td>\n",
       "      <td>0.485492</td>\n",
       "      <td>257.552276</td>\n",
       "      <td>18857.644451</td>\n",
       "      <td>257.552276</td>\n",
       "      <td>-0.438456</td>\n",
       "      <td>-0.138087</td>\n",
       "      <td>0.053657</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.179705</td>\n",
       "      <td>23.179705</td>\n",
       "      <td>74.624822</td>\n",
       "      <td>3.154358</td>\n",
       "      <td>0.082635</td>\n",
       "      <td>0.435554</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>3938.723717</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>-0.605130</td>\n",
       "      <td>-0.062250</td>\n",
       "      <td>0.366654</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>158.394650</td>\n",
       "      <td>158.394650</td>\n",
       "      <td>25088.865066</td>\n",
       "      <td>74.667954</td>\n",
       "      <td>72.394746</td>\n",
       "      <td>0.036520</td>\n",
       "      <td>0.082635</td>\n",
       "      <td>-0.046115</td>\n",
       "      <td>0.386116</td>\n",
       "      <td>0.435554</td>\n",
       "      <td>-0.049438</td>\n",
       "      <td>103.02091</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>7707.086742</td>\n",
       "      <td>3938.723717</td>\n",
       "      <td>3768.363025</td>\n",
       "      <td>103.02091</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>-0.589925</td>\n",
       "      <td>-0.605130</td>\n",
       "      <td>-0.015205</td>\n",
       "      <td>-0.195767</td>\n",
       "      <td>-0.062250</td>\n",
       "      <td>0.133517</td>\n",
       "      <td>0.300879</td>\n",
       "      <td>0.366654</td>\n",
       "      <td>-0.065775</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>-0.035714</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>-0.001099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>158.394650</td>\n",
       "      <td>34.769557</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>158.394650</td>\n",
       "      <td>34.769557</td>\n",
       "      <td>32969.246241</td>\n",
       "      <td>25088.865066</td>\n",
       "      <td>7880.381175</td>\n",
       "      <td>85.594972</td>\n",
       "      <td>74.667954</td>\n",
       "      <td>10.927018</td>\n",
       "      <td>23.179705</td>\n",
       "      <td>74.624822</td>\n",
       "      <td>3.154358</td>\n",
       "      <td>0.485492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.619121</td>\n",
       "      <td>93.966626</td>\n",
       "      <td>4</td>\n",
       "      <td>0.347504</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.792060</td>\n",
       "      <td>0.207940</td>\n",
       "      <td>0.744123</td>\n",
       "      <td>0.255877</td>\n",
       "      <td>0.589390</td>\n",
       "      <td>0.23715</td>\n",
       "      <td>721.146373</td>\n",
       "      <td>67881.765729</td>\n",
       "      <td>721.146373</td>\n",
       "      <td>-0.514662</td>\n",
       "      <td>0.009979</td>\n",
       "      <td>0.213624</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>374.738562</td>\n",
       "      <td>548.586348</td>\n",
       "      <td>140772.263712</td>\n",
       "      <td>76.462018</td>\n",
       "      <td>0.154733</td>\n",
       "      <td>0.267651</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>4881.332889</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>-0.371648</td>\n",
       "      <td>-0.488452</td>\n",
       "      <td>0.281322</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>370.875277</td>\n",
       "      <td>722.434134</td>\n",
       "      <td>179607.020941</td>\n",
       "      <td>95.838240</td>\n",
       "      <td>0.202670</td>\n",
       "      <td>0.261441</td>\n",
       "      <td>115.898524</td>\n",
       "      <td>11068.486835</td>\n",
       "      <td>115.898524</td>\n",
       "      <td>-0.315231</td>\n",
       "      <td>-0.190859</td>\n",
       "      <td>0.228041</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>243.386901</td>\n",
       "      <td>394.054982</td>\n",
       "      <td>37581.060223</td>\n",
       "      <td>42.932891</td>\n",
       "      <td>0.053207</td>\n",
       "      <td>0.296643</td>\n",
       "      <td>25.755228</td>\n",
       "      <td>2624.360536</td>\n",
       "      <td>25.755228</td>\n",
       "      <td>-0.006129</td>\n",
       "      <td>-0.614204</td>\n",
       "      <td>0.196741</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>204.754059</td>\n",
       "      <td>339.969004</td>\n",
       "      <td>29969.328407</td>\n",
       "      <td>38.681102</td>\n",
       "      <td>93.619121</td>\n",
       "      <td>0.154733</td>\n",
       "      <td>0.053207</td>\n",
       "      <td>0.101526</td>\n",
       "      <td>0.267651</td>\n",
       "      <td>0.296643</td>\n",
       "      <td>-0.028992</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>25.755228</td>\n",
       "      <td>25.755228</td>\n",
       "      <td>4881.332889</td>\n",
       "      <td>2624.360536</td>\n",
       "      <td>2256.972353</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>25.755228</td>\n",
       "      <td>25.755228</td>\n",
       "      <td>-0.371648</td>\n",
       "      <td>-0.006129</td>\n",
       "      <td>0.365519</td>\n",
       "      <td>-0.488452</td>\n",
       "      <td>-0.614204</td>\n",
       "      <td>-0.125752</td>\n",
       "      <td>0.281322</td>\n",
       "      <td>0.196741</td>\n",
       "      <td>0.084580</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>-0.089286</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>370.875277</td>\n",
       "      <td>204.754059</td>\n",
       "      <td>166.121218</td>\n",
       "      <td>722.434134</td>\n",
       "      <td>339.969004</td>\n",
       "      <td>382.465130</td>\n",
       "      <td>179607.020941</td>\n",
       "      <td>29969.328407</td>\n",
       "      <td>149637.692534</td>\n",
       "      <td>95.838240</td>\n",
       "      <td>38.681102</td>\n",
       "      <td>57.157137</td>\n",
       "      <td>548.586348</td>\n",
       "      <td>140772.263712</td>\n",
       "      <td>76.462018</td>\n",
       "      <td>0.237150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96.403550</td>\n",
       "      <td>96.927111</td>\n",
       "      <td>5</td>\n",
       "      <td>0.523561</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.729156</td>\n",
       "      <td>0.270844</td>\n",
       "      <td>0.713900</td>\n",
       "      <td>0.286100</td>\n",
       "      <td>0.520545</td>\n",
       "      <td>0.181495</td>\n",
       "      <td>641.899519</td>\n",
       "      <td>62140.905745</td>\n",
       "      <td>641.899519</td>\n",
       "      <td>-0.184619</td>\n",
       "      <td>-0.505225</td>\n",
       "      <td>0.213782</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>540.859780</td>\n",
       "      <td>869.238931</td>\n",
       "      <td>173711.660024</td>\n",
       "      <td>62.355277</td>\n",
       "      <td>0.193355</td>\n",
       "      <td>0.271203</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>42.872316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.287724</td>\n",
       "      <td>-0.328897</td>\n",
       "      <td>0.332550</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>780.383396</td>\n",
       "      <td>1352.149449</td>\n",
       "      <td>537985.264820</td>\n",
       "      <td>102.299414</td>\n",
       "      <td>0.208611</td>\n",
       "      <td>0.204776</td>\n",
       "      <td>529.821825</td>\n",
       "      <td>51307.774233</td>\n",
       "      <td>529.821825</td>\n",
       "      <td>-0.056180</td>\n",
       "      <td>-0.326396</td>\n",
       "      <td>0.309232</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>440.414392</td>\n",
       "      <td>846.059227</td>\n",
       "      <td>219202.951351</td>\n",
       "      <td>64.734582</td>\n",
       "      <td>0.077488</td>\n",
       "      <td>0.273612</td>\n",
       "      <td>24.399689</td>\n",
       "      <td>2561.515198</td>\n",
       "      <td>24.399689</td>\n",
       "      <td>-0.173196</td>\n",
       "      <td>-0.354183</td>\n",
       "      <td>0.379833</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>521.543359</td>\n",
       "      <td>1039.223434</td>\n",
       "      <td>378183.671566</td>\n",
       "      <td>81.592146</td>\n",
       "      <td>96.403550</td>\n",
       "      <td>0.193355</td>\n",
       "      <td>0.077488</td>\n",
       "      <td>0.115867</td>\n",
       "      <td>0.271203</td>\n",
       "      <td>0.273612</td>\n",
       "      <td>-0.00241</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>24.399689</td>\n",
       "      <td>-24.399689</td>\n",
       "      <td>42.872316</td>\n",
       "      <td>2561.515198</td>\n",
       "      <td>-2518.642882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.399689</td>\n",
       "      <td>-24.399689</td>\n",
       "      <td>-0.287724</td>\n",
       "      <td>-0.173196</td>\n",
       "      <td>0.114528</td>\n",
       "      <td>-0.328897</td>\n",
       "      <td>-0.354183</td>\n",
       "      <td>-0.025286</td>\n",
       "      <td>0.332550</td>\n",
       "      <td>0.379833</td>\n",
       "      <td>-0.047283</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>-0.053571</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>-0.000715</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>780.383396</td>\n",
       "      <td>521.543359</td>\n",
       "      <td>258.840037</td>\n",
       "      <td>1352.149449</td>\n",
       "      <td>1039.223434</td>\n",
       "      <td>312.926015</td>\n",
       "      <td>537985.264820</td>\n",
       "      <td>378183.671566</td>\n",
       "      <td>159801.593254</td>\n",
       "      <td>102.299414</td>\n",
       "      <td>81.592146</td>\n",
       "      <td>20.707268</td>\n",
       "      <td>869.238931</td>\n",
       "      <td>173711.660024</td>\n",
       "      <td>62.355277</td>\n",
       "      <td>0.181495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>97.562339</td>\n",
       "      <td>97.859862</td>\n",
       "      <td>6</td>\n",
       "      <td>0.297523</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.339263</td>\n",
       "      <td>0.660737</td>\n",
       "      <td>0.727668</td>\n",
       "      <td>0.272332</td>\n",
       "      <td>0.246871</td>\n",
       "      <td>0.19915</td>\n",
       "      <td>185.437639</td>\n",
       "      <td>18333.947462</td>\n",
       "      <td>185.437639</td>\n",
       "      <td>-0.444081</td>\n",
       "      <td>-0.189396</td>\n",
       "      <td>0.243712</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>262.703322</td>\n",
       "      <td>521.543359</td>\n",
       "      <td>118623.616623</td>\n",
       "      <td>79.201094</td>\n",
       "      <td>0.480797</td>\n",
       "      <td>0.230922</td>\n",
       "      <td>216.343912</td>\n",
       "      <td>21349.622071</td>\n",
       "      <td>216.343912</td>\n",
       "      <td>-0.463511</td>\n",
       "      <td>-0.146215</td>\n",
       "      <td>0.196775</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>216.343912</td>\n",
       "      <td>421.097971</td>\n",
       "      <td>57908.861663</td>\n",
       "      <td>67.071108</td>\n",
       "      <td>0.092392</td>\n",
       "      <td>0.190514</td>\n",
       "      <td>-46.35941</td>\n",
       "      <td>-4322.244948</td>\n",
       "      <td>46.35941</td>\n",
       "      <td>-0.198911</td>\n",
       "      <td>-0.114868</td>\n",
       "      <td>0.155605</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>131.351661</td>\n",
       "      <td>224.070480</td>\n",
       "      <td>27521.634254</td>\n",
       "      <td>35.365407</td>\n",
       "      <td>0.179940</td>\n",
       "      <td>0.2616</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>1712.967554</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>-0.216538</td>\n",
       "      <td>-0.174607</td>\n",
       "      <td>0.292429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>212.480628</td>\n",
       "      <td>421.097971</td>\n",
       "      <td>129593.465417</td>\n",
       "      <td>68.598047</td>\n",
       "      <td>97.562339</td>\n",
       "      <td>0.246871</td>\n",
       "      <td>0.092392</td>\n",
       "      <td>0.154479</td>\n",
       "      <td>0.19915</td>\n",
       "      <td>0.190514</td>\n",
       "      <td>0.008636</td>\n",
       "      <td>185.437639</td>\n",
       "      <td>-46.35941</td>\n",
       "      <td>139.078229</td>\n",
       "      <td>18333.947462</td>\n",
       "      <td>-4322.244948</td>\n",
       "      <td>14011.702514</td>\n",
       "      <td>185.437639</td>\n",
       "      <td>46.35941</td>\n",
       "      <td>139.078229</td>\n",
       "      <td>-0.444081</td>\n",
       "      <td>-0.198911</td>\n",
       "      <td>0.245170</td>\n",
       "      <td>-0.189396</td>\n",
       "      <td>-0.114868</td>\n",
       "      <td>0.074528</td>\n",
       "      <td>0.243712</td>\n",
       "      <td>0.155605</td>\n",
       "      <td>0.088107</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>-0.017857</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>262.703322</td>\n",
       "      <td>131.351661</td>\n",
       "      <td>131.351661</td>\n",
       "      <td>521.543359</td>\n",
       "      <td>224.070480</td>\n",
       "      <td>297.472879</td>\n",
       "      <td>118623.616623</td>\n",
       "      <td>27521.634254</td>\n",
       "      <td>91101.982369</td>\n",
       "      <td>79.201094</td>\n",
       "      <td>35.365407</td>\n",
       "      <td>43.835687</td>\n",
       "      <td>421.097971</td>\n",
       "      <td>57908.861663</td>\n",
       "      <td>67.071108</td>\n",
       "      <td>0.230922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>2528.653666</td>\n",
       "      <td>2528.769788</td>\n",
       "      <td>730</td>\n",
       "      <td>0.116122</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.201323</td>\n",
       "      <td>0.798677</td>\n",
       "      <td>0.455818</td>\n",
       "      <td>0.544182</td>\n",
       "      <td>0.091767</td>\n",
       "      <td>0.560355</td>\n",
       "      <td>206.041821</td>\n",
       "      <td>521250.880835</td>\n",
       "      <td>206.041821</td>\n",
       "      <td>-0.503169</td>\n",
       "      <td>-0.292843</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>23.179705</td>\n",
       "      <td>432.823966</td>\n",
       "      <td>7.938294</td>\n",
       "      <td>0.364051</td>\n",
       "      <td>0.364052</td>\n",
       "      <td>-463.594097</td>\n",
       "      <td>-1172081.166916</td>\n",
       "      <td>463.594097</td>\n",
       "      <td>-0.063607</td>\n",
       "      <td>-0.422195</td>\n",
       "      <td>0.108316</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>46.359410</td>\n",
       "      <td>69.539115</td>\n",
       "      <td>3880.490730</td>\n",
       "      <td>27.499058</td>\n",
       "      <td>0.109556</td>\n",
       "      <td>0.694673</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>130457.875507</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>-0.332933</td>\n",
       "      <td>-0.034595</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>14.924964</td>\n",
       "      <td>1.821170</td>\n",
       "      <td>0.434625</td>\n",
       "      <td>0.595968</td>\n",
       "      <td>257.552276</td>\n",
       "      <td>651480.446388</td>\n",
       "      <td>257.552276</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>-0.327778</td>\n",
       "      <td>0.035771</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>29.849929</td>\n",
       "      <td>1.821170</td>\n",
       "      <td>2528.653666</td>\n",
       "      <td>0.091767</td>\n",
       "      <td>0.109556</td>\n",
       "      <td>-0.017790</td>\n",
       "      <td>0.560355</td>\n",
       "      <td>0.694673</td>\n",
       "      <td>-0.134318</td>\n",
       "      <td>206.041821</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>154.531366</td>\n",
       "      <td>521250.880835</td>\n",
       "      <td>130457.875507</td>\n",
       "      <td>390793.005328</td>\n",
       "      <td>206.041821</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>154.531366</td>\n",
       "      <td>-0.503169</td>\n",
       "      <td>-0.332933</td>\n",
       "      <td>0.170236</td>\n",
       "      <td>-0.292843</td>\n",
       "      <td>-0.034595</td>\n",
       "      <td>0.258249</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>0.027163</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>23.179705</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>432.823966</td>\n",
       "      <td>14.924964</td>\n",
       "      <td>417.899002</td>\n",
       "      <td>7.938294</td>\n",
       "      <td>1.821170</td>\n",
       "      <td>6.117125</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>29.849929</td>\n",
       "      <td>1.821170</td>\n",
       "      <td>0.595968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>2530.589578</td>\n",
       "      <td>2530.846366</td>\n",
       "      <td>731</td>\n",
       "      <td>0.256788</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.485588</td>\n",
       "      <td>0.514412</td>\n",
       "      <td>0.247997</td>\n",
       "      <td>0.752003</td>\n",
       "      <td>0.120425</td>\n",
       "      <td>0.369944</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>130596.228055</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>0.268528</td>\n",
       "      <td>-0.403955</td>\n",
       "      <td>0.343002</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>339.969004</td>\n",
       "      <td>660.621588</td>\n",
       "      <td>284753.394759</td>\n",
       "      <td>103.472426</td>\n",
       "      <td>0.127573</td>\n",
       "      <td>0.189032</td>\n",
       "      <td>103.02091</td>\n",
       "      <td>260952.556302</td>\n",
       "      <td>103.02091</td>\n",
       "      <td>0.432141</td>\n",
       "      <td>-0.276293</td>\n",
       "      <td>0.246721</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>258.840037</td>\n",
       "      <td>475.183949</td>\n",
       "      <td>120981.760990</td>\n",
       "      <td>87.790534</td>\n",
       "      <td>0.365163</td>\n",
       "      <td>0.346028</td>\n",
       "      <td>17.170152</td>\n",
       "      <td>43655.951904</td>\n",
       "      <td>17.170152</td>\n",
       "      <td>0.063218</td>\n",
       "      <td>-0.311708</td>\n",
       "      <td>0.351750</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>262.703322</td>\n",
       "      <td>455.867529</td>\n",
       "      <td>106131.421465</td>\n",
       "      <td>67.235451</td>\n",
       "      <td>0.386839</td>\n",
       "      <td>0.235762</td>\n",
       "      <td>68.680607</td>\n",
       "      <td>174016.143436</td>\n",
       "      <td>68.680607</td>\n",
       "      <td>0.226795</td>\n",
       "      <td>-0.137310</td>\n",
       "      <td>0.217608</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>150.668081</td>\n",
       "      <td>282.019742</td>\n",
       "      <td>62237.101323</td>\n",
       "      <td>51.738884</td>\n",
       "      <td>2530.589578</td>\n",
       "      <td>0.120425</td>\n",
       "      <td>0.365163</td>\n",
       "      <td>-0.244739</td>\n",
       "      <td>0.369944</td>\n",
       "      <td>0.346028</td>\n",
       "      <td>0.023917</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>17.170152</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>130596.228055</td>\n",
       "      <td>43655.951904</td>\n",
       "      <td>86940.27615</td>\n",
       "      <td>51.510455</td>\n",
       "      <td>17.170152</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>0.268528</td>\n",
       "      <td>0.063218</td>\n",
       "      <td>0.205310</td>\n",
       "      <td>-0.403955</td>\n",
       "      <td>-0.311708</td>\n",
       "      <td>0.092247</td>\n",
       "      <td>0.343002</td>\n",
       "      <td>0.351750</td>\n",
       "      <td>-0.008748</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>-0.053571</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>-0.001315</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>339.969004</td>\n",
       "      <td>262.703322</td>\n",
       "      <td>77.265683</td>\n",
       "      <td>660.621588</td>\n",
       "      <td>455.867529</td>\n",
       "      <td>204.754059</td>\n",
       "      <td>284753.394759</td>\n",
       "      <td>106131.421465</td>\n",
       "      <td>178621.973294</td>\n",
       "      <td>103.472426</td>\n",
       "      <td>67.235451</td>\n",
       "      <td>36.236975</td>\n",
       "      <td>282.019742</td>\n",
       "      <td>62237.101323</td>\n",
       "      <td>51.738884</td>\n",
       "      <td>0.235762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>2531.245726</td>\n",
       "      <td>2531.531176</td>\n",
       "      <td>732</td>\n",
       "      <td>0.285450</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.750465</td>\n",
       "      <td>0.249535</td>\n",
       "      <td>0.567721</td>\n",
       "      <td>0.432279</td>\n",
       "      <td>0.426055</td>\n",
       "      <td>0.438314</td>\n",
       "      <td>-46.35941</td>\n",
       "      <td>-117115.463869</td>\n",
       "      <td>46.35941</td>\n",
       "      <td>-0.274683</td>\n",
       "      <td>0.139567</td>\n",
       "      <td>0.184138</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>394.054982</td>\n",
       "      <td>131876.984962</td>\n",
       "      <td>73.117181</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.272908</td>\n",
       "      <td>-30.906273</td>\n",
       "      <td>-77995.721549</td>\n",
       "      <td>30.906273</td>\n",
       "      <td>-0.399121</td>\n",
       "      <td>0.260018</td>\n",
       "      <td>0.353834</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>382.465130</td>\n",
       "      <td>757.203691</td>\n",
       "      <td>268485.183622</td>\n",
       "      <td>98.643194</td>\n",
       "      <td>0.324410</td>\n",
       "      <td>0.40341</td>\n",
       "      <td>-15.453137</td>\n",
       "      <td>-38910.748786</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>-0.200046</td>\n",
       "      <td>-0.014375</td>\n",
       "      <td>0.195847</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>142.941513</td>\n",
       "      <td>282.019742</td>\n",
       "      <td>31670.774342</td>\n",
       "      <td>38.534202</td>\n",
       "      <td>0.107869</td>\n",
       "      <td>0.309856</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>208.993534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.474011</td>\n",
       "      <td>0.068312</td>\n",
       "      <td>0.375597</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>328.379152</td>\n",
       "      <td>540.859780</td>\n",
       "      <td>150234.691108</td>\n",
       "      <td>75.289451</td>\n",
       "      <td>2531.245726</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.107869</td>\n",
       "      <td>0.033798</td>\n",
       "      <td>0.272908</td>\n",
       "      <td>0.309856</td>\n",
       "      <td>-0.036948</td>\n",
       "      <td>-30.906273</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>30.906273</td>\n",
       "      <td>-77995.721549</td>\n",
       "      <td>208.993534</td>\n",
       "      <td>77786.728015</td>\n",
       "      <td>30.906273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.906273</td>\n",
       "      <td>-0.399121</td>\n",
       "      <td>-0.474011</td>\n",
       "      <td>-0.074890</td>\n",
       "      <td>0.260018</td>\n",
       "      <td>0.068312</td>\n",
       "      <td>0.191706</td>\n",
       "      <td>0.353834</td>\n",
       "      <td>0.375597</td>\n",
       "      <td>-0.021764</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>-0.001608</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>382.465130</td>\n",
       "      <td>328.379152</td>\n",
       "      <td>54.085978</td>\n",
       "      <td>757.203691</td>\n",
       "      <td>540.859780</td>\n",
       "      <td>216.343912</td>\n",
       "      <td>268485.183622</td>\n",
       "      <td>150234.691108</td>\n",
       "      <td>118250.492514</td>\n",
       "      <td>98.643194</td>\n",
       "      <td>75.289451</td>\n",
       "      <td>23.353743</td>\n",
       "      <td>394.054982</td>\n",
       "      <td>131876.984962</td>\n",
       "      <td>73.117181</td>\n",
       "      <td>0.438314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>2533.065332</td>\n",
       "      <td>2533.145388</td>\n",
       "      <td>734</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.721732</td>\n",
       "      <td>0.278268</td>\n",
       "      <td>0.784716</td>\n",
       "      <td>0.215284</td>\n",
       "      <td>0.566355</td>\n",
       "      <td>0.670564</td>\n",
       "      <td>-77.265683</td>\n",
       "      <td>-195487.815048</td>\n",
       "      <td>77.265683</td>\n",
       "      <td>0.025602</td>\n",
       "      <td>-0.167074</td>\n",
       "      <td>0.009026</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>14.924964</td>\n",
       "      <td>1.931642</td>\n",
       "      <td>0.218361</td>\n",
       "      <td>0.582913</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>587399.864669</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>-0.414762</td>\n",
       "      <td>0.037655</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.589852</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>238.799430</td>\n",
       "      <td>7.726568</td>\n",
       "      <td>0.155377</td>\n",
       "      <td>0.65263</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>205.13025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.054841</td>\n",
       "      <td>0.143237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059906</td>\n",
       "      <td>0.683487</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>205.13025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.074826</td>\n",
       "      <td>0.543460</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.726568</td>\n",
       "      <td>59.699857</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>2533.065332</td>\n",
       "      <td>0.218361</td>\n",
       "      <td>0.059906</td>\n",
       "      <td>0.158455</td>\n",
       "      <td>0.582913</td>\n",
       "      <td>0.683487</td>\n",
       "      <td>-0.100574</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>587399.864669</td>\n",
       "      <td>205.13025</td>\n",
       "      <td>587194.734419</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.797048</td>\n",
       "      <td>-0.414762</td>\n",
       "      <td>-0.074826</td>\n",
       "      <td>0.339935</td>\n",
       "      <td>0.037655</td>\n",
       "      <td>0.543460</td>\n",
       "      <td>-0.505805</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.589852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.589852</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>7.726568</td>\n",
       "      <td>7.726568</td>\n",
       "      <td>238.799430</td>\n",
       "      <td>59.699857</td>\n",
       "      <td>179.099572</td>\n",
       "      <td>7.726568</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>14.924964</td>\n",
       "      <td>1.931642</td>\n",
       "      <td>0.670564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>2534.629471</td>\n",
       "      <td>2534.717361</td>\n",
       "      <td>735</td>\n",
       "      <td>0.087890</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.999041</td>\n",
       "      <td>0.744875</td>\n",
       "      <td>0.255125</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.34638</td>\n",
       "      <td>-386.328414</td>\n",
       "      <td>-979006.808985</td>\n",
       "      <td>386.328414</td>\n",
       "      <td>-0.651693</td>\n",
       "      <td>0.065094</td>\n",
       "      <td>0.315923</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>127.488377</td>\n",
       "      <td>135.214945</td>\n",
       "      <td>18283.081324</td>\n",
       "      <td>67.607472</td>\n",
       "      <td>0.744161</td>\n",
       "      <td>0.616999</td>\n",
       "      <td>695.391145</td>\n",
       "      <td>1762753.39663</td>\n",
       "      <td>695.391145</td>\n",
       "      <td>-0.835117</td>\n",
       "      <td>-0.151596</td>\n",
       "      <td>0.081237</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.769557</td>\n",
       "      <td>34.769557</td>\n",
       "      <td>134.324679</td>\n",
       "      <td>5.794926</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.327176</td>\n",
       "      <td>77.265683</td>\n",
       "      <td>196011.203226</td>\n",
       "      <td>77.265683</td>\n",
       "      <td>-0.177017</td>\n",
       "      <td>0.138727</td>\n",
       "      <td>0.295112</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>81.128967</td>\n",
       "      <td>84.992251</td>\n",
       "      <td>7223.682744</td>\n",
       "      <td>42.496126</td>\n",
       "      <td>0.254881</td>\n",
       "      <td>0.681812</td>\n",
       "      <td>386.328414</td>\n",
       "      <td>979382.299928</td>\n",
       "      <td>386.328414</td>\n",
       "      <td>-0.806843</td>\n",
       "      <td>-0.279302</td>\n",
       "      <td>0.067071</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>19.316421</td>\n",
       "      <td>134.324679</td>\n",
       "      <td>5.794926</td>\n",
       "      <td>2534.629471</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.34638</td>\n",
       "      <td>0.327176</td>\n",
       "      <td>0.019204</td>\n",
       "      <td>-386.328414</td>\n",
       "      <td>77.265683</td>\n",
       "      <td>309.062731</td>\n",
       "      <td>-979006.808985</td>\n",
       "      <td>196011.203226</td>\n",
       "      <td>782995.605759</td>\n",
       "      <td>386.328414</td>\n",
       "      <td>77.265683</td>\n",
       "      <td>309.062731</td>\n",
       "      <td>-0.651693</td>\n",
       "      <td>-0.177017</td>\n",
       "      <td>0.474676</td>\n",
       "      <td>0.065094</td>\n",
       "      <td>0.138727</td>\n",
       "      <td>-0.073633</td>\n",
       "      <td>0.315923</td>\n",
       "      <td>0.295112</td>\n",
       "      <td>0.020811</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>-0.017857</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>127.488377</td>\n",
       "      <td>81.128967</td>\n",
       "      <td>46.359410</td>\n",
       "      <td>135.214945</td>\n",
       "      <td>84.992251</td>\n",
       "      <td>50.222694</td>\n",
       "      <td>18283.081324</td>\n",
       "      <td>7223.682744</td>\n",
       "      <td>11059.398580</td>\n",
       "      <td>67.607472</td>\n",
       "      <td>42.496126</td>\n",
       "      <td>25.111347</td>\n",
       "      <td>34.769557</td>\n",
       "      <td>134.324679</td>\n",
       "      <td>5.794926</td>\n",
       "      <td>0.616999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>2549.650222</td>\n",
       "      <td>2549.918746</td>\n",
       "      <td>736</td>\n",
       "      <td>0.268523</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.524635</td>\n",
       "      <td>0.475365</td>\n",
       "      <td>0.660308</td>\n",
       "      <td>0.339692</td>\n",
       "      <td>0.346421</td>\n",
       "      <td>0.336876</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>87784.501574</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>-0.246209</td>\n",
       "      <td>-0.341970</td>\n",
       "      <td>0.184539</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>355.422141</td>\n",
       "      <td>78191.888209</td>\n",
       "      <td>73.368502</td>\n",
       "      <td>0.313887</td>\n",
       "      <td>0.22545</td>\n",
       "      <td>171.701517</td>\n",
       "      <td>438016.994619</td>\n",
       "      <td>171.701517</td>\n",
       "      <td>-0.158380</td>\n",
       "      <td>-0.344914</td>\n",
       "      <td>0.340996</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>367.011993</td>\n",
       "      <td>656.758304</td>\n",
       "      <td>208680.851487</td>\n",
       "      <td>99.011647</td>\n",
       "      <td>0.178214</td>\n",
       "      <td>0.244281</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>87757.458585</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>-0.109581</td>\n",
       "      <td>-0.355186</td>\n",
       "      <td>0.447139</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>579.492621</td>\n",
       "      <td>169965.493973</td>\n",
       "      <td>74.690160</td>\n",
       "      <td>0.161478</td>\n",
       "      <td>0.353176</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>87761.321869</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>-0.178466</td>\n",
       "      <td>-0.173398</td>\n",
       "      <td>0.247417</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>320.652584</td>\n",
       "      <td>82788.777228</td>\n",
       "      <td>53.358854</td>\n",
       "      <td>2549.650222</td>\n",
       "      <td>0.313887</td>\n",
       "      <td>0.161478</td>\n",
       "      <td>0.152410</td>\n",
       "      <td>0.22545</td>\n",
       "      <td>0.353176</td>\n",
       "      <td>-0.127726</td>\n",
       "      <td>171.701517</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>137.361214</td>\n",
       "      <td>438016.994619</td>\n",
       "      <td>87761.321869</td>\n",
       "      <td>350255.67275</td>\n",
       "      <td>171.701517</td>\n",
       "      <td>34.340303</td>\n",
       "      <td>137.361214</td>\n",
       "      <td>-0.158380</td>\n",
       "      <td>-0.178466</td>\n",
       "      <td>-0.020085</td>\n",
       "      <td>-0.344914</td>\n",
       "      <td>-0.173398</td>\n",
       "      <td>0.171516</td>\n",
       "      <td>0.340996</td>\n",
       "      <td>0.247417</td>\n",
       "      <td>0.093579</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>367.011993</td>\n",
       "      <td>193.164207</td>\n",
       "      <td>173.847786</td>\n",
       "      <td>656.758304</td>\n",
       "      <td>320.652584</td>\n",
       "      <td>336.105720</td>\n",
       "      <td>208680.851487</td>\n",
       "      <td>82788.777228</td>\n",
       "      <td>125892.074259</td>\n",
       "      <td>99.011647</td>\n",
       "      <td>53.358854</td>\n",
       "      <td>45.652793</td>\n",
       "      <td>355.422141</td>\n",
       "      <td>78191.888209</td>\n",
       "      <td>73.368502</td>\n",
       "      <td>0.336876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           start         stop label  duration  is_user_annotated_epoch  is_valid_epoch      P_LR      P_RL    P_Long   P_Short  P_Long_LR score_long_LR velocity_long_LR intercept_long_LR speed_long_LR  wcorr_long_LR  pearsonr_long_LR  travel_long_LR  coverage_long_LR  jump_long_LR  longest_sequence_length_ratio_long_LR  direction_change_bin_ratio_long_LR  congruent_dir_bins_ratio_long_LR  total_congruent_direction_change_long_LR  total_variation_long_LR  integral_second_derivative_long_LR  stddev_of_diff_long_LR  P_Long_RL score_long_RL velocity_long_RL intercept_long_RL speed_long_RL  wcorr_long_RL  pearsonr_long_RL  travel_long_RL  coverage_long_RL  jump_long_RL  longest_sequence_length_ratio_long_RL  direction_change_bin_ratio_long_RL  congruent_dir_bins_ratio_long_RL  total_congruent_direction_change_long_RL  total_variation_long_RL  integral_second_derivative_long_RL  stddev_of_diff_long_RL  P_Short_LR score_short_LR velocity_short_LR intercept_short_LR speed_short_LR  \\\n",
       "0      55.469478    55.668144     1  0.198666                    False            True  0.279922  0.720078  0.747300  0.252700   0.209186      0.218418       231.797048      13108.185152    231.797048      -0.176375               NaN        0.385125          0.464286      0.003908                               0.571429                            0.333333                          0.500000                                351.558857               494.500370                       101101.708481              110.807358   0.538114      0.177541       566.615007      31672.957977    566.615007      -0.423041               NaN        0.490432          0.339286      0.003314                               0.285714                            0.666667                          0.666667                                413.371403               629.715315                       165443.229777              105.700424    0.070736       0.199763        309.062731        17248.23328     309.062731   \n",
       "1      70.728617    70.977971     2  0.249354                    False            True  0.723395  0.276605  0.292040  0.707960   0.211260      0.235102        96.582103       7072.225651     96.582103      -0.280497         -0.203513        0.264021          0.392857      0.003229                               0.333333                            0.625000                          0.375000                                235.660333               452.004244                       100519.634871               70.231528   0.080780      0.188198        19.316421       1614.091544     19.316421      -0.380997         -0.157490        0.449062          0.339286      0.003993                               0.444444                            0.500000                          0.625000                                486.773802               768.793544                       284648.920009              114.211145    0.512135       0.278974         38.632841        2938.060587      38.632841   \n",
       "2      72.394746    72.503556     3  0.108810                    False           False  0.880846  0.119154  0.306491  0.693509   0.269971       0.57873       412.083642      30085.467842    412.083642      -0.230807         -0.207987        0.066193          0.214286      0.000425                               1.000000                            0.000000                          0.666667                                 38.632841                42.496126                         1074.597433               10.927018   0.036520      0.386116        103.02091       7707.086742     103.02091      -0.589925         -0.195767        0.300879          0.196429      0.004078                               1.000000                            0.000000                          1.000000                                193.164207               193.164207                        32969.246241               85.594972    0.610874       0.485492        257.552276       18857.644451     257.552276   \n",
       "3      93.619121    93.966626     4  0.347504                    False            True  0.792060  0.207940  0.744123  0.255877   0.589390       0.23715       721.146373      67881.765729    721.146373      -0.514662          0.009979        0.213624          0.267857      0.003823                               0.461538                            0.166667                          0.583333                                374.738562               548.586348                       140772.263712               76.462018   0.154733      0.267651        51.510455       4881.332889     51.510455      -0.371648         -0.488452        0.281322          0.196429      0.004248                               0.384615                            0.250000                          0.416667                                370.875277               722.434134                       179607.020941               95.838240    0.202670       0.261441        115.898524       11068.486835     115.898524   \n",
       "4      96.403550    96.927111     5  0.523561                    False            True  0.729156  0.270844  0.713900  0.286100   0.520545      0.181495       641.899519      62140.905745    641.899519      -0.184619         -0.505225        0.213782          0.410714      0.003314                               0.350000                            0.421053                          0.631579                                540.859780               869.238931                       173711.660024               62.355277   0.193355      0.271203             -0.0         42.872316           0.0      -0.287724         -0.328897        0.332550          0.250000      0.004588                               0.350000                            0.421053                          0.473684                                780.383396              1352.149449                       537985.264820              102.299414    0.208611       0.204776        529.821825       51307.774233     529.821825   \n",
       "5      97.562339    97.859862     6  0.297523                    False            True  0.339263  0.660737  0.727668  0.272332   0.246871       0.19915       185.437639      18333.947462    185.437639      -0.444081         -0.189396        0.243712          0.267857      0.003653                               0.363636                            0.500000                          0.300000                                262.703322               521.543359                       118623.616623               79.201094   0.480797      0.230922       216.343912      21349.622071    216.343912      -0.463511         -0.146215        0.196775          0.321429      0.003653                               0.363636                            0.300000                          0.300000                                216.343912               421.097971                        57908.861663               67.071108    0.092392       0.190514         -46.35941       -4322.244948       46.35941   \n",
       "..           ...          ...   ...       ...                      ...             ...       ...       ...       ...       ...        ...           ...              ...               ...           ...            ...               ...             ...               ...           ...                                    ...                                 ...                               ...                                       ...                      ...                                 ...                     ...        ...           ...              ...               ...           ...            ...               ...             ...               ...           ...                                    ...                                 ...                               ...                                       ...                      ...                                 ...                     ...         ...            ...               ...                ...            ...   \n",
       "701  2528.653666  2528.769788   730  0.116122                    False           False  0.201323  0.798677  0.455818  0.544182   0.091767      0.560355       206.041821     521250.880835    206.041821      -0.503169         -0.292843        0.036105          0.196429      0.000340                               1.000000                            0.000000                          0.666667                                 19.316421                23.179705                          432.823966                7.938294   0.364051      0.364052      -463.594097   -1172081.166916    463.594097      -0.063607         -0.422195        0.108316          0.267857      0.001020                               0.500000                            0.333333                          0.333333                                 46.359410                69.539115                         3880.490730               27.499058    0.109556       0.694673         51.510455      130457.875507      51.510455   \n",
       "702  2530.589578  2530.846366   731  0.256788                    False           False  0.485588  0.514412  0.247997  0.752003   0.120425      0.369944        51.510455     130596.228055     51.510455       0.268528         -0.403955        0.343002          0.178571      0.003483                               0.400000                            0.444444                          0.555556                                339.969004               660.621588                       284753.394759              103.472426   0.127573      0.189032        103.02091     260952.556302     103.02091       0.432141         -0.276293        0.246721          0.303571      0.004673                               0.500000                            0.444444                          0.333333                                258.840037               475.183949                       120981.760990               87.790534    0.365163       0.346028         17.170152       43655.951904      17.170152   \n",
       "703  2531.245726  2531.531176   732  0.285450                    False           False  0.750465  0.249535  0.567721  0.432279   0.426055      0.438314        -46.35941    -117115.463869      46.35941      -0.274683          0.139567        0.184138          0.142857      0.003568                               0.272727                            0.500000                          0.200000                                  0.000000               394.054982                       131876.984962               73.117181   0.141667      0.272908       -30.906273     -77995.721549     30.906273      -0.399121          0.260018        0.353834          0.232143      0.003568                               0.363636                            0.500000                          0.500000                                382.465130               757.203691                       268485.183622               98.643194    0.324410        0.40341        -15.453137      -38910.748786      15.453137   \n",
       "704  2533.065332  2533.145388   734  0.080056                    False           False  0.721732  0.278268  0.784716  0.215284   0.566355      0.670564       -77.265683    -195487.815048     77.265683       0.025602         -0.167074        0.009026          0.142857      0.000085                               1.000000                            0.000000                          0.500000                                  3.863284                 3.863284                           14.924964                1.931642   0.218361      0.582913       231.797048     587399.864669    231.797048      -0.414762          0.037655        0.036105          0.178571      0.000255                               1.000000                            0.000000                          0.500000                                 11.589852                15.453137                          238.799430                7.726568    0.155377        0.65263              -0.0          205.13025            0.0   \n",
       "705  2534.629471  2534.717361   735  0.087890                    False           False  0.000959  0.999041  0.744875  0.255125   0.000714       0.34638      -386.328414    -979006.808985    386.328414      -0.651693          0.065094        0.315923          0.178571      0.002804                               0.666667                            0.500000                          0.500000                                127.488377               135.214945                        18283.081324               67.607472   0.744161      0.616999       695.391145     1762753.39663    695.391145      -0.835117         -0.151596        0.081237          0.232143      0.000510                               1.000000                            0.000000                          1.000000                                 34.769557                34.769557                          134.324679                5.794926    0.000245       0.327176         77.265683      196011.203226      77.265683   \n",
       "706  2549.650222  2549.918746   736  0.268523                    False            True  0.524635  0.475365  0.660308  0.339692   0.346421      0.336876        34.340303      87784.501574     34.340303      -0.246209         -0.341970        0.184539          0.196429      0.003483                               0.500000                            0.333333                          0.444444                                  0.000000               355.422141                        78191.888209               73.368502   0.313887       0.22545       171.701517     438016.994619    171.701517      -0.158380         -0.344914        0.340996          0.250000      0.004163                               0.300000                            0.555556                          0.444444                                367.011993               656.758304                       208680.851487               99.011647    0.178214       0.244281         34.340303       87757.458585      34.340303   \n",
       "\n",
       "     wcorr_short_LR  pearsonr_short_LR  travel_short_LR  coverage_short_LR  jump_short_LR  longest_sequence_length_ratio_short_LR  direction_change_bin_ratio_short_LR  congruent_dir_bins_ratio_short_LR  total_congruent_direction_change_short_LR  total_variation_short_LR  integral_second_derivative_short_LR  stddev_of_diff_short_LR  P_Short_RL score_short_RL velocity_short_RL intercept_short_RL speed_short_RL  wcorr_short_RL  pearsonr_short_RL  travel_short_RL  coverage_short_RL  jump_short_RL  longest_sequence_length_ratio_short_RL  direction_change_bin_ratio_short_RL  congruent_dir_bins_ratio_short_RL  total_congruent_direction_change_short_RL  total_variation_short_RL  integral_second_derivative_short_RL  stddev_of_diff_short_RL  ripple_start_t  long_best_P_decoder  short_best_P_decoder  P_decoder_diff long_best_score short_best_score score_diff long_best_velocity short_best_velocity velocity_diff long_best_intercept short_best_intercept intercept_diff long_best_speed  \\\n",
       "0         -0.076130                NaN         0.397954           0.428571       0.004924                                0.571429                             0.166667                           0.500000                                 193.164207                343.832288                         27775.358648                78.302352    0.181964       0.202055        1287.76138       71768.577533     1287.76138       -0.059093                NaN         0.630467           0.410714       0.004924                                0.428571                             0.500000                           0.666667                                 297.472879                544.723064                        129638.240310                98.151158       55.469478             0.209186              0.070736        0.138450        0.218418         0.199763   0.018655         231.797048          309.062731    -77.265683        13108.185152          17248.23328   -4140.048128      231.797048   \n",
       "1         -0.124122           0.101345         0.281698           0.285714       0.003409                                0.222222                             0.625000                           0.500000                                 169.984502                324.515868                         66147.441982                52.652750    0.195825       0.256928         38.632841        2945.787156      38.632841        0.143256           0.106136         0.680770           0.267857       0.006692                                0.222222                             0.625000                           0.625000                                 394.054982                784.246680                        321856.856124               117.218011       70.728617             0.080780              0.195825       -0.115046        0.188198         0.256928   -0.06873          19.316421           38.632841    -19.316421         1614.091544          2945.787156   -1331.695612       19.316421   \n",
       "2         -0.438456          -0.138087         0.053657           0.250000       0.000379                                1.000000                             0.000000                           1.000000                                  23.179705                 23.179705                            74.624822                 3.154358    0.082635       0.435554         51.510455        3938.723717      51.510455       -0.605130          -0.062250         0.366654           0.232143       0.005177                                1.000000                             0.000000                           0.333333                                 158.394650                158.394650                         25088.865066                74.667954       72.394746             0.036520              0.082635       -0.046115        0.386116         0.435554  -0.049438          103.02091           51.510455     51.510455         7707.086742          3938.723717    3768.363025       103.02091   \n",
       "3         -0.315231          -0.190859         0.228041           0.375000       0.002778                                0.461538                             0.250000                           0.583333                                 243.386901                394.054982                         37581.060223                42.932891    0.053207       0.296643         25.755228        2624.360536      25.755228       -0.006129          -0.614204         0.196741           0.285714       0.002652                                0.461538                             0.333333                           0.333333                                 204.754059                339.969004                         29969.328407                38.681102       93.619121             0.154733              0.053207        0.101526        0.267651         0.296643  -0.028992          51.510455           25.755228     25.755228         4881.332889          2624.360536    2256.972353       51.510455   \n",
       "4         -0.056180          -0.326396         0.309232           0.321429       0.006187                                0.250000                             0.421053                           0.315789                                 440.414392                846.059227                        219202.951351                64.734582    0.077488       0.273612         24.399689        2561.515198      24.399689       -0.173196          -0.354183         0.379833           0.303571       0.005303                                0.250000                             0.473684                           0.421053                                 521.543359               1039.223434                        378183.671566                81.592146       96.403550             0.193355              0.077488        0.115867        0.271203         0.273612   -0.00241               -0.0           24.399689    -24.399689           42.872316          2561.515198   -2518.642882             0.0   \n",
       "5         -0.198911          -0.114868         0.155605           0.285714       0.003157                                0.454545                             0.300000                           0.300000                                 131.351661                224.070480                         27521.634254                35.365407    0.179940         0.2616         15.453137        1712.967554      15.453137       -0.216538          -0.174607         0.292429           0.285714       0.004924                                0.454545                             0.400000                           0.200000                                 212.480628                421.097971                        129593.465417                68.598047       97.562339             0.246871              0.092392        0.154479         0.19915         0.190514   0.008636         185.437639           -46.35941    139.078229        18333.947462         -4322.244948   14011.702514      185.437639   \n",
       "..              ...                ...              ...                ...            ...                                     ...                                  ...                                ...                                        ...                       ...                                  ...                      ...         ...            ...               ...                ...            ...             ...                ...              ...                ...            ...                                     ...                                  ...                                ...                                        ...                       ...                                  ...                      ...             ...                  ...                   ...             ...             ...              ...        ...                ...                 ...           ...                 ...                  ...            ...             ...   \n",
       "701       -0.332933          -0.034595         0.008943           0.125000       0.000126                                1.000000                             0.000000                           0.333333                                   3.863284                  3.863284                            14.924964                 1.821170    0.434625       0.595968        257.552276      651480.446388     257.552276        0.075822          -0.327778         0.035771           0.160714       0.000253                                1.000000                             0.000000                           1.000000                                  15.453137                 15.453137                            29.849929                 1.821170     2528.653666             0.091767              0.109556       -0.017790        0.560355         0.694673  -0.134318         206.041821           51.510455    154.531366       521250.880835        130457.875507  390793.005328      206.041821   \n",
       "702        0.063218          -0.311708         0.351750           0.232143       0.004798                                0.400000                             0.444444                           0.555556                                 262.703322                455.867529                        106131.421465                67.235451    0.386839       0.235762         68.680607      174016.143436      68.680607        0.226795          -0.137310         0.217608           0.250000       0.003914                                0.400000                             0.444444                           0.444444                                 150.668081                282.019742                         62237.101323                51.738884     2530.589578             0.120425              0.365163       -0.244739        0.369944         0.346028   0.023917          51.510455           17.170152     34.340303       130596.228055         43655.951904    86940.27615       51.510455   \n",
       "703       -0.200046          -0.014375         0.195847           0.196429       0.003030                                0.545455                             0.200000                           0.500000                                 142.941513                282.019742                         31670.774342                38.534202    0.107869       0.309856              -0.0         208.993534            0.0       -0.474011           0.068312         0.375597           0.142857       0.005177                                0.363636                             0.500000                           0.600000                                 328.379152                540.859780                        150234.691108                75.289451     2531.245726             0.141667              0.107869        0.033798        0.272908         0.309856  -0.036948         -30.906273                -0.0     30.906273       -77995.721549           208.993534   77786.728015       30.906273   \n",
       "704       -0.054841           0.143237         0.000000           0.142857       0.000000                                1.000000                             0.000000                           1.500000                                   0.000000                  0.000000                             0.000000                 0.000000    0.059906       0.683487              -0.0          205.13025            0.0       -0.074826           0.543460         0.026828           0.125000       0.000126                                1.000000                             0.000000                           0.500000                                   0.000000                  7.726568                            59.699857                 3.863284     2533.065332             0.218361              0.059906        0.158455        0.582913         0.683487  -0.100574         231.797048                -0.0    231.797048       587399.864669            205.13025  587194.734419      231.797048   \n",
       "705       -0.177017           0.138727         0.295112           0.196429       0.002652                                1.000000                             0.000000                           0.500000                                  81.128967                 84.992251                          7223.682744                42.496126    0.254881       0.681812        386.328414      979382.299928     386.328414       -0.806843          -0.279302         0.067071           0.178571       0.000505                                1.000000                             0.000000                           1.000000                                  19.316421                 19.316421                           134.324679                 5.794926     2534.629471             0.000714              0.000245        0.000470         0.34638         0.327176   0.019204        -386.328414           77.265683    309.062731      -979006.808985        196011.203226  782995.605759      386.328414   \n",
       "706       -0.109581          -0.355186         0.447139           0.214286       0.003535                                0.400000                             0.555556                           0.222222                                   0.000000                579.492621                        169965.493973                74.690160    0.161478       0.353176         34.340303       87761.321869      34.340303       -0.178466          -0.173398         0.247417           0.178571       0.004040                                0.500000                             0.222222                           0.444444                                 193.164207                320.652584                         82788.777228                53.358854     2549.650222             0.313887              0.161478        0.152410         0.22545         0.353176  -0.127726         171.701517           34.340303    137.361214       438016.994619         87761.321869   350255.67275      171.701517   \n",
       "\n",
       "    short_best_speed  speed_diff  long_best_wcorr  short_best_wcorr  wcorr_diff  long_best_pearsonr  short_best_pearsonr  pearsonr_diff  long_best_travel  short_best_travel  travel_diff  long_best_coverage  short_best_coverage  coverage_diff  long_best_jump  short_best_jump  jump_diff  long_best_longest_sequence_length_ratio  short_best_longest_sequence_length_ratio  longest_sequence_length_ratio_diff  long_best_direction_change_bin_ratio  short_best_direction_change_bin_ratio  direction_change_bin_ratio_diff  long_best_congruent_dir_bins_ratio  short_best_congruent_dir_bins_ratio  congruent_dir_bins_ratio_diff  long_best_total_congruent_direction_change  short_best_total_congruent_direction_change  total_congruent_direction_change_diff  long_best_total_variation  short_best_total_variation  total_variation_diff  long_best_integral_second_derivative  short_best_integral_second_derivative  integral_second_derivative_diff  long_best_stddev_of_diff  short_best_stddev_of_diff  \\\n",
       "0         309.062731  -77.265683        -0.176375         -0.076130    0.100245                 NaN                  NaN            NaN          0.385125           0.397954    -0.012829            0.464286             0.428571       0.035714        0.003908         0.004924  -0.001016                                 0.571429                                  0.571429                            0.000000                              0.333333                               0.166667                         0.166667                            0.500000                             0.500000                       0.000000                                  351.558857                                   193.164207                             158.394650                 494.500370                  343.832288            150.668081                         101101.708481                           27775.358648                     73326.349832                110.807358                  78.302352   \n",
       "1          38.632841  -19.316421        -0.380997          0.143256    0.237741           -0.157490             0.106136       0.051354          0.449062           0.680770    -0.231708            0.339286             0.267857       0.071429        0.003993         0.006692  -0.002699                                 0.444444                                  0.222222                            0.222222                              0.500000                               0.625000                        -0.125000                            0.625000                             0.625000                       0.000000                                  486.773802                                   394.054982                              92.718819                 768.793544                  784.246680            -15.453137                         284648.920009                          321856.856124                    -37207.936115                114.211145                 117.218011   \n",
       "2          51.510455   51.510455        -0.589925         -0.605130   -0.015205           -0.195767            -0.062250       0.133517          0.300879           0.366654    -0.065775            0.196429             0.232143      -0.035714        0.004078         0.005177  -0.001099                                 1.000000                                  1.000000                            0.000000                              0.000000                               0.000000                         0.000000                            1.000000                             0.333333                       0.666667                                  193.164207                                   158.394650                              34.769557                 193.164207                  158.394650             34.769557                          32969.246241                           25088.865066                      7880.381175                 85.594972                  74.667954   \n",
       "3          25.755228   25.755228        -0.371648         -0.006129    0.365519           -0.488452            -0.614204      -0.125752          0.281322           0.196741     0.084580            0.196429             0.285714      -0.089286        0.004248         0.002652   0.001597                                 0.384615                                  0.461538                           -0.076923                              0.250000                               0.333333                        -0.083333                            0.416667                             0.333333                       0.083333                                  370.875277                                   204.754059                             166.121218                 722.434134                  339.969004            382.465130                         179607.020941                           29969.328407                    149637.692534                 95.838240                  38.681102   \n",
       "4          24.399689  -24.399689        -0.287724         -0.173196    0.114528           -0.328897            -0.354183      -0.025286          0.332550           0.379833    -0.047283            0.250000             0.303571      -0.053571        0.004588         0.005303  -0.000715                                 0.350000                                  0.250000                            0.100000                              0.421053                               0.473684                        -0.052632                            0.473684                             0.421053                       0.052632                                  780.383396                                   521.543359                             258.840037                1352.149449                 1039.223434            312.926015                         537985.264820                          378183.671566                    159801.593254                102.299414                  81.592146   \n",
       "5           46.35941  139.078229        -0.444081         -0.198911    0.245170           -0.189396            -0.114868       0.074528          0.243712           0.155605     0.088107            0.267857             0.285714      -0.017857        0.003653         0.003157   0.000497                                 0.363636                                  0.454545                           -0.090909                              0.500000                               0.300000                         0.200000                            0.300000                             0.300000                       0.000000                                  262.703322                                   131.351661                             131.351661                 521.543359                  224.070480            297.472879                         118623.616623                           27521.634254                     91101.982369                 79.201094                  35.365407   \n",
       "..               ...         ...              ...               ...         ...                 ...                  ...            ...               ...                ...          ...                 ...                  ...            ...             ...              ...        ...                                      ...                                       ...                                 ...                                   ...                                    ...                              ...                                 ...                                  ...                            ...                                         ...                                          ...                                    ...                        ...                         ...                   ...                                   ...                                    ...                              ...                       ...                        ...   \n",
       "701        51.510455  154.531366        -0.503169         -0.332933    0.170236           -0.292843            -0.034595       0.258249          0.036105           0.008943     0.027163            0.196429             0.125000       0.071429        0.000340         0.000126   0.000214                                 1.000000                                  1.000000                            0.000000                              0.000000                               0.000000                         0.000000                            0.666667                             0.333333                       0.333333                                   19.316421                                     3.863284                              15.453137                  23.179705                    3.863284             19.316421                            432.823966                              14.924964                       417.899002                  7.938294                   1.821170   \n",
       "702        17.170152   34.340303         0.268528          0.063218    0.205310           -0.403955            -0.311708       0.092247          0.343002           0.351750    -0.008748            0.178571             0.232143      -0.053571        0.003483         0.004798  -0.001315                                 0.400000                                  0.400000                            0.000000                              0.444444                               0.444444                         0.000000                            0.555556                             0.555556                       0.000000                                  339.969004                                   262.703322                              77.265683                 660.621588                  455.867529            204.754059                         284753.394759                          106131.421465                    178621.973294                103.472426                  67.235451   \n",
       "703              0.0   30.906273        -0.399121         -0.474011   -0.074890            0.260018             0.068312       0.191706          0.353834           0.375597    -0.021764            0.232143             0.142857       0.089286        0.003568         0.005177  -0.001608                                 0.363636                                  0.363636                            0.000000                              0.500000                               0.500000                         0.000000                            0.500000                             0.600000                      -0.100000                                  382.465130                                   328.379152                              54.085978                 757.203691                  540.859780            216.343912                         268485.183622                          150234.691108                    118250.492514                 98.643194                  75.289451   \n",
       "704              0.0  231.797048        -0.414762         -0.074826    0.339935            0.037655             0.543460      -0.505805          0.036105           0.026828     0.009277            0.178571             0.125000       0.053571        0.000255         0.000126   0.000129                                 1.000000                                  1.000000                            0.000000                              0.000000                               0.000000                         0.000000                            0.500000                             0.500000                       0.000000                                   11.589852                                     0.000000                              11.589852                  15.453137                    7.726568              7.726568                            238.799430                              59.699857                       179.099572                  7.726568                   3.863284   \n",
       "705        77.265683  309.062731        -0.651693         -0.177017    0.474676            0.065094             0.138727      -0.073633          0.315923           0.295112     0.020811            0.178571             0.196429      -0.017857        0.002804         0.002652   0.000152                                 0.666667                                  1.000000                           -0.333333                              0.500000                               0.000000                         0.500000                            0.500000                             0.500000                       0.000000                                  127.488377                                    81.128967                              46.359410                 135.214945                   84.992251             50.222694                          18283.081324                            7223.682744                     11059.398580                 67.607472                  42.496126   \n",
       "706        34.340303  137.361214        -0.158380         -0.178466   -0.020085           -0.344914            -0.173398       0.171516          0.340996           0.247417     0.093579            0.250000             0.178571       0.071429        0.004163         0.004040   0.000123                                 0.300000                                  0.500000                           -0.200000                              0.555556                               0.222222                         0.333333                            0.444444                             0.444444                       0.000000                                  367.011993                                   193.164207                             173.847786                 656.758304                  320.652584            336.105720                         208680.851487                           82788.777228                    125892.074259                 99.011647                  53.358854   \n",
       "\n",
       "     stddev_of_diff_diff  total_variation_BEST  integral_second_derivative_BEST  stddev_of_diff_BEST  score_BEST  \n",
       "0              32.505007            629.715315                    165443.229777           105.700424    0.177541  \n",
       "1              -3.006866            324.515868                     66147.441982            52.652750    0.278974  \n",
       "2              10.927018             23.179705                        74.624822             3.154358    0.485492  \n",
       "3              57.157137            548.586348                    140772.263712            76.462018    0.237150  \n",
       "4              20.707268            869.238931                    173711.660024            62.355277    0.181495  \n",
       "5              43.835687            421.097971                     57908.861663            67.071108    0.230922  \n",
       "..                   ...                   ...                              ...                  ...         ...  \n",
       "701             6.117125             15.453137                        29.849929             1.821170    0.595968  \n",
       "702            36.236975            282.019742                     62237.101323            51.738884    0.235762  \n",
       "703            23.353743            394.054982                    131876.984962            73.117181    0.438314  \n",
       "704             3.863284              3.863284                        14.924964             1.931642    0.670564  \n",
       "705            25.111347             34.769557                       134.324679             5.794926    0.616999  \n",
       "706            45.652793            355.422141                     78191.888209            73.368502    0.336876  \n",
       "\n",
       "[707 rows x 134 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_merged_scores_df: pd.DataFrame =  directional_decoders_epochs_decode_result.build_complete_all_scores_merged_df()\n",
    "extracted_merged_scores_df\n",
    "\n",
    "ripple_weighted_corr_merged_df = deepcopy(directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df)\n",
    "\n",
    "## Need 'best_decoder_index':... actually 'most_likely_decoder_index'\n",
    "\n",
    "# best_decoder_index = deepcopy(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result.filter_epochs['best_decoder_index']) # hope this is correct and not just like the best wcorr or something\n",
    "best_decoder_index = deepcopy(directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df['most_likely_decoder_index'])\n",
    "\n",
    "new_heuristic_checking_columns = ['total_variation', 'integral_second_derivative', 'stddev_of_diff', 'score'] # , 'integral_second_derivative', 'stddev_of_diff', 'score'\n",
    "# best_decoder_names = [['long_LR', 'long_RL', 'short_LR', 'short_RL'][an_idx] for an_idx in best_decoder_index]\n",
    "## Example: extracted_merged_scores_df[['total_variation_long_LR', 'total_variation_long_RL', 'total_variation_short_LR', 'total_variation_short_RL']]\n",
    "\n",
    "for a_score_col in new_heuristic_checking_columns:\n",
    "    curr_score_col_decoder_col_names = [f\"{a_score_col}_{a_decoder_name}\" for a_decoder_name in ['long_LR', 'long_RL', 'short_LR', 'short_RL']]\n",
    "    print(f'curr_score_col_decoder_col_names: {curr_score_col_decoder_col_names}')\n",
    "    # extracted_merged_scores_df\n",
    "    _final_out = [extracted_merged_scores_df[curr_score_col_decoder_col_names].to_numpy()[epoch_idx, a_decoder_idx] for epoch_idx, a_decoder_idx in zip(np.arange(np.shape(extracted_merged_scores_df)[0]), best_decoder_index.to_numpy())]\n",
    "    extracted_merged_scores_df[f\"{a_score_col}_BEST\"] = _final_out # extracted_merged_scores_df[curr_score_col_decoder_col_names].to_numpy()[best_decoder_index]\n",
    "\n",
    "extracted_merged_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f63d2c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">start</th>\n",
       "      <th colspan=\"4\" halign=\"left\">stop</th>\n",
       "      <th colspan=\"4\" halign=\"left\">label</th>\n",
       "      <th colspan=\"4\" halign=\"left\">duration</th>\n",
       "      <th colspan=\"4\" halign=\"left\">is_valid_epoch</th>\n",
       "      <th colspan=\"4\" halign=\"left\">P_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">P_RL</th>\n",
       "      <th colspan=\"4\" halign=\"left\">P_Long</th>\n",
       "      <th colspan=\"4\" halign=\"left\">P_Short</th>\n",
       "      <th colspan=\"4\" halign=\"left\">P_Long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">score_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">velocity_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">intercept_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">speed_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">wcorr_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">pearsonr_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">travel_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">coverage_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">jump_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">longest_sequence_length_ratio_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">direction_change_bin_ratio_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">congruent_dir_bins_ratio_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">total_congruent_direction_change_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">total_variation_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">integral_second_derivative_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">stddev_of_diff_long_LR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">P_Long_RL</th>\n",
       "      <th colspan=\"4\" halign=\"left\">score_long_RL</th>\n",
       "      <th colspan=\"4\" halign=\"left\">velocity_long_RL</th>\n",
       "      <th colspan=\"4\" halign=\"left\">intercept_long_RL</th>\n",
       "      <th colspan=\"4\" halign=\"left\">speed_long_RL</th>\n",
       "      <th colspan=\"4\" halign=\"left\">wcorr_long_RL</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">travel_diff</th>\n",
       "      <th colspan=\"4\" halign=\"left\">long_best_coverage</th>\n",
       "      <th colspan=\"4\" halign=\"left\">short_best_coverage</th>\n",
       "      <th colspan=\"4\" halign=\"left\">coverage_diff</th>\n",
       "      <th colspan=\"4\" halign=\"left\">long_best_jump</th>\n",
       "      <th colspan=\"4\" halign=\"left\">short_best_jump</th>\n",
       "      <th colspan=\"4\" halign=\"left\">jump_diff</th>\n",
       "      <th colspan=\"4\" halign=\"left\">long_best_longest_sequence_length_ratio</th>\n",
       "      <th colspan=\"4\" halign=\"left\">short_best_longest_sequence_length_ratio</th>\n",
       "      <th colspan=\"4\" halign=\"left\">longest_sequence_length_ratio_diff</th>\n",
       "      <th colspan=\"4\" halign=\"left\">long_best_direction_change_bin_ratio</th>\n",
       "      <th colspan=\"4\" halign=\"left\">short_best_direction_change_bin_ratio</th>\n",
       "      <th colspan=\"4\" halign=\"left\">direction_change_bin_ratio_diff</th>\n",
       "      <th colspan=\"4\" halign=\"left\">long_best_congruent_dir_bins_ratio</th>\n",
       "      <th colspan=\"4\" halign=\"left\">short_best_congruent_dir_bins_ratio</th>\n",
       "      <th colspan=\"4\" halign=\"left\">congruent_dir_bins_ratio_diff</th>\n",
       "      <th colspan=\"4\" halign=\"left\">long_best_total_congruent_direction_change</th>\n",
       "      <th colspan=\"4\" halign=\"left\">short_best_total_congruent_direction_change</th>\n",
       "      <th colspan=\"4\" halign=\"left\">total_congruent_direction_change_diff</th>\n",
       "      <th colspan=\"4\" halign=\"left\">long_best_total_variation</th>\n",
       "      <th colspan=\"4\" halign=\"left\">short_best_total_variation</th>\n",
       "      <th colspan=\"4\" halign=\"left\">total_variation_diff</th>\n",
       "      <th colspan=\"4\" halign=\"left\">long_best_integral_second_derivative</th>\n",
       "      <th colspan=\"4\" halign=\"left\">short_best_integral_second_derivative</th>\n",
       "      <th colspan=\"4\" halign=\"left\">integral_second_derivative_diff</th>\n",
       "      <th colspan=\"4\" halign=\"left\">long_best_stddev_of_diff</th>\n",
       "      <th colspan=\"4\" halign=\"left\">short_best_stddev_of_diff</th>\n",
       "      <th colspan=\"4\" halign=\"left\">stddev_of_diff_diff</th>\n",
       "      <th colspan=\"4\" halign=\"left\">total_variation_BEST</th>\n",
       "      <th colspan=\"4\" halign=\"left\">integral_second_derivative_BEST</th>\n",
       "      <th colspan=\"4\" halign=\"left\">stddev_of_diff_BEST</th>\n",
       "      <th colspan=\"4\" halign=\"left\">score_BEST</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_user_annotated_epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>1467.038537</td>\n",
       "      <td>55.469478</td>\n",
       "      <td>2549.650222</td>\n",
       "      <td>658.295764</td>\n",
       "      <td>1467.258647</td>\n",
       "      <td>55.668144</td>\n",
       "      <td>2549.918746</td>\n",
       "      <td>658.282946</td>\n",
       "      <td>inf</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>214.861608</td>\n",
       "      <td>0.22011</td>\n",
       "      <td>0.034437</td>\n",
       "      <td>0.578857</td>\n",
       "      <td>0.129684</td>\n",
       "      <td>0.552553</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.497604</td>\n",
       "      <td>0.575793</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.219260</td>\n",
       "      <td>0.424207</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.999041</td>\n",
       "      <td>0.219260</td>\n",
       "      <td>0.515102</td>\n",
       "      <td>2.097451e-09</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.225344</td>\n",
       "      <td>0.484898</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.225344</td>\n",
       "      <td>0.304988</td>\n",
       "      <td>2.700810e-10</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.215702</td>\n",
       "      <td>0.409835</td>\n",
       "      <td>0.121295</td>\n",
       "      <td>0.977222</td>\n",
       "      <td>0.200278</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>-386.328414</td>\n",
       "      <td>540.859780</td>\n",
       "      <td>319.186237</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>-979006.808985</td>\n",
       "      <td>1.366212e+06</td>\n",
       "      <td>430845.065011</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.859780</td>\n",
       "      <td>282.574543</td>\n",
       "      <td>-0.104643</td>\n",
       "      <td>-0.982003</td>\n",
       "      <td>0.975768</td>\n",
       "      <td>0.459098</td>\n",
       "      <td>-0.088997</td>\n",
       "      <td>-0.936793</td>\n",
       "      <td>0.948809</td>\n",
       "      <td>0.408616</td>\n",
       "      <td>0.218055</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.920689</td>\n",
       "      <td>0.152494</td>\n",
       "      <td>0.258553</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.105683</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.600429</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.294241</td>\n",
       "      <td>0.280693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.221962</td>\n",
       "      <td>0.580967</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.328725</td>\n",
       "      <td>223.749530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>981.274172</td>\n",
       "      <td>190.653453</td>\n",
       "      <td>397.858831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1889.145944</td>\n",
       "      <td>356.602429</td>\n",
       "      <td>123847.055645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>889871.149208</td>\n",
       "      <td>146727.339209</td>\n",
       "      <td>63.499662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.326292</td>\n",
       "      <td>39.674532</td>\n",
       "      <td>0.210114</td>\n",
       "      <td>1.827370e-09</td>\n",
       "      <td>0.963086</td>\n",
       "      <td>0.163480</td>\n",
       "      <td>0.351341</td>\n",
       "      <td>0.104022</td>\n",
       "      <td>0.976563</td>\n",
       "      <td>0.183944</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>-463.594097</td>\n",
       "      <td>1699.845022</td>\n",
       "      <td>421.138488</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>-1.172081e+06</td>\n",
       "      <td>4.283668e+06</td>\n",
       "      <td>698494.401038</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1699.845022</td>\n",
       "      <td>361.462219</td>\n",
       "      <td>-0.069874</td>\n",
       "      <td>-0.937777</td>\n",
       "      <td>0.957470</td>\n",
       "      <td>0.440980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033907</td>\n",
       "      <td>-1.205270</td>\n",
       "      <td>0.604365</td>\n",
       "      <td>0.207042</td>\n",
       "      <td>0.275257</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.117131</td>\n",
       "      <td>0.284776</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.106841</td>\n",
       "      <td>-0.009518</td>\n",
       "      <td>-0.303571</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.087580</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.006818</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>-0.000501</td>\n",
       "      <td>-0.005886</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.578669</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.281584</td>\n",
       "      <td>0.576261</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.286803</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.179280</td>\n",
       "      <td>0.307962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.216950</td>\n",
       "      <td>0.305717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.219977</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.194237</td>\n",
       "      <td>0.558916</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.299771</td>\n",
       "      <td>0.571921</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.345406</td>\n",
       "      <td>-0.013005</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.273411</td>\n",
       "      <td>251.113469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1120.352401</td>\n",
       "      <td>208.953839</td>\n",
       "      <td>187.767496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>842.195943</td>\n",
       "      <td>169.678990</td>\n",
       "      <td>63.345973</td>\n",
       "      <td>-664.484872</td>\n",
       "      <td>853.785795</td>\n",
       "      <td>165.549233</td>\n",
       "      <td>448.961165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2043.67731</td>\n",
       "      <td>386.615723</td>\n",
       "      <td>348.676252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1603.262918</td>\n",
       "      <td>315.206913</td>\n",
       "      <td>100.284913</td>\n",
       "      <td>-1062.403138</td>\n",
       "      <td>1271.020482</td>\n",
       "      <td>264.814075</td>\n",
       "      <td>149269.068876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.026091e+06</td>\n",
       "      <td>173419.786476</td>\n",
       "      <td>94780.986080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>721323.526847</td>\n",
       "      <td>123158.374358</td>\n",
       "      <td>54488.082796</td>\n",
       "      <td>-647012.129368</td>\n",
       "      <td>933422.195170</td>\n",
       "      <td>159659.624851</td>\n",
       "      <td>72.104512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>212.480628</td>\n",
       "      <td>42.935729</td>\n",
       "      <td>53.667054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>204.754059</td>\n",
       "      <td>36.292503</td>\n",
       "      <td>18.437458</td>\n",
       "      <td>-158.394650</td>\n",
       "      <td>155.584985</td>\n",
       "      <td>40.611093</td>\n",
       "      <td>367.285395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1657.348896</td>\n",
       "      <td>335.134845</td>\n",
       "      <td>108326.791875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.005331e+06</td>\n",
       "      <td>139201.844691</td>\n",
       "      <td>57.947414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>162.257934</td>\n",
       "      <td>38.604488</td>\n",
       "      <td>0.392730</td>\n",
       "      <td>0.106443</td>\n",
       "      <td>0.969285</td>\n",
       "      <td>0.200030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1448.983212</td>\n",
       "      <td>373.508345</td>\n",
       "      <td>2521.104844</td>\n",
       "      <td>601.508672</td>\n",
       "      <td>1449.249112</td>\n",
       "      <td>373.754474</td>\n",
       "      <td>2521.309347</td>\n",
       "      <td>601.505098</td>\n",
       "      <td>1.035987e+115</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>198.022209</td>\n",
       "      <td>0.26590</td>\n",
       "      <td>0.102113</td>\n",
       "      <td>0.523960</td>\n",
       "      <td>0.115726</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.300406</td>\n",
       "      <td>0.559201</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.939301</td>\n",
       "      <td>0.223955</td>\n",
       "      <td>0.440799</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.223955</td>\n",
       "      <td>0.626715</td>\n",
       "      <td>2.658031e-01</td>\n",
       "      <td>0.925001</td>\n",
       "      <td>0.162840</td>\n",
       "      <td>0.373285</td>\n",
       "      <td>0.074999</td>\n",
       "      <td>0.734197</td>\n",
       "      <td>0.162840</td>\n",
       "      <td>0.353776</td>\n",
       "      <td>5.454213e-02</td>\n",
       "      <td>0.760475</td>\n",
       "      <td>0.185554</td>\n",
       "      <td>0.350166</td>\n",
       "      <td>0.153734</td>\n",
       "      <td>0.613475</td>\n",
       "      <td>0.112572</td>\n",
       "      <td>92.177749</td>\n",
       "      <td>-494.500370</td>\n",
       "      <td>679.938009</td>\n",
       "      <td>235.571406</td>\n",
       "      <td>167222.686892</td>\n",
       "      <td>-533875.882195</td>\n",
       "      <td>1.099631e+06</td>\n",
       "      <td>363545.704474</td>\n",
       "      <td>174.360453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>679.938009</td>\n",
       "      <td>181.773036</td>\n",
       "      <td>-0.209711</td>\n",
       "      <td>-0.919924</td>\n",
       "      <td>0.913879</td>\n",
       "      <td>0.585474</td>\n",
       "      <td>-0.168806</td>\n",
       "      <td>-0.869232</td>\n",
       "      <td>0.842920</td>\n",
       "      <td>0.460481</td>\n",
       "      <td>0.187973</td>\n",
       "      <td>0.02407</td>\n",
       "      <td>0.487424</td>\n",
       "      <td>0.093564</td>\n",
       "      <td>0.306620</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.087199</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.00017</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.610555</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.300196</td>\n",
       "      <td>0.239817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.201457</td>\n",
       "      <td>0.558394</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.193950</td>\n",
       "      <td>240.560108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>556.312916</td>\n",
       "      <td>141.224106</td>\n",
       "      <td>382.653583</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>931.051478</td>\n",
       "      <td>268.437027</td>\n",
       "      <td>95387.995301</td>\n",
       "      <td>134.324679</td>\n",
       "      <td>457942.681032</td>\n",
       "      <td>100655.570981</td>\n",
       "      <td>59.508192</td>\n",
       "      <td>5.463509</td>\n",
       "      <td>142.169381</td>\n",
       "      <td>27.925019</td>\n",
       "      <td>0.272939</td>\n",
       "      <td>4.914280e-02</td>\n",
       "      <td>0.862759</td>\n",
       "      <td>0.177063</td>\n",
       "      <td>0.357123</td>\n",
       "      <td>0.163036</td>\n",
       "      <td>0.697011</td>\n",
       "      <td>0.152577</td>\n",
       "      <td>45.546521</td>\n",
       "      <td>-734.023987</td>\n",
       "      <td>656.758304</td>\n",
       "      <td>226.951694</td>\n",
       "      <td>113781.385805</td>\n",
       "      <td>-5.866627e+05</td>\n",
       "      <td>1.300433e+06</td>\n",
       "      <td>330900.543532</td>\n",
       "      <td>134.338884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>734.023987</td>\n",
       "      <td>187.444151</td>\n",
       "      <td>-0.212546</td>\n",
       "      <td>-0.916330</td>\n",
       "      <td>0.806392</td>\n",
       "      <td>0.527904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012775</td>\n",
       "      <td>-0.474072</td>\n",
       "      <td>0.347076</td>\n",
       "      <td>0.165828</td>\n",
       "      <td>0.294861</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.105729</td>\n",
       "      <td>0.342334</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0.088018</td>\n",
       "      <td>-0.047474</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.073259</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.00101</td>\n",
       "      <td>0.006566</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>-0.004315</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.503451</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.252423</td>\n",
       "      <td>0.496776</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.249338</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.210882</td>\n",
       "      <td>0.346560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.207873</td>\n",
       "      <td>0.304551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.183725</td>\n",
       "      <td>0.042009</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.243989</td>\n",
       "      <td>0.470080</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.165730</td>\n",
       "      <td>0.518456</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.174307</td>\n",
       "      <td>-0.048376</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.185307</td>\n",
       "      <td>305.482126</td>\n",
       "      <td>42.496126</td>\n",
       "      <td>668.348156</td>\n",
       "      <td>151.469292</td>\n",
       "      <td>184.683827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>428.824540</td>\n",
       "      <td>108.572099</td>\n",
       "      <td>120.798299</td>\n",
       "      <td>-150.668081</td>\n",
       "      <td>459.730813</td>\n",
       "      <td>140.962298</td>\n",
       "      <td>511.084224</td>\n",
       "      <td>50.222694</td>\n",
       "      <td>1166.71181</td>\n",
       "      <td>300.681968</td>\n",
       "      <td>328.473378</td>\n",
       "      <td>42.496126</td>\n",
       "      <td>834.469374</td>\n",
       "      <td>211.732094</td>\n",
       "      <td>182.610845</td>\n",
       "      <td>-332.242436</td>\n",
       "      <td>703.117713</td>\n",
       "      <td>229.210351</td>\n",
       "      <td>164624.904902</td>\n",
       "      <td>4089.440231</td>\n",
       "      <td>4.579427e+05</td>\n",
       "      <td>132359.328274</td>\n",
       "      <td>63654.244889</td>\n",
       "      <td>1328.321827</td>\n",
       "      <td>292991.975078</td>\n",
       "      <td>70607.621627</td>\n",
       "      <td>100970.660013</td>\n",
       "      <td>-168010.323644</td>\n",
       "      <td>343259.254996</td>\n",
       "      <td>124868.016435</td>\n",
       "      <td>79.244003</td>\n",
       "      <td>19.751506</td>\n",
       "      <td>146.177580</td>\n",
       "      <td>29.010907</td>\n",
       "      <td>46.862270</td>\n",
       "      <td>12.748187</td>\n",
       "      <td>127.323642</td>\n",
       "      <td>23.292359</td>\n",
       "      <td>32.381733</td>\n",
       "      <td>-77.821191</td>\n",
       "      <td>102.172915</td>\n",
       "      <td>37.841324</td>\n",
       "      <td>351.181951</td>\n",
       "      <td>15.453137</td>\n",
       "      <td>857.649079</td>\n",
       "      <td>246.837563</td>\n",
       "      <td>83242.714558</td>\n",
       "      <td>134.324679</td>\n",
       "      <td>3.152749e+05</td>\n",
       "      <td>82709.621064</td>\n",
       "      <td>55.364423</td>\n",
       "      <td>5.463509</td>\n",
       "      <td>142.169381</td>\n",
       "      <td>26.201733</td>\n",
       "      <td>0.366264</td>\n",
       "      <td>0.191636</td>\n",
       "      <td>0.697011</td>\n",
       "      <td>0.124797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               start                                              stop                                               label                      duration                               is_valid_epoch                             P_LR                                    P_RL                                  P_Long                                     P_Short                               P_Long_LR                                   score_long_LR                               velocity_long_LR                                     intercept_long_LR                                             speed_long_LR                              wcorr_long_LR                               pearsonr_long_LR                               travel_long_LR                              coverage_long_LR                               jump_long_LR                              longest_sequence_length_ratio_long_LR                        direction_change_bin_ratio_long_LR                       \\\n",
       "                                mean         min          max         std         mean         min          max         std           mean  min max         std     mean       min       max       std           mean    min   max       std      mean       min       max       std      mean       min       max       std      mean           min       max       std      mean       min       max       std      mean           min       max       std          mean       min       max       std             mean         min         max         std              mean            min           max            std          mean  min         max         std          mean       min       max       std             mean       min       max       std           mean      min       max       std             mean       min       max       std         mean      min       max       std                                  mean     min  max       std                               mean  min   max       std   \n",
       "is_user_annotated_epoch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "False                    1467.038537   55.469478  2549.650222  658.295764  1467.258647   55.668144  2549.918746  658.282946            inf    1  99  214.861608  0.22011  0.034437  0.578857  0.129684       0.552553  False  True  0.497604  0.575793  0.000959  0.999993  0.219260  0.424207  0.000007  0.999041  0.219260  0.515102  2.097451e-09  0.999993  0.225344  0.484898  0.000007  1.000000  0.225344  0.304988  2.700810e-10  0.999986  0.215702      0.409835  0.121295  0.977222  0.200278            [nan] -386.328414  540.859780  319.186237             [nan] -979006.808985  1.366212e+06  430845.065011         [nan]  0.0  540.859780  282.574543     -0.104643 -0.982003  0.975768  0.459098        -0.088997 -0.936793  0.948809  0.408616       0.218055  0.00000  0.920689  0.152494         0.258553  0.071429  0.607143  0.105683     0.002674  0.00000  0.004673  0.001523                              0.600429  0.1250  1.0  0.294241                           0.280693  0.0  0.90  0.221962   \n",
       "True                     1448.983212  373.508345  2521.104844  601.508672  1449.249112  373.754474  2521.309347  601.505098  1.035987e+115  100  82  198.022209  0.26590  0.102113  0.523960  0.115726       0.902439  False  True  0.300406  0.559201  0.059459  0.939301  0.223955  0.440799  0.060699  0.940541  0.223955  0.626715  2.658031e-01  0.925001  0.162840  0.373285  0.074999  0.734197  0.162840  0.353776  5.454213e-02  0.760475  0.185554      0.350166  0.153734  0.613475  0.112572        92.177749 -494.500370  679.938009  235.571406     167222.686892 -533875.882195  1.099631e+06  363545.704474    174.360453  0.0  679.938009  181.773036     -0.209711 -0.919924  0.913879  0.585474        -0.168806 -0.869232  0.842920  0.460481       0.187973  0.02407  0.487424  0.093564         0.306620  0.142857  0.500000  0.087199     0.002955  0.00017  0.004503  0.001071                              0.610555  0.1875  1.0  0.300196                           0.239817  0.0  0.75  0.201457   \n",
       "\n",
       "                        congruent_dir_bins_ratio_long_LR                          total_congruent_direction_change_long_LR                              total_variation_long_LR                                     integral_second_derivative_long_LR                                           stddev_of_diff_long_LR                                  P_Long_RL                                   score_long_RL                               velocity_long_RL                                      intercept_long_RL                                            speed_long_RL                               wcorr_long_RL                                ... travel_diff                               long_best_coverage                               short_best_coverage                               coverage_diff                               long_best_jump                               short_best_jump                              jump_diff                               long_best_longest_sequence_length_ratio  \\\n",
       "                                                    mean       min  max       std                                     mean  min         max         std                    mean        min          max         std                               mean         min            max            std                   mean       min         max        std      mean           min       max       std          mean       min       max       std             mean         min          max         std              mean           min           max            std          mean  min          max         std          mean       min       max       std  ...        mean       min       max       std               mean       min       max       std                mean       min       max       std          mean       min       max       std           mean       min       max       std            mean      min       max       std      mean       min       max       std                                    mean   \n",
       "is_user_annotated_epoch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...                                                                                                                                                                                                                                                                                                                                                                      \n",
       "False                                           0.580967  0.090909  2.0  0.328725                               223.749530  0.0  981.274172  190.653453              397.858831   0.000000  1889.145944  356.602429                      123847.055645    0.000000  889871.149208  146727.339209              63.499662  0.000000  160.326292  39.674532  0.210114  1.827370e-09  0.963086  0.163480      0.351341  0.104022  0.976563  0.183944            [nan] -463.594097  1699.845022  421.138488             [nan] -1.172081e+06  4.283668e+06  698494.401038         [nan]  0.0  1699.845022  361.462219     -0.069874 -0.937777  0.957470  0.440980  ...   -0.033907 -1.205270  0.604365  0.207042           0.275257  0.071429  0.607143  0.117131            0.284776  0.053571  0.625000  0.106841     -0.009518 -0.303571  0.357143  0.087580       0.002907  0.000000  0.004673  0.001524        0.003409  0.00000  0.006818  0.002156 -0.000501 -0.005886  0.004037  0.001754                                0.578669   \n",
       "True                                            0.558394  0.235294  1.0  0.193950                               240.560108  0.0  556.312916  141.224106              382.653583  15.453137   931.051478  268.437027                       95387.995301  134.324679  457942.681032  100655.570981              59.508192  5.463509  142.169381  27.925019  0.272939  4.914280e-02  0.862759  0.177063      0.357123  0.163036  0.697011  0.152577        45.546521 -734.023987   656.758304  226.951694     113781.385805 -5.866627e+05  1.300433e+06  330900.543532    134.338884  0.0   734.023987  187.444151     -0.212546 -0.916330  0.806392  0.527904  ...    0.012775 -0.474072  0.347076  0.165828           0.294861  0.142857  0.500000  0.105729            0.342334  0.196429  0.517857  0.088018     -0.047474 -0.214286  0.071429  0.073259       0.003432  0.000765  0.004673  0.000939        0.003197  0.00101  0.006566  0.001465  0.000235 -0.004315  0.003199  0.001744                                0.503451   \n",
       "\n",
       "                                                 short_best_longest_sequence_length_ratio                          longest_sequence_length_ratio_diff                               long_best_direction_change_bin_ratio                          short_best_direction_change_bin_ratio                          direction_change_bin_ratio_diff                               long_best_congruent_dir_bins_ratio                           short_best_congruent_dir_bins_ratio                               congruent_dir_bins_ratio_diff                               long_best_total_congruent_direction_change                                     short_best_total_congruent_direction_change                              total_congruent_direction_change_diff                                     long_best_total_variation                                    short_best_total_variation                                     total_variation_diff                                        \\\n",
       "                              min  max       std                                     mean       min  max       std                               mean       min       max       std                                 mean  min       max       std                                  mean  min       max       std                            mean       min       max       std                               mean       min   max       std                                mean       min       max       std                          mean       min       max       std                                       mean        min          max         std                                        mean  min         max         std                                  mean         min         max         std                      mean        min         max         std                       mean        min          max         std                 mean          min          max         std   \n",
       "is_user_annotated_epoch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "False                    0.142857  1.0  0.281584                                 0.576261  0.090909  1.0  0.286803                           0.002408 -0.666667  0.600000  0.179280                             0.307962  0.0  0.833333  0.216950                              0.305717  0.0  0.800000  0.219977                        0.002245 -0.666667  0.666667  0.194237                           0.558916  0.090909  2.00  0.299771                            0.571921  0.111111  2.000000  0.345406                     -0.013005 -1.000000  1.000000  0.273411                                 251.113469   0.000000  1120.352401  208.953839                                  187.767496  0.0  842.195943  169.678990                             63.345973 -664.484872  853.785795  165.549233                448.961165   0.000000  2043.67731  386.615723                 348.676252   0.000000  1603.262918  315.206913           100.284913 -1062.403138  1271.020482  264.814075   \n",
       "True                     0.200000  1.0  0.252423                                 0.496776  0.153846  1.0  0.249338                           0.006675 -0.400000  0.714286  0.210882                             0.346560  0.0  0.750000  0.207873                              0.304551  0.0  0.666667  0.183725                        0.042009 -0.666667  0.500000  0.243989                           0.470080  0.142857  0.75  0.165730                            0.518456  0.166667  0.857143  0.174307                     -0.048376 -0.571429  0.416667  0.185307                                 305.482126  42.496126   668.348156  151.469292                                  184.683827  0.0  428.824540  108.572099                            120.798299 -150.668081  459.730813  140.962298                511.084224  50.222694  1166.71181  300.681968                 328.473378  42.496126   834.469374  211.732094           182.610845  -332.242436   703.117713  229.210351   \n",
       "\n",
       "                        long_best_integral_second_derivative                                           short_best_integral_second_derivative                                            integral_second_derivative_diff                                              long_best_stddev_of_diff                                   short_best_stddev_of_diff                                   stddev_of_diff_diff                                    total_variation_BEST                                     integral_second_derivative_BEST                                          stddev_of_diff_BEST                                  score_BEST                                \n",
       "                                                        mean          min           max            std                                  mean          min            max            std                            mean            min            max            std                     mean        min         max        std                      mean        min         max        std                mean         min         max        std                 mean        min          max         std                            mean         min           max            std                mean       min         max        std       mean       min       max       std  \n",
       "is_user_annotated_epoch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "False                                          149269.068876     0.000000  1.026091e+06  173419.786476                          94780.986080     0.000000  721323.526847  123158.374358                    54488.082796 -647012.129368  933422.195170  159659.624851                72.104512   0.000000  212.480628  42.935729                 53.667054   0.000000  204.754059  36.292503           18.437458 -158.394650  155.584985  40.611093           367.285395   0.000000  1657.348896  335.134845                   108326.791875    0.000000  1.005331e+06  139201.844691           57.947414  0.000000  162.257934  38.604488   0.392730  0.106443  0.969285  0.200030  \n",
       "True                                           164624.904902  4089.440231  4.579427e+05  132359.328274                          63654.244889  1328.321827  292991.975078   70607.621627                   100970.660013 -168010.323644  343259.254996  124868.016435                79.244003  19.751506  146.177580  29.010907                 46.862270  12.748187  127.323642  23.292359           32.381733  -77.821191  102.172915  37.841324           351.181951  15.453137   857.649079  246.837563                    83242.714558  134.324679  3.152749e+05   82709.621064           55.364423  5.463509  142.169381  26.201733   0.366264  0.191636  0.697011  0.124797  \n",
       "\n",
       "[2 rows x 532 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_merged_scores_df.groupby('is_user_annotated_epoch').agg(['mean', 'min', 'max', 'std']) ## successfully got the most-likely decoder for each epoch using the sequenceless probabilities and used this to selected the appopriate column for each of the heuristic measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f34a23a",
   "metadata": {},
   "source": [
    "### Continue something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcea0bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'long_LR': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: pandas.core.frame.DataFrame,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs)\n",
       " ),\n",
       " 'long_RL': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: pandas.core.frame.DataFrame,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs)\n",
       " ),\n",
       " 'short_LR': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: pandas.core.frame.DataFrame,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs)\n",
       " ),\n",
       " 'short_RL': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: pandas.core.frame.DataFrame,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs)\n",
       " )}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_epochs_df_dict = {k:deepcopy(v.filter_epochs) for k,v in filtered_decoder_filter_epochs_decoder_result_dict.items()}\n",
    "# filter_epochs_df_dict\n",
    "\n",
    "high_wcorr_filter_epochs_dict = {k:np.where((v['wcorr'].abs() >= 0.9))[0] for k,v in filter_epochs_df_dict.items()}\n",
    "# high_wcorr_filter_epochs_dict\n",
    "\n",
    "high_wcorr_any_epochs = union_of_arrays(*[v for k,v in high_wcorr_filter_epochs_dict.items()]) # get unique indicies\n",
    "# high_wcorr_any_epochs\n",
    "\n",
    "# high_wcorr_only_filtered_decoder_filter_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "high_wcorr_included_epoch_times = {k:v.iloc[high_wcorr_any_epochs][['start', 'stop']].to_numpy() for k,v in filter_epochs_df_dict.items()}\n",
    "# high_wcorr_included_epoch_times\n",
    "\n",
    "high_wcorr_only_filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(high_wcorr_included_epoch_times[a_name]) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "high_wcorr_only_filtered_decoder_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cb0cf21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  8,  24,  68,  73, 111, 116, 129, 188, 190, 211, 279, 303, 306, 312, 322, 359], dtype=int64),)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Find high wcorr values:\n",
    "filter_epochs = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "\n",
    "# np.sum((filter_epochs['wcorr'].abs() > 0.9))\n",
    "\n",
    "np.where((filter_epochs['wcorr'].abs() > 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ad6af",
   "metadata": {},
   "source": [
    "### :🎯:🟢 2024-05-24 07:24 - Shuffed WCorr Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ec946511",
   "metadata": {},
   "outputs": [],
   "source": [
    "## wcorr is computed on each decoded posterior: `curr_results_obj.p_x_given_n_list`\n",
    "\n",
    "## Actually need to shuffle the unit idenities and recompute the posteriors\n",
    "\n",
    "\n",
    "## ALT: `_perform_compute_custom_epoch_decoding` via `_compute_lap_and_ripple_epochs_decoding_for_decoder`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_lap_and_ripple_epochs_decoding_for_decoder\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _perform_compute_custom_epoch_decoding\n",
    "\n",
    "from neuropy.utils.misc import build_shuffled_ids, shuffle_ids # used in _SHELL_analyze_leave_one_out_decoding_results\n",
    "\n",
    "## INPUTS: num_shuffles\n",
    "num_shuffles: int = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ddfef8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasePositionDecoder(pf=PfND(spikes_df=None, position=None, epochs=None, config=<PlacefieldComputationParameters: {'speed_thresh': 10.0, 'grid_bin': (3.8632841399651463, 1.0), 'grid_bin_bounds': ((37.0773897438341, 250.69004399129707), (0, 4)), 'smooth': (2.0, 0.0), 'frate_thresh': 0.0, 'is_directional': True};>, position_srate=29.969773148751475, setup_on_init=False, compute_on_init=False, _save_intermediate_spikes_maps=True, _included_thresh_neurons_indx=None, _peak_frate_filter_function=None, _ratemap=<Ratemap: {'_filename': None, '_metadata': None, 'spikes_maps': array([[[  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   2],\n",
       "        ...,\n",
       "        [ 15, 123,   0,   0],\n",
       "        [  0,  36,   0,   0],\n",
       "        [  0,   0,   0,   0]],\n",
       "\n",
       "       [[ 33,  64,   0,   0],\n",
       "        [ 20,  27,   0,   0],\n",
       "        [ 10,  17,  18,   2],\n",
       "        ...,\n",
       "        [  8,  46,   0,   0],\n",
       "        [  0,  12,   0,   0],\n",
       "        [  0,   0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        ...,\n",
       "        [  6,   8,   0,   0],\n",
       "        [  0,   1,   0,   0],\n",
       "        [  0,   0,   0,   0]],\n",
       "\n",
       "       [[  3,  10,   0,   0],\n",
       "        [  0,   5,   0,   0],\n",
       "        [  0,  12,   0,   0],\n",
       "        ...,\n",
       "        [  6, 115,   0,   0],\n",
       "        [  0, 102,   0,   0],\n",
       "        [  0,   0,   0,   0]],\n",
       "\n",
       "       [[ 37,  30,   0,   0],\n",
       "        [ 92,  23,   0,   0],\n",
       "        [ 74,   6,   0,   0],\n",
       "        ...,\n",
       "        [  1,   1,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0]]]), 'tuning_curves': array([[[0, 0, 0.0136134, 0.117196],\n",
       "        [0, 0, 0.0192507, 0.128101],\n",
       "        [0, 0, 0.0264464, 0.131387],\n",
       "        ...,\n",
       "        [6.96741, 6.40515, 0.000476045, 0.00140438],\n",
       "        [4.68707, 5.11899, 0, 0.000154267],\n",
       "        [3.31604, 4.24666, 0, 0]],\n",
       "\n",
       "       [[4.79512, 6.53717, 0.981514, 0.489772],\n",
       "        [4.34933, 6.31153, 1.22084, 0.740366],\n",
       "        [3.57349, 5.78829, 1.507, 1.12561],\n",
       "        ...,\n",
       "        [2.86219, 2.7231, 0.000192444, 0.00111219],\n",
       "        [2.03176, 2.15533, 0, 0.000154267],\n",
       "        [1.50821, 1.75065, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.0640674, 0, 0, 0],\n",
       "        [0.102305, 0, 0, 0],\n",
       "        [0.161534, 0, 0, 0],\n",
       "        ...,\n",
       "        [3.09311, 0.593101, 0.000536817, 0.00145751],\n",
       "        [2.06664, 0.420561, 0, 0.000154267],\n",
       "        [1.44573, 0.308619, 0, 0]],\n",
       "\n",
       "       [[0.454945, 2.54759, 0, 0],\n",
       "        [0.590754, 3.07206, 0, 0],\n",
       "        [0.824094, 3.78823, 0, 0],\n",
       "        ...,\n",
       "        [1.82573, 6.50977, 0, 0],\n",
       "        [1.39642, 6.17399, 0, 0],\n",
       "        [1.09813, 5.9348, 0, 0]],\n",
       "\n",
       "       [[16.4415, 3.42252, 0, 0.0289449],\n",
       "        [16.3819, 3.05027, 0, 0.043519],\n",
       "        [15.4299, 2.38843, 0, 0.0644255],\n",
       "        ...,\n",
       "        [0.150041, 0.275749, 0, 0],\n",
       "        [0.136703, 0.174827, 0, 0],\n",
       "        [0.121329, 0.111271, 0, 0]]]), 'unsmoothed_tuning_maps': array([[[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0.630943],\n",
       "        ...,\n",
       "        [9.56482, 8.71461, 0, 0],\n",
       "        [0, 4.51428, 0, 0],\n",
       "        [0, 0, 0, 0]],\n",
       "\n",
       "       [[5.95785, 6.68315, 0, 0],\n",
       "        [5.60183, 6.97572, 0, 0],\n",
       "        [3.15471, 6.21325, 3.57256, 0.630943],\n",
       "        ...,\n",
       "        [5.10124, 3.25912, 0, 0],\n",
       "        [0, 1.50476, 0, 0],\n",
       "        [0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        ...,\n",
       "        [3.82593, 0.566804, 0, 0],\n",
       "        [0, 0.125397, 0, 0],\n",
       "        [0, 0, 0, 0]],\n",
       "\n",
       "       [[0.541622, 1.04424, 0, 0],\n",
       "        [0, 1.2918, 0, 0],\n",
       "        [0, 4.38582, 0, 0],\n",
       "        ...,\n",
       "        [3.82593, 8.14781, 0, 0],\n",
       "        [0, 12.7904, 0, 0],\n",
       "        [0, 0, 0, 0]],\n",
       "\n",
       "       [[6.68001, 3.13273, 0, 0],\n",
       "        [25.7684, 5.94228, 0, 0],\n",
       "        [23.3449, 2.19291, 0, 0],\n",
       "        ...,\n",
       "        [0.637655, 0.0708505, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]]]), '_neuron_ids': array([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 31, 32, 33, 35, 37, 38, 39, 40, 41, 43, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 89, 91, 92, 94, 95, 97]), '_neuron_extended_ids': [NeuronExtendedIdentityTuple(shank=1, cluster=8, id=4), NeuronExtendedIdentityTuple(shank=1, cluster=9, id=5), NeuronExtendedIdentityTuple(shank=1, cluster=11, id=6), NeuronExtendedIdentityTuple(shank=1, cluster=12, id=7), NeuronExtendedIdentityTuple(shank=1, cluster=14, id=8), NeuronExtendedIdentityTuple(shank=1, cluster=16, id=9), NeuronExtendedIdentityTuple(shank=2, cluster=2, id=10), NeuronExtendedIdentityTuple(shank=2, cluster=3, id=11), NeuronExtendedIdentityTuple(shank=2, cluster=5, id=12), NeuronExtendedIdentityTuple(shank=2, cluster=7, id=13), NeuronExtendedIdentityTuple(shank=2, cluster=13, id=15), NeuronExtendedIdentityTuple(shank=2, cluster=16, id=16), NeuronExtendedIdentityTuple(shank=2, cluster=19, id=18), NeuronExtendedIdentityTuple(shank=2, cluster=20, id=19), NeuronExtendedIdentityTuple(shank=2, cluster=21, id=20), NeuronExtendedIdentityTuple(shank=2, cluster=25, id=21), NeuronExtendedIdentityTuple(shank=2, cluster=26, id=22), NeuronExtendedIdentityTuple(shank=2, cluster=28, id=23), NeuronExtendedIdentityTuple(shank=2, cluster=30, id=24), NeuronExtendedIdentityTuple(shank=2, cluster=33, id=25), NeuronExtendedIdentityTuple(shank=3, cluster=2, id=28), NeuronExtendedIdentityTuple(shank=3, cluster=10, id=31), NeuronExtendedIdentityTuple(shank=3, cluster=11, id=32), NeuronExtendedIdentityTuple(shank=3, cluster=12, id=33), NeuronExtendedIdentityTuple(shank=3, cluster=16, id=35), NeuronExtendedIdentityTuple(shank=4, cluster=3, id=37), NeuronExtendedIdentityTuple(shank=4, cluster=4, id=38), NeuronExtendedIdentityTuple(shank=4, cluster=5, id=39), NeuronExtendedIdentityTuple(shank=4, cluster=6, id=40), NeuronExtendedIdentityTuple(shank=4, cluster=7, id=41), NeuronExtendedIdentityTuple(shank=7, cluster=5, id=43), NeuronExtendedIdentityTuple(shank=7, cluster=9, id=47), NeuronExtendedIdentityTuple(shank=8, cluster=6, id=49), NeuronExtendedIdentityTuple(shank=8, cluster=7, id=50), NeuronExtendedIdentityTuple(shank=8, cluster=10, id=51), NeuronExtendedIdentityTuple(shank=8, cluster=17, id=52), NeuronExtendedIdentityTuple(shank=8, cluster=18, id=53), NeuronExtendedIdentityTuple(shank=8, cluster=20, id=54), NeuronExtendedIdentityTuple(shank=8, cluster=21, id=55), NeuronExtendedIdentityTuple(shank=8, cluster=22, id=56), NeuronExtendedIdentityTuple(shank=8, cluster=23, id=57), NeuronExtendedIdentityTuple(shank=8, cluster=28, id=60), NeuronExtendedIdentityTuple(shank=8, cluster=29, id=61), NeuronExtendedIdentityTuple(shank=9, cluster=2, id=62), NeuronExtendedIdentityTuple(shank=9, cluster=3, id=63), NeuronExtendedIdentityTuple(shank=9, cluster=7, id=64), NeuronExtendedIdentityTuple(shank=9, cluster=11, id=68), NeuronExtendedIdentityTuple(shank=9, cluster=12, id=69), NeuronExtendedIdentityTuple(shank=9, cluster=14, id=71), NeuronExtendedIdentityTuple(shank=9, cluster=18, id=72), NeuronExtendedIdentityTuple(shank=10, cluster=2, id=73), NeuronExtendedIdentityTuple(shank=10, cluster=3, id=74), NeuronExtendedIdentityTuple(shank=10, cluster=4, id=75), NeuronExtendedIdentityTuple(shank=10, cluster=5, id=76), NeuronExtendedIdentityTuple(shank=10, cluster=17, id=77), NeuronExtendedIdentityTuple(shank=10, cluster=20, id=79), NeuronExtendedIdentityTuple(shank=10, cluster=21, id=80), NeuronExtendedIdentityTuple(shank=10, cluster=23, id=81), NeuronExtendedIdentityTuple(shank=10, cluster=25, id=82), NeuronExtendedIdentityTuple(shank=11, cluster=2, id=83), NeuronExtendedIdentityTuple(shank=11, cluster=3, id=84), NeuronExtendedIdentityTuple(shank=11, cluster=4, id=85), NeuronExtendedIdentityTuple(shank=12, cluster=7, id=89), NeuronExtendedIdentityTuple(shank=12, cluster=17, id=91), NeuronExtendedIdentityTuple(shank=12, cluster=22, id=92), NeuronExtendedIdentityTuple(shank=12, cluster=28, id=94), NeuronExtendedIdentityTuple(shank=12, cluster=29, id=95), NeuronExtendedIdentityTuple(shank=12, cluster=32, id=97)], 'xbin': array([37.0774, 40.9407, 44.804, 48.6672, 52.5305, 56.3938, 60.2571, 64.1204, 67.9837, 71.8469, 75.7102, 79.5735, 83.4368, 87.3001, 91.1634, 95.0267, 98.8899, 102.753, 106.617, 110.48, 114.343, 118.206, 122.07, 125.933, 129.796, 133.659, 137.523, 141.386, 145.249, 149.113, 152.976, 156.839, 160.702, 164.566, 168.429, 172.292, 176.156, 180.019, 183.882, 187.745, 191.609, 195.472, 199.335, 203.199, 207.062, 210.925, 214.788, 218.652, 222.515, 226.378, 230.242, 234.105, 237.968, 241.831, 245.695, 249.558, 253.421]), 'ybin': array([0, 1, 2, 3, 4]), 'occupancy': array([[5.53891, 9.57632, 0, 0],\n",
       "       [3.57026, 3.87057, 0, 0],\n",
       "       [3.16986, 2.73609, 5.03841, 3.16986],\n",
       "       [7.14053, 4.97168, 13.4802, 7.8746],\n",
       "       [4.20424, 6.87359, 6.07278, 6.33972],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 1.90192, 0.133468],\n",
       "       [0.033367, 0, 0.166835, 0.0333669],\n",
       "       [0, 0, 0, 0.0333669],\n",
       "       [0.900908, 1.00101, 1.06774, 1.50151],\n",
       "       [0, 0, 0.0333669, 0.0667339],\n",
       "       [0, 0, 0.100101, 0.100101],\n",
       "       [0, 0, 0.0667339, 0.0667339],\n",
       "       [0, 0, 0.100101, 0.100101],\n",
       "       [0, 0, 0.100101, 0.43377],\n",
       "       [0, 0, 0, 0.166835],\n",
       "       [0, 0, 0, 0.133468],\n",
       "       [0, 0, 0.200202, 0],\n",
       "       [0.266936, 0, 0.166835, 0],\n",
       "       [0, 0, 0.0667339, 0],\n",
       "       [8.1749, 9.07581, 7.44083, 9.50958],\n",
       "       [4.00403, 3.3367, 4.30434, 3.23659],\n",
       "       [1.76845, 1.50151, 1.96865, 1.20121],\n",
       "       [2.20222, 1.90192, 1.80182, 1.43478],\n",
       "       [2.10212, 1.46815, 1.46815, 1.43478],\n",
       "       [2.10212, 1.53488, 1.86855, 1.56825],\n",
       "       [2.16885, 1.70171, 1.93528, 1.50151],\n",
       "       [1.70171, 1.10111, 1.63498, 1.06774],\n",
       "       [2.10212, 2.06875, 2.36905, 2.00202],\n",
       "       [1.90192, 1.40141, 3.23659, 1.96865],\n",
       "       [2.10212, 1.56825, 5.80585, 3.30333],\n",
       "       [1.83518, 1.63498, 2.90292, 2.06875],\n",
       "       [1.66835, 1.56825, 2.30232, 2.80282],\n",
       "       [1.80182, 1.80182, 2.20222, 2.73609],\n",
       "       [1.33468, 1.40141, 2.53589, 4.10413],\n",
       "       [1.70171, 2.63599, 6.60666, 10.0768],\n",
       "       [2.50252, 2.13548, 0, 0.43377],\n",
       "       [4.97168, 3.90393, 0, 0],\n",
       "       [3.06976, 2.23559, 0, 0],\n",
       "       [5.60565, 4.77147, 0, 0],\n",
       "       [3.80383, 5.60565, 0, 0],\n",
       "       [2.10212, 0.800807, 0, 0],\n",
       "       [5.57228, 1.73508, 0, 0],\n",
       "       [1.56825, 14.1142, 0, 0],\n",
       "       [0.033367, 7.9747, 0, 0],\n",
       "       [0, 0, 0, 0]])};>, _ratemap_spiketrains=None, _ratemap_spiketrains_pos=None, _filtered_pos_df=None, _filtered_spikes_df=None, ndim=2, xbin=array([37.0774, 40.9407, 44.804, 48.6672, 52.5305, 56.3938, 60.2571, 64.1204, 67.9837, 71.8469, 75.7102, 79.5735, 83.4368, 87.3001, 91.1634, 95.0267, 98.8899, 102.753, 106.617, 110.48, 114.343, 118.206, 122.07, 125.933, 129.796, 133.659, 137.523, 141.386, 145.249, 149.113, 152.976, 156.839, 160.702, 164.566, 168.429, 172.292, 176.156, 180.019, 183.882, 187.745, 191.609, 195.472, 199.335, 203.199, 207.062, 210.925, 214.788, 218.652, 222.515, 226.378, 230.242, 234.105, 237.968, 241.831, 245.695, 249.558, 253.421]), ybin=array([0, 1, 2, 3, 4]), bin_info=None), neuron_IDXs=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]), neuron_IDs=array([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 31, 32, 33, 35, 37, 38, 39, 40, 41, 43, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 89, 91, 92, 94, 95, 97]), F=array([[0, 4.79512, 0, ..., 0.0640674, 0.454945, 16.4415],\n",
       "       [0, 6.53717, 0, ..., 0, 2.54759, 3.42252],\n",
       "       [0.0136134, 0.981514, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4.24666, 1.75065, 0, ..., 0.308619, 5.9348, 0.111271],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]]), P_x=array([[5.53891],\n",
       "       [9.57632],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3.57026],\n",
       "       [3.87057],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3.16986],\n",
       "       [2.73609],\n",
       "       [5.03841],\n",
       "       [3.16986],\n",
       "       [7.14053],\n",
       "       [4.97168],\n",
       "       [13.4802],\n",
       "       [7.8746],\n",
       "       [4.20424],\n",
       "       [6.87359],\n",
       "       [6.07278],\n",
       "       [6.33972],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1.90192],\n",
       "       [0.133468],\n",
       "       [0.033367],\n",
       "       [0],\n",
       "       [0.166835],\n",
       "       [0.0333669],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0.0333669],\n",
       "       [0.900908],\n",
       "       [1.00101],\n",
       "       [1.06774],\n",
       "       [1.50151],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0.0333669],\n",
       "       [0.0667339],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0.100101],\n",
       "       [0.100101],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0.0667339],\n",
       "       [0.0667339],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0.100101],\n",
       "       [0.100101],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0.100101],\n",
       "       [0.43377],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0.166835],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0.133468],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0.200202],\n",
       "       [0],\n",
       "       [0.266936],\n",
       "       [0],\n",
       "       [0.166835],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0.0667339],\n",
       "       [0],\n",
       "       [8.1749],\n",
       "       [9.07581],\n",
       "       [7.44083],\n",
       "       [9.50958],\n",
       "       [4.00403],\n",
       "       [3.3367],\n",
       "       [4.30434],\n",
       "       [3.23659],\n",
       "       [1.76845],\n",
       "       [1.50151],\n",
       "       [1.96865],\n",
       "       [1.20121],\n",
       "       [2.20222],\n",
       "       [1.90192],\n",
       "       [1.80182],\n",
       "       [1.43478],\n",
       "       [2.10212],\n",
       "       [1.46815],\n",
       "       [1.46815],\n",
       "       [1.43478],\n",
       "       [2.10212],\n",
       "       [1.53488],\n",
       "       [1.86855],\n",
       "       [1.56825],\n",
       "       [2.16885],\n",
       "       [1.70171],\n",
       "       [1.93528],\n",
       "       [1.50151],\n",
       "       [1.70171],\n",
       "       [1.10111],\n",
       "       [1.63498],\n",
       "       [1.06774],\n",
       "       [2.10212],\n",
       "       [2.06875],\n",
       "       [2.36905],\n",
       "       [2.00202],\n",
       "       [1.90192],\n",
       "       [1.40141],\n",
       "       [3.23659],\n",
       "       [1.96865],\n",
       "       [2.10212],\n",
       "       [1.56825],\n",
       "       [5.80585],\n",
       "       [3.30333],\n",
       "       [1.83518],\n",
       "       [1.63498],\n",
       "       [2.90292],\n",
       "       [2.06875],\n",
       "       [1.66835],\n",
       "       [1.56825],\n",
       "       [2.30232],\n",
       "       [2.80282],\n",
       "       [1.80182],\n",
       "       [1.80182],\n",
       "       [2.20222],\n",
       "       [2.73609],\n",
       "       [1.33468],\n",
       "       [1.40141],\n",
       "       [2.53589],\n",
       "       [4.10413],\n",
       "       [1.70171],\n",
       "       [2.63599],\n",
       "       [6.60666],\n",
       "       [10.0768],\n",
       "       [2.50252],\n",
       "       [2.13548],\n",
       "       [0],\n",
       "       [0.43377],\n",
       "       [4.97168],\n",
       "       [3.90393],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3.06976],\n",
       "       [2.23559],\n",
       "       [0],\n",
       "       [0],\n",
       "       [5.60565],\n",
       "       [4.77147],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3.80383],\n",
       "       [5.60565],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2.10212],\n",
       "       [0.800807],\n",
       "       [0],\n",
       "       [0],\n",
       "       [5.57228],\n",
       "       [1.73508],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1.56825],\n",
       "       [14.1142],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0.033367],\n",
       "       [7.9747],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]]), setup_on_init=True, post_load_on_init=True, debug_print=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 46 38 51 28  6 60 34  4 65 22 20 21  5 53 64  3 24 62 41 59 58 54 18 25 32 44 36 45 39 50 15 67  9 19 42 49  7 35 40 56 33 29 11 52 27 30 10 26 31  2 57 66 47 48 61 43 17  8 12 16 23 13 63 14 55  1  0], a_shuffle_aclus: [54 68 55 74 40 10 84 51  8 94 32 28 31  9 76 92  7 35 89 60 83 82 77 24 37 49 63 53 64 56 73 21 97 13 25 61 72 11 52 57 80 50 41 16 75 39 43 15 38 47  6 81 95 69 71 85 62 23 12 18 22 33 19 91 20 79  5  4]\n",
      "a_shuffle_IDXs: [ 7 56 21 44 53 26 66 54 20  1 36 38 51 22 16 63 50 12 42 61 19  0 11 13 10 67 37 15 31  3  5 43 46 47  8 52 45 62 59 48 64 27 65 29  2  6 14 49 28 25 39 33  4 55 35 24 57 17 32  9 58 41 18 23 40 34 60 30], a_shuffle_aclus: [11 80 31 63 76 38 95 77 28  5 53 55 74 32 22 91 73 18 61 85 25  4 16 19 15 97 54 21 47  7  9 62 68 69 12 75 64 89 83 71 92 39 94 41  6 10 20 72 40 37 56 50  8 79 52 35 81 23 49 13 82 60 24 33 57 51 84 43]\n",
      "a_shuffle_IDXs: [ 5  0 61 46 12 60 15 63 40 62 26 25  8 21 52 53 47 30 50 16 66 11 27 54 44 51  1 48 31 36 58 39 28 37 41 14 65 43 59  7  4 49 55 20 42 67 35 19  3 32 33 23 38 17 45 18 64  9 34 10 13  6 24 29 57  2 56 22], a_shuffle_aclus: [ 9  4 85 68 18 84 21 91 57 89 38 37 12 31 75 76 69 43 73 22 95 16 39 77 63 74  5 71 47 53 82 56 40 54 60 20 94 62 83 11  8 72 79 28 61 97 52 25  7 49 50 33 55 23 64 24 92 13 51 15 19 10 35 41 81  6 80 32]\n",
      "a_shuffle_IDXs: [29  6 13 10 31 19  3 22  2 16 60  9 64 48 17 47 20  0 15 26 51 23 11 34  5 36  8 41 52  4 49 67 40 57 18 12 59 14 25 27 63 39 24 28 21 58 42 45 54 50 46 38 55 32 62 44 37 65 30 66 53  7 33 43 35 61 56  1], a_shuffle_aclus: [41 10 19 15 47 25  7 32  6 22 84 13 92 71 23 69 28  4 21 38 74 33 16 51  9 53 12 60 75  8 72 97 57 81 24 18 83 20 37 39 91 56 35 40 31 82 61 64 77 73 68 55 79 49 89 63 54 94 43 95 76 11 50 62 52 85 80  5]\n",
      "a_shuffle_IDXs: [55 25  2 46 66 32 28 21 36 61 65 19 22 24 38 63 41 48  3  1 34  9 15 23  4 35  5 43 10 30 45  8 56  0 12 26 18 40 11 47 50 59 27 33 37 60 44 14 62 67  7 54 64 31 42 58 20 52 49 57  6 17 13 29 51 16 53 39], a_shuffle_aclus: [79 37  6 68 95 49 40 31 53 85 94 25 32 35 55 91 60 71  7  5 51 13 21 33  8 52  9 62 15 43 64 12 80  4 18 38 24 57 16 69 73 83 39 50 54 84 63 20 89 97 11 77 92 47 61 82 28 75 72 81 10 23 19 41 74 22 76 56]\n"
     ]
    }
   ],
   "source": [
    "## Shuffle the neuron_ids for a `alt_directional_merged_decoders_result` - `DirectionalPseudo2DDecodersResult `:\n",
    "\n",
    "an_all_directional_pf1D_Decoder: BasePositionDecoder = deepcopy(alt_directional_merged_decoders_result.all_directional_pf1D_Decoder) # BasePositionDecoder\n",
    "an_all_directional_pf1D_Decoder\n",
    "\n",
    "## Single\n",
    "# shuffled_aclus, shuffle_IDXs = shuffle_ids(an_all_directional_pf1D_Decoder.neuron_IDs)\n",
    "# an_all_directional_pf1D_Decoder.pf.ratemap.tuning_curves = an_all_directional_pf1D_Decoder.pf.ratemap.tuning_curves[shuffle_IDXs]\n",
    "\n",
    "shuffled_aclus, shuffle_IDXs = build_shuffled_ids(an_all_directional_pf1D_Decoder.neuron_IDs, num_shuffles=num_shuffles, seed=None)\n",
    "\n",
    "for a_shuffle_IDXs, a_shuffle_aclus in zip(shuffle_IDXs, shuffled_aclus):\n",
    "    print(f'a_shuffle_IDXs: {a_shuffle_IDXs}, a_shuffle_aclus: {a_shuffle_aclus}')\n",
    "    # an_all_directional_pf1D_Decoder.pf.ratemap.tuning_curves = an_all_directional_pf1D_Decoder.pf.ratemap.tuning_curves[a_shuffle_IDXs]\n",
    "    an_all_directional_pf1D_Decoder.pf.ratemap = an_all_directional_pf1D_Decoder.pf.ratemap.get_by_id(a_shuffle_aclus)\n",
    "    # an_all_directional_pf1D_Decoder.pf = an_all_directional_pf1D_Decoder.pf.get_by_id(a_shuffle_aclus)\n",
    "\n",
    "    # 'neuron_IDs', 'neuron_IDs', 'F', 'P_X'\n",
    "    neuron_indexed_field_names = ['neuron_IDs', 'neuron_IDs']\n",
    "    for a_field in neuron_indexed_field_names:\n",
    "        # an_all_directional_pf1D_Decoder.\n",
    "        setattr(an_all_directional_pf1D_Decoder, a_field, getattr(an_all_directional_pf1D_Decoder, a_field)[a_shuffle_IDXs])\n",
    "        # neuron_IDs[a_shuffle_IDXs]\n",
    "\n",
    "# an_all_directional_pf1D_Decoder.pf.get_by_id(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "daaf3b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "912672e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 41 67 33  1  4 22 42 17 46 32  6 57 15 55 60  0 65 44 21 49 53 25 56 11 61 62 58 10 20 48 24 52 39 37 30 45 51 43 28 34 18 35 31 19 59 38  9 50 23 29 16 54 27 63 12  8 40 66  5  3 13 64  7  2 26 47 36], a_shuffle_aclus: [38 22 61 39 33 62 89 11 31 56 20 73 54 69  5  6  4 97 19 25 55 74 68 63 76 51 77 82 92 80 94 95 32 40 37  9 43 57 75 49 15 41 16 23 83 79  7 91 13 53 50 72 24 52 35 85 47  8 81 12 60 71 21 28 64 84 10 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:333: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.025).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.025.\t707 remain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:333: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:333: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:333: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 54 62 42 47  2  7 20 21  6 56 37 32 31 17 64  8  1 41 48 15 34 65 51  4  9 19 14 59 36 33 46 28  5 45 67 61 13 35 24 50 63 44 49 55 39 40 29 12 10 26  3 23 53 43 66 22 60  0 27 18 25 16 52 58 30 57 38], a_shuffle_aclus: [76 24 77 11 10 64 28 80 25 73 63 37 20 23 31 21 47 33 22 94 69 15 97 57 62 91 83 38 79 18 39 56 49 12 43 61 51 71 16 95 13 35 19 55  5 40  8 50 85 92 84 60 53 74 75 81 89  6  4 52 41 68 72 32 82  9 54  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:333: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropShorterMode:\n",
      "\tminimum_event_duration present (minimum_event_duration=0.025).\n",
      "\tdropping 0 that are shorter than our minimum_event_duration of 0.025.\t707 remain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:333: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:333: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:333: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:333: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from neuropy.utils.mixins.binning_helpers import find_minimum_time_bin_duration\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _check_result_laps_epochs_df_performance\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _perform_compute_custom_epoch_decoding\n",
    "DecodedEpochsResultsDict = NewType('DecodedEpochsResultsDict', Dict[types.DecoderName, DecodedFilterEpochsResult]) # A Dict containing the decoded filter epochs result for each of the four 1D decoder names\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_lap_and_ripple_epochs_decoding_for_decoder, _perform_compute_custom_epoch_decoding, _compute_all_df_score_metrics\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import compute_weighted_correlations\n",
    "ShuffleIdx = NewType('ShuffleIdx', int)\n",
    "\n",
    "## All templates AND merged decode:\n",
    "def _try_all_templates_decode(spikes_df: pd.DataFrame, a_directional_merged_decoders_result: DirectionalPseudo2DDecodersResult, use_single_time_bin_per_epoch: bool,\n",
    "                        desired_laps_decoding_time_bin_size: Optional[float]=None, desired_ripple_decoding_time_bin_size: Optional[float]=None, desired_shared_decoding_time_bin_size: Optional[float]=None, minimum_event_duration: Optional[float]=None) -> Tuple[DirectionalPseudo2DDecodersResult, Tuple[DecodedEpochsResultsDict, DecodedEpochsResultsDict]]: #-> Dict[str, DirectionalPseudo2DDecodersResult]:\n",
    "    \"\"\" decodes laps and ripples for a single bin size but for each of the four track templates. \n",
    "    \n",
    "    Added 2024-05-23 04:23 \n",
    "\n",
    "    desired_laps_decoding_time_bin_size\n",
    "    desired_ripple_decoding_time_bin_size\n",
    "    minimum_event_duration: if provided, excludes all events shorter than minimum_event_duration\n",
    "\n",
    "    Uses:\n",
    "        .all_directional_pf1D_Decoder - calling `decode_specific_epochs(...)` on it\n",
    "\n",
    "    Looks like it updates:\n",
    "        .all_directional_laps_filter_epochs_decoder_result, .all_directional_ripple_filter_epochs_decoder_result, and whatever .perform_compute_marginals() updates\n",
    "\n",
    "    \n",
    "    Compared to `_compute_lap_and_ripple_epochs_decoding_for_decoder`, it looks like this only computes for the `*all*_directional_pf1D_Decoder` while `_compute_lap_and_ripple_epochs_decoding_for_decoder` is called for each separate directional pf1D decoder\n",
    "\n",
    "    Usage:\n",
    "\n",
    "        from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function, _try_all_templates_decode\n",
    "\n",
    "    \"\"\"\n",
    "    ripple_decoding_time_bin_size = None\n",
    "    if desired_shared_decoding_time_bin_size is not None:\n",
    "        assert desired_laps_decoding_time_bin_size is None\n",
    "        assert desired_ripple_decoding_time_bin_size is None\n",
    "        desired_laps_decoding_time_bin_size = desired_shared_decoding_time_bin_size\n",
    "        desired_ripple_decoding_time_bin_size = desired_shared_decoding_time_bin_size\n",
    "        \n",
    "    # Separate the decoder first so they're all independent:\n",
    "    a_directional_merged_decoders_result = deepcopy(a_directional_merged_decoders_result)\n",
    "\n",
    "    ## Decode Laps:\n",
    "    laps_epochs_df = deepcopy(a_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result.filter_epochs)\n",
    "    if not isinstance(laps_epochs_df, pd.DataFrame):\n",
    "        laps_epochs_df = laps_epochs_df.to_dataframe()\n",
    "    # global_any_laps_epochs_obj = deepcopy(owning_pipeline_reference.computation_results[global_epoch_name].computation_config.pf_params.computation_epochs) # global_epoch_name='maze_any' (? same as global_epoch_name?)\n",
    "    min_possible_laps_time_bin_size: float = find_minimum_time_bin_duration(laps_epochs_df['duration'].to_numpy())\n",
    "    min_bounded_laps_decoding_time_bin_size: float = min(desired_laps_decoding_time_bin_size, min_possible_laps_time_bin_size) # 10ms # 0.002\n",
    "    if desired_laps_decoding_time_bin_size < min_bounded_laps_decoding_time_bin_size:\n",
    "        print(f'WARN: desired_laps_decoding_time_bin_size: {desired_laps_decoding_time_bin_size} < min_bounded_laps_decoding_time_bin_size: {min_bounded_laps_decoding_time_bin_size}... hopefully it works.')\n",
    "    laps_decoding_time_bin_size: float = desired_laps_decoding_time_bin_size # allow direct use\n",
    "    if use_single_time_bin_per_epoch:\n",
    "        laps_decoding_time_bin_size = None\n",
    "\n",
    "        \n",
    "    a_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result = a_directional_merged_decoders_result.all_directional_pf1D_Decoder.decode_specific_epochs(spikes_df=deepcopy(spikes_df), filter_epochs=laps_epochs_df,\n",
    "                                                                                                                                                    decoding_time_bin_size=laps_decoding_time_bin_size, use_single_time_bin_per_epoch=use_single_time_bin_per_epoch, debug_print=False)\n",
    "\n",
    "    ## Decode Ripples: ripples are kinda optional (if `desired_ripple_decoding_time_bin_size is None` they are not computed.\n",
    "    if desired_ripple_decoding_time_bin_size is not None:\n",
    "        # global_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(owning_pipeline_reference.filtered_sessions[global_epoch_name].replay))\n",
    "        replay_epochs_df = deepcopy(a_directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result.filter_epochs)\n",
    "        if not isinstance(replay_epochs_df, pd.DataFrame):\n",
    "            replay_epochs_df = replay_epochs_df.to_dataframe()\n",
    "        ripple_decoding_time_bin_size: float = desired_ripple_decoding_time_bin_size # allow direct use            \n",
    "        ## Drop those less than the time bin duration\n",
    "        print(f'DropShorterMode:')\n",
    "        pre_drop_n_epochs = len(replay_epochs_df)\n",
    "        if minimum_event_duration is not None:                \n",
    "            replay_epochs_df = replay_epochs_df[replay_epochs_df['duration'] > minimum_event_duration]\n",
    "            post_drop_n_epochs = len(replay_epochs_df)\n",
    "            n_dropped_epochs = post_drop_n_epochs - pre_drop_n_epochs\n",
    "            print(f'\\tminimum_event_duration present (minimum_event_duration={minimum_event_duration}).\\n\\tdropping {n_dropped_epochs} that are shorter than our minimum_event_duration of {minimum_event_duration}.', end='\\t')\n",
    "        else:\n",
    "            replay_epochs_df = replay_epochs_df[replay_epochs_df['duration'] > desired_ripple_decoding_time_bin_size]\n",
    "            post_drop_n_epochs = len(replay_epochs_df)\n",
    "            n_dropped_epochs = post_drop_n_epochs - pre_drop_n_epochs\n",
    "            print(f'\\tdropping {n_dropped_epochs} that are shorter than our ripple decoding time bin size of {desired_ripple_decoding_time_bin_size}', end='\\t') \n",
    "\n",
    "        print(f'{post_drop_n_epochs} remain.')\n",
    "\n",
    "        # returns a `DecodedFilterEpochsResult`\n",
    "        a_directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result = a_directional_merged_decoders_result.all_directional_pf1D_Decoder.decode_specific_epochs(spikes_df=deepcopy(spikes_df), filter_epochs=replay_epochs_df,\n",
    "                                                                                                                                                                                        decoding_time_bin_size=ripple_decoding_time_bin_size, use_single_time_bin_per_epoch=use_single_time_bin_per_epoch, debug_print=False)\n",
    "\n",
    "\n",
    "    a_directional_merged_decoders_result.perform_compute_marginals() # this only works for the pseudo2D decoder, not the individual 1D ones\n",
    "\n",
    "\n",
    "    # directional_merged_decoders_result_dict: Dict[types.DecoderName, DirectionalPseudo2DDecodersResult] = {}\n",
    "\n",
    "    decoder_laps_filter_epochs_decoder_result_dict: DecodedEpochsResultsDict = {}\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict: DecodedEpochsResultsDict = {}\n",
    "    \n",
    "    for a_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "        # external-function way:\n",
    "        decoder_laps_filter_epochs_decoder_result_dict[a_name], decoder_ripple_filter_epochs_decoder_result_dict[a_name] = _compute_lap_and_ripple_epochs_decoding_for_decoder(a_decoder, curr_active_pipeline, desired_laps_decoding_time_bin_size=laps_decoding_time_bin_size, desired_ripple_decoding_time_bin_size=ripple_decoding_time_bin_size)\n",
    "\n",
    "\n",
    "    #TODO 2024-05-24 08:52: - [ ] WHat is this?\n",
    "    # decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict = _perform_compute_custom_epoch_decoding(curr_active_pipeline, a_directional_merged_decoders_result, track_templates) # Dict[str, Optional[DecodedFilterEpochsResult]]\n",
    "\n",
    "    # ## Recompute the epoch scores/metrics such as radon transform and wcorr:\n",
    "    # (decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict), merged_df_outputs_tuple, raw_dict_outputs_tuple = _compute_all_df_score_metrics(a_directional_merged_decoders_result, track_templates,\n",
    "    #                                                                                                                                                                                     decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "    #                                                                                                                                                                                     spikes_df=deepcopy(spikes_df),\n",
    "    #                                                                                                                                                                                     should_skip_radon_transform=True)\n",
    "    \n",
    "    # laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df, laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df = merged_df_outputs_tuple\n",
    "    # decoder_laps_radon_transform_df_dict, decoder_ripple_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict, decoder_ripple_radon_transform_extras_dict, decoder_laps_weighted_corr_df_dict, decoder_ripple_weighted_corr_df_dict = raw_dict_outputs_tuple\n",
    "\n",
    "\n",
    "    # for a_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    #     decoder_laps_filter_epochs_decoder_result_dict[a_name], decoder_ripple_filter_epochs_decoder_result_dict[a_name] = _compute_lap_and_ripple_epochs_decoding_for_decoder(a_decoder, curr_active_pipeline, desired_laps_decoding_time_bin_size=laps_decoding_time_bin_size, desired_ripple_decoding_time_bin_size=ripple_decoding_time_bin_size)\n",
    "\n",
    "    return a_directional_merged_decoders_result, (decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "    \n",
    "\n",
    "def add_session_df_columns(df: pd.DataFrame, session_name: str, curr_session_t_delta: Optional[float], time_col: str) -> pd.DataFrame:\n",
    "    \"\"\" adds session-specific information to the marginal dataframes \"\"\"\n",
    "    df['session_name'] = session_name \n",
    "    if curr_session_t_delta is not None:\n",
    "        df['delta_aligned_start_t'] = df[time_col] - curr_session_t_delta\n",
    "    return df\n",
    "\n",
    "# BEGIN BLOCK 2 - modernizing from `_perform_compute_custom_epoch_decoding`  ________________________________________________________________________________________________________ #\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# BEGIN FUNCTION BODY                                                                                                  #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "## Copy the default result:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "alt_directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = deepcopy(directional_merged_decoders_result)\n",
    "\n",
    "\n",
    "a_sweep_dict = dict(desired_shared_decoding_time_bin_size=alt_directional_merged_decoders_result.ripple_decoding_time_bin_size, use_single_time_bin_per_epoch=False, minimum_event_duration=alt_directional_merged_decoders_result.ripple_decoding_time_bin_size)\n",
    "\n",
    "# Uses: session_ctxt_key, all_param_sweep_options\n",
    "# output_alt_directional_merged_decoders_result: Dict[Tuple, Dict[types.DecoderName, DirectionalPseudo2DDecodersResult]] = {} # empty dict\n",
    "\n",
    "output_alt_directional_merged_decoders_result: Dict[ShuffleIdx, DirectionalPseudo2DDecodersResult] = {} # empty dict\n",
    "# output_alt_directional_merged_decoders_result: Dict[Tuple, Dict[types.DecoderName, DirectionalPseudo2DDecodersResult]] = {} # empty dict\n",
    "\n",
    "# Tuple[DirectionalPseudo2DDecodersResult, Tuple[DecodedEpochsResultsDict, DecodedEpochsResultsDict]]\n",
    "output_directional_decoders_epochs_decode_results_dict: Dict[ShuffleIdx, DecoderDecodedEpochsResult] = {} # `_decode_and_evaluate_epochs_using_directional_decoders`-style output\n",
    "\n",
    "output_laps_decoding_accuracy_results_dict = {} # empty dict\n",
    "output_extracted_result_tuples = {}\n",
    "\n",
    "shuffled_aclus, shuffle_IDXs = build_shuffled_ids(an_all_directional_pf1D_Decoder.neuron_IDs, num_shuffles=num_shuffles, seed=None)\n",
    "\n",
    "## FOR EACH SHUFFLE:\n",
    "for i, a_shuffle_IDXs, a_shuffle_aclus in zip(np.arange(num_shuffles), shuffle_IDXs, shuffled_aclus):\n",
    "    print(f'a_shuffle_IDXs: {a_shuffle_IDXs}, a_shuffle_aclus: {a_shuffle_aclus}')\n",
    "\n",
    "    an_all_directional_pf1D_Decoder = deepcopy(alt_directional_merged_decoders_result.all_directional_pf1D_Decoder)\n",
    "\n",
    "    \n",
    "    # an_all_directional_pf1D_Decoder.pf.ratemap.tuning_curves = an_all_directional_pf1D_Decoder.pf.ratemap.tuning_curves[a_shuffle_IDXs]\n",
    "    an_all_directional_pf1D_Decoder.pf.ratemap = an_all_directional_pf1D_Decoder.pf.ratemap.get_by_id(a_shuffle_aclus)\n",
    "\n",
    "    # 'neuron_IDs', 'neuron_IDs', 'F', 'P_X'\n",
    "    neuron_indexed_field_names = ['neuron_IDs', 'neuron_IDs']\n",
    "    for a_field in neuron_indexed_field_names:\n",
    "        # an_all_directional_pf1D_Decoder.\n",
    "        setattr(an_all_directional_pf1D_Decoder, a_field, getattr(an_all_directional_pf1D_Decoder, a_field)[a_shuffle_IDXs])\n",
    "\n",
    "    \n",
    "    alt_directional_merged_decoders_result.all_directional_pf1D_Decoder = an_all_directional_pf1D_Decoder\n",
    "\n",
    "    # for a_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    #     decoder_laps_filter_epochs_decoder_result_dict[a_name], decoder_ripple_filter_epochs_decoder_result_dict[a_name] = _compute_lap_and_ripple_epochs_decoding_for_decoder(a_decoder, curr_active_pipeline, desired_laps_decoding_time_bin_size=laps_decoding_time_bin_size, desired_ripple_decoding_time_bin_size=ripple_decoding_time_bin_size)\n",
    "\n",
    "\n",
    "    # output_alt_directional_merged_decoders_result[a_sweep_tuple] = _try_all_templates_decode(curr_active_pipeline, alt_directional_merged_decoders_result, **a_sweep_dict) # type: ignore\n",
    "\n",
    "    output_alt_directional_merged_decoders_result[i], (decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict) = _try_all_templates_decode(spikes_df=deepcopy(curr_active_pipeline.sess.spikes_df), a_directional_merged_decoders_result=alt_directional_merged_decoders_result,\n",
    "                                                                                                                                                                                      **a_sweep_dict)\n",
    "    an_alt_dir_Pseudo2D_decoders_result = output_alt_directional_merged_decoders_result[i]\n",
    "\n",
    "\n",
    "    ## Decode epochs for all four decoders:\n",
    "    laps_time_bin_marginals_df: pd.DataFrame = an_alt_dir_Pseudo2D_decoders_result.laps_time_bin_marginals_df.copy()\n",
    "    laps_all_epoch_bins_marginals_df: pd.DataFrame = an_alt_dir_Pseudo2D_decoders_result.laps_all_epoch_bins_marginals_df.copy()\n",
    "    \n",
    "    ## Ripples:\n",
    "    ripple_time_bin_marginals_df: pd.DataFrame = an_alt_dir_Pseudo2D_decoders_result.ripple_time_bin_marginals_df.copy()\n",
    "    ripple_all_epoch_bins_marginals_df: pd.DataFrame = an_alt_dir_Pseudo2D_decoders_result.ripple_all_epoch_bins_marginals_df.copy()\n",
    "\n",
    "    session_name = curr_session_name\n",
    "    curr_session_t_delta = t_delta\n",
    "    \n",
    "    for a_df, a_time_bin_column_name in zip((laps_time_bin_marginals_df, laps_all_epoch_bins_marginals_df, ripple_time_bin_marginals_df, ripple_all_epoch_bins_marginals_df), ('t_bin_center', 'lap_start_t', 't_bin_center', 'ripple_start_t')):\n",
    "        ## Add the session-specific columns:\n",
    "        a_df = add_session_df_columns(a_df, session_name, curr_session_t_delta, a_time_bin_column_name)\n",
    "\n",
    "    ## Weighted Correlation\n",
    "    # decoder_laps_weighted_corr_df_dict = compute_weighted_correlations(decoder_decoded_epochs_result_dict=deepcopy(decoder_laps_filter_epochs_decoder_result_dict))\n",
    "    decoder_ripple_weighted_corr_df_dict = compute_weighted_correlations(decoder_decoded_epochs_result_dict=deepcopy(decoder_ripple_filter_epochs_decoder_result_dict))\n",
    "\n",
    "    \n",
    "    ## Build the output tuple:\n",
    "    output_extracted_result_tuples[i] = (laps_time_bin_marginals_df, laps_all_epoch_bins_marginals_df, ripple_time_bin_marginals_df, ripple_all_epoch_bins_marginals_df, decoder_ripple_weighted_corr_df_dict) # output tuples are extracted here, where changes are needed I think\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "04793d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import compute_weighted_correlations\n",
    "\n",
    "\n",
    "## Weighted Correlation\n",
    "decoder_laps_weighted_corr_df_dict = compute_weighted_correlations(decoder_decoded_epochs_result_dict=deepcopy(decoder_laps_filter_epochs_decoder_result_dict))\n",
    "decoder_ripple_weighted_corr_df_dict = compute_weighted_correlations(decoder_decoded_epochs_result_dict=deepcopy(decoder_ripple_filter_epochs_decoder_result_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec4da95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'long_LR': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: pandas.core.frame.DataFrame,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs)\n",
       " ),\n",
       " 'long_RL': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: pandas.core.frame.DataFrame,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs)\n",
       " ),\n",
       " 'short_LR': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: pandas.core.frame.DataFrame,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs)\n",
       " ),\n",
       " 'short_RL': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: pandas.core.frame.DataFrame,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs)\n",
       " )}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dict[types.DecoderName, DecodedFilterEpochsResult]\n",
    "\n",
    "decoder_ripple_filter_epochs_decoder_result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c92a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8610bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df), (decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict) = _subfn_compute_complete_df_metrics(directional_merged_decoders_result, track_templates, decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                                                                                            decoder_laps_df_dict=deepcopy(decoder_laps_weighted_corr_df_dict), decoder_ripple_df_dict=deepcopy(decoder_ripple_weighted_corr_df_dict), active_df_columns = ['wcorr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a6b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7620d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs.directionality_ratio.unique()\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs.sweep_score.unique()\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs.laplacian_smoothness.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d94fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a merged (single df) frame\n",
    "decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb235522",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_epochs_df\n",
    "filtered_epochs_df[filtered_epochs_df['start'] >= t_delta]\n",
    "filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fdcf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_decoded_epochs_result_dict: generic\n",
    "app, paginated_multi_decoder_decoded_epochs_window, pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                decoder_decoded_epochs_result_dict=filtered_decoder_filter_epochs_decoder_result_dict,\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=high_wcorr_only_filtered_decoder_filter_epochs_decoder_result_dict,\n",
    "                                                                                                epochs_name='ripple',\n",
    "                                                                                                included_epoch_indicies=None, debug_print=False,\n",
    "                                                                                                params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, \n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 10,\n",
    "                                                                                                    'scrollable_figure': False,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': False,\n",
    "                                                                                                })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "# _tmp_out_selections = paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca820df",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.remove_data_overlays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c1bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp_out_selections = paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations()\n",
    "\n",
    "paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289385ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6097ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get radon transform data:\n",
    "a_pagination_controller = pagination_controller_dict['long_LR']\n",
    "radon_transform_data = a_pagination_controller.plots_data['radon_transform_data']\n",
    "radon_transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30830fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120293e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_selections_dict = paginated_multi_decoder_decoded_epochs_window.save_selections()\n",
    "# paginated_multi_decoder_decoded_epochs_window.ui.print = print\n",
    "_annotations = paginated_multi_decoder_decoded_epochs_window.print_user_annotations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d82308",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination_controller_dict['long_LR'].params.xbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eeaad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpldatacursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f785638",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.remove_data_overlays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ee5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3435812",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.params.xbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd64912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show crosshair at cursor position\n",
    "plt.connect('motion_notify_event', lambda event: plt.gcf().gca().format_coord(event.xdata, event.ydata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c382b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1c4d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _build_attached_raster_viewer\n",
    "\n",
    "_out_ripple_rasters = _build_attached_raster_viewer(paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=filtered_ripple_simple_pf_pearson_merged_df)\n",
    "\n",
    "## Enable programmatically updating the rasters viewer to the clicked epoch index when middle clicking on a posterior.\n",
    "@function_attributes(short_name=None, tags=['callback', 'raster'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2024-04-29 17:13', related_items=[])\n",
    "def update_attached_raster_viewer_epoch_callback(self, event, clicked_ax, clicked_data_index, clicked_epoch_is_selected, clicked_epoch_start_stop_time):\n",
    "    \"\"\" Enable programmatically updating the rasters viewer to the clicked epoch index when middle clicking on a posterior. \n",
    "    called when the user middle-clicks an epoch \n",
    "    \n",
    "    captures: _out_ripple_rasters\n",
    "    \"\"\"\n",
    "    print(f'update_attached_raster_viewer_epoch_callback(clicked_data_index: {clicked_data_index}, clicked_epoch_is_selected: {clicked_epoch_is_selected}, clicked_epoch_start_stop_time: {clicked_epoch_start_stop_time})')\n",
    "    if clicked_epoch_start_stop_time is not None:\n",
    "        if len(clicked_epoch_start_stop_time) == 2:\n",
    "            start_t, end_t = clicked_epoch_start_stop_time\n",
    "            print(f'start_t: {start_t}')\n",
    "            _out_ripple_rasters.programmatically_update_epoch_IDX_from_epoch_start_time(start_t)\n",
    "\n",
    "\n",
    "for a_name, a_pagination_controller in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    # a_pagination_controller.params.debug_print = True\n",
    "    if not a_pagination_controller.params.has_attr('on_middle_click_item_callbacks'):\n",
    "        a_pagination_controller.params['on_middle_click_item_callbacks'] = {}\n",
    "    a_pagination_controller.params.on_middle_click_item_callbacks['update_attached_raster_viewer_epoch_callback'] = update_attached_raster_viewer_epoch_callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8800a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_epoch_start_stop_time = [488.296 488.484]\n",
    "start_t = 488.29642327222973\n",
    "found_IDX = 24\n",
    "\n",
    "# ripple_idx=80, ripple_start_t=488.29642327222973\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1998f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enable programmatically updating the rasters viewer to the clicked epoch index when middle clicking on a posterior.\n",
    "@function_attributes(short_name=None, tags=['callback'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2024-04-29 17:16', related_items=[])\n",
    "def an_alt_clicked_epoch_callback(self, event, clicked_ax, clicked_data_index, clicked_epoch_is_selected, clicked_epoch_start_stop_time):\n",
    "    \"\"\" called when the user middle-clicks an epoch \n",
    "    \n",
    "    captures: _out_ripple_rasters\n",
    "    \"\"\"\n",
    "    print(f'an_alt_clicked_epoch_callback(clicked_data_index: {clicked_data_index}, clicked_epoch_is_selected: {clicked_epoch_is_selected}, clicked_epoch_start_stop_time: {clicked_epoch_start_stop_time})')\n",
    "    if clicked_epoch_start_stop_time is not None:\n",
    "        if len(clicked_epoch_start_stop_time) == 2:\n",
    "            start_t, end_t = clicked_epoch_start_stop_time\n",
    "            print(f'start_t: {start_t}')\n",
    "            _out_ripple_rasters.programmatically_update_epoch_IDX_from_epoch_start_time(start_t)\n",
    "\n",
    "\n",
    "for a_name, a_pagination_controller in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    # a_pagination_controller.params.debug_print = True\n",
    "    if not a_pagination_controller.params.has_attr('on_middle_click_item_callbacks'):\n",
    "        a_pagination_controller.params['on_middle_click_item_callbacks'] = {}    \n",
    "    a_pagination_controller.params.on_middle_click_item_callbacks['an_alt_clicked_epoch_callback'] = an_alt_clicked_epoch_callback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting to set identical low and high xlims makes transformation singular; automatically expanding. Is this what is causing the white posteriors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f80c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ddc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window.pagination_controllers['long_LR'].params.posterior_heatmap_imshow_kwargs = dict(vmin=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23369f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# paginated_multi_decoder_decoded_epochs_window.update_params(posterior_heatmap_imshow_kwargs = dict(vmin=0.0))\n",
    "\n",
    "paginated_multi_decoder_decoded_epochs_window.update_params(enable_per_epoch_action_buttons = True)\n",
    "paginated_multi_decoder_decoded_epochs_window.refresh_current_page()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.get_children_props('params')\n",
    "# paginated_multi_decoder_decoded_epochs_window.get_children_props('plots')\n",
    "# paginated_multi_decoder_decoded_epochs_window.get_children_props('plots.fig')\n",
    "paginated_multi_decoder_decoded_epochs_window.get_children_props('plots.fig')\n",
    "# paginated_multi_decoder_decoded_epochs_window.get_children_props('params.posterior_heatmap_imshow_kwargs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ca528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window# AttributeError: 'PhoPaginatedMultiDecoderDecodedEpochsWindow' object has no attribute 'params'\n",
    "\n",
    "paginated_multi_decoder_decoded_epochs_window.pagination_controllers['long_LR'].params.should_suppress_callback_exceptions = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a19394",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.jump_to_page(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea69a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f136d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2150f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    # v.params.enable_radon_transform_info = False\n",
    "    # v.params.enable_weighted_correlation_info = False\n",
    "    v._subfn_clear_selectability_rects()\n",
    "    \n",
    "# paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_ctrlr in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    a_ctrlr.perform_update_selections(defer_render=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fb8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009775d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with Ctx(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [[785.7379401021171, 785.9232737672282]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [[427.4610240198672, 427.55720829055645]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [[833.3391086903866, 833.4508065531263]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [[491.7975491596153, 492.17844624456484], [940.0164351915009, 940.2191870877286]]\n",
    "\n",
    "# with Ctx(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [array([785.738, 785.923])]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [array([427.461, 427.557])]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [array([833.339, 833.451])]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [array([491.798, 492.178]), array([940.016, 940.219])]\n",
    "\n",
    "# with Ctx(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [[785.7379401021171, 785.9232737672282]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [[427.4610240198672, 427.55720829055645]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [[833.3391086903866, 833.4508065531263]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [[491.7975491596153, 492.17844624456484], [940.0164351915009, 940.2191870877286]]\n",
    "\n",
    "# with Ctx(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [[208.356, 208.523], [693.842, 693.975], [954.574, 954.679]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [[224.037, 224.312]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [[145.776, 146.022], [198.220, 198.582], [220.041, 220.259], [511.570, 511.874], [865.238, 865.373]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [[191.817, 192.100], [323.147, 323.297]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-paginated_multi_decoder_decoded_epochs_window_page.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    paginated_multi_decoder_decoded_epochs_window.jump_to_page(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f513296",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.jump_to_page(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98478063",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.get_decoder_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec6078",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    # v.params.enable_radon_transform_info = False\n",
    "    # v.params.enable_weighted_correlation_info = False\n",
    "    v.params.enable_radon_transform_info = True\n",
    "    v.params.enable_weighted_correlation_info = True\n",
    "    v.params.debug_enabled = True\n",
    "\n",
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    print(f'decoder[{k}]:')\n",
    "    v.params.name\n",
    "    # v.params.on_render_page_callbacks\n",
    "    # v.params.enable_radon_transform_info\n",
    "    len(v.plots_data.radon_transform_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1ff3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7cc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b447b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.refresh_current_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec3540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sub_subfn_wrapped_in_brackets(s: str, bracket_strings = (\"[\", \"]\")) -> str:\n",
    "        return bracket_strings[0] + s + bracket_strings[1]\n",
    "    \n",
    "def _sub_subfn_format_nested_list(arr, precision:int=3, num_sep=\", \", array_sep=', ') -> str:\n",
    "    \"\"\"\n",
    "    Converts a nested list of floats into a single string,\n",
    "    with each float formatted to the specified precision.\n",
    "    \n",
    "    arr = np.array([[491.798, 492.178], [940.016, 940.219]])\n",
    "    _sub_subfn_format_nested_list(arr)\n",
    "\n",
    "    >> '[[491.798, 492.178], [940.016, 940.219]]'\n",
    "\n",
    "    arr = np.array([[785.738, 785.923]])\n",
    "    _sub_subfn_format_nested_list(arr)\n",
    "    >> '[[785.738, 785.923]]'\n",
    "    \"\"\"\n",
    "    return _sub_subfn_wrapped_in_brackets(array_sep.join([_sub_subfn_wrapped_in_brackets(num_sep.join([f\"{num:.{precision}f}\" for num in row])) for row in arr]))\n",
    "    \n",
    "# arr = np.array([[491.798, 492.178], [940.016, 940.219]])\n",
    "arr = np.array([[785.738, 785.923]])\n",
    "_sub_subfn_format_nested_list(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f0ab5d",
   "metadata": {},
   "source": [
    "### 2024-02-29 3pm - Get the active user-annotated epoch times from the `paginated_multi_decoder_decoded_epochs_window` and use these to filter `filtered_ripple_simple_pf_pearson_merged_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c982e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inputs: paginated_multi_decoder_decoded_epochs_window, filtered_ripple_simple_pf_pearson_merged_df\n",
    "any_good_selected_epoch_times = deepcopy(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times)\n",
    "any_good_selected_epoch_indicies = deepcopy(paginated_multi_decoder_decoded_epochs_window.find_data_indicies_from_epoch_times(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa1f903",
   "metadata": {},
   "source": [
    "## 🔶 2024-03-01 - Get the active user-annotated epoch times from the `UserAnnotationsManager` and use these to filter `filtered_ripple_simple_pf_pearson_merged_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc751d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.misc import numpyify_array\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.epoch import EpochsAccessor\n",
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "## Get from UserAnnotations directly instead of the intermediate viewer\n",
    "\n",
    "## # inputs: any_good_selected_epoch_times, any_good_selected_epoch_times, any_good_selected_epoch_indicies \n",
    "\n",
    "decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline, track_templates=track_templates)\n",
    "# any_good_selected_epoch_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(any_good_selected_epoch_times)\n",
    "# any_good_selected_epoch_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.find_data_indicies_from_epoch_times(any_good_selected_epoch_times)\n",
    "# any_good_selected_epoch_indicies\n",
    "# Add user-selection columns to df\n",
    "a_df = deepcopy(filtered_ripple_simple_pf_pearson_merged_df)\n",
    "# a_df = deepcopy(ripple_weighted_corr_merged_df)\n",
    "a_df['is_user_annotated_epoch'] = False\n",
    "# any_good_selected_epoch_indicies = a_df.epochs.find_data_indicies_from_epoch_times(any_good_selected_epoch_times)\n",
    "any_good_selected_epoch_indicies = find_data_indicies_from_epoch_times(a_df, np.squeeze(any_good_selected_epoch_times[:,0]), t_column_names=['ripple_start_t',])\n",
    "# any_good_selected_epoch_indicies = find_data_indicies_from_epoch_times(a_df, any_good_selected_epoch_times, t_column_names=['ripple_start_t',])\n",
    "any_good_selected_epoch_indicies\n",
    "# a_df['is_user_annotated_epoch'] = np.isin(a_df.index.to_numpy(), any_good_selected_epoch_indicies)\n",
    "a_df['is_user_annotated_epoch'].loc[any_good_selected_epoch_indicies] = True # Here's another .iloc issue! Changing to .loc\n",
    "a_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3a540",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DecoderDecodedEpochsResult.filter_epochs_dfs_by_annotation_times(curr_active_pipeline, any_good_selected_epoch_times, ripple_decoding_time_bin_size, filtered_ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dee7b3",
   "metadata": {},
   "source": [
    "### 2024-02-29 - 4pm - Filter the events for those meeting wcorr criteria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed7e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_wcorr_threshold: float = 0.33\n",
    "min_wcorr_diff_threshold: float = 0.2\n",
    "\n",
    "is_included_large_wcorr_diff = np.any((df[['wcorr_abs_diff']].abs() > min_wcorr_diff_threshold), axis=1)\n",
    "is_included_high_wcorr = np.any((df[['long_best_wcorr', 'short_best_wcorr']].abs() > min_wcorr_threshold), axis=1)\n",
    "\n",
    "df = df[is_included_high_wcorr]\n",
    "df\n",
    "\n",
    "# delta_aligned_start_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fc554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifts the absolute times to delta-relative values, as would be needed to draw on a 'delta_aligned_start_t' axis:\n",
    "delta_relative_t_start, delta_relative_t_delta, delta_relative_t_end = np.array([earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end]) - t_delta\n",
    "delta_relative_t_start, delta_relative_t_delta, delta_relative_t_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['_wcorr_y_col'] = df['long_best_wcorr'].abs()\n",
    "df['_wcorr_y_col_y_diff_col'] = df['long_best_wcorr'].abs() - df['short_best_wcorr'].abs()\n",
    "# df.plot.scatter(x='ripple_start_t', y='wcorr_y_col')\n",
    "df.plot.scatter(x='delta_aligned_start_t', y='_wcorr_y_col_y_diff_col')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5438dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['pearsonr_long_abs'] = df['long_best_pf_peak_x_pearsonr'].abs()\n",
    "# df['pearsonr_short_abs'] = df['short_best_pf_peak_x_pearsonr'].abs()\n",
    "# df['pearsonr_diff'] = df['long_best_pf_peak_x_pearsonr'].abs() - df['short_best_pf_peak_x_pearsonr'].abs()\n",
    "\n",
    "# df.plot.scatter(x='delta_aligned_start_t', y='pearsonr_long_abs')\n",
    "# df.plot.scatter(x='delta_aligned_start_t', y='pearsonr_short_abs')\n",
    "df.plot.scatter(x='delta_aligned_start_t', y='pearsonr_abs_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f951c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271d716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.debug_print = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02556ea",
   "metadata": {},
   "source": [
    "### Add utility footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3888f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, get_utility_dock_colors\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import ThinButtonBarWidget\n",
    "\n",
    "ui = paginated_multi_decoder_decoded_epochs_window.ui._contents\n",
    "# ui.dock_widgets\n",
    "# ui.dock_configs\n",
    "\n",
    "\n",
    "## Build the utility controls at the bottom:\n",
    "ctrls_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=get_utility_dock_colors, showCloseButton=False)\n",
    "\n",
    "button_bar_height = 21\n",
    "ctrls_button_bar_widget = ThinButtonBarWidget()\n",
    "ctrls_button_bar_widget.setObjectName(\"ctrls_button_bar\")\n",
    "\n",
    "ctrl_layout = pg.LayoutWidget()\n",
    "ctrl_layout.addWidget(ctrls_button_bar_widget, row=1, rowspan=1, col=1, colspan=2)\n",
    "ctrl_widgets_dict = dict(ctrls_widget=ctrls_button_bar_widget)\n",
    "# ctrl_layout.setSizePolicy(\n",
    "\n",
    "def onCopySelectionsClicked():\n",
    "    print(f'onCopySelectionsClicked()')\n",
    "    saved_selections_contexts_dict = paginated_multi_decoder_decoded_epochs_window.print_user_annotations()\n",
    "\n",
    "ctrl_widgets_dict['copy_selection_connection'] = ctrls_button_bar_widget.sigCopySelections.connect(onCopySelectionsClicked)\n",
    "\n",
    "ui.dock_widgets['bottom_controls'] = paginated_multi_decoder_decoded_epochs_window.add_display_dock(identifier='bottom_controls', widget=ctrl_layout, dockSize=(600, button_bar_height), dockAddLocationOpts=['bottom'], display_config=ctrls_dock_config)\n",
    "ui.dock_widgets['bottom_controls'][1].hideTitleBar()\n",
    "ui.dock_widgets['bottom_controls']\n",
    "\n",
    "button_bar_height = 21\n",
    "\n",
    "a_layout = ui.dock_widgets['bottom_controls'][0]\n",
    "a_layout.size()\n",
    "a_layout.setContentsMargins(0,0,0,0)\n",
    "a_layout.setFixedHeight(21)\n",
    "ui.dock_widgets['bottom_controls'][1].size()\n",
    "ui.dock_widgets['bottom_controls'][1].setContentsMargins(0,0,0,0)\n",
    "# ui.dock_widgets['bottom_controls'][1].hideTitleBar()\n",
    "# ui.dock_widgets['bottom_controls'][1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "setMargin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.dock_widgets['bottom_controls'][0].resize(600, 21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39be52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.find_display_dock('bottom_controls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.remove_display_dock('bottom_controls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "\n",
    "## Set epoch annotations from selections epochs \n",
    "annotations_man = UserAnnotationsManager()\n",
    "user_annotations = annotations_man.get_user_annotations()\n",
    "new_selections_dict = paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations(user_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf471332",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_selections_objs_dict = {a_name:EpochSelectionsObject(epoch_times=a_selections_values) for a_name, a_selections_values in loaded_selections_dict.items()}\n",
    "loaded_selections_objs_dict\n",
    "\n",
    "## Select just the selected epoch times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_selections_context_dict = {a_name:v.figure_ctx.adding_context_if_missing(user_annotation='selections') for a_name, v in saved_selections_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d312d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.print_user_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ee6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the excessively long plot titles?\n",
    "# root_dockAreaWindow.update\n",
    "pagination_controller_dict = paginated_multi_decoder_decoded_epochs_window.pagination_controllers\n",
    "all_widgets = {a_decoder_name:a_pagination_controller.ui.mw for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_windows = {a_decoder_name:a_pagination_controller.ui.mw.window() for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_plots = {a_decoder_name:a_pagination_controller.plots for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_plots_data = {a_decoder_name:a_pagination_controller.plots_data for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_params = {a_decoder_name:a_pagination_controller.params for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_current_page_idx = {a_decoder_name:a_pagination_controller.current_page_idx for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_current_page_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cfebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_separate_plots\n",
    "\n",
    "all_separate_weighted_corr_plots = {a_decoder_name:a_pagination_controller.plots.get('weighted_corr', {}) for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_weighted_corr_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.ui.print = self.private_print # builtins.print # the print function to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69313c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import EpochsAccessor\n",
    "\n",
    "# MLM\n",
    "# {a_name:a_ctrlr.params.is_selected for a_name, a_ctrlr in root_dockAreaWindow.pagination_controllers.items()}\n",
    "# {a_name:a_ctrlr.selected_epoch_times for a_name, a_ctrlr in root_dockAreaWindow.pagination_controllers.items()}\n",
    "\n",
    "any_good_selected_epoch_times: NDArray = paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times # drops duplicate rows (present in multiple decoders), and sorts them ascending\n",
    "# any_good_selected_epoch_times\n",
    "# Only at the decoder-level\n",
    "any_good_epoch_idxs_list = [a_ctrlr.find_data_indicies_from_epoch_times(any_good_selected_epoch_times) for a_name, a_ctrlr in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items()]\n",
    "any_good_epoch_idxs: NDArray = any_good_epoch_idxs_list[0]\n",
    "any_good_epoch_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29282203",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531db971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filtered_ripple_simple_pf_pearson_merged_df.epochs.find_data_indicies_from_epoch_times(any_good_selected_epoch_times)\n",
    "# filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(any_good_selected_epoch_times)\n",
    "\n",
    "found_data_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.find_data_indicies_from_epoch_times(epoch_times=any_good_selected_epoch_times)\n",
    "df = filtered_ripple_simple_pf_pearson_merged_df.epochs._obj.iloc[found_data_indicies].copy().reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a78ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ripple_simple_pf_pearson_merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1677479",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_selected_ripple_simple_pf_pearson_merged_df = filtered_ripple_simple_pf_pearson_merged_df.iloc[any_good_epoch_idxs, :].reset_index(drop=True)\n",
    "hand_selected_ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d400bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand_selected_ripple_simple_pf_pearson_merged_df['best_decoder_index']\n",
    "\n",
    "is_most_likely_long = (hand_selected_ripple_simple_pf_pearson_merged_df['P_Long'] >= 0.5)\n",
    "# is_most_likely_long\n",
    "\n",
    "long_likely_hand_selected_ripple_simple_pf_pearson_merged_df = hand_selected_ripple_simple_pf_pearson_merged_df[is_most_likely_long]\n",
    "long_likely_hand_selected_ripple_simple_pf_pearson_merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d33190",
   "metadata": {},
   "source": [
    "## 🖼️🎨 Plot laps to compare between decoders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4873ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import add_laps_groundtruth_information_to_dataframe\n",
    "\n",
    "# decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs # looks like 'lap_dir' column is wrong\n",
    "updated_laps_dfs_dict = {}\n",
    "\n",
    "## Update the .filter_epochs:\n",
    "for k, v in decoder_laps_filter_epochs_decoder_result_dict.items():\n",
    "    updated_laps_dfs_dict[k] = Epoch(add_laps_groundtruth_information_to_dataframe(curr_active_pipeline=curr_active_pipeline, result_laps_epochs_df=ensure_dataframe(v.filter_epochs)))\n",
    "    decoder_laps_filter_epochs_decoder_result_dict[k].filter_epochs =  updated_laps_dfs_dict[k]\n",
    "\n",
    "# updated_laps_dfs_dict['long_LR']\n",
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_app, laps_paginated_multi_decoder_decoded_epochs_window, laps_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                            decoder_decoded_epochs_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epochs_name='laps', included_epoch_indicies=None, \n",
    "    params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': False, \n",
    "    # 'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': True, 'enable_weighted_correlation_info': False,\n",
    "    'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': True, 'enable_weighted_correlation_info': True,\n",
    "    # 'disable_y_label': True,\n",
    "    # 'isPaginatorControlWidgetBackedMode': True,\n",
    "    # 'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "    # 'debug_print': True,\n",
    "    'max_subplots_per_page': 10,\n",
    "    'scrollable_figure': True,\n",
    "    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "    'use_AnchoredCustomText': False,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec05d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "\n",
    "## INPUTS: decoder_laps_filter_epochs_decoder_result_dict\n",
    "\n",
    "## Highlight the correct ones:\n",
    "# {k:Epoch(add_laps_groundtruth_information_to_dataframe(curr_active_pipeline=curr_active_pipeline, result_laps_epochs_df=ensure_dataframe(v.filter_epochs))) for k, v in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "\n",
    "## Select the true laps by emulating user_annotations:\n",
    "filter_epochs = ensure_dataframe(deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)) \n",
    "# filter_epochs\n",
    "\n",
    "decoder_name_idx_map = {'long_LR': 0, 'long_RL': 1, 'short_LR': 2, 'short_RL': 3} \n",
    "selections_dict = {}\n",
    "figure_ctx_dict = laps_paginated_multi_decoder_decoded_epochs_window.figure_ctx_dict\n",
    "loaded_selections_context_dict = {a_name:a_figure_ctx.adding_context_if_missing(user_annotation='selections') for a_name, a_figure_ctx in figure_ctx_dict.items()}\n",
    "\n",
    "for a_name, an_idx in decoder_name_idx_map.items():\n",
    "    a_selections_context = loaded_selections_context_dict[a_name]\n",
    "    selections_dict[a_selections_context] = filter_epochs[filter_epochs['true_decoder_index'] == an_idx][['start', 'stop']].to_numpy()\n",
    "\n",
    "\n",
    "## Clearing the existing selection rects and them having them rebuilt when the selection is updated fixes them being shifted.\n",
    "for k, v in laps_pagination_controller_dict.items():\n",
    "    v._subfn_clear_selectability_rects()\n",
    "\n",
    "# _tmp_out_selections = laps_paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations(user_annotations=selections_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6607cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e840a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f558fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89caf8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15bba6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e364cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_paginated_multi_decoder_decoded_epochs_window.remove_data_overlays(defer_refresh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e23e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_paginated_multi_decoder_decoded_epochs_window.remov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clearing the existing selection rects and them having them rebuilt when the selection is updated fixes them being shifted.\n",
    "for k, v in laps_pagination_controller_dict.items():\n",
    "    v._subfn_clear_selectability_rects()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5675f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b603bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f847f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1556870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(decoder_laps_filter_epochs_decoder_result_dict.keys())\n",
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the figure from the axes:\n",
    "a_fig = ax.get_figure()\n",
    "a_fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_controlling_pagination_controller = laps_paginated_multi_decoder_decoded_epochs_window.contents.pagination_controllers['long_LR'] # DecodedEpochSlicesPaginatedFigureController\n",
    "a_pagination_controller_figure_widget = paginator_controller_widget = a_controlling_pagination_controller.ui.mw # MatplotlibTimeSynchronizedWidget\n",
    "paginator_controller_widget = a_controlling_pagination_controller.ui.mw.ui.paginator_controller_widget # PaginationControlWidget\n",
    "# paginator_controller_widget\n",
    "a_pagination_controller_figure_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92048bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = a_controlling_pagination_controller.plots.axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_figure().canvas.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47481538",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_rectangles_dict = a_controlling_pagination_controller.plots.get('selection_rectangles_dict', None)\n",
    "selection_rectangles_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa452e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_controlling_pagination_controller.plots.fig.canvas.draw_idle()\n",
    "# a_controlling_pagination_controller.plots.fig.canvas.draw()\n",
    "# paginator_controller_widget.update()\n",
    "a_pagination_controller_figure_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72db1753",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator_controller_widget.go_to_page(3)\n",
    "# paginator_controller_widget.jump_to_page(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635fbe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_controlling_pagination_controller.ui.mw.ui.paginator_controller_widget.jump_to_page\n",
    "\n",
    "new_obj.plots_data.paginator\n",
    "new_obj.params.active_identifying_figure_ctx\n",
    "new_obj.on_paginator_control_widget_jump_to_page(page_idx=0)\n",
    "new_obj.ui.connections['paginator_controller_widget_jump_to_page']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c54dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, extant_plots in a_plots['weighted_corr'].items():\n",
    "    extant_wcorr_text = extant_plots.get('wcorr_text', None)\n",
    "    # extant_wcorr_text = extant_plots.pop('wcorr_text', None)\n",
    "    print(f'extant_wcorr_text: {extant_wcorr_text}')\n",
    "    # plot the radon transform line on the epoch:\n",
    "    if (extant_wcorr_text is not None):\n",
    "        # already exists, clear the existing ones. \n",
    "        # Let's assume we want to remove the 'Quadratic' line (line2)\n",
    "        print(f'removing extant text object at index: {i}.')\n",
    "        # extant_wcorr_text.remove()\n",
    "        extant_wcorr_text.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b7e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_pagination_controller in pagination_controller_dict.items():\n",
    "    display_context = a_pagination_controller.params.get('active_identifying_figure_ctx', IdentifyingContext())\n",
    "\n",
    "    # Get context for current page of items:\n",
    "    current_page_idx: int = int(a_pagination_controller.current_page_idx)\n",
    "    a_paginator = a_pagination_controller.paginator\n",
    "    total_num_pages = int(a_paginator.num_pages)\n",
    "    page_context = display_context.overwriting_context(page=current_page_idx, num_pages=total_num_pages)\n",
    "    print(page_context)\n",
    "\n",
    "    ## Get the figure/axes:\n",
    "    a_plots = a_pagination_controller.plots # RenderPlots\n",
    "    a_plot_data = a_pagination_controller.plots_data\n",
    "\n",
    "    a_params = a_pagination_controller.params\n",
    "    a_params.skip_plotting_measured_positions\n",
    "\n",
    "    figs = a_plots.fig\n",
    "    axs = a_plots.axs\n",
    "\n",
    "    # # with mpl.rc_context({'figure.figsize': (8.4, 4.8), 'figure.dpi': '220', 'savefig.transparent': True, 'ps.fonttype': 42, }):\n",
    "    # with mpl.rc_context({'figure.figsize': (16.8, 4.8), 'figure.dpi': '420', 'savefig.transparent': True, 'ps.fonttype': 42, }):\n",
    "    #     curr_active_pipeline.output_figure(final_context=page_context, fig=figs, write_vector_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d32342",
   "metadata": {},
   "source": [
    "## 💾 Export Paginated Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec0488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laps_paginated_multi_decoder_decoded_epochs_window.export_all_pages(curr_active_pipeline)\n",
    "paginated_multi_decoder_decoded_epochs_window.export_all_pages(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be8a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.export_decoder_pagination_controller_figure_page(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd2637",
   "metadata": {},
   "source": [
    "## 🔷🎨 Single Decoder Version (`DecodedEpochSlicesPaginatedFigureController`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d880d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import _subfn_update_decoded_epoch_slices\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController # `plot_decoded_epoch_slices_paginated`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import WeightedCorrelationPaginatedPlotDataProvider\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import DecodedPositionsPlotDataProvider, DecodedAndActualPositionsPlotData\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import perform_plot_1D_single_most_likely_position_curve\n",
    "\n",
    "# Inputs: epochs_name, decoder_ripple_filter_epochs_decoder_result_dict, curr_active_pipeline\n",
    "epochs_name = 'ripple'\n",
    "\n",
    "(a_name, a_decoder) = tuple(track_templates.get_decoders_dict().items())[0]\n",
    "\n",
    "# a_decoder_decoded_epochs_result = decoder_ripple_filter_epochs_decoder_result_dict[a_name]\n",
    "\n",
    "# a_decoder_decoded_epochs_result = decoder_ripple_filter_epochs_decoder_result_dict[a_name]\n",
    "a_decoder_decoded_epochs_result = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict[a_name]) ## FILTERED\n",
    "\n",
    "_out_pagination_controller = DecodedEpochSlicesPaginatedFigureController.init_from_decoder_data(active_filter_epochs=a_decoder_decoded_epochs_result.filter_epochs,\n",
    "                                                                                    filter_epochs_decoder_result= a_decoder_decoded_epochs_result,\n",
    "                                                                                    xbin=a_decoder.xbin, global_pos_df=curr_active_pipeline.sess.position.df,\n",
    "                                                                                    a_name=f'DecodedEpochSlices[{a_name}]', active_context=curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs=epochs_name, decoder=a_name),\n",
    "                                                                                    max_subplots_per_page=32,\n",
    "                                                                                    params_kwargs={'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, 'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': True, #'enable_radon_transform_info': True, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    'enable_radon_transform_info': True, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 32,\n",
    "                                                                                                    'scrollable_figure': True,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': True,\n",
    "                                                                                                    'disable_toolbar': False,\n",
    "                                                                                    }, \n",
    "                                                                                    # disable_toolbar=False\n",
    "                                                                                    )\n",
    "\n",
    "_out_pagination_controller.params.should_suppress_callback_exceptions = False\n",
    "_out_pagination_controller.add_data_overlays(a_decoder_decoded_epochs_result)\n",
    "_tmp_out_selections = _out_pagination_controller.restore_selections_from_user_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c780e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = _out_pagination_controller.plots.fig\n",
    "# fig.toolbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f46ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(_out_pagination_controller)\n",
    "\n",
    "_out_pagination_controller.plot_widget._buildUI_setup_statusbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff74414",
   "metadata": {},
   "source": [
    "single_epoch_field_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e429a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on_selected_epochs_changed\n",
    "\n",
    "active_captured_single_epoch_result: SingleEpochDecodedResult = a_decoder_decoded_epochs_result.get_result_for_epoch(active_epoch_idx=3)\n",
    "\n",
    "def get_selected_posterior_on_secondary_clicked_callback(self, event, clicked_ax, clicked_data_index, clicked_epoch_is_selected, clicked_epoch_start_stop_time):\n",
    "    \"\"\" called when the user alt-clicks an epoch \n",
    "    \n",
    "    captures: active_captured_single_epoch_result\n",
    "    \"\"\"\n",
    "    global active_captured_single_epoch_result\n",
    "    if self.params.debug_print:\n",
    "        print(f'get_selected_posterior_on_secondary_clicked_callback(clicked_data_index: {clicked_data_index}, clicked_epoch_is_selected: {clicked_epoch_is_selected}, clicked_epoch_start_stop_time: {clicked_epoch_start_stop_time})')\n",
    "    if clicked_epoch_start_stop_time is not None:\n",
    "        if len(clicked_epoch_start_stop_time) == 2:\n",
    "            start_t, end_t = clicked_epoch_start_stop_time\n",
    "            # print(f'start_t: {start_t}')\n",
    "            clicked_data_index: int = _out_pagination_controller.find_data_indicies_from_epoch_times(epoch_times=np.array([start_t, end_t]))[0]\n",
    "            if self.params.debug_print:\n",
    "                print(f'\\tclicked_data_index: {clicked_data_index}')            \n",
    "            active_captured_single_epoch_result = a_decoder_decoded_epochs_result.get_result_for_epoch(active_epoch_idx=clicked_data_index)\n",
    "            if self.params.debug_print:\n",
    "                print(f'\\tactive_captured_single_epoch_result.epoch_info_tuple: {active_captured_single_epoch_result.epoch_info_tuple}')\n",
    "                print(f'\\tdone.')\n",
    "\n",
    "\n",
    "# BEGIN FUNCTION BODY ________________________________________________________________________________________________ #\n",
    "if not _out_pagination_controller.params.has_attr('on_middle_click_item_callbacks'):\n",
    "    _out_pagination_controller.params['on_middle_click_item_callbacks'] = {}\n",
    "\n",
    "_out_pagination_controller.params.on_middle_click_item_callbacks['get_selected_posterior_on_secondary_clicked_callback'] = get_selected_posterior_on_secondary_clicked_callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoder_decoded_epochs_result.active_filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a619872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.media_output_helpers import get_array_as_image\n",
    "\n",
    "posterior_image = active_captured_single_epoch_result.get_posterior_as_image(desired_width=2048)\n",
    "posterior_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "\n",
    "# Define 8x8 blur filter kernel\n",
    "blur_kernel = np.ones((8, 8)) / 64\n",
    "\n",
    "# Apply blur to a 2D matrix\n",
    "blurred_matrix = convolve2d(active_captured_single_epoch_result.p_x_given_n, blur_kernel, mode='same', boundary='wrap')\n",
    "\n",
    "get_array_as_image(blurred_matrix, desired_height=400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "{i:col for i, col in enumerate(a_decoder_decoded_epochs_result.active_filter_epochs.columns)}\n",
    "\n",
    "column_indicies = np.arange(12, 19)\n",
    "column_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b8451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_pagination_controller.params.debug_print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc81f8",
   "metadata": {},
   "source": [
    "## 2024-04-30 Heuristic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21abb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *position_relative\": mapped between the ends of the track, 0.0 to 1.0\n",
    "most_likely_position_relative = (np.squeeze(active_captured_single_epoch_result.most_likely_position_indicies) / float(active_captured_single_epoch_result.n_xbins-1))\n",
    "most_likely_position_relative\n",
    "\n",
    "\n",
    "plt.hlines([0], colors='k', xmin=active_captured_single_epoch_result.time_bin_edges[0], xmax=active_captured_single_epoch_result.time_bin_edges[-1])\n",
    "plt.step(active_captured_single_epoch_result.time_bin_container.centers[1:], np.diff(most_likely_position_relative))\n",
    "plt.scatter(active_captured_single_epoch_result.time_bin_container.centers, most_likely_position_relative, color='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c52d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.Qt import QtGui, QtCore, QtWidgets\n",
    "# from pyphoplacecellanalysis.External.pyqtgraph.parametertree.parameterTypes.file import popupFilePicker\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.widgets.FileDialog import FileDialog\n",
    "\n",
    "from silx.gui import qt\n",
    "from silx.gui.dialog.ImageFileDialog import ImageFileDialog\n",
    "from silx.gui.dialog.DataFileDialog import DataFileDialog\n",
    "import silx.io\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import saveFile\n",
    "\n",
    "app = pg.mkQApp('silx_testing')\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc644214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from silx.gui.plot import Plot2D\n",
    "\n",
    "matrix = np.random.rand(10, 10)  # Example 2D matrix\n",
    "plot = Plot2D()\n",
    "plot.addImage(matrix, colormap=\"viridis\", vmin=0, vmax=1)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "\n",
    "HeuristicReplayScoring.bin_wise_track_coverage_score_fn(a_result=a_decoder_decoded_epochs_result, an_epoch_idx=active_captured_single_epoch_result.epoch_data_index, a_decoder_track_length=170.0)\n",
    "\n",
    "# np.diff(active_captured_single_epoch_result.most_likely_position_indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5407a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaeb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CodeConversion.convert_dictionary_to_class_defn(\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = _out_pagination_controller.plots.axs[0]\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d52d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.format_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f28b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ascending sequences of most-likely positions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def format_coord(x, y):\n",
    "    col = round(x)\n",
    "    row = round(y)\n",
    "    nrows, ncols = X.shape\n",
    "    if 0 <= col < ncols and 0 <= row < nrows:\n",
    "        z = X[row, col]\n",
    "        return f'x={x:1.4f}, y={y:1.4f}, z={z:1.4f}'\n",
    "    else:\n",
    "        return f'x={x:1.4f}, y={y:1.4f}'\n",
    "\n",
    "\n",
    "ax.format_coord = format_coord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de603c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_pagination_controller.plot_widget.setStatusTip('LONG STATUS TIP TEST')\n",
    "\n",
    "_out_pagination_controller.plot_widget.update_status('LONG STATUS TIP TEST')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b187c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_pagination_controller.plots.radon_transform\n",
    "fig = _out_pagination_controller.plots.fig\n",
    "\n",
    "# plt.subplots_adjust(left=0.15, right=0.85, top=0.9, bottom=0.1)\n",
    "# Adjust the margins using subplots_adjust\n",
    "fig.subplots_adjust(left=0.15, right=0.85, bottom=0.15, top=0.85)\n",
    "\n",
    "# Adjust the margins using the Figure object\n",
    "# fig.set_tight_layout(dict(rect=[0.1, 0.2, 0.8, 0.8]))\n",
    "# fig.tight_layout(dict(rect=[0.1, 0.2, 0.8, 0.8]))\n",
    "# fig.tight_layout(pad=1.0, rect=[0.1, 0.1, 0.8, 0.8])\n",
    "_out_pagination_controller.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9643ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a_name, a_decoder) = tuple(track_templates.get_decoders_dict().items())[0]\n",
    "a_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d1a25",
   "metadata": {},
   "source": [
    "## 🔷🎨 2024-03-06 - Uni Page Scrollable Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be9e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_decoded_epochs_result_dict: generic\n",
    "single_page_app, single_page_paginated_multi_decoder_decoded_epochs_window, single_page_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                                                                                                decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                included_epoch_indicies=None, debug_print=False,\n",
    "                                                                                                params_kwargs={'skip_plotting_most_likely_positions': False, 'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                               'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                                # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                                # 'disable_y_label': True,\n",
    "                                                                                                                'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                                'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                                # 'debug_print': True,\n",
    "                                                                                                                'max_subplots_per_page': 64,\n",
    "                                                                                                                'scrollable_figure': True,\n",
    "                                                                                                                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2565e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_page_paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "_tmp_out_selections = single_page_paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90abee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for curr_results_obj: LeaveOneOutDecodingAnalysisResult object\n",
    "num_filter_epochs:int = curr_results_obj.active_filter_epochs.n_epochs\n",
    "\n",
    "# `active_filter_epochs_df` native columns approach\n",
    "active_filter_epochs_df = curr_results_obj.active_filter_epochs.to_dataframe().copy()\n",
    "assert np.isin(['score', 'velocity', 'intercept', 'speed'], active_filter_epochs_df.columns).all()\n",
    "epochs_linear_fit_df = active_filter_epochs_df[['score', 'velocity', 'intercept', 'speed']].copy() # get the `epochs_linear_fit_df` as a subset of the filter epochs df\n",
    "# epochs_linear_fit_df approach\n",
    "assert curr_results_obj.all_included_filter_epochs_decoder_result.num_filter_epochs == np.shape(epochs_linear_fit_df)[0]\n",
    "\n",
    "num_filter_epochs:int = curr_results_obj.all_included_filter_epochs_decoder_result.num_filter_epochs # curr_results_obj.num_filter_epochs\n",
    "try:\n",
    "    time_bin_containers: List[BinningContainer] = deepcopy(curr_results_obj.time_bin_containers)\n",
    "except AttributeError as e:\n",
    "    # AttributeError: 'LeaveOneOutDecodingAnalysisResult' object has no attribute 'time_bin_containers' is expected when `curr_results_obj: LeaveOneOutDecodingAnalysisResult - for Long/Short plotting`\n",
    "    time_bin_containers: List[BinningContainer] = deepcopy(curr_results_obj.all_included_filter_epochs_decoder_result.time_bin_containers) # for curr_results_obj: LeaveOneOutDecodingAnalysisResult - for Long/Short plotting\n",
    "\n",
    "radon_transform_data = RadonTransformPlotDataProvider._subfn_build_radon_transform_plotting_data(active_filter_epochs_df=active_filter_epochs_df,\n",
    "            num_filter_epochs = num_filter_epochs, time_bin_containers = time_bin_containers, radon_transform_column_names=['score', 'velocity', 'intercept', 'speed'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d17b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fa458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _display_long_and_short_stacked_epoch_slices\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out_dict = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', save_figure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f3190",
   "metadata": {},
   "source": [
    "## Other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = _out_pagination_controller.plots['radon_transform'][7]\n",
    "extant_line = _out['line'] # matplotlib.lines.Line2D\n",
    "extant_line.linestyle = 'none'\n",
    "# extant_line.draw()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e00165",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(curr_active_pipeline.filtered_contexts.keys())) # ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Converting between decoder names and filtered epoch names:\n",
    "# {'long':'maze1', 'short':'maze2'}\n",
    "# {'LR':'odd', 'RL':'even'}\n",
    "long_LR_name, short_LR_name, long_RL_name, short_RL_name = ['maze1_odd', 'maze2_odd', 'maze1_even', 'maze2_even']\n",
    "decoder_name_to_session_context_name: Dict[str,str] = dict(zip(track_templates.get_decoder_names(), (long_LR_name, long_RL_name, short_LR_name, short_RL_name))) # {'long_LR': 'maze1_odd', 'long_RL': 'maze1_even', 'short_LR': 'maze2_odd', 'short_RL': 'maze2_even'}\n",
    "session_context_to_decoder_name: Dict[str,str] = dict(zip((long_LR_name, long_RL_name, short_LR_name, short_RL_name), track_templates.get_decoder_names())) # {'maze1_odd': 'long_LR', 'maze1_even': 'long_RL', 'maze2_odd': 'short_LR', 'maze2_even': 'short_RL'}\n",
    "\n",
    "decoder_name_to_session_context_name\n",
    "session_context_to_decoder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5896f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_num_slices: int = _out_pagination_controller.params.active_num_slices\n",
    "single_plot_fixed_height: float = _out_pagination_controller.params.single_plot_fixed_height\n",
    "all_plots_height: float = _out_pagination_controller.params.all_plots_height\n",
    "print(f'all_plots_height: {all_plots_height}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad67f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fed6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PendingNotebookCode import _add_maze_id_to_epochs\n",
    "\n",
    "\n",
    "## Add new weighted correlation results as new columns in existing filter_epochs df:\n",
    "active_filter_epochs = long_results_obj.active_filter_epochs\n",
    "# Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "active_filter_epochs = _add_maze_id_to_epochs(active_filter_epochs, short_session.t_start)\n",
    "active_filter_epochs._df['weighted_corr_LONG'] = epoch_long_weighted_corr_results[:,0]\n",
    "active_filter_epochs._df['weighted_corr_SHORT'] = epoch_short_weighted_corr_results[:,0]\n",
    "active_filter_epochs._df['weighted_corr_spearman_LONG'] = epoch_long_weighted_corr_results[:,1]\n",
    "active_filter_epochs._df['weighted_corr_spearman_SHORT'] = epoch_short_weighted_corr_results[:,1]\n",
    "\n",
    "\n",
    "active_filter_epochs\n",
    "active_filter_epochs.to_dataframe()\n",
    "## plot the `weighted_corr_LONG` over time\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=active_num_rows, sharex=True, sharey=sharey, figsize=figsize)\n",
    "\n",
    "## Weighted Correlation during replay epochs:\n",
    "_out_ax = active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_LONG', title='weighted_corr during replay events', marker=\"s\",  s=5, label=f'Long', alpha=0.8)\n",
    "active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_SHORT', xlabel='Replay Epoch Time', ylabel='Weighted Correlation', ax=_out_ax, marker=\"s\", c='r', s=5, label=f'Short', alpha=0.8)\n",
    "_out_ax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line\n",
    "## Weighted Spearman Correlation during replay epochs:\n",
    "_out_ax = active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_spearman_LONG', title='weighted_spearman_corr during replay events', marker=\"s\",  s=5, label=f'Long', alpha=0.8)\n",
    "active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_spearman_SHORT', xlabel='Replay Epoch Time', ylabel='Weighted Spearman Correlation', ax=_out_ax, marker=\"s\", c='r', s=5, label=f'Short', alpha=0.8)\n",
    "_out_ax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line\n",
    "_out_ax = active_filter_epochs._df.plot.scatter(x='start', y='score_LONG', title='Radon Transform Score during replay events', marker=\"s\",  s=5, label=f'Long', alpha=0.8)\n",
    "active_filter_epochs._df.plot.scatter(x='start', y='score_SHORT', xlabel='Replay Epoch Time', ylabel='Replay Radon Transform Score', ax=_out_ax, marker=\"s\", c='r', s=5, label=f'Short', alpha=0.8)\n",
    "_out_ax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe3e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad4f9a0",
   "metadata": {},
   "source": [
    "# 2024-02-15 - Do simple spike-t vs. template pf peak correlation like Kamran suggested this morning\n",
    "\n",
    "Replays can be of trajectories on either the current track configuration or on a temporally distant one (such as a trajectory on the long track after the track has been shortened). \n",
    "The goal of the decoder scoring methods are to evaluate how likely each decoder was. This means for each Epoch we obtain a score for all four decoders: Long_LR, Long_RL, Short_LR, Short_RL\n",
    "\n",
    "#### `posterior decoder likelihoods` - This scoring method produces a probability that the\n",
    "\n",
    "#### Radon Transform - TODO\n",
    "\n",
    "#### `compute_simple_spike_time_v_pf_peak_x_by_epoch` - This epoch scoring metric plots the placefield peak x position against the time in seconds of each spike relative to the start of the epoch. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d1e967",
   "metadata": {},
   "source": [
    "## TODO 2024-02-15 8pm - Add in to previous result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd539a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "\n",
    "# (laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df)\n",
    "# (laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df)\n",
    "laps_simple_pf_pearson_merged_df\n",
    "# laps_radon_transform_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57565cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_lap_epochs_dict = dict(zip((long_LR_name, long_RL_name, short_LR_name, short_RL_name), (long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj)))\n",
    "directional_active_lap_pf_results_dicts = TrialByTrialActivity.directional_compute_trial_by_trial_correlation_matrix(active_pf_dt=active_pf_dt, directional_lap_epochs_dict=directional_lap_epochs_dict, included_neuron_IDs=any_decoder_neuron_IDs)\n",
    "\n",
    "decoder_aclu_peak_location_df_merged = deepcopy(track_templates.get_decoders_aclu_peak_location_df(width=None))\n",
    "# decoder_aclu_peak_location_df_merged[np.isin(decoder_aclu_peak_location_df_merged['aclu'], both_included_neuron_stats_df.aclu.to_numpy())]\n",
    "decoder_aclu_peak_location_df_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74381521",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result: TrialByTrialActivity = directional_active_lap_pf_results_dicts['long_LR']\n",
    "# a_result.sp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8421fd1a",
   "metadata": {},
   "source": [
    "# 💾 2024-03-04 - Export `DecoderDecodedEpochsResult` CSVs with user annotations for epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae0ae73",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "_, _, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "filtered_valid_epoch_times = filtered_epochs_df[['start', 'stop']].to_numpy()\n",
    "\n",
    "## 2024-03-08 - Also constrain the user-selected ones (just to try it):\n",
    "decoder_user_selected_epoch_times_dict, any_user_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline, track_templates=track_templates)\n",
    "\n",
    "a_result_dict = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "# {a_name:ensure_dataframe(a_result.filter_epochs) for a_name, a_result in a_result_dict.items()}\n",
    "\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=True)\n",
    "\n",
    "# 🟪 2024-02-29 - `compute_pho_heuristic_replay_scores`\n",
    "directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict, _out_new_scores = HeuristicReplayScoring.compute_all_heuristic_scores(track_templates=track_templates, a_decoded_filter_epochs_decoder_result_dict=directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "\n",
    "## Merge the heuristic columns into the wcorr df columns for exports\n",
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "\n",
    "# {a_name:DecoderDecodedEpochsResult.try_add_is_user_annotated_epoch_column(ensure_dataframe(a_result.filter_epochs), any_good_selected_epoch_times=filtered_valid_epoch_times) for a_name, a_result in a_result_dict.items()}\n",
    "\n",
    "for a_name, a_result in a_result_dict.items():\n",
    "    # a_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=True)\n",
    "\n",
    "    ## Merge the heuristic columns into the wcorr df columns for exports\n",
    "    # directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    a_wcorr_result = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict[a_name]\n",
    "    \n",
    "    # did_update_user_annotation_col = DecoderDecodedEpochsResult.try_add_is_user_annotated_epoch_column(ensure_dataframe(a_result.filter_epochs), any_good_selected_epoch_times=any_user_selected_epoch_times, t_column_names=None)\n",
    "    # print(f'did_update_user_annotation_col: {did_update_user_annotation_col}')\n",
    "    # did_update_is_valid = DecoderDecodedEpochsResult.try_add_is_valid_epoch_column(ensure_dataframe(a_result.filter_epochs), any_good_selected_epoch_times=filtered_valid_epoch_times, t_column_names=None)\n",
    "    # print(f'did_update_is_valid: {did_update_is_valid}')\n",
    "\n",
    "# ['start',]\n",
    "\n",
    "a_result_dict = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "\n",
    "# {a_name:ensure_dataframe(a_result.filter_epochs) for a_name, a_result in a_result_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fb7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_new_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ba9f746",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected_outputs_path: \"K:\\scratch\\collected_outputs\"\n",
      "CURR_BATCH_OUTPUT_PREFIX: 2024-05-21_APOGEE-2006-6-09_22-24-40\n",
      "\tComputation complete. Exporting .CSVs...\n",
      "len(active_epochs_df): 707\n",
      "min_num_unique_aclu_inclusions: 12\n",
      "len(active_epochs_df): 405\n",
      "num_user_selected_times: 41\n",
      "adding user annotation column!\n",
      "\t succeded at getting 41 selected indicies (of 41 user selections) for ripple_weighted_corr_merged_df. got 41 indicies!\n",
      "num_valid_epoch_times: 405\n",
      "adding valid filtered epochs column!\n",
      "\t succeded at getting 405 selected indicies (of 405 valid filter epoch times) for ripple_weighted_corr_merged_df. got 405 indicies!\n",
      "num_user_selected_times: 41\n",
      "adding user annotation column!\n",
      "\t succeded at getting 41 selected indicies (of 41 user selections) for ripple_simple_pf_pearson_merged_df. got 41 indicies!\n",
      "num_valid_epoch_times: 405\n",
      "adding valid filtered epochs column!\n",
      "\t succeded at getting 405 selected indicies (of 405 valid filter epoch times) for ripple_simple_pf_pearson_merged_df. got 405 indicies!\n",
      "\t\tsuccessfully exported directional_decoders_epochs_decode_result to K:\\scratch\\collected_outputs!\n",
      "\t\t\tCSV Paths: laps_weighted_corr_merged_df: \"file:///K:/scratch/collected_outputs/2024-05-24_0700AM-kdiba_gor01_two_2006-6-09_22-24-40-%28laps_weighted_corr_merged_df%29_tbin-0.25.csv\"\n",
      "ripple_weighted_corr_merged_df: \"file:///K:/scratch/collected_outputs/2024-05-24_0700AM-kdiba_gor01_two_2006-6-09_22-24-40-%28ripple_weighted_corr_merged_df%29_tbin-0.025.csv\"\n",
      "laps_simple_pf_pearson_merged_df: \"file:///K:/scratch/collected_outputs/2024-05-24_0700AM-kdiba_gor01_two_2006-6-09_22-24-40-%28laps_simple_pf_pearson_merged_df%29_tbin-0.25.csv\"\n",
      "ripple_simple_pf_pearson_merged_df: \"file:///K:/scratch/collected_outputs/2024-05-24_0700AM-kdiba_gor01_two_2006-6-09_22-24-40-%28ripple_simple_pf_pearson_merged_df%29_tbin-0.025.csv\"\n",
      "ripple_all_scores_merged_df: \"file:///K:/scratch/collected_outputs/2024-05-24_0700AM-kdiba_gor01_two_2006-6-09_22-24-40-%28ripple_all_scores_merged_df%29_tbin-0.025.csv\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pathlib import Path\n",
    "\n",
    "# 💾 export_csvs\n",
    "\n",
    "BATCH_DATE_TO_USE: str = '2024-05-21_APOGEE' # TODO: Change this as needed, templating isn't actually doing anything rn.\n",
    "\n",
    "known_collected_outputs_paths = [Path(v).resolve() for v in ('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs', '/Users/pho/Dropbox (University of Michigan)/MED-DibaLabDropbox/Data/Pho/Outputs/output/collected_outputs', '/home/halechr/cloud/turbo/Data/Output/collected_outputs', '/home/halechr/FastData/gen_scripts/', '/home/halechr/FastData/collected_outputs/', 'output/gen_scripts/')]\n",
    "collected_outputs_path = find_first_extant_path(known_collected_outputs_paths)\n",
    "assert collected_outputs_path.exists(), f\"collected_outputs_path: '{collected_outputs_path}' does not exist! Is the right computer's config commented out above?\"\n",
    "print(f'collected_outputs_path: \"{collected_outputs_path}\"')\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline, track_templates=track_templates)\n",
    "print(f'\\tComputation complete. Exporting .CSVs...')\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "_, _, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "filtered_valid_epoch_times = filtered_epochs_df[['start', 'stop']].to_numpy()\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_output_csv_paths = directional_decoders_epochs_decode_result.export_csvs(parent_output_path=collected_outputs_path.resolve(), active_context=active_context, session_name=curr_session_name, curr_session_t_delta=t_delta,\n",
    "                                                                              user_annotation_selections={'ripple': any_good_selected_epoch_times},\n",
    "                                                                              valid_epochs_selections={'ripple': filtered_valid_epoch_times})\n",
    "\n",
    "print(f'\\t\\tsuccessfully exported directional_decoders_epochs_decode_result to {collected_outputs_path}!')\n",
    "_output_csv_paths_info_str: str = '\\n'.join([f'{a_name}: \"{file_uri_from_path(a_path)}\"' for a_name, a_path in _output_csv_paths.items()])\n",
    "# print(f'\\t\\t\\tCSV Paths: {_output_csv_paths}\\n')\n",
    "print(f'\\t\\t\\tCSV Paths: {_output_csv_paths_info_str}\\n')\n",
    "\n",
    "# {'laps_weighted_corr_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(laps_weighted_corr_merged_df)_tbin-0.025.csv'),\n",
    "#  'ripple_weighted_corr_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(ripple_weighted_corr_merged_df)_tbin-0.025.csv'),\n",
    "#  'laps_simple_pf_pearson_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(laps_simple_pf_pearson_merged_df)_tbin-0.025.csv'),\n",
    "#  'ripple_simple_pf_pearson_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(ripple_simple_pf_pearson_merged_df)_tbin-0.025.csv')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88335249",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_good_selected_epoch_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7420982",
   "metadata": {},
   "source": [
    "# 2024-03-04 - Filter out the epochs based on the criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuropy.utils.mixins.time_slicing import add_epochs_id_identity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, required_min_percentage_of_active_cells=0.333333, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "filtered_epochs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68233f",
   "metadata": {},
   "source": [
    "# 2024-03-27 - Look at active set cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.HDF5_representable import HDFConvertableEnum\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import TruncationCheckingResults\n",
    "\n",
    "\n",
    "## long_short_endcap_analysis:\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "truncation_checking_aclus_dict, jonathan_firing_rate_analysis_result.neuron_replay_stats_df = truncation_checking_result.build_truncation_checking_aclus_dict(neuron_replay_stats_df=jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "\n",
    "frs_index_inclusion_magnitude:float = 0.5\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "\n",
    "## Unrefined:\n",
    "# neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=frs_index_inclusion_magnitude)\n",
    "\n",
    "## Refine the LxC/SxC designators using the firing rate index metric:\n",
    "\n",
    "## Get global `long_short_fr_indicies_analysis`:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_short_fr_indicies_df = long_short_fr_indicies_analysis_results['long_short_fr_indicies_df']\n",
    "jonathan_firing_rate_analysis_result.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=frs_index_inclusion_magnitude)\n",
    "\n",
    "neuron_replay_stats_df, *exclusivity_tuple = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=frs_index_inclusion_magnitude)\n",
    "# short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = exclusivity_tuple\n",
    "exclusivity_aclus_tuple = [v.track_exclusive_aclus for v in exclusivity_tuple]\n",
    "exclusivity_aclus_dict = dict(zip(['short_exclusive', 'long_exclusive', 'BOTH', 'EITHER', 'XOR', 'NEITHER'], exclusivity_aclus_tuple))\n",
    "any_aclus = union_of_arrays(*exclusivity_aclus_tuple)\n",
    "exclusivity_aclus_dict['any'] = any_aclus\n",
    "refined_exclusivity_aclus_tuple = [v.get_refined_track_exclusive_aclus() for v in exclusivity_tuple]\n",
    "neuron_replay_stats_df: pd.DataFrame = HDFConvertableEnum.convert_dataframe_columns_for_hdf(neuron_replay_stats_df)\n",
    "\n",
    "# These keys exhaustively span all aclus:\n",
    "exhaustive_key_names = ['short_exclusive', 'long_exclusive', 'BOTH', 'NEITHER']\n",
    "assert np.all(any_aclus == union_of_arrays(*[exclusivity_aclus_dict[k] for k in exhaustive_key_names]))\n",
    "exhaustive_key_dict = {k:v for k, v in exclusivity_aclus_dict.items() if k in exhaustive_key_names}\n",
    "\n",
    "\n",
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_any_aclus = np.array([  3,   4,   5,   7,  10,  11,  13,  14,  15,  17,  23,  24,  25,  26,  31,  32,  33,  34,  45,  49,  50,  51,  52,  54,  55,  58,  61,  64,  68,  69,  70,  71,  73,  74,  75,  76,  78,  81,  82,  83,  84,  85,  87,  90,  92,  93,  96,  97, 102, 109])\n",
    "old_appearing_aclus = np.array([ 4, 11, 13, 23, 52, 58, 87])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af361ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_aclus = union_of_arrays(*[v for v in truncation_checking_aclus_dict.values() if len(v) > 0])\n",
    "any_aclus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2385b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520650ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.analyses.placefields import PfND\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import perform_sweep_lap_groud_truth_performance_testing, _perform_variable_time_bin_lap_groud_truth_performance_testing\n",
    "\n",
    "desired_laps_decoding_time_bin_size: float = 0.75\n",
    "\n",
    "## INPUTS: exclusivity_aclus_tuple, desired_laps_decoding_time_bin_size: float\n",
    "# short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = exclusivity_aclus_tuple\n",
    "# included_neuron_ids_list = [short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset]\n",
    "\n",
    "# included_neuron_ids_list = [*exclusivity_aclus_tuple]\n",
    "\n",
    "## INPUTS: truncation_checking_aclus_dict\n",
    "included_neuron_ids_list = list(truncation_checking_aclus_dict.values())\n",
    "row_names = list(truncation_checking_aclus_dict.keys())\n",
    "\n",
    "_output_tuples_list = perform_sweep_lap_groud_truth_performance_testing(curr_active_pipeline, \n",
    "                                                                        included_neuron_ids_list=included_neuron_ids_list,\n",
    "                                                                        desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_size)\n",
    "\n",
    "percent_laps_correctness_df: pd.DataFrame = pd.DataFrame.from_records([complete_decoded_context_correctness_tuple.percent_correct_tuple for (a_directional_merged_decoders_result, result_laps_epochs_df, complete_decoded_context_correctness_tuple) in _output_tuples_list],\n",
    "                          columns=(\"track_ID_correct\", \"dir_correct\", \"complete_correct\"), index=row_names)\n",
    "percent_laps_correctness_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb00384",
   "metadata": {},
   "source": [
    "# 2024-03-29 - Rigorous Decoder Performance assessment\n",
    "Quantify cell contributions to decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f9715a6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data_portion: 0.8333333333333334, test_data_portion: 0.16666666666666663\n"
     ]
    }
   ],
   "source": [
    "# Inputs: all_directional_pf1D_Decoder, alt_directional_merged_decoders_result\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrainTestLapsSplitting, CustomDecodeEpochsResult, decoder_name, epoch_split_key, get_proper_global_spikes_df\n",
    "\n",
    "## INPUTS: directional_laps_results, track_templates, directional_laps_results\n",
    "\n",
    "## Split the lap epochs into training and test periods.\n",
    "##### Ideally we could test the lap decoding error by sampling randomly from the time bins and omitting 1/6 of time bins from the placefield building (effectively the training data). These missing bins will be used as the \"test data\" and the decoding error will be computed by decoding them and subtracting the actual measured position during these bins.\n",
    "\n",
    "# ### Get the laps to train on\n",
    "# training_data_portion: float = 9.0/10.0\n",
    "# test_data_portion: float = 1.0 - training_data_portion # test data portion is 1/6 of the total duration\n",
    "# print(f'training_data_portion: {training_data_portion}, test_data_portion: {test_data_portion}')\n",
    "\n",
    "# decoders_dict = deepcopy(track_templates.get_decoders_dict())\n",
    "\n",
    "# # debug_output_hdf5_file_path = Path('output', 'laps_train_test_split.h5').resolve()\n",
    "# debug_output_hdf5_file_path = None\n",
    "\n",
    "# # (train_epochs_dict, test_epochs_dict), train_lap_specific_pf1D_Decoder_dict, split_train_test_lap_specific_configs = TrainTestLapsSplitting.compute_train_test_split_laps_decoders(directional_laps_results, track_templates, training_data_portion=training_data_portion,\n",
    "# #                                                                                                                                                              debug_output_hdf5_file_path=debug_output_hdf5_file_path, debug_plot=False, debug_print=True)  # type: Tuple[Tuple[Dict[str, Any], Dict[str, Any]], Dict[str, BasePositionDecoder], Any]\n",
    "\n",
    "# train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = train_lap_specific_pf1D_Decoder_dict\n",
    "\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrainTestSplitResult\n",
    "\n",
    "directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data.get('TrainTestSplit', None)\n",
    "\n",
    "training_data_portion: float = directional_train_test_split_result.training_data_portion\n",
    "test_data_portion: float = directional_train_test_split_result.test_data_portion\n",
    "print(f'training_data_portion: {training_data_portion}, test_data_portion: {test_data_portion}')\n",
    "\n",
    "test_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.test_epochs_dict\n",
    "train_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.train_epochs_dict\n",
    "train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_train_test_split_result.train_lap_specific_pf1D_Decoder_dict\n",
    "\n",
    "\n",
    "# Tuple[Tuple[Dict, Dict], Dict[str, BasePositionDecoder], Dict]\n",
    "\n",
    "# OUTPUTS: train_test_split_laps_df_dict\n",
    "\n",
    "# ## Get test epochs:\n",
    "# train_epoch_names: List[str] = [k for k in train_test_split_laps_df_dict.keys() if k.endswith('_train')]\n",
    "# test_epoch_names: List[str] = [k for k in train_test_split_laps_df_dict.keys() if k.endswith('_test')]\n",
    "# train_lap_specific_pf1D_Decoder_dict: Dict[str,BasePositionDecoder] = {k.split('_train', maxsplit=1)[0]:split_train_test_lap_specific_pf1D_Decoder_dict[k] for k in train_epoch_names} # the `k.split('_train', maxsplit=1)[0]` part just gets the original key like 'long_LR'\n",
    "# test_epochs_dict: Dict[str,Epoch] = {k.split('_test', maxsplit=1)[0]:v for k,v in train_test_split_laps_epoch_obj_dict.items() if k.endswith('_test')} # the `k.split('_test', maxsplit=1)[0]` part just gets the original key like 'long_LR'\n",
    "\n",
    "# a_training_test_split_laps_epoch_obj_dict[a_training_test_names[0]].to_hdf('output/laps_train_test_split.h5', f'{a_train_epoch_name}/laps_training_df')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d0456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _do_custom_decode_epochs_dict\n",
    "\n",
    "active_laps_decoding_time_bin_size: float = 0.75\n",
    "\n",
    "global_spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe()).dropna(subset=['lap']) # computation_result.sess.position.to_dataframe()\n",
    "\n",
    "# Dict[epoch_split_key, Dict[decoder_name, CustomDecodeEpochsResult]]\n",
    "\n",
    "## INPUTS: flat_epochs_to_decode_dict, active_laps_decoding_time_bin_size\n",
    "## Decoding of the test epochs (what matters):\n",
    "test_decoder_results_dict: Dict[decoder_name, CustomDecodeEpochsResult] = _do_custom_decode_epochs_dict(global_spikes_df=global_spikes_df, global_measured_position_df=global_measured_position_df,\n",
    "                                                                                                                                 pf1D_Decoder_dict=train_lap_specific_pf1D_Decoder_dict,\n",
    "                                                                                                                                 epochs_to_decode_dict=test_epochs_dict, \n",
    "                                                                                                                                 decoding_time_bin_size=active_laps_decoding_time_bin_size,\n",
    "                                                                                                                                 decoder_and_epoch_keys_independent=False)\n",
    "\n",
    "\n",
    "# flat_epochs_to_decode_dict = {f'{k}_train':v for k,v in train_epochs_dict.items()} | {f'{k}_test':v for k,v in test_epochs_dict.items()} # (train_epochs_dict, test_epochs_dict)\n",
    "# final_decoder_results_dict: Dict[epoch_split_key, Dict[decoder_name, CustomDecodeEpochsResult]] = _do_custom_decode_epochs_dict(curr_active_pipeline,\n",
    "#                                                                                                                                  pf1D_Decoder_dict=train_lap_specific_pf1D_Decoder_dict,\n",
    "#                                                                                                                                  epochs_to_decode_dict=flat_epochs_to_decode_dict,\n",
    "#                                                                                                                                  decoding_time_bin_size=active_laps_decoding_time_bin_size,\n",
    "#                                                                                                                                  decoder_and_epoch_keys_independent=True) # epochs_to_decode_dict.keys(): ['long_LR_train', 'long_RL_train', 'short_LR_train', 'short_RL_train', 'long_LR_test', 'long_RL_test', 'short_LR_test', 'short_RL_test']\n",
    "# matched_decoder_epochs_final_decoder_results_dict: Dict[decoder_name, CustomDecodeEpochsResult] = {k:v[k.replace('_train', '').replace('_test', '')] for k, v in final_decoder_results_dict.items()} # flatten down to only the matching decoder\n",
    "# matched_decoder_epochs_final_decoder_results_dict\n",
    "# print(list(matched_decoder_epochs_final_decoder_results_dict.keys())) # ['long_LR_train', 'long_RL_train', 'short_LR_train', 'short_RL_train', 'long_LR_test', 'long_RL_test', 'short_LR_test', 'short_RL_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e034df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import compute_weighted_correlations\n",
    "\n",
    "train_decoded_results_dict: Dict[str, DecodedFilterEpochsResult] = {k:v.decoder_result for k, v in test_decoder_results_dict.items()}\n",
    "\n",
    "weighted_corr_data_dict = compute_weighted_correlations(train_decoded_results_dict, debug_print=True)\n",
    "weighted_corr_data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a3a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_decoded_wcorr_df = pd.concat(weighted_corr_data_dict)\n",
    "train_decoded_wcorr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result.p_x_given_n_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f1a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_decoded_measured_diff_df: pd.DataFrame = test_decoder_results_dict['long_LR'].measured_decoded_position_comparion.decoded_measured_diff_df\n",
    "\n",
    "\n",
    "train_decoded_measured_diff_df_dict: Dict[str, pd.DataFrame] = {k:v.measured_decoded_position_comparion.decoded_measured_diff_df for k, v in test_decoder_results_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce176e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import pho_jointplot\n",
    "import seaborn as sns\n",
    "\n",
    "plot_key: str = 'err_cm'\n",
    "\n",
    "# Plot each list as a separate time series\n",
    "plt.figure(figsize=(10, 6))\n",
    "for key, value in train_decoded_measured_diff_df_dict.items():\n",
    "    # sns.lineplot(x=range(len(value)), y=value, label=key)\n",
    "    _out_line = sns.lineplot(data=value, x='t', y=plot_key, label=key)\n",
    "    _out_scatter = sns.scatterplot(data=value, x='t', y=plot_key) # no `, label=key` because we only want one entry in the legend\n",
    "\n",
    "plt.xlabel('lap_center_t (sec)')\n",
    "plt.ylabel('mean_error [cm]')\n",
    "plt.title('LAp Decoding Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10117f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epochs_dict = {k:Epoch(ensure_dataframe(v.measured_decoded_position_comparion.decoded_measured_diff_df)) for k, v in test_decoder_results_dict.items()}\n",
    "active_epochs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epochs_dict = {k:Epoch(ensure_dataframe(v)) for k, v in train_decoded_measured_diff_df_dict.items()}\n",
    "active_epochs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8f168",
   "metadata": {},
   "source": [
    "# 2024-04-03 - Time-bin effect on lap decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea00ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import make_class\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function\n",
    "\n",
    "return_full_decoding_results: bool = True\n",
    "desired_laps_decoding_time_bin_size = np.linspace(start=0.030, stop=1.0, num=4)\n",
    "\n",
    "\n",
    "SimpleBatchComputationDummy = make_class('SimpleBatchComputationDummy', attrs=['BATCH_DATE_TO_USE', 'collected_outputs_path'])\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path)\n",
    "\n",
    "custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_size,\n",
    "                                                                        use_single_time_bin_per_epoch=[False],\n",
    "                                                                        minimum_event_duration=[desired_laps_decoding_time_bin_size[-1]])\n",
    "\n",
    "\n",
    "_across_session_results_extended_dict = {}\n",
    "## Combine the output of `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tacross_session_results_extended_dict=_across_session_results_extended_dict, return_full_decoding_results=return_full_decoding_results,\n",
    "                                                save_hdf=True, save_csvs=True,\n",
    "                                                # desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=4),\n",
    "                                                custom_all_param_sweep_options=custom_all_param_sweep_options, # directly provide the parameter sweeps\n",
    "                                                )\n",
    "if return_full_decoding_results:\n",
    "    # with `return_full_decoding_results == True`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_full_directional_merged_decoders_result = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    # validate the result:\n",
    "    # {k:v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size for k,v in output_full_directional_merged_decoders_result.items()}\n",
    "    # assert np.all([np.isclose(dict(k)['desired_shared_decoding_time_bin_size'], v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size) for k,v in output_full_directional_merged_decoders_result.items()]), f\"the desired time_bin_size in the parameters should match the one used that will appear in the decoded result\"\n",
    "\n",
    "\n",
    "else:\n",
    "    # with `return_full_decoding_results == False`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    output_full_directional_merged_decoders_result = None\n",
    "\n",
    "(several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d97fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _show_sweep_result\n",
    "\n",
    "## INPUTS: output_full_directional_merged_decoders_result\n",
    "\n",
    "\n",
    "## RUN\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe()).dropna(subset=['lap']) # computation_result.sess.position.to_dataframe()\n",
    "# sweep_key_name: str=\"desired_shared_decoding_time_bin_size\"\n",
    "sweep_key_name: str=\"desired_laps_decoding_time_bin_size\"\n",
    "_out_pagination_controller, (all_swept_measured_positions_dfs_dict, all_swept_decoded_positions_df_dict, all_swept_decoded_measured_diff_df_dict) = _show_sweep_result(output_full_directional_merged_decoders_result, global_measured_position_df=global_measured_position_df,\n",
    "                                                                                                                                                        xbin=long_results_obj.original_1D_decoder.xbin,\n",
    "                                                                                                                                                        active_context=curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='laps', decoder='all_dir'),\n",
    "                                                                                                                                                        sweep_params_idx=2, sweep_key_name=sweep_key_name, max_subplots_per_page=4)\n",
    "# _out_pagination_controller\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed630cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_laps_decoding_time_bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e8f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Context Mask - provides additional information about an Identifying context, like whether a certain component of it should print:\n",
    "# has tags like 'print_debug', 'print_session', 'print_across_sessions'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import CustomDecodeEpochsResult\n",
    "\n",
    "\n",
    "## INPUTS: output_full_directional_merged_decoders_result\n",
    "\n",
    "# Interpolated measured position DataFrame - looks good\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe()).dropna(subset=['lap']) # computation_result.sess.position.to_dataframe()\n",
    "all_swept_measured_positions_dfs_dict, all_swept_decoded_positions_df_dict, all_swept_decoded_measured_diff_df_dict = CustomDecodeEpochsResult.build_measured_decoded_position_comparison({k:deepcopy(v.all_directional_laps_filter_epochs_decoder_result) for k, v in output_full_directional_merged_decoders_result.items()}, global_measured_position_df=global_measured_position_df)\n",
    "# all_swept_decoded_measured_diff_df_dict = {k:pd.DataFrame(v, columns=['t', 'err']) for k, v in all_swept_decoded_measured_diff_df_dict.items()}\n",
    "\n",
    "# global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe()).dropna(subset=['lap']) # computation_result.sess.position.to_dataframe()\n",
    "# test_measured_positions_dfs_dict, test_decoded_positions_df_dict, test_decoded_measured_diff_df_dict = CustomDecodeEpochsResult.build_measured_decoded_position_comparison(test_laps_decoder_results_dict, global_measured_position_df=global_measured_position_df)\n",
    "# train_measured_positions_dfs_dict, train_decoded_positions_df_dict, train_decoded_measured_diff_df_dict = CustomDecodeEpochsResult.build_measured_decoded_position_comparison(train_laps_decoder_results_dict, global_measured_position_df=global_measured_position_df)\n",
    "\n",
    "\n",
    "## OUTPUTS: all_swept_measured_positions_dfs_dict, all_swept_decoded_positions_df_dict, all_swept_decoded_measured_diff_df_dict\n",
    "all_swept_decoded_measured_diff_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# # Plot the time series using Seaborn\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.lineplot(data=df_melted, x=df_melted.index, y='value', hue='type')\n",
    "# plt.xlabel('Index')\n",
    "# plt.ylabel('Value')\n",
    "# plt.title('Time Series Plot')\n",
    "# plt.show()\n",
    "\n",
    "sweep_key_name: str=\"desired_laps_decoding_time_bin_size\"\n",
    "\n",
    "## INPUTS: all_swept_decoded_measured_diff_df_dict, sweep_key_name,\n",
    "\n",
    "\n",
    "# Plot each list as a separate time series\n",
    "plt.figure(figsize=(10, 6))\n",
    "for key, error_df in all_swept_decoded_measured_diff_df_dict.items():\n",
    "    # convert frozenset back to dict\n",
    "    a_sweep_params_dict = {s[0]:s[1] for i, s in enumerate(key)}\n",
    "    # error_df['err_cm'] = np.sqrt(error_df['err'])\n",
    "\n",
    "    # plot_key: str = 'err'\n",
    "    plot_key: str = 'err_cm'\n",
    "    \n",
    "    key_label = f'{round(a_sweep_params_dict[sweep_key_name], ndigits=3)}s'\n",
    "    # sns.lineplot(x=range(len(value)), y=value, label=key)\n",
    "    _out_line = sns.lineplot(data=error_df, x='t', y=plot_key, label=key_label)\n",
    "    _out_scatter = sns.scatterplot(data=error_df, x='t', y=plot_key) #  label=key_label, legend=None\n",
    "\n",
    "\n",
    "plt.xlabel('lap_center_t (sec)')\n",
    "plt.ylabel('mean_squared_error')\n",
    "plt.title('All Swept Time Bin Sizes Lap Decoding Error')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d321945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2024-04-03 - Interactively show the lap decoding performance for a single time bin size:\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "\n",
    "_out_pagination_controller = DecodedEpochSlicesPaginatedFigureController.init_from_decoder_data(an_all_directional_laps_filter_epochs_decoder_result.active_filter_epochs,\n",
    "                                                                                            an_all_directional_laps_filter_epochs_decoder_result,\n",
    "                                                                                            xbin=long_results_obj.original_1D_decoder.xbin, global_pos_df=global_session.position.df,\n",
    "                                                                                            active_context=curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices',\n",
    "                                                                                                                                                                #   t_bin=f'{an_all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size}s',\n",
    "                                                                                                                                                                  t_bin=f\"{a_sweep_params_dict['desired_shared_decoding_time_bin_size']}s\",\n",
    "                                                                                                                                                                   epochs='laps', decoder='all_dir'),\n",
    "                                                                                            a_name='an_all_directional_laps_filter_epochs_decoder_result', max_subplots_per_page=20)\n",
    "_out_pagination_controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbcd125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import compute_weighted_correlations\n",
    "\n",
    "\n",
    "# out_wcorr_df_dict = compute_weighted_correlations({k:[a_p_x_given_n for a_p_x_given_n in deepcopy(v.all_directional_laps_filter_epochs_decoder_result.p_x_given_n_list)] for k, v in output_full_directional_merged_decoders_result.items()})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f59e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result: DirectionalPseudo2DDecodersResult = list(output_full_directional_merged_decoders_result.values())[-2]\n",
    "all_directional_laps_filter_epochs_decoder_result: DecodedFilterEpochsResult = a_result.all_directional_laps_filter_epochs_decoder_result\n",
    "\n",
    "# out_wcorr_df_dict = compute_weighted_correlations({k:deepcopy(v.all_directional_laps_filter_epochs_decoder_result) for k, v in output_full_directional_merged_decoders_result.items()})\n",
    "# out_wcorr_df_dict = compute_weighted_correlations({'out': all_directional_laps_filter_epochs_decoder_result})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4997b1e4",
   "metadata": {},
   "source": [
    "# Completely Different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b61ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import add_laps_groundtruth_information_to_dataframe\n",
    "\n",
    "laps_weighted_corr_merged_df = add_laps_groundtruth_information_to_dataframe(curr_active_pipeline=curr_active_pipeline, result_laps_epochs_df=laps_weighted_corr_merged_df)\n",
    "laps_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5436c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_weighted_corr_merged_df[laps_weighted_corr_merged_df['best_decoder_index'] != laps_weighted_corr_merged_df['true_decoder_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4744404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_weighted_corr_merged_df[laps_weighted_corr_merged_df['best_decoder_index'] == laps_weighted_corr_merged_df['true_decoder_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e57782",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_weighted_corr_merged_df.to_clipboard(excel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325be3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult], decoder_laps_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict,\n",
    "# laps_weighted_corr_merged_df: pd.DataFrame, decoder_laps_weighted_corr_df_dict: Dict[str, pd.DataFrame],\n",
    "# laps_simple_pf_pearson_merged_df: pd.DataFrame\n",
    "# laps_simple_pf_pearson_merged_df\n",
    "laps_weighted_corr_merged_df\n",
    "\n",
    "# ['best_decoder_index'] # gives the index of the decoder with the best value of wcorr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c477ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the ground truth for the decoded laps:\n",
    "groudtruth_laps_epochs_df: pd.DataFrame = directional_merged_decoders_result.add_groundtruth_information(curr_active_pipeline=curr_active_pipeline)\n",
    "groudtruth_laps_epochs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f465051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_column_names = ['maze_id', 'is_LR_dir', 'is_most_likely_track_identity_Long', 'is_most_likely_direction_LR']\n",
    "groudtruth_laps_epochs_df[groundtruth_column_names]\n",
    "\n",
    "lap_idxs = groudtruth_laps_epochs_df['lap_id'] - 1\n",
    "lap_idxs\n",
    "## add the truth columns to `laps_weighted_corr_merged_df`:\n",
    "laps_weighted_corr_merged_df[groundtruth_column_names] = groudtruth_laps_epochs_df[groundtruth_column_names]\n",
    "laps_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6402fe8",
   "metadata": {},
   "source": [
    "## 📈 2024-03-07 - measured v. best-decoded Position + Derivatives Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.position_derivatives import _compute_pos_derivs\n",
    "\n",
    "measured_position_df = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "# # lap positions only:\n",
    "# measured_position_df = measured_position_df[~measured_position_df['lap'].isnull()] # only get the positions during the laps\n",
    "# measured_position_df['lap'] = measured_position_df['lap'].astype('int64')\n",
    "measured_position_df\n",
    "\n",
    "new_measured_pos_df: pd.DataFrame = _compute_pos_derivs(measured_position_df['t'].to_numpy(), position = deepcopy(measured_position_df['lin_pos'].to_numpy()), decoding_time_bin_size=laps_decoding_time_bin_size) \n",
    "# new_measured_pos_df\n",
    "\n",
    "extra_column_names = ['lap', 'lap_dir'] # 'y', \n",
    "assert np.shape(new_measured_pos_df)[0] == np.shape(measured_position_df)[0]\n",
    "new_measured_pos_df[extra_column_names] = measured_position_df[extra_column_names].copy()\n",
    "\n",
    "# lap positions only:\n",
    "new_measured_pos_df = new_measured_pos_df[~new_measured_pos_df['lap'].isnull()] # only get the positions during the laps\n",
    "new_measured_pos_df['lap'] = new_measured_pos_df['lap'].astype('int64')\n",
    "new_measured_pos_df\n",
    "\n",
    "\n",
    "# new_measured_pos_df['lap_dir'] = new_measured_pos_df['lap_dir'].astype('int64')\n",
    "\n",
    "# new_measured_pos_df\n",
    "\n",
    "# new_measured_pos_df.describe()\n",
    "\n",
    "\n",
    "# a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "\n",
    "# any_good_selected_epoch_times = deepcopy(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times)\n",
    "# any_good_selected_epoch_indicies = deepcopy(paginated_multi_decoder_decoded_epochs_window.find_data_indicies_from_epoch_times(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times))\n",
    "# any_good_selected_epoch_indicies\n",
    "\n",
    "# with suppress_print_context():\n",
    "# with disable_function_context(builtins, \"print\"):\n",
    "_out_new_scores = {}\n",
    "# an_epoch_idx: int = 0 # 7\n",
    "\n",
    "all_epochs_position_derivatives_df_dict: Dict[str, pd.DataFrame] = {}\n",
    "for a_name, a_result in a_decoded_filter_epochs_decoder_result_dict.items():\n",
    "    # print(f'\\na_name: {a_name}')\n",
    "    # 🟪 2024-02-29 - `compute_pho_heuristic_replay_scores`\n",
    "    # directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict, _out_new_scores = HeuristicReplayScoring.compute_all_heuristic_scores(track_templates=track_templates, a_decoded_filter_epochs_decoder_result_dict=directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "    _out_new_scores[a_name] = [HeuristicReplayScoring.compute_pho_heuristic_replay_scores(a_result=a_result, an_epoch_idx=an_epoch_idx, enable_debug_plot=False, debug_plot_axs=axs, debug_plot_name=a_name) for an_epoch_idx in np.arange(a_result.num_filter_epochs)]\n",
    "    all_epochs_position_derivatives_df_dict[a_name] = pd.concat([a_scores.position_derivatives_df for a_scores in _out_new_scores[a_name]], ignore_index=True)\n",
    "\n",
    "_out_new_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41abbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.position_derivatives import debug_plot_helper_add_position_and_derivatives\n",
    "\n",
    "\n",
    "fig, debug_plot_axs = debug_plot_helper_add_position_and_derivatives(new_measured_pos_df['t'].to_numpy(), new_measured_pos_df['x'].to_numpy(), new_measured_pos_df['vel_x'].to_numpy(), new_measured_pos_df['accel_x'].to_numpy(),\n",
    "                                                                        debug_plot_axs=None, debug_plot_name='measured', common_plot_kwargs=dict(color='k', markersize='5', marker='.', linestyle='None', alpha=0.35))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1bdd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.position_derivatives import debug_plot_position_and_derivatives_figure\n",
    "\n",
    "## INPUTS: new_measured_pos_df, all_epochs_position_derivatives_df_dict\n",
    "fig, debug_plot_axs = debug_plot_position_and_derivatives_figure(new_measured_pos_df, all_epochs_position_derivatives_df_dict, debug_plot_axs=None, debug_figure_title=None, enable_debug_plot = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f5c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.position_derivatives import debug_plot_position_derivatives_stack\n",
    "\n",
    "# fig = debug_plot_position_derivatives_stack(new_measured_pos_df, all_epochs_position_derivatives_df_dict)\n",
    "fig = debug_plot_position_derivatives_stack(new_measured_pos_df, all_epochs_position_derivatives_df_dict, show_scatter=True)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7fbba6",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d7aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: df1, df2\n",
    "position_deriv_column_names1 = pos_deriv_column_names\n",
    "df1 = measured_position_df[position_deriv_column_names1]\n",
    "\n",
    "position_deriv_column_names2 = ['x', 'vel_x', 'accel_x']\n",
    "df2 = deepcopy(all_epochs_position_derivatives_df[position_deriv_column_names2])\n",
    "\n",
    "# Set up the figure and axes.\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(8, 6))\n",
    "\n",
    "# List of columns to compare\n",
    "columns_to_compare = ['col1', 'col2', 'col3']\n",
    "\n",
    "\n",
    "# Loop through the list of columns and create a histogram for each.\n",
    "for i, (col1, col2) in enumerate(zip(position_deriv_column_names1, position_deriv_column_names2)):\n",
    "# for i, col in enumerate(columns_to_compare):\n",
    "    # Use the same bin edges for both histograms by computing them from the combined range of both DataFrames\n",
    "    combined_range = pd.concat([df1[col1], df2[col2]])\n",
    "    bins = np.histogram_bin_edges(combined_range, bins='auto')\n",
    "\n",
    "    # Plot the first DataFrame histogram\n",
    "    df1[col1].hist(bins=bins, ax=axes[i], alpha=0.5, label='Decoded')\n",
    "\n",
    "    # Plot the second DataFrame histogram\n",
    "    df2[col2].hist(bins=bins, ax=axes[i], alpha=0.5, label='Measured')\n",
    "\n",
    "    # Set the title and labels\n",
    "    axes[i].set_title(f'Histogram of {col1}')\n",
    "    axes[i].set_xlabel(col1)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "    # Add a legend\n",
    "    axes[i].legend()\n",
    "\n",
    "# Adjust layout for readability\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5670d2",
   "metadata": {},
   "source": [
    "# 💾🖼️ 2024-04-27 - Save Posteriors as Yellow-Blue plots to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c7718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import save_posterior\n",
    "\n",
    "\n",
    "directional_decoders_decode_result\n",
    "\n",
    "collapsed_per_lap_epoch_marginal_track_identity_point = laps_marginals_df[['P_Long', 'P_Short']].to_numpy().astype(float)\n",
    "collapsed_per_lap_epoch_marginal_dir_point = laps_marginals_df[['P_LR', 'P_RL']].to_numpy().astype(float)\n",
    "\n",
    "for epoch_id in np.arange(laps_filter_epochs_decoder_result.num_filter_epochs):\n",
    "\traw_tuple, marginal_dir_tuple, marginal_track_identity_tuple, marginal_dir_point_tuple, marginal_track_identity_point_tuple = save_posterior(raw_posterior_laps_marginals, laps_directional_marginals, laps_track_identity_marginals, collapsed_per_lap_epoch_marginal_dir_point, collapsed_per_lap_epoch_marginal_track_identity_point,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tparent_array_as_image_output_folder=parent_array_as_image_output_folder, epoch_id_identifier_str='lap', epoch_id=epoch_id)\n",
    "\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike3d-yellow",
   "language": "python",
   "name": "spike3d-yellow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
