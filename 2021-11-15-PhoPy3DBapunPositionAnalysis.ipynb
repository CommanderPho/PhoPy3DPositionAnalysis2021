{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6088dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: pho\n",
    "\"\"\"\n",
    "import sys\n",
    "from threading import Thread\n",
    "import time # for time.sleep\n",
    "from ipygany import PolyMesh, Scene, IsoColor, WarpByScalar\n",
    "import pyvista as pv\n",
    "import pyvistaqt as pvqt\n",
    "import colorcet as cc # Colormaps:\n",
    "import numpy as np\n",
    "import h5py\n",
    "import hdf5storage # conda install hdf5storage\n",
    "from pathlib import Path\n",
    "import bqplot.scales\n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "# import mplcursors\n",
    "import math # For color map generation\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.cm import hsv\n",
    "\n",
    "import ipywidgets as widgets\n",
    "# from PyQt5 import QtWidgets, uic\n",
    "from pyvistaqt import QtInteractor, MainWindow\n",
    "# from pyqt6 import QApplication\n",
    "from IPython.external.qt_for_kernel import QtGui\n",
    "from PyQt5.QtWidgets import QApplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313eba69-5c27-4e2d-8563-2220af614aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PhoPositionalData as pdp\n",
    "# from PhoPositionalData import load_exported, process_data\n",
    "from PhoPositionalData.load_exported import *\n",
    "# from PhoPositionalData.process_data import process_positionalAnalysis_data, gen_2d_histrogram, get_heatmap_color_vectors, process_chunk_equal_poritions_data, extract_spike_timeseries\n",
    "from PhoPositionalData.process_data import *\n",
    "from PhoPositionalData.plot_data import *\n",
    "from PhoPositionalData.plotting.animations import * # make_mp4_from_plotter, apply_close_overhead_zoomed_camera_view\n",
    "from PhoPositionalData.import_data import * # build_spike_positions_list, build_cellID_reverse_lookup_map\n",
    "from PhoPositionalData.analysis.interactive_placeCell_config import InteractivePlaceCellConfig, VideoOutputModeConfig, PlottingConfig  # VideoOutputModeConfig, InteractivePlaceCellConfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f94e40-c8dc-467a-9b67-7d2dcbbb277c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuropy module not found, adding directory to sys.path. \n",
      " >> Updated sys.path.\n",
      "Issue with pickled POSIX_PATH on windows for path R:\\data\\Bapun\\Day5TwoNovel\\RatS-Day5TwoNovel-2020-12-04_07-55-09.probegroup.npy, falling back to non-pickled version...\n",
      "linearized position loaded from file.\n",
      "Loading success: .ripple.npy.\n",
      "Loading success: .mua.npy.\n",
      "Loading success: .pbe.npy.\n"
     ]
    }
   ],
   "source": [
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "try:\n",
    "    from neuropy import core\n",
    "except ImportError:\n",
    "    sys.path.append(r'C:\\Users\\Pho\\repos\\NeuroPy') # Windows\n",
    "    # sys.path.append('/home/pho/repo/BapunAnalysis2021/NeuroPy') # Linux\n",
    "    # sys.path.append(r'/Users/pho/repo/Python Projects/NeuroPy') # MacOS\n",
    "    print('neuropy module not found, adding directory to sys.path. \\n >> Updated sys.path.')\n",
    "    from neuropy import core\n",
    "from neuropy.core.dataSession import DataSession, processDataSession\n",
    "\n",
    "# basedir = '/media/share/data/Bapun/Day5TwoNovel' # Linux\n",
    "basedir = 'R:\\data\\Bapun\\Day5TwoNovel' # Windows\n",
    "# basedir = '/Volumes/iNeo/Data/Bapun/Day5TwoNovel' # MacOS\n",
    "sess = core.processDataSession(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da09dc2-5426-49f3-a62f-45329369db48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraining to epoch with times (start: 11070, end: 13970)\n",
      "Recomputing active_epoch_placefields...\n",
      "done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  1,   3,  10,  11,  13,  14,  28,  34,  37,  38,  39,  41,  42,\n",
       "        43,  44,  47,  48,  53,  54,  55,  56,  57,  58,  61,  63,  64,\n",
       "        65,  68,  70,  75,  77,  80,  87,  91,  93,  95, 107], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NOTE: The only place that I need to be careful with indexing is with sess.position properties, as these appear to be represented in terms of the number of 60Hz samples instead of in seconds like the Neurons and other classes.\n",
    "active_epoch_name = 'maze1'\n",
    "# active_epoch_name = 'maze2'\n",
    "# active_subplots_shape = (1,1) # Single subplot\n",
    "active_subplots_shape = '1|2' # 1 subplot on left, two on right\n",
    "active_config = InteractivePlaceCellConfig(active_epoch_name,\n",
    "                    VideoOutputModeConfig(active_frame_range=np.arange(15200.0, 18000.0), video_output_parent_dir=Path('output', active_epoch_name), active_is_video_output_mode=False),\n",
    "                    PlottingConfig(output_subplots_shape=active_subplots_shape)) # '3|1\n",
    "active_epoch_times = sess.epochs[active_config.active_epochs] \n",
    "# active_epoch_times = sess.epochs['maze2'] \n",
    "# active_epoch_times = sess.epochs['maze1']  # array([11070, 13970], dtype=int64)\n",
    "print('Constraining to epoch with times (start: {}, end: {})'.format(active_epoch_times[0], active_epoch_times[1]))\n",
    "\n",
    "active_epoch_session_Neurons = sess.neurons.get_neuron_type('pyr').time_slice(active_epoch_times[0], active_epoch_times[1]) # Filter by pyramidal cells only, returns a core.Neurons object with its spiketrains filtered for the provided start/end times\n",
    "active_epoch_position_times_index_mask = sess.position.time_slice_indicies(active_epoch_times[0], active_epoch_times[1]) # a Boolean selection mask\n",
    "active_epoch_position_times = sess.position.time[active_epoch_position_times_index_mask] # The actual times\n",
    "active_epoch_relative_position_times = active_epoch_position_times - active_epoch_position_times[0] # Subtract off the first index, so that it becomes zero\n",
    "active_epoch_pos = sess.position.time_slice(active_epoch_times[0], active_epoch_times[1]) # active_epoch_pos's .time and start/end are all valid\n",
    "# have active_epoch_position_times: the actual times each position sample occured in seconds, active_epoch_relative_position_times: the same as active_epoch_position_times but starting at zero. Finally, have a complete active_epoch_pos object\n",
    "\n",
    "## Compute Placefields if needed:\n",
    "from neuropy.analyses import Pf1D, PF2d, Pf2D_new\n",
    "from neuropy.plotting.spikes import get_neuron_colors\n",
    "\n",
    "should_force_recompute_placefields = True\n",
    "\n",
    "try: active_epoch_placefields\n",
    "except NameError: active_epoch_placefields = None # Checks variable active_epoch_placefields's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "if ((active_epoch_placefields is None) or should_force_recompute_placefields):\n",
    "    print('Recomputing active_epoch_placefields...')\n",
    "    active_epoch_placefields1D = Pf1D(neurons=active_epoch_session_Neurons, position=active_epoch_pos.linear_pos_obj, speed_thresh=4, grid_bin=7)\n",
    "    # active_epoch_placefields = active_epoch_placefields1D\n",
    "    print('done.')\n",
    "else:\n",
    "    print('active_epoch_placefields already exists, reusing it')\n",
    "    \n",
    "    \n",
    "active_epoch_placefields2D_obj = Pf2D_new(neurons=active_epoch_session_Neurons, position=active_epoch_pos, speed_thresh=4, grid_bin=7)    \n",
    "# active_epoch_placefields2D_old = PF2d(active_epoch_times, active_epoch_session_Neurons.spiketrains, active_epoch_session_Neurons.neuron_ids, active_epoch_pos.x, active_epoch_pos.y, active_epoch_pos.time, trackingRate=active_epoch_pos.sampling_rate, \n",
    "                                  # gridbin=7, speed_thresh=4, frate_thresh=1, smooth=2)\n",
    "# active_epoch_placefields2D_old.plotMap()\n",
    "\n",
    "active_epoch_placefields = active_epoch_placefields2D_obj\n",
    "\n",
    "# Get the cell IDs that have a good place field mapping:\n",
    "good_placefield_neuronIDs = np.array(active_epoch_placefields.ratemap.neuron_ids) # in order of ascending ID\n",
    "good_placefield_neuronIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bc6aaf7-cec0-4ebf-bd4a-7f6167542dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cells: 37\n",
      "cell_ids: [  1   3  10  11  13  14  28  34  37  38  39  41  42  43  44  47  48  53\n",
      "  54  55  56  57  58  61  63  64  65  68  70  75  77  80  87  91  93  95\n",
      " 107]\n"
     ]
    }
   ],
   "source": [
    "# pf_ax, pf_sort_ind, pf_colors = active_epoch_placefields.plot_ratemaps()\n",
    "# from neuropy.utils import mathutil\n",
    "# curr_tuning_curves = mathutil.min_max_scaler(active_epoch_placefields.ratemap.tuning_curves) # 37x25x27 ndarray\n",
    "# curr_tuning_curves = active_epoch_placefields.ratemap.tuning_curves\n",
    "curr_tuning_curves = active_epoch_placefields.ratemap.normalized_tuning_curves\n",
    "# sort_ind = np.argsort(np.argmax(curr_tuning_curves, axis=1))\n",
    "# ind = np.unravel_index(np.argsort(curr_tuning_curves, axis=None), curr_tuning_curves.shape)\n",
    "num_curr_tuning_curves = len(curr_tuning_curves)\n",
    "pf_sort_ind = np.arange(num_curr_tuning_curves)\n",
    "pf_colors = get_neuron_colors(pf_sort_ind)\n",
    "pf_sort_ind = np.array([int(pf_sort_ind[i]) for i in np.arange(len(pf_sort_ind))]) # convert to integer scalar array\n",
    "pf_sorted_good_placefield_neuronIDs = good_placefield_neuronIDs[pf_sort_ind]\n",
    "reverse_color_sort_indices = np.argsort(pf_sort_ind)\n",
    "pf_colors = pf_colors[:, reverse_color_sort_indices] # pf_colors shape is still (4, 31)\n",
    "active_epoch_session_Neurons = active_epoch_session_Neurons.get_by_id(good_placefield_neuronIDs) # Filter by good placefields only\n",
    "\n",
    "\n",
    "# Unpacking final values into separate variables:\n",
    "# Spike variables:\n",
    "num_cells = active_epoch_session_Neurons.n_neurons\n",
    "spike_list = active_epoch_session_Neurons.spiketrains\n",
    "cell_ids = active_epoch_session_Neurons.neuron_ids\n",
    "flattened_spikes = active_epoch_session_Neurons.get_flattened_spikes() # get_flattened_spikes(..) returns a FlattenedSpiketrains object\n",
    "# Position variables: t, x, y\n",
    "t = active_epoch_pos.time\n",
    "x = active_epoch_pos.x\n",
    "y = active_epoch_pos.y\n",
    "linear_pos = active_epoch_pos.linear_pos\n",
    "# speeds = active_epoch_pos.speed # note this has 1 less element than active_epoch_pos.x\n",
    "# Determine the x and y positions each spike occured for each cell\n",
    "spike_positions_list = build_spike_positions_list(spike_list, t, x, y)\n",
    "reverse_cellID_idx_lookup_map = build_cellID_reverse_lookup_map(cell_ids)\n",
    "print('num_cells: {}'.format(num_cells))\n",
    "print('cell_ids: {}'.format(cell_ids)) # cell_ids is now a regular python list with 57 elements\n",
    "\n",
    "active_cells_colormap = pf_colors.T # Make the colormap from the listed colors\n",
    "active_cells_listed_colormap = ListedColormap(active_cells_colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f4e857c-90b7-4037-b226-9b024386398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize_xbin=False,\n",
    "# normalize_ybin=False,\n",
    "# ax=None,\n",
    "# pad=2,\n",
    "# normalize_tuning_curve=False,\n",
    "# sortby=None,\n",
    "# cmap=\"tab20b\",\n",
    "\n",
    "# active_epoch_placefields2D_obj.plotMap()\n",
    "\n",
    "def plot_placefields2D(active_placefields, pf_colors):\n",
    "    # curr_tuning_curves = active_epoch_placefields.ratemap.tuning_curves\n",
    "    curr_tuning_curves = active_placefields.ratemap.normalized_tuning_curves\n",
    "    num_curr_tuning_curves = len(curr_tuning_curves)\n",
    "    # Get the cell IDs that have a good place field mapping:\n",
    "    good_placefield_neuronIDs = np.array(active_placefields.ratemap.neuron_ids) # in order of ascending ID\n",
    "    tuningCurvePlot_x, tuningCurvePlot_y = np.meshgrid(active_placefields.ratemap.xbin_centers, active_placefields.ratemap.ybin_centers)\n",
    "    # tuningCurvePlot_x, tuningCurvePlot_y = np.meshgrid(active_placefields.ratemap.xbin, active_placefields.ratemap.ybin)\n",
    "    # tuningCurvePlot_x, tuningCurvePlot_y = active_placefields.ratemap.xbin_centers, active_placefields.ratemap.ybin_centers\n",
    "    pTuningCurves = pvqt.BackgroundPlotter(window_size=(1920, 1080), shape=(1,1), off_screen=False) # Use just like you would a pv.Plotter() instance\n",
    "    pTuningCurves.clear()\n",
    "    # Loop through the tuning curves and plot them:\n",
    "    for i in np.arange(num_curr_tuning_curves):\n",
    "    # for i in [1]:\n",
    "        curr_active_neuron_ID = good_placefield_neuronIDs[i]\n",
    "        curr_active_neuron_color = pf_colors[:, i]\n",
    "        curr_active_neuron_tuning_Curve = np.squeeze(curr_tuning_curves[i,:,:]).T.copy() # A single tuning curve\n",
    "        # point_cloud_fixedSegements_positionTrail = np.column_stack((x[active_window_sample_indicies], y[active_window_sample_indicies], z_fixed))\n",
    "        # pdata_positionTrail = pv.PolyData(point_cloud_fixedSegements_positionTrail.copy()) # a mesh\n",
    "        pdata_currActiveNeuronTuningCurve = pv.StructuredGrid(tuningCurvePlot_x, tuningCurvePlot_y, curr_active_neuron_tuning_Curve)\n",
    "        # Set the coordinates from the numpy array\n",
    "        # pdata_currActiveNeuronTuningCurve.points = curr_active_neuron_tuning_Curve\n",
    "        # set the dimensions\n",
    "        # pdata_currActiveNeuronTuningCurve.dimensions = [np.shape(curr_active_neuron_tuning_Curve)[0], np.shape(curr_active_neuron_tuning_Curve)[1], 1]\n",
    "        pdata_currActiveNeuronTuningCurve[\"Elevation\"] = curr_active_neuron_tuning_Curve.ravel(order=\"F\")\n",
    "        # pdata_currActiveNeuronTuningCurve.plot(show_edges=True, show_grid=True, cpos='xy', scalars=curr_active_neuron_tuning_Curve.T)\n",
    "        actor_currActiveNeuronTuningCurve = pTuningCurves.add_mesh(pdata_currActiveNeuronTuningCurve, show_edges=True, color=curr_active_neuron_color, opacity=1.0, use_transparency=False, lighting=True)\n",
    "\n",
    "    # pTuningCurves.legend()\n",
    "    pTuningCurves.show_grid()\n",
    "    pTuningCurves.add_axes(line_width=5, labels_off=False)\n",
    "    return pTuningCurves\n",
    "\n",
    "pTuningCurves = plot_placefields2D(active_epoch_placefields, pf_colors)\n",
    "pTuningCurves.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6aa9bde-ad25-4fb7-8abc-883b002ae641",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_flattened_spikes: 100778\n",
      "flattened_spike_positions_list: (2, 100778)\n"
     ]
    }
   ],
   "source": [
    "# Gets the flattened spikes, sorted in ascending timestamp for all cells.\n",
    "num_flattened_spikes = np.size(flattened_spikes.flattened_spike_times)\n",
    "print('num_flattened_spikes: {}'.format(num_flattened_spikes))\n",
    "# Build the Active UnitIDs\n",
    "flattened_spike_active_unitIdentities = np.array([int(reverse_cellID_idx_lookup_map[original_cellID]) for original_cellID in flattened_spikes.flattened_spike_identities]) # since flattened_spikes.flattened_spike_identities is already sorted, don't double sort\n",
    "## Build the flattened spike positions list\n",
    "flattened_spike_positions_list = np.concatenate(tuple(spike_positions_list), axis=1) # needs tuple(...) to conver the list into a tuple, which is the format it expects\n",
    "flattened_spike_positions_list = flattened_spike_positions_list[:, flattened_spikes.flattened_sort_indicies] # ensure the positions are ordered the same as the other flattened items so they line up\n",
    "print('flattened_spike_positions_list: {}'.format(np.shape(flattened_spike_positions_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e64b3d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_epoch_pos.sampling_rate (Hz): 60\n",
      "longer_spikes_window - curr_view_window_length_samples - 61440\n",
      "recent_spikes_window - curr_view_window_length_samples - 60\n"
     ]
    }
   ],
   "source": [
    "# have active_epoch_position_times: the actual times each position sample occured in seconds, active_epoch_relative_position_times: the same as active_epoch_position_times but starting at zero\n",
    "# describe the movement\n",
    "\n",
    "from PhoPositionalData.plotting.visualization_window import VisualizationWindow # Used to build \"Windows\" into the data points such as the window defining the fixed time period preceeding the current time where spikes had recently fired, etc.\n",
    "\n",
    "# Split the position data into equal sized chunks to be displayed at a single time. These will look like portions of the trajectory and be used to animate. # Chunk the data to create the animation.\n",
    "curr_plot_update_step = 1 # Update every frame\n",
    "curr_plot_update_frequency = curr_plot_update_step * active_epoch_pos.sampling_rate # number of updates per second (Hz)\n",
    "num_time_points = active_epoch_pos.n_frames / curr_plot_update_step\n",
    "print('active_epoch_pos.sampling_rate (Hz): {}'.format(active_epoch_pos.sampling_rate))\n",
    "\n",
    "# curr_window_duration = 2.5 # in seconds\n",
    "# curr_view_window_length_samples = int(np.floor(curr_window_duration * active_epoch_pos.sampling_rate)) # number of samples the window should last\n",
    "# recent_spikes_window = VisualizationWindow(duration_seconds=curr_window_duration, duration_num_frames=curr_view_window_length_samples)\n",
    "\n",
    "# curr_recently_window_duration = 0.5 # in seconds\n",
    "# curr_view_window_length_samples = int(np.floor(curr_window_duration * active_epoch_pos.sampling_rate)) # number of samples the window should last\n",
    "\n",
    "## Simplified with just two windows:\n",
    "longer_spikes_window = VisualizationWindow(duration_seconds=1024.0, sampling_rate=active_epoch_pos.sampling_rate) # have it start clearing spikes more than 30 seconds old\n",
    "curr_view_window_length_samples = longer_spikes_window.duration_num_frames # number of samples the window should last\n",
    "print('longer_spikes_window - curr_view_window_length_samples - {}'.format(curr_view_window_length_samples))\n",
    "\n",
    "recent_spikes_window = VisualizationWindow(duration_seconds=1.0, sampling_rate=active_epoch_pos.sampling_rate)\n",
    "curr_view_window_length_samples = recent_spikes_window.duration_num_frames # number of samples the window should last\n",
    "print('recent_spikes_window - curr_view_window_length_samples - {}'.format(curr_view_window_length_samples))\n",
    "\n",
    "## Build the sliding windows:\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "# build a sliding window to be able to retreive the correct flattened indicies for any given timestep\n",
    "active_epoch_position_linear_indicies = np.arange(np.size(active_epoch_position_times))\n",
    "pre_computed_window_sample_indicies = recent_spikes_window.build_sliding_windows(active_epoch_position_linear_indicies)\n",
    "# print('pre_computed_window_sample_indicies: {}\\n shape: {}'.format(pre_computed_window_sample_indicies, np.shape(pre_computed_window_sample_indicies)))\n",
    "\n",
    "## New Pre Computed Indicies Way:\n",
    "z_fixed = np.full((recent_spikes_window.duration_num_frames,), 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "242a014c-ae46-4e43-8095-91dbc11d3ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on frate_thresh, excluded neuron_ids: [ 10  37  41  68 107]\n"
     ]
    }
   ],
   "source": [
    "## ICA and PCA Analysis\n",
    "should_show_2D_ICA_plots = False\n",
    "from PhoPositionalData.analysis.neuronal_dimensionality_reduction import runAnalysis_PCAandICA\n",
    "active_session_ensembles, template, zsc_template, pca_data = runAnalysis_PCAandICA(active_epoch_session_Neurons, bin_size=0.250, frate_thresh=0.1, should_plot=should_show_2D_ICA_plots, active_cells_colormap=active_cells_colormap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bca1e4-77d4-4a42-9883-57f0ff6431d4",
   "metadata": {},
   "source": [
    "## Main Spike/Placemap plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d92bd2e-138f-4df6-8731-12fbdd3c950b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying custom Pyvista theme.\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from PhoPositionalData.plotting.gui import customize_default_pyvista_theme, print_controls_helper_text\n",
    "customize_default_pyvista_theme() # Sets the default theme values to those specified in my imported file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab61be64-3491-48d0-8e9e-35cd6017a631",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_time_points: 174000.0\n",
      "\n",
      "BackgroundPlotter already open, reusing it.. NOT Forcing creation of a new one!\n",
      "Creating a new BackgroundPlotter\n",
      "done.\n",
      "previous_camera_position: [(288.9183692477459, 296.8223418734783, 286.70209641678275),\n",
      " (3.316272735595703, 11.220245361328125, 1.0999999046325684),\n",
      " (0.0, 0.0, 1.0)]\n",
      "all done!\n"
     ]
    }
   ],
   "source": [
    "from PhoPositionalData.plotting.spikeAndPositions import build_active_spikes_plot_data, build_flat_map_plot_data, build_spike_spawn_effect_light_actor, spike_geom_circle, spike_geom_box, spike_geom_cone, animal_location_circle, animal_location_trail_circle\n",
    "from PhoPositionalData.plotting.spikeAndPositions import InteractiveSliderWrapper # for wrapping the slider\n",
    "num_time_points = active_epoch_pos.n_frames / curr_plot_update_step\n",
    "print('num_time_points: {}\\n'.format(num_time_points))\n",
    "\n",
    "## Opacity Helpers:\n",
    "last_only_opacity_values = np.zeros([curr_view_window_length_samples,])\n",
    "last_only_opacity_values[-1] = 1.0\n",
    "# gradually_fading_opacity_values = np.arange(curr_view_window_length_samples)\n",
    "gradually_fading_opacity_values = np.linspace(0.0, 1.0, curr_view_window_length_samples)\n",
    "long_gradually_fading_opacity_values = np.linspace(0.0, 1.0, longer_spikes_window.duration_num_frames)\n",
    "sharply_fading_opacity_values = np.linspace(0.0, 0.6, curr_view_window_length_samples)\n",
    "# sharply_fading_opacity_values[-1] = 0.1 # last element (corresponding to current position) is set to 1.0\n",
    "\n",
    "# active_trail_opacity_values = last_only_opacity_values.copy()\n",
    "# active_trail_opacity_values = gradually_fading_opacity_values.copy()\n",
    "active_trail_opacity_values = sharply_fading_opacity_values.copy()\n",
    "# print('active_trail_opacity_values: {}\\n'.format(np.shape(active_trail_opacity_values)))\n",
    "# active_trail_size_values = np.full([curr_view_window_length_samples,], 0.6) # all have a scale of 0.6\n",
    "active_trail_size_values = np.linspace(0.2, 0.6, curr_view_window_length_samples) # fade from a scale of 0.2 to 0.6\n",
    "# active_trail_size_values[-1] = 6.0 # except for the end (current) point, which has a scale of 1.0\n",
    "# active_trail_size_values = sharply_fading_opacity_values.copy()\n",
    "\n",
    "## Slider with Callback Function Example:\n",
    "\n",
    "######################\n",
    "# General Plotting Method:    \n",
    "def on_slider_update_mesh(value):\n",
    "    curr_i = int(value)    \n",
    "    active_window_sample_indicies = np.squeeze(pre_computed_window_sample_indicies[curr_i,:]) # Get the current precomputed indicies for this curr_i\n",
    "    \n",
    "    ## Spike Plotting:\n",
    "    # Get the times that fall within the current plot window:\n",
    "    curr_time_fixedSegments = t[active_window_sample_indicies] # New Way\n",
    "    t_start = curr_time_fixedSegments[0]\n",
    "    t_stop = curr_time_fixedSegments[-1]\n",
    "    # print('Constraining to curr_time_fixedSegments with times (start: {}, end: {})'.format(t_start, t_stop))\n",
    "    # print('curr_time_fixedSegments: {}'.format(curr_time_fixedSegments))\n",
    "    curr_text_rendering_string = 'curr_i: {:d}; (t_start: {:.2f}, t_stop: {:.2f})'.format(curr_i, t_start, t_stop) # :.3f\n",
    "    p.add_text(curr_text_rendering_string, name='lblCurrent_spike_range', position='lower_right', color='white', shadow=True, font_size=10)\n",
    "\n",
    "    ## Historical Spikes:\n",
    "    # active_included_all_historical_indicies = (flattened_spikes.flattened_spike_times < t_stop) # Accumulate Spikes mode. All spikes occuring prior to the end of the frame (meaning the current time) are plotted\n",
    "    historical_t_start = (t_stop - longer_spikes_window.duration_seconds) # Get the earliest time that will be included in the search\n",
    "    active_included_all_historical_indicies = ((flattened_spikes.flattened_spike_times > historical_t_start) & (flattened_spikes.flattened_spike_times < t_stop)) # Two Sided Range Mode\n",
    "    historical_spikes_pdata, historical_spikes_pc = build_active_spikes_plot_data(flattened_spikes.flattened_spike_times[active_included_all_historical_indicies],\n",
    "                                                                                  flattened_spike_active_unitIdentities[active_included_all_historical_indicies],\n",
    "                                                                                  flattened_spike_positions_list[:, active_included_all_historical_indicies],\n",
    "                                                                                  spike_geom=spike_geom_box.copy())\n",
    "    if historical_spikes_pc.n_points >= 1:\n",
    "        historical_main_spikes_mesh = p.add_mesh(historical_spikes_pc, name='historical_spikes_main', scalars='cellID', cmap=active_cells_listed_colormap, show_scalar_bar=False, lighting=True, render=False)\n",
    "\n",
    "    ## Actively Firing Spikes:\n",
    "    recent_spikes_t_start = (t_stop - recent_spikes_window.duration_seconds) # Get the earliest time that will be included in the recent spikes\n",
    "    # print('recent_spikes_t_start: {}; t_start: {}'.format(recent_spikes_t_start, t_start))\n",
    "    active_included_recent_only_indicies = ((flattened_spikes.flattened_spike_times > recent_spikes_t_start) & (flattened_spikes.flattened_spike_times < t_stop)) # Two Sided Range Mode\n",
    "    # active_included_recent_only_indicies = ((flattened_spikes.flattened_spike_times > t_start) & (flattened_spikes.flattened_spike_times < t_stop)) # Two Sided Range Mode\n",
    "    recent_only_spikes_pdata, recent_only_spikes_pc = build_active_spikes_plot_data(flattened_spikes.flattened_spike_times[active_included_recent_only_indicies],\n",
    "                                                                                    flattened_spike_active_unitIdentities[active_included_recent_only_indicies],\n",
    "                                                                                    flattened_spike_positions_list[:, active_included_recent_only_indicies],\n",
    "                                                                                    spike_geom=spike_geom_cone.copy())\n",
    "    if recent_only_spikes_pc.n_points >= 1:\n",
    "        recent_only_main_spikes_mesh = p.add_mesh(recent_only_spikes_pc, name='recent_only_spikes_main', scalars='cellID', cmap=active_cells_listed_colormap, show_scalar_bar=False, lighting=False, render=False) # color='white'\n",
    "        \n",
    "    ## Animal Position and Location Trail Plotting:\n",
    "    point_cloud_fixedSegements_positionTrail = np.column_stack((x[active_window_sample_indicies], y[active_window_sample_indicies], z_fixed))\n",
    "    pdata_positionTrail = pv.PolyData(point_cloud_fixedSegements_positionTrail.copy()) # a mesh\n",
    "    pdata_positionTrail.point_data['pho_fade_values'] = active_trail_opacity_values\n",
    "    pdata_positionTrail.point_data['pho_size_values'] = active_trail_size_values\n",
    "    # create many spheres from the point cloud\n",
    "    pc_positionTrail = pdata_positionTrail.glyph(scale='pho_size_values', geom=animal_location_trail_circle)\n",
    "    animal_location_trail_mesh = p.add_mesh(pc_positionTrail, name='animal_location_trail', ambient=0.6, opacity='linear_r', scalars='pho_fade_values', nan_opacity=0.0,\n",
    "                                            show_edges=False, render_lines_as_tubes=True, show_scalar_bar=False, use_transparency=True, render=False) # works to render a heat colored (most recent==hotter) position\n",
    "\n",
    "    ## Animal Current Position:\n",
    "    curr_animal_point = point_cloud_fixedSegements_positionTrail[-1,:].copy() # Get the last point\n",
    "    pdata_current_point = pv.PolyData(curr_animal_point) # a mesh\n",
    "    pc_current_point = pdata_current_point.glyph(scale=False, geom=animal_location_circle)\n",
    "    animal_current_location_point_mesh = p.add_mesh(pc_current_point, name='animal_location', color='green', ambient=0.6, opacity=0.5,\n",
    "                                                    show_edges=True, edge_color=[0.05, 0.8, 0.08], line_width=3.0, nan_opacity=0.0, render_lines_as_tubes=True,\n",
    "                                                    show_scalar_bar=False, use_transparency=True, render=False) # works to render a heat colored (most recent==hotter) position\n",
    "    \n",
    "    p.render() # renders to ensure it's updated after changing the ScalarVisibility above\n",
    "    # p.update()\n",
    "    # p.app.processEvents() # not needed probably\n",
    "    return\n",
    "\n",
    "\n",
    "################################################\n",
    "### Build Appropriate Plotter and set it up:\n",
    "#####################\n",
    "\n",
    "\n",
    "# This defines the position of the vertical/horizontal splitting, in this case 40% of the vertical/horizontal dimension of the window\n",
    "# pv.global_theme.multi_rendering_splitting_position = 0.40\n",
    "pv.global_theme.multi_rendering_splitting_position = 0.80\n",
    "\n",
    "# Only Create a new BackgroundPlotter if it's needed:\n",
    "if (active_config.video_output_config.active_is_video_output_mode):\n",
    "    ## Video mode should use a regular plotter object\n",
    "    p = pv.Plotter(notebook=False, shape=active_config.plotting_config.subplots_shape, window_size=([1280, 720]), off_screen=True) # , line_smoothing=True, polygon_smoothing=True, multi_samples=8\n",
    "else:\n",
    "    try: p\n",
    "    except NameError: p = None # Checks variable p's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "    if (p is not None):\n",
    "        if isinstance(p, pvqt.BackgroundPlotter):\n",
    "            if p.app_window.isHidden():\n",
    "                print('No open BackgroundPlotter')\n",
    "                p.close() # Close it to start over fresh\n",
    "                p = None\n",
    "                needs_create_new_backgroundPlotter = True\n",
    "            else:\n",
    "                print('BackgroundPlotter already open, reusing it.. NOT Forcing creation of a new one!')\n",
    "                # p.app_window.window().show()\n",
    "                # p.clear()\n",
    "                # needs_create_new_backgroundPlotter = False                \n",
    "                p.close() # Close it to start over fresh\n",
    "                p = None\n",
    "                needs_create_new_backgroundPlotter = True\n",
    "                \n",
    "        else:\n",
    "            print('No open BackgroundPlotter, p is a Plotter object')\n",
    "            p.close()\n",
    "            p = None\n",
    "            needs_create_new_backgroundPlotter = True\n",
    "    else:\n",
    "        print('No extant BackgroundPlotter')\n",
    "        needs_create_new_backgroundPlotter = True\n",
    "    if needs_create_new_backgroundPlotter:\n",
    "        print('Creating a new BackgroundPlotter')\n",
    "        p = pvqt.BackgroundPlotter(window_size=(1920, 1080), shape=active_config.plotting_config.subplots_shape, off_screen=False) # Use just like you would a pv.Plotter() instance\n",
    "        print('done.')\n",
    "\n",
    "# p.background_color = 'black'\n",
    "\n",
    "# # define the animation switch\n",
    "# def toggle_animation(state):\n",
    "#     animate.animation_state = state\n",
    "    \n",
    "\n",
    "if (not active_config.video_output_config.active_is_video_output_mode):\n",
    "    #Interactive Mode: Enable interactive controls:\n",
    "    interactive_timestamp_slider_actor = p.add_slider_widget(on_slider_update_mesh, [0, (num_time_points-1)], title='Trajectory Timestep', event_type='always', style='modern', pointa=(0.025, 0.1), pointb=(0.98, 0.1)) # fmt=\"%0.2f\"\n",
    "    interactive_timestamp_slider_wrapper = InteractiveSliderWrapper(interactive_timestamp_slider_actor)\n",
    "    \n",
    "    # interactive_checkbox_actor = p.add_checkbox_button_widget(toggle_animation, value=False, color_on='green')\n",
    "    \n",
    "## An unused constant-time callback that calls back every so often to perform updates\n",
    "# p.add_callback(animate, interval=16)  # to be smooth on 60Hz\n",
    "    \n",
    "# Plot the flat arena\n",
    "pdata_maze, pc_maze = build_flat_map_plot_data(x, y)\n",
    "p.add_mesh(pc_maze, name='maze_bg', color=\"black\", render=False)\n",
    "# p.show_grid()\n",
    "# p.add_axes(line_width=5, labels_off=True)\n",
    "p.enable_depth_peeling(number_of_peels=4, occlusion_ratio=0) # Supposedly helps with translucency\n",
    "p.hide_axes()\n",
    "# p.camera_position = 'xy' # Overhead (top) view\n",
    "# apply_close_overhead_zoomed_camera_view(p)\n",
    "apply_close_perspective_camera_view(p)\n",
    "\n",
    "p.render() # manually render when needed\n",
    "\n",
    "if active_config.video_output_config.active_is_video_output_mode:\n",
    "    print('Writing video to {}...'.format(active_config.video_output_config.active_video_output_fullpath))\n",
    "    p.show(auto_close=False)\n",
    "    make_mp4_from_plotter(p, active_config.video_output_config.active_frame_range, on_slider_update_mesh, filename=active_config.video_output_config.active_video_output_fullpath, framerate=60) # 60fps\n",
    "    p.close()\n",
    "    p = None\n",
    "\n",
    "# p.show()\n",
    "                  \n",
    "print('all done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26c6f507-f966-4b5e-9b87-beb2abb6a97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87014"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactive_timestamp_slider_wrapper.curr_index\n",
    "interactive_timestamp_slider_wrapper.step_index(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6c5f0-a525-444a-8540-a8ffcc96d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.subplot(1)\n",
    "p.add_text(\"Tuning Curves\")\n",
    "p.add_lines("
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "fde6e68fa8f5f4f0920a88ee99edd8d4121f14a57a7800ceb19ed197f25c05dc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
