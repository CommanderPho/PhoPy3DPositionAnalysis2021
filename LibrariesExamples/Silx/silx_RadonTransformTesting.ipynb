{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "The viztracer extension is already loaded. To reload it, use:\n",
      "  %reload_ext viztracer\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function pyphocorehelpers.pprint.wide_pprint_jupyter(obj, p, cycle, **kwargs)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAY_DATE_STR: 2024-02-15, DAY_DATE_TO_USE: 2024-02-15\n",
      "NOW_DATETIME: 2024-02-15_1120AM, NOW_DATETIME_TO_USE: 2024-02-15_1120AM\n",
      "global_data_root_parent_path changed to /media/halechr/MAX/Data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b2c0c80af64c9686201e146743491d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Data Root:', layout=Layout(width='auto'), options=(PosixPath('/media/halechr/MAX/Data'), PosixPath('/home/halechr/FastData')), style=ToggleButtonsStyle(button_width='max-content'), tooltip='global_data_root_parent_path', value=PosixPath('/media/halechr/MAX/Data'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "# %xmode Verbose\n",
    "# %xmode context\n",
    "%pdb off\n",
    "%load_ext viztracer\n",
    "from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "from attrs import define, field, fields, Factory\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "import builtins\n",
    "\n",
    "import IPython\n",
    "from IPython.core.formatters import PlainTextFormatter\n",
    "from IPython import get_ipython\n",
    "\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "# Jupyter-lab enable printing for any line on its own (instead of just the last one in the cell)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# BEGIN PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "\n",
    "## IPython pprint\n",
    "from pyphocorehelpers.pprint import wide_pprint, wide_pprint_ipython, wide_pprint_jupyter, MAX_LINE_LENGTH\n",
    "\n",
    "# Override default pprint\n",
    "builtins.pprint = wide_pprint\n",
    "\n",
    "text_formatter: PlainTextFormatter = IPython.get_ipython().display_formatter.formatters['text/plain']\n",
    "text_formatter.max_width = MAX_LINE_LENGTH\n",
    "text_formatter.for_type(object, wide_pprint_jupyter)\n",
    "\n",
    "\n",
    "# END PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "from pyphocorehelpers.print_helpers import get_now_time_str, get_now_day_str\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path, file_uri_from_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field, custom_define\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin, HDF_Converter\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_subsession_neuron_differences, debug_print_ratemap, debug_print_spike_counts, debug_plot_2d_binning, print_aligned_columns\n",
    "from neuropy.utils.debug_helpers import parameter_sweeps, _plot_parameter_sweep, compare_placefields_info\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies, paired_incremental_sorting\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, CapturedException, document_active_variables\n",
    "\n",
    "## Pho Programming Helpers:\n",
    "import inspect\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter, TypePrintMode, print_keys_if_possible, debug_dump_object_member_shapes, print_value_overview_only, document_active_variables, CapturedException\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers, PythonDictionaryDefinitionFormat, MemoryManagement, inspect_callable_arguments, get_arguments_as_optional_dict, GeneratedClassDefinitionType, CodeConversion\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper, print_widget_hierarchy\n",
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative, dict_to_full_array\n",
    "# doc_output_parent_folder: Path = Path('EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation').resolve() # ../.\n",
    "# print(f\"doc_output_parent_folder: {doc_output_parent_folder}\")\n",
    "# assert doc_output_parent_folder.exists()\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsResult, TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer, RankOrderResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses\n",
    "\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "# %matplotlib inline\n",
    "# %matplotlib auto\n",
    "\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget, render_colors\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "\n",
    "DAY_DATE_STR: str = date.today().strftime(\"%Y-%m-%d\")\n",
    "DAY_DATE_TO_USE = f'{DAY_DATE_STR}' # used for filenames throught the notebook\n",
    "print(f'DAY_DATE_STR: {DAY_DATE_STR}, DAY_DATE_TO_USE: {DAY_DATE_TO_USE}')\n",
    "\n",
    "NOW_DATETIME: str = get_now_rounded_time_str()\n",
    "NOW_DATETIME_TO_USE = f'{NOW_DATETIME}' # used for filenames throught the notebook\n",
    "print(f'NOW_DATETIME: {NOW_DATETIME}, NOW_DATETIME_TO_USE: {NOW_DATETIME_TO_USE}')\n",
    "\n",
    "\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import build_global_data_root_parent_path_selection_widget\n",
    "all_paths = [Path(r'/media/MAX/Data'), Path(r'/media/halechr/MAX/Data'), Path(r'/home/halechr/FastData'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')]\n",
    "global_data_root_parent_path = None\n",
    "def on_user_update_path_selection(new_path: Path):\n",
    "\tglobal global_data_root_parent_path\n",
    "\tnew_global_data_root_parent_path = new_path.resolve()\n",
    "\tglobal_data_root_parent_path = new_global_data_root_parent_path\n",
    "\tprint(f'global_data_root_parent_path changed to {global_data_root_parent_path}')\n",
    "\tassert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "\t\t\t\n",
    "global_data_root_parent_path_widget = build_global_data_root_parent_path_selection_widget(all_paths, on_user_update_path_selection)\n",
    "global_data_root_parent_path_widget\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyQt5.QtWidgets.QApplication object at 0x7f03b61eee50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading loaded session pickle file results : /media/halechr/MAX/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/2024-02-15_CustomDecodingResults.pkl... done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.793023081021702"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.Qt import QtGui, QtCore, QtWidgets\n",
    "# from pyphoplacecellanalysis.External.pyqtgraph.parametertree.parameterTypes.file import popupFilePicker\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.widgets.FileDialog import FileDialog\n",
    "\n",
    "from silx.gui import qt\n",
    "from silx.gui.dialog.ImageFileDialog import ImageFileDialog\n",
    "from silx.gui.dialog.DataFileDialog import DataFileDialog\n",
    "import silx.io\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import saveFile\n",
    "\n",
    "app = pg.mkQApp('silx_testing')\n",
    "app\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import loadData\n",
    "\n",
    "# load_path = Path(r\"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-02-13_CustomDecodingResults.pkl\").resolve()\n",
    "# load_path = Path(r\"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-02-13_9pm_CustomDecodingResults.pkl\").resolve()\n",
    "# load_path = Path(r\"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-02-14_CustomDecodingResults.pkl\").resolve()\n",
    "# load_path = Path(r\"W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\2024-02-15_CustomDecodingResults.pkl\").resolve()\n",
    "load_path = Path(\"/media/halechr/MAX/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/2024-02-15_CustomDecodingResults.pkl\").resolve()\n",
    "\n",
    "assert load_path.exists()\n",
    "loaded_dict = loadData(load_path, debug_print=False)\n",
    "## UNPACK HERE:\n",
    "pos_bin_size: float = loaded_dict['pos_bin_size']\n",
    "ripple_decoding_time_bin_size = loaded_dict['ripple_decoding_time_bin_size']\n",
    "laps_decoding_time_bin_size = loaded_dict['laps_decoding_time_bin_size']\n",
    "decoder_laps_filter_epochs_decoder_result_dict = loaded_dict['decoder_laps_filter_epochs_decoder_result_dict']\n",
    "decoder_ripple_filter_epochs_decoder_result_dict = loaded_dict['decoder_ripple_filter_epochs_decoder_result_dict']\n",
    "decoder_laps_radon_transform_df_dict = loaded_dict['decoder_laps_radon_transform_df_dict']\n",
    "decoder_ripple_radon_transform_df_dict = loaded_dict['decoder_ripple_radon_transform_df_dict']\n",
    "## New 2024-02-14 - Noon:\n",
    "decoder_laps_radon_transform_extras_dict = loaded_dict['decoder_laps_radon_transform_extras_dict']\n",
    "decoder_ripple_radon_transform_extras_dict = loaded_dict['decoder_ripple_radon_transform_extras_dict']\n",
    "\n",
    "\n",
    "# {'ripple_decoding_time_bin_size':ripple_decoding_time_bin_size, 'laps_decoding_time_bin_size':laps_decoding_time_bin_size, 'decoder_laps_filter_epochs_decoder_result_dict':decoder_laps_filter_epochs_decoder_result_dict, 'decoder_ripple_filter_epochs_decoder_result_dict':decoder_ripple_filter_epochs_decoder_result_dict, 'decoder_laps_radon_transform_df_dict':decoder_laps_radon_transform_df_dict, 'decoder_ripple_radon_transform_df_dict':decoder_ripple_radon_transform_df_dict}\n",
    "\n",
    "pos_bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0715084, 6.30848e-05, 0.0715084, ..., 0.0715084, 0.0715084, 0.0715084],\n",
       "       [0.0631044, 0.000130805, 0.0631044, ..., 0.0631044, 0.0631044, 0.0631044],\n",
       "       [0.0505503, 0.000251185, 0.0505503, ..., 0.0505503, 0.0505503, 0.0505503],\n",
       "       ...,\n",
       "       [0.0290197, 0.14635, 0.0290197, ..., 0.0290197, 0.0290197, 0.0290197],\n",
       "       [0.0400907, 0.201589, 0.0400907, ..., 0.0400907, 0.0400907, 0.0400907],\n",
       "       [0.0478853, 0.23969, 0.0478853, ..., 0.0478853, 0.0478853, 0.0478853]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.025"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       "\tfilter_epochs: neuropy.core.epoch.Epoch,\n",
       "\tnum_filter_epochs: int,\n",
       "\tmost_likely_positions_list: list | shape (n_epochs),\n",
       "\tp_x_given_n_list: list | shape (n_epochs),\n",
       "\tmarginal_x_list: list | shape (n_epochs),\n",
       "\tmarginal_y_list: list | shape (n_epochs),\n",
       "\tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       "\tspkcount: list | shape (n_epochs),\n",
       "\tnbins: numpy.ndarray | shape (n_epochs),\n",
       "\ttime_bin_containers: list | shape (n_epochs),\n",
       "\ttime_bin_edges: list | shape (n_epochs),\n",
       "\tepoch_description_list: list | shape (n_epochs)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "# decoder_laps_filter_epochs_decoder_result_dict\n",
    "\n",
    "result: DecodedFilterEpochsResult = decoder_laps_filter_epochs_decoder_result_dict['long_LR']\n",
    "a_posterior = result.p_x_given_n_list[0]\n",
    "a_posterior\n",
    "laps_decoding_time_bin_size\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "from silx.gui.data.DataViewerFrame import DataViewerFrame\n",
    "from silx.gui.plot import PlotWindow, ImageView\n",
    "from silx.gui.plot.Profile import ProfileToolBar\n",
    "\n",
    "\n",
    "# from silx import DataViewerFrame\n",
    "\n",
    "# viewer: DataViewerFrame = DataViewerFrame()\n",
    "# viewer.setData(a_posterior)\n",
    "# viewer.setVisible(True)\n",
    "\n",
    "plot = ImageView()  # Create a PlotWindow\n",
    "plot.setImage(a_posterior)\n",
    "toolBar = ProfileToolBar(plot=plot)  # Create a profile toolbar\n",
    "plot.addToolBar(toolBar)  # Add it to plot\n",
    "plot.show()  # To display the PlotWindow with the profile toolbar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nptyping import NDArray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_score(arr, y_line):\n",
    "    nlines = 1\n",
    "    y_line = np.rint(y_line).astype(\"int\")\n",
    "    \n",
    "    t = np.arange(arr.shape[1])\n",
    "    nt = arr.shape[1]\n",
    "    # tmid = (nt + 1) / 2 - 1\n",
    "\n",
    "    pos = np.arange(arr.shape[0])\n",
    "    npos = len(pos)\n",
    "    # pmid = (npos + 1) / 2 - 1\n",
    "\n",
    "    t_mat = np.tile(t, (nlines, 1))\n",
    "    posterior = np.zeros((nlines, nt))\n",
    "\n",
    "    # if line falls outside of array in a given bin, replace that with median posterior value of that bin across all positions\n",
    "    t_out = np.where((y_line < 0) | (y_line > npos - 1))\n",
    "    t_in = np.where((y_line >= 0) & (y_line <= npos - 1))\n",
    "    posterior[t_out] = np.median(arr[:, t_out[1]], axis=0)\n",
    "    posterior[t_in] = arr[y_line[t_in], t_in[1]]\n",
    "\n",
    "    old_settings = np.seterr(all=\"ignore\")\n",
    "    posterior_mean = np.nanmean(posterior, axis=1)\n",
    "    return posterior_mean\n",
    "\n",
    "\n",
    "# def radon_transform(arr: NDArray, nlines:int=10000, dt:float=1, dx:float=1, neighbours:int=1, enable_return_neighbors_arr=False):\n",
    "#     \"\"\"Line fitting algorithm primarily used in decoding algorithm, a variant of radon transform, algorithm based on Kloosterman et al. 2012\n",
    "\n",
    "#     from neuropy.analyses.decoders import radon_transform\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     arr : 2d array\n",
    "#         time axis is represented by columns, position axis is represented by rows\n",
    "#     dt : float\n",
    "#         time binsize in seconds, only used for velocity/intercept calculation\n",
    "#     dx : float\n",
    "#         position binsize in cm, only used for velocity/intercept calculation\n",
    "#     neighbours : int,\n",
    "#         probability in each bin is replaced by sum of itself and these many 'neighbours' column wise, default 1 neighbour\n",
    "\n",
    "#     NOTE: when returning velocity the sign is flipped to match with position going from bottom to up\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     score:\n",
    "#         sum of values (posterior) under the best fit line\n",
    "#     velocity:\n",
    "#         speed of replay in cm/s\n",
    "#     intercept:\n",
    "#         intercept of best fit line\n",
    "\n",
    "#     References\n",
    "#     ----------\n",
    "#     1) Kloosterman et al. 2012\n",
    "#     \"\"\"\n",
    "#     t = np.arange(arr.shape[1])\n",
    "#     nt = len(t)\n",
    "#     tmid = (nt + 1) / 2 - 1\n",
    "\n",
    "#     pos = np.arange(arr.shape[0])\n",
    "#     npos = len(pos)\n",
    "#     pmid = (npos + 1) / 2 - 1\n",
    "\n",
    "#     # using convolution to sum neighbours\n",
    "#     arr = np.apply_along_axis(\n",
    "#         np.convolve, axis=0, arr=arr, v=np.ones(2 * neighbours + 1), mode=\"same\"\n",
    "#     )\n",
    "\n",
    "#     # exclude stationary events by choosing phi little below 90 degree\n",
    "#     # NOTE: angle of line is given by (90-phi), refer Kloosterman 2012\n",
    "#     phi = np.random.uniform(low=(-np.pi / 2), high=(np.pi / 2), size=nlines)\n",
    "#     diag_len = np.sqrt((nt - 1) ** 2 + (npos - 1) ** 2)\n",
    "#     rho = np.random.uniform(low=-diag_len / 2, high=diag_len / 2, size=nlines)\n",
    "\n",
    "#     rho_mat = np.tile(rho, (nt, 1)).T\n",
    "#     phi_mat = np.tile(phi, (nt, 1)).T\n",
    "#     t_mat = np.tile(t, (nlines, 1))\n",
    "#     posterior = np.zeros((nlines, nt))\n",
    "\n",
    "#     y_line = ((rho_mat - (t_mat - tmid) * np.cos(phi_mat)) / np.sin(phi_mat)) + pmid\n",
    "#     y_line = np.rint(y_line).astype(\"int\")\n",
    "\n",
    "#     # if line falls outside of array in a given bin, replace that with median posterior value of that bin across all positions\n",
    "#     t_out = np.where((y_line < 0) | (y_line > npos - 1))\n",
    "#     t_in = np.where((y_line >= 0) & (y_line <= npos - 1))\n",
    "#     posterior[t_out] = np.median(arr[:, t_out[1]], axis=0)\n",
    "#     posterior[t_in] = arr[y_line[t_in], t_in[1]]\n",
    "\n",
    "#     old_settings = np.seterr(all=\"ignore\")\n",
    "#     posterior_mean = np.nanmean(posterior, axis=1)\n",
    "\n",
    "#     best_line = np.argmax(posterior_mean)\n",
    "#     score = posterior_mean[best_line]\n",
    "#     best_phi, best_rho = phi[best_line], rho[best_line]\n",
    "\n",
    "#     # converts to real world values\n",
    "#     time_mid, pos_mid = nt * dt / 2, npos * dx / 2\n",
    "\n",
    "#     velocity = dx / (dt * np.tan(best_phi))\n",
    "#     intercept = (\n",
    "#         (dx * time_mid) / (dt * np.tan(best_phi))\n",
    "#         + (best_rho / np.sin(best_phi)) * dx\n",
    "#         + pos_mid\n",
    "#     )\n",
    "#     np.seterr(**old_settings)\n",
    "\n",
    "#     if enable_return_neighbors_arr:\n",
    "#         return score, -velocity, intercept, (neighbours, arr.copy())\n",
    "#     else:\n",
    "#         return score, -velocity, intercept\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<silx.gui.plot.Profile._CustomProfileManager object at 0x7f03a064c700>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_man = toolBar.getProfileManager()\n",
    "profile_man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope: -0.15598885963190603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: 3.6380344785847694\n"
     ]
    }
   ],
   "source": [
    "roi = profile_man.getCurrentRoi()\n",
    "(x1, y1), (x2, y2) = roi.getEndPoints() # (array([27.0929, 67.4479]), array([463.253, -0.58816]))\n",
    "\n",
    "# Compute slope/intercept\n",
    "slope = (y2 - y1) / (x2 - x1)\n",
    "intercept = y2 - (slope * x1)\n",
    "print(f'slope: {slope}')\n",
    "print(f'intercept: {intercept}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors = roi.getProfileLineWidth()\n",
    "neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept_real_units: 13.799148746824784, slope_real_units: -23.66677379864296\n"
     ]
    }
   ],
   "source": [
    "dx: float = pos_bin_size\n",
    "dt: float = laps_decoding_time_bin_size\n",
    "intercept_real_units: float = intercept * dx\n",
    "slope_real_units: float = slope * (dx / dt)\n",
    "\n",
    "print(f'intercept_real_units: {intercept_real_units}, slope_real_units: {slope_real_units}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = deepcopy(a_posterior)\n",
    "posterior_mean = compute_score(arr, y_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyQt5.QtWidgets.QStackedWidget object at 0x7f03b39ac4c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewer.getReachableViews()\n",
    "imgView = viewer.currentAvailableViews()[1] # returns `[<silx.gui.data.DataViews._RawView object at 0x7f03b42270a0>, <silx.gui.data.DataViews._ImageView object at 0x7f03b4227e20>, <silx.gui.data.DataViews._Plot1dView object at 0x7f03b42271f0>]`\n",
    "imgView.getWidget()\n",
    "# viewer.getProfileManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing selected\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import openDialogAtHome\n",
    "dialog, result = openDialogAtHome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = DataFileDialog()\n",
    "dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_on_save_file(fileName: C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/LibrariesExamples/Silx/test_file_name.h5)\n"
     ]
    }
   ],
   "source": [
    "# class SaveAsManager:\n",
    "# \t@QtCore.pyqtSlot(object)\n",
    "# \tdef _on_save_file(self, fileName=None):\n",
    "# \t\tprint(f'_on_save_file(fileName: {fileName})')\n",
    "\n",
    "\n",
    "# \tdef saveFile(self, on_save_file_callback, fileName=None, startDir=None, suggestedFileName='custom_node.pEval'):\n",
    "# \t\t\"\"\"Save this Custom Eval Node to a .pEval file\n",
    "# \t\t\"\"\"\n",
    "# \t\tif fileName is None:\n",
    "# \t\t\tif startDir is None:\n",
    "# \t\t\t\tstartDir = '.'\n",
    "# \t\t\tfileDialog = FileDialog(None, \"Save h5 as..\", startDir, \"H5py File (*.h5)\")\n",
    "# \t\t\tfileDialog.setDefaultSuffix(\"h5\")\n",
    "# \t\t\tfileDialog.setAcceptMode(QtWidgets.QFileDialog.AcceptMode.AcceptSave) \n",
    "# \t\t\tfileDialog.show()\n",
    "# \t\t\tfileDialog.fileSelected.connect(on_save_file_callback)\n",
    "# \t\t\treturn fileDialog\n",
    "# \t\t# configfile.writeConfigFile(self.eval_node.saveState(), fileName)\n",
    "# \t\t# self.sigFileSaved.emit(fileName)\n",
    "\n",
    "# \tfileDialog = saveFile(_on_save_file, fileName=None, startDir=None, suggestedFileName='test_file_name.h5')\n",
    "# \tfileDialog.exec_()\n",
    "\n",
    "\n",
    "# @QtCore.pyqtSlot(object)\n",
    "# def _on_save_file(fileName=None):\n",
    "# \tprint(f'_on_save_file(fileName: {fileName})')\n",
    "\n",
    "# def saveFile(on_save_file_callback, fileName=None, startDir=None, suggestedFileName='custom_node.pEval'):\n",
    "# \t\"\"\"Save this Custom Eval Node to a .pEval file\n",
    "# \t\"\"\"\n",
    "# \tif startDir is None:\n",
    "# \t\tstartDir = '.'\n",
    "# \tfileDialog = FileDialog(None, \"Save h5 as..\", startDir, \"H5py File (*.h5)\")\n",
    "# \tfileDialog.setDefaultSuffix(\"h5\")\n",
    "# \tfileDialog.setAcceptMode(QtWidgets.QFileDialog.AcceptMode.AcceptSave) \n",
    "# \tfileDialog.show()\n",
    "# \tfileDialog.fileSelected.connect(on_save_file_callback)\n",
    "# \tfileDialog.exec_() # open modally\n",
    "# \treturn fileDialog\n",
    "# configfile.writeConfigFile(self.eval_node.saveState(), fileName)\n",
    "# self.sigFileSaved.emit(fileName)\n",
    "\n",
    "# lambda fileName: print(f'_on_save_file(fileName: {fileName})')\n",
    "\n",
    "fileDialog = saveFile(lambda fileName: print(f'_on_save_file(fileName: {fileName})'), caption=\"Save as..\",, startDir=None, suggestedFileName='test_file_name.h5')\n",
    "# fileDialog.exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_on_save_file(fileName: C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/LibrariesExamples/Silx/test.pkl)\n"
     ]
    }
   ],
   "source": [
    "fileDialog = saveFile(lambda fileName: print(f'_on_save_file(fileName: {fileName})'), caption=\"Save pickle as..\", startDir=None, suggestedFileName='test.pkl', filter=\"Pickle File (*.pkl)\", default_suffix=\"pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_on_save_file(fileName: C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/LibrariesExamples/Silx/test.h5)\n"
     ]
    }
   ],
   "source": [
    "fileDialog = saveFile(lambda fileName: print(f'_on_save_file(fileName: {fileName})'), caption=\"Save HDF5 file as..\", startDir=None, suggestedFileName='test.h5', filter=\"H5py File (*.h5)\", default_suffix=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = QtWidgets.QFileDialog.getSaveFileName(\n",
    "            self,\n",
    "            f\"{translate('TableWidget', 'Save As')}...\",\n",
    "            \"\",\n",
    "            f\"{translate('TableWidget', 'Tab-separated values')} (*.tsv)\"\n",
    "        )\n",
    "        if isinstance(fileName, tuple):\n",
    "            fileName = fileName[0]  # Qt4/5 API difference\n",
    "        if fileName == '':\n",
    "            return\n",
    "        with open(fileName, 'w') as fd:\n",
    "            fd.write(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
