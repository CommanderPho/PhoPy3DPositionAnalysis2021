{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "scripts_output_path: /nfs/turbo/umms-kdiba/Data/Output/gen_scripts\n",
      "collected_outputs_path: /nfs/turbo/umms-kdiba/Data/Output/collected_outputs\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "from copy import deepcopy\n",
    "from typing import List, Dict, Optional, Union, Callable\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables as tb\n",
    "from copy import deepcopy\n",
    "from datetime import datetime, timedelta\n",
    "from attrs import define, field, Factory\n",
    "\n",
    "# # required to enable non-blocking interaction:\n",
    "# %gui qt5 ## TODO 2024-01-18 - this causes kernel to crash when running notebook remotely via VSCode's ssh remote\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.exception_helpers import CapturedException\n",
    "\n",
    "# Jupyter interactivity:\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.gui.Jupyter.JupyterButtonRowWidget import JupyterButtonRowWidget\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core import Epoch\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "import pyphoplacecellanalysis.General.Batch.runBatch\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun, BatchResultDataframeAccessor, run_diba_batch, BatchComputationProcessOptions, BatchSessionCompletionHandler, SavingOptions\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import SessionBatchProgress\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults, AcrossSessionTables, AcrossSessionsVisualizations\n",
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "from pyphoplacecellanalysis.General.Batch.pythonScriptTemplating import build_vscode_workspace, build_windows_powershell_run_script\n",
    "\n",
    "from pyphocorehelpers.exception_helpers import CapturedException\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult, BatchSessionCompletionHandler\n",
    "\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_file_metadata\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file, save_copydict_to_text_file, read_copydict_from_text_file, invert_filedict\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import get_file_str_if_file_exists\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import check_output_h5_files, copy_files_in_filelist_to_dest\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import ConcreteSessionFolder, BackupMethods\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots, BatchPhoJonathanFiguresHelper\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "\n",
    "from neuropy.core.neuron_identities import NeuronIdentityDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import build_merged_neuron_firing_rate_indicies\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsHelpers\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget\n",
    "\n",
    "import inspect\n",
    "from jinja2 import Template\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import MAIN_get_template_string, write_test_script\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import curr_runtime_context_header_template, export_rank_order_results_completion_function, figures_rank_order_results_completion_function, compute_and_export_marginals_dfs_completion_function, determine_session_t_delta_completion_function, perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function, compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function, reload_exported_kdiba_session_position_info_mat_completion_function\n",
    "\n",
    "BATCH_DATE_TO_USE = '2024-04-28_GL' # used for filenames throught the notebook\n",
    "# BATCH_DATE_TO_USE = '2024-04-28_Lab' # used for filenames throught the notebook\n",
    "# BATCH_DATE_TO_USE = '2024-04-28_Apogee' # used for filenames throught the notebook\n",
    "\n",
    "# scripts_output_path = Path('/home/halechr/cloud/turbo/Data/Output/gen_scripts/').resolve() # Greatlakes\n",
    "# scripts_output_path = Path('output/gen_scripts/').resolve() # Apogee\n",
    "# # scripts_output_path = Path('/home/halechr/FastData/gen_scripts/').resolve() # Lab\n",
    "# assert scripts_output_path.exists()\n",
    "known_scripts_output_paths = [Path(v).resolve() for v in ['/home/halechr/cloud/turbo/Data/Output/gen_scripts/', '/home/halechr/FastData/gen_scripts/', 'output/gen_scripts/']]\n",
    "scripts_output_path = find_first_extant_path(known_scripts_output_paths)\n",
    "assert scripts_output_path.exists(), f\"scripts_output_path: {scripts_output_path} does not exist! Is the right computer's config commented out above?\"\n",
    "# fullwidth_path_widget(scripts_output_path, file_name_label='Scripts Output Path:')\n",
    "print(f'scripts_output_path: {scripts_output_path}')\n",
    "\n",
    "collected_outputs_path = scripts_output_path.joinpath('../collected_outputs').resolve()\n",
    "collected_outputs_path.mkdir(exist_ok=True)\n",
    "assert collected_outputs_path.exists()\n",
    "print(f'collected_outputs_path: {collected_outputs_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d958aaf",
   "metadata": {},
   "source": [
    "## Build Processing Scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb673d3",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the generated code for user-contributed functions:\n",
    "custom_user_completion_functions_dict = {\n",
    "                                    # \"export_rank_order_results_completion_function\": export_rank_order_results_completion_function, # ran 2024-04-28 12:57am\n",
    "                                    # \"figures_rank_order_results_completion_function\": figures_rank_order_results_completion_function,\n",
    "                                    # \"compute_and_export_marginals_dfs_completion_function\": compute_and_export_marginals_dfs_completion_function, # ran 2024-04-28 12:38am\n",
    "                                    # \"determine_session_t_delta_completion_function\": determine_session_t_delta_completion_function,\n",
    "                                    # 'perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function': perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function, # ran 2024-04-28 12:38am\n",
    "                                    # 'compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function': compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function, # ran 2024-04-28 12:38am\n",
    "                                    # 'reload_exported_kdiba_session_position_info_mat_completion_function': reload_exported_kdiba_session_position_info_mat_completion_function,\n",
    "                                    }\n",
    "\n",
    "custom_user_completion_function_template_code, custom_user_completion_functions_dict = MAIN_get_template_string(BATCH_DATE_TO_USE=BATCH_DATE_TO_USE, collected_outputs_path=collected_outputs_path, override_custom_user_completion_functions_dict=custom_user_completion_functions_dict)\n",
    "# print(custom_user_completion_function_template_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa767589",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_figures_script_paths: ['/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_one_2006-6-08_14-26-15/figures_kdiba_gor01_one_2006-6-08_14-26-15.py', '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_one_2006-6-09_1-22-43/figures_kdiba_gor01_one_2006-6-09_1-22-43.py', '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_one_2006-6-12_15-55-31/figures_kdiba_gor01_one_2006-6-12_15-55-31.py', '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_two_2006-6-07_16-40-19/figures_kdiba_gor01_two_2006-6-07_16-40-19.py', '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_two_2006-6-08_21-16-25/figures_kdiba_gor01_two_2006-6-08_21-16-25.py', '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_two_2006-6-09_22-24-40/figures_kdiba_gor01_two_2006-6-09_22-24-40.py', '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_two_2006-6-12_16-53-46/figures_kdiba_gor01_two_2006-6-12_16-53-46.py', '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_vvp01_one_2006-4-09_17-29-30/figures_kdiba_vvp01_one_2006-4-09_17-29-30.py', '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_vvp01_one_2006-4-10_12-25-50/figures_kdiba_vvp01_one_2006-4-10_12-25-50.py', '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_vvp01_two_2006-4-09_16-40-54/figures_kdiba_vvp01_two_2006-4-09_16-40-54.py', '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_vvp01_two_2006-4-10_12-58-3/figures_kdiba_vvp01_two_2006-4-10_12-58-3.py', '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_pin01_one_11-02_17-46-44/figures_kdiba_pin01_one_11-02_17-46-44.py', '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_pin01_one_11-02_19-28-0/figures_kdiba_pin01_one_11-02_19-28-0.py', '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_pin01_one_11-03_12-3-25/figures_kdiba_pin01_one_11-03_12-3-25.py', '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_pin01_one_fet11-01_12-58-54/figures_kdiba_pin01_one_fet11-01_12-58-54.py']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb387e330a74556be551ccc165b1181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Box(children=(Label(value='run_kdiba_gor01_one_2006-6-08_14-26-15.py', layout=Layout(width='aut…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.pythonScriptTemplating import BatchScriptsCollection, generate_batch_single_session_scripts, display_generated_scripts_ipywidget\n",
    "\n",
    "# Hardcoded included_session_contexts:\n",
    "included_session_contexts = [\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'), # Other file\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'), \n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'), # \n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'), # \n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'), \n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'), #\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'), #\n",
    "]\n",
    "\n",
    "## Setup Functions:\n",
    "extended_computations_include_includelist=['lap_direction_determination', 'pf_computation', \n",
    "                                           'pfdt_computation', 'firing_rate_trends',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "    'extended_stats',\n",
    "    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', # 'long_short_rate_remapping',\n",
    "    # 'ratemap_peaks_prominence2d',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    # 'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'merged_directional_placefields',\n",
    "    'rank_order_shuffle_analysis',\n",
    "    'directional_train_test_split',\n",
    "    'directional_decoders_decode_continuous',\n",
    "    'directional_decoders_evaluate_epochs',\n",
    "    'directional_decoders_epoch_heuristic_scoring',\n",
    "]\n",
    "force_recompute_override_computations_includelist = []\n",
    "# force_recompute_override_computations_includelist = ['split_to_directional_laps','merged_directional_placefields','directional_decoders_evaluate_epochs','directional_decoders_epoch_heuristic_scoring']\n",
    "# force_recompute_override_computations_includelist = ['directional_decoders_evaluate_epochs','directional_decoders_epoch_heuristic_scoring']\n",
    "# force_recompute_override_computations_includelist = ['split_to_directional_laps','merged_directional_placefields']\n",
    "# force_recompute_override_computations_includelist = ['long_short_decoding_analyses', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding',]\n",
    "\n",
    "active_global_batch_result_filename=f'global_batch_result_{BATCH_DATE_TO_USE}.pkl'\n",
    "\n",
    "debug_print = False\n",
    "known_global_data_root_parent_paths = [Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'/media/halechr/MAX/Data'), Path(r'W:/Data'), Path(r'/home/halechr/FastData'), Path(r'/Volumes/MoverNew/data')] # Path(r'/home/halechr/cloud/turbo/Data'), , Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'/home/halechr/turbo/Data'), \n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "good_session_concrete_folders = ConcreteSessionFolder.build_concrete_session_folders(global_data_root_parent_path, included_session_contexts)\n",
    "\n",
    "## Build Slurm Scripts:\n",
    "session_basedirs_dict: Dict[IdentifyingContext, Path] = {a_session_folder.context:a_session_folder.path for a_session_folder in good_session_concrete_folders}\n",
    "batch_scripts_collection: BatchScriptsCollection = generate_batch_single_session_scripts(global_data_root_parent_path, session_batch_basedirs=session_basedirs_dict, included_session_contexts=included_session_contexts,\n",
    "                                                                                                               output_directory=scripts_output_path, use_separate_run_directories=True,\n",
    "                                                                                                               should_freeze_pipeline_updates=True, \n",
    "                                                                                                               create_slurm_scripts=False, should_create_vscode_workspace=False,\n",
    "                                                                                                               extended_computations_include_includelist=extended_computations_include_includelist, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, # ['split_to_directional_laps', 'rank_order_shuffle_analysis'],\n",
    "                                                                                                                should_perform_figure_generation_to_file=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tbatch_session_completion_handler_kwargs=dict(enable_hdf5_output=False),\n",
    "                                                                                                                # custom_user_completion_functions=custom_user_completion_functions,\n",
    "                                                                                                                custom_user_completion_function_template_code=custom_user_completion_function_template_code,\n",
    "                                                                                                                # should_force_reload_all=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tshould_force_reload_all=False,\n",
    "                                                                                                                )\n",
    "\n",
    "\n",
    "\n",
    "# batch_scripts_collection.included_session_contexts, output_python_scripts, output_slurm_scripts\n",
    "\n",
    "output_python_scripts = batch_scripts_collection.output_python_scripts\n",
    "output_slurm_scripts = batch_scripts_collection.output_slurm_scripts\n",
    "vscode_workspace_path = batch_scripts_collection.vscode_workspace_path\n",
    "if vscode_workspace_path is not None:\n",
    "    display(fullwidth_path_widget(vscode_workspace_path, file_name_label='vscode_workspace_path:'))\n",
    "\n",
    "computation_script_paths = [x[0] for x in output_python_scripts]\n",
    "generate_figures_script_paths = [x[1] for x in output_python_scripts]\n",
    "print(f'generate_figures_script_paths: {generate_figures_script_paths}')\n",
    "_out_widget = display_generated_scripts_ipywidget(batch_scripts_collection.included_session_contexts, output_python_scripts)\n",
    "display(_out_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd6b61a8",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Maximum number of parallel script executions\n",
    "max_parallel_executions = 1\n",
    "# List of your script paths\n",
    "# script_paths = computation_script_paths\n",
    "script_paths = generate_figures_script_paths\n",
    "\n",
    "if (platform.system() == 'Windows'):\n",
    "    powershell_script_path = build_windows_powershell_run_script(script_paths, max_concurrent_jobs=max_parallel_executions)\n",
    "    # print(f'powershell_script_path: {powershell_script_path}')\n",
    "    display(fullwidth_path_widget(powershell_script_path, file_name_label='powershell_script_path:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.pythonScriptTemplating import get_running_python\n",
    "\n",
    "active_venv_path, python_executable, activate_script_path = get_running_python()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb44a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"c:/Users/pho/repos/Spike3DWorkEnv/Spike3D/.venv/Scripts/activate.bat\"\n",
    "\"cd l:/Scratch/gen_scripts/run_kdiba_vvp01_one_2006-4-10_12-25-50\"\n",
    "\"c:/Users/pho/repos/Spike3DWorkEnv/Spike3D/.venv/Scripts/python.exe l:/Scratch/gen_scripts/run_kdiba_vvp01_one_2006-4-10_12-25-50/run_kdiba_vvp01_one_2006-4-10_12-25-50.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f98344",
   "metadata": {},
   "source": [
    "## Execute the generated scripts in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d2fb7d6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a98db2e12d4a4d977c437093e6ca6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, bar_style='info', description='Running:', max=15)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed /nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_one_2006-6-08_14-26-15/figures_kdiba_gor01_one_2006-6-08_14-26-15.py\n",
      "Completed /nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_one_2006-6-09_1-22-43/figures_kdiba_gor01_one_2006-6-09_1-22-43.py\n",
      "Completed /nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_one_2006-6-12_15-55-31/figures_kdiba_gor01_one_2006-6-12_15-55-31.py\n",
      "Completed /nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_two_2006-6-07_16-40-19/figures_kdiba_gor01_two_2006-6-07_16-40-19.py\n",
      "Completed /nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_two_2006-6-08_21-16-25/figures_kdiba_gor01_two_2006-6-08_21-16-25.py\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "## recieves: max_parallel_executions, script_paths\n",
    "\"\"\"\n",
    "# Maximum number of parallel script executions\n",
    "max_parallel_executions = 5\n",
    "# List of your script paths\n",
    "script_paths = output_python_scripts\n",
    "\"\"\"\n",
    "\n",
    "# Function to execute a script\n",
    "def run_script(script_path):\n",
    "    python_executable = 'python'\n",
    "    # python_executable = '/home/halechr/Library/VSCode/green/.venv_green/bin/python'\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run([python_executable, script_path], capture_output=True, text=True)\n",
    "        return script_path, result.stdout, result.stderr\n",
    "    except Exception as e:\n",
    "        return script_path, None, str(e)\n",
    "\n",
    "# Create a progress bar\n",
    "progress_bar = widgets.IntProgress(value=0, min=0, max=len(script_paths), description='Running:', bar_style='info')\n",
    "display(progress_bar)\n",
    "\n",
    "# Run scripts in parallel with a limit on the number of parallel instances\n",
    "with ProcessPoolExecutor(max_workers=max_parallel_executions) as executor:\n",
    "    futures = {executor.submit(run_script, path): path for path in script_paths}\n",
    "    for future in as_completed(futures):\n",
    "        script, stdout, stderr = future.result()\n",
    "        progress_bar.value += 1  # Update the progress bar\n",
    "        if stderr:\n",
    "            print(f\"Error in {script}: {stderr}\")\n",
    "        else:\n",
    "            print(f\"Completed {script}\")\n",
    "\n",
    "# Progress bar will automatically update as scripts complete\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f583772",
   "metadata": {},
   "source": [
    "## Resume normal stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5938c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "active_global_batch_result_filename=f'global_batch_result_{BATCH_DATE_TO_USE}.pkl'\n",
    "\n",
    "debug_print = False\n",
    "known_global_data_root_parent_paths = [Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/media/halechr/MAX/Data'), Path(r'/Volumes/MoverNew/data')] # , Path(r'/home/halechr/FastData'), Path(r'/home/halechr/turbo/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data')\n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "## Build Pickle Path:\n",
    "global_batch_result_file_path = Path(global_data_root_parent_path).joinpath(active_global_batch_result_filename).resolve() # Use Default\n",
    "# Hardcoded included_session_contexts:\n",
    "included_session_contexts = UserAnnotationsManager.get_hardcoded_good_sessions()\n",
    "good_session_concrete_folders = ConcreteSessionFolder.build_concrete_session_folders(global_data_root_parent_path, included_session_contexts)\n",
    "\n",
    "# Output Paths:\n",
    "included_h5_paths = [get_file_str_if_file_exists(v.pipeline_results_h5) for v in good_session_concrete_folders]\n",
    "# copy_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, backup_mode=BackupMethods.RenameInSourceDirectory, only_include_file_types=['local_pkl', 'global_pkl'])\n",
    "check_output_h5_files(included_h5_paths)\n",
    "# from pyphoplacecellanalysis.General.Batch.pythonScriptTemplating import generate_batch_single_session_scripts\n",
    "\n",
    "# ## Build Slurm Scripts:\n",
    "# session_basedirs_dict: Dict[IdentifyingContext, Path] = {a_session_folder.context:a_session_folder.path for a_session_folder in good_session_concrete_folders}\n",
    "# included_session_contexts, output_python_scripts, output_slurm_scripts = generate_batch_single_session_scripts(global_data_root_parent_path, session_batch_basedirs=session_basedirs_dict, included_session_contexts=included_session_contexts, output_directory=Path('output/generated_slurm_scripts/').resolve(), use_separate_run_directories=True, should_perform_figure_generation_to_file=False)\n",
    "# display(output_python_scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15077fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.Filesystem.path_helpers import save_filelist_to_text_file\n",
    "\n",
    "## INPUTS: good_session_concrete_folders, target_dir, BATCH_DATE_TO_USE\n",
    "\n",
    "# target_dir: Path = Path(global_data_root_parent_path)\n",
    "target_dir: Path = collected_outputs_path\n",
    "\n",
    "included_h5_paths = [Path(get_file_str_if_file_exists(v.pipeline_results_h5)).resolve() for v in good_session_concrete_folders]\n",
    "check_output_h5_files(included_h5_paths)\n",
    "included_h5_paths\n",
    "\n",
    "def _across_session_h5_output_basename_fn(session_context: Optional[IdentifyingContext], session_descr: Optional[str], basename: str, *args, separator_char: str = \"_\"):\n",
    "    \"\"\" Captures `BATCH_DATE_TO_USE` \"\"\"\n",
    "    # a_session_folder.context\n",
    "    if session_context is not None:\n",
    "        session_descr = session_context.session_name # '2006-6-07_16-40-19'\n",
    "    _filename_list = [BATCH_DATE_TO_USE, session_descr, basename]\n",
    "    if len(args) > 0:\n",
    "        _filename_list.extend([str(a_part) for a_part in args if a_part is not None])\n",
    "    return separator_char.join(_filename_list)\n",
    "\n",
    "copy_h5_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, target_dir=collected_outputs_path, backup_mode=BackupMethods.CommonTargetDirectory, rename_backup_basename_fn=_across_session_h5_output_basename_fn, only_include_file_types=['h5']) # , rename_backup_suffix=BATCH_DATE_TO_USE\n",
    "copy_h5_dict\n",
    "\n",
    "\n",
    "## INPUTS: target_dir, BATCH_DATE_TO_USE\n",
    "h5_filelist_output_filename=f'{BATCH_DATE_TO_USE}_all_sessions_h5_filelist.txt'\n",
    "h5_filelist_output_file_path = Path(target_dir).joinpath(h5_filelist_output_filename).resolve() # Use Default\n",
    "print(f'h5_filelist_output_file_path: {h5_filelist_output_file_path}')\n",
    "_out_string, filelist_path = save_filelist_to_text_file(included_h5_paths, filelist_path=h5_filelist_output_file_path, debug_print=True) # r\"W:\\Data\\all_sessions_h5_filelist_2024-03-28_Apogee.txt\"\n",
    "filelist_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f6e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_h5_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c5651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.Filesystem.path_helpers import read_filelist_from_text_file\n",
    "    \n",
    "an_h5_filelist_path = Path(r'L:/Scratch/collected_outputs/2024-03-28_Apogee_all_sessions_h5_filelist.txt').resolve()\n",
    "read_hdf5_output_paths = read_filelist_from_text_file(filelist_path=an_h5_filelist_path, debug_print=False)\n",
    "read_hdf5_output_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f140f",
   "metadata": {},
   "source": [
    "# Output File Processing Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135cb2d8-65b3-405b-a41b-22b2fa7cb28e",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## INPUT a_copy_dict\n",
    "a_copy_dict = copy_h5_dict\n",
    "\n",
    "moved_files_dict_h5_files = copy_movedict(a_copy_dict)\n",
    "moved_files_dict_h5_files\n",
    "# INPUTS: active_filelist_prefix, target_dir\n",
    "# active_filelist_prefix: str = 'backed_up_files'\n",
    "active_filelist_prefix: str = 'session_h5_files'\n",
    "\n",
    "# target_dir: Path = Path(global_data_root_parent_path)\n",
    "target_dir: Path = collected_outputs_path\n",
    "\n",
    "moved_files_copydict_output_filename=f'{active_filelist_prefix}_copydict_{BATCH_DATE_TO_USE}.csv'\n",
    "moved_files_copydict_file_path = target_dir.joinpath(moved_files_copydict_output_filename).resolve() # Use Default\n",
    "print(f'moved_files_copydict_file_path: \"{moved_files_copydict_file_path}\"')\n",
    "\n",
    "_out_string, filedict_out_path = save_copydict_to_text_file(moved_files_dict_h5_files, moved_files_copydict_file_path, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab869730",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: moved_files_copydict_file_path\n",
    "moved_files_copydict_file_path = Path(r\"W:\\Data\\session_h5_files_copydict_2024-03-28_Apogee.csv\").resolve()\n",
    "assert moved_files_copydict_file_path.exists()\n",
    "\n",
    "read_moved_files_dict_files = read_copydict_from_text_file(moved_files_copydict_file_path, debug_print=False)\n",
    "read_moved_files_dict_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4671e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_moved_files_dict_files\n",
    "restore_moved_files_dict_files = invert_filedict(read_moved_files_dict_files)\n",
    "restore_moved_files_dict_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb0953",
   "metadata": {},
   "source": [
    "## Extract `across_sessions_instantaneous_fr_dict` from the computation outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c123baf6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    "\n",
    "# neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_all_known_tables(included_session_contexts, included_h5_paths, should_restore_native_column_types=True, )\n",
    "\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_and_save_all_combined_tables(included_session_contexts, included_h5_paths, override_output_parent_path=global_data_root_parent_path, output_path_suffix=f'{BATCH_DATE_TO_USE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8615ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "session_identifier_key: str = 'session_name'\n",
    "# session_identifier_key: str = 'session_datetime'\n",
    "\n",
    "## !IMPORTANT! Count of the fields of interest using .value_counts(...) and converting to an explicit pd.DataFrame:\n",
    "# _out_value_counts_df: pd.DataFrame = neuron_replay_stats_table.value_counts(subset=['format_name', 'animal', 'session_name', 'session_datetime','track_membership'], normalize=False, sort=False, ascending=True, dropna=True).reset_index()\n",
    "# _out_value_counts_df.columns = ['format_name', 'animal', 'session_name', 'session_datetime', 'track_membership', 'count']\n",
    "_out_value_counts_df: pd.DataFrame = neuron_replay_stats_table.value_counts(subset=['format_name', 'animal', 'session_name', 'session_datetime','track_membership','is_refined_LxC', 'is_refined_SxC'], normalize=False, sort=False, ascending=True, dropna=True).reset_index()\n",
    "_out_value_counts_df.columns = ['format_name', 'animal', 'session_name', 'session_datetime', 'track_membership', 'is_refined_LxC', 'is_refined_SxC', 'count']\n",
    "_out_value_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af57298",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the time of the first session for each animal:\n",
    "first_session_time  = _out_value_counts_df.groupby(['animal']).agg(session_datetime_first=('session_datetime', 'first')).reset_index()\n",
    "\n",
    "## Subtract this initial time from all of the 'session_datetime' entries for each animal:\n",
    "# Merge the first session time back into the original DataFrame\n",
    "merged_df = pd.merge(_out_value_counts_df, first_session_time, on='animal')\n",
    "\n",
    "# Subtract this initial time from all of the 'session_datetime' entries for each animal\n",
    "merged_df['time_since_first_session'] = merged_df['session_datetime'] - merged_df['session_datetime_first']\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25bb1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "point_size = 8\n",
    "df = _out_value_counts_df.copy()\n",
    "animals = df['animal'].unique()\n",
    "track_memberships = df['track_membership'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(animals), figsize=(15, 5))\n",
    "\n",
    "for i, animal in enumerate(animals):\n",
    "\tax = axes[i]\n",
    "\tsubset_df = df[df['animal'] == animal]\n",
    "\t\n",
    "\tfor track_membership in track_memberships:\n",
    "\t\ttrack_subset_df = subset_df[subset_df['track_membership'] == track_membership]\n",
    "\t\tax.plot(track_subset_df['session_datetime'], track_subset_df['count'], label=f'Track: {track_membership}')\n",
    "\t\tax.scatter(track_subset_df['session_datetime'], track_subset_df['count'], s=point_size)\n",
    "\t\t\n",
    "\tax.set_title(f'Animal: {animal}')\n",
    "\tax.set_xlabel('Session Datetime')\n",
    "\tax.set_ylabel('Count')\n",
    "\tax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94408ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_value_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784fcc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## See if the number of cells decreases over re-exposures to the track\n",
    "df = _out_value_counts_df[_out_value_counts_df['animal'] == 'gor01']\n",
    "# df = _out_value_counts_df[_out_value_counts_df['animal'] == 'pin01']\n",
    "# df = _out_value_counts_df[_out_value_counts_df['animal'] == 'vvp01']\n",
    "\n",
    "# Sort by column: 'session_datetime' (ascending)\n",
    "df = df.sort_values(['session_datetime'])\n",
    "\n",
    "'LEFT_ONLY'\n",
    "\n",
    "# df.to_clipboard(index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a502f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the number of cells in each session of the animal:\n",
    "num_LxCs = df[df['track_membership'] == 'LEFT_ONLY']['count'].to_numpy()\n",
    "num_Shared = df[df['track_membership'] == 'SHARED']['count'].to_numpy()\n",
    "num_SxCs = df[df['track_membership'] == 'RIGHT_ONLY']['count'].to_numpy()\n",
    "\n",
    "num_TotalCs = num_LxCs + num_Shared + num_SxCs\n",
    "num_TotalCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The only safe point to align each session to is the switchpoint (the delta):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046bbce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each session can be expressed in terms of time from the start of the first session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f99ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "\n",
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=num_sessions, save_figure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc1ac7-5771-4cd5-94c6-7a6244eb8217",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "source": [
    "## Extract output files from all completed sessions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056d9a7",
   "metadata": {},
   "source": [
    "# 2023-10-06 - `joined_neruon_fri_df` loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_DATE_TO_USE = '2023-10-05_NewParameters'\n",
    "BATCH_DATE_TO_USE = '2023-10-07'\n",
    "all_sessions_joined_neruon_fri_df, out_path = build_and_merge_all_sessions_joined_neruon_fri_df(global_data_root_parent_path, BATCH_DATE_TO_USE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb893bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joined_neruon_fri_df_basename = f'{BATCH_DATE_TO_USE}_{output_file_prefix}_joined_neruon_fri_df'\n",
    "AcrossSessionTables.write_table_to_files(joined_neruon_fri_df, global_data_root_parent_path=global_data_root_parent_path, output_basename=joined_neruon_fri_df_basename, include_csv=False)\n",
    "print(f'>>\\t done with {output_file_prefix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be651cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2023-10-04 - Load Saved across-sessions-data, process, and produce figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "graphics_output_dict = AcrossSessionsResults.post_compute_all_sessions_processing(global_data_root_parent_path=global_data_root_parent_path, BATCH_DATE_TO_USE=BATCH_DATE_TO_USE, plotting_enabled=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9987dc",
   "metadata": {},
   "source": [
    " #TODO 2023-10-05 11:40: - [ ] Extract the \"contrarian cells\", the ones that have a strong exclusivity on the laps but the opposite tendency on the replays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d829b90",
   "metadata": {},
   "source": [
    "## 2023-11-15 - For manual testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Load the saved across-session results:\n",
    "# Outputs: across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list, neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table\n",
    "\n",
    "inst_fr_output_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    "\n",
    "## Load all across-session tables from the pickles:\n",
    "output_path_suffix: str = f'{BATCH_DATE_TO_USE}'\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.load_all_combined_tables(override_output_parent_path=global_data_root_parent_path, output_path_suffix=output_path_suffix) # output_path_suffix=f'2023-10-04-GL-Recomp'\n",
    "num_sessions = len(neuron_replay_stats_table.session_uid.unique().to_numpy())\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "# neuron_replay_stats_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7abca14",
   "metadata": {},
   "source": [
    "# 2024-01-18 - Extracts the callback results 'determine_computation_datetimes_completion_function':\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e0aa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_callback_fn_results = {a_sess_ctxt:a_result.across_session_results.get('determine_session_t_delta_completion_function', {}) for a_sess_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None}\n",
    "extracted_callback_fn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abede5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1166ebaa6782096f56d317eaa8536ead07f1521e1978b8150f0942b7b78fbd85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
