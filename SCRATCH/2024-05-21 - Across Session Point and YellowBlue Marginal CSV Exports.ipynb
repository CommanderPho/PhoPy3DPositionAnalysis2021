{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook allows collecting results across multiple pipeline runs. Concatenating across sessions and bin sizes. \n",
    "It takes CSVs, then determines the most recent one from the filename. \n",
    "\n",
    "There are two major sets of decoded epochs - Laps and Ripples/Replays\n",
    "There are two sets of marginals for the decoded epochs - the \"by epoch\" and \"by time bin\" marginals.\n",
    "The \"by time bin\" epochs are a larger granulation, with each epoch consisting of one or more time bin.\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "# 2024-01-23 - \n",
    "# C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-23_GL-fet11-01_12-58-54_time_bin_size_sweep_results.h5\n",
    "# C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-23_GL-11-03_12-3-25_time_bin_size_sweep_results.h5\n",
    "# C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-23_GL-11-02_17-46-44_time_bin_size_sweep_results.h5\n",
    "# C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-23_GL-11-02_19-28-0_time_bin_size_sweep_results.h5\n",
    "# C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-23_GL-2006-4-10_12-58-3_time_bin_size_sweep_results.h5\n",
    "# C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-23_GL-2006-4-10_12-25-50_time_bin_size_sweep_results.h5\n",
    "# C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-23_GL-2006-4-09_16-40-54_time_bin_size_sweep_results.h5\n",
    "# C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-23_GL-2006-6-09_22-24-40_time_bin_size_sweep_results.h5\n",
    "# C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-23_GL-2006-6-12_16-53-46_time_bin_size_sweep_results.h5\n",
    "# C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-23_GL-2006-4-09_17-29-30_time_bin_size_sweep_results.h5\n",
    "# C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-23_GL-2006-6-08_14-26-15_time_bin_size_sweep_results.h5\n",
    "# C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-23_GL-2006-6-09_1-22-43_time_bin_size_sweep_results.h5\n",
    "# C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-23_GL-2006-6-07_16-40-19_time_bin_size_sweep_results.h5\n",
    "# C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-23_GL-2006-6-08_21-16-25_time_bin_size_sweep_results.h5\n",
    "# C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-23_GL-2006-6-12_15-55-31_time_bin_size_sweep_results.h5\n",
    "\n",
    "\n",
    "\n",
    "# found_session_export_paths = [Path(v).resolve() for v in  [\"C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-12_0420PM-kdiba_pin01_one_fet11-01_12-58-54-(laps_marginals_df).csv\",\n",
    "# \"C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-12_0420PM-kdiba_pin01_one_fet11-01_12-58-54-(ripple_marginals_df).csv\",\n",
    "# \"C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-12_0645PM-kdiba_pin01_one_fet11-01_12-58-54-(laps_marginals_df).csv\",\n",
    "# \"C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-12_0645PM-kdiba_pin01_one_fet11-01_12-58-54-(ripple_marginals_df).csv\",\n",
    "# \"C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-12_0828PM-kdiba_pin01_one_fet11-01_12-58-54-(laps_marginals_df).csv\",\n",
    "# \"C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-12_0828PM-kdiba_pin01_one_fet11-01_12-58-54-(ripple_marginals_df).csv\",\n",
    "# ]]\n",
    "\n",
    "[\n",
    "    \"2024-02-19_0430PM-kdiba_vvp01_one_2006-4-10_12-25-50-(ripple_simple_pf_pearson_merged_df)_tbin-0.025.csv\",\n",
    "    \"2024-02-17_0210AM-kdiba_vvp01_one_2006-4-09_17-29-30-(laps_simple_pf_pearson_merged_df)_tbin-0.025.csv\",\n",
    "    \"2024-02-19_0430PM-kdiba_vvp01_one_2006-4-10_12-25-50-(laps_weighted_corr_merged_df)_tbin-0.025.csv\",\n",
    "    \"2024-02-19_0430PM-kdiba_vvp01_one_2006-4-10_12-25-50-(ripple_weighted_corr_merged_df)_tbin-0.025.csv\",\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from neuropy.utils.indexing_helpers import PandasHelpers\n",
    "from pyphocorehelpers.indexing_helpers import partition_df\n",
    "# Set the maximum number of columns to display\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "# %matplotlib inline\n",
    "# %matplotlib auto\n",
    "\n",
    "# Switch to the desired interactivity mode\n",
    "plt.interactive(True)\n",
    "\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "pio.templates.default = template\n",
    "from pyphocorehelpers.plotting.media_output_helpers import fig_to_clipboard\n",
    "from pyphocorehelpers.Filesystem.path_helpers import file_uri_from_path, sanitize_filename_for_Windows\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget, simple_path_display_widget\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_helper_save_figures, _helper_build_figure, plotly_pre_post_delta_scatter, plot_across_sessions_scatter_results\n",
    "\n",
    "# from ..PendingNotebookCode import plot_across_sessions_scatter_results, plot_histograms, plot_stacked_histograms\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import find_csv_files, find_HDF5_files, find_most_recent_files, process_csv_file, plot_across_sessions_scatter_results, plot_histograms, plot_stacked_histograms\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import load_across_sessions_exported_files, _process_and_load_exported_file, _common_cleanup_operations, convert_to_dataframe\n",
    "\n",
    "debug_print: bool = False\n",
    "\n",
    "# TODAY_DAY_DATE: str = f\"2024-04-09_GL\"\n",
    "TODAY_DAY_DATE: str = f\"2024-05-21_GL\"\n",
    "\n",
    "print(f'TODAY_DAY_DATE: {TODAY_DAY_DATE}')\n",
    "\n",
    "types.session_str: TypeAlias = str # a unique session identifier\n",
    "\n",
    "known_bad_sessions = [IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44')]\n",
    "known_bad_session_strs = [str(v.get_description()) for v in known_bad_sessions]\n",
    "known_bad_session_strs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions\n",
    "\"_new\" (as in `all_sessions_new_ripple_df`) adds simple_pearson and a few other measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "## Load across session t_delta CSV, which contains the t_delta for each session:\n",
    "\n",
    "## INPUTS: known_bad_session_strs,\n",
    "\n",
    "\n",
    "cuttoff_date = datetime(2024, 4, 15)\n",
    "# cuttoff_date = None\n",
    "\n",
    "# t_delta_csv_path = Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\output\\collected_outputs\\2024-01-18_GL_t_split_df.csv').resolve() # Apogee\n",
    "# t_delta_csv_path = Path('/home/halechr/cloud/turbo/Data/Output/collected_outputs/2024-01-18_GL_t_split_df.csv').resolve() # GL\n",
    "\n",
    "# collected_outputs_directory = '/home/halechr/FastData/collected_outputs/'\n",
    "# collected_outputs_directory = r'C:\\Users\\pho\\Desktop\\collected_outputs'\n",
    "# collected_outputs_directory = r'C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs' # APOGEE\n",
    "# collected_outputs_directory = '/home/halechr/cloud/turbo/Data/Output/collected_outputs' # GL\n",
    "\n",
    "known_collected_outputs_paths = [Path(v).resolve() for v in ['/Volumes/SwapSSD/Data/collected_outputs', r\"K:/scratch/collected_outputs\", '/Users/pho/Dropbox (University of Michigan)/MED-DibaLabDropbox/Data/Pho/Outputs/output/collected_outputs', r'C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs',\n",
    "                                                              '/home/halechr/FastData/collected_outputs/', '/home/halechr/cloud/turbo/Data/Output/collected_outputs']]\n",
    "collected_outputs_directory = find_first_extant_path(known_collected_outputs_paths)\n",
    "assert collected_outputs_directory.exists(), f\"collected_outputs_directory: {collected_outputs_directory} does not exist! Is the right computer's config commented out above?\"\n",
    "# fullwidth_path_widget(scripts_output_path, file_name_label='Scripts Output Path:')\n",
    "print(f'collected_outputs_directory: {collected_outputs_directory}')\n",
    "\n",
    "# Create a 'figures' subfolder if it doesn't exist\n",
    "figures_folder: Path = collected_outputs_directory.joinpath('figures').resolve()\n",
    "figures_folder.mkdir(parents=False, exist_ok=True)\n",
    "assert figures_folder.exists()\n",
    "print(f'\\tfigures_folder: {file_uri_from_path(figures_folder)}')\n",
    "\n",
    "# Create an output path for the across session collected results (like the aggregate CSVs built from the individual session CSVs)\n",
    "across_sessions_output_folder: Path = collected_outputs_directory.joinpath('../across_sessions').resolve()\n",
    "across_sessions_output_folder.mkdir(parents=False, exist_ok=True)\n",
    "assert across_sessions_output_folder.exists()\n",
    "print(f'\\tacross_sessions_output_folder: {file_uri_from_path(across_sessions_output_folder)}')\n",
    "\n",
    "# t_delta_csv_path = collected_outputs_directory.joinpath('2024-01-18_GL_t_split_df.csv').resolve() # GL\n",
    "t_delta_csv_path = collected_outputs_directory.joinpath('../2024-01-18_GL_t_split_df.csv').resolve()\n",
    "assert t_delta_csv_path.exists(), f\"t_split_df CSV at '{t_delta_csv_path}' does not exist!\"\n",
    "\n",
    "## Find the files:\n",
    "csv_files = find_csv_files(collected_outputs_directory)\n",
    "h5_files = find_HDF5_files(collected_outputs_directory)\n",
    "\n",
    "csv_sessions = find_most_recent_files(found_session_export_paths=csv_files, cuttoff_date=cuttoff_date)\n",
    "h5_sessions = find_most_recent_files(found_session_export_paths=h5_files)\n",
    "\n",
    "## The CSV containing the session delta time:\n",
    "t_delta_df = pd.read_csv(t_delta_csv_path, index_col=0) # Assuming that your CSV file has an index column\n",
    "# adds `delta_aligned_t_start`, `delta_aligned_t_end` columns\n",
    "t_delta_df['delta_aligned_t_start'] = t_delta_df['t_start'] - t_delta_df['t_delta']\n",
    "t_delta_df['delta_aligned_t_end'] = t_delta_df['t_end'] - t_delta_df['t_delta']\n",
    "\n",
    "# computes `earliest_delta_aligned_t_start`, latest_delta_aligned_t_end\n",
    "earliest_delta_aligned_t_start: float = np.nanmin(t_delta_df['delta_aligned_t_start'])\n",
    "latest_delta_aligned_t_end: float = np.nanmax(t_delta_df['delta_aligned_t_end'])\n",
    "print(f'earliest_delta_aligned_t_start: {earliest_delta_aligned_t_start}, latest_delta_aligned_t_end: {latest_delta_aligned_t_end}')\n",
    "t_delta_dict = t_delta_df.to_dict(orient='index')\n",
    "# t_delta_df\n",
    "\n",
    "# #TODO 2024-03-02 12:12: - [ ] Could add weighted correlation if there is a dataframe for that and it's computed:\n",
    "_df_raw_variable_names = ['simple_pf_pearson_merged_df', 'weighted_corr_merged_df']\n",
    "_df_variables_names = ['laps_weighted_corr_merged_df', 'ripple_weighted_corr_merged_df', 'laps_simple_pf_pearson_merged_df', 'ripple_simple_pf_pearson_merged_df']\n",
    "\n",
    "# # tbin_values_dict = {'laps': self.laps_decoding_time_bin_size, 'ripple': self.ripple_decoding_time_bin_size}\n",
    "time_col_name_dict = {'laps': 'lap_start_t', 'ripple': 'ripple_start_t'} ## default should be 't_bin_center'\n",
    "\n",
    "# fold older files:\n",
    "# {'laps_marginals_df': 'lap_start_t', 'ripple_marginals_df': 'ripple_start_t', 'laps_time_bin_marginals_df':'t_bin_center', 'ripple_time_bin_marginals_df':'t_bin_center'}\n",
    "    \n",
    "\n",
    "# csv_sessions\n",
    "# Extract each of the separate files from the sessions:\n",
    "\n",
    "# final_sessions: Dict[types.session_str, Dict[str, Path]] = {}\n",
    "\n",
    "final_sessions_loaded_laps_dict = {}\n",
    "final_sessions_loaded_ripple_dict = {}\n",
    "final_sessions_loaded_laps_time_bin_dict = {}\n",
    "final_sessions_loaded_ripple_time_bin_dict = {}\n",
    "\n",
    "final_sessions_loaded_simple_pearson_laps_dict = {}\n",
    "final_sessions_loaded_simple_pearson_ripple_dict = {}\n",
    "\n",
    "# stupid reudndant but compatible method\n",
    "final_sessions_loaded_laps_wcorr_dict = {}\n",
    "final_sessions_loaded_ripple_wcorr_dict = {}\n",
    "\n",
    "final_sessions_loaded_laps_all_scores_dict = {}\n",
    "final_sessions_loaded_ripple_all_scores_dict = {}\n",
    "\n",
    "if cuttoff_date is not None:\n",
    "    final_sessions: Dict[types.session_str, Dict[str, Path]] = {session_str:{file_type:a_path for file_type, (a_path, an_decoding_time_bin_size_str, an_export_datetime) in session_dict.items() if ((an_export_datetime >= cuttoff_date) and (session_str not in known_bad_session_strs))}\n",
    "                                                                                              for session_str, session_dict in csv_sessions.items() }\n",
    "else:\n",
    "    # no cutoff recency date:\n",
    "    final_sessions: Dict[types.session_str, Dict[str, Path]] = {session_str:{file_type:a_path for file_type, (a_path, an_decoding_time_bin_size_str, an_export_datetime) in session_dict.items() if (session_str not in known_bad_session_strs)}\n",
    "                                                                                            for session_str, session_dict in csv_sessions.items()}\n",
    "\n",
    "\n",
    "for session_str, session_dict in final_sessions.items():\n",
    "    session_name = str(session_str)  # Extract session name from the filename\n",
    "    if debug_print:\n",
    "        print(f'processing session_name: {session_name}')\n",
    "    curr_session_t_delta = t_delta_dict.get(session_name, {}).get('t_delta', None)\n",
    "    if curr_session_t_delta is None:\n",
    "        print(f'WARN: curr_session_t_delta is None for session_str = \"{session_str}\"')\n",
    "\n",
    "    # Process each file type with its corresponding details\n",
    "    _process_and_load_exported_file(session_dict, 'laps_marginals_df', final_sessions_loaded_laps_dict, session_str, curr_session_t_delta, 'lap_start_t')\n",
    "    _process_and_load_exported_file(session_dict, 'ripple_marginals_df', final_sessions_loaded_ripple_dict, session_str, curr_session_t_delta, 'ripple_start_t')\n",
    "    _process_and_load_exported_file(session_dict, 'laps_time_bin_marginals_df', final_sessions_loaded_laps_time_bin_dict, session_str, curr_session_t_delta, 't_bin_center')\n",
    "    _process_and_load_exported_file(session_dict, 'ripple_time_bin_marginals_df', final_sessions_loaded_ripple_time_bin_dict, session_str, curr_session_t_delta, 't_bin_center')\n",
    "    _process_and_load_exported_file(session_dict, 'laps_simple_pf_pearson_merged_df', final_sessions_loaded_simple_pearson_laps_dict, session_str, curr_session_t_delta, 'lap_start_t')\n",
    "    _process_and_load_exported_file(session_dict, 'ripple_simple_pf_pearson_merged_df', final_sessions_loaded_simple_pearson_ripple_dict, session_str, curr_session_t_delta, 'ripple_start_t')\n",
    "    _process_and_load_exported_file(session_dict, 'laps_weighted_corr_merged_df', final_sessions_loaded_laps_wcorr_dict, session_str, curr_session_t_delta, 'lap_start_t')\n",
    "    _process_and_load_exported_file(session_dict, 'ripple_weighted_corr_merged_df', final_sessions_loaded_ripple_wcorr_dict, session_str, curr_session_t_delta, 'ripple_start_t')\n",
    "    \n",
    "    # _process_and_load_exported_file(session_dict, 'laps_all_scores_merged_df', final_sessions_loaded_laps_all_scores_dict, session_str, curr_session_t_delta, 'lap_start_t')\n",
    "    _process_and_load_exported_file(session_dict, 'ripple_all_scores_merged_df', final_sessions_loaded_ripple_all_scores_dict, session_str, curr_session_t_delta, 'ripple_start_t')\n",
    "\n",
    "\n",
    "\n",
    "## Build across_sessions join dataframes:\n",
    "all_sessions_laps_df: pd.DataFrame = PandasHelpers.safe_concat(list(final_sessions_loaded_laps_dict.values()), axis='index', ignore_index=True)\n",
    "all_sessions_ripple_df: pd.DataFrame = PandasHelpers.safe_concat(list(final_sessions_loaded_ripple_dict.values()), axis='index', ignore_index=True)\n",
    "# Add 'epoch_idx' column for compatibility:\n",
    "if all_sessions_laps_df is not None:\n",
    "    all_sessions_laps_df['epoch_idx'] = all_sessions_laps_df['lap_idx']\n",
    "if all_sessions_ripple_df is not None:\n",
    "    all_sessions_ripple_df['epoch_idx'] = all_sessions_ripple_df['ripple_idx']\n",
    "\n",
    "# *_time_bin marginals:\n",
    "all_sessions_laps_time_bin_df: pd.DataFrame = PandasHelpers.safe_concat(list(final_sessions_loaded_laps_time_bin_dict.values()), axis='index', ignore_index=True)\n",
    "all_sessions_ripple_time_bin_df: pd.DataFrame = PandasHelpers.safe_concat(list(final_sessions_loaded_ripple_time_bin_dict.values()), axis='index', ignore_index=True)\n",
    "\n",
    "# NEW ________________________________________________________________________________________________________________ #\n",
    "all_sessions_simple_pearson_laps_df: pd.DataFrame = PandasHelpers.safe_concat(list(final_sessions_loaded_simple_pearson_laps_dict.values()), axis='index', ignore_index=True)\n",
    "all_sessions_simple_pearson_ripple_df: pd.DataFrame = PandasHelpers.safe_concat(list(final_sessions_loaded_simple_pearson_ripple_dict.values()), axis='index', ignore_index=True)\n",
    "\n",
    "if len(final_sessions_loaded_laps_wcorr_dict) > 0:\n",
    "    all_sessions_wcorr_laps_df: pd.DataFrame = PandasHelpers.safe_concat(list(final_sessions_loaded_laps_wcorr_dict.values()), axis='index', ignore_index=True)\n",
    "else:\n",
    "    all_sessions_wcorr_laps_df = None # empty df would be better\n",
    "\n",
    "all_sessions_wcorr_ripple_df: pd.DataFrame = PandasHelpers.safe_concat(list(final_sessions_loaded_ripple_wcorr_dict.values()), axis='index', ignore_index=True)\n",
    "\n",
    "# `*_all_scores_*`: __________________________________________________________________________________________________ #\n",
    "# all_sessions_all_score_laps_df: pd.DataFrame = PandasHelpers.safe_concat(list(final_sessions_loaded_laps_all_scores_dict.values()), axis='index', ignore_index=True)\n",
    "all_sessions_all_scores_ripple_df: pd.DataFrame = PandasHelpers.safe_concat(list(final_sessions_loaded_ripple_all_scores_dict.values()), axis='index', ignore_index=True)\n",
    "\n",
    "\n",
    "dfs_list = (all_sessions_laps_df, all_sessions_ripple_df, all_sessions_laps_time_bin_df, all_sessions_ripple_time_bin_df)\n",
    "for a_df in dfs_list:\n",
    "    if a_df is not None:\n",
    "        if 'time_bin_size' not in a_df:\n",
    "            print('Uh-oh! time_bin_size is missing! This must be old exports!')\n",
    "            print(f'\\tTry to determine the time_bin_size from the filenames: {csv_sessions}')\n",
    "            ## manual correction UwU\n",
    "            time_bin_size: float = 0.025\n",
    "            print(f'WARNING! MANUAL OVERRIDE TIME BIN SIZE SET: time_bin_size = {time_bin_size}. Assigning to dataframes....')\n",
    "            a_df['time_bin_size'] = time_bin_size\n",
    "        else:\n",
    "            # Filter rows based on column: 'time_bin_size'\n",
    "            a_df = a_df[a_df['time_bin_size'].notna()]\n",
    "\n",
    "\n",
    "# if 'time_bin_size' not in all_sessions_laps_df:\n",
    "#     print('Uh-oh! time_bin_size is missing! This must be old exports!')\n",
    "#     print(f'\\tTry to determine the time_bin_size from the filenames: {csv_sessions}')\n",
    "#     ## manual correction UwU\n",
    "#     time_bin_size: float = 0.025\n",
    "#     print(f'WARNING! MANUAL OVERRIDE TIME BIN SIZE SET: time_bin_size = {time_bin_size}. Assigning to dataframes....')\n",
    "#     all_sessions_laps_df['time_bin_size'] = time_bin_size\n",
    "#     all_sessions_ripple_df['time_bin_size'] = time_bin_size\n",
    "#     all_sessions_laps_time_bin_df['time_bin_size'] = time_bin_size\n",
    "#     all_sessions_ripple_time_bin_df['time_bin_size'] = time_bin_size\n",
    "#     print(f'\\tdone.')\n",
    "# else:\n",
    "#     # Filter rows based on column: 'time_bin_size'\n",
    "#     all_sessions_laps_df = all_sessions_laps_df[all_sessions_laps_df['time_bin_size'].notna()]\n",
    "#     all_sessions_ripple_df = all_sessions_ripple_df[all_sessions_ripple_df['time_bin_size'].notna()]\n",
    "#     all_sessions_laps_time_bin_df = all_sessions_laps_time_bin_df[all_sessions_laps_time_bin_df['time_bin_size'].notna()]\n",
    "#     all_sessions_ripple_time_bin_df = all_sessions_ripple_time_bin_df[all_sessions_ripple_time_bin_df['time_bin_size'].notna()]\n",
    "\n",
    "all_sessions_laps_df, all_sessions_ripple_df, all_sessions_laps_time_bin_df, all_sessions_ripple_time_bin_df = [_common_cleanup_operations(a_df) for a_df in (all_sessions_laps_df, all_sessions_ripple_df, all_sessions_laps_time_bin_df, all_sessions_ripple_time_bin_df)]\n",
    "all_sessions_simple_pearson_laps_df, all_sessions_simple_pearson_ripple_df, all_sessions_wcorr_laps_df, all_sessions_wcorr_ripple_df = [_common_cleanup_operations(a_df) for a_df in (all_sessions_simple_pearson_laps_df, all_sessions_simple_pearson_ripple_df, all_sessions_wcorr_laps_df, all_sessions_wcorr_ripple_df)]\n",
    "\n",
    "# all_sessions_all_score_laps_df, all_sessions_all_scores_ripple_df = [_common_cleanup_operations(a_df) for a_df in (all_sessions_all_score_laps_df, all_sessions_all_scores_ripple_df)]\n",
    "# all_sessions_all_score_laps_df = _common_cleanup_operations(all_sessions_all_score_laps_df)\n",
    "all_sessions_all_scores_ripple_df = _common_cleanup_operations(all_sessions_all_scores_ripple_df)\n",
    "\n",
    "all_sessions_simple_pearson_laps_df: pd.DataFrame = DecoderDecodedEpochsResult.merge_decoded_epochs_result_dfs(all_sessions_simple_pearson_laps_df, all_sessions_wcorr_laps_df, should_drop_directional_columns=False, start_t_idx_name='delta_aligned_start_t')\n",
    "all_sessions_simple_pearson_ripple_df: pd.DataFrame = DecoderDecodedEpochsResult.merge_decoded_epochs_result_dfs(all_sessions_simple_pearson_ripple_df, all_sessions_wcorr_ripple_df, should_drop_directional_columns=False, start_t_idx_name='ripple_start_t')\n",
    "\n",
    "# all_sessions_laps_time_bin_df # 601845 rows × 9 column\n",
    "\n",
    "parsed_csv_files_df: pd.DataFrame = convert_to_dataframe(csv_sessions)\n",
    "parsed_csv_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(np.unique(parsed_csv_files_df.file_type))) # ['laps_marginals_df', 'laps_simple_pf_pearson_merged_df', 'laps_time_bin_marginals_df', 'laps_weighted_corr_merged_df', 'merged_complete_epoch_stats_df', 'ripple_all_scores_merged_df', 'ripple_marginals_df', 'ripple_simple_pf_pearson_merged_df', 'ripple_time_bin_marginals_df', 'ripple_weighted_corr_merged_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "display(parsed_csv_files_df)\n",
    "\n",
    "across_sessions_parsed_csv_files_path = across_sessions_output_folder.joinpath(f'{TODAY_DAY_DATE}_parsed_csv_files_df.csv').resolve()\n",
    "# parsed_csv_files_df.to_clipboard(excel=True)\n",
    "parsed_csv_files_df.to_csv(across_sessions_parsed_csv_files_path)\n",
    "display(fullwidth_path_widget(across_sessions_parsed_csv_files_path, file_name_label='across_sessions_parsed_csv_files_path:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import export_across_session_CSVs\n",
    "\n",
    "final_across_session_summary_CSVs_output_path = across_sessions_output_folder.resolve()\n",
    "display(fullwidth_path_widget(final_across_session_summary_CSVs_output_path, file_name_label='final_across_session_summary_CSVs_output_path:'))\n",
    "final_csv_export_paths = export_across_session_CSVs(final_output_path=final_across_session_summary_CSVs_output_path, TODAY_DAY_DATE=TODAY_DAY_DATE,\n",
    "                                                    all_sessions_laps_df=all_sessions_laps_df,  all_sessions_ripple_df=all_sessions_ripple_df,  all_sessions_laps_time_bin_df=all_sessions_laps_time_bin_df,  all_sessions_ripple_time_bin_df=all_sessions_ripple_time_bin_df, \n",
    "                                                    all_sessions_simple_pearson_laps_df=all_sessions_simple_pearson_laps_df,  all_sessions_simple_pearson_ripple_df=all_sessions_simple_pearson_ripple_df,\n",
    "                                                    all_sessions_all_scores_ripple_df=all_sessions_all_scores_ripple_df,  all_sessions_all_scores_laps_df=None,\n",
    "                                                    )\n",
    "final_csv_export_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_csv_files_df['file_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_csv_files_df[parsed_csv_files_df['file_type'] == 'ripple_all_scores_merged_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h5_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import load_across_sessions_exported_h5_files\n",
    "\n",
    "## INPUTS: h5_sessions, session_dict, cuttoff_date, known_bad_session_strs\n",
    "parsed_h5_files_df, h5_contexts_paths_dict = load_across_sessions_exported_h5_files(collected_outputs_directory=collected_outputs_directory, cuttoff_date=cuttoff_date,\n",
    "                                                                                    known_bad_session_strs=known_bad_session_strs)\n",
    "h5_session_contexts = list(h5_contexts_paths_dict.keys())\n",
    "included_h5_paths = list(h5_contexts_paths_dict.values())\n",
    "\n",
    "parsed_h5_files_df\n",
    "# h5_contexts_paths_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "\n",
    "included_session_contexts = deepcopy(h5_session_contexts)\n",
    "included_h5_paths = deepcopy(included_h5_paths)\n",
    "num_sessions = len(included_session_contexts)\n",
    "(neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table), output_path_dicts = AcrossSessionTables.build_and_save_all_combined_tables(included_session_contexts, included_h5_paths,\n",
    "                                                                                                                                                    override_output_parent_path=across_sessions_output_folder, output_path_suffix=f'{TODAY_DAY_DATE}',\n",
    "                                                                                                                                                    should_restore_native_column_types=True, include_csv=True, include_pkl=True)\n",
    "output_path_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "\n",
    "# matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "AcrossSessionsResults.post_compute_all_sessions_processing(global_data_root_parent_path=collected_outputs_directory, BATCH_DATE_TO_USE=TODAY_DAY_DATE, plotting_enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_multi_session_context, _out_aggregate_fig_2 = AcrossSessionsVisualizations.across_sessions_bar_graphs(across_session_inst_fr_computation, num_sessions, enable_tiny_point_labels=False, enable_hover_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=num_sessions) ## WORKS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(all_sessions_all_scores_ripple_df.columns)) # ['start', 'stop', 'label', 'duration', 'is_user_annotated_epoch', 'is_valid_epoch', 'P_LR', 'P_RL', 'P_Long', 'P_Short', 'P_Long_LR', 'score_long_LR', 'velocity_long_LR', 'intercept_long_LR', 'speed_long_LR', 'wcorr_long_LR', 'pearsonr_long_LR', 'travel_long_LR', 'coverage_long_LR', 'jump_long_LR', 'longest_sequence_length_ratio_long_LR', 'direction_change_bin_ratio_long_LR', 'congruent_dir_bins_ratio_long_LR', 'total_congruent_direction_change_long_LR', 'P_Long_RL', 'score_long_RL', 'velocity_long_RL', 'intercept_long_RL', 'speed_long_RL', 'wcorr_long_RL', 'pearsonr_long_RL', 'travel_long_RL', 'coverage_long_RL', 'jump_long_RL', 'longest_sequence_length_ratio_long_RL', 'direction_change_bin_ratio_long_RL', 'congruent_dir_bins_ratio_long_RL', 'total_congruent_direction_change_long_RL', 'P_Short_LR', 'score_short_LR', 'velocity_short_LR', 'intercept_short_LR', 'speed_short_LR', 'wcorr_short_LR', 'pearsonr_short_LR', 'travel_short_LR', 'coverage_short_LR', 'jump_short_LR', 'longest_sequence_length_ratio_short_LR', 'direction_change_bin_ratio_short_LR', 'congruent_dir_bins_ratio_short_LR', 'total_congruent_direction_change_short_LR', 'P_Short_RL', 'score_short_RL', 'velocity_short_RL', 'intercept_short_RL', 'speed_short_RL', 'wcorr_short_RL', 'pearsonr_short_RL', 'travel_short_RL', 'coverage_short_RL', 'jump_short_RL', 'longest_sequence_length_ratio_short_RL', 'direction_change_bin_ratio_short_RL', 'congruent_dir_bins_ratio_short_RL', 'total_congruent_direction_change_short_RL', 'ripple_start_t', 'long_best_travel', 'short_best_travel', 'travel_diff', 'long_best_coverage', 'short_best_coverage', 'coverage_diff', 'long_best_jump', 'short_best_jump', 'jump_diff', 'long_best_longest_sequence_length_ratio', 'short_best_longest_sequence_length_ratio', 'longest_sequence_length_ratio_diff', 'long_best_direction_change_bin_ratio', 'short_best_direction_change_bin_ratio', 'direction_change_bin_ratio_diff', 'long_best_congruent_dir_bins_ratio', 'short_best_congruent_dir_bins_ratio', 'congruent_dir_bins_ratio_diff', 'long_best_total_congruent_direction_change', 'short_best_total_congruent_direction_change', 'total_congruent_direction_change_diff', 'session_name', 'time_bin_size', 'delta_aligned_start_t']\n",
    "# ['long_best_total_congruent_direction_change', 'short_best_total_congruent_direction_change']\n",
    "['longest_sequence_length_ratio_diff', 'direction_change_bin_ratio_diff', 'congruent_dir_bins_ratio_diff', 'total_congruent_direction_change_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_simple_pearson_ripple_df # 3138 rows × 24 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_simple_pearson_laps_df # 931 rows × 25 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_ripple_df # 17592 rows × 10 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_all_scores_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_sessions_simple_pearson_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find all columns starting with 'wcorr': wcorr_long_LR\n",
    "sub_string: str = 'wcorr'\n",
    "sub_string: str = 'pearsonr'\n",
    "columns_list = list(all_sessions_simple_pearson_ripple_df.columns)\n",
    "matching_columns = [s for s in columns_list if sub_string in s]\n",
    "print(matching_columns) # ['wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL', 'long_best_wcorr', 'short_best_wcorr', 'wcorr_abs_diff']\n",
    "\n",
    "['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr', 'long_best_pf_peak_x_pearsonr', 'short_best_pf_peak_x_pearsonr', 'pearsonr_abs_diff']\n",
    "['wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL', 'long_best_wcorr', 'short_best_wcorr', 'wcorr_abs_diff']\n",
    "\n",
    "assert np.shape(all_sessions_simple_pearson_ripple_df)[0] == np.shape(all_sessions_all_scores_ripple_df)[0], f\"np.shape(all_sessions_all_scores_ripple_df)[0]: {np.shape(all_sessions_all_scores_ripple_df)[0]} != np.shape(all_sessions_simple_pearson_ripple_df)[0]: {np.shape(all_sessions_simple_pearson_ripple_df)[0]}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr', 'long_best_pf_peak_x_pearsonr', 'short_best_pf_peak_x_pearsonr', 'pearsonr_abs_diff']\n",
    "['wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL', 'long_best_wcorr', 'short_best_wcorr', 'wcorr_abs_diff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024-03-02 - Get only the user-annotated ripples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import _split_user_annotated_ripple_df\n",
    "\n",
    "## Bump\n",
    "# input_df = all_sessions_simple_pearson_ripple_df\n",
    "# input_df = all_sessions_all_scores_ripple_df\n",
    "\n",
    "all_sessions_all_scores_ripple_df, (valid_ripple_df, invalid_ripple_df), (user_approved_ripple_df, user_rejected_ripple_df) = _split_user_annotated_ripple_df(all_sessions_all_scores_ripple_df)\n",
    "\n",
    "## 2024-03-14 - 'is_valid_epoch' column\n",
    "# 'is_valid_epoch'\n",
    "## OUTPUTS: valid_ripple_df, invalid_ripple_df, user_approved_ripple_df, user_rejected_ripple_df, (user_annotated_epoch_unique_session_names, unannotated_session_names)\n",
    "user_approved_ripple_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2024-02-29 - 4pm - Filter the events for those meeting wcorr criteria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df: pd.DataFrame = deepcopy(all_sessions_user_annotated_ripple_df)\n",
    "df: pd.DataFrame = deepcopy(valid_ripple_df) # valid epochs, but not just those that the user approved\n",
    "# df: pd.DataFrame = deepcopy(user_approved_ripple_df)\n",
    "\n",
    "## INPUTS: df\n",
    "\n",
    "min_wcorr_threshold: float = 0.33\n",
    "min_wcorr_diff_threshold: float = 0.2\n",
    "\n",
    "# is_included_large_wcorr_diff = np.any((df[['wcorr_abs_diff']].abs() > min_wcorr_diff_threshold), axis=1)\n",
    "is_included_large_wcorr_diff = np.any((df[['wcorr_diff']].abs() > min_wcorr_diff_threshold), axis=1)\n",
    "is_included_high_wcorr = np.any((df[['long_best_wcorr', 'short_best_wcorr']].abs() > min_wcorr_threshold), axis=1)\n",
    "\n",
    "df = df[is_included_high_wcorr]\n",
    "df\n",
    "\n",
    "# wcorr_long_LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_all_scores_ripple_df.time_bin_size.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting via Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "# template: str = 'plotly_white'\n",
    "pio.templates.default = template\n",
    "from PIL import Image\n",
    "\n",
    "from pyphocorehelpers.programming_helpers import copy_image_to_clipboard\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_helper_save_figures, _helper_build_figure, plotly_pre_post_delta_scatter, plot_across_sessions_scatter_results\n",
    "\n",
    "# 1650, 446\n",
    "fig_size_kwargs = {'width': 1650, 'height': 480}\n",
    "\n",
    "\n",
    "def save_plotly(a_fig, a_fig_context):\n",
    "    \"\"\" \n",
    "    captures: TODAY_DAY_DATE\n",
    "    \"\"\"\n",
    "    fig_save_path: Path = figures_folder.joinpath('_'.join([TODAY_DAY_DATE, sanitize_filename_for_Windows(a_fig_context.get_description())])).resolve()\n",
    "    figure_out_paths = {'.html': fig_save_path.with_suffix('.html'), '.png': fig_save_path.with_suffix('.png')}\n",
    "    a_fig.write_html(figure_out_paths['.html'])\n",
    "    display(fullwidth_path_widget(figure_out_paths['.html'], file_name_label='.html'))\n",
    "    # print(file_uri_from_path(figure_out_paths['.html']))\n",
    "    a_fig.write_image(figure_out_paths['.png'])\n",
    "    # print(file_uri_from_path(figure_out_paths['.png']))\n",
    "    display(fullwidth_path_widget(figure_out_paths['.png'], file_name_label='.png'))\n",
    "    return figure_out_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "## INPUTS: all_sessions_all_scores_ripple_df\n",
    "concatenated_ripple_df = deepcopy(all_sessions_all_scores_ripple_df).infer_objects()\n",
    "\n",
    "## Add plotly helper columns:\n",
    "concatenated_ripple_df['pre_post_delta_category'] = 'post-delta'\n",
    "concatenated_ripple_df['pre_post_delta_category'][concatenated_ripple_df['delta_aligned_start_t'] < 0.0] = 'pre-delta'\n",
    "\n",
    "# {'pre_post_delta_category': ['pre-delta', 'post-delta']\n",
    "# }\n",
    "\n",
    "ripple_title_prefix = \"User Annotated Sessions Ripples\"\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(user_approved_ripple_df)\n",
    "# ripple_title_prefix = \"User Selected Ripples Only\"\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(user_rejected_ripple_df)\n",
    "# ripple_title_prefix = \"User Rejected Ripples Only\"\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(df)\n",
    "\n",
    "\n",
    "# Create a bubble chart for ripples\n",
    "enabled_time_bin_sizes = None\n",
    "ripple_num_unique_sessions: int = concatenated_ripple_df.session_name.nunique(dropna=True) # number of unique sessions, ignoring the NA entries\n",
    "ripple_num_unique_time_bins: int = concatenated_ripple_df.time_bin_size.nunique(dropna=True)\n",
    "ripple_title_string_suffix: str = f'{ripple_num_unique_sessions} Sessions'\n",
    "ripple_title: str = f\"{ripple_title_prefix} - {ripple_title_string_suffix}\"\n",
    "fig_ripples, figure_ripples_context = _helper_build_figure(data_results_df=concatenated_ripple_df, histogram_bins=25, earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end, enabled_time_bin_sizes=enabled_time_bin_sizes, main_plot_mode='default', title=ripple_title)\n",
    "fig_ripples = fig_ripples.update_layout(fig_size_kwargs)\n",
    "fig_ripples.show()\n",
    "# fig_to_clipboard(fig_ripples)\n",
    "figure_out_paths = save_plotly(a_fig=fig_ripples, a_fig_context=figure_ripples_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "histogram_bins = 25\n",
    "# concatenated_ripple_df = deepcopy(df)\n",
    "\n",
    "# ripple_title_prefix = 'test'\n",
    "# # Create a bubble chart for ripples\n",
    "# ripple_num_unique_sessions: int = concatenated_ripple_df.session_name.nunique(dropna=True) # number of unique sessions, ignoring the NA entries\n",
    "# # ripple_num_unique_time_bins: int = concatenated_ripple_df.time_bin_size.nunique(dropna=True)\n",
    "# ripple_title_string_suffix: str = f'{ripple_num_unique_sessions} Sessions'\n",
    "# ripple_title: str = f\"{ripple_title_prefix} - {ripple_title_string_suffix}\"\n",
    "# fig_ripples = _helper_build_figure(data_results_df=concatenated_ripple_df, histogram_bins=histogram_bins, earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end, enabled_time_bin_sizes=None,\n",
    "#                                     main_plot_mode='separate_row_per_session', title=ripple_title)\n",
    "\n",
    "# concatenated_ripple_df = deepcopy(concatenated_ripple_df)\n",
    "concatenated_ripple_df = deepcopy(all_sessions_all_scores_ripple_df)\n",
    "concatenated_ripple_df\n",
    "# ['longest_sequence_length_ratio_diff', 'direction_change_bin_ratio_diff', 'congruent_dir_bins_ratio_diff', 'total_congruent_direction_change_diff']\n",
    "\n",
    "\n",
    "# variable_name = 'P_Long'\n",
    "variable_name = 'P_Short' # Shows expected effect - short-only replay prior to delta and then split replays post-delta\n",
    "# variable_name = 'long_best_pf_peak_x_pearsonr'\n",
    "# variable_name = 'long_best_jump'\n",
    "# variable_name = 'wcorr_abs_diff'\n",
    "# variable_name = 'pearsonr_abs_diff'\n",
    "# variable_name = 'direction_change_bin_ratio_diff'\n",
    "# variable_name = 'longest_sequence_length_ratio_diff'\n",
    "# variable_name = 'long_best_longest_sequence_length_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'congruent_dir_bins_ratio_diff'\n",
    "# variable_name = 'total_congruent_direction_change_diff'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'long_best_direction_change_bin_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# 'color':'is_user_annotated_epoch'\n",
    "# 'color': 'is_user_annotated_epoch', \n",
    "\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'color':\"is_user_annotated_epoch\", 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "# hist_kwargs = dict(color=\"time_bin_size\")\n",
    "hist_kwargs = dict(color=\"is_user_annotated_epoch\") # , histnorm='probability density'\n",
    "new_fig_ripples, new_fig_ripples_context = plotly_pre_post_delta_scatter(data_results_df=concatenated_ripple_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, hist_kwargs=hist_kwargs, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end), legend_title_text='Is User Selected')\n",
    "new_fig_ripples = new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "figure_out_paths = save_plotly(a_fig=new_fig_ripples, a_fig_context=figure_ripples_context)\n",
    "new_fig_ripples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_fig_ripples.get_subplot(\n",
    "# import kaleido\n",
    "\n",
    "# new_fig_ripples.layout\n",
    "new_fig_ripples.layout.width\n",
    "\n",
    "# from kaleido._version import __version__ # '0.1.0.post1'\n",
    "# __version__\n",
    "\n",
    "## for dash:\n",
    "possible_plotly_figure_option_values = {'color':['session_name','is_user_annotated_epoch', 'time_bin_size', 'pre_post_delta_category'],\n",
    "'x': ['delta_aligned_start_t', 'ripple_start_t'],\n",
    "'y': ['P_LR', 'P_RL', 'P_Long', 'P_Short', 'P_Long_LR', 'score_long_LR', 'velocity_long_LR', 'intercept_long_LR', 'speed_long_LR', 'wcorr_long_LR', 'pearsonr_long_LR', 'travel_long_LR', 'coverage_long_LR', 'jump_long_LR', 'longest_sequence_length_ratio_long_LR', 'direction_change_bin_ratio_long_LR', 'congruent_dir_bins_ratio_long_LR', 'total_congruent_direction_change_long_LR', 'P_Long_RL', 'score_long_RL', 'velocity_long_RL', 'intercept_long_RL', 'speed_long_RL', 'wcorr_long_RL', 'pearsonr_long_RL', 'travel_long_RL', 'coverage_long_RL', 'jump_long_RL', 'longest_sequence_length_ratio_long_RL', 'direction_change_bin_ratio_long_RL', 'congruent_dir_bins_ratio_long_RL', 'total_congruent_direction_change_long_RL', 'P_Short_LR', 'score_short_LR', 'velocity_short_LR', 'intercept_short_LR', 'speed_short_LR', 'wcorr_short_LR', 'pearsonr_short_LR', 'travel_short_LR', 'coverage_short_LR', 'jump_short_LR', 'longest_sequence_length_ratio_short_LR', 'direction_change_bin_ratio_short_LR', 'congruent_dir_bins_ratio_short_LR', 'total_congruent_direction_change_short_LR', 'P_Short_RL', 'score_short_RL', 'velocity_short_RL', 'intercept_short_RL', 'speed_short_RL', 'wcorr_short_RL', 'pearsonr_short_RL', 'travel_short_RL', 'coverage_short_RL', 'jump_short_RL', 'longest_sequence_length_ratio_short_RL', 'direction_change_bin_ratio_short_RL', 'congruent_dir_bins_ratio_short_RL', 'total_congruent_direction_change_short_RL', 'long_best_P_decoder', 'short_best_P_decoder', 'P_decoder_diff', 'long_best_score', 'short_best_score', 'score_diff', 'long_best_velocity', 'short_best_velocity', 'velocity_diff', 'long_best_intercept', 'short_best_intercept', 'intercept_diff', 'long_best_speed', 'short_best_speed', 'speed_diff', 'long_best_wcorr', 'short_best_wcorr', 'wcorr_diff', 'long_best_pearsonr', 'short_best_pearsonr', 'pearsonr_diff', 'long_best_travel', 'short_best_travel', 'travel_diff', 'long_best_coverage', 'short_best_coverage', 'coverage_diff', 'long_best_jump', 'short_best_jump', 'jump_diff', 'long_best_longest_sequence_length_ratio', 'short_best_longest_sequence_length_ratio', 'longest_sequence_length_ratio_diff', 'long_best_direction_change_bin_ratio', 'short_best_direction_change_bin_ratio', 'direction_change_bin_ratio_diff', 'long_best_congruent_dir_bins_ratio', 'short_best_congruent_dir_bins_ratio', 'congruent_dir_bins_ratio_diff', 'long_best_total_congruent_direction_change', 'short_best_total_congruent_direction_change', 'total_congruent_direction_change_diff'],\n",
    "}\n",
    "\n",
    "\n",
    "color_options = [\"is_user_annotated_epoch\", \"pre_post_delta_category\"]\n",
    "\n",
    "variable_options = {'pre_post_delta_category': ['pre-delta', 'post-delta']\n",
    "}\n",
    "\n",
    "concatenated_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable_name = 'short_best_direction_change_bin_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "variable_name = 'short_best_wcorr'\n",
    "# 'color':'is_user_annotated_epoch'\n",
    "# 'color': 'is_user_annotated_epoch', \n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'color':\"pre_post_delta_category\", 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], , 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "# hist_kwargs = dict(color=\"time_bin_size\")\n",
    "hist_kwargs = dict(color=\"pre_post_delta_category\") # , histnorm='probability density'\n",
    "new_fig_ripples, figure_context = plotly_pre_post_delta_scatter(data_results_df=concatenated_ripple_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, hist_kwargs=hist_kwargs, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end))\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=0.0, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "new_fig_ripples.show()\n",
    "figure_out_paths = save_plotly(a_fig=new_fig_ripples, a_fig_context=figure_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable_name = 'total_congruent_direction_change_diff'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'long_best_total_congruent_direction_change'\n",
    "variable_name = 'wcorr_diff'\n",
    "# variable_name = 'long_best_wcorr'\n",
    "# 'color':'is_user_annotated_epoch'\n",
    "# 'color': 'is_user_annotated_epoch', \n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'color':\"is_user_annotated_epoch\", 'title': f\"'{variable_name}'\", 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], \n",
    "# hist_kwargs = dict(color=\"time_bin_size\")\n",
    "hist_kwargs = dict(color=\"is_user_annotated_epoch\") # , histnorm='probability density'\n",
    "new_fig_ripples, figure_context = plotly_pre_post_delta_scatter(data_results_df=concatenated_ripple_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, hist_kwargs=hist_kwargs, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end))\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=0.0, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "new_fig_ripples.show()\n",
    "figure_out_paths = save_plotly(a_fig=new_fig_ripples, a_fig_context=figure_context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import partition, partition_df, partition_df_dict\n",
    "import scipy.stats as stats\n",
    "\n",
    "# stats_variable_name: str = 'P_Short'\n",
    "# stats_variable_name: str = 'short_best_direction_change_bin_ratio'\n",
    "stats_variable_name: str = 'short_best_wcorr'\n",
    "\n",
    "## INPUTS: stats_variable_name, valid_ripple_df\n",
    "\n",
    "\n",
    "# ['pre-delta', 'post-delta']\n",
    "analysis_df = deepcopy(valid_ripple_df[[\"delta_aligned_start_t\", \"pre_post_delta_category\", stats_variable_name]]).dropna(subset=[\"pre_post_delta_category\", stats_variable_name])\n",
    "# partition_df(analysis_df, partitionColumn='pre_post_delta_category')\n",
    "\n",
    "# _partition_values, (_pre_delta_df, _post_delta_df) = partition(analysis_df, partitionColumn='pre_post_delta_category') # use `valid_ripple_df` instead of the original dataframe to only get those which are valid.\n",
    "_pre_post_delta_partition_df_dict = partition_df_dict(analysis_df, partitionColumn='pre_post_delta_category')\n",
    "_pre_delta_df = _pre_post_delta_partition_df_dict['pre-delta']\n",
    "_post_delta_df = _pre_post_delta_partition_df_dict['post-delta']\n",
    "\n",
    "actual_diff_means = np.nanmean(_post_delta_df[stats_variable_name].to_numpy()) - np.nanmean(_pre_delta_df[stats_variable_name].to_numpy())\n",
    "print(f'stats_variable_name: {stats_variable_name}: actual_diff_means: {actual_diff_means}')\n",
    "\n",
    "_pre_delta_df\n",
    "_post_delta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shuffles: int = 10000\n",
    "# stats_variable_name: str = 'P_Short'\n",
    "\n",
    "shuffle_results = []\n",
    "## INPUT: n_shuffles, analysis_df, stats_variable_name\n",
    "shuffled_analysis_df = deepcopy(analysis_df)\n",
    "for i in np.arange(n_shuffles):\n",
    "    # shuffled_analysis_df[stats_variable_name] = shuffled_analysis_df[stats_variable_name].sample(frac=1).to_numpy() # .reset_index(drop=True)\n",
    "    shuffled_analysis_df['pre_post_delta_category'] = shuffled_analysis_df.sample(frac=1)['pre_post_delta_category'].to_numpy()\n",
    "    _shuffled_pre_post_delta_partition_df_dict = partition_df_dict(shuffled_analysis_df, partitionColumn='pre_post_delta_category')\n",
    "    _shuffled_pre_delta_df = _shuffled_pre_post_delta_partition_df_dict['pre-delta']\n",
    "    _shuffled_post_delta_df = _shuffled_pre_post_delta_partition_df_dict['post-delta']\n",
    "\n",
    "    _diff_mean = np.nanmean(_shuffled_post_delta_df[stats_variable_name].to_numpy()) - np.nanmean(_shuffled_pre_delta_df[stats_variable_name].to_numpy())\n",
    "    shuffle_results.append(_diff_mean)\n",
    "\n",
    "shuffle_results = np.array(shuffle_results)\n",
    "shuffle_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(actual_diff_means > np.abs(shuffle_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data for two groups\n",
    "# group1 = np.random.rand(25)\n",
    "# group2 = np.random.rand(20)\n",
    "\n",
    "## INPUTS: stats_variable_name\n",
    "print(f'stats_variable_name: {stats_variable_name}')\n",
    "\n",
    "group1 = _pre_delta_df[stats_variable_name].to_numpy()\n",
    "group2 = _post_delta_df[stats_variable_name].to_numpy()\n",
    "\n",
    "# perform mann whitney test \n",
    "stat, p_value = stats.mannwhitneyu(group1, group2) \n",
    "print('Statistics=%.2f, p=%.2f' % (stat, p_value)) \n",
    "\n",
    "# Level of significance \n",
    "alpha = 0.05\n",
    "# conclusion \n",
    "if p_value < alpha: \n",
    "    print('Reject Null Hypothesis (Significant difference between two samples)') \n",
    "else: \n",
    "    print('Do not Reject Null Hypothesis (No significant difference between two samples)')\n",
    "\n",
    "# Calculate the sample variances\n",
    "variance1 = np.var(group1, ddof=1)\n",
    "variance2 = np.var(group2, ddof=1)\n",
    " \n",
    "print('Variance 1:',variance1)\n",
    "print('Variance 2:',variance2)\n",
    "\n",
    "# Calculate the F-statistic\n",
    "f_value = variance1 / variance2\n",
    " \n",
    "# Calculate the degrees of freedom\n",
    "df1 = len(group1) - 1\n",
    "df2 = len(group2) - 1\n",
    " \n",
    "# Calculate the p-value\n",
    "p_value = stats.f.cdf(f_value, df1, df2)\n",
    " \n",
    "# Print the results\n",
    "print('Degree of freedom 1:',df1)\n",
    "print('Degree of freedom 2:',df2)\n",
    "print(\"F-statistic:\", f_value)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "\n",
    "# Statistics=351933.00, p=0.00\n",
    "# Reject Null Hypothesis (Significant difference between two samples)\n",
    "# Variance 1: 0.017720245875104713\n",
    "# Variance 2: 0.02501347759017487\n",
    "# Degree of freedom 1: 1104\n",
    "# Degree of freedom 2: 1282\n",
    "# F-statistic: 0.7084279189577826\n",
    "# p-value: 1.882791591520268e-09\n",
    "\n",
    "\n",
    "# stats_variable_name: short_best_wcorr\n",
    "# Statistics=770405.00, p=0.00\n",
    "# Reject Null Hypothesis (Significant difference between two samples)\n",
    "# Variance 1: 0.13962063046395118\n",
    "# Variance 2: 0.15575146845969287\n",
    "# Degree of freedom 1: 1108\n",
    "# Degree of freedom 2: 1281\n",
    "# F-statistic: 0.8964321931904211\n",
    "# p-value: 0.030077963036698012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## User non-selected:\n",
    "scatter_title = f'user_approved_ripple_df Several Sessions {variable_name}'\n",
    "# variable_name = 'wcorr_abs_diff'\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': scatter_title, 'range_y': [0.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size'}} # , 'color': 'time_bin_size'\n",
    "new_fig_ripples, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(user_approved_ripple_df), out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end))\n",
    "_extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "new_fig_ripples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEA: The ones with clear replays (diagonal sequences in the decoded posteriors) are by definiition ambiguous, because there's not much difference between the long/short decoders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## User non-selected:\n",
    "scatter_title = f'Non-selected Several Sessions {variable_name}'\n",
    "# variable_name = 'wcorr_abs_diff'\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': scatter_title, 'range_y': [0.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size'}} # , 'color': 'time_bin_size'\n",
    "new_fig_ripples, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(user_rejected_ripple_df), out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end))\n",
    "new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "new_fig_ripples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laps test\n",
    "concatenated_ripple_df = deepcopy(all_sessions_simple_pearson_laps_df)\n",
    "\n",
    "scatter_title = 'Several Sessions'\n",
    "variable_name = 'wcorr_abs_diff'\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'title': scatter_title, 'range_y': [0.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size'}} \n",
    "new_fig_ripples, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(concatenated_ripple_df), out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end))\n",
    "new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "new_fig_ripples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import PlottingHelpers\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import plot_across_sessions_scatter_results\n",
    "\n",
    "# Example usage:\n",
    "all_session_figures = plot_across_sessions_scatter_results(collected_outputs_directory, concatenated_laps_df=all_sessions_laps_df, concatenated_ripple_df=all_sessions_ripple_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t#    enabled_time_bin_sizes=[0.03, 0.10],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   laps_title_prefix=f\"Laps\", ripple_title_prefix=f\"Ripples\", save_figures=True, figure_save_extension=['.html','.png'])\n",
    "fig_laps, fig_ripples = all_session_figures[0]\n",
    "# fig_laps.update_layout(fig_size_kwargs)\n",
    "# fig_ripples.update_layout(fig_size_kwargs)\n",
    "\n",
    "# fig_laps.show()\n",
    "fig_ripples.show()\n",
    "# fig_laps.write_html(f\"../output/{TODAY_DAY_DATE}_AcrossSession_fig_laps.html\")\n",
    "# fig_ripples.write_html(f\"../output/{TODAY_DAY_DATE}_AcrossSession_fig_ripples.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_to_clipboard(fig_ripples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "## time_bin version:\n",
    "all_time_bin_session_figures = plot_across_sessions_scatter_results(collected_outputs_directory, concatenated_laps_df=all_sessions_laps_time_bin_df, concatenated_ripple_df=all_sessions_ripple_time_bin_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t#    enabled_time_bin_sizes=[0.03, 0.10],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   main_plot_mode='separate_row_per_session',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   laps_title_prefix=f\"Laps_per_time_bin\", ripple_title_prefix=f\"Ripples_per_time_bin\", save_figures=True, figure_save_extension=['.html','.png'])\n",
    "fig_time_bin_laps, fig_time_bin_ripples = all_time_bin_session_figures[0]\n",
    "# fig_time_bin_laps.show()\n",
    "fig_time_bin_ripples.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import plotly_pre_post_delta_scatter\n",
    "\n",
    "## Test collapsed histograms-only results:\n",
    "histograms_only_all_time_bin_session_figures = plot_across_sessions_scatter_results(collected_outputs_directory, concatenated_laps_df=all_sessions_laps_time_bin_df, concatenated_ripple_df=all_sessions_ripple_time_bin_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t#    enabled_time_bin_sizes=[0.03, 0.10],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# enabled_time_bin_sizes=[0.03, 0.058, 0.10], # [0.03 , 0.044, 0.058, 0.072, 0.086, 0.1]\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   main_plot_mode='default',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   laps_title_prefix=f\"Laps_per_time_bin\", ripple_title_prefix=f\"Ripples_per_time_bin\", save_figures=False, figure_save_extension=['.html','.png'])\n",
    "histograms_only_fig_time_bin_laps, histograms_only_fig_time_bin_ripples = histograms_only_all_time_bin_session_figures[0]\n",
    "# histograms_only_fig_time_bin_laps.show()\n",
    "histograms_only_fig_time_bin_ripples.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.subplots as sp\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import plotly_pre_post_delta_scatter\n",
    "# data_results_df: pd.DataFrame = deepcopy(all_sessions_laps_df) # all_sessions_laps_time_bin_df\n",
    "# histogram_bins = 'auto'\n",
    "histogram_bins: int = 25\n",
    "\n",
    "new_laps_fig, new_laps_fig_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(all_sessions_laps_df), out_scatter_fig=fig_laps, histogram_bins=histogram_bins)\n",
    "new_laps_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib-based versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_histograms\n",
    "\n",
    "matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Spike3D.PendingNotebookCode import plot_stacked_histograms\n",
    "\n",
    "# You can use it like this:'long_best_dir_simple_pearsonr'\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Laps', session_spec='All Sessions', data_results_df=all_sessions_laps_time_bin_df, time_bin_duration_str=\"75 ms\")\n",
    "_out1: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Ripples', session_spec='All Sessions', data_results_df=all_sessions_ripple_time_bin_df, time_bin_duration_str=\"75 ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig_to_clipboard(_out0.figures[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all_sessions_new_laps_df, all_sessions_new_ripple_df\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms(data_type='New Laps', session_spec='All Sessions', data_results_df=all_sessions_new_laps_df, time_bin_duration_str=\"25 ms\")\n",
    "_out1: \"MatplotlibRenderPlots\" = plot_histograms(data_type='New Ripples', session_spec='All Sessions', data_results_df=all_sessions_new_ripple_df, time_bin_duration_str=\"25 ms\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_new_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_sessions_new_laps_df['session_name'].unique()) # 10 sessions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms_across_sessions, plot_stacked_histograms\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "column_name: str = 'P_Short'\n",
    "\n",
    "# You can use it like this:\n",
    "num_unique_sessions: int = all_sessions_laps_time_bin_df.session_name.nunique(dropna=True) # number of unique sessions, ignoring the NA entries\n",
    "num_unique_time_bins: int = all_sessions_laps_time_bin_df.time_bin_size.nunique(dropna=True)\n",
    "_laps_histogram_out = plot_stacked_histograms(all_sessions_laps_time_bin_df, 'Laps', f'{num_unique_sessions} Sessions', f\"{num_unique_time_bins} tbin sizes\", column_name=column_name)\n",
    "\n",
    "fig_to_clipboard(_laps_histogram_out.figures[0])\n",
    "\n",
    "num_unique_sessions: int = all_sessions_ripple_time_bin_df.session_name.nunique(dropna=True) # number of unique sessions, ignoring the NA entries\n",
    "num_unique_time_bins: int = all_sessions_ripple_time_bin_df.time_bin_size.nunique(dropna=True)\n",
    "_ripple_histogram_out = plot_stacked_histograms(all_sessions_ripple_time_bin_df, 'Ripples', f'{num_unique_sessions} Sessions', f\"{num_unique_time_bins} tbin sizes\", column_name=column_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_ripple_time_bin_df['time_bin_size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_time_bin_size: float = 0.072 # 0.058\n",
    "# active_time_bin_size: float = 0.086\n",
    "active_time_bin_size: float = 0.1 # looks the most bimodal with as little of an intermediate value as possible.\n",
    "_single_time_bin_ripple_histogram_out = plot_stacked_histograms(all_sessions_ripple_time_bin_df[all_sessions_ripple_time_bin_df['time_bin_size'] == active_time_bin_size], 'Ripples', f'{num_unique_sessions} Sessions', f\"tbin: {active_time_bin_size:0.3f}s\", column_name=column_name)\n",
    "fig_to_clipboard(_single_time_bin_ripple_histogram_out.figures[0], bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_to_clipboard(_ripple_histogram_out.figures[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_laps_histogram_out.figures[0]\n",
    "\n",
    "figures_folder\n",
    "\n",
    "figures_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024-03-28 - AcrossSessionTable (PhoDibaPaper2023 formats) .h5 and figure exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_all_known_tables(included_session_contexts, included_h5_paths, should_restore_native_column_types=True)\n",
    "num_sessions: int = len(long_short_fr_indicies_analysis_table['session_uid'].unique())\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "\n",
    "long_short_fr_indicies_analysis_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "matplotlib.use('Qt5Agg')\n",
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=num_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphics_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_image_to_clipboard(graphics_output_dict['figures'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike3d-yellow",
   "language": "python",
   "name": "spike3d-yellow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
