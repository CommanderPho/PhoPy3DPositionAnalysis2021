{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'cell_type': 'code', 'execution_count': 4, 'id': '0056bc66-7629-4ef7-8c87-f28f8fcd9dc8', 'metadata': {'autorun': True, 'notebookRunGroups': {'groupValue': '1'}, 'tags': ['imports', 'REQUIRED', 'ACTIVE']}, 'outputs': [{'name': 'stdout', 'output_type': 'stream', 'text': 'Automatic pdb calling has been turned OFF\\nThe autoreload extension is already loaded. To reload it, use:\\n  %reload_ext autoreload\\n'}], 'source': \"%config IPCompleter.use_jedi = False\\n%pdb off\\n%load_ext autoreload\\n%autoreload 3\\nimport sys\\nfrom copy import deepcopy\\nfrom typing import List, Dict, Optional, Union, Callable\\nfrom pathlib import Path\\nimport pathlib\\nimport numpy as np\\nimport pandas as pd\\nimport tables as tb\\nfrom copy import deepcopy\\nfrom datetime import datetime, timedelta\\nfrom attrs import define, field, Factory\\n\\n# required to enable non-blocking interaction:\\n%gui qt5\\n\\n## Pho's Custom Libraries:\\nfrom pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\\nfrom pyphocorehelpers.function_helpers import function_attributes\\nfrom pyphocorehelpers.print_helpers import CapturedException\\n\\n# Jupyter interactivity:\\nimport ipywidgets as widgets\\nfrom IPython.display import display\\nfrom pyphocorehelpers.gui.Jupyter.JupyterButtonRowWidget import JupyterButtonRowWidget\\n\\n# pyPhoPlaceCellAnalysis:\\n# NeuroPy (Diba Lab Python Repo) Loading\\nfrom neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\\nfrom neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\\nfrom neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\\nfrom neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\\nfrom neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\\nfrom neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\\n\\n## For computation parameters:\\nfrom neuropy.utils.result_context import IdentifyingContext\\nfrom neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\\nfrom neuropy.core import Epoch\\n\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\\nimport pyphoplacecellanalysis.General.Batch.runBatch\\nfrom pyphoplacecellanalysis.General.Batch.runBatch import BatchRun, BatchResultDataframeAccessor, run_diba_batch, BatchComputationProcessOptions, BatchSessionCompletionHandler, SavingOptions\\nfrom pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\\n\\nfrom neuropy.core.user_annotations import UserAnnotationsManager\\nfrom pyphoplacecellanalysis.General.Batch.runBatch import SessionBatchProgress\\nfrom pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionTables, AcrossSessionsVisualizations\\n\\nfrom pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\\n\\nfrom pyphocorehelpers.print_helpers import CapturedException\\nfrom pyphoplacecellanalysis.General.Batch.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor\\nfrom pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult, BatchSessionCompletionHandler\\n\\nfrom pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_file_metadata\\nfrom pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file, save_copydict_to_text_file, read_copydict_from_text_file, invert_filedict\\nfrom pyphoplacecellanalysis.General.Batch.runBatch import get_file_str_if_file_exists\\nfrom pyphoplacecellanalysis.General.Batch.AcrossSessionResults import check_output_h5_files, copy_files_in_filelist_to_dest\\nfrom pyphoplacecellanalysis.General.Batch.runBatch import ConcreteSessionFolder, BackupMethods\\n\\nfrom pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots, BatchPhoJonathanFiguresHelper\\nfrom pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\\n\\nfrom neuropy.core.neuron_identities import NeuronIdentityDataframeAccessor\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import build_merged_neuron_firing_rate_indicies\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsHelpers\\n\\n# BATCH_DATE_TO_USE = '2023-10-20' # used for filenames throught the notebook\\n# BATCH_DATE_TO_USE = '2023-10-18_Apogee' # used for filenames throught the notebook\\nBATCH_DATE_TO_USE = '2023-11-10_GL' # used for filenames throught the notebook\"}, {'cell_type': 'code', 'execution_count': 5, 'id': '8ef5938c', 'metadata': {'notebookRunGroups': {'groupValue': '1'}, 'tags': []}, 'outputs': [{'name': 'stdout', 'output_type': 'stream', 'text': 'Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/global_batch_result_2023-11-10_GL.pkl... done.\\nno difference between provided and internal paths.\\n'}, {'data': {'text/html': '<div>\\n<style scoped>\\n    .dataframe tbody tr th:only-of-type {\\n        vertical-align: middle;\\n    }\\n\\n    .dataframe tbody tr th {\\n        vertical-align: top;\\n    }\\n\\n    .dataframe thead th {\\n        text-align: right;\\n    }\\n</style>\\n<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>format_name</th>\\n      <th>animal</th>\\n      <th>exper_name</th>\\n      <th>session_name</th>\\n      <th>context</th>\\n      <th>basedirs</th>\\n      <th>status</th>\\n      <th>errors</th>\\n      <th>session_datetime</th>\\n      <th>n_long_laps</th>\\n      <th>n_long_replays</th>\\n      <th>n_short_laps</th>\\n      <th>n_short_replays</th>\\n      <th>is_ready</th>\\n      <th>global_computation_result_file</th>\\n      <th>loaded_session_pickle_file</th>\\n      <th>ripple_result_file</th>\\n      <th>has_user_replay_annotations</th>\\n      <th>has_user_grid_bin_bounds_annotations</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>one</td>\\n      <td>2006-6-07_11-26-53</td>\\n      <td>kdiba_gor01_one_2006-6-07_11-26-53</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2006-06-07 11:26:53</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>False</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>one</td>\\n      <td>2006-6-08_14-26-15</td>\\n      <td>kdiba_gor01_one_2006-6-08_14-26-15</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2006-06-08 14:26:15</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>one</td>\\n      <td>2006-6-09_1-22-43</td>\\n      <td>kdiba_gor01_one_2006-6-09_1-22-43</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2006-06-09 01:22:43</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>3</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>one</td>\\n      <td>2006-6-09_3-23-37</td>\\n      <td>kdiba_gor01_one_2006-6-09_3-23-37</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2006-06-09 03:23:37</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td></td>\\n      <td></td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>False</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>one</td>\\n      <td>2006-6-12_15-55-31</td>\\n      <td>kdiba_gor01_one_2006-6-12_15-55-31</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2006-06-12 15:55:31</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>...</th>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n    </tr>\\n    <tr>\\n      <th>67</th>\\n      <td>kdiba</td>\\n      <td>pin01</td>\\n      <td>one</td>\\n      <td>fet11-04_21-20-3</td>\\n      <td>kdiba_pin01_one_fet11-04_21-20-3</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2009-11-04 21:20:03</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\\n      <td>False</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>68</th>\\n      <td>kdiba</td>\\n      <td>pin01</td>\\n      <td>one</td>\\n      <td>redundant</td>\\n      <td>kdiba_pin01_one_redundant</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/red...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>NaT</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td></td>\\n      <td></td>\\n      <td></td>\\n      <td>False</td>\\n      <td>False</td>\\n    </tr>\\n    <tr>\\n      <th>69</th>\\n      <td>kdiba</td>\\n      <td>pin01</td>\\n      <td>one</td>\\n      <td>showclus</td>\\n      <td>kdiba_pin01_one_showclus</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sho...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>NaT</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td></td>\\n      <td></td>\\n      <td></td>\\n      <td>False</td>\\n      <td>False</td>\\n    </tr>\\n    <tr>\\n      <th>70</th>\\n      <td>kdiba</td>\\n      <td>pin01</td>\\n      <td>one</td>\\n      <td>sleep</td>\\n      <td>kdiba_pin01_one_sleep</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sleep</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>NaT</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td></td>\\n      <td></td>\\n      <td></td>\\n      <td>False</td>\\n      <td>False</td>\\n    </tr>\\n    <tr>\\n      <th>71</th>\\n      <td>kdiba</td>\\n      <td>pin01</td>\\n      <td>one</td>\\n      <td>tmaze</td>\\n      <td>kdiba_pin01_one_tmaze</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/tmaze</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>NaT</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td></td>\\n      <td></td>\\n      <td></td>\\n      <td>False</td>\\n      <td>False</td>\\n    </tr>\\n  </tbody>\\n</table>\\n<p>72 rows × 19 columns</p>\\n</div>', 'text/plain': '   format_name animal exper_name        session_name  \\\\\\n0        kdiba  gor01        one  2006-6-07_11-26-53   \\n1        kdiba  gor01        one  2006-6-08_14-26-15   \\n2        kdiba  gor01        one   2006-6-09_1-22-43   \\n3        kdiba  gor01        one   2006-6-09_3-23-37   \\n4        kdiba  gor01        one  2006-6-12_15-55-31   \\n..         ...    ...        ...                 ...   \\n67       kdiba  pin01        one    fet11-04_21-20-3   \\n68       kdiba  pin01        one           redundant   \\n69       kdiba  pin01        one            showclus   \\n70       kdiba  pin01        one               sleep   \\n71       kdiba  pin01        one               tmaze   \\n\\n                               context  \\\\\\n0   kdiba_gor01_one_2006-6-07_11-26-53   \\n1   kdiba_gor01_one_2006-6-08_14-26-15   \\n2    kdiba_gor01_one_2006-6-09_1-22-43   \\n3    kdiba_gor01_one_2006-6-09_3-23-37   \\n4   kdiba_gor01_one_2006-6-12_15-55-31   \\n..                                 ...   \\n67    kdiba_pin01_one_fet11-04_21-20-3   \\n68           kdiba_pin01_one_redundant   \\n69            kdiba_pin01_one_showclus   \\n70               kdiba_pin01_one_sleep   \\n71               kdiba_pin01_one_tmaze   \\n\\n                                             basedirs  \\\\\\n0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n3   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n..                                                ...   \\n67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \\n68  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/red...   \\n69  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sho...   \\n70   /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/sleep   \\n71   /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/tmaze   \\n\\n                              status errors    session_datetime  n_long_laps  \\\\\\n0   SessionBatchProgress.NOT_STARTED   None 2006-06-07 11:26:53            0   \\n1   SessionBatchProgress.NOT_STARTED   None 2006-06-08 14:26:15            0   \\n2   SessionBatchProgress.NOT_STARTED   None 2006-06-09 01:22:43            0   \\n3   SessionBatchProgress.NOT_STARTED   None 2006-06-09 03:23:37            0   \\n4   SessionBatchProgress.NOT_STARTED   None 2006-06-12 15:55:31            0   \\n..                               ...    ...                 ...          ...   \\n67  SessionBatchProgress.NOT_STARTED   None 2009-11-04 21:20:03            0   \\n68  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \\n69  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \\n70  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \\n71  SessionBatchProgress.NOT_STARTED   None                 NaT            0   \\n\\n    n_long_replays  n_short_laps  n_short_replays  is_ready  \\\\\\n0                0             0                0     False   \\n1                0             0                0     False   \\n2                0             0                0     False   \\n3                0             0                0     False   \\n4                0             0                0     False   \\n..             ...           ...              ...       ...   \\n67               0             0                0     False   \\n68               0             0                0     False   \\n69               0             0                0     False   \\n70               0             0                0     False   \\n71               0             0                0     False   \\n\\n                       global_computation_result_file  \\\\\\n0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n3                                                       \\n4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n..                                                ...   \\n67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \\n68                                                      \\n69                                                      \\n70                                                      \\n71                                                      \\n\\n                           loaded_session_pickle_file  \\\\\\n0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n3                                                       \\n4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n..                                                ...   \\n67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \\n68                                                      \\n69                                                      \\n70                                                      \\n71                                                      \\n\\n                                   ripple_result_file  \\\\\\n0   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n3   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n..                                                ...   \\n67  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \\n68                                                      \\n69                                                      \\n70                                                      \\n71                                                      \\n\\n    has_user_replay_annotations  has_user_grid_bin_bounds_annotations  \\n0                         False                                  True  \\n1                          True                                  True  \\n2                          True                                  True  \\n3                         False                                  True  \\n4                          True                                  True  \\n..                          ...                                   ...  \\n67                        False                                  True  \\n68                        False                                 False  \\n69                        False                                 False  \\n70                        False                                 False  \\n71                        False                                 False  \\n\\n[72 rows x 19 columns]'}, 'metadata': {}, 'output_type': 'display_data'}], 'source': 'active_global_batch_result_filename=f\\'global_batch_result_{BATCH_DATE_TO_USE}.pkl\\'\\n\\ndebug_print = False\\nknown_global_data_root_parent_paths = [Path(r\\'W:\\\\Data\\'), Path(r\\'/media/MAX/Data\\'), Path(r\\'/home/halechr/cloud/turbo/Data\\'), Path(r\\'/Volumes/MoverNew/data\\'), Path(r\\'/home/halechr/turbo/Data\\'), Path(r\\'/nfs/turbo/umms-kdiba/Data\\')] # , Path(r\\'/home/halechr/FastData\\')\\nglobal_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\\nassert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer\\'s config commented out above?\"\\n## Build Pickle Path:\\nglobal_batch_result_file_path = Path(global_data_root_parent_path).joinpath(active_global_batch_result_filename).resolve() # Use Default\\n\\n# try to load an existing batch result:\\nglobal_batch_run = BatchRun.try_init_from_file(global_data_root_parent_path, active_global_batch_result_filename=active_global_batch_result_filename,\\n\\t\\t\\t\\t\\t\\tskip_root_path_conversion=False, debug_print=debug_print) # on_needs_create_callback_fn=run_diba_batch\\n\\nbatch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\\ngood_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\\nbatch_progress_df.batch_results.build_all_columns()\\ngood_only_batch_progress_df.batch_results.build_all_columns()\\nbatch_progress_df\\nwith pd.option_context(\\'display.max_rows\\', 10, \\'display.max_columns\\', None):  # more options can be specified also\\n    # display(batch_progress_df)\\n    # display(good_only_batch_progress_df)\\n    display(batch_progress_df)'}, {'cell_type': 'markdown', 'id': 'ab824348', 'metadata': {'tags': []}, 'source': '# Run Batch Executions/Computations'}, {'cell_type': 'code', 'execution_count': 6, 'id': '019afbbd-70d2-4e75-9548-b6f22d2e31ca', 'metadata': {'notebookRunGroups': {'groupValue': '12'}, 'scrolled': True, 'tags': []}, 'outputs': [{'data': {'text/html': '<div>\\n<style scoped>\\n    .dataframe tbody tr th:only-of-type {\\n        vertical-align: middle;\\n    }\\n\\n    .dataframe tbody tr th {\\n        vertical-align: top;\\n    }\\n\\n    .dataframe thead th {\\n        text-align: right;\\n    }\\n</style>\\n<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>format_name</th>\\n      <th>animal</th>\\n      <th>exper_name</th>\\n      <th>session_name</th>\\n      <th>context</th>\\n      <th>basedirs</th>\\n      <th>status</th>\\n      <th>errors</th>\\n      <th>session_datetime</th>\\n      <th>n_long_laps</th>\\n      <th>n_long_replays</th>\\n      <th>n_short_laps</th>\\n      <th>n_short_replays</th>\\n      <th>is_ready</th>\\n      <th>global_computation_result_file</th>\\n      <th>loaded_session_pickle_file</th>\\n      <th>ripple_result_file</th>\\n      <th>has_user_replay_annotations</th>\\n      <th>has_user_grid_bin_bounds_annotations</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>1</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>one</td>\\n      <td>2006-6-08_14-26-15</td>\\n      <td>kdiba_gor01_one_2006-6-08_14-26-15</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2006-06-08 14:26:15</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>one</td>\\n      <td>2006-6-09_1-22-43</td>\\n      <td>kdiba_gor01_one_2006-6-09_1-22-43</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2006-06-09 01:22:43</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>one</td>\\n      <td>2006-6-12_15-55-31</td>\\n      <td>kdiba_gor01_one_2006-6-12_15-55-31</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2006-06-12 15:55:31</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>6</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>two</td>\\n      <td>2006-6-07_16-40-19</td>\\n      <td>kdiba_gor01_two_2006-6-07_16-40-19</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2006-06-07 16:40:19</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>8</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>two</td>\\n      <td>2006-6-08_21-16-25</td>\\n      <td>kdiba_gor01_two_2006-6-08_21-16-25</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2006-06-08 21:16:25</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>...</th>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n      <td>...</td>\\n    </tr>\\n    <tr>\\n      <th>32</th>\\n      <td>kdiba</td>\\n      <td>vvp01</td>\\n      <td>two</td>\\n      <td>2006-4-10_12-58-3</td>\\n      <td>kdiba_vvp01_two_2006-4-10_12-58-3</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2006-04-10 12:58:03</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>52</th>\\n      <td>kdiba</td>\\n      <td>pin01</td>\\n      <td>one</td>\\n      <td>11-02_17-46-44</td>\\n      <td>kdiba_pin01_one_11-02_17-46-44</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2009-11-02 17:46:44</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>53</th>\\n      <td>kdiba</td>\\n      <td>pin01</td>\\n      <td>one</td>\\n      <td>11-02_19-28-0</td>\\n      <td>kdiba_pin01_one_11-02_19-28-0</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2009-11-02 19:28:00</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>54</th>\\n      <td>kdiba</td>\\n      <td>pin01</td>\\n      <td>one</td>\\n      <td>11-03_12-3-25</td>\\n      <td>kdiba_pin01_one_11-03_12-3-25</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2009-11-03 12:03:25</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>64</th>\\n      <td>kdiba</td>\\n      <td>pin01</td>\\n      <td>one</td>\\n      <td>fet11-01_12-58-54</td>\\n      <td>kdiba_pin01_one_fet11-01_12-58-54</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\\n      <td>SessionBatchProgress.NOT_STARTED</td>\\n      <td>None</td>\\n      <td>2009-11-01 12:58:54</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>False</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n  </tbody>\\n</table>\\n<p>15 rows × 19 columns</p>\\n</div>', 'text/plain': '   format_name animal exper_name        session_name  \\\\\\n1        kdiba  gor01        one  2006-6-08_14-26-15   \\n2        kdiba  gor01        one   2006-6-09_1-22-43   \\n4        kdiba  gor01        one  2006-6-12_15-55-31   \\n6        kdiba  gor01        two  2006-6-07_16-40-19   \\n8        kdiba  gor01        two  2006-6-08_21-16-25   \\n..         ...    ...        ...                 ...   \\n32       kdiba  vvp01        two   2006-4-10_12-58-3   \\n52       kdiba  pin01        one      11-02_17-46-44   \\n53       kdiba  pin01        one       11-02_19-28-0   \\n54       kdiba  pin01        one       11-03_12-3-25   \\n64       kdiba  pin01        one   fet11-01_12-58-54   \\n\\n                               context  \\\\\\n1   kdiba_gor01_one_2006-6-08_14-26-15   \\n2    kdiba_gor01_one_2006-6-09_1-22-43   \\n4   kdiba_gor01_one_2006-6-12_15-55-31   \\n6   kdiba_gor01_two_2006-6-07_16-40-19   \\n8   kdiba_gor01_two_2006-6-08_21-16-25   \\n..                                 ...   \\n32   kdiba_vvp01_two_2006-4-10_12-58-3   \\n52      kdiba_pin01_one_11-02_17-46-44   \\n53       kdiba_pin01_one_11-02_19-28-0   \\n54       kdiba_pin01_one_11-03_12-3-25   \\n64   kdiba_pin01_one_fet11-01_12-58-54   \\n\\n                                             basedirs  \\\\\\n1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n..                                                ...   \\n32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \\n52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \\n\\n                              status errors    session_datetime  n_long_laps  \\\\\\n1   SessionBatchProgress.NOT_STARTED   None 2006-06-08 14:26:15            0   \\n2   SessionBatchProgress.NOT_STARTED   None 2006-06-09 01:22:43            0   \\n4   SessionBatchProgress.NOT_STARTED   None 2006-06-12 15:55:31            0   \\n6   SessionBatchProgress.NOT_STARTED   None 2006-06-07 16:40:19            0   \\n8   SessionBatchProgress.NOT_STARTED   None 2006-06-08 21:16:25            0   \\n..                               ...    ...                 ...          ...   \\n32  SessionBatchProgress.NOT_STARTED   None 2006-04-10 12:58:03            0   \\n52  SessionBatchProgress.NOT_STARTED   None 2009-11-02 17:46:44            0   \\n53  SessionBatchProgress.NOT_STARTED   None 2009-11-02 19:28:00            0   \\n54  SessionBatchProgress.NOT_STARTED   None 2009-11-03 12:03:25            0   \\n64  SessionBatchProgress.NOT_STARTED   None 2009-11-01 12:58:54            0   \\n\\n    n_long_replays  n_short_laps  n_short_replays  is_ready  \\\\\\n1                0             0                0     False   \\n2                0             0                0     False   \\n4                0             0                0     False   \\n6                0             0                0     False   \\n8                0             0                0     False   \\n..             ...           ...              ...       ...   \\n32               0             0                0     False   \\n52               0             0                0     False   \\n53               0             0                0     False   \\n54               0             0                0     False   \\n64               0             0                0     False   \\n\\n                       global_computation_result_file  \\\\\\n1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n..                                                ...   \\n32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \\n52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \\n\\n                           loaded_session_pickle_file  \\\\\\n1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n..                                                ...   \\n32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \\n52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \\n\\n                                   ripple_result_file  \\\\\\n1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n..                                                ...   \\n32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \\n52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \\n\\n    has_user_replay_annotations  has_user_grid_bin_bounds_annotations  \\n1                          True                                  True  \\n2                          True                                  True  \\n4                          True                                  True  \\n6                          True                                  True  \\n8                          True                                  True  \\n..                          ...                                   ...  \\n32                         True                                  True  \\n52                         True                                  True  \\n53                         True                                  True  \\n54                         True                                  True  \\n64                         True                                  True  \\n\\n[15 rows x 19 columns]'}, 'metadata': {}, 'output_type': 'display_data'}], 'source': \"# Hardcoded included_session_contexts:\\nincluded_session_contexts = [\\n    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'), # prev completed\\n    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'), # prev completed\\n    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'), # prev completed\\n    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'), # prev completed\\n    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\\n    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\\n    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\\n    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\\n    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\\n    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\\n    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\\n    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'), # prev completed\\n    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\\n    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\\n    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'), # prev completed\\n]\\n\\ngood_session_concrete_folders = ConcreteSessionFolder.build_concrete_session_folders(global_data_root_parent_path, included_session_contexts)\\ngood_session_concrete_folders\\n\\n\\nfrom pyphoplacecellanalysis.General.Batch.pythonScriptTemplating import generate_batch_single_session_scripts\\n\\n## Build Slurm Scripts:\\nsession_basedirs_dict: Dict[IdentifyingContext, Path] = {a_session_folder.context:a_session_folder.path for a_session_folder in good_session_concrete_folders}\\nincluded_session_contexts, output_python_scripts, output_slurm_scripts = generate_batch_single_session_scripts(global_data_root_parent_path, session_batch_basedirs=session_basedirs_dict, included_session_contexts=included_session_contexts, output_directory=Path('output/generated_slurm_scripts/').resolve(), use_separate_run_directories=True)\\noutput_python_scripts\\n\\nincluded_session_batch_progress_df = batch_progress_df[np.isin(batch_progress_df['context'].values, included_session_contexts)]\\nwith pd.option_context('display.max_rows', 10, 'display.max_columns', None):  # more options can be specified also\\n    display(included_session_batch_progress_df)\"}, {'cell_type': 'markdown', 'id': '71584edc', 'metadata': {}, 'source': '# Execute Batch'}, {'cell_type': 'code', 'execution_count': 7, 'id': 'ab6ae279', 'metadata': {'notebookRunGroups': {'groupValue': '1'}, 'scrolled': True, 'tags': []}, 'outputs': [{'name': 'stdout', 'output_type': 'stream', 'text': 'len(included_session_contexts): 15\\nBeginning processing with len(included_session_contexts): 15\\nbuild_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-08_14-26-15\"):build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-09_1-22-43\"):build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-12_15-55-31\"):build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-07_16-40-19\"):build_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-08_21-16-25\"):\\n\\n\\n\\n\\n\\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-08_14-26-15 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-08_14-26-15.log\\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-09_1-22-43 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-09_1-22-43.log\\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-12_15-55-31 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.one.2006-6-12_15-55-31.log\\n\\n\\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-07_16-40-19 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-07_16-40-19.log\\n\\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-08_21-16-25 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-08_21-16-25.log\\n\\n========================== runBatch STARTING ==========================\\n========================== runBatch STARTING ==========================\\tglobal_data_root_parent_path: /home/halechr/cloud/turbo/Data\\n\\n\\tglobal_data_root_parent_path: /home/halechr/cloud/turbo/Data\\tsession_context: kdiba_gor01_one_2006-6-08_14-26-15\\n\\n\\tsession_context: kdiba_gor01_one_2006-6-09_1-22-43\\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15\\n\\n\\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43__________________________________________________________________\\n\\n__________________________________________________________________basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15\\n\\nbasedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43active_data_mode_name: kdiba\\n\\nactive_data_mode_name: kdiba\\nLoading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl... Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl... ========================== runBatch STARTING ==========================\\n========================== runBatch STARTING ==========================\\n\\tglobal_data_root_parent_path: /home/halechr/cloud/turbo/Data========================== runBatch STARTING ==========================\\n\\tglobal_data_root_parent_path: /home/halechr/cloud/turbo/Data\\n\\tsession_context: kdiba_gor01_one_2006-6-12_15-55-31\\n\\tglobal_data_root_parent_path: /home/halechr/cloud/turbo/Data\\n\\tsession_context: kdiba_gor01_two_2006-6-07_16-40-19\\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31\\n\\n\\n\\tsession_context: kdiba_gor01_two_2006-6-08_21-16-25\\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19__________________________________________________________________\\n\\n\\n\\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25__________________________________________________________________basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31\\n\\n\\n__________________________________________________________________basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19active_data_mode_name: kdiba\\n\\n\\nbasedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25active_data_mode_name: kdiba\\n\\nLoading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl...active_data_mode_name: kdiba \\nLoading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl... Loading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl... done.\\nLoading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl.\\nproperties already present in pickled version. No need to save.\\npipeline load success!\\nusing provided computation_functions_name_includelist: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'position_decoding\\']\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\\nsaving_mode.shouldSave == False, so not saving at the end of batch_load_session\\non_complete_success_execution_session(curr_session_context: kdiba_gor01_one_2006-6-09_1-22-43, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43, ...)\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nwere pipeline preprocessing parameters missing and updated?: False\\nWARNING: filtered_contexts[\\'maze1_any\\']\\'s actual context name is incorrect. \\n\\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: filtered_contexts[long_epoch_name]\\'s actual context name is incorrect. \\n\\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: basic pipleine was updated by post_compute_validate and needs to be saved to be correct.Overriding self.save_mode to ensure pipeline is saved!\\nfinalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl\\ndone.\\nLoading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl.\\nproperties already present in pickled version. No need to save.\\npipeline load success!\\nusing provided computation_functions_name_includelist: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'position_decoding\\']\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\\nsaving_mode.shouldSave == False, so not saving at the end of batch_load_session\\non_complete_success_execution_session(curr_session_context: kdiba_gor01_one_2006-6-12_15-55-31, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31, ...)\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nwere pipeline preprocessing parameters missing and updated?: False\\nWARNING: filtered_contexts[\\'maze1_any\\']\\'s actual context name is incorrect. \\n\\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: filtered_contexts[long_epoch_name]\\'s actual context name is incorrect. \\n\\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: basic pipleine was updated by post_compute_validate and needs to be saved to be correct.Overriding self.save_mode to ensure pipeline is saved!\\nfinalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl\\nSaving (file mode \\'None\\') saved session pickle file results : None... Saving (file mode \\'None\\') saved session pickle file results : None... done.\\nmoving new output at \\'/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/20231109201937-loadedSessPickle.pkl\\' -> to desired location: \\'/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/loadedSessPickle.pkl\\'\\nWARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.\\n_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\\nincluded includelist is specified: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'ratemap_peaks_prominence2d\\', \\'position_decoding\\', \\'position_decoding_two_step\\', \\'spike_burst_detection\\', \\'split_to_directional_laps\\', \\'rank_order_shuffle_analysis\\'], so only performing these extended computations.\\nRunning batch_extended_computations(...) with global_epoch_name: \"maze_any\"\\npf_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npf_computation missing.\\n\\t Recomputing pf_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_placefields... done.\\nLoading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl.\\nproperties already present in pickled version. No need to save.using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\npipeline load success!\\n\\t done.\\nRecomputing active_epoch_placefields2D... using provided computation_functions_name_includelist: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'position_decoding\\']\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\\nsaving_mode.shouldSave == False, so not saving at the end of batch_load_session\\non_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-07_16-40-19, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19, ...)\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nwere pipeline preprocessing parameters missing and updated?: False\\nWARNING: filtered_contexts[\\'maze1_any\\']\\'s actual context name is incorrect. \\n\\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: filtered_contexts[long_epoch_name]\\'s actual context name is incorrect. \\n\\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: basic pipleine was updated by post_compute_validate and needs to be saved to be correct.Overriding self.save_mode to ensure pipeline is saved!\\nfinalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl\\nusing self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_placefields2D... done.\\nmoving new output at \\'/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/20231109201938-loadedSessPickle.pkl\\' -> to desired location: \\'/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl\\'\\nWARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.\\n_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\\nincluded includelist is specified: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'ratemap_peaks_prominence2d\\', \\'position_decoding\\', \\'position_decoding_two_step\\', \\'spike_burst_detection\\', \\'split_to_directional_laps\\', \\'rank_order_shuffle_analysis\\'], so only performing these extended computations.\\nRunning batch_extended_computations(...) with global_epoch_name: \"maze_any\"\\npf_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npf_computation missing.\\n\\t Recomputing pf_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_placefields... Saving (file mode \\'None\\') saved session pickle file results : None... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_placefields2D... done.\\nLoading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl.\\nproperties already present in pickled version. No need to save.\\npipeline load success!\\nusing provided computation_functions_name_includelist: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'position_decoding\\']\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\n\\t done.WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\n\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\n\\t done.\\npfdt_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npfdt_computation missing.\\n\\t Recomputing pfdt_computation...\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-NonePerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\\nsaving_mode.shouldSave == False, so not saving at the end of batch_load_session\\non_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-08_21-16-25, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25, ...)\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_dataRecomputing active_epoch_time_dependent_placefields...\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\n DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nwere pipeline preprocessing parameters missing and updated?: False\\nWARNING: filtered_contexts[\\'maze1_any\\']\\'s actual context name is incorrect. \\n\\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: filtered_contexts[long_epoch_name]\\'s actual context name is incorrect. \\n\\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: basic pipleine was updated by post_compute_validate and needs to be saved to be correct.Overriding self.save_mode to ensure pipeline is saved!\\nfinalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl\\nusing self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\nusing self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nRecomputing active_epoch_placefields2D... \\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... Saving (file mode \\'None\\') saved session pickle file results : None... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\ndone.\\nLoading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl.\\nRecomputing active_epoch_time_dependent_placefields... properties already present in pickled version. No need to save.\\npipeline load success!\\nusing provided computation_functions_name_includelist: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'position_decoding\\']\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\\nsaving_mode.shouldSave == False, so not saving at the end of batch_load_session\\non_complete_success_execution_session(curr_session_context: kdiba_gor01_one_2006-6-08_14-26-15, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15, ...)\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nwere pipeline preprocessing parameters missing and updated?: False\\nWARNING: filtered_contexts[\\'maze1_any\\']\\'s actual context name is incorrect. \\n\\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: filtered_contexts[long_epoch_name]\\'s actual context name is incorrect. \\n\\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: basic pipleine was updated by post_compute_validate and needs to be saved to be correct.Overriding self.save_mode to ensure pipeline is saved!\\nfinalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl\\nusing self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_time_dependent_placefields... Saving (file mode \\'None\\') saved session pickle file results : None... using self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_time_dependent_placefields... done.\\nmoving new output at \\'/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/20231109202014-loadedSessPickle.pkl\\' -> to desired location: \\'/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl\\'\\nWARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.\\n_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\\nusing self.config.grid_bin_bounds_1D: (28.300282316379977, 259.30028231638)\\nincluded includelist is specified: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'ratemap_peaks_prominence2d\\', \\'position_decoding\\', \\'position_decoding_two_step\\', \\'spike_burst_detection\\', \\'split_to_directional_laps\\', \\'rank_order_shuffle_analysis\\'], so only performing these extended computations.\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... Running batch_extended_computations(...) with global_epoch_name: \"maze_any\"\\npf_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npf_computation missing.\\n\\t Recomputing pf_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((28.300282316379977, 259.30028231638), (128.30369397123394, 154.72988093974095))\\n\\t done.\\n\\t done.\\nposition_decoding, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\nposition_decoding missing.\\n\\t Recomputing position_decoding...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nusing self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_placefields2D... done.\\nmoving new output at \\'/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/20231109202007-loadedSessPickle.pkl\\' -> to desired location: \\'/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl\\'\\nusing self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_placefields2D... WARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.\\n_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\\nincluded includelist is specified: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'ratemap_peaks_prominence2d\\', \\'position_decoding\\', \\'position_decoding_two_step\\', \\'spike_burst_detection\\', \\'split_to_directional_laps\\', \\'rank_order_shuffle_analysis\\'], so only performing these extended computations.\\nRunning batch_extended_computations(...) with global_epoch_name: \"maze_any\"\\npf_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npf_computation missing.\\n\\t Recomputing pf_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nusing self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\nRecomputing active_epoch_placefields... \\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nusing self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_placefields2D... Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_placefields2D... Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nusing self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\n\\t done.\\nusing self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_placefields... Recomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\n\\t done.\\npfdt_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npfdt_computation missing.\\n\\t Recomputing pfdt_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_placefields2D... done.\\nmoving new output at \\'/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/20231109202031-loadedSessPickle.pkl\\' -> to desired location: \\'/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl\\'\\nusing self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... WARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.\\n_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\\nincluded includelist is specified: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'ratemap_peaks_prominence2d\\', \\'position_decoding\\', \\'position_decoding_two_step\\', \\'spike_burst_detection\\', \\'split_to_directional_laps\\', \\'rank_order_shuffle_analysis\\'], so only performing these extended computations.\\nRunning batch_extended_computations(...) with global_epoch_name: \"maze_any\"\\npf_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npf_computation missing.\\n\\t Recomputing pf_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_placefields2D... Performing run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nusing self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\nusing self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... \\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\t done.\\n\\t done.\\npfdt_computation, maze_any already computed.using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\n\\n\\tforce_recompute is true so recomputing anyway\\npfdt_computation missing.\\n\\t Recomputing pfdt_computation...\\n\\t done.\\n\\t done.\\npfdt_computation, maze_any already computed.Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n\\n\\tforce_recompute is true so recomputing anyway\\npfdt_computation missing.\\n\\t Recomputing pfdt_computation...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_placefields2D... Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\nusing self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\n\\t done.\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_time_dependent_placefields...Recomputing active_epoch_placefields...  using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nusing self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\nRecomputing active_epoch_time_dependent_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nusing self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))Recomputing active_epoch_time_dependent_placefields2D... \\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\nusing self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... \\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_placefields2D...using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337)) \\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nusing self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\nRecomputing active_epoch_time_dependent_placefields2D... \\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nusing self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\nRecomputing active_epoch_time_dependent_placefields... \\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\t done.\\n\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (36.58620390950715, 248.91627658974846)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\n\\t done.\\n\\t done.using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\npfdt_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npfdt_computation missing.\\n\\t Recomputing pfdt_computation...\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... Recomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... Performing run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nusing self.config.grid_bin_bounds: ((36.58620390950715, 248.91627658974846), (132.81136363636367, 149.2840909090909))\\n\\t done.\\n\\t done.\\nposition_decoding, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\nposition_decoding missing.\\n\\t Recomputing position_decoding...\\nusing self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.397021260868584, 245.3970212608686)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.397021260868584, 245.3970212608686), (133.66465594522782, 155.97244934208123))\\n\\t done.\\n\\t done.\\nposition_decoding, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\nposition_decoding missing.\\n\\t Recomputing position_decoding...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nusing self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\n\\t done.using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\n\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_time_dependent_placefields... \\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\\n\\t done.\\n\\t done.\\nposition_decoding, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\nposition_decoding missing.\\n\\t Recomputing position_decoding...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nusing self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_time_dependent_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nusing self.config.grid_bin_bounds_1D: (29.16, 261.7)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.16, 261.7), (130.23, 150.99))\\n\\t done.\\n\\t done.\\nposition_decoding, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\nposition_decoding missing.\\n\\t Recomputing position_decoding...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\n\\t done.\\nposition_decoding_two_step missing.\\n\\t Recomputing position_decoding_two_step...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (17657,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (11455,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (31477,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (18156,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (12657,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (32002,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (18467,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (12943,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (32287,)\\n\\t done.\\nException occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\\n Inner exception: \\'pf1D_TwoStepDecoder\\'\\nERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_gor01_one_2006-6-12_15-55-31. error: !! \\'pf1D_TwoStepDecoder\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'pf1D_TwoStepDecoder\\'), <traceback object at 0x15135425a4c0>)\\nno changes in global results.\\nskipping figure generation because should_perform_figure_generation_to_file == False\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\t time since last computation: 0:00:00.006538\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5\\nOVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5!\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-12_15-55-31/output/pipeline_results.h5\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nWARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (26737,) should be less than time_window_edges: (20071,)!\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nWARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (26737,) should be less than time_window_edges: (20071,)!\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-12_15-55-31'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'ERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1510fa6d66c0>) while trying to build the session HDF output.\\nERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1510fc215f40>) while trying to build the session HDF output for kdiba_gor01_one_2006-6-12_15-55-31\\n\\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-12_15-55-31...\\nWARN: on_complete_success_execution_session: encountered exception !! \\'jonathan_firing_rate_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'jonathan_firing_rate_analysis\\'), <traceback object at 0x1512e0c52d80>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_gor01_one_2006-6-12_15-55-31]\\n\"========================== END BATCH ==========================\\n\\n\\nbuild_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-09_22-24-40\"):\\n\\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-09_22-24-40 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-09_22-24-40.log\\n========================== runBatch STARTING ==========================\\n\\tglobal_data_root_parent_path: /home/halechr/cloud/turbo/Data\\n\\tsession_context: kdiba_gor01_two_2006-6-09_22-24-40\\n\\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40\\n__________________________________________________________________\\nbasedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40\\nactive_data_mode_name: kdiba\\nLoading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl... Performing run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\ndone.\\nLoading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl.\\nproperties already present in pickled version. No need to save.\\npipeline load success!\\nusing provided computation_functions_name_includelist: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'position_decoding\\']\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\\nsaving_mode.shouldSave == False, so not saving at the end of batch_load_session\\non_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-09_22-24-40, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40, ...)\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nwere pipeline preprocessing parameters missing and updated?: False\\nWARNING: filtered_contexts[\\'maze1_any\\']\\'s actual context name is incorrect. \\n\\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: filtered_contexts[long_epoch_name]\\'s actual context name is incorrect. \\n\\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: basic pipleine was updated by post_compute_validate and needs to be saved to be correct.Overriding self.save_mode to ensure pipeline is saved!\\nfinalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl\\nSaving (file mode \\'None\\') saved session pickle file results : None... Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nWARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (18166,) should be less than time_window_edges: (12769,)!\\nWARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (18166,) should be less than time_window_edges: (12769,)!\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nWARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (44903,) should be less than time_window_edges: (34338,)!\\ndone.\\nmoving new output at \\'/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/20231109202616-loadedSessPickle.pkl\\' -> to desired location: \\'/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/loadedSessPickle.pkl\\'\\nWARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.\\n_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\\nincluded includelist is specified: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'ratemap_peaks_prominence2d\\', \\'position_decoding\\', \\'position_decoding_two_step\\', \\'spike_burst_detection\\', \\'split_to_directional_laps\\', \\'rank_order_shuffle_analysis\\'], so only performing these extended computations.\\nRunning batch_extended_computations(...) with global_epoch_name: \"maze_any\"\\npf_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npf_computation missing.\\n\\t Recomputing pf_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nWARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (44903,) should be less than time_window_edges: (34338,)!\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nusing self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nWARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (21408,) should be less than time_window_edges: (18527,)!\\nusing self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_placefields2D... WARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (21408,) should be less than time_window_edges: (18527,)!\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nusing self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\n\\t done.\\npfdt_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npfdt_computation missing.\\n\\t Recomputing pfdt_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... Performing run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nWARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (51395,) should be less than time_window_edges: (49637,)!\\nusing self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... WARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (51395,) should be less than time_window_edges: (49637,)!\\nusing self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... \\t done.\\nposition_decoding_two_step missing.\\n\\t Recomputing position_decoding_two_step...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nusing self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_time_dependent_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (19569,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_time_dependent_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (12399,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_time_dependent_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (34184,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_time_dependent_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (19094,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (29.088604852961407, 251.70402561515647)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (12085,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((29.088604852961407, 251.70402561515647), (138.496638485457, 153.496638485457))\\n\\t done.\\n\\t done.\\nposition_decoding, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\nposition_decoding missing.\\n\\t Recomputing position_decoding...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (33504,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (20270,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (12894,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': '\\t done.\\nposition_decoding_two_step missing.\\n\\t Recomputing position_decoding_two_step...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (30644,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (34680,)\\n\\t done.\\nException occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\\n Inner exception: \\'pf1D_TwoStepDecoder\\'\\nERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_gor01_two_2006-6-08_21-16-25. error: !! \\'pf1D_TwoStepDecoder\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'pf1D_TwoStepDecoder\\'), <traceback object at 0x151325f0f0c0>)\\nno changes in global results.\\nskipping figure generation because should_perform_figure_generation_to_file == False\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\t time since last computation: 0:00:00.007770\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5\\nOVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5!\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/pipeline_results.h5\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (18397,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-08_21-16-25'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'ERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1510e9378e80>) while trying to build the session HDF output.\\nERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1510e8b520c0>) while trying to build the session HDF output for kdiba_gor01_two_2006-6-08_21-16-25\\n\\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-08_21-16-25...\\nWARN: on_complete_success_execution_session: encountered exception !! \\'jonathan_firing_rate_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'jonathan_firing_rate_analysis\\'), <traceback object at 0x1510e8d6edc0>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_gor01_two_2006-6-08_21-16-25]\\n\"========================== END BATCH ==========================\\n\\n\\nbuild_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-12_16-53-46\"):\\n\\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-12_16-53-46 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.gor01.two.2006-6-12_16-53-46.log\\n========================== runBatch STARTING ==========================\\n\\tglobal_data_root_parent_path: /home/halechr/cloud/turbo/Data\\n\\tsession_context: kdiba_gor01_two_2006-6-12_16-53-46\\n\\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46\\n__________________________________________________________________\\nbasedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46\\nactive_data_mode_name: kdiba\\nLoading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (50031,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'done.\\nLoading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl.\\nproperties already present in pickled version. No need to save.\\npipeline load success!\\nusing provided computation_functions_name_includelist: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'position_decoding\\']\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\n\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\\nsaving_mode.shouldSave == False, so not saving at the end of batch_load_session\\non_complete_success_execution_session(curr_session_context: kdiba_gor01_two_2006-6-12_16-53-46, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46, ...)\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nwere pipeline preprocessing parameters missing and updated?: False\\nWARNING: filtered_contexts[\\'maze1_any\\']\\'s actual context name is incorrect. \\n\\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: filtered_contexts[long_epoch_name]\\'s actual context name is incorrect. \\n\\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: basic pipleine was updated by post_compute_validate and needs to be saved to be correct.Overriding self.save_mode to ensure pipeline is saved!\\nfinalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl\\nSaving (file mode \\'None\\') saved session pickle file results : None... Performing run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (30241,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\ndone.\\nmoving new output at \\'/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/20231109202924-loadedSessPickle.pkl\\' -> to desired location: \\'/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/loadedSessPickle.pkl\\'\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (18554,)\\nWARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.\\n_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nincluded includelist is specified: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'ratemap_peaks_prominence2d\\', \\'position_decoding\\', \\'position_decoding_two_step\\', \\'spike_burst_detection\\', \\'split_to_directional_laps\\', \\'rank_order_shuffle_analysis\\'], so only performing these extended computations.\\nRunning batch_extended_computations(...) with global_epoch_name: \"maze_any\"\\npf_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npf_computation missing.\\n\\t Recomputing pf_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_placefields... '}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_placefields2D... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (49975,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (30745,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\n\\t done.\\npfdt_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npfdt_computation missing.\\n\\t Recomputing pfdt_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (18711,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... \\t done.\\nposition_decoding_two_step missing.\\n\\t Recomputing position_decoding_two_step...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nusing self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_time_dependent_placefields... '}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_time_dependent_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nusing self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (50132,)\\n\\t done.\\nException occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\\n Inner exception: \\'pf1D_TwoStepDecoder\\'\\nERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_gor01_one_2006-6-09_1-22-43. error: !! \\'pf1D_TwoStepDecoder\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'pf1D_TwoStepDecoder\\'), <traceback object at 0x15132393db00>)\\nno changes in global results.\\nskipping figure generation because should_perform_figure_generation_to_file == False\\nusing self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\t done.\\n\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\t time since last computation: 0:00:00.031135\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5\\nOVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5!\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_time_dependent_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (35523,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nusing self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... '}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (24.481516142738176, 255.4815161427382)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((24.481516142738176, 255.4815161427382), (132.49260896751392, 155.30747604466447))\\n\\t done.\\n\\t done.\\nposition_decoding, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\nposition_decoding missing.\\n\\t Recomputing position_decoding...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (37611,)\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-09_1-22-43'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'ERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x151050289bc0>) while trying to build the session HDF output.\\nERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x15104fecd800>) while trying to build the session HDF output for kdiba_gor01_one_2006-6-09_1-22-43\\n\\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-09_1-22-43...\\nWARN: on_complete_success_execution_session: encountered exception !! \\'jonathan_firing_rate_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'jonathan_firing_rate_analysis\\'), <traceback object at 0x1510503b5980>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_gor01_one_2006-6-09_1-22-43]\\n\"========================== END BATCH ==========================\\n\\n\\nbuild_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-09_17-29-30\"):\\n\\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-09_17-29-30 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-09_17-29-30.log\\n========================== runBatch STARTING ==========================\\n\\tglobal_data_root_parent_path: /home/halechr/cloud/turbo/Data\\n\\tsession_context: kdiba_vvp01_one_2006-4-09_17-29-30\\n\\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30\\n__________________________________________________________________\\nbasedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30\\nactive_data_mode_name: kdiba\\nLoading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl... Performing run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (76719,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'done.\\nLoading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl.\\nproperties already present in pickled version. No need to save.\\npipeline load success!\\nusing provided computation_functions_name_includelist: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'position_decoding\\']\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\\nsaving_mode.shouldSave == False, so not saving at the end of batch_load_session\\non_complete_success_execution_session(curr_session_context: kdiba_vvp01_one_2006-4-09_17-29-30, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30, ...)\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nwere pipeline preprocessing parameters missing and updated?: False\\nWARNING: filtered_contexts[\\'maze1_any\\']\\'s actual context name is incorrect. \\n\\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: filtered_contexts[long_epoch_name]\\'s actual context name is incorrect. \\n\\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: basic pipleine was updated by post_compute_validate and needs to be saved to be correct.Overriding self.save_mode to ensure pipeline is saved!\\nfinalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl\\nSaving (file mode \\'None\\') saved session pickle file results : None... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (34631,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nWARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (16001,) should be less than time_window_edges: (12999,)!\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'WARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (16001,) should be less than time_window_edges: (12999,)!\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nWARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (12076,) should be less than time_window_edges: (9109,)!\\nWARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (12076,) should be less than time_window_edges: (9109,)!\\ndone.\\nmoving new output at \\'/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/20231109203115-loadedSessPickle.pkl\\' -> to desired location: \\'/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl\\'\\nWARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.\\n_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\\nincluded includelist is specified: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'ratemap_peaks_prominence2d\\', \\'position_decoding\\', \\'position_decoding_two_step\\', \\'spike_burst_detection\\', \\'split_to_directional_laps\\', \\'rank_order_shuffle_analysis\\'], so only performing these extended computations.\\nRunning batch_extended_computations(...) with global_epoch_name: \"maze_any\"\\npf_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npf_computation missing.\\n\\t Recomputing pf_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (38409,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nusing self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_placefields2D... '}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nWARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (28077,) should be less than time_window_edges: (22715,)!\\nusing self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_placefields... WARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (28077,) should be less than time_window_edges: (22715,)!\\nusing self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nusing self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_placefields2D... \\t done.\\nposition_decoding_two_step missing.\\n\\t Recomputing position_decoding_two_step...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (12742,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (77100,)\\nusing self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_placefields2D... Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (9198,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\n\\t done.\\npfdt_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npfdt_computation missing.\\n\\t Recomputing pfdt_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... \\t done.\\nposition_decoding_two_step missing.\\n\\t Recomputing position_decoding_two_step...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nusing self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... '}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (22940,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (12210,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (36136,)\\nusing self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_time_dependent_placefields... '}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (35433,)\\nusing self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (8541,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_time_dependent_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (21807,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (24514,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_time_dependent_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (13127,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (38641,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (9198,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nusing self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Recomputing active_epoch_time_dependent_placefields... '}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (28.54313873072426, 255.54313873072425)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((28.54313873072426, 255.54313873072425), (-55.2405385510412, -12.237798967230454))\\n\\t done.\\n\\t done.\\nposition_decoding, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\nposition_decoding missing.\\n\\t Recomputing position_decoding...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (22940,)\\n\\t done.\\nException occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\\n Inner exception: \\'pf1D_TwoStepDecoder\\'\\nERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_gor01_two_2006-6-12_16-53-46. error: !! \\'pf1D_TwoStepDecoder\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'pf1D_TwoStepDecoder\\'), <traceback object at 0x1510e890fb00>)\\nno changes in global results.\\nskipping figure generation because should_perform_figure_generation_to_file == False\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\t time since last computation: 0:00:00.007087\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5\\nOVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5!\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-12_16-53-46/output/pipeline_results.h5\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-12_16-53-46'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'ERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x151356f89900>) while trying to build the session HDF output.\\nERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x15109ae3e300>) while trying to build the session HDF output for kdiba_gor01_two_2006-6-12_16-53-46\\n\\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-12_16-53-46...\\nWARN: on_complete_success_execution_session: encountered exception !! \\'jonathan_firing_rate_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'jonathan_firing_rate_analysis\\'), <traceback object at 0x151356ced380>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_gor01_two_2006-6-12_16-53-46]\\n\"========================== END BATCH ==========================\\n\\n\\nbuild_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-10_12-25-50\"):\\n\\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-10_12-25-50 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.one.2006-4-10_12-25-50.log\\n========================== runBatch STARTING ==========================\\n\\tglobal_data_root_parent_path: /home/halechr/cloud/turbo/Data\\n\\tsession_context: kdiba_vvp01_one_2006-4-10_12-25-50\\n\\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50\\n__________________________________________________________________\\nbasedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50\\nactive_data_mode_name: kdiba\\nLoading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (61667,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (35751,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (77332,)\\n\\t done.\\nException occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\\n Inner exception: \\'pf1D_TwoStepDecoder\\'\\nERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_gor01_two_2006-6-07_16-40-19. error: !! \\'pf1D_TwoStepDecoder\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'pf1D_TwoStepDecoder\\'), <traceback object at 0x151356cad980>)\\nno changes in global results.\\nskipping figure generation because should_perform_figure_generation_to_file == False\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\t time since last computation: 0:00:00.007148\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5\\nOVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5!\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/pipeline_results.h5\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nWARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (32341,) should be less than time_window_edges: (26888,)!\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (24308,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'WARNING: PREVIOUSLY ASSERT: \\n\\t spikes_df[time_variable_name]: (32341,) should be less than time_window_edges: (26888,)!\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-07_16-40-19'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'ERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1511f7c1efc0>) while trying to build the session HDF output.\\nERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x15117052ce40>) while trying to build the session HDF output for kdiba_gor01_two_2006-6-07_16-40-19\\n\\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-07_16-40-19...\\nWARN: on_complete_success_execution_session: encountered exception !! \\'jonathan_firing_rate_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'jonathan_firing_rate_analysis\\'), <traceback object at 0x1513544f3280>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_gor01_two_2006-6-07_16-40-19]\\n\"========================== END BATCH ==========================\\n\\n\\nbuild_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-09_16-40-54\"):\\n\\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-09_16-40-54 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-09_16-40-54.log\\n========================== runBatch STARTING ==========================\\n\\tglobal_data_root_parent_path: /home/halechr/cloud/turbo/Data\\n\\tsession_context: kdiba_vvp01_two_2006-4-09_16-40-54\\n\\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54\\n__________________________________________________________________\\nbasedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54\\nactive_data_mode_name: kdiba\\nLoading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (61692,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'done.\\nLoading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl.\\nproperties already present in pickled version. No need to save.\\npipeline load success!\\nusing provided computation_functions_name_includelist: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'position_decoding\\']\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\\nsaving_mode.shouldSave == False, so not saving at the end of batch_load_session\\non_complete_success_execution_session(curr_session_context: kdiba_vvp01_one_2006-4-10_12-25-50, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50, ...)\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nwere pipeline preprocessing parameters missing and updated?: False\\nWARNING: filtered_contexts[\\'maze1_any\\']\\'s actual context name is incorrect. \\n\\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: filtered_contexts[long_epoch_name]\\'s actual context name is incorrect. \\n\\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: basic pipleine was updated by post_compute_validate and needs to be saved to be correct.Overriding self.save_mode to ensure pipeline is saved!\\nfinalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl\\nSaving (file mode \\'None\\') saved session pickle file results : None... done.\\nLoading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl.\\nproperties already present in pickled version. No need to save.\\npipeline load success!\\nusing provided computation_functions_name_includelist: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'position_decoding\\']\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\\nsaving_mode.shouldSave == False, so not saving at the end of batch_load_session\\non_complete_success_execution_session(curr_session_context: kdiba_vvp01_two_2006-4-09_16-40-54, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54, ...)\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nwere pipeline preprocessing parameters missing and updated?: False\\nWARNING: filtered_contexts[\\'maze1_any\\']\\'s actual context name is incorrect. \\n\\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: filtered_contexts[long_epoch_name]\\'s actual context name is incorrect. \\n\\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: basic pipleine was updated by post_compute_validate and needs to be saved to be correct.Overriding self.save_mode to ensure pipeline is saved!\\nfinalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nSaving (file mode \\'None\\') saved session pickle file results : None... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (36246,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (25095,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'done.\\nmoving new output at \\'/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/20231109203335-loadedSessPickle.pkl\\' -> to desired location: \\'/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/loadedSessPickle.pkl\\'\\nWARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.\\n_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\\nincluded includelist is specified: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'ratemap_peaks_prominence2d\\', \\'position_decoding\\', \\'position_decoding_two_step\\', \\'spike_burst_detection\\', \\'split_to_directional_laps\\', \\'rank_order_shuffle_analysis\\'], so only performing these extended computations.\\nRunning batch_extended_computations(...) with global_epoch_name: \"maze_any\"\\npf_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npf_computation missing.\\n\\t Recomputing pf_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_placefields... done.\\nmoving new output at \\'/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/20231109203331-loadedSessPickle.pkl\\' -> to desired location: \\'/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/loadedSessPickle.pkl\\'\\nWARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.\\n_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nincluded includelist is specified: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'ratemap_peaks_prominence2d\\', \\'position_decoding\\', \\'position_decoding_two_step\\', \\'spike_burst_detection\\', \\'split_to_directional_laps\\', \\'rank_order_shuffle_analysis\\'], so only performing these extended computations.\\nRunning batch_extended_computations(...) with global_epoch_name: \"maze_any\"\\npf_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npf_computation missing.\\n\\t Recomputing pf_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (62479,)\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_placefields2D... \\t done.\\nException occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\\n Inner exception: \\'pf1D_TwoStepDecoder\\'\\nERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_gor01_one_2006-6-08_14-26-15. error: !! \\'pf1D_TwoStepDecoder\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'pf1D_TwoStepDecoder\\'), <traceback object at 0x151323bc6140>)\\nno changes in global results.\\nskipping figure generation because should_perform_figure_generation_to_file == False\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\t time since last computation: 0:00:00.013089\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5\\nOVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5!\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/pipeline_results.h5\\nusing self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nusing self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\nusing self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\t done.\\n\\t done.\\npfdt_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npfdt_computation missing.\\n\\t Recomputing pfdt_computation...\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_placefields... Recomputing active_epoch_time_dependent_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nusing self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... '}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-08_14-26-15'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'ERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x151354203d80>) while trying to build the session HDF output.\\nERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x151212becc00>) while trying to build the session HDF output for kdiba_gor01_one_2006-6-08_14-26-15\\n\\t doing specific instantaneous firing rate computation for context: kdiba_gor01_one_2006-6-08_14-26-15...\\nWARN: on_complete_success_execution_session: encountered exception !! \\'jonathan_firing_rate_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'jonathan_firing_rate_analysis\\'), <traceback object at 0x151356ddbf80>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_gor01_one_2006-6-08_14-26-15]\\n\"========================== END BATCH ==========================\\n\\n\\nbuild_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-10_12-58-3\"):\\n\\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-10_12-58-3 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.vvp01.two.2006-4-10_12-58-3.log\\n========================== runBatch STARTING ==========================\\n\\tglobal_data_root_parent_path: /home/halechr/cloud/turbo/Data\\n\\tsession_context: kdiba_vvp01_two_2006-4-10_12-58-3\\n\\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3\\n__________________________________________________________________\\nbasedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3\\nactive_data_mode_name: kdiba\\nLoading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nusing self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\t done.\\n\\t done.\\npfdt_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npfdt_computation missing.\\n\\t Recomputing pfdt_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... done.\\nLoading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl.\\nusing self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\nproperties already present in pickled version. No need to save.\\npipeline load success!\\t done.\\n\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nusing provided computation_functions_name_includelist: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'position_decoding\\']\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\nRecomputing active_epoch_time_dependent_placefields... \\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\nusing self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\nRecomputing active_epoch_time_dependent_placefields...\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter. \\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\\nsaving_mode.shouldSave == False, so not saving at the end of batch_load_session\\non_complete_success_execution_session(curr_session_context: kdiba_vvp01_two_2006-4-10_12-58-3, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3, ...)\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nwere pipeline preprocessing parameters missing and updated?: False\\nWARNING: filtered_contexts[\\'maze1_any\\']\\'s actual context name is incorrect. \\n\\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: filtered_contexts[long_epoch_name]\\'s actual context name is incorrect. \\n\\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: basic pipleine was updated by post_compute_validate and needs to be saved to be correct.Overriding self.save_mode to ensure pipeline is saved!\\nfinalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl\\nSaving (file mode \\'None\\') saved session pickle file results : None... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (29.64642522460817, 257.8732552112081)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((29.64642522460817, 257.8732552112081), (106.68603845428224, 146.71219371189815))\\n\\t done.\\n\\t done.\\nposition_decoding, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\nposition_decoding missing.\\n\\t Recomputing position_decoding...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nusing self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... done.\\nmoving new output at \\'/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/20231109203449-loadedSessPickle.pkl\\' -> to desired location: \\'/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl\\'\\nWARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.\\n_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\\nincluded includelist is specified: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'ratemap_peaks_prominence2d\\', \\'position_decoding\\', \\'position_decoding_two_step\\', \\'spike_burst_detection\\', \\'split_to_directional_laps\\', \\'rank_order_shuffle_analysis\\'], so only performing these extended computations.\\nRunning batch_extended_computations(...) with global_epoch_name: \"maze_any\"using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\npf_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\n\\t done.pf_computation missing.\\n\\t Recomputing pf_computation...\\n\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (25.5637332724328, 257.964172947664)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nusing self.config.grid_bin_bounds: ((25.5637332724328, 257.964172947664), (89.1844223602494, 131.92462510535915))\\n\\t done.\\n\\t done.\\nposition_decoding, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\nposition_decoding missing.\\n\\t Recomputing position_decoding...\\nusing self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nusing self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\n\\t done.\\npfdt_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npfdt_computation missing.\\n\\t Recomputing pfdt_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nusing self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_time_dependent_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nusing self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nusing self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (30.511181558838498, 247.5111815588389)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((30.511181558838498, 247.5111815588389), (106.97411662767412, 147.52430924258078))\\n\\t done.\\n\\t done.\\nposition_decoding, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\nposition_decoding missing.\\n\\t Recomputing position_decoding...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:330: RuntimeWarning: invalid value encountered in divide\\n  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': '\\t done.\\nposition_decoding_two_step missing.\\n\\t Recomputing position_decoding_two_step...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (26133,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (49904,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (77176,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (27155,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (49317,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': '\\t done.\\nposition_decoding_two_step missing.\\n\\t Recomputing position_decoding_two_step...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (24427,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (77508,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (13517,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (27155,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (49904,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': '\\t done.\\nposition_decoding_two_step missing.\\n\\t Recomputing position_decoding_two_step...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (40280,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (25452,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (77624,)\\n\\t done.\\nException occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\\n Inner exception: \\'pf1D_TwoStepDecoder\\'\\nERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_gor01_two_2006-6-09_22-24-40. error: !! \\'pf1D_TwoStepDecoder\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'pf1D_TwoStepDecoder\\'), <traceback object at 0x15135475c900>)\\nno changes in global results.\\nskipping figure generation because should_perform_figure_generation_to_file == False\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\t time since last computation: 0:00:00.006981\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5\\nOVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5!\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/2006-6-09_22-24-40/output/pipeline_results.h5\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (23382,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (14450,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (13880,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-09_22-24-40'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'ERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1510fd5b1140>) while trying to build the session HDF output.\\nERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1510fbd8bfc0>) while trying to build the session HDF output for kdiba_gor01_two_2006-6-09_22-24-40\\n\\t doing specific instantaneous firing rate computation for context: kdiba_gor01_two_2006-6-09_22-24-40...\\nWARN: on_complete_success_execution_session: encountered exception !! \\'jonathan_firing_rate_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'jonathan_firing_rate_analysis\\'), <traceback object at 0x1510fc43e080>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_gor01_two_2006-6-09_22-24-40]\\n\"========================== END BATCH ==========================\\n\\n\\nbuild_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-02_17-46-44\"):\\n\\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-02_17-46-44 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-02_17-46-44.log\\n========================== runBatch STARTING ==========================\\n\\tglobal_data_root_parent_path: /home/halechr/cloud/turbo/Data\\n\\tsession_context: kdiba_pin01_one_11-02_17-46-44\\n\\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44\\n__________________________________________________________________\\nbasedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44\\nactive_data_mode_name: kdiba\\nLoading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (42597,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (40690,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (25391,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'done.\\nLoading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl.\\nproperties already present in pickled version. No need to save.\\npipeline load success!\\nusing provided computation_functions_name_includelist: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'position_decoding\\']\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\\nsaving_mode.shouldSave == False, so not saving at the end of batch_load_session\\non_complete_success_execution_session(curr_session_context: kdiba_pin01_one_11-02_17-46-44, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44, ...)\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nwere pipeline preprocessing parameters missing and updated?: False\\nWARNING: filtered_contexts[\\'maze1_any\\']\\'s actual context name is incorrect. \\n\\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: filtered_contexts[long_epoch_name]\\'s actual context name is incorrect. \\n\\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: basic pipleine was updated by post_compute_validate and needs to be saved to be correct.Overriding self.save_mode to ensure pipeline is saved!\\nfinalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl\\nSaving (file mode \\'None\\') saved session pickle file results : None... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (14088,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (25027,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (14069,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'done.\\nmoving new output at \\'/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/20231109203826-loadedSessPickle.pkl\\' -> to desired location: \\'/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/loadedSessPickle.pkl\\'\\nWARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.\\n_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\\nincluded includelist is specified: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'ratemap_peaks_prominence2d\\', \\'position_decoding\\', \\'position_decoding_two_step\\', \\'spike_burst_detection\\', \\'split_to_directional_laps\\', \\'rank_order_shuffle_analysis\\'], so only performing these extended computations.\\nRunning batch_extended_computations(...) with global_epoch_name: \"maze_any\"\\npf_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npf_computation missing.\\n\\t Recomputing pf_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (42231,)\\nusing self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_placefields2D... Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nusing self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (26171,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (40880,)\\nusing self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_placefields2D... \\t done.\\nException occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\\n Inner exception: \\'pf1D_TwoStepDecoder\\'\\nERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_vvp01_one_2006-4-09_17-29-30. error: !! \\'pf1D_TwoStepDecoder\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'pf1D_TwoStepDecoder\\'), <traceback object at 0x151354209b80>)\\nno changes in global results.\\nskipping figure generation because should_perform_figure_generation_to_file == False\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\t time since last computation: 0:00:00.006515\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5\\nOVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5!\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/output/pipeline_results.h5\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (14863,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nusing self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_placefields... '}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\n\\t done.\\npfdt_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npfdt_computation missing.\\n\\t Recomputing pfdt_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... '}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-09_17-29-30'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)ERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x151356c49ec0>) while trying to build the session HDF output.\\n\\nERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x151323ab2900>) while trying to build the session HDF output for kdiba_vvp01_one_2006-4-09_17-29-30\\n\\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_one_2006-4-09_17-29-30...\\nWARN: on_complete_success_execution_session: encountered exception !! \\'jonathan_firing_rate_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'jonathan_firing_rate_analysis\\'), <traceback object at 0x151356e74f00>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_vvp01_one_2006-4-09_17-29-30]\\n\\t done.\"========================== END BATCH ==========================\\n\\n\\nRecomputing active_epoch_time_dependent_placefields2D... \\nbuild_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-02_19-28-0\"):\\n\\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-02_19-28-0 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-02_19-28-0.log\\n========================== runBatch STARTING ==========================\\n\\tglobal_data_root_parent_path: /home/halechr/cloud/turbo/Data\\n\\tsession_context: kdiba_pin01_one_11-02_19-28-0\\n\\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0\\n__________________________________________________________________\\nbasedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0\\nactive_data_mode_name: kdiba\\nLoading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... done.\\nLoading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl.\\nproperties already present in pickled version. No need to save.\\npipeline load success!\\nusing provided computation_functions_name_includelist: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'position_decoding\\']\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\\nsaving_mode.shouldSave == False, so not saving at the end of batch_load_session\\non_complete_success_execution_session(curr_session_context: kdiba_pin01_one_11-02_19-28-0, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0, ...)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nwere pipeline preprocessing parameters missing and updated?: False\\nWARNING: filtered_contexts[\\'maze1_any\\']\\'s actual context name is incorrect. \\n\\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: filtered_contexts[long_epoch_name]\\'s actual context name is incorrect. \\n\\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: basic pipleine was updated by post_compute_validate and needs to be saved to be correct.Overriding self.save_mode to ensure pipeline is saved!\\nfinalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl\\nusing self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_time_dependent_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (43010,)\\n\\t done.\\nException occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\\n Inner exception: \\'pf1D_TwoStepDecoder\\'\\nERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_vvp01_two_2006-4-09_16-40-54. error: !! \\'pf1D_TwoStepDecoder\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'pf1D_TwoStepDecoder\\'), <traceback object at 0x151356beba80>)\\nno changes in global results.\\nskipping figure generation because should_perform_figure_generation_to_file == False\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_timesDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\n\\t time since last computation: 0:00:00.014339\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5\\nOVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5!\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-09_16-40-54/output/pipeline_results.h5\\nSaving (file mode \\'None\\') saved session pickle file results : None... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... '}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-09_16-40-54'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'ERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1511f854d580>) while trying to build the session HDF output.\\nERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1511f7e2da40>) while trying to build the session HDF output for kdiba_vvp01_two_2006-4-09_16-40-54\\n\\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_two_2006-4-09_16-40-54...\\nWARN: on_complete_success_execution_session: encountered exception !! \\'jonathan_firing_rate_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'jonathan_firing_rate_analysis\\'), <traceback object at 0x1511f8206a40>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_vvp01_two_2006-4-09_16-40-54]\\n\"========================== END BATCH ==========================\\n\\n\\nbuild_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-03_12-3-25\"):\\n\\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-03_12-3-25 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.11-03_12-3-25.log\\n========================== runBatch STARTING ==========================\\n\\tglobal_data_root_parent_path: /home/halechr/cloud/turbo/Data\\n\\tsession_context: kdiba_pin01_one_11-03_12-3-25\\n\\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25\\n__________________________________________________________________\\nbasedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25\\nactive_data_mode_name: kdiba\\nLoading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (26.927879930920472, 253.7869451377655)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((26.927879930920472, 253.7869451377655), (129.2279041328145, 152.2279041328145))\\n\\t done.\\n\\t done.\\nposition_decoding, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\nposition_decoding missing.\\n\\t Recomputing position_decoding...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\ndone.\\nmoving new output at \\'/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/20231109203925-loadedSessPickle.pkl\\' -> to desired location: \\'/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/loadedSessPickle.pkl\\'\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nWARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.\\n_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\\nincluded includelist is specified: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'ratemap_peaks_prominence2d\\', \\'position_decoding\\', \\'position_decoding_two_step\\', \\'spike_burst_detection\\', \\'split_to_directional_laps\\', \\'rank_order_shuffle_analysis\\'], so only performing these extended computations.\\nRunning batch_extended_computations(...) with global_epoch_name: \"maze_any\"\\npf_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npf_computation missing.\\n\\t Recomputing pf_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_placefields2D... \\t done.\\nposition_decoding_two_step missing.\\n\\t Recomputing position_decoding_two_step...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nusing self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_placefields2D... done.\\nLoading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl.\\nproperties already present in pickled version. No need to save.\\npipeline load success!\\nusing provided computation_functions_name_includelist: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'position_decoding\\']\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\n\\t done.WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\n\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\\nsaving_mode.shouldSave == False, so not saving at the end of batch_load_session\\non_complete_success_execution_session(curr_session_context: kdiba_pin01_one_11-03_12-3-25, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25, ...)\\nRecomputing active_epoch_placefields... DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nwere pipeline preprocessing parameters missing and updated?: False\\nWARNING: filtered_contexts[\\'maze1_any\\']\\'s actual context name is incorrect. \\n\\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: filtered_contexts[long_epoch_name]\\'s actual context name is incorrect. \\n\\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: basic pipleine was updated by post_compute_validate and needs to be saved to be correct.Overriding self.save_mode to ensure pipeline is saved!\\nfinalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl\\nusing self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_placefields2D... Saving (file mode \\'None\\') saved session pickle file results : None... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nusing self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_placefields2D... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (25191,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nusing self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_placefields... '}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_placefields2D... done.\\nmoving new output at \\'/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/20231109203952-loadedSessPickle.pkl\\' -> to desired location: \\'/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/loadedSessPickle.pkl\\'\\nWARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.\\n_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\\nincluded includelist is specified: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'ratemap_peaks_prominence2d\\', \\'position_decoding\\', \\'position_decoding_two_step\\', \\'spike_burst_detection\\', \\'split_to_directional_laps\\', \\'rank_order_shuffle_analysis\\'], so only performing these extended computations.\\nRunning batch_extended_computations(...) with global_epoch_name: \"maze_any\"\\npf_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npf_computation missing.using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t Recomputing pf_computation...\\n\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_placefields... Recomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_placefields2D... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (12914,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nusing self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_placefields... '}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t done.\\n\\t done.\\npfdt_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npfdt_computation missing.\\n\\t Recomputing pfdt_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nusing self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\nRecomputing active_epoch_placefields... \\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_time_dependent_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nusing self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\n\\t done.\\npfdt_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npfdt_computation missing.\\n\\t Recomputing pfdt_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nusing self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\nRecomputing active_epoch_time_dependent_placefields... \\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... \\t done.\\nposition_decoding_two_step missing.\\n\\t Recomputing position_decoding_two_step...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_time_dependent_placefields... Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nusing self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (41198,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nusing self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_time_dependent_placefields... '}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.2851382680749, 246.39985985110218)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.2851382680749, 246.39985985110218), (133.85711719213543, 152.81579979839964))\\n\\t done.\\n\\t done.\\nposition_decoding, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\nposition_decoding missing.\\n\\t Recomputing position_decoding...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nusing self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (20.551685242617875, 249.52142297024744)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (26105,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((20.551685242617875, 249.52142297024744), (136.6282885482392, 154.9308054334688))\\n\\t done.\\n\\t done.\\nposition_decoding, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\nposition_decoding missing.\\n\\t Recomputing position_decoding...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (25889,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (13524,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (12800,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (42372,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (41776,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (26406,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (26312,)\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (13133,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': '\\t done.\\nposition_decoding_two_step missing.\\n\\t Recomputing position_decoding_two_step...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (18140,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (13343,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (8883,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (27638,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Performing run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (42435,)\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (18498,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (8972,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (42319,)\\n\\t done.\\nException occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\\n Inner exception: \\'pf1D_TwoStepDecoder\\'\\nERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_vvp01_one_2006-4-10_12-25-50. error: !! \\'pf1D_TwoStepDecoder\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'pf1D_TwoStepDecoder\\'), <traceback object at 0x151356d71b00>)\\nno changes in global results.\\nskipping figure generation because should_perform_figure_generation_to_file == False\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\t time since last computation: 0:00:00.007382\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5\\nOVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5!\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/2006-4-10_12-25-50/output/pipeline_results.h5\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (28191,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': '\\t done.\\nposition_decoding_two_step missing.\\n\\t Recomputing position_decoding_two_step...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-10_12-25-50'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'ERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1510e8897880>) while trying to build the session HDF output.\\nERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1510e8b04180>) while trying to build the session HDF output for kdiba_vvp01_one_2006-4-10_12-25-50\\n\\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_one_2006-4-10_12-25-50...\\nWARN: on_complete_success_execution_session: encountered exception !! \\'jonathan_firing_rate_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'jonathan_firing_rate_analysis\\'), <traceback object at 0x1510e8d61e40>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_vvp01_one_2006-4-10_12-25-50]\\n\"========================== END BATCH ==========================\\n\\n\\nbuild_batch_task_logger(module_name=\"gl0003.arc-ts.umich.edu.kdiba.pin01.one.fet11-01_12-58-54\"):\\n\\t Batch Task logger com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.fet11-01_12-58-54 has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.PhoPy3DPositionAnalyis.Batch.runBatch.run_specific_batch.gl0003.arc-ts.umich.edu.kdiba.pin01.one.fet11-01_12-58-54.log\\n========================== runBatch STARTING ==========================\\n\\tglobal_data_root_parent_path: /home/halechr/cloud/turbo/Data\\n\\tsession_context: kdiba_pin01_one_fet11-01_12-58-54\\n\\tsession_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54\\n__________________________________________________________________\\nbasedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54\\nactive_data_mode_name: kdiba\\nLoading loaded session pickle file results : /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (27018,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': '\\t done.\\nposition_decoding_two_step missing.\\n\\t Recomputing position_decoding_two_step...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (18921,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (9200,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (29250,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (14198,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (22234,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (11117,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (20672,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': \"two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (28419,)\\n\\t done.\\nException occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\\n Inner exception: 'pf1D_TwoStepDecoder'\\nERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_pin01_one_11-03_12-3-25. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x1511f85363c0>)\\nno changes in global results.\\nskipping figure generation because should_perform_figure_generation_to_file == False\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\t time since last computation: 0:00:00.031456\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5\\nOVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5!\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/pipeline_results.h5\\ndone.\\nLoading pickled pipeline success: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl.\\nproperties already present in pickled version. No need to save.\\npipeline load success!\\nusing provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\\n\\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\\nWARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\\nsaving_mode.shouldSave == False, so not saving at the end of batch_load_session\\non_complete_success_execution_session(curr_session_context: kdiba_pin01_one_fet11-01_12-58-54, curr_session_basedir: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54, ...)\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\\nwere pipeline preprocessing parameters missing and updated?: False\\nWARNING: filtered_contexts['maze1_any']'s actual context name is incorrect. \\n\\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \\n\\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\\n\\tUpdating it. (THIS IS A HACK)\\nWARNING: basic pipleine was updated by post_compute_validate and needs to be saved to be correct.Overriding self.save_mode to ensure pipeline is saved!\\nfinalized_loaded_sess_pickle_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl\\n\"}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '11-03_12-3-25'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'ERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x151170d27e40>) while trying to build the session HDF output.\\nERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1511f7e86140>) while trying to build the session HDF output for kdiba_pin01_one_11-03_12-3-25\\n\\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-03_12-3-25...\\nWARN: on_complete_success_execution_session: encountered exception !! \\'jonathan_firing_rate_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'jonathan_firing_rate_analysis\\'), <traceback object at 0x1511f8581180>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_pin01_one_11-03_12-3-25]\\n\"========================== END BATCH ==========================\\n\\n\\nSaving (file mode \\'None\\') saved session pickle file results : None... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (34083,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (21371,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (56616,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (10708,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (43046,)\\n\\t done.\\nException occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\\n Inner exception: \\'pf1D_TwoStepDecoder\\'\\nERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_vvp01_two_2006-4-10_12-58-3. error: !! \\'pf1D_TwoStepDecoder\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'pf1D_TwoStepDecoder\\'), <traceback object at 0x1512126a4780>)\\nno changes in global results.\\nskipping figure generation because should_perform_figure_generation_to_file == False\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\t time since last computation: 0:00:00.006420\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5\\nOVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5!\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (28766,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (33134,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (21882,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-10_12-58-3'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'ERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x151354192d80>) while trying to build the session HDF output.\\nERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x151212af4580>) while trying to build the session HDF output for kdiba_vvp01_two_2006-4-10_12-58-3\\n\\t doing specific instantaneous firing rate computation for context: kdiba_vvp01_two_2006-4-10_12-58-3...\\nWARN: on_complete_success_execution_session: encountered exception !! \\'jonathan_firing_rate_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'jonathan_firing_rate_analysis\\'), <traceback object at 0x1513541c6a00>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_vvp01_two_2006-4-10_12-58-3]\\n\"========================== END BATCH ==========================\\n\\n\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (22485,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (11282,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'done.\\nmoving new output at \\'/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/20231109204307-loadedSessPickle.pkl\\' -> to desired location: \\'/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/loadedSessPickle.pkl\\'\\nWARNING: self.force_global_recompute was False but pipeline was_updated. The global properties must be recomputed when the local functions change, so self.force_global_recompute will be set to True and computation will continue.\\n_perform_long_short_instantaneous_spike_rate_groups_analysis is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\\nincluded includelist is specified: [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\', \\'ratemap_peaks_prominence2d\\', \\'position_decoding\\', \\'position_decoding_two_step\\', \\'spike_burst_detection\\', \\'split_to_directional_laps\\', \\'rank_order_shuffle_analysis\\'], so only performing these extended computations.\\nRunning batch_extended_computations(...) with global_epoch_name: \"maze_any\"\\npf_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npf_computation missing.\\n\\t Recomputing pf_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (56351,)\\nusing self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_placefields2D... Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_placefields2D... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (34248,)\\nusing self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nException occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\\n Inner exception: \\'pf1D_TwoStepDecoder\\'\\nERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_pin01_one_11-02_19-28-0. error: !! \\'pf1D_TwoStepDecoder\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'pf1D_TwoStepDecoder\\'), <traceback object at 0x151323723280>)\\nno changes in global results.\\nskipping figure generation because should_perform_figure_generation_to_file == False\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\t time since last computation: 0:00:00.007958\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_placefields... pipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5\\nOVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5!\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_19-28-0/output/pipeline_results.h5\\nusing self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_placefields2D... '}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '11-02_19-28-0'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'ERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1512e0c40880>) while trying to build the session HDF output.\\nERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x151050331a00>) while trying to build the session HDF output for kdiba_pin01_one_11-02_19-28-0\\n\\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-02_19-28-0...\\nWARN: on_complete_success_execution_session: encountered exception !! \\'jonathan_firing_rate_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'jonathan_firing_rate_analysis\\'), <traceback object at 0x1513557dab00>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_pin01_one_11-02_19-28-0]\\n\"========================== END BATCH ==========================\\n\\n\\nusing self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_placefields2D... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (29250,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\n\\t done.\\npfdt_computation, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\npfdt_computation missing.\\n\\t Recomputing pfdt_computation...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nRecomputing active_epoch_time_dependent_placefields... two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (22102,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nusing self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'Recomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\nRecomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (22.403791476255435, 255.28121598502332)\\n\\t done.\\nRecomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((22.403791476255435, 255.28121598502332), (135.43617904962073, 153.6679723832235))\\n\\t done.\\n\\t done.\\nposition_decoding, maze_any already computed.\\n\\tforce_recompute is true so recomputing anyway\\nposition_decoding missing.\\n\\t Recomputing position_decoding...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\ntwo_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (56616,)\\n\\t done.\\nException occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\\n Inner exception: \\'pf1D_TwoStepDecoder\\'\\nERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_pin01_one_11-02_17-46-44. error: !! \\'pf1D_TwoStepDecoder\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'pf1D_TwoStepDecoder\\'), <traceback object at 0x1510fd79b200>)\\nno changes in global results.\\nskipping figure generation because should_perform_figure_generation_to_file == False\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\t time since last computation: 0:00:00.007295\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5\\nOVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5!\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-02_17-46-44/output/pipeline_results.h5\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '11-02_17-46-44'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'ERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1510fbf6a5c0>) while trying to build the session HDF output.\\nERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1510f96ea5c0>) while trying to build the session HDF output for kdiba_pin01_one_11-02_17-46-44\\n\\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_11-02_17-46-44...\\nWARN: on_complete_success_execution_session: encountered exception !! \\'jonathan_firing_rate_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'jonathan_firing_rate_analysis\\'), <traceback object at 0x1510fbd38140>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_pin01_one_11-02_17-46-44]\\n\"========================== END BATCH ==========================\\n\\n\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\n\\t done.\\nposition_decoding_two_step missing.\\n\\t Recomputing position_decoding_two_step...\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (47472,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (26268,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (88460,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (48472,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (26935,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (88522,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (48967,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': 'two_step_decoder_result[\\'most_likely_position_flat_max_likelihood_values\\'].shape = (28368,)\\nPerforming run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': '/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:367: RuntimeWarning: divide by zero encountered in divide\\n  return C * np.exp(numerator/denominator)\\n'}, {'name': 'stdout', 'output_type': 'stream', 'text': \"two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (89955,)\\n\\t done.\\nException occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\\n Inner exception: 'pf1D_TwoStepDecoder'\\nERROR perform `batch_extended_computations` or saving GLOBAL COMPUTATION RESULTS for pipeline of curr_session_context: kdiba_pin01_one_fet11-01_12-58-54. error: !! 'pf1D_TwoStepDecoder' ::::: (<class 'KeyError'>, KeyError('pf1D_TwoStepDecoder'), <traceback object at 0x1510e8d967c0>)\\nno changes in global results.\\nskipping figure generation because should_perform_figure_generation_to_file == False\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\nDEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_times\\n\\t time since last computation: 0:00:00.007386\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5\\nOVERWRITING (or writing) the file /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5!\\npipeline hdf5_output_path: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-01_12-58-54/output/pipeline_results.h5\\n\"}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: 'fet11-01_12-58-54'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'ERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x151325edb0c0>) while trying to build the session HDF output.\\nERROR: encountered exception !! \\'long_short_fr_indicies_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'long_short_fr_indicies_analysis\\'), <traceback object at 0x1513548d7100>) while trying to build the session HDF output for kdiba_pin01_one_fet11-01_12-58-54\\n\\t doing specific instantaneous firing rate computation for context: kdiba_pin01_one_fet11-01_12-58-54...\\nWARN: on_complete_success_execution_session: encountered exception !! \\'jonathan_firing_rate_analysis\\' ::::: (<class \\'KeyError\\'>, KeyError(\\'jonathan_firing_rate_analysis\\'), <traceback object at 0x151325e6f8c0>) while trying to compute the instantaneous firing rates and set self.across_sessions_instantaneous_fr_dict[kdiba_pin01_one_fet11-01_12-58-54]\\n\"========================== END BATCH ==========================\\n\\n\\n'}], 'source': '# %pdb on\\n\\n# multiprocessing_kwargs = dict(use_multiprocessing=False, num_processes=1)\\nmultiprocessing_kwargs = dict(use_multiprocessing=True, num_processes=5)\\n  \\n# Whether to output figures:\\nshould_perform_figure_generation_to_file=False\\n# should_perform_figure_generation_to_file=True\\n\\n## Included Session Contexts:\\n# included_session_contexts = batch_progress_df[np.logical_and(batch_progress_df[\\'has_user_replay_annotations\\'], batch_progress_df[\\'is_ready\\'])][\\'context\\'].to_numpy().tolist()\\n\\n# Only require sessions to have replay annotations:\\n# included_session_contexts = batch_progress_df[batch_progress_df[\\'has_user_replay_annotations\\']][\\'context\\'].to_numpy().tolist()\\n\\n# included_session_contexts = batch_progress_df[\\'context\\'].to_numpy().tolist()[:4] # Only get the first 6\\n# Limit the contexts to run to the last N:\\n# included_session_contexts = included_session_contexts[3:5]\\n\\n# included_session_contexts = [included_session_contexts[3]]\\n\\n# ALL\\nincluded_session_contexts = included_session_contexts\\n\\n# ## No filtering the sessions:\\n# included_session_contexts = None\\n\\nif included_session_contexts is not None:\\n    print(f\\'len(included_session_contexts): {len(included_session_contexts)}\\')\\nelse:\\n    print(f\\'included_session_contexts is None so all session contexts will be included.\\')\\n\\n# included_session_contexts\\n\\n# # No recomputing at all:\\n# result_handler = BatchSessionCompletionHandler(force_reload_all=False,\\n#                                                 session_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=False, should_save=SavingOptions.NEVER, override_file=),\\n#                                                 global_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=False, should_save=SavingOptions.NEVER),\\n#                                                 should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, should_generate_all_plots=True, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_global_recompute=False,\\n#                                                 **multiprocessing_kwargs)\\n\\n# No Reloading\\nresult_handler = BatchSessionCompletionHandler(force_reload_all=False,\\n                                                session_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=True, should_save=SavingOptions.IF_CHANGED),\\n                                                global_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=True, should_save=SavingOptions.IF_CHANGED),\\n                                                should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, should_generate_all_plots=True, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_global_recompute=False,\\n                                                **multiprocessing_kwargs)\\n\\n\\n# # # Forced Reloading:\\n# result_handler = BatchSessionCompletionHandler(force_reload_all=True,\\n#                                                 session_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=SavingOptions.ALWAYS),\\n#                                                 global_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=SavingOptions.ALWAYS),\\n#                                                 should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE, force_global_recompute=True,\\n#                                                 **multiprocessing_kwargs)\\n\\n\\nactive_post_run_callback_fn = result_handler.on_complete_success_execution_session\\n# active_post_run_callback_fn = _temp_on_complete_success_execution_session\\n\\n\\n# def a_test_completion_function(self, global_data_root_parent_path, curr_session_context, curr_session_basedir, curr_active_pipeline, across_session_results_extended_dict: dict) -> dict:\\n#     # print(f\\'>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\\')\\n#     print(f\\'<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\\')\\n#     print(f\\'a_test_completion_function(curr_session_context: {curr_session_context}, curr_session_basedir: {str(curr_session_basedir)}, ...,across_session_results_extended_dict: {across_session_results_extended_dict})\\')\\n#     long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\\n#     # long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\\n#     # long_results, short_results, global_results = [curr_active_pip eline.computation_results[an_epoch_name][\\'computed_data\\'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\\n#     # Get existing laps from session:\\n#     # long_laps, short_laps, global_laps = [curr_active_pipeline.filtered_sessions[an_epoch_name].laps.as_epoch_obj() for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\\n#     # long_replays, short_replays, global_replays = [Epoch(curr_active_pipeline.filtered_sessions[an_epoch_name].replay.epochs.get_valid_df()) for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\\n#     # long_PBEs, short_PBEs, global_PBEs = [curr_active_pipeline.filtered_sessions[an_epoch_name].pbe for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\\n\\n\\n#     output_file_prefix = curr_session_context.get_description(separator=\"|\", include_property_names=False)\\n#     print(f\\'-----------------_____------______---- BEGIN Directional Laps Result: \\\\n\\\\toutput_file_prefix: {output_file_prefix}\\\\n\\\\tcurr_active_pipeline.active_config_names: {curr_active_pipeline.active_config_names}\\')\\n#     directional_laps_result = curr_active_pipeline.global_computation_results.computed_data[\\'DirectionalLaps\\'][\\'computed_base_epoch_names\\']\\n#     print(f\"\\\\tsplit_directional_laps_names: {curr_active_pipeline.global_computation_results.computed_data[\\'DirectionalLaps\\'][\\'split_directional_laps_names\\']}\")\\n#     print(f\"\\\\tsplit_directional_laps_names: {curr_active_pipeline.global_computation_results.computed_data[\\'DirectionalLaps\\'][\\'computed_base_epoch_names\\']}\")\\n#     print(f\\'\\\\n__ End Directional Laps result\\')\\n\\n#     # jonathan_firing_rate_analysis_result = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\\n#     # (epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\\n#     # neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.05)\\n\\n#     # ## Output the BatchPhoJonathanFiguresHelper\\n#     # fig_1c_figures_all_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df.sort_values(\\'custom_frs_index\\', ascending=True, inplace=False), included_unit_neuron_IDs=None,\\n# \\t# n_max_page_rows=20, write_vector_format=False, write_png=True,\\n# \\t# show_only_refined_cells=False, disable_top_row=False, split_by_short_long_shared=False)\\n\\n    \\n#     # global_replays.filename = Path(f\"output/{output_file_prefix}_global_replays\").resolve()\\n#     # print(f\\'global_replays.filename: {global_replays.filename}\\')\\n#     # global_replays.to_neuroscope()\\n\\n#     # global_PBEs.filename = Path(f\"output/{output_file_prefix}_global_PBEs\").resolve()\\n#     # print(f\\'global_PBEs.filename: {global_PBEs.filename}\\')\\n#     # global_PBEs.to_neuroscope(\\'PBE\\')\\n\\n\\n#     # curr_active_pipeline, directional_lap_specific_configs = DirectionalLapsHelpers.split_to_directional_laps(curr_active_pipeline, add_created_configs_to_pipeline=True)\\n#     # curr_active_pipeline, directional_lap_specific_configs = constrain_to_laps(curr_active_pipeline)\\n#     # list(directional_lap_specific_configs.keys())\\n\\n#     # joined_neruon_fri_df = build_merged_neuron_firing_rate_indicies(curr_active_pipeline, enable_display_intermediate_results=False)\\n#     # AcrossSessionTables.write_table_to_files(joined_neruon_fri_df, global_data_root_parent_path=global_data_root_parent_path, output_basename=f\\'{BATCH_DATE_TO_USE}_{output_file_prefix}_joined_neruon_fri_df\\')\\n#     print(f\\'>>\\\\t done with {output_file_prefix}\\')\\n#     print(f\\'>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\\')\\n#     print(f\\'>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\\')\\n\\n#     return across_session_results_extended_dict\\n\\n\\n# result_handler.completion_functions.append(a_test_completion_function)\\n\\n## Specific Setup for 2023-09-28 Changes to LxC/SxC \"refinements\"\\nresult_handler.extended_computations_include_includelist = [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\',\\n                                                # \\'pf_dt_sequential_surprise\\',\\n                                                \\'ratemap_peaks_prominence2d\\',\\n                                                \\'position_decoding\\', \\n                                                \\'position_decoding_two_step\\',\\n                                                # \\'long_short_decoding_analyses\\',\\n                                                # \\'jonathan_firing_rate_analysis\\', \\'long_short_fr_indicies_analyses\\', \\'short_long_pf_overlap_analyses\\', \\'long_short_post_decoding\\', \\'long_short_rate_remapping\\',\\n                                                # \\'long_short_inst_spike_rate_groups\\',\\n                                                # \\'long_short_endcap_analysis\\',\\n                                                \\'spike_burst_detection\\',\\n                                                \\'split_to_directional_laps\\',\\n                                                \\'rank_order_shuffle_analysis\\'\\n                                                ]\\n\\n\\nbasic_local_computations = [\\'pf_computation\\', \\'pfdt_computation\\', \\'firing_rate_trends\\',\\n#                                                 \\'pf_dt_sequential_surprise\\',\\n                                                # \\'ratemap_peaks_prominence2d\\',\\n                                                \\'position_decoding\\', \\n                                                #\\'position_decoding_two_step\\', \\n                                                ]\\n \\n# result_handler.extended_computations_include_includelist = [\\'long_short_inst_spike_rate_groups\\']\\n\\n\\nresult_handler.enable_hdf5_output = True # output the HDF5 when done.\\n# result_handler.override_existing_frs_index_values = True\\n# result_handler.frs_index_inclusion_magnitude = 0.1\\n\\n# result_handler.enable_hdf5_output = False\\nresult_handler.override_existing_frs_index_values = False\\n\\n\\n## Execute with the custom arguments.\\nglobal_batch_run.execute_all(force_reload=result_handler.force_reload_all, saving_mode=result_handler.saving_mode, skip_extended_batch_computations=True, post_run_callback_fn=active_post_run_callback_fn,\\n                             fail_on_exception=False, included_session_contexts=included_session_contexts,\\n                                                                                        **{\\'computation_functions_name_includelist\\': basic_local_computations,\\n                                                                                            \\'active_session_computation_configs\\': None,\\n                                                                                            \\'allow_processing_previously_completed\\': True}, **multiprocessing_kwargs) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\\n\\n# 4m 39.8s'}, {'cell_type': 'code', 'execution_count': 8, 'id': 'f130e5c9', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [{'name': 'stdout', 'output_type': 'stream', 'text': \"Saving (file mode '/nfs/turbo/umms-kdiba/Data/global_batch_result_2023-11-10_GL.pkl') saved session pickle file results : /nfs/turbo/umms-kdiba/Data/global_batch_result_2023-11-10_GL.pkl... \\tmoving new output at '/nfs/turbo/umms-kdiba/Data/20231109205315-global_batch_result_2023-11-10_GL.pkltmp' -> to desired location: '/nfs/turbo/umms-kdiba/Data/global_batch_result_2023-11-10_GL.pkl'\\ndone.\\n\"}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-08_14-26-15'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-09_1-22-43'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-12_15-55-31'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-07_16-40-19'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-08_21-16-25'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-09_22-24-40'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-6-12_16-53-46'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-09_17-29-30'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-10_12-25-50'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-09_16-40-54'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '2006-4-10_12-58-3'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '11-02_17-46-44'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '11-02_19-28-0'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '11-03_12-3-25'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}, {'name': 'stdout', 'output_type': 'stream', 'text': 'done outputting HDF file.\\n'}, {'name': 'stderr', 'output_type': 'stream', 'text': \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: 'fet11-01_12-58-54'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\\n  check_attribute_name(name)\\n\"}], 'source': \"# Save to pickle:\\nsaveData(global_batch_result_file_path, global_batch_run) # Update the global batch run dictionary\\n\\n# Save to HDF5\\nsuffix = f'{BATCH_DATE_TO_USE}'\\n## Build Pickle Path:\\nfile_path = global_data_root_parent_path.joinpath(f'global_batch_output_{suffix}.h5').resolve()\\nglobal_batch_run.to_hdf(file_path,'/')\"}, {'cell_type': 'code', 'execution_count': 9, 'id': '0981cde1', 'metadata': {'notebookRunGroups': {'groupValue': '21'}, 'tags': []}, 'outputs': [{'data': {'text/html': '<div>\\n<style scoped>\\n    .dataframe tbody tr th:only-of-type {\\n        vertical-align: middle;\\n    }\\n\\n    .dataframe tbody tr th {\\n        vertical-align: top;\\n    }\\n\\n    .dataframe thead th {\\n        text-align: right;\\n    }\\n</style>\\n<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>format_name</th>\\n      <th>animal</th>\\n      <th>exper_name</th>\\n      <th>session_name</th>\\n      <th>context</th>\\n      <th>basedirs</th>\\n      <th>status</th>\\n      <th>errors</th>\\n      <th>session_datetime</th>\\n      <th>n_long_laps</th>\\n      <th>n_long_replays</th>\\n      <th>n_short_laps</th>\\n      <th>n_short_replays</th>\\n      <th>is_ready</th>\\n      <th>global_computation_result_file</th>\\n      <th>loaded_session_pickle_file</th>\\n      <th>ripple_result_file</th>\\n      <th>has_user_replay_annotations</th>\\n      <th>has_user_grid_bin_bounds_annotations</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>1</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>one</td>\\n      <td>2006-6-08_14-26-15</td>\\n      <td>kdiba_gor01_one_2006-6-08_14-26-15</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>SessionBatchProgress.COMPLETED</td>\\n      <td>None</td>\\n      <td>2006-06-08 14:26:15</td>\\n      <td>40</td>\\n      <td>354</td>\\n      <td>40</td>\\n      <td>272</td>\\n      <td>True</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>one</td>\\n      <td>2006-6-09_1-22-43</td>\\n      <td>kdiba_gor01_one_2006-6-09_1-22-43</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>SessionBatchProgress.COMPLETED</td>\\n      <td>None</td>\\n      <td>2006-06-09 01:22:43</td>\\n      <td>44</td>\\n      <td>235</td>\\n      <td>40</td>\\n      <td>180</td>\\n      <td>True</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>one</td>\\n      <td>2006-6-12_15-55-31</td>\\n      <td>kdiba_gor01_one_2006-6-12_15-55-31</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>SessionBatchProgress.COMPLETED</td>\\n      <td>None</td>\\n      <td>2006-06-12 15:55:31</td>\\n      <td>40</td>\\n      <td>57</td>\\n      <td>34</td>\\n      <td>76</td>\\n      <td>True</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>6</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>two</td>\\n      <td>2006-6-07_16-40-19</td>\\n      <td>kdiba_gor01_two_2006-6-07_16-40-19</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>SessionBatchProgress.COMPLETED</td>\\n      <td>None</td>\\n      <td>2006-06-07 16:40:19</td>\\n      <td>41</td>\\n      <td>287</td>\\n      <td>40</td>\\n      <td>446</td>\\n      <td>True</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>8</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>two</td>\\n      <td>2006-6-08_21-16-25</td>\\n      <td>kdiba_gor01_two_2006-6-08_21-16-25</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>SessionBatchProgress.COMPLETED</td>\\n      <td>None</td>\\n      <td>2006-06-08 21:16:25</td>\\n      <td>38</td>\\n      <td>62</td>\\n      <td>40</td>\\n      <td>77</td>\\n      <td>True</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>9</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>two</td>\\n      <td>2006-6-09_22-24-40</td>\\n      <td>kdiba_gor01_two_2006-6-09_22-24-40</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>SessionBatchProgress.COMPLETED</td>\\n      <td>None</td>\\n      <td>2006-06-09 22:24:40</td>\\n      <td>47</td>\\n      <td>155</td>\\n      <td>41</td>\\n      <td>568</td>\\n      <td>True</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>10</th>\\n      <td>kdiba</td>\\n      <td>gor01</td>\\n      <td>two</td>\\n      <td>2006-6-12_16-53-46</td>\\n      <td>kdiba_gor01_two_2006-6-12_16-53-46</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>SessionBatchProgress.COMPLETED</td>\\n      <td>None</td>\\n      <td>2006-06-12 16:53:46</td>\\n      <td>40</td>\\n      <td>69</td>\\n      <td>40</td>\\n      <td>58</td>\\n      <td>True</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>12</th>\\n      <td>kdiba</td>\\n      <td>vvp01</td>\\n      <td>one</td>\\n      <td>2006-4-09_17-29-30</td>\\n      <td>kdiba_vvp01_one_2006-4-09_17-29-30</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\\n      <td>SessionBatchProgress.COMPLETED</td>\\n      <td>None</td>\\n      <td>2006-04-09 17:29:30</td>\\n      <td>44</td>\\n      <td>80</td>\\n      <td>42</td>\\n      <td>80</td>\\n      <td>True</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>13</th>\\n      <td>kdiba</td>\\n      <td>vvp01</td>\\n      <td>one</td>\\n      <td>2006-4-10_12-25-50</td>\\n      <td>kdiba_vvp01_one_2006-4-10_12-25-50</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\\n      <td>SessionBatchProgress.COMPLETED</td>\\n      <td>None</td>\\n      <td>2006-04-10 12:25:50</td>\\n      <td>42</td>\\n      <td>34</td>\\n      <td>42</td>\\n      <td>26</td>\\n      <td>True</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>31</th>\\n      <td>kdiba</td>\\n      <td>vvp01</td>\\n      <td>two</td>\\n      <td>2006-4-09_16-40-54</td>\\n      <td>kdiba_vvp01_two_2006-4-09_16-40-54</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\\n      <td>SessionBatchProgress.COMPLETED</td>\\n      <td>None</td>\\n      <td>2006-04-09 16:40:54</td>\\n      <td>48</td>\\n      <td>44</td>\\n      <td>50</td>\\n      <td>26</td>\\n      <td>True</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>32</th>\\n      <td>kdiba</td>\\n      <td>vvp01</td>\\n      <td>two</td>\\n      <td>2006-4-10_12-58-3</td>\\n      <td>kdiba_vvp01_two_2006-4-10_12-58-3</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\\n      <td>SessionBatchProgress.COMPLETED</td>\\n      <td>None</td>\\n      <td>2006-04-10 12:58:03</td>\\n      <td>40</td>\\n      <td>75</td>\\n      <td>41</td>\\n      <td>31</td>\\n      <td>True</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>52</th>\\n      <td>kdiba</td>\\n      <td>pin01</td>\\n      <td>one</td>\\n      <td>11-02_17-46-44</td>\\n      <td>kdiba_pin01_one_11-02_17-46-44</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>SessionBatchProgress.COMPLETED</td>\\n      <td>None</td>\\n      <td>2009-11-02 17:46:44</td>\\n      <td>40</td>\\n      <td>138</td>\\n      <td>41</td>\\n      <td>156</td>\\n      <td>True</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>53</th>\\n      <td>kdiba</td>\\n      <td>pin01</td>\\n      <td>one</td>\\n      <td>11-02_19-28-0</td>\\n      <td>kdiba_pin01_one_11-02_19-28-0</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>SessionBatchProgress.COMPLETED</td>\\n      <td>None</td>\\n      <td>2009-11-02 19:28:00</td>\\n      <td>44</td>\\n      <td>112</td>\\n      <td>50</td>\\n      <td>51</td>\\n      <td>True</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>54</th>\\n      <td>kdiba</td>\\n      <td>pin01</td>\\n      <td>one</td>\\n      <td>11-03_12-3-25</td>\\n      <td>kdiba_pin01_one_11-03_12-3-25</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>SessionBatchProgress.COMPLETED</td>\\n      <td>None</td>\\n      <td>2009-11-03 12:03:25</td>\\n      <td>41</td>\\n      <td>32</td>\\n      <td>43</td>\\n      <td>18</td>\\n      <td>True</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n    <tr>\\n      <th>64</th>\\n      <td>kdiba</td>\\n      <td>pin01</td>\\n      <td>one</td>\\n      <td>fet11-01_12-58-54</td>\\n      <td>kdiba_pin01_one_fet11-01_12-58-54</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\\n      <td>SessionBatchProgress.COMPLETED</td>\\n      <td>None</td>\\n      <td>2009-11-01 12:58:54</td>\\n      <td>50</td>\\n      <td>605</td>\\n      <td>22</td>\\n      <td>282</td>\\n      <td>True</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\\n      <td>/nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...</td>\\n      <td>True</td>\\n      <td>True</td>\\n    </tr>\\n  </tbody>\\n</table>\\n</div>', 'text/plain': '   format_name animal exper_name        session_name  \\\\\\n1        kdiba  gor01        one  2006-6-08_14-26-15   \\n2        kdiba  gor01        one   2006-6-09_1-22-43   \\n4        kdiba  gor01        one  2006-6-12_15-55-31   \\n6        kdiba  gor01        two  2006-6-07_16-40-19   \\n8        kdiba  gor01        two  2006-6-08_21-16-25   \\n9        kdiba  gor01        two  2006-6-09_22-24-40   \\n10       kdiba  gor01        two  2006-6-12_16-53-46   \\n12       kdiba  vvp01        one  2006-4-09_17-29-30   \\n13       kdiba  vvp01        one  2006-4-10_12-25-50   \\n31       kdiba  vvp01        two  2006-4-09_16-40-54   \\n32       kdiba  vvp01        two   2006-4-10_12-58-3   \\n52       kdiba  pin01        one      11-02_17-46-44   \\n53       kdiba  pin01        one       11-02_19-28-0   \\n54       kdiba  pin01        one       11-03_12-3-25   \\n64       kdiba  pin01        one   fet11-01_12-58-54   \\n\\n                               context  \\\\\\n1   kdiba_gor01_one_2006-6-08_14-26-15   \\n2    kdiba_gor01_one_2006-6-09_1-22-43   \\n4   kdiba_gor01_one_2006-6-12_15-55-31   \\n6   kdiba_gor01_two_2006-6-07_16-40-19   \\n8   kdiba_gor01_two_2006-6-08_21-16-25   \\n9   kdiba_gor01_two_2006-6-09_22-24-40   \\n10  kdiba_gor01_two_2006-6-12_16-53-46   \\n12  kdiba_vvp01_one_2006-4-09_17-29-30   \\n13  kdiba_vvp01_one_2006-4-10_12-25-50   \\n31  kdiba_vvp01_two_2006-4-09_16-40-54   \\n32   kdiba_vvp01_two_2006-4-10_12-58-3   \\n52      kdiba_pin01_one_11-02_17-46-44   \\n53       kdiba_pin01_one_11-02_19-28-0   \\n54       kdiba_pin01_one_11-03_12-3-25   \\n64   kdiba_pin01_one_fet11-01_12-58-54   \\n\\n                                             basedirs  \\\\\\n1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n9   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n10  /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n12  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \\n13  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \\n31  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \\n32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \\n52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \\n\\n                            status errors    session_datetime  n_long_laps  \\\\\\n1   SessionBatchProgress.COMPLETED   None 2006-06-08 14:26:15           40   \\n2   SessionBatchProgress.COMPLETED   None 2006-06-09 01:22:43           44   \\n4   SessionBatchProgress.COMPLETED   None 2006-06-12 15:55:31           40   \\n6   SessionBatchProgress.COMPLETED   None 2006-06-07 16:40:19           41   \\n8   SessionBatchProgress.COMPLETED   None 2006-06-08 21:16:25           38   \\n9   SessionBatchProgress.COMPLETED   None 2006-06-09 22:24:40           47   \\n10  SessionBatchProgress.COMPLETED   None 2006-06-12 16:53:46           40   \\n12  SessionBatchProgress.COMPLETED   None 2006-04-09 17:29:30           44   \\n13  SessionBatchProgress.COMPLETED   None 2006-04-10 12:25:50           42   \\n31  SessionBatchProgress.COMPLETED   None 2006-04-09 16:40:54           48   \\n32  SessionBatchProgress.COMPLETED   None 2006-04-10 12:58:03           40   \\n52  SessionBatchProgress.COMPLETED   None 2009-11-02 17:46:44           40   \\n53  SessionBatchProgress.COMPLETED   None 2009-11-02 19:28:00           44   \\n54  SessionBatchProgress.COMPLETED   None 2009-11-03 12:03:25           41   \\n64  SessionBatchProgress.COMPLETED   None 2009-11-01 12:58:54           50   \\n\\n    n_long_replays  n_short_laps  n_short_replays  is_ready  \\\\\\n1              354            40              272      True   \\n2              235            40              180      True   \\n4               57            34               76      True   \\n6              287            40              446      True   \\n8               62            40               77      True   \\n9              155            41              568      True   \\n10              69            40               58      True   \\n12              80            42               80      True   \\n13              34            42               26      True   \\n31              44            50               26      True   \\n32              75            41               31      True   \\n52             138            41              156      True   \\n53             112            50               51      True   \\n54              32            43               18      True   \\n64             605            22              282      True   \\n\\n                       global_computation_result_file  \\\\\\n1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n9   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n10  /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n12  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \\n13  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \\n31  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \\n32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \\n52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \\n\\n                           loaded_session_pickle_file  \\\\\\n1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n9   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n10  /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n12  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \\n13  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \\n31  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \\n32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \\n52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \\n\\n                                   ripple_result_file  \\\\\\n1   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n2   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n4   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/200...   \\n6   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n8   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n9   /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n10  /nfs/turbo/umms-kdiba/Data/KDIBA/gor01/two/200...   \\n12  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \\n13  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/one/200...   \\n31  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \\n32  /nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/200...   \\n52  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n53  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n54  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-...   \\n64  /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet...   \\n\\n    has_user_replay_annotations  has_user_grid_bin_bounds_annotations  \\n1                          True                                  True  \\n2                          True                                  True  \\n4                          True                                  True  \\n6                          True                                  True  \\n8                          True                                  True  \\n9                          True                                  True  \\n10                         True                                  True  \\n12                         True                                  True  \\n13                         True                                  True  \\n31                         True                                  True  \\n32                         True                                  True  \\n52                         True                                  True  \\n53                         True                                  True  \\n54                         True                                  True  \\n64                         True                                  True  '}, 'execution_count': 9, 'metadata': {}, 'output_type': 'execute_result'}], 'source': 'batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\\ngood_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\\nbatch_progress_df.batch_results.build_all_columns()\\ngood_only_batch_progress_df.batch_results.build_all_columns()\\ngood_only_batch_progress_df'}, {'cell_type': 'markdown', 'id': '690f140f', 'metadata': {}, 'source': '# Across Sessions After Batching Complete'}, {'cell_type': 'code', 'execution_count': None, 'id': '3dce885b-5b99-4a7a-9f72-2eed2e45ae18', 'metadata': {'tags': []}, 'outputs': [], 'source': \"a_batch_progress_df = included_session_batch_progress_df.copy()\\n\\ngood_session_concrete_folders = [ConcreteSessionFolder(a_context, a_basedir) for a_context, a_basedir in zip(list(a_batch_progress_df.context.values), list(a_batch_progress_df.basedirs.values))]\\n\\n# good_only_batch_progress_df.batch_results\\n# included_h5_paths = [get_file_str_if_file_exists(v.joinpath('output','pipeline_results.h5').resolve()) for v in list(good_only_batch_progress_df.basedirs.values)]\\n# included_h5_paths = [a_dir.joinpath('output','pipeline_results.h5').resolve() for a_dir in included_session_batch_progress_df['basedirs']]\\nincluded_h5_paths = [get_file_str_if_file_exists(v.pipeline_results_h5) for v in good_session_concrete_folders]\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'f39738fa-f8f3-46d2-a937-0fb08c0ccb43', 'metadata': {'tags': []}, 'outputs': [], 'source': \"# target_dir = Path('output/across_session_results/2023-09-29').resolve()\\n# target_dir = Path('/home/halechr/cloud/turbo/Pho/Output/across_session_results/2023-09-29').resolve()\\n# target_dir = Path('/home/halechr/cloud/turbo/Pho/Output/across_session_results/2023-10-03').resolve()\\n# copy_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, target_dir=target_dir)\\n# copy_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, backup_mode=BackupMethods.RenameInSourceDirectory, rename_backup_suffix='2023-10-05', only_include_file_types=['local_pkl', 'global_pkl','h5'])\\ncopy_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, backup_mode=BackupMethods.RenameInSourceDirectory, rename_backup_suffix=BATCH_DATE_TO_USE, only_include_file_types=['local_pkl', 'global_pkl'])\\n# copy_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, backup_mode=BackupMethods.RenameInSourceDirectory, rename_backup_suffix='2023-10-07', only_include_file_types=['local_pkl', 'global_pkl','h5'])\\ncopy_dict\"}, {'cell_type': 'code', 'execution_count': None, 'id': '135cb2d8-65b3-405b-a41b-22b2fa7cb28e', 'metadata': {'scrolled': True, 'tags': []}, 'outputs': [], 'source': 'moved_files_dict_h5_files = copy_movedict(copy_dict)\\nmoved_files_dict_h5_files'}, {'cell_type': 'code', 'execution_count': None, 'id': '243e3954-15a4-449c-b927-56d5d79153c8', 'metadata': {'tags': []}, 'outputs': [], 'source': \"moved_files_copydict_output_filename=f'backed_up_files_copydict_{BATCH_DATE_TO_USE}.csv'\\nmoved_files_copydict_file_path = Path(global_data_root_parent_path).joinpath(moved_files_copydict_output_filename).resolve() # Use Default\\nprint(f'moved_files_copydict_file_path: {moved_files_copydict_file_path}')\\n\\n_out_string, filedict_out_path = save_copydict_to_text_file(moved_files_dict_h5_files, moved_files_copydict_file_path, debug_print=True)\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'ab869730', 'metadata': {}, 'outputs': [], 'source': 'read_moved_files_dict_files = read_copydict_from_text_file(moved_files_copydict_file_path, debug_print=False)\\nread_moved_files_dict_files'}, {'cell_type': 'code', 'execution_count': None, 'id': 'dd4671e4', 'metadata': {}, 'outputs': [], 'source': '# read_moved_files_dict_files\\nrestore_moved_files_dict_files = invert_filedict(read_moved_files_dict_files)\\nrestore_moved_files_dict_files'}, {'cell_type': 'code', 'execution_count': None, 'id': 'd067d8f2', 'metadata': {}, 'outputs': [], 'source': 'check_output_h5_files(included_h5_paths)'}, {'cell_type': 'markdown', 'id': '1bdb0953', 'metadata': {}, 'source': '## Extract `across_sessions_instantaneous_fr_dict` from the computation outputs'}, {'cell_type': 'code', 'execution_count': None, 'id': '39691fe2', 'metadata': {}, 'outputs': [], 'source': \"# Somewhere in there there are `InstantaneousSpikeRateGroupsComputation` results to extract\\nacross_sessions_instantaneous_fr_dict = {} # InstantaneousSpikeRateGroupsComputation\\nacross_sessions_recomputed_instantaneous_fr_dict = {}\\n\\n# Get only the sessions with non-None results\\nsessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\\ngood_session_batch_outputs = {a_ctxt:a_result for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None}\\n\\nfor a_ctxt, a_result in good_session_batch_outputs.items():\\n    if a_result is not None:\\n        # a_good_result = a_result.__dict__.get('across_sessions_batch_results', {}).get('inst_fr_comps', None)\\n        a_good_result = a_result.across_session_results.get('inst_fr_comps', None)\\n        if a_good_result is not None:\\n            across_sessions_instantaneous_fr_dict[a_ctxt] = a_good_result\\n            # print(a_result['across_sessions_batch_results']['inst_fr_comps'])\\n        a_good_recomp_result = a_result.across_session_results.get('recomputed_inst_fr_comps', None)\\n        if a_good_recomp_result is not None:\\n            across_sessions_recomputed_instantaneous_fr_dict[a_ctxt] = a_good_recomp_result\\n            \\nnum_sessions = len(across_sessions_instantaneous_fr_dict)\\nprint(f'num_sessions: {num_sessions}')\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'bbeb9efc', 'metadata': {}, 'outputs': [], 'source': 'across_sessions_recomputed_instantaneous_fr_dict'}, {'cell_type': 'code', 'execution_count': None, 'id': '09136799', 'metadata': {}, 'outputs': [], 'source': \"# When done, `result_handler.across_sessions_instantaneous_fr_dict` is now equivalent to what it would have been before. It can be saved using the normal `.save_across_sessions_data(...)`\\n\\n## Save the instantaneous firing rate results dict: (# Dict[IdentifyingContext] = InstantaneousSpikeRateGroupsComputation)\\n# AcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_instantaneous_fr_dict, global_data_root_parent_path=global_data_root_parent_path,\\n#                                                  inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl')\\n\\n\\nAcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_recomputed_instantaneous_fr_dict, global_data_root_parent_path=global_data_root_parent_path,\\n                                                 inst_fr_output_filename=f'across_session_result_long_short_recomputed_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl')\\n\\n\\n\\n# ## Save pickle:\\n# inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\\n# global_batch_result_inst_fr_file_path = Path(global_data_root_parent_path).joinpath(inst_fr_output_filename).resolve() # Use Default\\n# print(f'global_batch_result_inst_fr_file_path: {global_batch_result_inst_fr_file_path}')\\n# # Save the all sessions instantaneous firing rate dict to the path:\\n# saveData(global_batch_result_inst_fr_file_path, across_sessions_instantaneous_fr_dict)\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'c123baf6', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionTables\\n\\n# neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_all_known_tables(included_session_contexts, included_h5_paths, should_restore_native_column_types=True, )\\n\\nneuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_and_save_all_combined_tables(included_session_contexts, included_h5_paths, override_output_parent_path=global_data_root_parent_path, output_path_suffix=f'{BATCH_DATE_TO_USE}')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '5a859bff-8cdb-4281-a64f-251d24db7cb9', 'metadata': {'notebookRunGroups': {'groupValue': '2'}, 'tags': []}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionTables\\n\\nneuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_all_known_tables(included_session_contexts, included_h5_paths, should_restore_native_column_types=True)\\n# neuron_replay_stats_table['is_refined_LxC']\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'b04b2430-c9ec-4adb-81a8-1ffbf8a0cb3c', 'metadata': {'notebookRunGroups': {'groupValue': '2'}, 'tags': []}, 'outputs': [], 'source': 'long_short_fr_indicies_analysis_table'}, {'cell_type': 'code', 'execution_count': None, 'id': '2043eb76', 'metadata': {}, 'outputs': [], 'source': 'neuron_replay_stats_table'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c95013ea', 'metadata': {}, 'outputs': [], 'source': 'neuron_identities_table'}, {'cell_type': 'code', 'execution_count': None, 'id': '5b8ced5f', 'metadata': {}, 'outputs': [], 'source': \"# np.sum(neuron_replay_stats_table['is_refined_LxC'])\\n# np.isnan(neuron_replay_stats_table['is_refined_LxC'])\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'f8615ac3', 'metadata': {}, 'outputs': [], 'source': \"# Options\\nsession_identifier_key: str = 'session_name'\\n# session_identifier_key: str = 'session_datetime'\\n\\n## !IMPORTANT! Count of the fields of interest using .value_counts(...) and converting to an explicit pd.DataFrame:\\n# _out_value_counts_df: pd.DataFrame = neuron_replay_stats_table.value_counts(subset=['format_name', 'animal', 'session_name', 'session_datetime','track_membership'], normalize=False, sort=False, ascending=True, dropna=True).reset_index()\\n# _out_value_counts_df.columns = ['format_name', 'animal', 'session_name', 'session_datetime', 'track_membership', 'count']\\n_out_value_counts_df: pd.DataFrame = neuron_replay_stats_table.value_counts(subset=['format_name', 'animal', 'session_name', 'session_datetime','track_membership','is_refined_LxC', 'is_refined_SxC'], normalize=False, sort=False, ascending=True, dropna=True).reset_index()\\n_out_value_counts_df.columns = ['format_name', 'animal', 'session_name', 'session_datetime', 'track_membership', 'is_refined_LxC', 'is_refined_SxC', 'count']\\n_out_value_counts_df\"}, {'cell_type': 'code', 'execution_count': None, 'id': '6af57298', 'metadata': {}, 'outputs': [], 'source': \"## Find the time of the first session for each animal:\\nfirst_session_time  = _out_value_counts_df.groupby(['animal']).agg(session_datetime_first=('session_datetime', 'first')).reset_index()\\n\\n## Subtract this initial time from all of the 'session_datetime' entries for each animal:\\n# Merge the first session time back into the original DataFrame\\nmerged_df = pd.merge(_out_value_counts_df, first_session_time, on='animal')\\n\\n# Subtract this initial time from all of the 'session_datetime' entries for each animal\\nmerged_df['time_since_first_session'] = merged_df['session_datetime'] - merged_df['session_datetime_first']\\n\\nmerged_df\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'b25bb1f8', 'metadata': {}, 'outputs': [], 'source': \"import matplotlib.pyplot as plt\\n\\npoint_size = 8\\ndf = _out_value_counts_df.copy()\\nanimals = df['animal'].unique()\\ntrack_memberships = df['track_membership'].unique()\\n\\nfig, axes = plt.subplots(1, len(animals), figsize=(15, 5))\\n\\nfor i, animal in enumerate(animals):\\n\\tax = axes[i]\\n\\tsubset_df = df[df['animal'] == animal]\\n\\t\\n\\tfor track_membership in track_memberships:\\n\\t\\ttrack_subset_df = subset_df[subset_df['track_membership'] == track_membership]\\n\\t\\tax.plot(track_subset_df['session_datetime'], track_subset_df['count'], label=f'Track: {track_membership}')\\n\\t\\tax.scatter(track_subset_df['session_datetime'], track_subset_df['count'], s=point_size)\\n\\t\\t\\n\\tax.set_title(f'Animal: {animal}')\\n\\tax.set_xlabel('Session Datetime')\\n\\tax.set_ylabel('Count')\\n\\tax.legend()\\n\\nplt.tight_layout()\\nplt.show()\"}, {'cell_type': 'code', 'execution_count': None, 'id': '94408ac4', 'metadata': {}, 'outputs': [], 'source': '_out_value_counts_df'}, {'cell_type': 'code', 'execution_count': None, 'id': '784fcc04', 'metadata': {}, 'outputs': [], 'source': \"\\n\\n## See if the number of cells decreases over re-exposures to the track\\ndf = _out_value_counts_df[_out_value_counts_df['animal'] == 'gor01']\\n# df = _out_value_counts_df[_out_value_counts_df['animal'] == 'pin01']\\n# df = _out_value_counts_df[_out_value_counts_df['animal'] == 'vvp01']\\n\\n# Sort by column: 'session_datetime' (ascending)\\ndf = df.sort_values(['session_datetime'])\\n\\n'LEFT_ONLY'\\n\\n# df.to_clipboard(index=False)\\ndf\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'd8a502f7', 'metadata': {}, 'outputs': [], 'source': \"## Get the number of cells in each session of the animal:\\nnum_LxCs = df[df['track_membership'] == 'LEFT_ONLY']['count'].to_numpy()\\nnum_Shared = df[df['track_membership'] == 'SHARED']['count'].to_numpy()\\nnum_SxCs = df[df['track_membership'] == 'RIGHT_ONLY']['count'].to_numpy()\\n\\nnum_TotalCs = num_LxCs + num_Shared + num_SxCs\\nnum_TotalCs\"}, {'cell_type': 'code', 'execution_count': None, 'id': '2feb3fa1', 'metadata': {}, 'outputs': [], 'source': '# The only safe point to align each session to is the switchpoint (the delta):\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '046bbce9', 'metadata': {}, 'outputs': [], 'source': '# Each session can be expressed in terms of time from the start of the first session.\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'a00d2419', 'metadata': {}, 'outputs': [], 'source': 'df.plot()\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '56f99ff8', 'metadata': {}, 'outputs': [], 'source': \"\\nfrom pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsVisualizations\\n\\nmatplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\\ngraphics_output_dict = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=num_sessions, save_figure=True)\"}, {'cell_type': 'markdown', 'id': 'cadc1ac7-5771-4cd5-94c6-7a6244eb8217', 'metadata': {'notebookRunGroups': {'groupValue': '2'}, 'tags': []}, 'source': '## Extract output files from all completed sessions:'}, {'cell_type': 'code', 'execution_count': None, 'id': '47cb0cd9-3e60-4425-9351-dfc903f3f067', 'metadata': {'notebookRunGroups': {'groupValue': '2'}, 'tags': []}, 'outputs': [], 'source': 'from pyphocorehelpers.Filesystem.path_helpers import convert_filelist_to_new_parent\\n\\ndef save_filelist_to_text_file(hdf5_output_paths, filelist_path: Path):\\n    _out_string = \\'\\\\n\\'.join([str(a_file) for a_file in hdf5_output_paths])\\n    print(f\\'{_out_string}\\')\\n    print(f\\'saving out to \"{filelist_path}\"...\\')\\n    with open(filelist_path, \\'w\\') as f:\\n        f.write(_out_string)\\n    return _out_string, filelist_path\\n\\n# Save output filelist:\\n\\n# \\'/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5\\'\\n\\n# kdiba_vvp01_two_2006-4-10_12-58-3\\n# \\toutputs_local ={\\'pkl\\': PosixPath(\\'/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl\\')}\\n# \\toutputs_global ={\\'pkl\\': PosixPath(\\'/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl\\'), \\'hdf5\\': PosixPath(\\'/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5\\')}\\nsession_identifiers, pkl_output_paths, hdf5_output_paths = global_batch_run.build_output_files_lists()\\n\\nh5_filelist_path = global_data_root_parent_path.joinpath(f\\'fileList_Greatlakes_HDF5_{BATCH_DATE_TO_USE}.txt\\').resolve()\\n_out_string, src_filelist_HDF5_savepath = save_filelist_to_text_file(hdf5_output_paths, h5_filelist_path)\\n\\npkls_filelist_path = global_data_root_parent_path.joinpath(f\\'fileList_Greatlakes_pkls_{BATCH_DATE_TO_USE}.txt\\').resolve()\\n_out_string, src_filelist_pkls_savepath = save_filelist_to_text_file(pkl_output_paths, pkls_filelist_path)\\n\\n# source_parent_path = Path(r\\'/media/MAX/cloud/turbo/Data\\')\\nsource_parent_path = Path(r\\'/nfs/turbo/umms-kdiba/Data\\')\\ndest_parent_path = Path(r\\'/~/W/Data/\\')\\n# # Build the destination filelist from the source_filelist and the two paths:\\nfilelist_source = hdf5_output_paths\\nfilelist_dest_paths = convert_filelist_to_new_parent(filelist_source, original_parent_path=source_parent_path, dest_parent_path=dest_parent_path)\\nfilelist_dest_paths\\n\\ndest_Apogee_h5_filelist_path = global_data_root_parent_path.joinpath(f\\'dest_fileList_Apogee_{BATCH_DATE_TO_USE}.txt\\').resolve()\\n_out_string, dest_filelist_savepath = save_filelist_to_text_file(filelist_dest_paths, dest_Apogee_h5_filelist_path)'}, {'cell_type': 'code', 'execution_count': None, 'id': '3a8e69a3', 'metadata': {'notebookRunGroups': {'groupValue': '2'}, 'scrolled': True, 'tags': []}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult\\nfrom neuropy.core.epoch import Epoch\\n\\n# Save to HDF5\\nsuffix = f'{BATCH_DATE_TO_USE}'\\n## Build Pickle Path:\\nfile_path = global_data_root_parent_path.joinpath(f'global_batch_output_{suffix}.h5').resolve()\\nfile_path\\nglobal_batch_run.to_hdf(file_path,'/')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '282ce774-98fb-4e69-a7e2-e94cbff1b0b5', 'metadata': {'tags': []}, 'outputs': [], 'source': \"# Get only the sessions with non-None results\\nsessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\\n\\n# list(global_batch_run.session_batch_outputs.keys())\\n\\n# Somewhere in there there are `InstantaneousSpikeRateGroupsComputation` results to extract\\nacross_sessions_instantaneous_fr_dict = {} # InstantaneousSpikeRateGroupsComputation\\n\\n# good_session_batch_outputs = global_batch_run.session_batch_outputs\\n\\nsessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\\ngood_session_batch_outputs = {a_ctxt:a_result for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None}\\n\\nfor a_ctxt, a_result in good_session_batch_outputs.items():\\n    if a_result is not None:\\n        # a_good_result = a_result.__dict__.get('across_sessions_batch_results', {}).get('inst_fr_comps', None)\\n        a_good_result = a_result.across_session_results.get('inst_fr_comps', None)\\n        if a_good_result is not None:\\n            across_sessions_instantaneous_fr_dict[a_ctxt] = a_good_result\\n            # print(a_result['across_sessions_batch_results']['inst_fr_comps'])\\n            \\nnum_sessions = len(across_sessions_instantaneous_fr_dict)\\nprint(f'num_sessions: {num_sessions}')\\n\\n# When done, `result_handler.across_sessions_instantaneous_fr_dict` is now equivalent to what it would have been before. It can be saved using the normal `.save_across_sessions_data(...)`\\n\\n## Save the instantaneous firing rate results dict: (# Dict[IdentifyingContext] = InstantaneousSpikeRateGroupsComputation)\\nAcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_instantaneous_fr_dict, global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl')\\n\\n# ## Save pickle:\\n# inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\\n# global_batch_result_inst_fr_file_path = Path(global_data_root_parent_path).joinpath(inst_fr_output_filename).resolve() # Use Default\\n# print(f'global_batch_result_inst_fr_file_path: {global_batch_result_inst_fr_file_path}')\\n# # Save the all sessions instantaneous firing rate dict to the path:\\n# saveData(global_batch_result_inst_fr_file_path, across_sessions_instantaneous_fr_dict)\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'c60d19a7-5a89-43f1-aa33-3a7450d1f965', 'metadata': {'tags': []}, 'outputs': [], 'source': 'across_sessions_instantaneous_fr_dict'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e178426c-54df-47ac-8103-a66f114c77e5', 'metadata': {'tags': []}, 'outputs': [], 'source': '[a_ctxt.get_initialization_code_string() for a_ctxt in sessions_with_results]'}, {'cell_type': 'markdown', 'id': '28828512', 'metadata': {}, 'source': '# OLD'}, {'cell_type': 'markdown', 'id': '5056d9a7', 'metadata': {}, 'source': '# 2023-10-06 - `joined_neruon_fri_df` loading'}, {'cell_type': 'code', 'execution_count': None, 'id': 'bd6d0b19', 'metadata': {}, 'outputs': [], 'source': \"# BATCH_DATE_TO_USE = '2023-10-05_NewParameters'\\nBATCH_DATE_TO_USE = '2023-10-07'\\nall_sessions_joined_neruon_fri_df, out_path = build_and_merge_all_sessions_joined_neruon_fri_df(global_data_root_parent_path, BATCH_DATE_TO_USE)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'fbb893bf', 'metadata': {}, 'outputs': [], 'source': \"\\njoined_neruon_fri_df_basename = f'{BATCH_DATE_TO_USE}_{output_file_prefix}_joined_neruon_fri_df'\\nAcrossSessionTables.write_table_to_files(joined_neruon_fri_df, global_data_root_parent_path=global_data_root_parent_path, output_basename=joined_neruon_fri_df_basename, include_csv=False)\\nprint(f'>>\\\\t done with {output_file_prefix}')\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'd89c4c9f', 'metadata': {}, 'outputs': [], 'source': ''}, {'cell_type': 'markdown', 'id': 'be651cc7', 'metadata': {'tags': []}, 'source': '# 2023-10-04 - Load Saved across-sessions-data and testing Batch-computed inst_firing_rates:'}, {'cell_type': 'code', 'execution_count': None, 'id': '28ad5bf6', 'metadata': {}, 'outputs': [], 'source': '# from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\\n# from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\\n# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\\n# from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import list_of_dicts_to_dict_of_lists\\nfrom pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '34549c8f', 'metadata': {}, 'outputs': [], 'source': \"## Load the saved across-session results:\\n# inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\\n# inst_fr_output_filename = 'across_session_result_long_short_inst_firing_rate.pkl'\\n# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-07-21.pkl'\\n# inst_fr_output_filename=f'across_session_result_handler_{BATCH_DATE_TO_USE}.pkl'\\n# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-08-09_Test.pkl'\\n# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-10-04-GL.pkl'\\n# inst_fr_output_filename='across_session_result_long_short_recomputed_inst_firing_rate_2023-10-04-GL-Recomp.pkl'\\ninst_fr_output_filename='across_session_result_long_short_recomputed_inst_firing_rate_2023-10-07.pkl'\\nacross_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\\n# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\\nnum_sessions = len(across_sessions_instantaneous_fr_dict)\\nprint(f'num_sessions: {num_sessions}')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '0abea5de', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionTables\\n \\n## Load all across-session tables from the pickles:\\nneuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.load_all_combined_tables(override_output_parent_path=global_data_root_parent_path, output_path_suffix=f'2023-10-07') # output_path_suffix=f'2023-10-04-GL-Recomp'\\nnum_sessions = len(neuron_replay_stats_table.session_uid.unique().to_numpy())\\nprint(f'num_sessions: {num_sessions}')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '44ef2a8b', 'metadata': {}, 'outputs': [], 'source': 'neuron_replay_stats_table'}, {'cell_type': 'code', 'execution_count': None, 'id': 'db4ac006', 'metadata': {}, 'outputs': [], 'source': 'from neuropy.core.user_annotations import UserAnnotationsManager, SessionCellExclusivityRecord\\nfrom neuropy.utils.result_context import IdentifyingContext\\n\\n# for a_ctx, a_val in annotation_man.get_hardcoded_specific_session_override_dict().items():\\n# \\tannotation_man.annotations[a_ctx] = a_val\\n\\n# for a_ctx, a_val in UserAnnotationsManager.get_user_annotations().items():\\n# \\tannotation_man.annotations[a_ctx] = a_val\\n\\n# for a_ctx, a_val in session_cell_exclusivity_annotations.items():\\n# \\t# Not ideal. Adds a key \\'session_cell_exclusivity\\' to the extant session context instead of being indexable by an entirely new context\\n# \\tannotation_man.annotations[a_ctx] = annotation_man.annotations.get(a_ctx, {}) | dict(session_cell_exclusivity=a_val)\\n# \\t# annotation_man.annotations[a_ctx.overwriting_context(user_annotation=\\'session_cell_exclusivity\\')] = a_val\\n\\nannotation_man = UserAnnotationsManager()\\n\\nLxC_uids = []\\nSxC_uids = []\\n\\nfor a_ctxt in included_session_contexts:\\n\\tsession_uid = a_ctxt.get_description(separator=\"|\", include_property_names=False)\\n\\tsession_uid\\n\\tsession_cell_exclusivity: SessionCellExclusivityRecord = annotation_man.annotations[a_ctxt].get(\\'session_cell_exclusivity\\', None)\\n\\tLxC_uids.extend([f\"{session_uid}|{aclu}\" for aclu in session_cell_exclusivity.LxC])\\n\\tSxC_uids.extend([f\"{session_uid}|{aclu}\" for aclu in session_cell_exclusivity.SxC])\\n\\t\\n# [a_ctxt.get_description(separator=\"|\", include_property_names=False) for a_ctxt in included_session_contexts]\\n\\nlong_short_fr_indicies_analysis_table[\\'XxC_status\\'] = \\'Shared\\'\\nlong_short_fr_indicies_analysis_table.loc[np.isin(long_short_fr_indicies_analysis_table.neuron_uid, LxC_uids), \\'XxC_status\\'] = \\'LxC\\'\\nlong_short_fr_indicies_analysis_table.loc[np.isin(long_short_fr_indicies_analysis_table.neuron_uid, SxC_uids), \\'XxC_status\\'] = \\'SxC\\'\\n\\nlong_short_fr_indicies_analysis_table'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e5df97ff', 'metadata': {}, 'outputs': [], 'source': \"## 2023-10-11 - Get the long peak location\\n\\nlong_short_fr_indicies_analysis_table['long_pf_peak_x'] = neuron_replay_stats_table['long_pf_peak_x']\\nlong_short_fr_indicies_analysis_table\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'b1641aee', 'metadata': {}, 'outputs': [], 'source': \"matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\\nlong_short_fr_indicies_analysis_table.plot.scatter(x='long_pf_peak_x', y='x_frs_index', title='Pf Peak position vs. LapsFRI', ylabel='Lap FRI')\\n\\nlong_short_fr_indicies_analysis_table.plot.scatter(x='long_pf_peak_x', y='y_frs_index', title='Pf Peak position vs. ReplayFRI', ylabel='Replay FRI')\"}, {'cell_type': 'markdown', 'id': '0e9987dc', 'metadata': {}, 'source': ' #TODO 2023-10-05 11:40: - [ ] Extract the \"contrarian cells\", the ones that have a strong exclusivity on the laps but the opposite tendency on the replays\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'ce13554d', 'metadata': {}, 'outputs': [], 'source': \"long_short_fr_indicies_analysis_table.to_csv('output/2023-10-07_long_short_fr_indicies_analysis_table.csv')\"}, {'cell_type': 'markdown', 'id': '1427597f', 'metadata': {}, 'source': '# 2023-10-10 - Statistics for `across_sessions_bar_graphs`, analysing `across_session_inst_fr_computation` '}, {'cell_type': 'code', 'execution_count': None, 'id': 'e33422d9', 'metadata': {}, 'outputs': [], 'source': \"import scipy.stats as stats\\nfrom pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import pho_stats_perform_diagonal_line_binomial_test, pho_stats_bar_graph_t_tests\\n\\nbinom_test_chance_result = pho_stats_perform_diagonal_line_binomial_test(long_short_fr_indicies_analysis_table)\\nprint(f'binom_test_chance_result: {binom_test_chance_result}')\\n\\nLxC_Laps_T_result, SxC_Laps_T_result, LxC_Replay_T_result, SxC_Replay_T_result = pho_stats_bar_graph_t_tests(across_session_inst_fr_computation)\"}, {'cell_type': 'markdown', 'id': 'a24ea5a5', 'metadata': {}, 'source': '## 2023-10-04 - Run `AcrossSessionsVisualizations` corresponding to the PhoDibaPaper2023 figures for all sessions\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '7cc1152c', 'metadata': {'tags': []}, 'outputs': [], 'source': '## Hacks the `PaperFigureTwo` and `InstantaneousSpikeRateGroupsComputation` \\nglobal_multi_session_context, _out_aggregate_fig_2 = AcrossSessionsVisualizations.across_sessions_bar_graphs(across_session_inst_fr_computation, num_sessions, enable_tiny_point_labels=False, enable_hover_labels=False)\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c437e42f', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsVisualizations\\n\\nmatplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\\ngraphics_output_dict = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=num_sessions, save_figure=True)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'ff34b020', 'metadata': {}, 'outputs': [], 'source': \"matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\\ngraphics_output_dict = AcrossSessionsVisualizations.across_sessions_long_and_short_firing_rate_replays_v_laps_figure(neuron_replay_stats_table=neuron_replay_stats_table, num_sessions=num_sessions, save_figure=True)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '00dd481a', 'metadata': {}, 'outputs': [], 'source': 'ann_man = UserAnnotationsManager()\\nincluded_annotations = {ctxt:ann_man.annotations[ctxt].get(\\'session_cell_exclusivity\\', None) for ctxt in included_session_contexts}\\n\\nall_LxCs = []\\nall_SxCs = []\\n\\nfor ctxt, an_ann in included_annotations.items():\\n\\tsession_ctxt_key:str = ctxt.get_description(separator=\\'|\\', subset_includelist=IdentifyingContext._get_session_context_keys())\\n\\tall_LxCs.extend([f\"{session_ctxt_key}|{aclu}\" for aclu in an_ann.LxC])\\n\\tall_SxCs.extend([f\"{session_ctxt_key}|{aclu}\" for aclu in an_ann.SxC])\\n\\t\\nall_LxCs'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c1222a17', 'metadata': {}, 'outputs': [], 'source': 'all_SxCs'}, {'cell_type': 'code', 'execution_count': 10, 'id': '1381fcf5', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [{'ename': 'NameError', 'evalue': \"name 'across_session_inst_fr_computation' is not defined\", 'output_type': 'error', 'traceback': ['\\x1b[0;31m---------------------------------------------------------------------------\\x1b[0m', '\\x1b[0;31mNameError\\x1b[0m                                 Traceback (most recent call last)', \"\\x1b[1;32m/home/halechr/repos/Spike3D/BatchGenerateOutputs_2023-11-10.ipynb Cell 66\\x1b[0m line \\x1b[0;36m1\\n\\x1b[0;32m----> <a href='vscode-notebook-cell:/home/halechr/repos/Spike3D/BatchGenerateOutputs_2023-11-10.ipynb#Y122sZmlsZQ%3D%3D?line=0'>1</a>\\x1b[0m across_session_inst_fr_computation\\x1b[39m.\\x1b[39mLxC_scatter_props\\n\\x1b[1;32m      <a href='vscode-notebook-cell:/home/halechr/repos/Spike3D/BatchGenerateOutputs_2023-11-10.ipynb#Y122sZmlsZQ%3D%3D?line=1'>2</a>\\x1b[0m across_session_inst_fr_computation\\x1b[39m.\\x1b[39mSxC_scatter_props\\n\", \"\\x1b[0;31mNameError\\x1b[0m: name 'across_session_inst_fr_computation' is not defined\"]}], 'source': 'across_session_inst_fr_computation.LxC_scatter_props\\nacross_session_inst_fr_computation.SxC_scatter_props'}, {'cell_type': 'code', 'execution_count': None, 'id': '63258151', 'metadata': {}, 'outputs': [], 'source': '## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\\nglobal_multi_session_context = IdentifyingContext(format_name=\\'kdiba\\', num_sessions=num_sessions) # some global context across all of the sessions, not sure what to put here.\\n\\n# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\\n\\n## Display the aggregate across sessions:\\n_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn\\'t save this info\\n_out_fig_2.computation_result = across_session_inst_fr_computation # the result loaded from the file\\n_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\\n# Set callback, the only self-specific property\\n# _out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)\\n_out_fig_2.scatter_props_fn = _return_scatter_props_fn'}, {'cell_type': 'code', 'execution_count': None, 'id': '50e9d06b', 'metadata': {}, 'outputs': [], 'source': 'LxC_aclus = _out_fig_2.computation_result.LxC_aclus\\nSxC_aclus = _out_fig_2.computation_result.SxC_aclus\\n\\nLxC_aclus'}, {'cell_type': 'code', 'execution_count': None, 'id': '96c498f8', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureOutputManager, FigureOutputLocation, ContextToPathMode\\n\\nregistered_output_files = {}\\n\\ndef output_figure(final_context: IdentifyingContext, fig, write_vector_format:bool=False, write_png:bool=True, debug_print=True):\\n    \"\"\" outputs the figure using the provided context. \"\"\"\\n    from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_and_write_to_file\\n    def register_output_file(output_path, output_metadata=None):\\n        \"\"\" registers a new output file for the pipeline \"\"\"\\n        print(f\\'register_output_file(output_path: {output_path}, ...)\\')\\n        registered_output_files[output_path] = output_metadata or {}\\n\\n    fig_out_man = FigureOutputManager(figure_output_location=FigureOutputLocation.DAILY_PROGRAMMATIC_OUTPUT_FOLDER, context_to_path_mode=ContextToPathMode.HIERARCHY_UNIQUE)\\n    active_out_figure_paths = build_and_write_to_file(fig, final_context, fig_out_man, write_vector_format=write_vector_format, write_png=write_png, register_output_file_fn=register_output_file)\\n    return active_out_figure_paths, final_context\\n\\n\\n# Set callback, the only self-specific property\\n_out_fig_2._pipeline_file_callback_fn = output_figure'}, {'cell_type': 'code', 'execution_count': None, 'id': '1db0f1d5', 'metadata': {}, 'outputs': [], 'source': '_out_fig_2.computation_result.Fig2_Laps_FR'}, {'cell_type': 'code', 'execution_count': None, 'id': '17ef9f3d', 'metadata': {}, 'outputs': [], 'source': '_out_fig_2.computation_result.Fig2_Laps_FR'}, {'cell_type': 'code', 'execution_count': None, 'id': 'a694ec1c', 'metadata': {}, 'outputs': [], 'source': '# Showing\\nrestore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend=\\'Qt5Agg\\')\\n# Perform interactive Matplotlib operations with \\'Qt5Agg\\' backend\\n_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\\n\\t\\n_out_fig_2.perform_save()'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c96ed659', 'metadata': {}, 'outputs': [], 'source': '## 2023-10-11 - Surprise Shuffling\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '7d829b90', 'metadata': {}, 'outputs': [], 'source': ''}]\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "\n",
    "def extract_cells(notebook_path):\n",
    "    \"\"\" extracts the cells from the provided notebook. \"\"\"\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as notebook_file:\n",
    "        notebook_content = nbformat.read(notebook_file, as_version=4)\n",
    "\n",
    "    cells = notebook_content['cells']\n",
    "    return cells\n",
    "\n",
    "# Example usage\n",
    "notebook_path = '../BatchGenerateOutputs_2023-11-10.ipynb'\n",
    "extracted_cells = extract_cells(notebook_path)\n",
    "print(extracted_cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': \"%config IPCompleter.use_jedi = False\\n%pdb off\\n%load_ext autoreload\\n%autoreload 3\\nimport sys\\nfrom copy import deepcopy\\nfrom typing import List, Dict, Optional, Union, Callable\\nfrom pathlib import Path\\nimport pathlib\\nimport numpy as np\\nimport pandas as pd\\nimport tables as tb\\nfrom copy import deepcopy\\nfrom datetime import datetime, timedelta\\nfrom attrs import define, field, Factory\\n\\n# required to enable non-blocking interaction:\\n%gui qt5\\n\\n## Pho's Custom Libraries:\\nfrom pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\\nfrom pyphocorehelpers.function_helpers import function_attributes\\nfrom pyphocorehelpers.print_helpers import CapturedException\\n\\n# Jupyter interactivity:\\nimport ipywidgets as widgets\\nfrom IPython.display import display\\nfrom pyphocorehelpers.gui.Jupyter.JupyterButtonRowWidget import JupyterButtonRowWidget\\n\\n# pyPhoPlaceCellAnalysis:\\n# NeuroPy (Diba Lab Python Repo) Loading\\nfrom neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\\nfrom neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\\nfrom neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\\nfrom neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\\nfrom neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\\nfrom neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\\n\\n## For computation parameters:\\nfrom neuropy.utils.result_context import IdentifyingContext\\nfrom neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\\nfrom neuropy.core import Epoch\\n\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\\nimport pyphoplacecellanalysis.General.Batch.runBatch\\nfrom pyphoplacecellanalysis.General.Batch.runBatch import BatchRun, BatchResultDataframeAccessor, run_diba_batch, BatchComputationProcessOptions, BatchSessionCompletionHandler, SavingOptions\\nfrom pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\\n\\nfrom neuropy.core.user_annotations import UserAnnotationsManager\\nfrom pyphoplacecellanalysis.General.Batch.runBatch import SessionBatchProgress\\nfrom pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionTables, AcrossSessionsVisualizations\\n\\nfrom pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\\n\\nfrom pyphocorehelpers.print_helpers import CapturedException\\nfrom pyphoplacecellanalysis.General.Batch.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor\\nfrom pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult, BatchSessionCompletionHandler\\n\\nfrom pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_file_metadata\\nfrom pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file, save_copydict_to_text_file, read_copydict_from_text_file, invert_filedict\\nfrom pyphoplacecellanalysis.General.Batch.runBatch import get_file_str_if_file_exists\\nfrom pyphoplacecellanalysis.General.Batch.AcrossSessionResults import check_output_h5_files, copy_files_in_filelist_to_dest\\nfrom pyphoplacecellanalysis.General.Batch.runBatch import ConcreteSessionFolder, BackupMethods\\n\\nfrom pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots, BatchPhoJonathanFiguresHelper\\nfrom pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\\n\\nfrom neuropy.core.neuron_identities import NeuronIdentityDataframeAccessor\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import build_merged_neuron_firing_rate_indicies\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsHelpers\\n\\n# BATCH_DATE_TO_USE = '2023-10-20' # used for filenames throught the notebook\\n# BATCH_DATE_TO_USE = '2023-10-18_Apogee' # used for filenames throught the notebook\\nBATCH_DATE_TO_USE = '2023-11-10_GL' # used for filenames throught the notebook\",\n",
       "  'tags': ['imports', 'REQUIRED', 'ACTIVE']}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells_with_tags = []\n",
    "for cell in extracted_cells:\n",
    "\tcell_content = cell['source']\n",
    "\tcell_tags = cell['metadata'].get('tags', None)\n",
    "\tif (cell_tags is not None) and (len(cell_tags) > 0):\n",
    "\t\tcells_with_tags.append({'content': cell_content, 'tags': cell_tags})\n",
    "\n",
    "cells_with_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
