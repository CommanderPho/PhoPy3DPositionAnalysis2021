{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from typing import List, Dict, Optional, Union, Callable\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables as tb\n",
    "from copy import deepcopy\n",
    "from datetime import datetime, timedelta\n",
    "from attrs import define, field, Factory\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import CapturedException\n",
    "\n",
    "# Jupyter interactivity:\n",
    "import os\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.gui.Jupyter.JupyterButtonRowWidget import JupyterButtonRowWidget\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core import Epoch\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "import pyphoplacecellanalysis.General.Batch.runBatch\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun, BatchResultDataframeAccessor, run_diba_batch, BatchComputationProcessOptions, BatchSessionCompletionHandler, SavingOptions\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import SessionBatchProgress\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults, AcrossSessionTables, AcrossSessionsVisualizations\n",
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "\n",
    "from pyphocorehelpers.print_helpers import CapturedException\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult, BatchSessionCompletionHandler\n",
    "\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_file_metadata\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file, save_copydict_to_text_file, read_copydict_from_text_file, invert_filedict\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import get_file_str_if_file_exists\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import check_output_h5_files, copy_files_in_filelist_to_dest\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import ConcreteSessionFolder, BackupMethods\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots, BatchPhoJonathanFiguresHelper\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "\n",
    "from neuropy.core.neuron_identities import NeuronIdentityDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import build_merged_neuron_firing_rate_indicies\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsHelpers\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display, Javascript\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers\n",
    "from pyphocorehelpers.programming_helpers import CodeParsers\n",
    "from pyphocorehelpers.programming_helpers import NotebookProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/SCRATCH/2023-11-13 - Programmatic ipynb Processing.ipynb')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Finds the path of THIS notebook:\n",
    "notebook_path = Path(IPythonHelpers.try_find_notebook_filepath(IPython.extract_module_locals())).resolve()\n",
    "notebook_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'cell_type': 'code', 'execution_count': None, 'id': 'initial_id', 'metadata': {'ExecuteTime': {'end_time': '2023-11-16T23:21:20.608442900Z', 'start_time': '2023-11-16T23:21:20.217442100Z'}, 'collapsed': True, 'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': '%config IPCompleter.use_jedi = False\\n# %xmode Verbose\\n# %xmode context\\n%pdb off\\n%load_ext viztracer\\nfrom viztracer import VizTracer\\n%load_ext autoreload\\n%autoreload 3\\nimport sys\\nfrom typing import Dict, List, Tuple, Optional\\nfrom pathlib import Path\\n\\n# required to enable non-blocking interaction:\\n%gui qt5\\n\\nfrom copy import deepcopy\\nfrom numba import jit\\nimport numpy as np\\nimport pandas as pd\\npd.options.mode.chained_assignment = None  # default=\\'warn\\'\\n# pd.options.mode.dtype_backend = \\'pyarrow\\' # use new pyarrow backend instead of numpy\\nfrom attrs import define, field, fields, Factory\\nimport tables as tb\\nfrom datetime import datetime, timedelta\\n\\n# Pho\\'s Formatting Preferences\\nimport builtins\\n\\nimport IPython\\nfrom IPython.core.formatters import PlainTextFormatter\\nfrom IPython import get_ipython\\n\\nfrom pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\\nset_pho_preferences_concise()\\n# Jupyter-lab enable printing for any line on its own (instead of just the last one in the cell)\\nfrom IPython.core.interactiveshell import InteractiveShell\\nInteractiveShell.ast_node_interactivity = \"all\"\\n\\n# BEGIN PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\\n\\n\\n## IPython pprint\\nfrom pyphocorehelpers.pprint import wide_pprint, wide_pprint_ipython, wide_pprint_jupyter, MAX_LINE_LENGTH\\n\\n# Override default pprint\\nbuiltins.pprint = wide_pprint\\n\\ntext_formatter: PlainTextFormatter = IPython.get_ipython().display_formatter.formatters[\\'text/plain\\']\\ntext_formatter.max_width = MAX_LINE_LENGTH\\ntext_formatter.for_type(object, wide_pprint_jupyter)\\n\\n\\n# END PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\\n\\nfrom pyphocorehelpers.print_helpers import get_now_time_str, get_now_day_str\\n\\n## Pho\\'s Custom Libraries:\\nfrom pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path, file_uri_from_path\\nfrom pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\\n\\n# NeuroPy (Diba Lab Python Repo) Loading\\n# from neuropy import core\\nfrom neuropy.analyses.placefields import PlacefieldComputationParameters\\nfrom neuropy.core.epoch import NamedTimerange, Epoch\\nfrom neuropy.core.ratemap import Ratemap\\nfrom neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\\nfrom neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\\nfrom neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\\nfrom neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\\nfrom neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field, custom_define\\nfrom neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin, HDF_Converter\\n\\n## For computation parameters:\\nfrom neuropy.analyses.placefields import PlacefieldComputationParameters\\nfrom neuropy.utils.dynamic_container import DynamicContainer\\nfrom neuropy.utils.result_context import IdentifyingContext\\nfrom neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\\nfrom neuropy.core.neurons import NeuronType\\nfrom neuropy.core.user_annotations import UserAnnotationsManager\\nfrom neuropy.core.position import Position\\nfrom neuropy.core.session.dataSession import DataSession\\nfrom neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\\nfrom neuropy.utils.debug_helpers import debug_print_placefield, debug_print_subsession_neuron_differences, debug_print_ratemap, debug_print_spike_counts, debug_plot_2d_binning, print_aligned_columns\\nfrom neuropy.utils.debug_helpers import parameter_sweeps, _plot_parameter_sweep, compare_placefields_info\\nfrom neuropy.utils.indexing_helpers import NumpyHelpers, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies, paired_incremental_sorting\\nfrom pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, CapturedException, document_active_variables\\n\\n## Pho Programming Helpers:\\nimport inspect\\nfrom pyphocorehelpers.print_helpers import DocumentationFilePrinter, TypePrintMode, print_keys_if_possible, debug_dump_object_member_shapes, print_value_overview_only, document_active_variables, CapturedException\\nfrom pyphocorehelpers.programming_helpers import IPythonHelpers, PythonDictionaryDefinitionFormat, MemoryManagement, inspect_callable_arguments, get_arguments_as_optional_dict, GeneratedClassDefinitionType, CodeConversion\\nfrom pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper, print_widget_hierarchy\\ndoc_output_parent_folder: Path = Path(\\'EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation\\').resolve() # ../.\\nprint(f\"doc_output_parent_folder: {doc_output_parent_folder}\")\\nassert doc_output_parent_folder.exists()\\n\\n# pyPhoPlaceCellAnalysis:\\nfrom pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\\nfrom pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\\nfrom pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_extended_programmatic_figures\\nfrom pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\\n\\nimport pyphoplacecellanalysis.External.pyqtgraph as pg\\n\\nfrom pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\\nfrom pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\\nfrom pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\\nfrom pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\\nfrom pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\\nfrom pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsResult, TrackTemplates\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer, RankOrderResult\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses\\n\\n\\n# Plotting\\n# import pylustrator # customization of figures\\nimport matplotlib\\nimport matplotlib as mpl\\nimport matplotlib.pyplot as plt\\n_bak_rcParams = mpl.rcParams.copy()\\n\\nmatplotlib.use(\\'Qt5Agg\\')\\n# %matplotlib inline\\n# %matplotlib auto\\n\\n# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend=\\'Qt5Agg\\')\\n_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend=\\'Qt5Agg\\')\\n\\n# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\\nfrom pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\\nfrom pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\\nfrom pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\\nfrom pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\\nfrom pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\\nfrom pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\\n\\nfrom pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\\nfrom pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\\n\\n# Jupyter Widget Interactive\\nimport ipywidgets as widgets\\nfrom IPython.display import display, HTML\\nfrom pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\\nfrom pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\\nfrom pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget, render_colors\\n\\nfrom datetime import datetime, date, timedelta\\nfrom pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\\n\\nDAY_DATE_STR: str = date.today().strftime(\"%Y-%m-%d\")\\nDAY_DATE_TO_USE = f\\'{DAY_DATE_STR}\\' # used for filenames throught the notebook\\nprint(f\\'DAY_DATE_STR: {DAY_DATE_STR}, DAY_DATE_TO_USE: {DAY_DATE_TO_USE}\\')\\n\\nNOW_DATETIME: str = get_now_rounded_time_str()\\nNOW_DATETIME_TO_USE = f\\'{NOW_DATETIME}\\' # used for filenames throught the notebook\\nprint(f\\'NOW_DATETIME: {NOW_DATETIME}, NOW_DATETIME_TO_USE: {NOW_DATETIME_TO_USE}\\')\\n\\n\\nfrom pyphocorehelpers.gui.Jupyter.simple_widgets import build_global_data_root_parent_path_selection_widget\\nall_paths = [Path(r\\'/media/MAX/Data\\'), Path(r\\'/media/halechr/MAX/Data\\'), Path(r\\'/home/halechr/FastData\\'), Path(r\\'W:\\\\Data\\'), Path(r\\'/home/halechr/cloud/turbo/Data\\'), Path(r\\'/Volumes/MoverNew/data\\'), Path(r\\'/home/halechr/turbo/Data\\')]\\nglobal_data_root_parent_path = None\\ndef on_user_update_path_selection(new_path: Path):\\n\\tglobal global_data_root_parent_path\\n\\tnew_global_data_root_parent_path = new_path.resolve()\\n\\tglobal_data_root_parent_path = new_global_data_root_parent_path\\n\\tprint(f\\'global_data_root_parent_path changed to {global_data_root_parent_path}\\')\\n\\tassert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer\\'s config commented out above?\"\\n\\t\\t\\t\\nglobal_data_root_parent_path_widget = build_global_data_root_parent_path_selection_widget(all_paths, on_user_update_path_selection)\\nglobal_data_root_parent_path_widget'}, {'cell_type': 'markdown', 'id': '30db844b', 'metadata': {}, 'source': '# Load Pipeline'}, {'cell_type': 'code', 'execution_count': None, 'id': '7f07773d', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': '# ==================================================================================================================== #\\n# Load Data                                                                                                            #\\n# ==================================================================================================================== #\\n\\nactive_data_mode_name = \\'kdiba\\'\\nlocal_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name=\\'\\', configuration_name=\\'one\\', session_name=a_sess.session_name\\nlocal_session_root_parent_path = global_data_root_parent_path.joinpath(\\'KDIBA\\')\\n\\n# [*] - indicates bad or session with a problem\\n# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \\n# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'gor01\\',exper_name=\\'one\\',session_name=\\'2006-6-08_14-26-15\\') # DONE. Very good. Many good Pfs, many good replays.\\ncurr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'gor01\\',exper_name=\\'one\\',session_name=\\'2006-6-09_1-22-43\\') # DONE, might be the BEST SESSION, good example session with lots of place cells, clean replays, and clear bar graphs.\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'gor01\\',exper_name=\\'one\\',session_name=\\'2006-6-12_15-55-31\\') # DONE, Good Pfs but no good replays ---- VERY weird effect of the replays, a sharp drop to strongly negative values more than 3/4 through the experiment.\\n\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'gor01\\',exper_name=\\'one\\',session_name=\\'2006-6-13_14-42-6\\') # BAD, 2023-07-14, unsure why still.\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'gor01\\',exper_name=\\'two\\',session_name=\\'2006-6-07_16-40-19\\') # DONE, GREAT, both good Pfs and replays! Interesting see-saw!\\n\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'gor01\\',exper_name=\\'two\\',session_name=\\'2006-6-08_21-16-25\\') # DONE, Added replay selections. Very \"jumpy\" between the starts and ends of the track.\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'gor01\\',exper_name=\\'two\\',session_name=\\'2006-6-09_22-24-40\\') # 2024-01-10 new RANKORDER APOGEE | DONE, Added replay selections. A TON of putative replays in general, most bad, but some good. LOOKIN GOOD!\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'gor01\\',exper_name=\\'twolong_LR_pf1Dsession_name=\\'2006-4-12_15-25-59\\') # BAD, No Epochs\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'vvp01\\',exper_name=\\'two\\',session_name=\\'2006-4-16_18-47-52\\')\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'vvp01\\',exper_name=\\'two\\',session_name=\\'2006-4-17_12-52-15\\')\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'vvp01\\',exper_name=\\'two\\',session_name=\\'2006-4-25_13-20-55\\')\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'vvp01\\',exper_name=\\'two\\',session_name=\\'2006-4-28_12-38-13\\')\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'pin01\\',exper_name=\\'one\\',session_name=\\'11-02_17-46-44\\') # DONE, good. Many good pfs, many good replays. Noticed very strange jumping off the track in the 3D behavior/spikes viewer. Is there something wrong with this session?\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'pin01\\',exper_name=\\'one\\',session_name=\\'11-02_19-28-0\\') # DONE, good?, replays selected, few --- \"ZeroDivisionError: float division by zero\"\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'pin01\\',exper_name=\\'one\\',session_name=\\'11-03_12-3-25\\') # DONE, very few replays\\n\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'pin01\\',exper_name=\\'one\\',session_name=\\'11-09_12-15-3\\') ### KeyError: \\'maze1_odd\\'\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'pin01\\',exper_name=\\'one\\',session_name=\\'11-09_22-4-5\\') ### \\n\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'pin01\\',exper_name=\\'one\\',session_name=\\'fet11-01_12-58-54\\') # DONE, replays selected, quite a few replays but few are very good.\\n\\n# curr_context = IdentifyingContext(format_name=\\'kdiba\\',animal=\\'gor01\\',exper_name=\\'two\\',session_name=\\'2006-6-08_21-16-25\\')\\n\\nlocal_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # \\'gor01\\', \\'one\\' - probably not needed anymore\\nbasedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\\nprint(f\\'basedir: {str(basedir)}\\')\\n\\n# Read if possible:\\nsaving_mode = PipelineSavingScheme.SKIP_SAVING\\nforce_reload = False\\n# \\n# # Force write:\\n# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\\n# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\\n# force_reload = True\\n\\n## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\\n\\n# ==================================================================================================================== #\\n# Load Pipeline                                                                                                        #\\n# ==================================================================================================================== #\\n# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\\n# epoch_name_includelist = [\\'maze\\']\\nepoch_name_includelist = None\\nactive_computation_functions_name_includelist=[\\'lap_direction_determination\\', \\'pf_computation\\',\\n                                            #    \\'pfdt_computation\\',\\n                                                \\'firing_rate_trends\\',\\n                                                # \\'pf_dt_sequential_surprise\\', \\n                                            #    \\'ratemap_peaks_prominence2d\\',\\n                                                \\'position_decoding\\', \\n                                                # \\'position_decoding_two_step\\', \\n                                            #    \\'long_short_decoding_analyses\\', \\'jonathan_firing_rate_analysis\\', \\'long_short_fr_indicies_analyses\\', \\'short_long_pf_overlap_analyses\\', \\'long_short_post_decoding\\', \\'long_short_rate_remapping\\',\\n                                            #     \\'long_short_inst_spike_rate_groups\\',\\n                                            #     \\'long_short_endcap_analysis\\',\\n                                            # \\'split_to_directional_laps\\',\\n]\\n\\ncurr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\\n                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\\n                                        saving_mode=saving_mode, force_reload=force_reload,\\n                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True) # , active_pickle_filename = \\'loadedSessPickle_withParameters.pkl\\'\\n\\n\\n\\n## Post Compute Validate 2023-05-16:\\nwas_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\\nif was_updated:\\n    print(f\\'was_updated: {was_updated}\\')\\n    try:\\n        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\\n    except Exception as e:\\n        ## TODO: catch/log saving error and indicate that it isn\\'t saved.\\n        exception_info = sys.exc_info()\\n        e = CapturedException(e, exception_info)\\n        print(f\\'ERROR RE-SAVING PIPELINE after update. error: {e}\\')\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '188ed6fa', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': 'list(curr_active_pipeline.global_computation_results.computed_data.keys())\\n\\n\\n# 2024-01-22 ERROR: when the pipeline is manually saved, its global_computations seem to be saved to the pickle too. After modifying how global computations are loaded from pickle, the following global computations code block no longer appropriately overwrites the existing results.'}, {'cell_type': 'code', 'execution_count': None, 'id': 'fd94b83e', 'metadata': {}, 'outputs': [], 'source': \"global_dropped_keys, local_dropped_keys = curr_active_pipeline.perform_drop_computed_result(computed_data_keys_to_drop=['DirectionalLaps', 'DirectionalMergedDecoders', 'RankOrder', 'DirectionalDecodersDecoded'], debug_print=True)\\n# global_dropped_keys, local_dropped_keys = curr_active_pipeline.perform_drop_computed_result(computed_data_keys_to_drop=[k for k in list(curr_active_pipeline.global_computation_results.computed_data.keys())], debug_print=True) # drop all global keys\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'acba46b6', 'metadata': {'ExecuteTime': {'end_time': '2023-11-16T23:21:40.574268400Z', 'start_time': '2023-11-16T23:21:35.966373700Z'}, 'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': '### GLOBAL COMPUTATIONS:\\nextended_computations_include_includelist=[\\'lap_direction_determination\\', #\\'pf_computation\\', \\'firing_rate_trends\\',# \\'pfdt_computation\\',\\n    # \\'pf_dt_sequential_surprise\\',\\n     \\'ratemap_peaks_prominence2d\\',\\n    \\'long_short_decoding_analyses\\', \\'jonathan_firing_rate_analysis\\', \\'long_short_fr_indicies_analyses\\', \\'short_long_pf_overlap_analyses\\', \\n    \\'long_short_post_decoding\\', # #TODO 2024-01-19 05:49: - [ ] `\\'long_short_post_decoding\\' is broken for some reason `AttributeError: \\'NoneType\\' object has no attribute \\'active_filter_epochs\\'``\\n    \\'long_short_rate_remapping\\',\\n    \\'long_short_inst_spike_rate_groups\\',\\n    \\'long_short_endcap_analysis\\',\\n    # \\'spike_burst_detection\\',\\n    \\'split_to_directional_laps\\',\\n    \\'merged_directional_placefields\\',\\n    \\'rank_order_shuffle_analysis\\',\\n    \\'directional_decoders_decode_continuous\\'\\n] # do only specified\\n\\nforce_recompute_override_computations_includelist = None\\n# force_recompute_override_computations_includelist = [\\'merged_directional_placefields\\']\\n# force_recompute_override_computations_includelist = [\\'split_to_directional_laps\\', \\'merged_directional_placefields\\', \\'rank_order_shuffle_analysis\\'] # , \\'directional_decoders_decode_continuous\\'\\n# force_recompute_override_computations_includelist = [\\'directional_decoders_decode_continuous\\'] # \\n\\n\\nif not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\\n    try:\\n        # curr_active_pipeline.load_pickled_global_computation_results()\\n        curr_active_pipeline.load_pickled_global_computation_results(allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist) # is new\\n    except Exception as e:\\n        exception_info = sys.exc_info()\\n        e = CapturedException(e, exception_info)\\n        print(f\\'cannot load global results: {e}\\')\\n        raise\\n\\ncurr_active_pipeline.reload_default_computation_functions()\\n\\nforce_recompute_global = force_reload\\n# force_recompute_global = True\\nnewly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\\n                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\\nif (len(newly_computed_values) > 0):\\n    print(f\\'newly_computed_values: {newly_computed_values}.\\')\\n    if (saving_mode.value != \\'skip_saving\\'):\\n        print(f\\'Saving global results...\\')\\n        try:\\n            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\\n            # Try to write out the global computation function results:\\n            curr_active_pipeline.save_global_computation_results()\\n        except Exception as e:\\n            exception_info = sys.exc_info()\\n            e = CapturedException(e, exception_info)\\n            print(f\\'\\\\n\\\\n!!WARNING!!: saving the global results threw the exception: {e}\\')\\n            print(f\\'\\\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\\\n\\\\n\\\\n\\')\\n    else:\\n        print(f\\'\\\\n\\\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"\\')\\n        print(f\\'\\\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\\\n\\\\n\\\\n\\')\\nelse:\\n    print(f\\'no changes in global results.\\')\\n\\n# except Exception as e:\\n#     exception_info = sys.exc_info()\\n#     e = CapturedException(e, exception_info)\\n#     print(f\\'second half threw: {e}\\')\\n\\n# 4m 5.2s for inst fr computations\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'ee3d4f61', 'metadata': {}, 'outputs': [], 'source': 'curr_active_pipeline.reload_default_computation_functions()\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '47820977', 'metadata': {}, 'outputs': [], 'source': \"\\nextended_computations_include_includelist=['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation',\\n    # 'pf_dt_sequential_surprise',\\n    #  'ratemap_peaks_prominence2d',\\n    'long_short_decoding_analyses',\\n    'jonathan_firing_rate_analysis',\\n    'long_short_fr_indicies_analyses',\\n    'short_long_pf_overlap_analyses',\\n    'long_short_post_decoding',\\n    'long_short_rate_remapping',\\n    'long_short_inst_spike_rate_groups',\\n    'long_short_endcap_analysis',\\n    # 'spike_burst_detection',\\n    'split_to_directional_laps',\\n    'merged_directional_placefields',\\n    'rank_order_shuffle_analysis',\\n    'directional_decoders_decode_continuous'\\n] # do only specified\\n\\n# force_recompute_override_computations_includelist = ['split_to_directional_laps',\\n#     # 'merged_directional_placefields',\\n#     # 'directional_decoders_decode_continuous',\\n# ]\\nforce_recompute_override_computations_includelist = None\\n\\nnewly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\\n                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\\nnewly_computed_values\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '4262dd1b', 'metadata': {}, 'outputs': [], 'source': '\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '272e20f8', 'metadata': {}, 'outputs': [], 'source': \"# curr_active_pipeline.reload_default_computation_functions()\\n# force_recompute_override_computations_includelist = ['_decode_continuous_using_directional_decoders']\\n# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_decode_continuous_using_directional_decoders'], force_recompute_override_computations_includelist=force_recompute_override_computations_includelist,\\n# \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   enabled_filter_names=None, fail_on_exception=True, debug_print=False)\\n# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_decode_continuous_using_directional_decoders'], computation_kwargs_list=[{'time_bin_size': 0.025}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\\n# curr_active_pipeline.perform_specific_computation(extended_computations_include_includelist=['_decode_continuous_using_directional_decoders'], computation_kwargs_list=[{'time_bin_size': 0.02}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\\ncurr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['pfdt_computation'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '0b7ab89f', 'metadata': {}, 'outputs': [], 'source': \"curr_active_pipeline.save_global_computation_results() # newly_computed_values: [('pfdt_computation', 'maze_any')]\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'ec7af96d', 'metadata': {}, 'outputs': [], 'source': 'split_save_folder, split_save_paths, split_save_output_types, failed_keys = curr_active_pipeline.save_split_global_computation_results(debug_print=True)'}, {'cell_type': 'markdown', 'id': '77babf98', 'metadata': {}, 'source': '## Continue Saving/Exporting stuf'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c2a869b1', 'metadata': {}, 'outputs': [], 'source': 'curr_active_pipeline.export_pipeline_to_h5()'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e3f06d1f', 'metadata': {}, 'outputs': [], 'source': 'curr_active_pipeline.clear_display_outputs()\\ncurr_active_pipeline.clear_registered_output_files()'}, {'cell_type': 'code', 'execution_count': None, 'id': '837f39f2', 'metadata': {}, 'outputs': [], 'source': 'curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE)\\n# curr_active_pipeline.save_pipeline()'}, {'cell_type': 'markdown', 'id': '693db067', 'metadata': {}, 'source': '# Pho Interactive Pipeline Jupyter Widget'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e275e3bb', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': 'import ipywidgets as widgets\\nfrom IPython.display import display\\nfrom pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\\nfrom pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\\n\\n_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\\n# display(_pipeline_jupyter_widget)\\n_pipeline_jupyter_widget'}, {'cell_type': 'markdown', 'id': '1fe54599', 'metadata': {}, 'source': '# End Run'}, {'cell_type': 'code', 'execution_count': None, 'id': '1a533ba8', 'metadata': {'ExecuteTime': {'end_time': '2023-11-16T23:21:40.700275900Z', 'start_time': '2023-11-16T23:21:40.584273Z'}, 'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': \"# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\\nlong_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\\nlong_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\\nlong_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\\nlong_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\\nlong_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\\nlong_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\\nlong_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\\nlong_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\\n\\nassert short_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\\nassert long_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\\n\\nt_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\\nt_start, t_delta, t_end\"}, {'cell_type': 'code', 'execution_count': None, 'id': '92b35196', 'metadata': {}, 'outputs': [], 'source': \"# I have several python variables I want to print: t_start, t_delta, t_end\\n# I want to generate a print statement that explicitly lists the variable name prior to its value like `print(f't_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')`\\n# Currently I have to t_start, t_delta, t_end\\ncurr_active_pipeline.get_session_context()\\n\\nprint(f'{curr_active_pipeline.session_name}:\\\\tt_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '9071e94f', 'metadata': {'ExecuteTime': {'end_time': '2023-11-16T23:21:43.601382Z', 'start_time': '2023-11-16T23:21:40.702275600Z'}, 'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': \"## long_short_decoding_analyses:\\nfrom attrs import astuple\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import LeaveOneOutDecodingAnalysis\\n\\ncurr_long_short_decoding_analyses: LeaveOneOutDecodingAnalysis = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\\nlong_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global \\ndecoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\\n\\n## Get global `long_short_fr_indicies_analysis`:\\nlong_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\\nlong_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\\nlong_short_fr_indicies_df = long_short_fr_indicies_analysis_results['long_short_fr_indicies_df']\\n\\n## Get global 'long_short_post_decoding' results:\\ncurr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\\nexpected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\\nrate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\\nFlat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result.Flat_epoch_time_bins_mean, expected_v_observed_result.Flat_decoder_time_bin_centers, expected_v_observed_result.num_neurons, expected_v_observed_result.num_timebins_in_epoch, expected_v_observed_result.num_total_flat_timebins, expected_v_observed_result.is_short_track_epoch, expected_v_observed_result.is_long_track_epoch, expected_v_observed_result.short_short_diff, expected_v_observed_result.long_long_diff\\n\\njonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\\n(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\\nneuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.05)\\n\\n## Update long_exclusive/short_exclusive properties with `long_short_fr_indicies_df`\\n# long_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\\n# short_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '4ba8f0cf', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': 'curr_long_short_decoding_analyses.long_results_obj'}, {'cell_type': 'code', 'execution_count': None, 'id': 'b83acf39', 'metadata': {}, 'outputs': [], 'source': 'expected_v_observed_result.observed_from_expected_diff_ptp_LONG'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c49f5d4f', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': '# Unpack all directional variables:\\n## {\"even\": \"RL\", \"odd\": \"LR\"}\\nlong_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = [\\'maze1_odd\\', \\'maze2_odd\\', \\'maze_odd\\', \\'maze1_even\\', \\'maze2_even\\', \\'maze_even\\', \\'maze1_any\\', \\'maze2_any\\', \\'maze_any\\']\\n\\n# Most popular\\n# long_LR_name, short_LR_name, long_RL_name, short_RL_name, global_any_name\\n\\n# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\\n(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\\nlong_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\\n(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\\n(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\\n(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\\n(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\\n(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\\n(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '7104fc37', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalMergedDecodersResult, DirectionalLapsResult, DirectionalDecodersDecodedResult\\n\\ndirectional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\\ndirectional_merged_decoders_result: DirectionalMergedDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']   \\nrank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\\nminimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\\nincluded_qclu_values: float = rank_order_results.included_qclu_values\\nprint(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\\nprint(f'included_qclu_values: {included_qclu_values}')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '65751b8a', 'metadata': {}, 'outputs': [], 'source': \"# Export the decoded epochs to a file so they can be compared across sessions?\\ndirectional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result.to_hdf(Path('output/all_directional_laps_filter_epochs_decoder_result.hdf').resolve(), 'all_directional_laps_filter_epochs_decoder_result', enable_hdf_testing_mode=True, debug_print=True)\\ndirectional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result.filter_epochs.to_hdf('output/all_directional_laps_filter_epochs_decoder_result-filter_epochs.hdf', 'filter_epochs')\\ndirectional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result.filter_epochs.to_dataframe()\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '238f67cb', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersDecodedResult\\n\\ndirectional_decoders_decode_result: DirectionalDecodersDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\\nall_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\\npseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\\nspikes_df = directional_decoders_decode_result.spikes_df\\ncontinuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\\npreviously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\\nprint(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '14c27c6a', 'metadata': {}, 'outputs': [], 'source': 'directional_decoders_decode_result'}, {'cell_type': 'code', 'execution_count': None, 'id': '1e5ed775', 'metadata': {}, 'outputs': [], 'source': 'continuously_decoded_result_cache_dict'}, {'cell_type': 'code', 'execution_count': None, 'id': '1d5126a4', 'metadata': {}, 'outputs': [], 'source': 'DirectionalDecodersDecodedResult.validate_has_directional_decoded_continuous_epochs(curr_active_pipeline)'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e3ed0870', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\\n\\n\\nmost_recent_time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\\n# most_recent_time_bin_size\\nmost_recent_continuously_decoded_dict = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\\n# most_recent_continuously_decoded_dict\\n\\n## Adds in the 'pseudo2D' decoder in:\\ntime_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\\n# time_bin_size: float = 0.01\\nprint(f'time_bin_size: {time_bin_size}')\\ncontinuously_decoded_dict = continuously_decoded_result_cache_dict[time_bin_size]\\npseudo2D_decoder_continuously_decoded_result = continuously_decoded_dict.get('pseudo2D', None)\\nif pseudo2D_decoder_continuously_decoded_result is None:\\n\\t# compute here...\\n\\t## Currently used for both cases to decode:\\n\\tt_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\\n\\tsingle_global_epoch_df: pd.DataFrame = pd.DataFrame({'start': [t_start], 'stop': [t_end], 'label': [0]}) # Build an Epoch object containing a single epoch, corresponding to the global epoch for the entire session:\\n\\tsingle_global_epoch: Epoch = Epoch(single_global_epoch_df)\\n\\tspikes_df = directional_decoders_decode_result.spikes_df\\n\\tpseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = pseudo2D_decoder.decode_specific_epochs(spikes_df=deepcopy(spikes_df), filter_epochs=single_global_epoch, decoding_time_bin_size=time_bin_size, debug_print=False)\\n\\tcontinuously_decoded_dict['pseudo2D'] = pseudo2D_decoder_continuously_decoded_result\\n\\tcontinuously_decoded_dict\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'c37af9e3', 'metadata': {}, 'outputs': [], 'source': \"non_marginalized_raw_result = DirectionalMergedDecodersResult.build_non_marginalized_raw_posteriors(pseudo2D_decoder_continuously_decoded_result)[0]['p_x_given_n']\\nmarginal_over_direction = DirectionalMergedDecodersResult.build_custom_marginal_over_direction(pseudo2D_decoder_continuously_decoded_result)[0]['p_x_given_n']\\nmarginal_over_track_ID = DirectionalMergedDecodersResult.build_custom_marginal_over_long_short(pseudo2D_decoder_continuously_decoded_result)[0]['p_x_given_n']\\nnon_marginalized_raw_result.shape # (4, 128672)\\nmarginal_over_direction.shape # (2, 128672)\\nmarginal_over_track_ID.shape # (2, 128672)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '647719b8', 'metadata': {}, 'outputs': [], 'source': 'track_identity_marginals, track_identity_all_epoch_bins_marginal, most_likely_track_identity_from_decoder, is_most_likely_track_identity_Long'}, {'cell_type': 'code', 'execution_count': None, 'id': 'b8a15241', 'metadata': {}, 'outputs': [], 'source': 'active_marginal_list = plots_data.active_marginal_fn(plots_data.filter_epochs_decoder_result)'}, {'cell_type': 'code', 'execution_count': None, 'id': '75e2e0dd', 'metadata': {}, 'outputs': [], 'source': \"curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded'] = directional_decoders_decode_result\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'bfe7fdc9', 'metadata': {}, 'outputs': [], 'source': '# Update the original result:\\ndirectional_decoders_decode_result.continuously_decoded_result_cache_dict[time_bin_size] = continuously_decoded_dict'}, {'cell_type': 'code', 'execution_count': None, 'id': 'cbc8e5dc', 'metadata': {}, 'outputs': [], 'source': 'directional_decoders_decode_result.continuously_decoded_result_cache_dict[time_bin_size]'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c81017f4', 'metadata': {}, 'outputs': [], 'source': 'pseudo2D_decoder_continuously_decoded_result.marginal_x_list'}, {'cell_type': 'code', 'execution_count': None, 'id': 'df668cc3', 'metadata': {}, 'outputs': [], 'source': \"assert len(pseudo2D_decoder_continuously_decoded_result.marginal_x_list) == 1\\nmarginal_x = pseudo2D_decoder_continuously_decoded_result.marginal_x_list[0]['p_x_given_n']\\nmarginal_x.shape # (62, 209389)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'c39cc2ce', 'metadata': {}, 'outputs': [], 'source': \"assert len(pseudo2D_decoder_continuously_decoded_result.marginal_y_list) == 1\\nmarginal_y = pseudo2D_decoder_continuously_decoded_result.marginal_y_list[0]['p_x_given_n']\\nmarginal_y.shape # (4, 209389)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '59c29796', 'metadata': {}, 'outputs': [], 'source': 'assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\\np_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]\\n# p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0][\\'p_x_given_n\\']\\np_x_given_n.shape # (62, 4, 209389)\\n\\n## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\\nassert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\\nsplit_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate((\\'long_LR\\', \\'long_RL\\', \\'short_LR\\', \\'short_RL\\'))}\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '90b648ac', 'metadata': {}, 'outputs': [], 'source': 'directional_decoders_decode_result.continuously_decoded_result_cache_dict[time_bin_size]'}, {'cell_type': 'code', 'execution_count': None, 'id': '599acd65', 'metadata': {}, 'outputs': [], 'source': 'continuously_decoded_dict'}, {'cell_type': 'code', 'execution_count': None, 'id': '41ea6554', 'metadata': {}, 'outputs': [], 'source': 'DirectionalDecodersDecodedResult.validate_has_directional_decoded_continuous_epochs(curr_active_pipeline=curr_active_pipeline)'}, {'cell_type': 'code', 'execution_count': None, 'id': 'badc467d', 'metadata': {}, 'outputs': [], 'source': \"from typing import Callable, Type\\nfrom neuropy.utils.mixins.HDF5_representable import HDFSerializationRegister\\n\\na_register = HDFSerializationRegister()\\n\\na_register.converion_registery[pd.DataFrame] = lambda x, *hdf_args, **hdf_kwargs: x.to_hdf(*hdf_args, **hdf_kwargs)\\na_register.converion_registery[Epoch] = lambda x, *hdf_args, **hdf_kwargs: x.to_dataframe().to_hdf(*hdf_args, **hdf_kwargs)\\n\\n\\n# works!\\na_register.to_hdf(directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result.filter_epochs, 'output/all_directional_laps_filter_epochs_decoder_result-filter_epochs.hdf', 'filter_epochs')\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '982fca18', 'metadata': {}, 'outputs': [], 'source': \"\\n\\n# print_keys_if_possible('DirectionalMergedDecoders', directional_merged_decoders_result)\\n\\nfrom ansi2html import Ansi2HTMLConverter # used by DocumentationFilePrinter to build html document from ansi-color coded version\\nfrom pyphocorehelpers.print_helpers import DocumentationFilePrinter\\n\\ndoc_printer = DocumentationFilePrinter(doc_output_parent_folder=Path('EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation'), doc_name='DirectionalMergedDecodersResult')\\ndoc_printer.save_documentation('DirectionalMergedDecodersResult', directional_merged_decoders_result, non_expanded_item_keys=['_reverse_cellID_index_map'], additional_excluded_item_classes='neuropy.analyses.PfND', max_depth=2)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'fa2dc5fe', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': '# NEW 2023-11-22 method: Get the templates (which can be filtered by frate first) and the from those get the decoders):        \\n# track_templates: TrackTemplates = directional_laps_results.get_shared_aclus_only_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # shared-only\\ntrack_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only\\nlong_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = track_templates.get_decoders()\\n\\n# Unpack all directional variables:\\n## {\"even\": \"RL\", \"odd\": \"LR\"}\\nlong_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = [\\'maze1_odd\\', \\'maze2_odd\\', \\'maze_odd\\', \\'maze1_even\\', \\'maze2_even\\', \\'maze_even\\', \\'maze1_any\\', \\'maze2_any\\', \\'maze_any\\']\\n# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\\n(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\\nlong_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\\n(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\\n(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\\n(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\\n(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\\n(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\\n(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\\n\\n# `LongShortStatsItem` form (2024-01-02):\\n# LR_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\\n# RL_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\\nLR_results_long_short_z_diffs = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\\nRL_results_long_short_z_diff = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c260739a4f36c662', 'metadata': {}, 'outputs': [], 'source': \"active_burst_intervals = curr_active_pipeline.computation_results[global_epoch_name].computed_data['burst_detection']['burst_intervals']\\n# active_burst_intervals\"}, {'cell_type': 'code', 'execution_count': None, 'id': '769a1c6006aba5b7', 'metadata': {}, 'outputs': [], 'source': \"# Relative Entropy/Surprise Results:\\nactive_extended_stats = global_results['extended_stats']\\nactive_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise'] # DynamicParameters\\nhistorical_snapshots = active_relative_entropy_results['historical_snapshots']\\npost_update_times: np.ndarray = active_relative_entropy_results['post_update_times'] # (4152,) = (n_post_update_times,)\\nsnapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\\ntime_intervals: np.ndarray = active_relative_entropy_results['time_intervals']\\nsurprise_time_bin_duration = (post_update_times[2]-post_update_times[1])\\nlong_short_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\\nshort_long_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\\nflat_relative_entropy_results: np.ndarray = active_relative_entropy_results['flat_relative_entropy_results'] # (149, 63) - (nSnapshots, nXbins)\\nflat_jensen_shannon_distance_results: np.ndarray = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (149, 63) - (nSnapshots, nXbins)\\nflat_jensen_shannon_distance_across_all_positions: np.ndarray = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\\nflat_surprise_across_all_positions: np.ndarray = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\\n\\n## Get the placefield dt matrix:\\nif 'snapshot_occupancy_weighted_tuning_maps' not in active_relative_entropy_results:\\n\\t## Compute it if missing:\\n\\toccupancy_weighted_tuning_maps_over_time = np.stack([placefield_snapshot.occupancy_weighted_tuning_maps_matrix for placefield_snapshot in historical_snapshots.values()])\\n\\tactive_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] = occupancy_weighted_tuning_maps_over_time\\nelse:\\n\\toccupancy_weighted_tuning_maps_over_time = active_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] # (n_post_update_times, n_neurons, n_xbins)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '9554d3bf5955d9d3', 'metadata': {}, 'outputs': [], 'source': '# Time-dependent\\nlong_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\\nlong_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\\nglobal_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\\nglobal_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt'}, {'cell_type': 'code', 'execution_count': None, 'id': '8624c62d5c18c556', 'metadata': {}, 'outputs': [], 'source': \"## long_short_endcap_analysis: checks for cells localized to the endcaps that have their placefields truncated after shortening the track\\ntruncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\\ndisappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\\n# disappearing_endcap_aclus\\ntrivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\\n# trivially_remapping_endcap_aclus\\nsignificant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\\n# significant_distant_remapping_endcap_aclus\\nappearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\\n# appearing_aclus\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'cbf30c04', 'metadata': {}, 'outputs': [], 'source': \"curr_active_pipeline.prepare_for_display()\\ncurr_active_pipeline.display('_display_1d_placefields', 'maze1_odd') # , 'maze1_odd'\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'bcc832fb', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Mixins.ExportHelpers import programmatic_render_to_file\\n\\nprogrammatic_render_to_file(curr_active_pipeline, curr_display_function_name='_display_1d_placefields', write_vector_format=True, write_png=True, debug_print=True)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '6314950a', 'metadata': {}, 'outputs': [], 'source': 'curr_active_pipeline.reload_default_display_functions()\\ncurr_active_pipeline.prepare_for_display()'}, {'cell_type': 'code', 'execution_count': None, 'id': 'b0ccab8b', 'metadata': {}, 'outputs': [], 'source': \"_out = curr_active_pipeline.display('_display_1d_placefields', 'maze_any')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '357f844b', 'metadata': {}, 'outputs': [], 'source': \"curr_active_pipeline.display('_display_1d_placefields', 'maze_any')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '546f7639', 'metadata': {}, 'outputs': [], 'source': \"curr_active_pipeline.display('_display_placemaps_pyqtplot_2D', 'maze2_odd')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '0aaf32b0', 'metadata': {}, 'outputs': [], 'source': \"curr_active_pipeline.display('_display_1d_placefields', 'maze2_odd')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '45a6994d', 'metadata': {}, 'outputs': [], 'source': \"curr_active_pipeline.display('_display_3d_interactive_spike_and_behavior_browser', 'maze1_odd')\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'cfbb1191', 'metadata': {}, 'outputs': [], 'source': '\\n# Adjust layout to make space for the footer\\n# plt.subplots_adjust(bottom=0.35)\\n\\nplt.tight_layout(pad=2.0)'}, {'cell_type': 'code', 'execution_count': None, 'id': '885ecb1d', 'metadata': {}, 'outputs': [], 'source': '_display_placemaps_pyqtplot_2D'}, {'cell_type': 'code', 'execution_count': None, 'id': '44a1db23', 'metadata': {}, 'outputs': [], 'source': 'curr_active_pipeline.registered_display_function_docs_dict'}, {'cell_type': 'code', 'execution_count': None, 'id': 'b558758b', 'metadata': {}, 'outputs': [], 'source': \"from mpl_multitab import MplMultiTab, MplMultiTab2D\\nfrom pyphoplacecellanalysis.General.Mixins.ExportHelpers import programmatic_display_to_PDF, programmatic_render_to_file\\nfrom pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_single_cell_1D_placecell_validation\\nfrom pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_1d_placecell_validations\\n\\n\\n# matplotlib_configuration_update(is_interactive=True)\\n\\n# curr_active_pipeline.display('_display_grid_bin_bounds_validation')\\n_out = curr_active_pipeline.display('_display_1d_placefield_validations', 'maze1_odd')\\n_out.ui.show()\"}, {'cell_type': 'code', 'execution_count': None, 'id': '7f301b08', 'metadata': {}, 'outputs': [], 'source': \"\\nprogrammatic_display_to_PDF(curr_active_pipeline, curr_display_function_name='_display_1d_placefield_validations', filter_name='maze1_odd', debug_print=True)\\n\\n# plt.show()\"}, {'cell_type': 'code', 'execution_count': None, 'id': '3f824cf2', 'metadata': {}, 'outputs': [], 'source': \"placefield_cell_index = 0\\nactive_epoch_placefields1D = deepcopy(long_pf1D)\\ncurr_cell_normalized_tuning_curve = active_epoch_placefields1D.ratemap.normalized_tuning_curves[placefield_cell_index, :].squeeze()\\n{'xbin_centers': active_epoch_placefields1D.ratemap.xbin_centers, 'curr_cell_normalized_tuning_curve': curr_cell_normalized_tuning_curve}\\n\\n{'xbin_centers': np.array([31.0565, 34.8495, 38.6426, 42.4356, 46.2286, 50.0216, 53.8147, 57.6077, 61.4007, 65.1937, 68.9867, 72.7798, 76.5728, 80.3658, 84.1588, 87.9519, 91.7449, 95.5379, 99.3309, 103.124, 106.917, 110.71, 114.503, 118.296, 122.089, 125.882, 129.675, 133.468, 137.261, 141.054, 144.847, 148.64, 152.433, 156.226, 160.019, 163.812, 167.605, 171.398, 175.191, 178.984, 182.777, 186.57, 190.363, 194.157, 197.95, 201.743, 205.536, 209.329, 213.122, 216.915, 220.708, 224.501, 228.294, 232.087, 235.88, 239.673, 243.466, 247.259, 251.052, 254.845, 258.638, 262.431]),\\n 'curr_cell_normalized_tuning_curve': np.array([5.92979e-05, 0.000150933, 0.00036895, 0.000736517, 0.00121915, 0.00173714, 0.0022042, 0.00252859, 0.0026496, 0.0027108, 0.00312627, 0.00423033, 0.00579314, 0.00709557, 0.00766535, 0.00789647, 0.00884807, 0.0115452, 0.0165549, 0.0238423, 0.0323681, 0.039895, 0.0442459, 0.0452642, 0.0449909, 0.0457691, 0.0485138, 0.0525281, 0.0562324, 0.0581433, 0.0575758, 0.0544383, 0.0486438, 0.0404683, 0.0315115, 0.0243731, 0.0207242, 0.0199181, 0.0197507, 0.0183449, 0.0153819, 0.0119837, 0.00951012, 0.00827676, 0.00740415, 0.00596512, 0.00396809, 0.00210018, 0.000875453, 0.000302685, 0.000153468, 0.00027615, 0.000667689, 0.00135676, 0.00224608, 0.00305331, 0.0034339, 0.0031979, 0.0024518, 0.00153458, 0.00079294, 0.000405152])}\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'ff5d7994', 'metadata': {}, 'outputs': [], 'source': '# batch_extended_programmatic_figures\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '40083faa', 'metadata': {}, 'outputs': [], 'source': \"curr_active_pipeline.display('_display_1d_placefields', 'maze1_odd')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '77344ed3', 'metadata': {}, 'outputs': [], 'source': \"curr_active_pipeline.display('_display_1d_placefields', 'maze2_even')\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'a66fdc07', 'metadata': {}, 'outputs': [], 'source': \"\\n#TODO 2023-11-29 09:18: - [ ] Not good, the self.filtered_contexts are not unique!\\nlist(curr_active_pipeline.filtered_contexts.values())\\n# [IdentifyingContext<(... 'maze2')>, IdentifyingContext<(... 'maze2')>, IdentifyingContext<(..., 'maze')>, IdentifyingContext<(... 'maze2')>, IdentifyingContext<(... 'maze2')>, IdentifyingContext<(..., 'maze')>, IdentifyingContext<(...ze1_any')>, IdentifyingContext<(... 'maze2')>, IdentifyingContext<(..., 'maze')>]\\n[(v == curr_active_pipeline.filtered_contexts['maze1_even']) for v in list(curr_active_pipeline.filtered_contexts.values())]\\n# [True, True, False, True, True, False, False, True, False]\\n# meaning `curr_active_pipeline.display('_display_1d_placefields', curr_active_pipeline.filtered_contexts['maze1_even'])` doesn't work\\ncurr_active_pipeline.filtered_contexts.index(curr_active_pipeline.filtered_contexts['maze1_even'])\"}, {'cell_type': 'code', 'execution_count': None, 'id': '8c4e9d82', 'metadata': {}, 'outputs': [], 'source': \"curr_active_pipeline.display('_display_1d_placefields', 'maze2_odd')\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '497d3385', 'metadata': {}, 'outputs': [], 'source': \"write_vector_format = False\\nwrite_png = True\\ndebug_print = True\\nfrom neuropy.plotting.ratemaps import BackgroundRenderingOptions\\n\\nprogrammatic_render_to_file(curr_active_pipeline, curr_display_function_name='_display_2d_placefield_result_plot_ratemaps_2D', write_vector_format=write_vector_format, write_png=write_png, debug_print=debug_print, bg_rendering_mode=BackgroundRenderingOptions.EMPTY) #  🟢✅ Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear.\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'ce7e9185', 'metadata': {}, 'outputs': [], 'source': \"_out = curr_active_pipeline.display('_display_2d_placefield_occupancy', 'maze2_any')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '90e90109', 'metadata': {}, 'outputs': [], 'source': \"_out = curr_active_pipeline.display('_display_2d_placefield_occupancy', 'maze1_any')\\noccupancy_ax = _out.axes #.get_aspect()\\npf = long_pf2D\\n# pf.xbin\\n# pf.ybin\\n# pf.xbin_centers\\n# pf.ybin_centers\\n\\n# aspect_ratio = np.ptp(pf.xbin) / np.ptp(pf.ybin)  # ptp: peak to peak (range)\\n# aspect_ratio = 0.102803738317757\\n# print(f'aspect_ratio: {aspect_ratio}')\\n# occupancy_ax.set_aspect(aspect_ratio, adjustable='box') # If 'box', change the physical dimensions of the Axes. If 'datalim', change the x or y data limits.\\n\\n\\n## See \\n# https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_anchor.html#\\n\\n\\noccupancy_ax.set_aspect('equal', adjustable=None)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'ce50ea4d', 'metadata': {}, 'outputs': [], 'source': \"occupancy_ax.set_aspect('equal', adjustable='datalim')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '800ecc2e', 'metadata': {}, 'outputs': [], 'source': \"occupancy_ax.set_aspect('equal', adjustable='box')\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'cea7d05b', 'metadata': {}, 'outputs': [], 'source': 'curr_active_pipeline.reload_default_display_functions()'}, {'cell_type': 'code', 'execution_count': None, 'id': 'f42513c8', 'metadata': {}, 'outputs': [], 'source': \"programmatic_render_to_file(curr_active_pipeline, curr_display_function_name='_display_2d_placefield_occupancy', write_vector_format=write_vector_format, write_png=write_png, debug_print=debug_print)\"}, {'cell_type': 'markdown', 'id': '5a572825', 'metadata': {}, 'source': '# EVEN: \"RL\", ODD: \"LR\"\\nStarts with Even (idx=0)\\n- EVEN: \"RL\"\\nshared_RL_aclus_only_neuron_IDs\\n`is_even = (an_epoch.lap_dir == 0)`\\n- ODD: \"LR\"\\nshared_LR_aclus_only_neuron_IDs\\n`is_odd = (an_epoch.lap_dir == 1)`'}, {'cell_type': 'markdown', 'id': '9ac0ef2b', 'metadata': {}, 'source': '# 🟢 2023-10-20 - Z-Score Comparisons with Neuron_ID Shuffled templates\\n1. Take the intersection of the long and short templates to get only the common cells\\n2. Determine the long and short \"tempaltes\": this is done by ranking the aclus for each by their placefields\\' center of mass. `compute_placefield_center_of_masses`\\n\\t2a. `long_pf_peak_ranks`, `short_pf_peak_ranks` - there are one of each of these for each shared aclu.\\n3. Generate the unit_id shuffled (`shuffled_aclus`, `shuffle_IDXs`) ahead of time to use to shuffle the two templates during the epochs.\\n4. For each replay event, take each shuffled template\\n\\t4a. Iterate through each shuffle and obtain the shuffled templates like `long_pf_peak_ranks[epoch_specific_shuffled_indicies]`, `short_pf_peak_ranks[epoch_specific_shuffled_indicies]`\\n\\t4b. compute the spearman rank-order of the event and each shuffled template, and accumulate the results in `long_spearmanr_rank_stats_results`, `short_spearmanr_rank_stats_results`\\n\\n5. After we\\'re done with the shuffle loop, accumulate the results and convert to the right output format.\\n\\n6. When all epochs are done, loop through the results (the epochs again) and compute the z-scores for each epoch so they can be compared to each other. Keep track of the means and std_dev for comparisons later, and subtract the two sets of z-scores (long/short) to get the delta_Z for each template.\\n\\n7. TODO: Next figure out what to do with the array of z-scores and delta_Z. We have:\\n\\tn_epochs sets of results\\n\\t\\tn_shuffles scores of delta_Z\\n\\n'}, {'cell_type': 'markdown', 'id': '87fd9d61', 'metadata': {}, 'source': \"## Convo with Kamran 2023-10-23:\\n- Use directional templates **\\n- No need to worry about re-ranking\\n[X] Plot the long and short separately in addition to the difference, so we show significant reqplay on each as a sanity check\\n[X] Absolute value difference?\\n[X] Fisher transform the correlation values (check if there is a difference) because correlation coefficients aren't going to be normally distributed.\\n\\t[ ] Then Z-score releative to fisher.\\n\\n- T-test to compare to mean of zero (if looking at the difference)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '419ffd4a', 'metadata': {}, 'outputs': [], 'source': '## Concerns:\\n# 1. Permutation recommended over shuffling for small numbers of ids\\n# 2.\\n\\n# 5Hz thresholding of templates\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'fd86cb20', 'metadata': {'ExecuteTime': {'end_time': '2023-11-16T23:22:34.093953500Z', 'start_time': '2023-11-16T23:22:33.960957900Z'}, 'notebookRunGroups': {'groupValue': '1'}, 'slideshow': {'slide_type': 'fragment'}}, 'outputs': [], 'source': 'from nptyping import NDArray\\nfrom attrs import define, field, Factory, astuple\\nimport scipy.stats\\nfrom scipy import ndimage\\nfrom neuropy.utils.misc import build_shuffled_ids # used in _SHELL_analyze_leave_one_out_decoding_results\\nfrom pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import pho_stats_paired_t_test\\n\\n# minimum_inclusion_fr_Hz: float = 2.0\\nrank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data[\\'RankOrder\\']\\nminimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\\n\\n# Recover from the saved global result:\\ndirectional_laps_results = curr_active_pipeline.global_computation_results.computed_data[\\'DirectionalLaps\\']\\n# NEW 2023-11-22 method: Get the templates (which can be filtered by frate first) and the from those get the decoders):        \\n# track_templates: TrackTemplates = directional_laps_results.get_shared_aclus_only_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # shared-only\\ntrack_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only\\nlong_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = track_templates.get_decoders()\\n\\n## Pre 2023-11-22 method: building a TrackTemplates object after getting the raw decoders:\\n# long_LR_one_step_decoder_1D, long_RL_one_step_decoder_1D, short_LR_one_step_decoder_1D, short_RL_one_step_decoder_1D = directional_laps_results.get_decoders()\\n# long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = directional_laps_results.get_shared_aclus_only_decoders()\\n# track_templates: TrackTemplates = TrackTemplates.init_from_paired_decoders(LR_decoder_pair=(long_LR_decoder, short_LR_decoder), RL_decoder_pair=(long_RL_decoder, short_RL_decoder))\\n# # track_templates: TrackTemplates = TrackTemplates.init_from_paired_decoders(LR_decoder_pair=(long_LR_one_step_decoder_1D, short_LR_one_step_decoder_1D), RL_decoder_pair=(long_RL_one_step_decoder_1D, short_RL_one_step_decoder_1D)) # NOTE: now use the un-constrained versions\\n\\n# Unpack all directional variables:\\n## {\"even\": \"RL\", \"odd\": \"LR\"}\\nlong_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = [\\'maze1_odd\\', \\'maze2_odd\\', \\'maze_odd\\', \\'maze1_even\\', \\'maze2_even\\', \\'maze_even\\', \\'maze1_any\\', \\'maze2_any\\', \\'maze_any\\']\\n# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\\n(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\\nlong_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\\n(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\\n(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\\n(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\\n(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\\n(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\\n(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\\n\\nall_directional_decoder_names = [\\'long_LR\\', \\'long_RL\\', \\'short_LR\\', \\'short_RL\\']\\nall_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = dict(zip(all_directional_decoder_names, [deepcopy(long_LR_pf1D_Decoder), deepcopy(long_RL_pf1D_Decoder), deepcopy(short_LR_pf1D_Decoder), deepcopy(short_RL_pf1D_Decoder)]))\\n\\n\\n# `LongShortStatsItem` form (2024-01-02):\\n# LR_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\\n# RL_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\\nLR_results_long_short_z_diffs = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\\nRL_results_long_short_z_diff = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '3ebb454c', 'metadata': {'tags': ['histogram']}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import plot_rank_order_histograms\\n\\n# Plot histograms:\\npost_title_info: str = f'{minimum_inclusion_fr_Hz} Hz\\\\n{curr_active_pipeline.get_session_context().get_description()}'\\n_out_z_score, _out_real, _out_most_likely_z = plot_rank_order_histograms(rank_order_results, post_title_info=post_title_info)\\n\"}, {'cell_type': 'markdown', 'id': 'b641e1f6', 'metadata': {}, 'source': '#TODO 2023-12-10 19:56: - [ ] Histogram Display Helpers\\n\\n#TODO 2023-12-10 19:56: - [ ] Pf1D Helpers\\n\\n#TODO 2023-12-10 19:57: - [ ] Variant Saving\\n '}, {'cell_type': 'code', 'execution_count': None, 'id': 'c33ed6d2', 'metadata': {}, 'outputs': [], 'source': \"track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=0.0) # non-shared-only\\nlong_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = track_templates.get_decoders()\\n\\n# filtered_decoder_list = [filtered_by_frate(a_decoder, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, debug_print=True) for a_decoder in (long_LR_one_step_decoder_1D, long_RL_one_step_decoder_1D, short_LR_one_step_decoder_1D, short_RL_one_step_decoder_1D)]\\noriginal_neuron_ids_list = [a_decoder.pf.ratemap.neuron_ids for a_decoder in (long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder)]\\nis_aclu_included_list = [a_decoder.pf.ratemap.tuning_curve_unsmoothed_peak_firing_rates >= minimum_inclusion_fr_Hz for a_decoder in (long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder)]\\nfiltered_aclus_list = [np.array(a_decoder.pf.ratemap.neuron_ids)[a_decoder.pf.ratemap.tuning_curve_unsmoothed_peak_firing_rates >= minimum_inclusion_fr_Hz] for a_decoder in (long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder)]\\n\\n## For a given run direction (LR/RL) let's require inclusion in either (OR) long v. short to be included.\\nfiltered_included_LR_aclus = np.union1d(filtered_aclus_list[0], filtered_aclus_list[2])\\nfiltered_included_RL_aclus = np.union1d(filtered_aclus_list[1], filtered_aclus_list[3])\\n# build the final shared aclus:\\nfiltered_direction_shared_aclus_list = [filtered_included_LR_aclus, filtered_included_RL_aclus, filtered_included_LR_aclus, filtered_included_RL_aclus] # contains the shared aclus for that direction\\n# rebuild the is_aclu_included_list from the shared aclus\\nis_aclu_included_list = [np.isin(an_original_neuron_ids, a_filtered_neuron_ids) for an_original_neuron_ids, a_filtered_neuron_ids in zip(original_neuron_ids_list, filtered_direction_shared_aclus_list)]\\n\\n# is_aclu_included_list[0]\\nfiltered_direction_shared_aclus_list\"}, {'cell_type': 'code', 'execution_count': None, 'id': '017813cc', 'metadata': {}, 'outputs': [], 'source': '# # for 5Hz:\\n# [array([  5,   7,  31,  39,  41,  45,  46,  48,  50,  55,  61,  62,  64,  69,  72,  75,  76,  78,  79,  83,  84,  86,  88,  90,  91,  92,  95,  99, 100, 108]),\\n#  array([  5,   7,   9,  31,  32,  39,  41,  45,  46,  48,  50,  55,  61,  62,  64,  69,  72,  75,  76,  78,  79,  83,  84,  86,  88,  90,  91,  92,  93,  95,  99, 101, 108]),\\n#  array([  5,   7,  31,  39,  41,  45,  46,  48,  50,  55,  61,  62,  64,  69,  72,  75,  76,  78,  79,  83,  84,  86,  88,  90,  91,  92,  95,  99, 100, 108]),\\n#  array([  5,   7,   9,  31,  32,  39,  41,  45,  46,  48,  50,  55,  61,  62,  64,  69,  72,  75,  76,  78,  79,  83,  84,  86,  88,  90,  91,  92,  93,  95,  99, 101, 108])]\\n\\n# # for 20Hz:\\n# [array([  5,  41,  46,  48,  69,  78,  79,  83,  86,  88,  90, 108]),\\n#  array([ 62,  64,  75,  78,  83,  91, 101]),\\n#  array([  5,  41,  46,  48,  69,  78,  79,  83,  86,  88,  90, 108]),\\n#  array([ 62,  64,  75,  78,  83,  91, 101])]'}, {'cell_type': 'markdown', 'id': 'f6ccfe1f', 'metadata': {}, 'source': '# 2023-11-22 - RECOMPUTE'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c22e7090', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalLapsHelpers\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions\\n\\ncurr_active_pipeline.reload_default_computation_functions()\\n\\n## clear the old values to prepare for the new ones:\\ncurr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'] = None\\ncurr_active_pipeline.global_computation_results.computed_data['RankOrder'] = None\\ndel curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\\ndel curr_active_pipeline.global_computation_results.computed_data['RankOrder']\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '7f64b8a0', 'metadata': {}, 'outputs': [], 'source': 'curr_active_pipeline.global_computation_results.computed_data[\\'DirectionalLaps\\'] = DirectionalLapsHelpers.build_global_directional_result_from_natural_epochs(curr_active_pipeline, progress_print=True) # repalce the directional laps object\\ndirectional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data[\\'DirectionalLaps\\']\\n\\nnum_shuffles = 500\\n\\nminimum_inclusion_fr_Hz = 5.0\\nincluded_qclu_values = [1,2]\\n\\n# minimum_inclusion_fr_Hz = 1.0\\n# included_qclu_values = [1,2,4,9]\\n\\n# perform_rank_order_shuffle_analysis\\nwith VizTracer(output_file=f\"viztracer_{get_now_time_str()}-perform_rank_order_shuffle_analysis_{curr_active_pipeline.session_name}_num_shuffles-{num_shuffles}.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\\n    ## DO ALL:\\n    RankOrderGlobalComputationFunctions.perform_rank_order_shuffle_analysis(curr_active_pipeline, curr_active_pipeline.global_computation_results, None, None, include_includelist=None, debug_print=False,\\n                                                                            num_shuffles=num_shuffles, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values, skip_laps=False)\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '715580af', 'metadata': {}, 'outputs': [], 'source': '## Custom `RankOrderAnalyses.most_likely_directional_rank_order_shuffling(...)`\\n# Requires \"New method 2023-12-15\" result\\n# Set the global result:\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses\\n\\ntry:\\n\\tprint(f\\'\\\\tdone. building global result.\\')\\n\\tcurr_active_pipeline.global_computation_results.computed_data[\\'RankOrder\\'].adding_active_aclus_info()\\n\\tcurr_active_pipeline.global_computation_results.computed_data[\\'RankOrder\\'].ripple_most_likely_result_tuple, curr_active_pipeline.global_computation_results.computed_data[\\'RankOrder\\'].laps_most_likely_result_tuple = RankOrderAnalyses.most_likely_directional_rank_order_shuffling(curr_active_pipeline)\\n\\nexcept (AssertionError, BaseException) as e:\\n\\tprint(f\\'Issue with `RankOrderAnalyses.most_likely_directional_rank_order_shuffling(...)` e: {e}\\')\\n\\traise'}, {'cell_type': 'code', 'execution_count': None, 'id': '91b0e4d4', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses\\n\\ncurr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_most_likely_result_tuple, curr_active_pipeline.global_computation_results.computed_data['RankOrder'].laps_most_likely_result_tuple = RankOrderAnalyses.most_likely_directional_rank_order_shuffling(curr_active_pipeline)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '222cfc4a', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalMergedDecodersResult\\n\\n## Extract the rank_order_results:\\nrank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\\nrank_order_results.adding_active_aclus_info()\\n\\ndirectional_laps_results = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\\ntrack_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=rank_order_results.minimum_inclusion_fr_Hz) # non-shared-only\\ndecoders_dict = track_templates.get_decoders_dict() # decoders_dict = {'long_LR': track_templates.long_LR_decoder, 'long_RL': track_templates.long_RL_decoder, 'short_\\n# LR': track_templates.short_LR_decoder, 'short_RL': track_templates.short_RL_decoder, }\\n\\n# Get the `directional_merged_decoders_result` to determining most-likely direction from the merged pseudo-2D decoder:\\ndirectional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\\n# directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\\n# directional_merged_decoders_result.all_directional_pf1D_Decoder\\n# directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\\n\\nlaps_marginals = DirectionalMergedDecodersResult.determine_directional_likelihoods(directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result)\\nlaps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir = laps_marginals\\n\\nripple_marginals = DirectionalMergedDecodersResult.determine_directional_likelihoods(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result)\\nripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir = ripple_marginals\\n\\n\\n# directional_merged_decoders_result.\\n# ripple_most_likely_result_tuple\"}, {'cell_type': 'code', 'execution_count': None, 'id': '08112e9a', 'metadata': {}, 'outputs': [], 'source': 'ripple_directional_all_epoch_bins_marginal'}, {'cell_type': 'code', 'execution_count': None, 'id': 'a662a3b7', 'metadata': {}, 'outputs': [], 'source': 'rank_order_results.ripple_combined_epoch_stats_df'}, {'cell_type': 'code', 'execution_count': None, 'id': '3e450b79', 'metadata': {}, 'outputs': [], 'source': \"active_replay_epochs_df # 'Long_normed_LR_evidence', 'Long_normed_RL_evidence', 'Short_normed_LR_evidence', 'Short_normed_RL_evidence'\\n# active_replay_epochs_df[['Long_normed_LR_evidence', 'Short_normed_RL_evidence']]\"}, {'cell_type': 'code', 'execution_count': None, 'id': '5a8a5e68', 'metadata': {}, 'outputs': [], 'source': \"## 2024-01-04 - DirectionalMergedDecoders version:\\n# NOTE: ripple_most_likely_direction_from_decoder comes with with more epochs than the already filtered `rank_order_results.ripple_combined_epoch_stats_df` version. We'll get only the active indicies from `rank_order_results.ripple_combined_epoch_stats_df.index`\\n# needs: rank_order_results, ripple_most_likely_direction_from_decoder, ripple_directional_all_epoch_bins_marginal, \\ncombined_best_direction_indicies = deepcopy(ripple_most_likely_direction_from_decoder) # .shape (611,)\\n# np.shape(combined_best_direction_indicies)\\ncombined_best_direction_indicies = combined_best_direction_indicies[rank_order_results.ripple_combined_epoch_stats_df['label'].to_numpy()] # get only the indicies for the active epochs\\n# np.shape(combined_best_direction_indicies)\\nassert np.shape(combined_best_direction_indicies)[0] == np.shape(rank_order_results.ripple_combined_epoch_stats_df)[0]\\nlong_best_direction_indicies = combined_best_direction_indicies.copy() # use same (globally best) indicies for Long/Short\\nshort_best_direction_indicies = combined_best_direction_indicies.copy() # use same (globally best) indicies for Long/Short\\n\\n# gets the LR likelihood for each of these (long/short)\\nlong_relative_direction_likelihoods = ripple_directional_all_epoch_bins_marginal[rank_order_results.ripple_combined_epoch_stats_df['label'].to_numpy(), 0] # (n_epochs, 2)\\nshort_relative_direction_likelihoods = ripple_directional_all_epoch_bins_marginal[rank_order_results.ripple_combined_epoch_stats_df['label'].to_numpy(), 0] # (n_epochs, 2)\\n\\nripple_directional_likelihoods_tuple: DirectionalRankOrderLikelihoods = DirectionalRankOrderLikelihoods(long_relative_direction_likelihoods=long_relative_direction_likelihoods,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tshort_relative_direction_likelihoods=short_relative_direction_likelihoods,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tlong_best_direction_indices=long_best_direction_indicies, \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tshort_best_direction_indices=short_best_direction_indicies,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'f3976821', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses\\n\\n## Main\\nripple_result_tuple, laps_result_tuple = RankOrderAnalyses.most_likely_directional_rank_order_shuffling(curr_active_pipeline, decoding_time_bin_size=0.003)'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c0145e38', 'metadata': {}, 'outputs': [], 'source': \"## 2024-01-04 - DirectionalMergedDecoders version:\\n# NOTE: laps_most_likely_direction_from_decoder comes with with more epochs than the already filtered `rank_order_results.laps_combined_epoch_stats_df` version. We'll get only the active indicies from `rank_order_results.ripple_combined_epoch_stats_df.index`\\n# needs: rank_order_results, laps_most_likely_direction_from_decoder, laps_directional_all_epoch_bins_marginal, \\nlaps_marginals = DirectionalMergedDecodersResult.determine_directional_likelihoods(directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result)\\nlaps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir = laps_marginals\\n\\ncombined_best_direction_indicies = deepcopy(laps_most_likely_direction_from_decoder) # .shape (611,)\\n# np.shape(combined_best_direction_indicies)\\ncombined_best_direction_indicies = combined_best_direction_indicies[rank_order_results.laps_combined_epoch_stats_df['label'].to_numpy()] # get only the indicies for the active epochs\\n# np.shape(combined_best_direction_indicies)\\nassert np.shape(combined_best_direction_indicies)[0] == np.shape(rank_order_results.laps_combined_epoch_stats_df)[0]\\nlong_best_direction_indicies = combined_best_direction_indicies.copy() # use same (globally best) indicies for Long/Short\\nshort_best_direction_indicies = combined_best_direction_indicies.copy() # use same (globally best) indicies for Long/Short\\n\\n# gets the LR likelihood for each of these (long/short)\\nlong_relative_direction_likelihoods = laps_directional_all_epoch_bins_marginal[rank_order_results.laps_combined_epoch_stats_df['label'].to_numpy(), 0] # (n_epochs, 2)\\nshort_relative_direction_likelihoods = laps_directional_all_epoch_bins_marginal[rank_order_results.laps_combined_epoch_stats_df['label'].to_numpy(), 0] # (n_epochs, 2)\\n\\nlaps_directional_likelihoods_tuple: DirectionalRankOrderLikelihoods = DirectionalRankOrderLikelihoods(long_relative_direction_likelihoods=long_relative_direction_likelihoods,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tshort_relative_direction_likelihoods=short_relative_direction_likelihoods,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tlong_best_direction_indices=long_best_direction_indicies, \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tshort_best_direction_indices=short_best_direction_indicies,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '0b4a4744', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses\\n\\nRankOrderAnalyses.percentiles_computations(rank_order_results=rank_order_results)\\nlaps_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.laps_merged_complete_epoch_stats_df ## New method\\nripple_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method'}, {'cell_type': 'code', 'execution_count': None, 'id': 'b48c2f08', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalLapsHelpers\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions\\n\\ncurr_active_pipeline.reload_default_computation_functions()\\n\\n## DO just Pandas-based method and post-processing for best directions:\\nRankOrderGlobalComputationFunctions.perform_pandas_based_rank_order_shuffle_analysis(curr_active_pipeline, curr_active_pipeline.global_computation_results, None, None, include_includelist=None, debug_print=True,\\n                                                                        num_shuffles=1000, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values, skip_laps=False)'}, {'cell_type': 'code', 'execution_count': None, 'id': '22c50e7e', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses\\n\\ndirectional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data[\\'DirectionalLaps\\']\\nselected_spikes_df = deepcopy(curr_active_pipeline.global_computation_results.computed_data[\\'RankOrder\\'].LR_ripple.selected_spikes_df)\\n# active_epochs = global_computation_results.computed_data[\\'RankOrder\\'].ripple_most_likely_result_tuple.active_epochs\\nactive_epochs = deepcopy(curr_active_pipeline.global_computation_results.computed_data[\\'RankOrder\\'].LR_ripple.epochs_df)\\ntrack_templates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\\n\\nwith VizTracer(output_file=f\"viztracer_{get_now_time_str()}-pandas_df_based_correlation_computations.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\\n\\tripple_combined_epoch_stats_df, ripple_new_output_tuple = RankOrderAnalyses.pandas_df_based_correlation_computations(selected_spikes_df=selected_spikes_df, active_epochs_df=active_epochs, track_templates=track_templates, num_shuffles=100)\\n\\nripple_combined_epoch_stats_df\\n\\n# n_shuffles: [5, 50]\\n# time: [\"10.4s\", \"1m 15.9s\"]'}, {'cell_type': 'code', 'execution_count': None, 'id': '21d6d5a1', 'metadata': {}, 'outputs': [], 'source': \"print(list(ripple_combined_epoch_stats_df.columns)) # ['long_RL_spearman', 'long_LR_pearson', 'short_RL_spearman', 'short_RL_pearson', 'long_LR_spearman', 'short_LR_pearson', 'short_LR_spearman', 'long_RL_pearson', 'long_RL_spearman_Z', 'long_LR_pearson_Z', 'short_RL_spearman_Z', 'short_RL_pearson_Z', 'long_LR_spearman_Z', 'short_LR_pearson_Z', 'short_LR_spearman_Z', 'long_RL_pearson_Z', 'label']\\n\\n['LR_Long_spearman_Z', 'LR_Long_spearman_Z', 'LR_Long_spearman_Z', 'LR_Long_spearman_Z']\\n\\n{'long_LR':'LR_Long'}\\n\\ndecoder_name_to_column_name_prefix_map: Dict[str, str] = dict(zip(['long_LR', 'long_RL', 'short_LR', 'short_RL'], ['LR_Long', 'RL_Long', 'LR_Short', 'RL_Short']))\\n\\nrename_fn = lambda a_name: a_name.replace(\\n\\n[a_name.replace( for a_name in list(ripple_combined_epoch_stats_df.columns)]\\n\\n\\n['long_RL_spearman', 'long_LR_pearson', 'short_RL_spearman', 'short_RL_pearson', 'long_LR_spearman', 'short_LR_pearson', 'short_LR_spearman', 'long_RL_pearson', 'long_RL_spearman_Z', 'long_LR_pearson_Z', 'short_RL_spearman_Z', 'short_RL_pearson_Z', 'long_LR_spearman_Z', 'short_LR_pearson_Z', 'short_LR_spearman_Z', 'long_RL_pearson_Z', 'label']\\n\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'ef655eec', 'metadata': {}, 'outputs': [], 'source': 'def build_column_rename_dict(column_names: List[str], decoder_name_to_column_name_prefix_map:Optional[Dict[str,str]]=None) -> Dict[str,str]:\\n  \"\"\" \\n  \\n  column_names = [\\'long_RL_spearman\\', \\'long_LR_pearson\\', \\'short_RL_spearman\\', \\'short_RL_pearson\\', \\'long_LR_spearman\\', \\'short_LR_pearson\\', \\'short_LR_spearman\\', \\'long_RL_pearson\\', \\'long_RL_spearman_Z\\', \\'long_LR_pearson_Z\\', \\'short_RL_spearman_Z\\', \\'short_RL_pearson_Z\\', \\'long_LR_spearman_Z\\', \\'short_LR_pearson_Z\\', \\'short_LR_spearman_Z\\', \\'long_RL_pearson_Z\\']\\n  decoder_name_to_column_name_prefix_map = dict(zip([\\'long_LR\\', \\'long_RL\\', \\'short_LR\\', \\'short_RL\\'], [\\'LR_Long\\', \\'RL_Long\\', \\'LR_Short\\', \\'RL_Short\\']))\\n\\n  old_to_new_names = build_column_rename_dict(column_names, decoder_name_to_column_name_prefix_map.copy())\\n  print(old_to_new_names)\\n\\n  {\\'long_RL_spearman\\': \\'RL_Long_spearman\\', \\'long_LR_pearson\\': \\'LR_Long_pearson\\', \\'short_RL_spearman\\': \\'RL_Short_spearman\\', \\'short_RL_pearson\\': \\'RL_Short_pearson\\', \\'long_LR_spearman\\': \\'LR_Long_spearman\\', \\'short_LR_pearson\\': \\'LR_Short_pearson\\', \\'short_LR_spearman\\': \\'LR_Short_spearman\\', \\'long_RL_pearson\\': \\'RL_Long_pearson\\', \\'long_RL_spearman_Z\\': \\'RL_Long_spearman_Z\\', \\'long_LR_pearson_Z\\': \\'LR_Long_pearson_Z\\', \\'short_RL_spearman_Z\\': \\'RL_Short_spearman_Z\\', \\'short_RL_pearson_Z\\': \\'RL_Short_pearson_Z\\', \\'long_LR_spearman_Z\\': \\'LR_Long_spearman_Z\\', \\'short_LR_pearson_Z\\': \\'LR_Short_pearson_Z\\', \\'short_LR_spearman_Z\\': \\'LR_Short_spearman_Z\\', \\'long_RL_pearson_Z\\': \\'RL_Long_pearson_Z\\'}\\n  \"\"\"\\n  if decoder_name_to_column_name_prefix_map is None:\\n    decoder_name_to_column_name_prefix_map = dict(zip([\\'long_LR\\', \\'long_RL\\', \\'short_LR\\', \\'short_RL\\'], [\\'LR_Long\\', \\'RL_Long\\', \\'LR_Short\\', \\'RL_Short\\']))\\n  \\n  old_to_new_names = {}\\n  for col in column_names:\\n    for decoder_name, prefix in decoder_name_to_column_name_prefix_map.items():\\n      if decoder_name in col:\\n        new_col = prefix + col.split(decoder_name)[-1]\\n        old_to_new_names[col] = new_col\\n  return old_to_new_names\\n  \\ncolumn_names = [\\'long_RL_spearman\\', \\'long_LR_pearson\\', \\'short_RL_spearman\\', \\'short_RL_pearson\\', \\'long_LR_spearman\\', \\'short_LR_pearson\\', \\'short_LR_spearman\\', \\'long_RL_pearson\\', \\'long_RL_spearman_Z\\', \\'long_LR_pearson_Z\\', \\'short_RL_spearman_Z\\', \\'short_RL_pearson_Z\\', \\'long_LR_spearman_Z\\', \\'short_LR_pearson_Z\\', \\'short_LR_spearman_Z\\', \\'long_RL_pearson_Z\\']\\nold_to_new_names = build_column_rename_dict(column_names)\\nprint(old_to_new_names)\\nripple_combined_epoch_stats_df = ripple_combined_epoch_stats_df.rename(columns=old_to_new_names, inplace=False)\\nripple_combined_epoch_stats_df'}, {'cell_type': 'code', 'execution_count': None, 'id': 'd7aac86f', 'metadata': {}, 'outputs': [], 'source': 'ripple_combined_epoch_stats_df.LR_Long_spearman_Z'}, {'cell_type': 'code', 'execution_count': None, 'id': 'd2c4c11c', 'metadata': {}, 'outputs': [], 'source': \"curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_combined_epoch_stats_df, curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_new_output_tuple = ripple_combined_epoch_stats_df, ripple_new_output_tuple\"}, {'cell_type': 'code', 'execution_count': None, 'id': '9513b9b5', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses\\n\\ndecoder_aclu_peak_map_dict = track_templates.get_decoder_aclu_peak_map_dict()\\noverride_decoder_aclu_peak_map_dict = deepcopy(decoder_aclu_peak_map_dict)\\nactive_selected_spikes_df = RankOrderAnalyses._subfn_build_all_pf_peak_x_columns(track_templates, selected_spikes_df=selected_spikes_df, override_decoder_aclu_peak_map_dict=override_decoder_aclu_peak_map_dict)\\nepoch_id_grouped_selected_spikes_df =  active_selected_spikes_df.groupby('Probe_Epoch_id') # I can even compute this outside the loop?\"}, {'cell_type': 'code', 'execution_count': None, 'id': '83a9133f', 'metadata': {}, 'outputs': [], 'source': '\\nactive_selected_spikes_df = deepcopy(epoch_id_grouped_selected_spikes_df)\\nactive_selected_spikes_df = RankOrderAnalyses._subfn_build_all_pf_peak_x_columns(track_templates, selected_spikes_df=active_selected_spikes_df, override_decoder_aclu_peak_map_dict=override_decoder_aclu_peak_map_dict)\\nactive_selected_spikes_df'}, {'cell_type': 'code', 'execution_count': None, 'id': '499ff169', 'metadata': {}, 'outputs': [], 'source': \"\\n\\n#TODO 2023-12-18 13:20: - [ ] This assumes that `'Probe_Epoch_id'` is correct and consistent for both directions, yeah?\\n\\n## Compute real values here:\\ndecoder_names = track_templates.get_decoder_names()\\n\\nepoch_id_grouped_selected_spikes_df =  active_selected_spikes_df.groupby('Probe_Epoch_id') # I can even compute this outside the loop?\\nspearman_correlations = epoch_id_grouped_selected_spikes_df.apply(lambda group: RankOrderAnalyses._subfn_calculate_correlations(group, method='spearman', decoder_names=decoder_names)).reset_index() # Reset index to make 'Probe_Epoch_id' a column\\npearson_correlations = epoch_id_grouped_selected_spikes_df.apply(lambda group: RankOrderAnalyses._subfn_calculate_correlations(group, method='pearson', decoder_names=decoder_names)).reset_index() # Reset index to make 'Probe_Epoch_id' a column\\n\\nreal_stats_df = pd.concat((spearman_correlations, pearson_correlations), axis='columns')\\nreal_stats_df = real_stats_df.loc[:, ~real_stats_df.columns.duplicated()] # drop duplicated 'Probe_Epoch_id' column\\n# Change column type to uint64 for column: 'Probe_Epoch_id'\\nreal_stats_df = real_stats_df.astype({'Probe_Epoch_id': 'uint64'})\\n# Rename column 'Probe_Epoch_id' to 'label'\\nreal_stats_df = real_stats_df.rename(columns={'Probe_Epoch_id': 'label'})\\nreal_stats_df\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'f86d5ac8', 'metadata': {}, 'outputs': [], 'source': \"rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\\nminimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\\nincluded_qclu_values: List[int] = rank_order_results.included_qclu_values\\nripple_result_tuple, laps_result_tuple = rank_order_results.ripple_most_likely_result_tuple, rank_order_results.laps_most_likely_result_tuple\\ndirectional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\\ntrack_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\\nprint(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\\nprint(f'included_qclu_values: {included_qclu_values}')\\n\\n# 10m 29.5s for 1000 shuffles.  c:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\viztracer_2023-11-22_16-11-perform_rank_order_shuffle_analysis.json\\n\\n# 3m 33.9s - 500\\n# 3m 26.4s - 1000\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'd6d74122', 'metadata': {}, 'outputs': [], 'source': \"_ripples_outputs = RankOrderAnalyses.main_ripples_analysis(curr_active_pipeline, num_shuffles=500, rank_alignment='median', minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values)\\n(LR_ripple_outputs, RL_ripple_outputs, ripple_evts_paired_tests) = _ripples_outputs\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '76178217', 'metadata': {}, 'outputs': [], 'source': '# LR_ripple_outputs.epochs_df\\nLR_ripple_outputs.spikes_df'}, {'cell_type': 'code', 'execution_count': None, 'id': '1d42afeb', 'metadata': {}, 'outputs': [], 'source': 'RL_ripple_outputs.spikes_df'}, {'cell_type': 'code', 'execution_count': None, 'id': '5383aae5', 'metadata': {}, 'outputs': [], 'source': 'LR_ripple_outputs.selected_spikes_df'}, {'cell_type': 'code', 'execution_count': None, 'id': 'f4b664cb', 'metadata': {}, 'outputs': [], 'source': 'RL_ripple_outputs.\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '3fc41020', 'metadata': {}, 'outputs': [], 'source': '## Ensure equivalence of the two LR_ripple_outputs and RL_ripple_outputs for the fields that matter:\\nassert LR_ripple_outputs.spikes_df.equals(RL_ripple_outputs.spikes_df), f\"spikes_df are not equal\"\\nassert LR_ripple_outputs.selected_spikes_df.equals(RL_ripple_outputs.selected_spikes_df), f\"selected_spikes_df are not equal\"\\nassert LR_ripple_outputs.epochs_df.equals(RL_ripple_outputs.epochs_df), f\"epochs_df are not equal\"'}, {'cell_type': 'code', 'execution_count': None, 'id': '9defd355', 'metadata': {}, 'outputs': [], 'source': '_new_rank_order_event_raster_debugger = RankOrderRastersDebugger.init_rank_order_debugger(deepcopy(LR_ripple_outputs.selected_spikes_df), deepcopy(LR_ripple_outputs.epochs_df), track_templates, rank_order_results, None, None)\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'dfe68671', 'metadata': {}, 'outputs': [], 'source': '# TypeError: <lambda>() missing 1 required positional argument\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '28f1c551', 'metadata': {}, 'outputs': [], 'source': '## Recompute just the `most_likely_directional_rank_order_shuffling` part:\\n# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer\\n# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderLikelihoods\\n# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses\\n## Main\\nripple_result_tuple, laps_result_tuple = RankOrderAnalyses.most_likely_directional_rank_order_shuffling(curr_active_pipeline)\\nripple_result_tuple'}, {'cell_type': 'code', 'execution_count': None, 'id': 'cc170273', 'metadata': {}, 'outputs': [], 'source': 'rank_order_results.ripple_most_likely_result_tuple, rank_order_results.laps_most_likely_result_tuple = ripple_result_tuple, laps_result_tuple'}, {'cell_type': 'code', 'execution_count': None, 'id': '8d4b9c0f', 'metadata': {}, 'outputs': [], 'source': 'directional_likelihoods_tuple: DirectionalRankOrderLikelihoods = deepcopy(ripple_result_tuple.directional_likelihoods_tuple)\\ndirectional_likelihoods_tuple.long_best_direction_indices\\ndirectional_likelihoods_tuple.short_best_direction_indices\\n# directional_likelihoods_tuple.long_relative_direction_likelihoods'}, {'cell_type': 'markdown', 'id': '426c292d', 'metadata': {}, 'source': '\\n\\n\\n\\n# Saving/Loading `DirectionalLaps_2Hz`'}, {'cell_type': 'code', 'execution_count': None, 'id': '5ed6c50e', 'metadata': {'tags': ['save', 'persistance']}, 'outputs': [], 'source': 'from datetime import datetime, date, timedelta\\nfrom pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import save_rank_order_results\\n\\n# DAY_DATE_STR: str = date.today().strftime(\"%Y-%m-%d\")\\n# DAY_DATE_TO_USE = f\\'{DAY_DATE_STR}\\' # used for filenames throught the notebook\\n# print(f\\'DAY_DATE_STR: {DAY_DATE_STR}, DAY_DATE_TO_USE: {DAY_DATE_TO_USE}\\')\\n\\n# NOW_DATETIME: str = get_now_rounded_time_str()\\n# NOW_DATETIME_TO_USE = f\\'{NOW_DATETIME}\\' # used for filenames throught the notebook\\n# print(f\\'NOW_DATETIME: {NOW_DATETIME}, NOW_DATETIME_TO_USE: {NOW_DATETIME_TO_USE}\\')\\n\\nformatted_time = get_now_rounded_time_str()\\nprint(formatted_time)\\nsave_rank_order_results(curr_active_pipeline, day_date=f\"{formatted_time}\") # \"2024-01-02_301pm\" \"2024-01-02_322pm\" 322pm # \"2024-01-02_301pm\" \"2024-01-02_322pm\" 322pm\\n# \\'2024-01-09_0125PM-minimum_inclusion_fr-5-included_qclu_values-[1, 2]\\'\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e700b239', 'metadata': {}, 'outputs': [], 'source': 'search_path = Path(\\'/media/MAX/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/\\').resolve()\\nsorted(search_path.glob(f\"{DAY_DATE_TO_USE}*\"))\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '02da8a7c', 'metadata': {'tags': ['load']}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import SaveStringGenerator\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.Loading import loadData\\n\\n# Load the data from a file into the pipeline:\\n# out_filename_str: str = \\'2023-12-11-minimum_inclusion_fr_Hz_2_included_qclu_values_1-2_\\' # specific\\n\\nminimum_inclusion_fr_Hz: float = 5.0\\nincluded_qclu_values: List[int] = [1,2]\\nout_filename_str = SaveStringGenerator.generate_save_suffix(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values, day_date=f\\'{DAY_DATE_TO_USE}_11am\\') # \\'2023-12-21_349am\\'\\n# out_filename_str = SaveStringGenerator.generate_save_suffix(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values, day_date=\\'2023-12-22_312pm\\') # \\'2023-12-21_349am\\'\\nprint(f\\'out_filename_str: \"{out_filename_str}\"\\')\\n# day_date_str: str = \\'2023-12-11_with_tuple_newer_\\'\\n# day_date_str: str = \\'\\'\\ndirectional_laps_output_path = curr_active_pipeline.get_output_path().joinpath(f\\'{out_filename_str}DirectionalLaps.pkl\\').resolve()\\nassert directional_laps_output_path.exists()\\n# loaded_directional_laps, loaded_rank_order = loadData(directional_laps_output_path)\\nloaded_directional_laps = loadData(directional_laps_output_path)\\nassert (loaded_directional_laps is not None)\\n# assert (loaded_rank_order is not None)\\n\\nrank_order_output_path = curr_active_pipeline.get_output_path().joinpath(f\\'{out_filename_str}RankOrder.pkl\\').resolve()\\nloaded_rank_order = loadData(rank_order_output_path)'}, {'cell_type': 'code', 'execution_count': None, 'id': '475a82b8', 'metadata': {}, 'outputs': [], 'source': \"# Apply the loaded data to the pipeline:\\ncurr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'], curr_active_pipeline.global_computation_results.computed_data['RankOrder'] = loaded_directional_laps, loaded_rank_order\\ncurr_active_pipeline.global_computation_results.computed_data['RankOrder']\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'cd521ff3', 'metadata': {}, 'outputs': [], 'source': 'rank_order_results.RL_ripple.selected_spikes_df'}, {'cell_type': 'code', 'execution_count': None, 'id': '7c0a14f8', 'metadata': {}, 'outputs': [], 'source': 'rank_order_results.LR_ripple.selected_spikes_df'}, {'cell_type': 'markdown', 'id': 'f4ec24467335a760', 'metadata': {}, 'source': '# POST-Compute:'}, {'cell_type': 'code', 'execution_count': None, 'id': '728c46e6', 'metadata': {'notebookRunGroups': {'groupValue': '21'}, 'tags': ['unwrap']}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multi_sort_raster_browser\\nfrom pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\\n\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import paired_separately_sort_neurons, paired_incremental_sort_neurons # _display_directional_template_debugger\\nfrom neuropy.utils.indexing_helpers import paired_incremental_sorting, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies\\nfrom pyphoplacecellanalysis.GUI.Qt.Widgets.ScrollBarWithSpinBox.ScrollBarWithSpinBox import ScrollBarWithSpinBox\\n\\nfrom neuropy.utils.mixins.HDF5_representable import HDF_SerializationMixin\\nfrom pyphoplacecellanalysis.General.Model.ComputationResults import ComputedResult\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses, RankOrderResult, ShuffleHelper, Zscorer, LongShortStatsTuple, DirectionalRankOrderLikelihoods, DirectionalRankOrderResult, RankOrderComputationsContainer\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import TimeColumnAliasesProtocol\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalMergedDecodersResult\\n\\n## Display Testing\\n# from pyphoplacecellanalysis.External.pyqtgraph import QtGui\\nfrom pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import pyqtplot_build_image_bounds_extent, pyqtplot_plot_image\\n\\nspikes_df = curr_active_pipeline.sess.spikes_df\\nrank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data[\\'RankOrder\\']\\nminimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\\nincluded_qclu_values: List[int] = rank_order_results.included_qclu_values\\nripple_result_tuple, laps_result_tuple = rank_order_results.ripple_most_likely_result_tuple, rank_order_results.laps_most_likely_result_tuple\\ndirectional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data[\\'DirectionalLaps\\']\\ntrack_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\\nprint(f\\'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}\\')\\nprint(f\\'included_qclu_values: {included_qclu_values}\\')\\n# ripple_result_tuple\\n\\n## Unpacks `rank_order_results`: \\n# global_replays = Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\\n# global_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\\n# active_replay_epochs, active_epochs_df, active_selected_spikes_df = combine_rank_order_results(rank_order_results, global_replays, track_templates=track_templates)\\n# active_epochs_df\\n\\n# ripple_result_tuple.directional_likelihoods_tuple.long_best_direction_indices\\ndir_index_to_direction_name_map: Dict[int, str] = {0:\\'LR\\', 1:\"RL\"}\\n\\n\\n## All three DataFrames are the same number of rows, each with one row corresponding to an Epoch:\\nactive_replay_epochs_df = deepcopy(rank_order_results.LR_ripple.epochs_df)\\n# active_replay_epochs_df\\n\\n# Change column type to int8 for columns: \\'long_best_direction_indices\\', \\'short_best_direction_indices\\'\\n# directional_likelihoods_df = pd.DataFrame.from_dict(ripple_result_tuple.directional_likelihoods_tuple._asdict()).astype({\\'long_best_direction_indices\\': \\'int8\\', \\'short_best_direction_indices\\': \\'int8\\'})\\ndirectional_likelihoods_df = ripple_result_tuple.directional_likelihoods_df\\n# directional_likelihoods_df\\n\\n# 2023-12-15 - Newest method:\\n# laps_combined_epoch_stats_df = rank_order_results.laps_combined_epoch_stats_df\\n\\n# ripple_combined_epoch_stats_df: pd.DataFrame  = rank_order_results.ripple_combined_epoch_stats_df\\n# ripple_combined_epoch_stats_df\\n\\n\\n# # Concatenate the three DataFrames along the columns axis:\\n# # Assert that all DataFrames have the same number of rows:\\n# assert len(active_replay_epochs_df) == len(directional_likelihoods_df) == len(ripple_combined_epoch_stats_df), \"DataFrames have different numbers of rows.\"\\n# # Assert that all DataFrames have at least one row:\\n# assert len(active_replay_epochs_df) > 0, \"active_replay_epochs_df is empty.\"\\n# assert len(directional_likelihoods_df) > 0, \"directional_likelihoods_df is empty.\"\\n# assert len(ripple_combined_epoch_stats_df) > 0, \"ripple_combined_epoch_stats_df is empty.\"\\n# merged_complete_epoch_stats_df: pd.DataFrame = pd.concat([active_replay_epochs_df.reset_index(drop=True, inplace=False), directional_likelihoods_df.reset_index(drop=True, inplace=False), ripple_combined_epoch_stats_df.reset_index(drop=True, inplace=False)], axis=1)\\n# merged_complete_epoch_stats_df = merged_complete_epoch_stats_df.set_index(active_replay_epochs_df.index, inplace=False)\\n\\n# merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\\n# merged_complete_epoch_stats_df.to_csv(\\'output/2023-12-21_merged_complete_epoch_stats_df.csv\\')\\n# merged_complete_epoch_stats_df\\n\\nlaps_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.laps_merged_complete_epoch_stats_df ## New method\\nripple_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\\n\\n# DirectionalMergedDecoders: Get the result after computation:\\ndirectional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data[\\'DirectionalMergedDecoders\\']\\n\\nall_directional_decoder_dict_value = directional_merged_decoders_result.all_directional_decoder_dict\\nall_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\\n# long_directional_pf1D_Decoder_value = directional_merged_decoders_result.long_directional_pf1D_Decoder\\n# long_directional_decoder_dict_value = directional_merged_decoders_result.long_directional_decoder_dict\\n# short_directional_pf1D_Decoder_value = directional_merged_decoders_result.short_directional_pf1D_Decoder\\n# short_directional_decoder_dict_value = directional_merged_decoders_result.short_directional_decoder_dict\\n\\nall_directional_laps_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\\nall_directional_ripple_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\\n\\nlaps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.laps_directional_marginals_tuple\\nlaps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = directional_merged_decoders_result.laps_track_identity_marginals_tuple\\nripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.ripple_directional_marginals_tuple\\nripple_track_identity_marginals, ripple_track_identity_all_epoch_bins_marginal, ripple_most_likely_track_identity_from_decoder, ripple_is_most_likely_track_identity_Long = directional_merged_decoders_result.ripple_track_identity_marginals_tuple\\n\\nripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\\nlaps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\\n\\nprint(f\\'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}\\')\\n\\nlaps_all_epoch_bins_marginals_df = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\\nripple_all_epoch_bins_marginals_df = directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e8d2363d', 'metadata': {}, 'outputs': [], 'source': \"type(all_directional_decoder_dict_value)\\nlist(all_directional_decoder_dict_value.keys()) # ['long_LR', 'long_RL', 'short_LR', 'short_RL']\"}, {'cell_type': 'code', 'execution_count': None, 'id': '634e6027', 'metadata': {}, 'outputs': [], 'source': 'laps_all_epoch_bins_marginals_df\\nlaps_most_likely_direction_from_decoder\\nlong_'}, {'cell_type': 'code', 'execution_count': None, 'id': '8cdabd71', 'metadata': {}, 'outputs': [], 'source': 'type(ripple_result_tuple) # pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations.DirectionalRankOrderResult\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '8fca534c', 'metadata': {}, 'outputs': [], 'source': \"assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \\n\\nripple_result_tuple.plot_histograms(num='test')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '084f3f69', 'metadata': {}, 'outputs': [], 'source': 'from functools import wraps, partial\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\ndef register_type_display(func_to_register, type_to_register):\\n\\t\"\"\" adds the display function (`func_to_register`) it decorates to the class (`type_to_register) as a method\\n\\n\\n\\t\"\"\"\\n\\t@wraps(func_to_register)\\n\\tdef wrapper(*args, **kwargs):\\n\\t\\treturn func_to_register(*args, **kwargs)\\n\\n\\tfunction_name: str = func_to_register.__name__ # get the name of the function to be added as the property\\n\\tsetattr(type_to_register, function_name, wrapper) # set the function as a method with the same name as the decorated function on objects of the class.\\t\\n\\treturn wrapper\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '15629dae', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\\nfrom pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots \\n\\n# @register_type_display(DirectionalRankOrderResult)\\ndef plot_histograms(self: DirectionalRankOrderResult, **kwargs) -> \"MatplotlibRenderPlots\":\\n\\t\"\"\" \\n\\tnum=\\'RipplesRankOrderZscore\\'\\n\\t\"\"\"\\n\\tprint(f\\'.plot_histograms(..., kwargs: {kwargs})\\')\\n\\tfig = plt.figure(layout=\"constrained\", **kwargs)\\n\\tax_dict = fig.subplot_mosaic(\\n\\t\\t[\\n\\t\\t\\t[\"long_short_best_z_score_diff\", \"long_short_best_z_score_diff\"],\\n\\t\\t\\t[\"long_best_z_scores\", \"short_best_z_scores\"],\\n\\t\\t],\\n\\t)\\n\\tplots = (pd.DataFrame({\\'long_best_z_scores\\': self.long_best_dir_z_score_values}).hist(ax=ax_dict[\\'long_best_z_scores\\'], bins=21, alpha=0.8),\\n\\t\\tpd.DataFrame({\\'short_best_z_scores\\': self.short_best_dir_z_score_values}).hist(ax=ax_dict[\\'short_best_z_scores\\'], bins=21, alpha=0.8),\\n\\t\\tpd.DataFrame({\\'long_short_best_z_score_diff\\': self.long_short_best_dir_z_score_diff_values}).hist(ax=ax_dict[\\'long_short_best_z_score_diff\\'], bins=21, alpha=0.8),\\n\\t)\\n\\treturn MatplotlibRenderPlots(name=\\'plot_histogram_figure\\', figures=[fig], axes=ax_dict)\\n\\n\\nregister_type_display(plot_histograms, DirectionalRankOrderResult)\\n## Call the newly added `plot_histograms` function on the `ripple_result_tuple` object which is of type `DirectionalRankOrderResult`:\\nassert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \\nripple_result_tuple.plot_histograms(num=\\'test\\')'}, {'cell_type': 'code', 'execution_count': None, 'id': '1c291690', 'metadata': {}, 'outputs': [], 'source': 'ripple_result_tuple.plot_histograms()'}, {'cell_type': 'code', 'execution_count': None, 'id': '33b30bcb', 'metadata': {}, 'outputs': [], 'source': \"print(f'\\\\t try saving to CSV...')\\nmerged_complete_epoch_stats_df = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\\n\\nmerged_complete_ripple_epoch_stats_df_output_path = curr_active_pipeline.get_output_path().joinpath(f'{DAY_DATE_TO_USE}_1247pm_merged_complete_epoch_stats_df.csv').resolve()\\nmerged_complete_epoch_stats_df.to_csv(merged_complete_ripple_epoch_stats_df_output_path)\\nprint(f'\\\\t saving to CSV: {merged_complete_ripple_epoch_stats_df_output_path} done.')\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'ee47f176', 'metadata': {}, 'outputs': [], 'source': \"from pyphocorehelpers.indexing_helpers import reorder_columns\\n\\ndict(zip(['Long_LR_evidence', 'Long_RL_evidence', 'Short_LR_evidence', 'Short_RL_evidence'], np.arange(4)+4))\\nreorder_columns(merged_complete_epoch_stats_df, column_name_desired_index_dict=dict(zip(['Long_LR_evidence', 'Long_RL_evidence', 'Short_LR_evidence', 'Short_RL_evidence'], np.arange(4)+4)))\\n\"}, {'cell_type': 'markdown', 'id': '2dceda30', 'metadata': {}, 'source': '## 2023-12-21 - Computing Spearman Percentiles as an alternative to the Z-score from shuffling, which does not seem to work for small numbers of active cells in an event:'}, {'cell_type': 'code', 'execution_count': None, 'id': 'b45aa7e2', 'metadata': {}, 'outputs': [], 'source': \"output_active_epoch_computed_values, shuffled_results_output_dict, combined_variable_names, valid_stacked_arrays, real_stacked_arrays, n_valid_shuffles = rank_order_results.ripple_new_output_tuple\\n# shuffled_results_output_dict['short_LR_pearson_Z']\\nprint(list(shuffled_results_output_dict.keys())) # ['short_LR_pearson_Z', 'short_LR_spearman_Z', 'short_RL_pearson_Z', 'short_RL_spearman_Z', 'long_LR_pearson_Z', 'long_RL_pearson_Z', 'long_RL_spearman_Z', 'long_LR_spearman_Z']\\n\\n['long_LR_pearson_Z', 'long_RL_pearson_Z', 'short_LR_pearson_Z', 'short_RL_pearson_Z']\"}, {'cell_type': 'code', 'execution_count': None, 'id': '46b40bfe', 'metadata': {}, 'outputs': [], 'source': \"## 2023-12-22 - Add the LR-LR, RL-RL differences\\nmerged_complete_epoch_stats_df['LongShort_LR_quantile_diff'] = merged_complete_epoch_stats_df['LR_Long_rank_percentile'] - merged_complete_epoch_stats_df['LR_Short_rank_percentile']\\nmerged_complete_epoch_stats_df['LongShort_RL_quantile_diff'] = merged_complete_epoch_stats_df['RL_Long_rank_percentile'] - merged_complete_epoch_stats_df['RL_Short_rank_percentile']\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'e73865dd', 'metadata': {}, 'outputs': [], 'source': \"ripple_combined_epoch_stats_df = deepcopy(merged_complete_epoch_stats_df)\\n\\n# Filter rows based on columns: 'Long_BestDir_quantile', 'Short_BestDir_quantile'\\nquantile_significance_threshold: float = 0.95\\nsignificant_BestDir_quantile_stats_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['Long_BestDir_quantile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['Short_BestDir_quantile'] > quantile_significance_threshold)]\\nLR_likely_active_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['combined_best_direction_indicies']==0) & ((ripple_combined_epoch_stats_df['LR_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['LR_Short_rank_percentile'] > quantile_significance_threshold))]\\nRL_likely_active_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['combined_best_direction_indicies']==1) & ((ripple_combined_epoch_stats_df['RL_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['RL_Short_rank_percentile'] > quantile_significance_threshold))]\\n\\n# significant_ripple_combined_epoch_stats_df = ripple_combined_epoch_stats_df[(ripple_combined_epoch_stats_df['LR_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['LR_Short_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['RL_Long_rank_percentile'] > quantile_significance_threshold) | (ripple_combined_epoch_stats_df['RL_Short_rank_percentile'] > quantile_significance_threshold)]\\n# significant_ripple_combined_epoch_stats_df\\nis_epoch_significant = np.isin(ripple_combined_epoch_stats_df.index, significant_BestDir_quantile_stats_df.index)\\nactive_replay_epochs_df = rank_order_results.LR_ripple.epochs_df\\nsignificant_ripple_epochs: Epoch = Epoch(deepcopy(active_replay_epochs_df).epochs.get_valid_df()).boolean_indicies_slice(is_epoch_significant)\\nepoch_identifiers = significant_ripple_epochs._df.label.astype({'label': RankOrderAnalyses._label_column_type}).values #.labels\\nx_values = significant_ripple_epochs.midtimes\\nx_axis_name_suffix = 'Mid-time (Sec)'\\n\\n# significant_ripple_epochs_df = significant_ripple_epochs.to_dataframe()\\n# significant_ripple_epochs_df\\n\\nsignificant_BestDir_quantile_stats_df['midtimes'] = significant_ripple_epochs.midtimes\\nsignificant_BestDir_quantile_stats_df\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'bb18612f', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import _plot_significant_event_quantile_fig\\n\\n# active_replay_epochs_df = rank_order_results.LR_ripple.epochs_df\\n# if isinstance(global_events, pd.DataFrame):\\n#     active_replay_epochs = Epoch(deepcopy(active_replay_epochs_df).epochs.get_valid_df())\\n\\n\\n# _out = _plot_significant_event_quantile_fig(curr_active_pipeline, significant_ripple_combined_epoch_stats_df=significant_ripple_combined_epoch_stats_df)\\n# _out\\n\\nmarker_style = dict(linestyle='None', color='#ff7f0eff', markersize=6, markerfacecolor='#ff7f0eb4', markeredgecolor='#ff7f0eff')\\n\\n    # dict(facecolor='#ff7f0eb4', size=8.0)\\n    # fignum='best_quantiles'\\n\\n# ripple_combined_epoch_stats_df['combined_best_direction_indicies']\\n\\n_out = significant_BestDir_quantile_stats_df[['midtimes', 'LongShort_BestDir_quantile_diff']].plot(x='midtimes', y='LongShort_BestDir_quantile_diff', title='Sig. (>0.95) Best Quantile Diff', **marker_style, marker='o')\\n\\n\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'a618ac40', 'metadata': {}, 'outputs': [], 'source': \"import seaborn as sns\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import plot_quantile_diffs\\n\\n_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\\nglobal_epoch = curr_active_pipeline.filtered_epochs[global_epoch_name]\\nshort_epoch = curr_active_pipeline.filtered_epochs[short_epoch_name]\\nsplit_time_t: float = short_epoch.t_start\\nactive_context = curr_active_pipeline.sess.get_context()\\n\\ncollector = plot_quantile_diffs(ripple_merged_complete_epoch_stats_df, t_split=split_time_t, active_context=active_context)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '0dd89199', 'metadata': {}, 'outputs': [], 'source': '\\nfrom flexitext import flexitext ## flexitext for formatted matplotlib text\\nfrom neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\\nperform_update_title_subtitle(fig=fig_long_pf_1D, ax=ax_long_pf_1D, title_string=title_string, subtitle_string=subtitle_string, active_context=active_context, use_flexitext_titles=True)\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '1e46ba5f', 'metadata': {}, 'outputs': [], 'source': '\\nfrom neuropy.utils.matplotlib_helpers import draw_epoch_regions\\nepochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, defer_render=False, debug_print=False)'}, {'cell_type': 'code', 'execution_count': None, 'id': '24ecb4c7', 'metadata': {}, 'outputs': [], 'source': \"print(list(significant_BestDir_quantile_stats_df.columns))\\n['LR_Long_rank_percentile', 'LR_Short_rank_percentile', 'RL_Long_rank_percentile', 'RL_Short_rank_percentile', 'Long_BestDir_quantile', 'Short_BestDir_quantile', 'LongShort_BestDir_quantile_diff']\\n\\nfor a_name in ['LR_Long_rank_percentile', 'LR_Short_rank_percentile', 'RL_Long_rank_percentile', 'RL_Short_rank_percentile', 'Long_BestDir_quantile', 'Short_BestDir_quantile', 'LongShort_BestDir_quantile_diff']:\\n\\t_out = significant_BestDir_quantile_stats_df[['midtimes', 'LongShort_BestDir_quantile_diff']].plot(x='midtimes', y=a_name, title=f'Sig. (>0.95) {a_name}', **marker_style, marker='o')\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'f883fba9', 'metadata': {}, 'outputs': [], 'source': \"# quantile_results_df[['LR_Long_rank_percentile', 'RL_Long_rank_percentile', 'LR_Short_rank_percentile', 'RL_Short_rank_percentile']].plot.hist(bins=21)\\n# quantile_results_df[['LR_Long_rank_percentile', 'RL_Long_rank_percentile', 'LR_Short_rank_percentile', 'RL_Short_rank_percentile']].plot.hist(bins=21)\\n\\ndf = quantile_results_df[['LR_Long_rank_percentile', 'RL_Long_rank_percentile', 'LR_Short_rank_percentile', 'RL_Short_rank_percentile']].copy()\\n# Create the subplots and loop through columns\\nfig, axes = plt.subplots(4, 1, figsize=(10, 10))\\nfor i, col in enumerate(df.columns):\\n    df[col].plot.hist(ax=axes[i], bins=21)\\n    axes[i].set_title(col)\\n\\n# Adjust layout and display plot\\nplt.tight_layout()\\nplt.show()\\n\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '9fd61a13', 'metadata': {}, 'outputs': [], 'source': 'win = pg.GraphicsLayoutWidget(show=True)\\nwin.resize(800,350)\\nwin.setWindowTitle(\\'Z-Scorer: Histogram\\')\\nplt1 = win.addPlot()\\nvals = quantile_results_df.LR_Long_rank_percentile\\nfisher_z_transformed_vals = np.arctanh(vals)\\n\\n## compute standard histogram\\ny, x = np.histogram(vals) # , bins=np.linspace(-3, 8, 40)\\n# fisher_z_transformed_y, x = np.histogram(fisher_z_transformed_vals, bins=x)\\n\\n## Using stepMode=\"center\" causes the plot to draw two lines for each sample.\\n## notice that len(x) == len(y)+1\\nplt1.plot(x, y, stepMode=\"center\", fillLevel=0, fillOutline=True, brush=(0,0,255,50), name=\\'original_values\\')\\nplt1.plot(x, y, stepMode=\"center\", fillLevel=0, fillOutline=True, brush=(0,0,255,50), name=\\'original_values\\')\\n# plt1.plot(x, fisher_z_transformed_y, stepMode=\"center\", fillLevel=0, fillOutline=True, brush=(0,255,100,50), name=\\'fisher_z_values\\')\\n\\n# ## Now draw all points as a nicely-spaced scatter plot\\ny = pg.pseudoScatter(vals, spacing=0.15)\\n# #plt2.plot(vals, y, pen=None, symbol=\\'o\\', symbolSize=5)\\nplt2.plot(vals, y, pen=None, symbol=\\'o\\', symbolSize=5, symbolPen=(255,255,255,200), symbolBrush=(0,0,255,150))\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'd30cb791', 'metadata': {}, 'outputs': [], 'source': \"\\npd.concat((ripple_combined_epoch_stats_df, ripple_p_values_epoch_stats_df), axis='columns')\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'd300a225', 'metadata': {}, 'outputs': [], 'source': 'ripple_result_tuple.directional_likelihoods_tuple'}, {'cell_type': 'code', 'execution_count': None, 'id': '43327521', 'metadata': {}, 'outputs': [], 'source': 'np.logical_not(np.isnan(rank_order_results.ripple_combined_epoch_stats_df.index).any())\\n# ripple_combined_epoch_stats_df.label.isna()'}, {'cell_type': 'code', 'execution_count': None, 'id': 'bb3c142b', 'metadata': {}, 'outputs': [], 'source': 'ripple_combined_epoch_stats_df'}, {'cell_type': 'code', 'execution_count': None, 'id': '4f3cedf8', 'metadata': {}, 'outputs': [], 'source': 'np.isnan(ripple_combined_epoch_stats_df.label).any()'}, {'cell_type': 'code', 'execution_count': None, 'id': '31224e10', 'metadata': {}, 'outputs': [], 'source': 'np.isnan(ripple_combined_epoch_stats_df.index).any()'}, {'cell_type': 'code', 'execution_count': None, 'id': '60749347', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': \"print(f'\\\\tdone. building global result.')\\ndirectional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\\nselected_spikes_df = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.selected_spikes_df)\\n# active_epochs = global_computation_results.computed_data['RankOrder'].ripple_most_likely_result_tuple.active_epochs\\nactive_epochs = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.epochs_df)\\ntrack_templates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '97ab4052', 'metadata': {}, 'outputs': [], 'source': 'ripple_combined_epoch_stats_df, ripple_new_output_tuple = RankOrderAnalyses.pandas_df_based_correlation_computations(selected_spikes_df=selected_spikes_df, active_epochs_df=active_epochs, track_templates=track_templates, num_shuffles=100)\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '313886d9', 'metadata': {}, 'outputs': [], 'source': \"# new_output_tuple (output_active_epoch_computed_values, valid_stacked_arrays, real_stacked_arrays, n_valid_shuffles) = ripple_new_output_tuple\\ncurr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_combined_epoch_stats_df, curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_new_output_tuple = ripple_combined_epoch_stats_df, ripple_new_output_tuple\\nprint(f'done!')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '35e95d52', 'metadata': {}, 'outputs': [], 'source': \"decoder_aclu_peak_map_dict = track_templates.get_decoder_aclu_peak_map_dict()\\n## Restrict to only the relevant columns, and Initialize the dataframe columns to np.nan:\\nactive_selected_spikes_df: pd.DataFrame = deepcopy(selected_spikes_df[['t_rel_seconds', 'aclu', 'Probe_Epoch_id']]).sort_values(['Probe_Epoch_id', 't_rel_seconds', 'aclu']).astype({'Probe_Epoch_id': RankOrderAnalyses._label_column_type}) # Sort by columns: 'Probe_Epoch_id' (ascending), 't_rel_seconds' (ascending), 'aclu' (ascending)\\n\\n# _pf_peak_x_column_names = ['LR_Long_pf_peak_x', 'RL_Long_pf_peak_x', 'LR_Short_pf_peak_x', 'RL_Short_pf_peak_x']\\n_pf_peak_x_column_names = [f'{a_decoder_name}_pf_peak_x' for a_decoder_name in track_templates.get_decoder_names()]\\nactive_selected_spikes_df[_pf_peak_x_column_names] = pd.DataFrame([[RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type]], index=active_selected_spikes_df.index)\\n\\nunique_Probe_Epoch_IDs = active_selected_spikes_df['Probe_Epoch_id'].unique()\\nunique_Probe_Epoch_IDs\"}, {'cell_type': 'code', 'execution_count': None, 'id': '0896891d', 'metadata': {}, 'outputs': [], 'source': \"for a_probe_epoch_ID in unique_Probe_Epoch_IDs:\\n\\t# probe_epoch_df = active_selected_spikes_df[a_probe_epoch_ID == active_selected_spikes_df['Probe_Epoch_id']]\\n\\t# epoch_unique_aclus = probe_epoch_df.aclu.unique()\\n\\tmask = (a_probe_epoch_ID == active_selected_spikes_df['Probe_Epoch_id'])\\n\\t# epoch_unique_aclus = active_selected_spikes_df.loc[mask, 'aclu'].unique()\\n\\tfor a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items():\\n\\t\\t# Shuffle aclus here:\\n\\t\\tactive_selected_spikes_df.loc[mask, 'aclu'] = active_selected_spikes_df.loc[mask, 'aclu'].sample(frac=1).values\\n\\t\\tactive_selected_spikes_df.loc[mask, f'{a_decoder_name}_pf_peak_x'] = active_selected_spikes_df.loc[mask, 'aclu'].map(a_aclu_peak_map)\\n\\n\\t\\t# ## Shuffle aclus here:\\n\\t\\t# # probe_epoch_df.aclu.sample(1000)\\n\\t\\t# # a_aclu_peak_map\\n\\t\\t# # Assuming 'df' is your DataFrame and 'column_name' is the column you want to shuffle\\n\\t\\t# probe_epoch_df['aclu'] = probe_epoch_df['aclu'].sample(frac=1).reset_index(drop=True)\\n\\n\\t\\t# probe_epoch_df[f'{a_decoder_name}_pf_peak_x'] = probe_epoch_df.aclu.map(a_aclu_peak_map)\\n\\n\\t\\t# active_selected_spikes_df[f'{a_decoder_name}_pf_peak_x'] = active_selected_spikes_df.aclu.map(a_aclu_peak_map)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'c9d43ee1', 'metadata': {}, 'outputs': [], 'source': \"# Determine the number of shuffles you want to do\\nnum_shuffles = 5\\n\\n# Create a list to hold the shuffled DataFrames\\nshuffled_dfs = []\\n\\nfor i in range(num_shuffles):\\n    # Working on a copy of the DataFrame\\n    shuffled_df = active_selected_spikes_df.copy()\\n    \\n    for a_probe_epoch_ID in unique_Probe_Epoch_IDs:\\n        mask = (a_probe_epoch_ID == shuffled_df['Probe_Epoch_id'])\\n        shuffled_df.loc[mask, 'aclu'] = shuffled_df.loc[mask, 'aclu'].sample(frac=1).values\\n        \\n    # Adding the shuffled DataFrame to the list\\n    shuffled_dfs.append(shuffled_df)\\n\\n# Now applying the mapping\\nfor i in range(num_shuffles):\\n    shuffled_df = shuffled_dfs[i]\\n    \\n    for a_probe_epoch_ID in unique_Probe_Epoch_IDs:\\n        mask = (a_probe_epoch_ID == shuffled_df['Probe_Epoch_id'])\\n        \\n        for a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items():\\n            shuffled_df.loc[mask, f'{a_decoder_name}_pf_peak_x'] = shuffled_df.loc[mask, 'aclu'].map(a_aclu_peak_map)\\n        \\n    # Replacing the shuffled DataFrame in the list after mapping has been applied\\n    shuffled_dfs[i] = shuffled_df\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'f8c2e32c', 'metadata': {}, 'outputs': [], 'source': \"shuffled_dfs\\n\\n'polars[pandas,numpy,pyarrow,fsspec,connectorx,plot]'\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '9c306ade', 'metadata': {}, 'outputs': [], 'source': '## 2024-01-09 - More Efficient\\nimport polars as pl\\n\\n\\n\\n\\ndef _new_compute_single_rank_order_shuffle(track_templates, active_selected_spikes_df: pd.DataFrame):\\n    \"\"\" 2024-01-09 - Candidate for moving into RankOrderComputations \\n    captures: decoder_names\\n    \\n    Usage:\\n    \\n    shuffled_dfs = _perform_efficient_shuffle(active_selected_spikes_df, decoder_aclu_peak_map_dict, num_shuffles=5)\\n    \\n    \"\"\"\\n    decoder_names = track_templates.get_decoder_names()\\n    \\n    ## Compute real values here:\\n    epoch_id_grouped_selected_spikes_df = active_selected_spikes_df.groupby(\\'Probe_Epoch_id\\') # I can even compute this outside the loop?\\n\\n    # spearman_correlations = epoch_id_grouped_selected_spikes_df.apply(lambda group: RankOrderAnalyses._subfn_calculate_correlations(group, method=\\'spearman\\', decoder_names=decoder_names)).reset_index() # Reset index to make \\'Probe_Epoch_id\\' a column\\n    # pearson_correlations = epoch_id_grouped_selected_spikes_df.apply(lambda group: RankOrderAnalyses._subfn_calculate_correlations(group, method=\\'pearson\\', decoder_names=decoder_names)).reset_index() # Reset index to make \\'Probe_Epoch_id\\' a column\\n\\n    # real_stats_df = pd.concat((spearman_correlations, pearson_correlations), axis=\\'columns\\')\\n    # real_stats_df = real_stats_df.loc[:, ~real_stats_df.columns.duplicated()] # drop duplicated \\'Probe_Epoch_id\\' column\\n    # # Change column type to uint64 for column: \\'Probe_Epoch_id\\'\\n    # real_stats_df = real_stats_df.astype({\\'Probe_Epoch_id\\': \\'uint64\\'})\\n    # # Rename column \\'Probe_Epoch_id\\' to \\'label\\'\\n    # real_stats_df = real_stats_df.rename(columns={\\'Probe_Epoch_id\\': \\'label\\'})\\n    \\n    # Parallelize correlation computations if required\\n    correlations = []\\n    for method in [\\'spearman\\', \\'pearson\\']:\\n        correlations.append(\\n            epoch_id_grouped_selected_spikes_df.apply(\\n                lambda group: RankOrderAnalyses._subfn_calculate_correlations(\\n                    group, method=method, decoder_names=decoder_names)\\n            )\\n        )\\n  \\n    # Adjust and join all calculated correlations\\n    real_stats_df = pd.concat(correlations, axis=\\'columns\\').reset_index()\\n    real_stats_df = real_stats_df.loc[:, ~real_stats_df.columns.duplicated()]\\n\\n    real_stats_df.rename(columns={\\'Probe_Epoch_id\\': \\'label\\'}, inplace=True)\\n    real_stats_df[\\'label\\'] = real_stats_df[\\'label\\'].astype(\\'uint64\\')  # in-place type casting\\n    \\n    return real_stats_df\\n\\n\\n# Determine the number of shuffles you want to do\\ndef _new_perform_efficient_shuffle(track_templates, active_selected_spikes_df, decoder_aclu_peak_map_dict, num_shuffles:int=5):\\n    \"\"\" 2024-01-09 - Performs the shuffles in a simple way\\n    \\n    \"\"\"\\n    unique_Probe_Epoch_IDs = active_selected_spikes_df[\\'Probe_Epoch_id\\'].unique()\\n\\n    # Create a list to hold the shuffled dataframes\\n    shuffled_dfs = []\\n    shuffled_stats_dfs = []\\n\\n    for i in range(num_shuffles):\\n        # Working on a copy of the DataFrame\\n        shuffled_df = active_selected_spikes_df.copy()\\n\\n        for a_probe_epoch_ID in unique_Probe_Epoch_IDs:\\n            mask = (a_probe_epoch_ID == shuffled_df[\\'Probe_Epoch_id\\'])\\n            \\n            # Shuffle \\'aclu\\' values\\n            shuffled_df.loc[mask, \\'aclu\\'] = shuffled_df.loc[mask, \\'aclu\\'].sample(frac=1).values\\n            \\n            # # Apply aclu peak map dictionary to \\'aclu\\' column\\n            # for a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items():\\n            #     shuffled_df.loc[mask, f\\'{a_decoder_name}_pf_peak_x\\'] = shuffled_df.loc[mask, \\'aclu\\'].map(a_aclu_peak_map)\\n            \\n\\n        # end `for a_probe_epoch_ID`\\n        # Once done, apply the aclu peak maps to shuffled_df\\'s \\'aclu\\' column:\\n        for a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items():\\n            shuffled_df[f\\'{a_decoder_name}_pf_peak_x\\'] = shuffled_df.aclu.map(a_aclu_peak_map)\\n            \\n        a_shuffle_stats_df = _new_compute_single_rank_order_shuffle(track_templates, active_selected_spikes_df=shuffled_df)\\n        \\n        # Adding the shuffled DataFrame to the list\\n        shuffled_dfs.append(shuffled_df)\\n        shuffled_stats_dfs.append(a_shuffle_stats_df)\\n        \\n    return shuffled_dfs, shuffled_stats_dfs\\n\\n\\n\\ndef _suggested_perform_efficient_shuffle(track_templates, active_selected_spikes_df, decoder_aclu_peak_map_dict, num_shuffles: int = 5):\\n    unique_Probe_Epoch_IDs = active_selected_spikes_df[\\'Probe_Epoch_id\\'].unique()\\n    shuffled_dfs = []\\n    shuffled_stats_dfs = []\\n\\n    def map_dict_to_group(group, a_dict, column):\\n        group[column] = group[column].map(a_dict)\\n        return group\\n\\n    for i in range(num_shuffles):\\n        shuffled_df = active_selected_spikes_df.copy()\\n\\n        for a_probe_epoch_ID in unique_Probe_Epoch_IDs:\\n            shuffled_df.loc[shuffled_df[\\'Probe_Epoch_id\\'] == a_probe_epoch_ID, \\'aclu\\'] = shuffled_df.loc[shuffled_df[\\'Probe_Epoch_id\\'] == a_probe_epoch_ID, \\'aclu\\'].sample(frac=1).values\\n\\n        for a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items():\\n            shuffled_df = shuffled_df.groupby(\\'Probe_Epoch_id\\').apply(map_dict_to_group, a_dict=a_aclu_peak_map, column=f\\'{a_decoder_name}_pf_peak_x\\')\\n\\n        a_shuffle_stats_df = _new_compute_single_rank_order_shuffle(track_templates, active_selected_spikes_df=shuffled_df)\\n\\n        shuffled_dfs.append(shuffled_df)\\n        shuffled_stats_dfs.append(a_shuffle_stats_df)\\n\\n    return shuffled_dfs, shuffled_stats_dfs\\n\\n\\n\\n## Compute:\\ndecoder_aclu_peak_map_dict = track_templates.get_decoder_aclu_peak_map_dict()\\n## Restrict to only the relevant columns, and Initialize the dataframe columns to np.nan:\\nactive_selected_spikes_df: pd.DataFrame = deepcopy(selected_spikes_df[[\\'t_rel_seconds\\', \\'aclu\\', \\'Probe_Epoch_id\\']]).sort_values([\\'Probe_Epoch_id\\', \\'t_rel_seconds\\', \\'aclu\\']).astype({\\'Probe_Epoch_id\\': RankOrderAnalyses._label_column_type}) # Sort by columns: \\'Probe_Epoch_id\\' (ascending), \\'t_rel_seconds\\' (ascending), \\'aclu\\' (ascending)\\n# _pf_peak_x_column_names = [\\'LR_Long_pf_peak_x\\', \\'RL_Long_pf_peak_x\\', \\'LR_Short_pf_peak_x\\', \\'RL_Short_pf_peak_x\\']\\n_pf_peak_x_column_names = [f\\'{a_decoder_name}_pf_peak_x\\' for a_decoder_name in track_templates.get_decoder_names()]\\nactive_selected_spikes_df[_pf_peak_x_column_names] = pd.DataFrame([[RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type]], index=active_selected_spikes_df.index)\\n\\n# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-suggested_perform_efficient_shuffle.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\\nshuffled_dfs, shuffled_stats_dfs = _suggested_perform_efficient_shuffle(track_templates, active_selected_spikes_df, decoder_aclu_peak_map_dict, num_shuffles=10) # 50, 1m 21.2s, 10, 16.1s\\n# shuffled_dfs, shuffled_stats_dfs = _new_perform_efficient_shuffle(track_templates, active_selected_spikes_df, decoder_aclu_peak_map_dict, num_shuffles=10) # 10, 12.8s\\n\\n\\nshuffled_dfs\\nshuffled_stats_dfs\\n# 5, 4.1 sec\\n# 0.5s!!\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '8421d876', 'metadata': {}, 'outputs': [], 'source': 'output_active_epoch_computed_values = shuffled_stats_dfs\\n# Build the output `stacked_arrays`: _________________________________________________________________________________ #\\n\\nstacked_arrays = np.stack([a_shuffle_real_stats_df[combined_variable_names].to_numpy() for a_shuffle_real_stats_df in output_active_epoch_computed_values], axis=0) # for compatibility: .shape (n_shuffles, n_epochs, n_columns)\\n# stacked_df = pd.concat(output_active_epoch_computed_values, axis=\\'index\\')\\n\\n## Drop any shuffle indicies where NaNs are returned for any of the stats values.\\nis_valid_row = np.logical_not(np.isnan(stacked_arrays)).all(axis=(1,2)) # row [0, 66, :] is bad, ... so is [1, 66, :], ... [20, 66, :], ... they are repeated!!\\nn_valid_shuffles = np.sum(is_valid_row)\\nif debug_print:\\n\\tprint(f\\'n_valid_shuffles: {n_valid_shuffles}\\')\\nvalid_stacked_arrays = stacked_arrays[is_valid_row] ## Get only the rows where all elements along both axis (1, 2) are True\\n\\n# Need: valid_stacked_arrays, real_stacked_arrays, combined_variable_names\\ncombined_epoch_stats_df: pd.DataFrame = pd.DataFrame(real_stacked_arrays, columns=combined_variable_names)\\ncombined_variable_z_score_column_names = [f\"{a_name}_Z\" for a_name in combined_variable_names] # combined_variable_z_score_column_names: [\\'LR_Long_spearman_Z\\', \\'RL_Long_spearman_Z\\', \\'LR_Short_spearman_Z\\', \\'RL_Short_spearman_Z\\', \\'LR_Long_pearson_Z\\', \\'RL_Long_pearson_Z\\', \\'LR_Short_pearson_Z\\', \\'RL_Short_pearson_Z\\']\\n\\n## Extract the stats values for each shuffle from `valid_stacked_arrays`:\\nn_epochs = np.shape(real_stacked_arrays)[0]\\nn_variables = np.shape(real_stacked_arrays)[1]\\n\\n# valid_stacked_arrays.shape: (n_shuffles, n_epochs, n_variables)\\nassert n_epochs == np.shape(valid_stacked_arrays)[-2]\\nassert n_variables == np.shape(valid_stacked_arrays)[-1]'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e660e692', 'metadata': {}, 'outputs': [], 'source': \"from joblib import Parallel, delayed\\n\\n# Determine the number of shuffles you want to do\\nnum_shuffles = 5\\n\\n# Define the operation to be run in parallel for a shuffle iteration\\ndef shuffle_iteration(i):\\n    # Working on a copy of the DataFrame\\n    shuffled_df = active_selected_spikes_df.copy()\\n\\n    for a_probe_epoch_ID in unique_Probe_Epoch_IDs:\\n        mask = (a_probe_epoch_ID == shuffled_df['Probe_Epoch_id'])\\n\\n        # Shuffle 'aclu' values\\n        shuffled_df.loc[mask, 'aclu'] = shuffled_df.loc[mask, 'aclu'].sample(frac=1).values\\n\\n        # Apply aclu peak map dictionary to 'aclu' column\\n        for a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items():\\n            shuffled_df.loc[mask, f'{a_decoder_name}_pf_peak_x'] = shuffled_df.loc[mask, 'aclu'].map(a_aclu_peak_map)\\n\\n    # Return the shuffled DataFrame\\n    return shuffled_df\\n\\n# Create a list to hold the shuffled dataframes\\nshuffled_dfs = Parallel(n_jobs=-1)(delayed(shuffle_iteration)(i) for i in range(num_shuffles))\"}, {'cell_type': 'code', 'execution_count': None, 'id': '8f45e697', 'metadata': {}, 'outputs': [], 'source': \"# ['long_LR_pf_peak_x', 'long_RL_pf_peak_x', 'short_LR_pf_peak_x', 'short_RL_pf_peak_x']\\npeak_column_names = [f'{a_decoder_name}_pf_peak_x' for a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items()]\\nprint(peak_column_names) \\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'da6b42a7', 'metadata': {}, 'outputs': [], 'source': \"def _perform_efficient_shuffle_pre_mapping(active_selected_spikes_df, decoder_aclu_peak_map_dict, num_shuffles:int=5):\\n    # Apply aclu peak map dictionary to each decoder name\\n    for a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items():\\n        active_selected_spikes_df[f'{a_decoder_name}_pf_peak_x'] = active_selected_spikes_df['aclu'].map(a_aclu_peak_map)\\n\\n    unique_Probe_Epoch_IDs = active_selected_spikes_df['Probe_Epoch_id'].unique()\\n    shuffles = {}\\n    for i in range(num_shuffles):\\n        shuffles[i] = active_selected_spikes_df.copy()\\n        for a_probe_epoch_ID in unique_Probe_Epoch_IDs:\\n            mask = (a_probe_epoch_ID == shuffles[i]['Probe_Epoch_id'])\\n            # Shuffle multiple columns here:\\n            for a_decoder_name in decoder_aclu_peak_map_dict.keys():\\n                shuffles[i].loc[mask, f'{a_decoder_name}_pf_peak_x'] = shuffles[i].loc[mask, f'{a_decoder_name}_pf_peak_x'].sample(frac=1).values\\n    return shuffles\\n\\n## Compute:\\ndecoder_aclu_peak_map_dict = track_templates.get_decoder_aclu_peak_map_dict()\\n## Restrict to only the relevant columns, and Initialize the dataframe columns to np.nan:\\nactive_selected_spikes_df: pd.DataFrame = deepcopy(selected_spikes_df[['t_rel_seconds', 'aclu', 'Probe_Epoch_id']]).sort_values(['Probe_Epoch_id', 't_rel_seconds', 'aclu']).astype({'Probe_Epoch_id': RankOrderAnalyses._label_column_type}) # Sort by columns: 'Probe_Epoch_id' (ascending), 't_rel_seconds' (ascending), 'aclu' (ascending)\\n# _pf_peak_x_column_names = ['LR_Long_pf_peak_x', 'RL_Long_pf_peak_x', 'LR_Short_pf_peak_x', 'RL_Short_pf_peak_x']\\n_pf_peak_x_column_names = [f'{a_decoder_name}_pf_peak_x' for a_decoder_name in track_templates.get_decoder_names()]\\nactive_selected_spikes_df[_pf_peak_x_column_names] = pd.DataFrame([[RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type, RankOrderAnalyses._NaN_Type]], index=active_selected_spikes_df.index)\\nshuffled_dfs = _perform_efficient_shuffle_pre_mapping(active_selected_spikes_df, decoder_aclu_peak_map_dict, num_shuffles=5)\\n# shuffled_dfs\\n# 5, 1.5 sec\"}, {'cell_type': 'code', 'execution_count': None, 'id': '548d3db2', 'metadata': {}, 'outputs': [], 'source': \"# Shuffle 'aclu' values\\nshuffled_df.loc[mask, 'aclu'] = shuffled_df.loc[mask, 'aclu'].sample(frac=1).values\\n\\n\\n# Shuffle aclu and their corresponding peaks: ['aclu', 'long_LR_pf_peak_x', 'long_RL_pf_peak_x', 'short_LR_pf_peak_x', 'short_RL_pf_peak_x']\\npeak_column_names = [f'{a_decoder_name}_pf_peak_x' for a_decoder_name, a_aclu_peak_map in decoder_aclu_peak_map_dict.items()] # ['long_LR_pf_peak_x', 'long_RL_pf_peak_x', 'short_LR_pf_peak_x', 'short_RL_pf_peak_x']\\nshuffled_df.loc[mask, ['aclu','long_LR_pf_peak_x', 'long_RL_pf_peak_x', 'short_LR_pf_peak_x', 'short_RL_pf_peak_x']] = shuffled_df.loc[mask, ['aclu','long_LR_pf_peak_x', 'long_RL_pf_peak_x', 'short_LR_pf_peak_x', 'short_RL_pf_peak_x']].sample(frac=1).values\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '4d641689', 'metadata': {}, 'outputs': [], 'source': 'print_object_memory_usage(output_active_epoch_computed_values) # 0.946189 MB\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '3e3d1caf', 'metadata': {}, 'outputs': [], 'source': \"## #TODO 2023-12-13 02:07: - [ ] Figure out how 'Probe_Epoch_id' maps to `ripple_result_tuple.active_epochs`\\nripple_result_tuple.active_epochs\\nrank_order_results.LR_ripple.ranked_aclus_stats_dict\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '50f1bbbf', 'metadata': {}, 'outputs': [], 'source': '## Add the pf_x information for each aclu:\\n## 2023-10-11 - Get the long/short peak locations\\n# decoder_peak_coms_list = [a_decoder.pf.ratemap.peak_tuning_curve_center_of_masses[is_good_aclus] for a_decoder in decoder_args]\\ndecoder_aclu_peak_location_dict_list = [dict(zip(neuron_IDs, peak_locations)) for neuron_IDs, peak_locations in zip(track_templates.decoder_neuron_IDs_list, track_templates.decoder_peak_location_list)]\\ndecoder_aclu_peak_location_dict_list\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'de234ecb', 'metadata': {}, 'outputs': [], 'source': 'track_templates.long_LR_decoder.peak_locations'}, {'cell_type': 'code', 'execution_count': None, 'id': '4cc4b6e5', 'metadata': {}, 'outputs': [], 'source': 'track_templates.long_LR_decoder.peak_tuning_curve_center_of_masses'}, {'cell_type': 'code', 'execution_count': None, 'id': 'bc1305ed', 'metadata': {}, 'outputs': [], 'source': 'track_templates.decoder_LR_pf_peak_ranks_list'}, {'cell_type': 'code', 'execution_count': None, 'id': 'f7b179f8', 'metadata': {}, 'outputs': [], 'source': '## Replays:\\nglobal_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\\nif isinstance(global_replays, pd.DataFrame):\\n\\tglobal_replays = Epoch(global_replays.epochs.get_valid_df())\\n\\n# get the aligned epochs and the z-scores aligned to them:\\nactive_replay_epochs, (active_LR_ripple_long_z_score, active_RL_ripple_long_z_score, active_LR_ripple_short_z_score, active_RL_ripple_short_z_score) = rank_order_results.get_aligned_events(global_replays.to_dataframe().copy(), is_laps=False)\\nactive_replay_epochs'}, {'cell_type': 'code', 'execution_count': None, 'id': 'b6384a30', 'metadata': {}, 'outputs': [], 'source': '## Laps:\\nlong_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\\nglobal_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping()\\nactive_laps_epochs, (active_LR_ripple_long_z_score, active_RL_ripple_long_z_score, active_LR_ripple_short_z_score, active_RL_ripple_short_z_score) = rank_order_results.get_aligned_events(global_laps.to_dataframe(), is_laps=True)'}, {'cell_type': 'code', 'execution_count': None, 'id': '91e8ff66', 'metadata': {}, 'outputs': [], 'source': 'ripple_result_tuple.plot_histogram()'}, {'cell_type': 'code', 'execution_count': None, 'id': '7dfbe341', 'metadata': {}, 'outputs': [], 'source': '# Find only the significant events (|z| > 1.96):\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses\\n\\nfiltered_z_score_df, (n_events, n_significant_events, percent_significant_events) = RankOrderAnalyses.find_only_significant_events(rank_order_results, high_z_criteria=1.96)\\nfiltered_z_score_df'}, {'cell_type': 'code', 'execution_count': None, 'id': '19d6bcd9', 'metadata': {}, 'outputs': [], 'source': 'print(filtered_z_score_df.index.to_numpy())\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '86532662', 'metadata': {}, 'outputs': [], 'source': '# 2023-11-20 - Finding high-significance periods for Kamran:\\nz_threshold = 1.96\\nis_greater_than_z_threshold_long = (np.abs(ripple_result_tuple.long_best_dir_z_score_values) > z_threshold)\\nis_greater_than_z_threshold_short = (np.abs(ripple_result_tuple.short_best_dir_z_score_values) > z_threshold)\\nis_significant_either = np.logical_or(is_greater_than_z_threshold_long, is_greater_than_z_threshold_short)\\nis_significant_either\\n\\n# is_greater_than_3std_long = (np.abs(ripple_result_tuple.long_best_dir_z_score_values) >= 3.0)\\n# is_greater_than_3std_short = (np.abs(ripple_result_tuple.short_best_dir_z_score_values) >= 3.0)\\n# is_significant_either = np.logical_or(is_greater_than_3std_long, is_greater_than_3std_short)\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '5f925cde', 'metadata': {}, 'outputs': [], 'source': \"significant_ripple_epochs = deepcopy(Epoch(ripple_result_tuple.active_epochs)).boolean_indicies_slice(is_significant_either)\\n# significant_ripple_epochs = deepcopy(global_replays).boolean_indicies_slice(is_significant_either)\\nsignificant_ripple_epochs.to_dataframe()\\n\\n# significant_ripple_epochs.filename = Path(f'output/2023-11-27_SignificantReplayRipples').resolve()\\n# significant_ripple_epochs.to_neuroscope()\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '6a8beece', 'metadata': {}, 'outputs': [], 'source': '# active_epochs = ripple_result_tuple.active_epochs\\nactive_epochs: Epoch = rank_order_results.RL_ripple.epochs_df # Epoch(rank_order_results.RL_ripple.epochs_df)\\n# type(active_epochs)\\nactive_epochs.n_epochs\\n# rank_order_results.RL_ripple.spikes_df'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c93ffe0d', 'metadata': {}, 'outputs': [], 'source': 'rank_order_results.LR_ripple.epochs_df\\nrank_order_results.LR_ripple.spikes_df\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '39525572', 'metadata': {}, 'outputs': [], 'source': \"combined_variable_names: ['LR_Long_spearman', 'RL_Long_spearman', 'LR_Short_spearman', 'RL_Short_spearman', 'LR_Long_pearson', 'RL_Long_pearson', 'LR_Short_pearson', 'RL_Short_pearson']\\ncombined_variable_z_score_column_names: ['LR_Long_spearman_Z', 'RL_Long_spearman_Z', 'LR_Short_spearman_Z', 'RL_Short_spearman_Z', 'LR_Long_pearson_Z', 'RL_Long_pearson_Z', 'LR_Short_pearson_Z', 'RL_Short_pearson_Z']\"}, {'cell_type': 'code', 'execution_count': None, 'id': '17f47973', 'metadata': {}, 'outputs': [], 'source': \"curr_active_pipeline.build_display_context_for_filtered_session(filtered_session_name='maze_any', display_fn_name='test')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '6b319650', 'metadata': {}, 'outputs': [], 'source': 'rank_order_results.LR_ripple.selected_spikes_df'}, {'cell_type': 'code', 'execution_count': None, 'id': 'fef5436c', 'metadata': {}, 'outputs': [], 'source': 'rank_order_results.RL_ripple.selected_spikes_df'}, {'cell_type': 'markdown', 'id': '619ebf52', 'metadata': {}, 'source': '#### Iterates through the epochs (via the slider) and saves out the images:\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '53f73ed6', 'metadata': {}, 'outputs': [], 'source': \"export_path = Path(r'C:\\\\Users\\\\pho\\\\Desktop\\\\2023-12-19 Exports').resolve()\\nall_save_paths = _out_rank_order_event_raster_debugger.export_figure_all_slider_values(export_path=export_path)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '9a46e840', 'metadata': {}, 'outputs': [], 'source': '_out_rank_order_event_raster_debugger.active_epoch_IDX'}, {'cell_type': 'code', 'execution_count': None, 'id': '33d7d125', 'metadata': {}, 'outputs': [], 'source': '_out_rank_order_event_raster_debugger.active_epoch_result_df'}, {'cell_type': 'code', 'execution_count': None, 'id': '41d5bd28', 'metadata': {}, 'outputs': [], 'source': \"aclu_y_values_dict = {_active_plot_identifier:{int(aclu):new_sorted_raster.neuron_y_pos[aclu] for aclu in new_sorted_raster.neuron_IDs} for _active_plot_identifier, new_sorted_raster in _out_rank_order_event_raster_debugger.plots_data.seperate_new_sorted_rasters_dict.items()}\\naclu_max_y_values_dict = {_active_plot_identifier:np.max(list({int(aclu):new_sorted_raster.neuron_y_pos[aclu] for aclu in new_sorted_raster.neuron_IDs}.values())) for _active_plot_identifier, new_sorted_raster in _out_rank_order_event_raster_debugger.plots_data.seperate_new_sorted_rasters_dict.items()} # {'long_LR': 51.48039215686274, 'long_RL': 53.5, 'short_LR': 51.48039215686274, 'short_RL': 53.5}\\nglobal_max_y_value = np.max(list(aclu_max_y_values_dict.values()))\\nglobal_max_y_value\"}, {'cell_type': 'code', 'execution_count': None, 'id': '01518ab5', 'metadata': {}, 'outputs': [], 'source': 'max_n_neurons = np.max([len(v) for v in _out_rank_order_event_raster_debugger.plots_data.unsorted_original_neuron_IDs_lists])\\nmax_n_neurons'}, {'cell_type': 'code', 'execution_count': None, 'id': '277c056e', 'metadata': {}, 'outputs': [], 'source': \"_out_rank_order_event_raster_debugger.plots.all_separate_plots['long_LR']['root_plot']\\n\\n\\nroot_plots_dict\"}, {'cell_type': 'markdown', 'id': 'f1f2a9a6', 'metadata': {}, 'source': '#  Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '7cc87fb8', 'metadata': {}, 'outputs': [], 'source': 'curr_active_pipeline.prepare_for_display()'}, {'cell_type': 'code', 'execution_count': None, 'id': '82cc7400', 'metadata': {}, 'outputs': [], 'source': \"# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\\n# active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\\n\\n_out_graphics_dict = curr_active_pipeline.display('_display_spike_rasters_pyqtplot_2D', 'maze_any') # 'maze_any'\\nassert isinstance(_out_graphics_dict, dict)\\nactive_2d_plot, active_3d_plot, spike_raster_window = _out_graphics_dict['spike_raster_plt_2d'], _out_graphics_dict['spike_raster_plt_3d'], _out_graphics_dict['spike_raster_window']\"}, {'cell_type': 'code', 'execution_count': None, 'id': '5b39a1bb', 'metadata': {}, 'outputs': [], 'source': 'main_content_splitter: pg.QtWidgets.QSplitter = active_2d_plot.ui.main_content_splitter\\nmain_content_splitter'}, {'cell_type': 'code', 'execution_count': None, 'id': 'f6bfb57d', 'metadata': {}, 'outputs': [], 'source': 'dynamic_docked_widget_container: NestedDockAreaWidget = active_2d_plot.ui.dynamic_docked_widget_container\\ndynamic_docked_widget_container'}, {'cell_type': 'code', 'execution_count': None, 'id': 'fa584bab', 'metadata': {}, 'outputs': [], 'source': 'dynamic_docked_widget_container.parentWidget()'}, {'cell_type': 'code', 'execution_count': None, 'id': '51c9dae4', 'metadata': {}, 'outputs': [], 'source': '# active_2d_plot.disp\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '43aec411', 'metadata': {}, 'outputs': [], 'source': 'main_content_splitter.orientation() #(pg.Qt.Vertical)\\nmain_content_splitter.setOrientation(0)\\nmain_content_splitter.setStyleSheet(\"\"\"\\n    QSplitter::handle {\\n        background: rgb(255, 0, 4);\\n    }\\n    QSplitter::handle:horizontal {\\n        width: 15px;\\n    }\\n    QSplitter::handle:vertical {\\n        height: 15px;\\n    }\\n\"\"\")\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '3bae05bd', 'metadata': {}, 'outputs': [], 'source': 'main_content_splitter.setHandleWidth(10)\\nmain_content_splitter.setLineWidth(5)'}, {'cell_type': 'code', 'execution_count': None, 'id': 'd411e197', 'metadata': {}, 'outputs': [], 'source': 'active_2d_plot.enable_debug_print = True\\n# active_2d_plot.enable_debug_widgets = True\\n\\nactive_2d_plot.debug_print_spike_raster_timeline_alignments()'}, {'cell_type': 'code', 'execution_count': None, 'id': 'a3bd85d1', 'metadata': {}, 'outputs': [], 'source': '# active_2d_plot.find_matplotlib_render_plot_widget('}, {'cell_type': 'code', 'execution_count': None, 'id': 'efd6b290', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewPseudo2DDecodedEpochs_MatplotlibPlotCommand\\n\\nglobal_window_menus = active_2d_plot.window().ui.menus.global_window_menus #.window().rootWindow #.activeMenuReference\\n# active_2d_plot.rootWindow\\nactionPseudo2DDecodedEpochsDockedMatplotlibView = global_window_menus.docked_widgets.actions_dict['actionPseudo2DDecodedEpochsDockedMatplotlibView']\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'd7914f0f', 'metadata': {}, 'outputs': [], 'source': 'actionPseudo2DDecodedEpochsDockedMatplotlibView.activate(pg.QtGui.QAction.Trigger)'}, {'cell_type': 'code', 'execution_count': None, 'id': '0ccfa179', 'metadata': {}, 'outputs': [], 'source': 'DirectionalDecodersDecodedResult.validate_has_directional_decoded_continuous_epochs(curr_active_pipeline)'}, {'cell_type': 'code', 'execution_count': None, 'id': '53ffafed', 'metadata': {}, 'outputs': [], 'source': 'actionPseudo2DDecodedEpochsDockedMatplotlibView'}, {'cell_type': 'code', 'execution_count': None, 'id': '4a100cbd', 'metadata': {}, 'outputs': [], 'source': \"# print_keys_if_possible('menus', active_2d_plot.ui.menus, max_depth=3)\\n\\n# print_keys_if_possible('global_window_menus', global_window_menus, max_depth=4)\\n\\n## Document `add_renderables_menu`\\ndoc_printer = DocumentationFilePrinter(doc_output_parent_folder=doc_output_parent_folder, doc_name='global_window_menus')\\ndoc_printer.save_documentation('global_window_menus', global_window_menus, non_expanded_item_keys=['name'], max_depth=4)\\ndoc_printer\\n\\n\\n# menuDockedWidgets\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '0fc023ad', 'metadata': {}, 'outputs': [], 'source': 'activeMenuReference\\n'}, {'cell_type': 'markdown', 'id': '0592dc1f', 'metadata': {}, 'source': '### 📣 Programmatically adding several epoch rectangles by calling the addRenderable context menu functions all at once for SpikeRaster2D'}, {'cell_type': 'code', 'execution_count': None, 'id': 'd0ffa08b', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.EpochRenderingMixin import EpochRenderingMixin, RenderedEpochsItemsContainer\\n\\nadd_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\\nmenu_commands = ['AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.SessionEpochs']\\nfor a_command in menu_commands:\\n    add_renderables_menu[a_command].trigger()\\n    \\n# Setup the rendered intervals using a stacked layout:\\ninterval_info: Dict[str, Dict] = active_2d_plot.list_all_rendered_intervals()\\nrendered_interval_keys = list(interval_info.keys())\\ndesired_interval_height_ratios = [2.0, 2.0, 1.0, 0.1, 1.0, 1.0, 1.0] # ratio of heights to each interval\\nrequired_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout(desired_interval_height_ratios, epoch_render_stack_height=20.0, interval_stack_location='below')\\nstacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(rendered_interval_keys, required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\\nactive_2d_plot.update_rendered_intervals_visualization_properties(stacked_epoch_layout_dict)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '0cc778a5', 'metadata': {}, 'outputs': [], 'source': ''}, {'cell_type': 'code', 'execution_count': None, 'id': '45e5f0ab', 'metadata': {}, 'outputs': [], 'source': 'interval_info: Dict[str, Dict] = active_2d_plot.list_all_rendered_intervals()\\ninterval_info'}, {'cell_type': 'code', 'execution_count': None, 'id': '8cf7cf29', 'metadata': {}, 'outputs': [], 'source': \"type(interval_info['Laps']['background_static_scroll_window_plot'])\"}, {'cell_type': 'code', 'execution_count': None, 'id': '4cf8970f', 'metadata': {}, 'outputs': [], 'source': 'interval_datasources = active_2d_plot.interval_datasources # RenderPlotsData\\ninterval_datasources'}, {'cell_type': 'code', 'execution_count': None, 'id': 'cf418231', 'metadata': {}, 'outputs': [], 'source': 'add_renderables_menu[\"Clear\"][\\'all\\'][\\'Time\\'][\\'Intervals\\'].trigger()\\n# child_plots_removal_list\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '3b5a5f2f', 'metadata': {}, 'outputs': [], 'source': 'active_2d_plot.clear_all_rendered_intervals()'}, {'cell_type': 'code', 'execution_count': None, 'id': 'ad4fa097', 'metadata': {}, 'outputs': [], 'source': 'list(add_renderables_menu.keys()) # [\\'AddTimeIntervals\\', \\'AddTimeCurves\\', \\'AddMatplotlibPlot\\', \\'Clear\\']\\n\\n# print_keys_if_possible(\"add_renderables_menu\", add_renderables_menu, max_depth=5)\\n\\n# DocumentationFilePrinter\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'b0ab85db', 'metadata': {}, 'outputs': [], 'source': \"## Document `add_renderables_menu`\\ndoc_printer = DocumentationFilePrinter(doc_output_parent_folder=doc_output_parent_folder, doc_name='add_renderables_menu')\\ndoc_printer.save_documentation('add_renderables_menu', add_renderables_menu, non_expanded_item_keys=['_reverse_cellID_index_map'])\\ndoc_printer\"}, {'cell_type': 'code', 'execution_count': None, 'id': '2dd5be6c', 'metadata': {}, 'outputs': [], 'source': 'add_renderables_menu'}, {'cell_type': 'code', 'execution_count': None, 'id': 'eb1ef7b8', 'metadata': {}, 'outputs': [], 'source': 'spike_raster_window.show()'}, {'cell_type': 'markdown', 'id': 'cc724152', 'metadata': {}, 'source': '### Programmatically Get/Manuplate/Update Dock widgets:'}, {'cell_type': 'code', 'execution_count': None, 'id': 'acc5c4d8', 'metadata': {'tags': ['dockItem']}, 'outputs': [], 'source': '# active_2d_plot.clear_all_matplotlib_plots()\\nfrom pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, CustomCyclicColorsDockDisplayConfig\\nfrom pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\\nfrom pyphocorehelpers.gui.Qt.widget_positioning_helpers import WidgetGeometryInfo\\nfrom pyphoplacecellanalysis.External.pyqtgraph.dockarea.DockArea import DockArea\\nfrom pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig\\n\\ndynamic_docked_widget_container: NestedDockAreaWidget = active_2d_plot.ui.dynamic_docked_widget_container\\ndock_area: DockArea = dynamic_docked_widget_container.area\\ndynamic_docked_widget_container'}, {'cell_type': 'code', 'execution_count': None, 'id': 'a28c5d32', 'metadata': {}, 'outputs': [], 'source': '\\nan_info = WidgetGeometryInfo.init_from_widget(dynamic_docked_widget_container)\\na_size_policy: pg.QtWidgets.QSizePolicy = an_info.sizePolicy\\na_size_policy\\n# self.setSizePolicy(QtWidgets.QSizePolicy.Expanding,QtWidgets.QSizePolicy.Fixed)\\n# QtGui.QSizePolicy.Expanding, QtGui.QSizePolicy.Preferred\\na_size_policy.horizontalPolicy()\\na_size_policy.verticalPolicy()\\na_size_policy.horizontalStretch()\\na_size_policy.verticalStretch()\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e8d17a0d', 'metadata': {}, 'outputs': [], 'source': 'from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import print_widget_hierarchy\\n\\na_window = dynamic_docked_widget_container.window()\\nprint_widget_hierarchy(a_window)\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'dacd5033', 'metadata': {}, 'outputs': [], 'source': \"dynamic_docked_widget_container.setStyleSheet('background-color: rgb(54, 27, 81);')\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'e4145ebc', 'metadata': {}, 'outputs': [], 'source': 'dynamic_docked_widget_container.parentWidget() # Spike2DRaster\\ndynamic_docked_widget_container'}, {'cell_type': 'code', 'execution_count': None, 'id': '16db76fc', 'metadata': {}, 'outputs': [], 'source': 'dynamic_docked_widget_container.getContentsMargins()\\ndynamic_docked_widget_container.size()\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '262dc900', 'metadata': {}, 'outputs': [], 'source': '_dockitems_list: List[Dock] = dynamic_docked_widget_container.get_flat_dockitems_list() # [<Dock long_LR_ContinuousDecode (65, 200)>, <Dock long_RL_ContinuousDecode (65, 200)>, <Dock short_LR_ContinuousDecode (65, 200)>, <Dock short_RL_ContinuousDecode (65, 200)>]\\n_dockitems_list'}, {'cell_type': 'code', 'execution_count': None, 'id': '9ed58a7a', 'metadata': {}, 'outputs': [], 'source': '_dockitems_list: List[Dock] = dynamic_docked_widget_container.get_flat_dockitems_list()\\n_dockitems_names_list = [v.name() for v in _dockitems_list]\\n_widgets_list = dynamic_docked_widget_container.get_flat_widgets_list()\\nassert len(_dockitems_names_list) == len(_widgets_list), f\"lists must be equal!\"\\n_widgets_dict = dict(zip(_dockitems_names_list, _widgets_list))\\n_widgets_dict\\n\\n# _dockitems_names_list = [v.title() for v in _dockitems_list]\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '7e67782b', 'metadata': {}, 'outputs': [], 'source': '# dynamic_docked_widget_container.getContentsMargins()\\n# dynamic_docked_widget_container.geometry()\\na_layout = dynamic_docked_widget_container.layout()\\na_layout.getContentsMargins()\\na_layout.setContentsMargins(0,0,0,0)\\na_layout.verticalSpacing()\\na_layout.setVerticalSpacing(2)'}, {'cell_type': 'code', 'execution_count': None, 'id': '4127b469', 'metadata': {}, 'outputs': [], 'source': '# max_height = 65\\ngeometry_config_dict = {}\\nfor a_dockitem in _dockitems_list:\\n\\t# a_dockitem\\n\\t# a_dockitem.setMaximumHeight(max_height)\\n\\t# a_dockitem.maximumSize()\\n\\t# a_dockitem.minimumSize()\\n\\t# a_dockitem.baseSize()\\n\\t# a_dockitem.sizePolicy()\\n\\t# a_dockitem.geometry()\\n\\ta_geometry_config = WidgetGeometryInfo.init_from_widget(a_dockitem)\\n\\tgeometry_config_dict[a_dockitem.name()] = a_geometry_config\\n\\t# a_dockitem.setMinimumSize()\\n\\t\\ngeometry_config_dict'}, {'cell_type': 'code', 'execution_count': None, 'id': '09d1de8a', 'metadata': {}, 'outputs': [], 'source': \"dockitem_geometry = []\\nfor a_dockitem in _dockitems_list:\\n\\tprint(f'a_dockitem.name: {a_dockitem.name()}')\\n\\ta_dockitem.setMaximumHeight(35)\\n\\t# a_dockitem.getMaximumWidth()\\n\\t# a_dockitem.setMaximumSize()\\n\\t# geometry_config_dict[a_dockitem.name()].apply_to_widget(a_dockitem)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '9c75bc5e', 'metadata': {}, 'outputs': [], 'source': 'a_dockitem = _dockitems_list[0]\\na_dockitem'}, {'cell_type': 'code', 'execution_count': None, 'id': '3c8706eb', 'metadata': {}, 'outputs': [], 'source': 'a_dockitem.geometry() # PyQt5.QtCore.QRect(0, 0, 1835, 158)\\n# a_dockitem.saveGeometry()\\na_dockitem.getContentsMargins()'}, {'cell_type': 'code', 'execution_count': None, 'id': '00cc86ad', 'metadata': {}, 'outputs': [], 'source': 'a_dockitem.size() # PyQt5.QtCore.QSize(1835, 121)'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e2489a24', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.Pho2D.matplotlib.MatplotlibTimeSynchronizedWidget import MatplotlibTimeSynchronizedWidget\\n\\n\\na_key, a_widget = list(_widgets_dict.items())[0]\\n# a_key\\n# a_widget\\n# : MatplotlibTimeSynchronizedWidget\\na_fig = a_widget.getFigure() # this only seems to return the current viewport (the clipped window) not the entire plot\\n\\n\\noutput_path: Path = Path(\\'output\\').resolve()\\n\\nperiod_replacement_char: str = \\'➗\\'\\nfinal_fig_save_basename_path: str = f\"{a_key}\"\\nfilename_replaced: str = str(final_fig_save_basename_path).replace(\\'.\\', period_replacement_char)\\n\\ncurr_fig_output_path: Path = output_path.joinpath(filename_replaced).with_suffix(\\'.png\\').resolve()\\n\\nprint(F\\'curr_fig_output_path: {file_uri_from_path(curr_fig_output_path)}\\')\\na_fig.savefig(curr_fig_output_path, transparent=True)'}, {'cell_type': 'code', 'execution_count': None, 'id': '455612a3', 'metadata': {}, 'outputs': [], 'source': 'save_array_as_image'}, {'cell_type': 'code', 'execution_count': None, 'id': '31446769', 'metadata': {}, 'outputs': [], 'source': '\\n\\na_widget: MatplotlibTimeSynchronizedWidget = _widgets_list[0]\\na_widget.params.verticalScrollBarPolicy = pg.QtCore.Qt.ScrollBarPolicy.ScrollBarAsNeeded\\na_widget.params.horizontalScrollBarPolicy = pg.QtCore.Qt.ScrollBarPolicy.ScrollBarAsNeeded\\na_widget.params'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c8e8adca', 'metadata': {}, 'outputs': [], 'source': 'scrollAreaWidget = a_widget.ui.scrollAreaWidget\\nscrollAreaWidget.setVerticalScrollBarPolicy(pg.QtCore.Qt.ScrollBarPolicy.ScrollBarAsNeeded) #  Qt.ScrollBarAlwaysOn\\nscrollAreaWidget.setHorizontalScrollBarPolicy(pg.QtCore.Qt.ScrollBarPolicy.ScrollBarAsNeeded) # Qt.ScrollBarAlwaysOff\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c74be304', 'metadata': {}, 'outputs': [], 'source': '# a_widget.size() # PyQt5.QtCore.QSize(1835, 50)\\n# a_fig = a_widget.getFigure() # this only seems to return the current viewport (the clipped window) not the entire plot\\n# a_fig\\n\\n\\ndynamic_docked_widget_container\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '5d9adb33', 'metadata': {}, 'outputs': [], 'source': \"# 'output/test.png'\\na_fig.savefig('output/test.png', transparent=True)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '08a54dcd', 'metadata': {}, 'outputs': [], 'source': '# a_dockitem.resize\\na_dockitem.setMaximumHeight(50)\\na_dockitem.update()'}, {'cell_type': 'code', 'execution_count': None, 'id': '16fd5ca7', 'metadata': {}, 'outputs': [], 'source': 'a_widget.height() # 132\\na_widget.width() # 1835\\na_widget.setMaximumHeight(100)'}, {'cell_type': 'code', 'execution_count': None, 'id': 'f576f210', 'metadata': {}, 'outputs': [], 'source': 'a_widget.setMaximumHeight(50)'}, {'cell_type': 'code', 'execution_count': None, 'id': '65e277ce', 'metadata': {}, 'outputs': [], 'source': 'active_2d_plot.dock'}, {'cell_type': 'code', 'execution_count': None, 'id': '08fe1c5f', 'metadata': {}, 'outputs': [], 'source': 'dynamic_docked_widget_container'}, {'cell_type': 'code', 'execution_count': None, 'id': 'a3c300e1', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\\n\\n\\n## ✅ Add a new row for each of the four 1D directional decoders:\\nwidget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.add_new_matplotlib_render_plot_widget(row=2, col=0, name=\\'PhoManualTest\\')\\nan_ax = matplotlib_fig_axes[0]\\n\\n# all_directional_decoder_names = [\\'long_LR\\', \\'long_RL\\', \\'short_LR\\', \\'short_RL\\']\\n# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = dict(zip(all_directional_decoder_names, [deepcopy(long_LR_pf1D_Decoder), deepcopy(long_RL_pf1D_Decoder), deepcopy(short_LR_pf1D_Decoder), deepcopy(short_RL_pf1D_Decoder)]))\\n\\na_decoder_name: str = \"long_LR\"\\n\\n\\n_active_config_name = None\\nvariable_name: str = a_decoder_name\\nactive_decoder = deepcopy(all_directional_pf1D_Decoder_dict[a_decoder_name]) # computation_result.computed_data[\\'pf2D_Decoder\\']\\n# active_result = deepcopy(_out_continuously_decoded_dict[a_decoder_name]) # already decoded\\nactive_marginals = active_decoder.marginal.x\\nactive_bins = active_decoder.xbin\\n\\n# active_most_likely_positions = active_marginals.most_likely_positions_1D # Raw decoded positions\\nactive_most_likely_positions = None\\n\\nactive_posterior = active_marginals.p_x_given_n\\n\\n# most_likely_positions_mode: \\'standard\\'|\\'corrected\\'\\n# fig, curr_ax = curr_active_pipeline.display(\\'_display_plot_marginal_1D_most_likely_position_comparisons\\', _active_config_name, variable_name=\\'x\\', most_likely_positions_mode=\\'corrected\\', ax=an_ax) # ax=active_2d_plot.ui.matplotlib_view_widget.ax\\n ## Actual plotting portion:\\nfig, curr_ax = plot_1D_most_likely_position_comparsions(None, time_window_centers=active_decoder.time_window_centers, xbin=active_bins,\\n                                                        posterior=active_posterior,\\n                                                        active_most_likely_positions_1D=active_most_likely_positions,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tax=an_ax, variable_name=variable_name, debug_print=True, enable_flat_line_drawing=False)\\n\\n                                                        # **overriding_dict_with(lhs_dict={\\'ax\\':None, \\'variable_name\\':variable_name, \\'enable_flat_line_drawing\\':False, \\'debug_print\\': False}, **kwargs))\\n\\n# out_plot_tuple = plot_decoded_epoch_slices(active_filter_epochs, filter_epochs_decoder_result, global_pos_df=computation_result.sess.position.to_dataframe(), xbin=active_decoder.xbin, included_epoch_indicies=included_epoch_indicies,\\n# \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t**overriding_dict_with(lhs_dict={\\'name\\':default_figure_name, \\'debug_test_max_num_slices\\':256, \\'enable_flat_line_drawing\\':False, \\'debug_print\\': False}, **kwargs))\\n# params, plots_data, plots, ui = out_plot_tuple\\n\\n\\n# `self._curr_active_pipeline` -> `self._active_pipeline``\\n# print(f\\'\\\\t AddNewDecodedPosition_MatplotlibPlotCommand.execute(...) finished with the display call...\\')\\n# active_2d_plot.ui.matplotlib_view_widget.draw()\\nwidget.draw() # alternative to accessing through full path?\\nactive_2d_plot.sync_matplotlib_render_plot_widget(\\'PhoManualTest\\') # Sync it with the active window:'}, {'cell_type': 'code', 'execution_count': None, 'id': '6044e084', 'metadata': {}, 'outputs': [], 'source': 'active_result: DecodedFilterEpochsResult = deepcopy(pseudo2D_decoder_continuously_decoded_result) # already decoded\\nactive_result'}, {'cell_type': 'code', 'execution_count': None, 'id': '1074c09e', 'metadata': {}, 'outputs': [], 'source': 'assert len(active_result.p_x_given_n_list) == 1, f\"expected len(active_result.p_x_given_n_list)==1 but len(active_result.p_x_given_n_list): {len(active_result.p_x_given_n_list)}\"\\np_x_given_n = active_result.p_x_given_n_list[0]\\nmarginal_x = active_result.marginal_x_list[0]\\ntime_bin_container =  active_result.time_bin_containers[0]'}, {'cell_type': 'code', 'execution_count': None, 'id': '87316d5a', 'metadata': {}, 'outputs': [], 'source': 'time_window_centers = time_bin_container.centers'}, {'cell_type': 'code', 'execution_count': None, 'id': 'da49c5ce', 'metadata': {}, 'outputs': [], 'source': 'time_window_centers'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e47f0ee4', 'metadata': {}, 'outputs': [], 'source': 'marginal_x\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c92c9028', 'metadata': {}, 'outputs': [], 'source': \"## ✅ Add a row for the pseudo2D decoder `pseudo2D_decoder`:\\nwidget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.add_new_matplotlib_render_plot_widget(row=2, col=0, name='pseudo2D_decoder')\\nan_ax = matplotlib_fig_axes[0]\\n\\n# pseudo2D_decoder_continuously_decoded_result = pseudo2D_decoder.decode_specific_epochs(spikes_df=spikes_df, filter_epochs=single_global_epoch, decoding_time_bin_size=time_bin_size, debug_print=False)\\n_active_config_name = None\\nvariable_name: str = 'pseudo2D_decoder'\\nactive_decoder = deepcopy(pseudo2D_decoder) # computation_result.computed_data['pf2D_Decoder']\\nactive_result = deepcopy(pseudo2D_decoder_continuously_decoded_result) # already decoded\\n\\n# active_marginals = active_decoder.marginal.x\\nactive_marginals = deepcopy(marginal_x)\\nactive_bins = active_decoder.xbin\\n\\n# active_most_likely_positions = active_marginals.most_likely_positions_1D # Raw decoded positions\\nactive_most_likely_positions = None\\nactive_posterior = active_marginals.p_x_given_n\\n\\n# most_likely_positions_mode: 'standard'|'corrected'\\n# fig, curr_ax = curr_active_pipeline.display('_display_plot_marginal_1D_most_likely_position_comparisons', _active_config_name, variable_name='x', most_likely_positions_mode='corrected', ax=an_ax) # ax=active_2d_plot.ui.matplotlib_view_widget.ax\\n ## Actual plotting portion:\\nfig, curr_ax = plot_1D_most_likely_position_comparsions(None, time_window_centers=time_window_centers, xbin=active_bins,\\n                                                        posterior=active_posterior,\\n                                                        active_most_likely_positions_1D=active_most_likely_positions,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tax=an_ax, variable_name=variable_name, debug_print=True, enable_flat_line_drawing=False)\\n\\n\\nwidget.draw() # alternative to accessing through full path?\\nactive_2d_plot.sync_matplotlib_render_plot_widget('pseudo2D_decoder') # Sync it with the active window:\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'dd0402ef', 'metadata': {}, 'outputs': [], 'source': 'dynamic_docked_widget_container.add_display_dock'}, {'cell_type': 'code', 'execution_count': None, 'id': 'b7ce91d5', 'metadata': {}, 'outputs': [], 'source': \"## Build Dock Widgets:\\n# decoder_names_list = ('long_LR', 'long_RL', 'short_LR', 'short_RL')\\n_out_dock_widgets = {}\\ndock_configs = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'), (CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_LR_dock_colors, showCloseButton=False), CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_RL_dock_colors, showCloseButton=False),\\n\\t\\t\\t\\tCustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_LR_dock_colors, showCloseButton=False), CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_RL_dock_colors, showCloseButton=False))))\\n# dock_add_locations = (['left'], ['left'], ['right'], ['right'])\\ndock_add_locations = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'), (['right'], ['right'], ['right'], ['right'])))\\n\\nfor i, (a_decoder_name, a_heatmap) in enumerate(_out_pf1D_heatmaps.items()):\\n\\t_out_dock_widgets[a_decoder_name] = root_dockAreaWindow.add_display_dock(identifier=a_decoder_name, widget=a_heatmap[0], dockSize=(300,200), dockAddLocationOpts=dock_add_locations[a_decoder_name], display_config=dock_configs[a_decoder_name])\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '87cd89d6', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_additional_window_menus\\n\\n## Finally, add the display function to the active context\\nactive_identifying_context = global_epoch_context\\nactive_display_fn_identifying_ctx = active_identifying_context.adding_context('display_fn', display_fn_name='display_spike_rasters_window')\\nactive_display_fn_identifying_ctx_string = active_display_fn_identifying_ctx.get_description(separator='|') # Get final discription string:\\n\\ncomputation_result = deepcopy(curr_active_pipeline.computation_results[global_epoch_name])\\n\\n## Build the additional menus:\\noutput_references = _build_additional_window_menus(spike_raster_window, curr_active_pipeline, computation_result, active_display_fn_identifying_ctx)\\noutput_references\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'dc9bb66b', 'metadata': {}, 'outputs': [], 'source': 'output_references'}, {'cell_type': 'code', 'execution_count': None, 'id': '829ad15c', 'metadata': {}, 'outputs': [], 'source': 'active_2d_plot.ui.menus #.global_window_menus.docked_widgets'}, {'cell_type': 'code', 'execution_count': None, 'id': '87f1a335', 'metadata': {}, 'outputs': [], 'source': \"dockedWidgets_menuProvider = spike_raster_window.main_menu_window.ui.menus.global_window_menus.docked_widgets.menu_provider_obj\\nactions_dict = dockedWidgets_menuProvider.activeMenuReference.actions_dict #['actionMenuDockedWidgets']\\nactions_dict\\n# DockedWidgets_MenuProvider_actionsDict\"}, {'cell_type': 'code', 'execution_count': None, 'id': '5aa3dd2a', 'metadata': {}, 'outputs': [], 'source': \"\\nactions_dict['actionNewDockedMatplotlibView'].activate(pg.QtGui.QAction.Trigger)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'c05dbb46', 'metadata': {}, 'outputs': [], 'source': \"# actions_dict['actionAddDockedWidget'].activate(pg.QtGui.QAction.Trigger)\\nactions_dict['actionNewDockedContextNested'].activate(pg.QtGui.QAction.Trigger)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '99aa129f', 'metadata': {}, 'outputs': [], 'source': ''}, {'cell_type': 'code', 'execution_count': None, 'id': '7da8ba57', 'metadata': {}, 'outputs': [], 'source': ''}, {'cell_type': 'code', 'execution_count': None, 'id': 'bd6abb70', 'metadata': {}, 'outputs': [], 'source': '# spike_raster_window # Spike3DRasterWindowWidget\\nspike_raster_window.ui #.menus.global_window_menus.docked_widgets # <pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Uic_AUTOGEN_Spike3DRasterWindowBase.Ui_RootWidget at 0x199fc0c0490>\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '69746542', 'metadata': {}, 'outputs': [], 'source': 'active_3d_plot'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c55c976a', 'metadata': {}, 'outputs': [], 'source': 'active_2d_plot, active_3d_plot, spike_raster_window'}, {'cell_type': 'code', 'execution_count': None, 'id': '39840338', 'metadata': {}, 'outputs': [], 'source': 'active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e75eb376', 'metadata': {}, 'outputs': [], 'source': 'spike_raster_window'}, {'cell_type': 'code', 'execution_count': None, 'id': '10b7afeb', 'metadata': {}, 'outputs': [], 'source': \"spikes_window = spike_raster_window.spikes_window # SpikesDataframeWindow\\n\\nbottomPlaybackControlBarWidget = spike_raster_window.ui.bottomPlaybackControlBarWidget # Spike3DRasterBottomPlaybackControlBar \\n\\ndoubleSpinBox_ActiveWindowStartTime = bottomPlaybackControlBarWidget.ui.doubleSpinBox_ActiveWindowStartTime\\ndoubleSpinBox_ActiveWindowEndTime = bottomPlaybackControlBarWidget.ui.doubleSpinBox_ActiveWindowEndTime\\n\\n\\n# spikes_window.timeWindow.start\\n# spikes_window.active_window_start_time\\n# spikes_window.update_window_start_end(451.8908457518555, 451.9895490613999) ## Works but does not trigger refresh/update of the window. The changes are reflected as soon as you try to scroll at all though.\\n# spikes_window.active_window_end_time\\n\\nprint(f'spikes_window.active_window_start_time: {spikes_window.active_window_start_time}, spikes_window.active_window_end_time: {spikes_window.active_window_end_time}')\\n# need to block signals:\\n# doubleSpinBox_ActiveWindowStartTime.blockSignals(True)\\n# doubleSpinBox_ActiveWindowEndTime.blockSignals(True)\\ndoubleSpinBox_ActiveWindowStartTime.setValue(spikes_window.active_window_start_time)\\ndoubleSpinBox_ActiveWindowEndTime.setValue(spikes_window.active_window_end_time)\\n# doubleSpinBox_ActiveWindowStartTime.blockSignals(False) # unblock the signals when done\\n# doubleSpinBox_ActiveWindowEndTime.blockSignals(False)\\n\\n\\n# @pyqtExceptionPrintingSlot(float, float)\\ndef on_active_window_changed(start_t, end_t, _obj):\\n\\t# need to block signals:\\n\\t# doubleSpinBox_ActiveWindowStartTime.blockSignals(True)\\n\\t# doubleSpinBox_ActiveWindowEndTime.blockSignals(True)\\n\\tif start_t is not None:\\n\\t\\tdoubleSpinBox_ActiveWindowStartTime.setValue(start_t)\\n\\tif end_t is not None:\\n\\t\\tdoubleSpinBox_ActiveWindowEndTime.setValue(end_t)\\n\\t# doubleSpinBox_ActiveWindowStartTime.blockSignals(False) # unblock the signals when done\\n\\t# doubleSpinBox_ActiveWindowEndTime.blockSignals(False)\\n\\ncurr_window_ctrls_connection = spikes_window.windowed_data_window_updated_signal.connect(on_active_window_changed)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '113a3acd', 'metadata': {}, 'outputs': [], 'source': 'doubleSpinBox_ActiveWindowStartTime.setReadOnly(True)\\ndoubleSpinBox_ActiveWindowEndTime.setReadOnly(True)\\n\\nspikes_window.on_window_changed.connect('}, {'cell_type': 'code', 'execution_count': None, 'id': '8319e362', 'metadata': {}, 'outputs': [], 'source': 'doubleSpinBox_ActiveWindowStartTime.setVisible(False)\\nbottomPlaybackControlBarWidget.setVisible(False)'}, {'cell_type': 'code', 'execution_count': None, 'id': '01d043d6', 'metadata': {}, 'outputs': [], 'source': '# global_epoch_context\\ncurr_active_pipeline.reload_default_display_functions()\\n# curr_active_pipeline.prepare_for_display()\\ncurr_active_pipeline.clear_display_outputs()\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'bb657697', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_2d\\n# Complete Version:\\n# fig, axs, laps_pages = plot_lap_trajectories_2d(curr_active_pipeline.sess, curr_num_subplots=len(curr_active_pipeline.sess.laps.lap_id), active_page_index=0)\\n# Paginated Version:\\nfig, axs, laps_pages = plot_lap_trajectories_2d(curr_active_pipeline.sess, curr_num_subplots=22, active_page_index=0)\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'a2ed66e1', 'metadata': {}, 'outputs': [], 'source': 'fig, axs, laps_pages = plot_lap_trajectories_2d(curr_active_pipeline.sess, curr_num_subplots=22, active_page_index=1)'}, {'cell_type': 'code', 'execution_count': None, 'id': '2441e547', 'metadata': {}, 'outputs': [], 'source': '# Gets the existing SpikeRasterWindow or creates a new one if one doesn\\'t already exist:\\nfrom pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper\\nimport pyphoplacecellanalysis.External.pyqtgraph as pg # Used to get the app for TopLevelWindowHelper.top_level_windows\\n## For searching with `TopLevelWindowHelper.all_widgets(...)`:\\nfrom pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\\nfrom pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike3DRaster import Spike3DRaster\\nfrom pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\\n\\nfound_spike_raster_windows = TopLevelWindowHelper.all_widgets(pg.mkQApp(), searchType=Spike3DRasterWindowWidget)\\n\\nif len(found_spike_raster_windows) < 1:\\n\\t# no existing spike_raster_windows. Make a new one\\n\\tprint(f\\'no existing SpikeRasterWindow. Creating a new one.\\')\\n\\t# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\\n\\t# active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\\n\\n\\tactive_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\\n\\nelse:\\n\\tprint(f\\'found {len(found_spike_raster_windows)} existing Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...). Will use the most recent.\\')\\n\\t# assert len(found_spike_raster_windows) == 1, f\"found {len(found_spike_raster_windows)} Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...) but require exactly one.\"\\n\\t# Get the most recent existing one and reuse that:\\n\\tspike_raster_window = found_spike_raster_windows[0]\\n\\n\\n# Extras:\\nactive_2d_plot = spike_raster_window.spike_raster_plt_2d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\\nactive_3d_plot = spike_raster_window.spike_raster_plt_3d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\\nmain_graphics_layout_widget = active_2d_plot.ui.main_graphics_layout_widget # GraphicsLayoutWidget\\nmain_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\\nbackground_static_scroll_plot_widget = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem'}, {'cell_type': 'code', 'execution_count': None, 'id': '7c6338da', 'metadata': {}, 'outputs': [], 'source': 'spike_raster_window.isVisible() # False\\n# spike_raster_window.show()\\nspike_raster_window.close()'}, {'cell_type': 'code', 'execution_count': None, 'id': '0bafe4df', 'metadata': {}, 'outputs': [], 'source': 'spike_raster_window.connection_man.active_connections'}, {'cell_type': 'code', 'execution_count': None, 'id': '0a801d59', 'metadata': {}, 'outputs': [], 'source': 'found_any_window = TopLevelWindowHelper.top_level_windows(pg.mkQApp())\\nfound_any_window'}, {'cell_type': 'code', 'execution_count': None, 'id': '17d815bb', 'metadata': {}, 'outputs': [], 'source': '# print windows:\\n[print_widget_hierarchy(v) for k, v in found_any_window.items()]'}, {'cell_type': 'code', 'execution_count': None, 'id': '5c00e166', 'metadata': {}, 'outputs': [], 'source': '_display_out = curr_active_pipeline.last_added_display_output\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'b06ea13e', 'metadata': {}, 'outputs': [], 'source': \"ipspikesDataExplorer = _display_out['ipspikesDataExplorer']\\npActiveSpikesBehaviorPlotter = _display_out['plotter']\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '2c92cd2f', 'metadata': {}, 'outputs': [], 'source': ' = curr_active_pipeline.last_added_display_output\\n_display_out\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e02ac639', 'metadata': {}, 'outputs': [], 'source': \"ipspikesDataExplorer = self._display_output['ipspikesDataExplorer']\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'bd461fb3', 'metadata': {}, 'outputs': [], 'source': '### Adjusting Spike Emphasis:\\n#### Usage Examples:\\nfrom pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\\nfrom neuropy.core.neuron_identities import NeuronType\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'b1dd5449', 'metadata': {}, 'outputs': [], 'source': \"\\n## Example 1: De-emphasize spikes excluded from the placefield calculations:\\nis_spike_included_in_pf = np.isin(spike_raster_window.spike_raster_plt_2d.spikes_df.index, active_pf_2D.filtered_spikes_df.index)\\nspike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not(is_spike_included_in_pf), SpikeEmphasisState.Deemphasized)\\n\\n## Example 2: De-emphasize spikes that don't have their 'aclu' from a given set of indicies:\\nis_spike_included = spike_raster_window.spike_raster_plt_2d.spikes_df.aclu.to_numpy() == 2\\nspike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not(is_spike_included), SpikeEmphasisState.Deemphasized)\\n\\n## Example 3: De-emphasize all spikes \\nactive_2d_plot.update_spike_emphasis(new_emphasis_state=SpikeEmphasisState.Deemphasized)\\n\\n## Example 4: Hide all spikes entirely\\nactive_2d_plot.update_spike_emphasis(new_emphasis_state=SpikeEmphasisState.Hidden)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '98b9a61d', 'metadata': {}, 'outputs': [], 'source': \"## Setup: Hide all non-pyramidal spikes entirely\\nspikes_df = spike_raster_window.spikes_df\\nspike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not((spikes_df.neuron_type == NeuronType.from_string('pyr'))), SpikeEmphasisState.Hidden)\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'f3feb699', 'metadata': {}, 'outputs': [], 'source': 'spikes_window = spike_raster_window.spikes_window # SpikesDataframeWindow\\n# spikes_window.update_window_start_end(451.8908457518555, 451.9895490613999) ## Works but does not trigger refresh/update of the window. The changes are reflected as soon as you try to scroll at all though.\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '1ae85b4a', 'metadata': {}, 'outputs': [], 'source': '# 20*60.0 + 50.0 +  0.218 = 1250.218\\n\\nspikes_window.update_window_start_end(1250.218, (1250.218 + 3.0))\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '325548b0', 'metadata': {}, 'outputs': [], 'source': \"spikes_window.window_duration # Prints the current window's duration. The win. dur. label control in the left bar is not updated.\\n\\ndesired_window_fraction: float = 0.1 # 10% of the window is the default jump size\\nrelevant_jump_duration: float = spikes_window.window_duration * desired_window_fraction\\nrelevant_jump_duration\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '7bc81002', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.spikes_mixins import SpikeRenderingPyVistaMixin\\nfrom pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractivePlaceCellTuningCurvesDataExplorer import InteractivePlaceCellTuningCurvesDataExplorer\\n# from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractivePlaceCellTuningCurvesDataExplorer import InteractivePlaceCellTuningCurvesDataExplorer\\nfrom pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractivePlaceCellDataExplorer import InteractivePlaceCellDataExplorer\\n\\nfound_windows_of_type = TopLevelWindowHelper.all_widgets(pg.mkQApp(), searchType=InteractivePlaceCellDataExplorer)\\nfound_windows_of_type\\nTopLevelWindowHelper.top_level_windows(pg.mkQApp(), only_visible=True)'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e2abd93f', 'metadata': {}, 'outputs': [], 'source': '(451.8908457518555, 451.9895490613999)'}, {'cell_type': 'code', 'execution_count': None, 'id': '6c418968', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import BatchPhoJonathanFiguresHelper\\n\\nfig_1c_figures_out_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=True, disable_top_row=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\"}, {'cell_type': 'markdown', 'id': '2ea2f309', 'metadata': {}, 'source': '# PhoKamran2023Paper Results'}, {'cell_type': 'code', 'execution_count': None, 'id': '85a7dd8b', 'metadata': {}, 'outputs': [], 'source': \"pg.setConfigOptions(background='white', foreground='black') # black on white background (more traditional) color scheme\"}, {'cell_type': 'markdown', 'id': '162d813d', 'metadata': {}, 'source': '## Figure 1) pf1D Ratemaps, Active set, etc'}, {'cell_type': 'code', 'execution_count': None, 'id': '273696fc', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\\nfrom pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\\nfrom pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_1_add_replay_epoch_rasters\\n\\ncurr_active_pipeline.prepare_for_display()\\npf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics, fig_1c_figures_out_dict = PAPER_FIGURE_figure_1_full(curr_active_pipeline) # did not display the pf1'}, {'cell_type': 'code', 'execution_count': None, 'id': '84fa9acc', 'metadata': {}, 'outputs': [], 'source': \"# rdf = jonathan_firing_rate_analysis_result.rdf.rdf\\n# rdf\\n# ==================================================================================================================== #\\n# Fig 1c) 2023-07-14 - LxC and SxC PhoJonathanSession plots                                                            #\\n# ==================================================================================================================== #\\nfrom pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\\n\\n## Get global 'jonathan_firing_rate_analysis' results:\\ncurr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\\nneuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\\n\\nfig_1c_figures_out_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=True, disable_top_row=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\\n\"}, {'cell_type': 'markdown', 'id': '5cba3c7a', 'metadata': {}, 'source': \"## Figure 2) `PaperFigureTwo`: LxC/SxC Analyses\\nNote: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions.\"}, {'cell_type': 'code', 'execution_count': None, 'id': '97d3e1ff', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PaperFigureTwo\\n\\n_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # 10ms\\n_out_fig_2.compute(curr_active_pipeline=curr_active_pipeline)\\n_out_fig_2.display()'}, {'cell_type': 'markdown', 'id': '14a52142', 'metadata': {}, 'source': '## Figure 3) `PAPER_FIGURE_figure_3`: Firing Rate Index and Long/Short Firing Rate Replays v. Laps'}, {'cell_type': 'code', 'execution_count': None, 'id': '5f765ed6', 'metadata': {}, 'outputs': [], 'source': 'from neuropy.utils.matplotlib_helpers import FormattedFigureText\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _plot_long_short_firing_rate_indicies\\n# curr_active_pipeline.reload_default_display_functions()\\n\\n_out, _out2 = PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=True)'}, {'cell_type': 'markdown', 'id': 'a909c676', 'metadata': {}, 'source': '##  All Programmatic Plots'}, {'cell_type': 'code', 'execution_count': None, 'id': 'd6bcb738', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\\n\\nbatch_perform_all_plots(curr_active_pipeline, enable_neptune=False, neptuner=None)'}, {'cell_type': 'markdown', 'id': '54aa4837', 'metadata': {}, 'source': '# ❇️🆕 READY/NEXT: 2023-11-10 - All directional pf1D works for merging all four 1D templates!!'}, {'cell_type': 'code', 'execution_count': None, 'id': '76086ac5', 'metadata': {'notebookRunGroups': {'groupValue': '31'}}, 'outputs': [], 'source': 'from neuropy.analyses.placefields import PfND\\nfrom pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\\nfrom neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\\nfrom pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalMergedDecodersResult\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '84a6af1f', 'metadata': {}, 'outputs': [], 'source': '\\n\"\"\" \\n1. Builds a combined pseudo-2D decoder out of the four 1D directional decoders.\\n\\ty-bins (centers) of the pseduo-decoder are: {\\'long_LR\\': 0, \\'long_RL\\': 1, \\'short_LR\\': 2, \\'short_RL\\': 3}\\n\\n2. \\n\"\"\"\\n\\n# Use the four epochs to make to a pseudo-y:\\nall_directional_decoder_names = [\\'long_LR\\', \\'long_RL\\', \\'short_LR\\', \\'short_RL\\']\\nall_directional_decoder_dict = dict(zip(all_directional_decoder_names, [deepcopy(long_LR_pf1D), deepcopy(long_RL_pf1D), deepcopy(short_LR_pf1D), deepcopy(short_RL_pf1D)]))\\nall_directional_pf1D = PfND.build_merged_directional_placefields(all_directional_decoder_dict, debug_print=False)\\nall_directional_pf1D_Decoder = BasePositionDecoder(all_directional_pf1D, setup_on_init=True, post_load_on_init=True, debug_print=False)'}, {'cell_type': 'code', 'execution_count': None, 'id': '0ac7fcab', 'metadata': {'notebookRunGroups': {'groupValue': '3'}}, 'outputs': [], 'source': \"active_context = curr_active_pipeline.get_session_context()\\n\\ncollected_output_path = Path('output/collected_outputs').resolve()\\ncollected_output_path.mkdir(exist_ok=True)\\n\\n(laps_marginals_df, laps_out_path, laps_time_bin_marginals_df, laps_time_bin_marginals_out_path), (ripple_marginals_df, ripple_out_path, ripple_time_bin_marginals_df, ripple_time_bin_marginals_out_path) = directional_merged_decoders_result.compute_and_export_marginals_df_csvs(parent_output_path=collected_output_path, active_context=active_context)\\nfile_uri_from_path(laps_out_path)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '7f780ebc', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import plot_all_epoch_bins_marginal_predictions\\n\\n_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\\nglobal_epoch = curr_active_pipeline.filtered_epochs[global_epoch_name]\\nt_start, t_end = global_epoch.start_end_times\\nshort_epoch = curr_active_pipeline.filtered_epochs[short_epoch_name]\\nsplit_time_t: float = short_epoch.t_start\\nactive_context = curr_active_pipeline.sess.get_context()\\n\\n## Get the result after computation:\\ndirectional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\\n\\ncollector = plot_all_epoch_bins_marginal_predictions(directional_merged_decoders_result, t_start=t_start, t_split=split_time_t, t_end=t_end, active_context=active_context, perform_write_to_file_callback=None)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '223159f0', 'metadata': {}, 'outputs': [], 'source': '_display_directional_track_template_pf1Ds\\n\\n_display_directional_merged_pfs'}, {'cell_type': 'code', 'execution_count': None, 'id': 'cabd07bb', 'metadata': {}, 'outputs': [], 'source': \"## Document `DirectionalDecodersDecodedResult`\\ndirectional_decoders_decode_result: DirectionalDecodersDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\\ndoc_printer = DocumentationFilePrinter(doc_output_parent_folder=doc_output_parent_folder, doc_name='DirectionalDecodersDecodedResult')\\ndoc_printer.save_documentation('DirectionalDecodersDecodedResult', directional_decoders_decode_result, non_expanded_item_keys=['_reverse_cellID_index_map'])\"}, {'cell_type': 'code', 'execution_count': None, 'id': '325fb1f2', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalMergedDecodersResult\\n\\n# Fully unpack the `'DirectionalMergedDecoders'` result:\\ndirectional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\\n# directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\\n# directional_merged_decoders_result.all_directional_pf1D_Decoder\\n# directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\\n\\n\\nlaps_epochs_df = deepcopy(directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result.filter_epochs).to_dataframe()\\nlaps_directional_marginals_tuple = DirectionalMergedDecodersResult.determine_directional_likelihoods(directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result)\\nlaps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = laps_directional_marginals_tuple\\nlaps_track_identity_marginals = DirectionalMergedDecodersResult.determine_long_short_likelihoods(directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result)\\ntrack_identity_marginals, track_identity_all_epoch_bins_marginal, most_likely_track_identity_from_decoder, is_most_likely_track_identity_Long = laps_track_identity_marginals\\n\\n## Decode Ripples:\\nripple_epochs_df = deepcopy(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result.filter_epochs)\\nall_directional_ripple_filter_epochs_decoder_result: DecodedFilterEpochsResult = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\\nripple_marginals = DirectionalMergedDecodersResult.determine_directional_likelihoods(all_directional_ripple_filter_epochs_decoder_result)\\nripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir  = ripple_marginals\\nripple_track_identity_marginals = DirectionalMergedDecodersResult.determine_long_short_likelihoods(all_directional_ripple_filter_epochs_decoder_result)\\nripple_track_identity_marginals, ripple_track_identity_all_epoch_bins_marginal, ripple_most_likely_track_identity_from_decoder, ripple_is_most_likely_track_identity_Long = ripple_track_identity_marginals\\n\\n# directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\\n\\ndirectional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\\n\\n\\n# ripple_marginals = DirectionalMergedDecodersResult.determine_directional_likelihoods(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result)\\n# ripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir  = ripple_marginals\\n\\ntype(ripple_marginals)\\ntype(ripple_track_identity_marginals)\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'cf9c7178', 'metadata': {}, 'outputs': [], 'source': 'ripple_marginals'}, {'cell_type': 'code', 'execution_count': None, 'id': 'edaae3ad', 'metadata': {}, 'outputs': [], 'source': 'curr_active_pipeline.reload_default_display_functions()'}, {'cell_type': 'code', 'execution_count': None, 'id': '583b6bc9', 'metadata': {}, 'outputs': [], 'source': 'laps_all_epoch_bins_marginals_df = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\\nripple_all_epoch_bins_marginals_df = directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df'}, {'cell_type': 'code', 'execution_count': None, 'id': '71baf530', 'metadata': {}, 'outputs': [], 'source': \"# Interactive-mode parameters:\\n_interactive_mode_kwargs = dict(should_use_MatplotlibTimeSynchronizedWidget=True, scrollable_figure=True, defer_render=False)\\n_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\\n_curr_interaction_mode_kwargs = _interactive_mode_kwargs # interactive mode\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'cbc756e7', 'metadata': {}, 'outputs': [], 'source': \"# Non-interactive:\\n_non_interactive_mode_kwargs = dict(should_use_MatplotlibTimeSynchronizedWidget=False, scrollable_figure=False, defer_render=True)\\n_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=False, backend='AGG')\\n_curr_interaction_mode_kwargs = _non_interactive_mode_kwargs # non-interactive mode\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'a729bc28', 'metadata': {}, 'outputs': [], 'source': \"_out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs', curr_active_pipeline.get_session_context(),\\n\\tmax_num_lap_epochs = 240, max_num_ripple_epochs = 500,\\n\\trender_directional_marginal_laps=True, render_directional_marginal_ripples=True, render_track_identity_marginal_laps=True, render_track_identity_marginal_ripples=True,\\n\\t# render_directional_marginal_laps=True, render_directional_marginal_ripples=False, render_track_identity_marginal_laps=False, render_track_identity_marginal_ripples=False,\\n\\t# constrained_layout=True, # layout='none',\\n\\t# build_fn='basic_view', constrained_layout=True, \\n\\tbuild_fn='insets_view', constrained_layout=True, #constrained_layout=None, layout='none', # , constrained_layout=False constrained_layout=None, layout='none', # , constrained_layout=None, layout='none' extrodinarily fast\\n\\t**_curr_interaction_mode_kwargs, # interactive mode\\n\\tskip_plotting_measured_positions=True, skip_plotting_most_likely_positions=True, save_figure=True, \\n\\t# directional_merged_decoders_result=directional_merged_de?coders_result, # Custom `directional_merged_decoders_result` to use instead of the computed one.\\n\\t)\\ncollector = _out['collector']\"}, {'cell_type': 'code', 'execution_count': None, 'id': '880ed671', 'metadata': {}, 'outputs': [], 'source': '# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-display_dir_merged_pf_decoded_epochs.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\\n# Here\\n_out = curr_active_pipeline.display(\\'_display_directional_merged_pf_decoded_epochs\\', max_num_lap_epochs = 85, max_num_ripple_epochs = 120,\\n\\t# render_directional_marginal_laps=True, render_directional_marginal_ripples=True, render_track_identity_marginal_laps=True, render_track_identity_marginal_ripples=True,\\n\\trender_directional_marginal_laps=True, render_directional_marginal_ripples=False, render_track_identity_marginal_laps=False, render_track_identity_marginal_ripples=False,\\n\\t# constrained_layout=True, # layout=\\'none\\',\\n \\t# build_fn=\\'basic_view\\', constrained_layout=True,\\n\\tbuild_fn=\\'insets_view\\', constrained_layout=False, # constrained_layout=None, layout=\\'none\\', # , constrained_layout=None, layout=\\'none\\' extrodinarily fast\\n\\t**_curr_interaction_mode_kwargs, # interactive mode\\n\\tskip_plotting_measured_positions=True, skip_plotting_most_likely_positions=True, save_figure=True) # , size=(5,12), dpi=96 size=(15,7), dpi=72, constrained_layout=True\\ncollector = _out[\\'collector\\']\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e21b6cb2', 'metadata': {}, 'outputs': [], 'source': '(num=plots.figure_id, ncols=1, nrows=1, dpi=dpi, clear=True, sharex=False, sharey=False, constrained_layout=constrained_layout, frameon=False)'}, {'cell_type': 'code', 'execution_count': None, 'id': '8814f465', 'metadata': {}, 'outputs': [], 'source': \"collector = _out['collector']\\nlaps_plot_tuple = _out['directional_laps_plot_tuple']\\nparams, plots_data, plots, ui = laps_plot_tuple\\n# mw = ui.mw\"}, {'cell_type': 'code', 'execution_count': None, 'id': '00ae74df', 'metadata': {}, 'outputs': [], 'source': \"params.get('skip_plotting_most_likely_positions', False)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '0e218368', 'metadata': {}, 'outputs': [], 'source': 'collector.figures'}, {'cell_type': 'code', 'execution_count': None, 'id': '1338c5c0', 'metadata': {}, 'outputs': [], 'source': 'import matplotlib as mpl\\nimport matplotlib.pyplot as plt\\n# import seaborn as sns\\nfrom flexitext import flexitext ## flexitext for formatted matplotlib text\\n\\nfrom pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import FigureCollector\\nfrom pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import PlottingHelpers\\nfrom neuropy.utils.matplotlib_helpers import FormattedFigureText\\n\\nfig = mw.getFigure()\\nsub_context = collector.contexts[0]\\n\\n\\n# Recover the proper title:\\ntitle = mw.params.name\\n\\n# `flexitext` version:\\ntext_formatter = FormattedFigureText()\\nfig.suptitle(\\'\\')\\ntext_formatter.setup_margins(fig) # , top_margin=0.740\\ntitle_text_obj = flexitext(text_formatter.left_margin, text_formatter.top_margin, title, va=\"bottom\", xycoords=\"figure fraction\")\\nfooter_text_obj = flexitext((text_formatter.left_margin * 0.1), (text_formatter.bottom_margin * 0.25),\\n\\t\\t\\t\\t\\t\\t\\ttext_formatter._build_footer_string(active_context=sub_context),\\n\\t\\t\\t\\t\\t\\t\\tva=\"top\", xycoords=\"figure fraction\")'}, {'cell_type': 'code', 'execution_count': None, 'id': '6829fe6c', 'metadata': {}, 'outputs': [], 'source': \"active_display_context = curr_active_pipeline.build_display_context_for_session('directional_merged_pf_decoded_epochs')\\nactive_display_context\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'a7280e86', 'metadata': {}, 'outputs': [], 'source': \"# _main_context = [{'decoded_epochs': 'Laps', 'Marginal': 'Direction'}, {'decoded_epochs': 'Laps', 'Marginal': 'Direction'}, {'decoded_epochs': 'Laps', 'Marginal': 'Direction'}, {'decoded_epochs': 'Laps', 'Marginal': 'Direction'}]\\n\\n# Safe seperator characters\\nsafe_seperators_list = ['-','.','_'] # for dates I frequently use '2006-6-09_1-22-43' format, meaning both dashes and underscores are ruled out as info separators\\n\\n\\n'_'.join(['Laps', 'Direction'])\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '09d43925', 'metadata': {}, 'outputs': [], 'source': \"\\n_params_kwargs = {'t_bin_size': directional_merged_decoders_result.laps_decoding_time_bin_size} # Parameters:\\n\\n_merged_context = _main_context | _params_kwargs\\n_merged_context\\n\\n# {'decoded_epochs': 'Laps', 'Marginal': 'Direction', 't_bin_size': 0.075}\\n\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'c4b4ca02', 'metadata': {}, 'outputs': [], 'source': 'ripple_filter_epochs_decoder_result = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\\nripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\\nripple_decoding_time_bin_size\\nlaps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\\nlaps_decoding_time_bin_size\\n'}, {'cell_type': 'markdown', 'id': 'afaffae7', 'metadata': {}, 'source': '# 2024-01-06 - Decoded Epoch Posterior Marginal Figures outputs:\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e598e0ec', 'metadata': {}, 'outputs': [], 'source': \"\\nif active_context is not None:\\n\\tdisplay_context = active_context.adding_context('display_fn', display_fn_name='plot_rank_order_histograms')\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'b00267bb', 'metadata': {}, 'outputs': [], 'source': \"import seaborn as sns\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import plot_quantile_diffs\\n\\n_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\\nglobal_epoch = curr_active_pipeline.filtered_epochs[global_epoch_name]\\nshort_epoch = curr_active_pipeline.filtered_epochs[short_epoch_name]\\nsplit_time_t: float = short_epoch.t_start\\nactive_context = curr_active_pipeline.sess.get_context()\\n\\ndef _perform_write_to_file_callback(final_context, fig):\\n\\treturn curr_active_pipeline.output_figure(final_context, fig)\\n\\ncollector = plot_quantile_diffs(ripple_merged_complete_epoch_stats_df, t_split=split_time_t, active_context=active_context, perform_write_to_file_callback=_perform_write_to_file_callback)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '7bb65cf4', 'metadata': {}, 'outputs': [], 'source': \"curr_active_pipeline.display('_display_directional_merged_pfs')\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'd2a5da91', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\\n\\ndirectional_merged_decoders_result: DirectionalMergedDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\\n\\nlaps_filter_epochs_decoder_result = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\\nlaps_filter_epochs_decoder_result\\n\\nrender_merged_pseudo2D_decoder_laps=True\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'd4cfe1ca', 'metadata': {}, 'outputs': [], 'source': \"## Validate Laps:\\n# requires `laps_is_most_likely_direction_LR_dir` from `laps_marginals`\\nlong_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\\nglobal_session = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name]) # used for validate_lap_dir_estimations(...) \\nglobal_any_laps_epochs_obj = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computation_config.pf_params.computation_epochs) # global_epoch_name='maze_any'\\npercent_laps_estimated_correctly = DirectionalMergedDecodersResult.validate_lap_dir_estimations(global_session, active_global_laps_df=global_any_laps_epochs_obj.to_dataframe(), laps_is_most_likely_direction_LR_dir=laps_is_most_likely_direction_LR_dir)\\nprint(f'percent_laps_estimated_correctly: {percent_laps_estimated_correctly}')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '697b518c', 'metadata': {}, 'outputs': [], 'source': 'directional_marginals, directional_all_epoch_bins_marginal, most_likely_direction_from_decode, is_most_likely_direction_LR_dir = DirectionalMergedDecodersResult.determine_directional_likelihoods(directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result)\\n\\nlaps_track_identity_marginals = DirectionalMergedDecodersResult.determine_long_short_likelihoods(directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result)\\ntrack_identity_marginals, track_identity_all_epoch_bins_marginal, most_likely_track_identity_from_decoder, is_most_likely_track_identity_Long = laps_track_identity_marginals\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '7b76a725', 'metadata': {}, 'outputs': [], 'source': 'laps_filter_epochs_decoder_result = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\\n\\nall_directional_pf1D_Decoder_value'}, {'cell_type': 'code', 'execution_count': None, 'id': '5232cebf', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '0d95d551', 'metadata': {}, 'outputs': [], 'source': \"\\nactive_decoder = all_directional_pf1D_Decoder_value\\nlaps_plot_tuple = plot_decoded_epoch_slices(global_any_laps_epochs_obj, laps_filter_epochs_decoder_result, global_pos_df=global_session.position.to_dataframe(), xbin=active_decoder.xbin,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tname='TEST NEW LAPS',\\n                                            # active_marginal_fn = lambda filter_epochs_decoder_result: filter_epochs_decoder_result.marginal_y_list,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tactive_marginal_fn = lambda filter_epochs_decoder_result:  DirectionalMergedDecodersResult.build_custom_marginal_over_direction(filter_epochs_decoder_result),\\n                                            )\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'e42357ce', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices\\n\\nactive_decoder = all_directional_pf1D_Decoder_value\\nlaps_plot_tuple = plot_decoded_epoch_slices(global_any_laps_epochs_obj, laps_filter_epochs_decoder_result, global_pos_df=global_session.position.to_dataframe(), xbin=active_decoder.xbin,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tname='TEST NEW LAPS',\\n                                            # active_marginal_fn = lambda filter_epochs_decoder_result: filter_epochs_decoder_result.marginal_y_list,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tactive_marginal_fn = lambda filter_epochs_decoder_result:  DirectionalMergedDecodersResult.build_custom_marginal_over_direction(filter_epochs_decoder_result),\\n                                            )\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'de05349b', 'metadata': {}, 'outputs': [], 'source': \"owning_pipeline_reference = curr_active_pipeline\\n\\n# Direction (LR/RL) Marginal:\\nglobal_any_laps_epochs_obj = deepcopy(owning_pipeline_reference.computation_results[global_epoch_name].computation_config.pf_params.computation_epochs) # global_epoch_name='maze_any'\\nactive_decoder = directional_merged_decoders_result.all_directional_pf1D_Decoder\\ndirectional_laps_plot_tuple = plot_decoded_epoch_slices(global_any_laps_epochs_obj, directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result, global_pos_df=global_session.position.to_dataframe(), xbin=active_decoder.xbin,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tname='Directional_Marginal_LAPS',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tactive_marginal_fn = lambda filter_epochs_decoder_result: DirectionalMergedDecodersResult.build_custom_marginal_over_direction(filter_epochs_decoder_result),\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t# single_plot_fixed_height=single_plot_fixed_height, debug_test_max_num_slices=max_num_lap_epochs, size=size, dpi=dpi, constrained_layout=constrained_layout, scrollable_figure=scrollable_figure,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t)\\n\\n# Track-identity (Long/Short) Marginal:\\nglobal_any_laps_epochs_obj = deepcopy(owning_pipeline_reference.computation_results[global_epoch_name].computation_config.pf_params.computation_epochs) # global_epoch_name='maze_any'\\nactive_decoder = directional_merged_decoders_result.all_directional_pf1D_Decoder\\ntrack_identity_marginal_laps_plot_tuple = plot_decoded_epoch_slices(global_any_laps_epochs_obj, directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result, global_pos_df=global_session.position.to_dataframe(), xbin=active_decoder.xbin,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tname='TrackIdentity_Marginal_LAPS',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tactive_marginal_fn = lambda filter_epochs_decoder_result: DirectionalMergedDecodersResult.build_custom_marginal_over_long_short(filter_epochs_decoder_result),\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t# single_plot_fixed_height=single_plot_fixed_height, debug_test_max_num_slices=max_num_lap_epochs, size=size, dpi=dpi, constrained_layout=constrained_layout, scrollable_figure=scrollable_figure,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t)\\n\\n# Replays: ___________________________________________________________________________________________________________ #\\n\\n# Direction (LR/RL) Marginal:\\nglobal_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(global_session.replay))\\nactive_decoder = directional_merged_decoders_result.all_directional_pf1D_Decoder\\ndirectional_ripples_plot_tuple = plot_decoded_epoch_slices(global_replays,  directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result, global_pos_df=global_session.position.to_dataframe(), xbin=active_decoder.xbin,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tname='Directional_Marginal_Ripples',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tactive_marginal_fn = lambda filter_epochs_decoder_result: DirectionalMergedDecodersResult.build_custom_marginal_over_direction(filter_epochs_decoder_result),\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t# single_plot_fixed_height=single_plot_fixed_height, debug_test_max_num_slices=max_num_ripple_epochs, size=size, dpi=dpi, constrained_layout=constrained_layout, scrollable_figure=scrollable_figure,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t)\\n\\n# Track-identity (Long/Short) Marginal:\\nglobal_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(global_session.replay))\\nactive_decoder = directional_merged_decoders_result.all_directional_pf1D_Decoder\\ntrack_identity_marginal_ripples_plot_tuple = plot_decoded_epoch_slices(global_replays,  directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result, global_pos_df=global_session.position.to_dataframe(), xbin=active_decoder.xbin,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tname='TrackIdentity_Marginal_Ripples',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tactive_marginal_fn = lambda filter_epochs_decoder_result: DirectionalMergedDecodersResult.build_custom_marginal_over_long_short(filter_epochs_decoder_result),\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t# single_plot_fixed_height=single_plot_fixed_height, debug_test_max_num_slices=max_num_ripple_epochs, size=size, dpi=dpi, constrained_layout=constrained_layout, scrollable_figure=scrollable_figure,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'cc43280e', 'metadata': {}, 'outputs': [], 'source': \"\\n\\nglobal_any_laps_epochs_obj = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computation_config.pf_params.computation_epochs) # global_epoch_name='maze_any'\\nactive_decoder = directional_merged_decoders_result.all_directional_pf1D_Decoder\\nimplemented_laps_plot_tuple = plot_decoded_epoch_slices(global_any_laps_epochs_obj, directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result, global_pos_df=global_session.position.to_dataframe(), xbin=active_decoder.xbin,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tname='Directional_Marginal_LAPS',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tactive_marginal_fn = lambda filter_epochs_decoder_result: DirectionalMergedDecodersResult.build_custom_marginal_over_direction(filter_epochs_decoder_result),\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t# single_plot_fixed_height=single_plot_fixed_height, debug_test_max_num_slices=max_num_lap_epochs, size=size, dpi=dpi, constrained_layout=constrained_layout, scrollable_figure=scrollable_figure,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'a2670344', 'metadata': {}, 'outputs': [], 'source': \"active_decoder = all_directional_pf1D_Decoder_value\\nripples_plot_tuple = plot_decoded_epoch_slices(global_replays, all_directional_ripples_filter_epochs_decoder_result, global_pos_df=global_session.position.to_dataframe(), xbin=active_decoder.xbin,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tname='stacked_epoch_slices_matplotlib_subplots_Ripples',\\n                                            # active_marginal_fn = lambda filter_epochs_decoder_result: filter_epochs_decoder_result.marginal_y_list,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tactive_marginal_fn = lambda filter_epochs_decoder_result: build_custom_marginal_over_direction(filter_epochs_decoder_result),\\n                                            )\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '9fb0daf9', 'metadata': {}, 'outputs': [], 'source': \"\\n\\nactive_decoder = all_directional_pf1D_Decoder_value\\nlaps_plot_tuple = plot_decoded_epoch_slices(global_any_laps_epochs_obj, long_only_laps_filter_epochs_decoder_result, global_pos_df=global_session.position.to_dataframe(), xbin=active_decoder.xbin,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tname='long_only_lstacked_epoch_slices_matplotlib_subplots_LAPS',\\n                                            # active_marginal_fn = lambda filter_epochs_decoder_result: filter_epochs_decoder_result.marginal_y_list,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tactive_marginal_fn = lambda filter_epochs_decoder_result: build_custom_marginal_over_direction(filter_epochs_decoder_result),\\n                                            )\\n\\n\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '454fef46', 'metadata': {}, 'outputs': [], 'source': \"directional_merged_decoders_result = global_computation_results.computed_data['DirectionalMergedDecoders']\\n\\n# requires `laps_is_most_likely_direction_LR_dir` from `laps_marginals`\\nlong_epoch_name, short_epoch_name, global_epoch_name = owning_pipeline_reference.find_LongShortGlobal_epoch_names()\\nglobal_session = deepcopy(owning_pipeline_reference.filtered_sessions[global_epoch_name]) # used for validate_lap_dir_estimations(...) \\n\\n# Direction (LR/RL) Marginal:\\nglobal_any_laps_epochs_obj = deepcopy(owning_pipeline_reference.computation_results[global_epoch_name].computation_config.pf_params.computation_epochs) # global_epoch_name='maze_any'\\nactive_decoder = directional_merged_decoders_result.all_directional_pf1D_Decoder\\nlaps_plot_tuple = plot_decoded_epoch_slices(global_any_laps_epochs_obj, directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result, global_pos_df=global_session.position.to_dataframe(), xbin=active_decoder.xbin,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tname='stacked_epoch_slices_matplotlib_subplots_LAPS',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t# active_marginal_fn = lambda filter_epochs_decoder_result: filter_epochs_decoder_result.marginal_y_list,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tactive_marginal_fn = lambda filter_epochs_decoder_result: DirectionalMergedDecodersResult.build_custom_marginal_over_direction(filter_epochs_decoder_result),\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tdebug_test_max_num_slices=max_num_lap_epochs\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t)\\n\\n# Track-identity (Long/Short) Marginal:\\nglobal_any_laps_epochs_obj = deepcopy(owning_pipeline_reference.computation_results[global_epoch_name].computation_config.pf_params.computation_epochs) # global_epoch_name='maze_any'\\nactive_decoder = directional_merged_decoders_result.all_directional_pf1D_Decoder\\ntrack_identity_marginal_laps_plot_tuple = plot_decoded_epoch_slices(global_any_laps_epochs_obj, directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result, global_pos_df=global_session.position.to_dataframe(), xbin=active_decoder.xbin,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tname='TrackIdentity_Marginal_LAPS',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tactive_marginal_fn = lambda filter_epochs_decoder_result: DirectionalMergedDecodersResult.build_custom_marginal_over_long_short(filter_epochs_decoder_result),\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tdebug_test_max_num_slices=max_num_lap_epochs\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t)\\n\\n\\n\\n## Replays:\\nglobal_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(global_session.replay))\\nactive_decoder = directional_merged_decoders_result.all_directional_pf1D_Decoder\\nripples_plot_tuple = plot_decoded_epoch_slices(global_replays,  directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result, global_pos_df=global_session.position.to_dataframe(), xbin=active_decoder.xbin,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tname='stacked_epoch_slices_matplotlib_subplots_Ripples',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t# active_marginal_fn = lambda filter_epochs_decoder_result: filter_epochs_decoder_result.marginal_y_list,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tactive_marginal_fn = lambda filter_epochs_decoder_result: DirectionalMergedDecodersResult.build_custom_marginal_over_direction(filter_epochs_decoder_result),\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t)\\n\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '291de005', 'metadata': {}, 'outputs': [], 'source': '# Decode using long_directional_decoder\\nglobal_spikes_df, (odd_shuffle_helper, even_shuffle_helper) = RankOrderAnalyses.common_analysis_helper(curr_active_pipeline=curr_active_pipeline, num_shuffles=1000)\\nspikes_df = deepcopy(global_spikes_df) #.spikes.sliced_by_neuron_id(track_templates.shared_aclus_only_neuron_IDs)\\nglobal_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\\n# long_directional_decoding_result: DecodedFilterEpochsResult = long_directional_pf1D_Decoder.decode_specific_epochs(spikes_df, global_replays, decoding_time_bin_size=0.01)\\nall_directional_decoding_result: DecodedFilterEpochsResult = all_directional_pf1D_Decoder.decode_specific_epochs(spikes_df, global_replays, decoding_time_bin_size=0.01)'}, {'cell_type': 'code', 'execution_count': None, 'id': 'd50d6aab', 'metadata': {}, 'outputs': [], 'source': \"num_spikes = len(all_directional_pf1D.spikes_df)\\nprint(f'num_spikes: {num_spikes}')\\nnum_unique_spikes = len(all_directional_pf1D.spikes_df[['t_rel_seconds']].unique())\\nprint(f'num_unique_spikes: {num_unique_spikes}')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '678ff61e', 'metadata': {}, 'outputs': [], 'source': \"## Post 2022-10-22 display_all_pf_2D_pyqtgraph_binned_image_rendering-based method:\\n\\n# Visualization:\\nfrom pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap, visualize_heatmap_pyqtgraph\\nfrom pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array, display_all_pf_2D_pyqtgraph_binned_image_rendering\\nfrom pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\\n\\n# active_context = curr_active_pipeline.build_display_context_for_session(track_config='All-Directions', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')\\nactive_context = curr_active_pipeline.build_display_context_for_session(track_config='Long-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')\\nassert active_context is not None\\nactive_pf_2D = long_directional_pf1D_Decoder.pf # computation_result.computed_data['pf2D']\\n# active_pf_2D = all_directional_pf1D_Decoder.pf # computation_result.computed_data['pf2D']\\n# active_pf_2D = all_directions_merged_pf\\n# active_pf_2D = long_directional_manual_merged_pf\\n\\n# figure_format_config = {} # empty dict for config\\nfigure_format_config = {} # kwargs # kwargs as default figure_format_config\\nout_all_pf_2D_pyqtgraph_binned_image_fig = display_all_pf_2D_pyqtgraph_binned_image_rendering(active_pf_2D, figure_format_config) # output is BasicBinnedImageRenderingWindow\\n\\n# Set the window title from the context\\nout_all_pf_2D_pyqtgraph_binned_image_fig.setWindowTitle(f'{active_context.get_description()}')\\n\\nout_all_pf_2D_pyqtgraph_binned_image_fig.show()\"}, {'cell_type': 'code', 'execution_count': None, 'id': '43305707', 'metadata': {}, 'outputs': [], 'source': 'long_directional_pf1D_Decoder.ratemap.plot()'}, {'cell_type': 'markdown', 'id': 'b319bd93', 'metadata': {}, 'source': '# 🔶 2023-12-23 - All Plots - Final'}, {'cell_type': 'code', 'execution_count': None, 'id': '6121e192', 'metadata': {'notebookRunGroups': {'groupValue': '2'}}, 'outputs': [], 'source': 'from typing import Iterable\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalDisplayFunctions\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import plot_rank_order_histograms\\n\\ncurr_active_pipeline.reload_default_display_functions()\\ncurr_active_pipeline.prepare_for_display()\\n\\nsave_figure = True'}, {'cell_type': 'markdown', 'id': '590e9fec', 'metadata': {}, 'source': '## 2024-01-08 - Pulled from NonInteractiveProcessing to see plots easily.'}, {'cell_type': 'code', 'execution_count': None, 'id': '6a1c373e', 'metadata': {'notebookRunGroups': {'groupValue': '2'}}, 'outputs': [], 'source': '# _display_directional_merged_pf_decoded_epochs_marginals ________________________________________________________________________________ #\\ntry:\\n\\t_out = curr_active_pipeline.display(\\'_display_directional_merged_pf_decoded_epochs_marginals\\', curr_active_pipeline.get_session_context(), defer_render=True, save_figure=save_figure)\\nexcept Exception as e:\\n\\tprint(f\\'batch_extended_programmatic_figures(...): \"_display_directional_merged_pf_decoded_epochs_marginals\" failed with error: {e}\\\\n skipping.\\')\\n\\traise\\n\\n# # _display_rank_order_z_stats_results ________________________________________________________________________________ #\\n# try:\\n# \\t_out = curr_active_pipeline.display(\\'_display_rank_order_z_stats_results\\', curr_active_pipeline.get_session_context(), defer_render=True, save_figure=save_figure)\\n# except Exception as e:\\n# \\tprint(f\\'batch_extended_programmatic_figures(...): \"_display_rank_order_z_stats_results\" failed with error: {e}\\\\n skipping.\\')\\n# \\traise'}, {'cell_type': 'code', 'execution_count': None, 'id': 'dbbd04d8', 'metadata': {}, 'outputs': [], 'source': \"# from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow\\n\\n# curr_active_pipeline.reload_default_display_functions()\\n\\n# _out = curr_active_pipeline.display('_display_directional_track_template_pf1Ds', curr_active_pipeline.get_session_context(), defer_render=False, save_figure=save_figure)\\n\\n_out = curr_active_pipeline.display('_display_directional_merged_pfs', curr_active_pipeline.get_session_context(), defer_render=False, save_figure=save_figure)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'bba1bc7f', 'metadata': {}, 'outputs': [], 'source': 'all_dir_outputs = list(_out.values())[0] # BasicBinnedImageRenderingWindow \\n# list(all_dir_outputs.keys())\\nnames_list = [v for v in list(all_dir_outputs.plots.keys()) if v not in (\\'name\\', \\'context\\')]\\nnames_list\\n\\nout_figs_dict = {}\\n# active_context = curr_active_pipeline.build_display_context_for_session(display_fn_name=\\'directional_merged_pfs\\')\\n# for a_name, a_plot in all_dir_outputs.plots.items():\\nfor a_name in names_list:\\n\\t# Adjust the size of the text for the item by passing formatted text\\n\\ta_plot: pg.PlotItem = all_dir_outputs.plots[a_name].mainPlotItem # PlotItem \\n\\t# if (a_plot is not None) and (not isinstance(a_plot, str)):\\n\\t# a_plot.setTitle(f\"<span style = \\'font-size : 12px;\\' >{a_name}</span>\")\\n\\t# a_plo\\n\\t# active_context , epochs=\\'replays\\', decoder=\\'long_results_obj\\'\\t\\n\\tfinal_context = curr_active_pipeline.build_display_context_for_session(display_fn_name=\\'directional_merged_pfs\\', track_config=\\'All-Directions\\', cell=a_name)\\n\\tout_figs_dict[a_name] = curr_active_pipeline.output_figure(final_context, a_plot.getViewBox())\\n\\t\\n\\n# list(out_figs_dict.values())[0][0][0]\\nout_figs_paths = [v[0][0] for v in list(out_figs_dict.values())]\\nout_figs_paths'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c41b63b5', 'metadata': {}, 'outputs': [], 'source': \"# Take the individual cell's pf export figures and composite them into a single stack\\n\\nfrom PIL import Image\\nfrom pyphocorehelpers.plotting.filesystem_figure_operations import render_image_stack\\n\\noutput_img, output_path = render_image_stack(out_figs_paths, offset=55, single_image_alpha_level=0.85)\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'f47f2f5d', 'metadata': {}, 'outputs': [], 'source': 'output_img'}, {'cell_type': 'code', 'execution_count': None, 'id': 'abc9d74d', 'metadata': {}, 'outputs': [], 'source': \"final_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='directional_merged_pfs', track_config='All-Directions', cell=a_name)\\ncurr_active_pipeline.output_figure(final_context, a_plot.getViewBox(), write_vector_format=True, write_png=True)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '57dedb98', 'metadata': {}, 'outputs': [], 'source': '# final_context\\n\\ncurr_active_pipeline.get_output_path()'}, {'cell_type': 'code', 'execution_count': None, 'id': '0ef7dd06', 'metadata': {}, 'outputs': [], 'source': 'a_plot.titleLabel.setContentsMargins(50, 0, 0, 0)\\na_plot.titleLabel.\\n\\nfor i in range(4):\\n\\ta_plot.layout.setRowPreferredHeight(i, 0)\\n\\ta_plot.layout.setRowMinimumHeight(i, 0)\\n\\ta_plot.layout.setRowSpacing(i, 0)\\n\\ta_plot.layout.setRowStretchFactor(i, 1)\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'a96a165e', 'metadata': {}, 'outputs': [], 'source': 'a_plot.layout.setRowMinimumHeight(0, 500) # idk...\\na_plot.layout.setRowPreferredHeight(1, 0) # nothing\\na_plot.layout.setRowPreferredHeight(2, 30) # the plot item\\na_plot.layout.setRowPreferredHeight(3, 0) \\na_plot.layout.setRowPreferredHeight(4, 0)'}, {'cell_type': 'code', 'execution_count': None, 'id': '9c1ca405', 'metadata': {}, 'outputs': [], 'source': '# no clue why 2 is a good value for this...\\na_plot.titleLabel.setMaximumHeight(2)\\na_plot.layout.setRowFixedHeight(0, 2)\\n\\n## Could be the plot item size that should be changed?\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'dc6d78c1', 'metadata': {}, 'outputs': [], 'source': \"# this gets rid of the annoying white bounding box in the ViewBox of the plot\\n# a_plot.hideAxis('left') # Hide left border\\na_plot.hideAxis('right') # Hide right border\\n# a_plot.hideAxis('top') # Hide top border\\na_plot.hideAxis('bottom') # Hide bottom border\\n\\na_plot.showAxes('left')\\na_plot.showAxes('top')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '91970a33', 'metadata': {}, 'outputs': [], 'source': \"vb: pg.ViewBox = a_plot.getViewBox()\\n# vb.background = pg.mkColor('red')\\n# vb.border\\n# vb.setBorder(None)\\nvb.setBackgroundColor(pg.mkColor('red')) # works\\nvb.setBackgroundColor(None)\\nvb.setBorder(pg.mkPen('blue'))\\n# vb.setXRange(\\nvb.setYRange(0, 0.2, 0.0, update=True)\"}, {'cell_type': 'markdown', 'id': '828a2288', 'metadata': {}, 'source': '# 2024-01-23 - DirectionalMergedDecodersResult Experimentation'}, {'cell_type': 'code', 'execution_count': None, 'id': '5834c657', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalMergedDecodersResult\\n\\ndirectional_merged_decoders_result: DirectionalMergedDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\\nlaps_filter_epochs_decoder_result: DecodedFilterEpochsResult = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\\n\\n\\nlaps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.laps_directional_marginals_tuple\\n# laps_directional_marginals # a list just like `laps_filter_epochs_decoder_result.p_x_given_n_list`   # .shape (2, n_curr_epoch_time_bins) - (2, 120)\\nlaps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = directional_merged_decoders_result.laps_track_identity_marginals_tuple\\n\\n# .shape: (n_x_bins, 4, n_curr_epoch_time_bins) - (63, 4, 120)\\n# laps_directional_marginals\\nraw_posterior_laps_marginals = DirectionalMergedDecodersResult.build_non_marginalized_raw_posteriors(laps_filter_epochs_decoder_result)\\nraw_posterior_laps_marginals\"}, {'cell_type': 'code', 'execution_count': None, 'id': '2438b1d8', 'metadata': {}, 'outputs': [], 'source': 'laps_most_likely_direction_from_decoder'}, {'cell_type': 'code', 'execution_count': None, 'id': '2cf31210', 'metadata': {}, 'outputs': [], 'source': \"\\nepoch_id = 0\\na_raw_posterior_marginal_p_x_given_n = raw_posterior_laps_marginals[epoch_id]['p_x_given_n'] # .shape: (4, n_curr_epoch_time_bins) - (63, 4, 120)\\nprint(f'a_raw_posterior_marginal_p_x_given_n: {np.shape(a_raw_posterior_marginal_p_x_given_n)}') # .shape: (4, n_curr_epoch_time_bins) - (4, 120)\\n# a_raw_posterior_marginal_p_x_given_n\\n\\n\\nepoch_id = 0\\na_marginal_dir_p_x_given_n = laps_directional_marginals[epoch_id]['p_x_given_n'] # .shape: (n_x_bins, 4, n_curr_epoch_time_bins) - (63, 4, 120)\\nprint(f'a_marginal_dir_p_x_given_n: {np.shape(a_marginal_dir_p_x_given_n)}') # .shape: (2, n_curr_epoch_time_bins) - (2, 120)\\n# a_marginal_dir_p_x_given_n\\na_p_x_given_n = laps_filter_epochs_decoder_result.p_x_given_n_list[epoch_id] # .shape: (n_x_bins, 4, n_curr_epoch_time_bins) - (63, 4, 120)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '13800650', 'metadata': {}, 'outputs': [], 'source': 'import numpy as np\\nimport matplotlib.pyplot as plt\\nfrom PIL import Image\\nfrom pyphocorehelpers.plotting.media_output_helpers import save_array_as_image\\n\\n## Outputs the three decoded posteriors from the marginal decoders\\nparent_array_as_image_output_folder: Path = Path(f\\'output/array_as_image\\').resolve()\\nparent_array_as_image_output_folder.mkdir(exist_ok=True)\\nparent_array_as_image_output_folder: Path = parent_array_as_image_output_folder.joinpath(f\"{curr_active_pipeline.get_session_context()}\").resolve()\\nparent_array_as_image_output_folder.mkdir(exist_ok=True)\\n\\nfile_uri_from_path(parent_array_as_image_output_folder)'}, {'cell_type': 'code', 'execution_count': None, 'id': '2af77259', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalMergedDecodersResult\\n\\n# f\"{curr_active_pipeline.get_session_context()}\"\\n# curr_active_pipeline.session_name\\ndirectional_merged_decoders_result.laps_time_bin_marginals_df\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c58c46d1', 'metadata': {}, 'outputs': [], 'source': '(laps_marginals_df, laps_out_path, laps_time_bin_marginals_df, laps_time_bin_marginals_out_path), (ripple_marginals_df, ripple_out_path, ripple_time_bin_marginals_df, ripple_time_bin_marginals_out_path) = directional_merged_decoders_result.compute_and_export_marginals_df_csvs(parent_output_path=parent_array_as_image_output_folder, active_context=curr_active_pipeline.get_session_context())\\nlaps_marginals_df'}, {'cell_type': 'markdown', 'id': '2c9e04e7', 'metadata': {}, 'source': '# TODO: 2024-01-23 - Writes the posteriors out to file '}, {'cell_type': 'code', 'execution_count': None, 'id': '78cb2e92', 'metadata': {}, 'outputs': [], 'source': '\\nepoch_id: int = 3\\nepoch_id_identifier_str: str = \\'lap\\'\\nepoch_id_str = f\"{epoch_id_identifier_str}[{epoch_id}]\"\\n\\n_img_path = parent_array_as_image_output_folder.joinpath(f\\'{epoch_id_str}_marginal_track_identity_point.png\\').resolve()\\nimg_data = np.atleast_2d(collapsed_per_lap_epoch_marginal_track_identity_point[epoch_id,:]).T\\nmarginal_dir_tuple = save_array_as_image(img_data, desired_height=50, desired_width=None, skip_img_normalization=True, out_path=_img_path)\\n\\n_img_path = parent_array_as_image_output_folder.joinpath(f\\'{epoch_id_str}_marginal_dir_point.png\\').resolve()\\nimg_data = np.atleast_2d(collapsed_per_lap_epoch_marginal_dir_point[epoch_id,:]).T\\nmarginal_dir_tuple = save_array_as_image(img_data, desired_height=50, desired_width=None, skip_img_normalization=True, out_path=_img_path)\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '9585a85a', 'metadata': {}, 'outputs': [], 'source': 'def save_posterior(raw_posterior_laps_marginals, laps_directional_marginals, laps_track_identity_marginals, collapsed_per_lap_epoch_marginal_dir_point, collapsed_per_lap_epoch_marginal_track_identity_point, parent_array_as_image_output_folder: Path, epoch_id_identifier_str: str = \\'lap\\', epoch_id: int = 9):\\n\\t\"\"\" 2024-01-23 - Writes the posteriors out to file \\n\\t\\n\\t\"\"\"\\n\\tassert parent_array_as_image_output_folder.exists()\\n\\t\\n\\tepoch_id_str = f\"{epoch_id_identifier_str}[{epoch_id}]\"\\n\\t_img_path = parent_array_as_image_output_folder.joinpath(f\\'{epoch_id_str}_raw_marginal.png\\').resolve()\\n\\timg_data = raw_posterior_laps_marginals[epoch_id][\\'p_x_given_n\\'].astype(float)  # .shape: (4, n_curr_epoch_time_bins) - (63, 4, 120)\\n\\traw_tuple = save_array_as_image(img_data, desired_height=100, desired_width=None, skip_img_normalization=True, out_path=_img_path)\\n\\t# image_raw, path_raw = raw_tuple\\n\\n\\t_img_path = parent_array_as_image_output_folder.joinpath(f\\'{epoch_id_str}_marginal_dir.png\\').resolve()\\n\\timg_data = laps_directional_marginals[epoch_id][\\'p_x_given_n\\'].astype(float)\\n\\tmarginal_dir_tuple = save_array_as_image(img_data, desired_height=50, desired_width=None, skip_img_normalization=True, out_path=_img_path)\\n\\t# image_marginal_dir, path_marginal_dir = marginal_dir_tuple\\n\\n\\t_img_path = parent_array_as_image_output_folder.joinpath(f\\'{epoch_id_str}_marginal_track_identity.png\\').resolve()\\n\\timg_data = laps_track_identity_marginals[epoch_id][\\'p_x_given_n\\'].astype(float)\\n\\tmarginal_track_identity_tuple = save_array_as_image(img_data, desired_height=50, desired_width=None, skip_img_normalization=True, out_path=_img_path)\\n\\t# image_marginal_track_identity, path_marginal_track_identity = marginal_track_identity_tuple\\n\\n\\n\\t_img_path = parent_array_as_image_output_folder.joinpath(f\\'{epoch_id_str}_marginal_track_identity_point.png\\').resolve()\\n\\timg_data = np.atleast_2d(collapsed_per_lap_epoch_marginal_track_identity_point[epoch_id,:]).T\\n\\tmarginal_dir_point_tuple = save_array_as_image(img_data, desired_height=50, desired_width=None, skip_img_normalization=True, out_path=_img_path)\\n\\n\\t_img_path = parent_array_as_image_output_folder.joinpath(f\\'{epoch_id_str}_marginal_dir_point.png\\').resolve()\\n\\timg_data = np.atleast_2d(collapsed_per_lap_epoch_marginal_dir_point[epoch_id,:]).T\\n\\tmarginal_track_identity_point_tuple = save_array_as_image(img_data, desired_height=50, desired_width=None, skip_img_normalization=True, out_path=_img_path)\\n\\n\\n\\treturn raw_tuple, marginal_dir_tuple, marginal_track_identity_tuple, marginal_dir_point_tuple, marginal_track_identity_point_tuple\\n\\t\\n\\n\\ncollapsed_per_lap_epoch_marginal_track_identity_point = laps_marginals_df[[\\'P_Long\\', \\'P_Short\\']].to_numpy().astype(float)\\ncollapsed_per_lap_epoch_marginal_dir_point = laps_marginals_df[[\\'P_LR\\', \\'P_RL\\']].to_numpy().astype(float)\\n\\nfor epoch_id in np.arange(laps_filter_epochs_decoder_result.num_filter_epochs):\\n\\traw_tuple, marginal_dir_tuple, marginal_track_identity_tuple, marginal_dir_point_tuple, marginal_track_identity_point_tuple = save_posterior(raw_posterior_laps_marginals, laps_directional_marginals, laps_track_identity_marginals, collapsed_per_lap_epoch_marginal_dir_point, collapsed_per_lap_epoch_marginal_track_identity_point,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t    parent_array_as_image_output_folder=parent_array_as_image_output_folder, epoch_id_identifier_str=\\'lap\\', epoch_id=epoch_id)'}, {'cell_type': 'code', 'execution_count': None, 'id': '808816e8', 'metadata': {}, 'outputs': [], 'source': ''}, {'cell_type': 'code', 'execution_count': None, 'id': '629b20d5', 'metadata': {}, 'outputs': [], 'source': \"import napari\\n\\n# img_data = a_p_x_given_n.astype(float).transpose(2, 0, 1)\\n# img_data = a_p_x_given_n.astype(float)\\nimg_data = a_marginal_dir_p_x_given_n.astype(float)\\n# img_data = a_raw_posterior_marginal_p_x_given_n.astype(float)\\n\\nprint(f'np.shape(img_data): {np.shape(img_data)}')\\n# out = napari.gui_qt()\\n# viewer = napari.view_image(data.astronaut(), rgb=True)\\nviewer = napari.view_image(img_data) # rgb=True\\n\\nviewer\"}, {'cell_type': 'code', 'execution_count': None, 'id': '2dad6729', 'metadata': {}, 'outputs': [], 'source': \"if 'snapshot_occupancy_weighted_tuning_maps' not in active_relative_entropy_results:\\n\\tactive_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] = np.stack([placefield_snapshot.occupancy_weighted_tuning_maps_matrix for placefield_snapshot in active_relative_entropy_results['historical_snapshots'].values()])\\n\\n\\nimage_layer_dict = {}\\nlayer_properties_dict = {\\n\\t'snapshot_occupancy_weighted_tuning_maps': dict(blending='additive', colormap='viridis', name='pf1D_dt'),\\n#  'flat_jensen_shannon_distance_results': dict(blending='additive', colormap='gray'),\\n\\t'long_short_rel_entr_curves_frames': dict(blending='additive', colormap='bop blue'),\\n\\t'short_long_rel_entr_curves_frames': dict(blending='additive', colormap='red'),\\n\\t\\n}\\n\\nfor a_name, layer_properties in layer_properties_dict.items():\\n\\t# image_layer_dict[a_name] = viewer.add_image(active_relative_entropy_results_xr_dict[a_name].to_numpy().astype(float), name=a_name)\\n\\timage_layer_dict[a_name] = viewer.add_image(active_relative_entropy_results[a_name].astype(float), **(dict(name=a_name)|layer_properties))\\n\\nassert viewer.dims.ndim == 3\\n## Set the dimensions appropriately\\nviewer.dims.axis_labels = ('t', 'neuron_id', 'xbin')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '55c527c6', 'metadata': {'tags': ['figure', 'marginal', 'active']}, 'outputs': [], 'source': '# _display_directional_merged_pf_decoded_epochs ______________________________________________________________________ #\\ntry:\\n\\t# Interactive-mode parameters:\\n\\t_interactive_mode_kwargs = dict(should_use_MatplotlibTimeSynchronizedWidget=True, scrollable_figure=True, defer_render=False)\\n\\t_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend=\\'Qt5Agg\\')\\n\\t_curr_interaction_mode_kwargs = _interactive_mode_kwargs # interactive mode\\n\\n\\t# Non-interactive:\\n\\t# _non_interactive_mode_kwargs = dict(should_use_MatplotlibTimeSynchronizedWidget=False, scrollable_figure=False, defer_render=True)\\n\\t# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=False, backend=\\'AGG\\')\\n\\t# _curr_interaction_mode_kwargs = _non_interactive_mode_kwargs # non-interactive mode\\n\\n\\t_out = curr_active_pipeline.display(\\'_display_directional_merged_pf_decoded_epochs\\', curr_active_pipeline.get_session_context(),\\n\\t\\t\\t\\tmax_num_lap_epochs = 100, max_num_ripple_epochs = 10,\\n\\t\\t\\t\\trender_merged_pseudo2D_decoder_laps=True, \\n\\t\\t\\t\\t# render_directional_marginal_laps=False, render_directional_marginal_ripples=False, render_track_identity_marginal_laps=False, render_track_identity_marginal_ripples=False,\\n\\t\\t\\t\\trender_directional_marginal_laps=True, render_directional_marginal_ripples=False, render_track_identity_marginal_laps=True, render_track_identity_marginal_ripples=False,\\n\\t\\t\\t\\t# constrained_layout=True, # layout=\\'none\\',\\n\\t\\t\\t\\tbuild_fn=\\'basic_view\\', constrained_layout=True, \\n\\t\\t\\t\\t# build_fn=\\'insets_view\\', constrained_layout=None, layout=\\'none\\', # , constrained_layout=False constrained_layout=None, layout=\\'none\\', # , constrained_layout=None, layout=\\'none\\' extrodinarily fast\\n\\t\\t\\t\\t**_curr_interaction_mode_kwargs, # interactive mode\\n\\t\\t\\t\\tskip_plotting_measured_positions=True, skip_plotting_most_likely_positions=True, save_figure=save_figure)\\n\\t\\nexcept Exception as e:\\n\\tprint(f\\'batch_extended_programmatic_figures(...): \"_display_directional_merged_pf_decoded_epochs\" failed with error: {e}\\\\n skipping.\\')\\n\\traise\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'eaa1cbba', 'metadata': {}, 'outputs': [], 'source': '# global_any_laps_epochs_obj\\n\\n\\n\\ncurr_active_pipeline.filtered_sessions[long_any_name].laps'}, {'cell_type': 'markdown', 'id': '6974d23f', 'metadata': {}, 'source': '### Plot the z-scores differences and their raw-values'}, {'cell_type': 'code', 'execution_count': None, 'id': '09e7c645', 'metadata': {}, 'outputs': [], 'source': \"# from PyQt5.QtWidgets import QGraphicsTextItem\\nfrom pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum, LongShortDisplayConfigManager\\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses, plot_rank_order_epoch_inst_fr_result_tuples\\nfrom pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\\n\\n# histogram_display_context = active_context.adding_context('display_fn', display_fn_name='plot_rank_order_epoch_inst_fr_result_tuples')\\nripple_outputs = plot_rank_order_epoch_inst_fr_result_tuples(curr_active_pipeline, ripple_result_tuple, 'Ripple', show=False)\\n# _out_ripple_result_tuple_histograms.context = histogram_display_context.adding_context('subplot', subplot_name='ripple_result_tuple')\\ndiff_app, diff_win, diff_p1, diff_out_plot_1D, diff_label_tuple, raw_app, raw_win, raw_p1, raw_out_plot_1D, raw_label_tuple = ripple_outputs\\ndiff_header_label, diff_footer_label = diff_label_tuple\\nraw_header_label, raw_footer_label = raw_label_tuple\\n\"}, {'cell_type': 'markdown', 'id': '0bd68cf0', 'metadata': {}, 'source': '# 2023-01-16 - Continuously applied Pseduo2D decoder across time'}, {'cell_type': 'code', 'execution_count': None, 'id': '691320ff', 'metadata': {}, 'outputs': [], 'source': '## How to I get time-parcilated intervals, similar to epochs, from the raw timezz? I know there are a lot of decoders in the past that did this. I think that more involved decoder even does it automatically by taking a time-bin size.\\n\\n## Each lap was labeled LR_Long, RL_Long, LR_Short, or RL_Short. \\n\\n## From this four 1D non-directional decoders were built independently from the data obtained from each of the four running directions. This resulted in four independent sets of firing rmaps, a set consisting of all participating cells, each of which mapped a position bin on the track to an average firing rate. Minimum peak activity thresholds were applied independently to each, meaning some cells were only participating in one of the four configurations. \\n\\n## To determine the correct configuration for each time bin these four 1D decoders were vertically concatenated to form a \"pseudo-2D\" ratemap for each cell, where the artficial y-direction mapped to four possible  \\n## The deta was vertically concatenated to form \\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'f6a9af7d', 'metadata': {}, 'outputs': [], 'source': 'from neuropy.core.epoch import Epoch\\nfrom pyphocorehelpers.indexing_helpers import BinningContainer, BinningInfo\\nfrom pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder, BayesianPlacemapPositionDecoder\\n\\nt_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()'}, {'cell_type': 'code', 'execution_count': None, 'id': 'bfd0d6ca', 'metadata': {}, 'outputs': [], 'source': \"# Build an Epoch object containing a single epoch, corresponding to the global epoch for the entire session:\\nsingle_global_epoch_df: pd.DataFrame = pd.DataFrame({'start': [t_start], 'stop': [t_end], 'label': [0]})\\n# single_global_epoch_df['label'] = single_global_epoch_df.index.to_numpy()\\nsingle_global_epoch: Epoch = Epoch(single_global_epoch_df)\\nsingle_global_epoch\"}, {'cell_type': 'code', 'execution_count': None, 'id': '7fc056fa', 'metadata': {}, 'outputs': [], 'source': \"## Build Epoch object across whole sessions:\\n# time_bin_size = long_LR_pf1D_Decoder.time_bin_size\\ntime_bin_size = 0.02 # 20ms bins\\n# time_binning_container: BinningContainer = deepcopy(long_LR_pf1D_Decoder.time_binning_container)\\n# time_binning_container\\n# time_binning_container.edges # array([31.8648, 31.8978, 31.9308, ..., 1203.56, 1203.6, 1203.63])\\n# time_binning_container.centers # array([31.8813, 31.9143, 31.9473, ..., 1203.55, 1203.58, 1203.61])\\nprint(f'time_bin_size: {time_bin_size}')\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'fc498488', 'metadata': {}, 'outputs': [], 'source': \"global_spikes_df, _, _ = RankOrderAnalyses.common_analysis_helper(curr_active_pipeline=curr_active_pipeline, num_shuffles=0) # does not do shuffling\\n\\n# # Get proper global_spikes_df:\\n# rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\\n# minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\\n# included_qclu_values: List[int] = rank_order_results.included_qclu_values\\n# directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\\n# track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\\n# any_list_neuron_IDs = track_templates.any_decoder_neuron_IDs # neuron_IDs as they appear in any list\\n# global_spikes_df = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].spikes_df).spikes.sliced_by_neuron_id(any_list_neuron_IDs) # Cut spikes_df down to only the neuron_IDs that appear at least in one decoder:\\n\\nspikes_df = deepcopy(global_spikes_df) #.spikes.sliced_by_neuron_id(track_templates.shared_aclus_only_neuron_IDs)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '8173f658', 'metadata': {}, 'outputs': [], 'source': '## Already come in with long_LR_pf1D_Decoder, long_LR_pf1D_Decoder\\nlong_LR_pf1D_Decoder # type(long_LR_pf1D_Decoder) # pyphoplacecellanalysis.Analysis.Decoder.reconstruction.BayesianPlacemapPositionDecoder\\nlong_RL_pf1D_Decoder\\nshort_LR_pf1D_Decoder\\nshort_RL_pf1D_Decoder'}, {'cell_type': 'code', 'execution_count': None, 'id': '57e1a98b', 'metadata': {}, 'outputs': [], 'source': 'time_bin_size = 0.02 # 20ms bins'}, {'cell_type': 'code', 'execution_count': None, 'id': 'a7df58ae', 'metadata': {}, 'outputs': [], 'source': 'pseudo2D_decoder: BasePositionDecoder = all_directional_pf1D_Decoder_value\\npseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = pseudo2D_decoder.decode_specific_epochs(spikes_df=spikes_df, filter_epochs=single_global_epoch, decoding_time_bin_size=time_bin_size, debug_print=False)\\n# 16.1s'}, {'cell_type': 'code', 'execution_count': None, 'id': '1314a194', 'metadata': {}, 'outputs': [], 'source': 'assert pseudo2D_decoder_continuously_decoded_result.num_filter_epochs == 1, f\"expected a single global filter epoch but got {pseudo2D_decoder_continuously_decoded_result.num_filter_epoch}\"\\nsingle_global_epoch_df: pd.DataFrame = pseudo2D_decoder_continuously_decoded_result.filter_epochs[0] # \\nsingle_global_epoch: Epoch = Epoch(single_global_epoch_df)\\nsingle_global_epoch'}, {'cell_type': 'code', 'execution_count': None, 'id': '3a014c39', 'metadata': {}, 'outputs': [], 'source': \"# Decode continuously for the four 1D directional decoders:\\n# all_directional_decoder_names = ['long_LR', 'long_RL', 'short_LR', 'short_RL']\\n# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = dict(zip(all_directional_decoder_names, [deepcopy(long_LR_pf1D_Decoder), deepcopy(long_RL_pf1D_Decoder), deepcopy(short_LR_pf1D_Decoder), deepcopy(short_RL_pf1D_Decoder)]))\\n\\nall_directional_continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = {k:v.decode_specific_epochs(spikes_df=spikes_df, filter_epochs=single_global_epoch, decoding_time_bin_size=time_bin_size, debug_print=False) for k,v in all_directional_pf1D_Decoder_dict.items()}\\n# _out_continuously_decoded_dict \\n# 32.7s\\nall_directional_continuously_decoded_dict\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'a2993591', 'metadata': {}, 'outputs': [], 'source': \"directional_decoders_decode_result: DirectionalDecodersDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\\nall_directional_pf1D_Decoder_dict = directional_decoders_decode_result.pf1D_Decoder_dict\\ncontinuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\\npreviously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\\npreviously_decoded_keys\"}, {'cell_type': 'code', 'execution_count': None, 'id': '524f6e38', 'metadata': {}, 'outputs': [], 'source': 'pseudo2D_decoder_continuously_decoded_result'}, {'cell_type': 'code', 'execution_count': None, 'id': '78646cf4', 'metadata': {}, 'outputs': [], 'source': '## Yellow-blue plots from `pseudo2D_decoder_continuously_decoded_result` (continuous time)?\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'd9ad1255', 'metadata': {}, 'outputs': [], 'source': \"directional_decoders_decode_result.most_recent_continuously_decoded_dict['long_LR']\"}, {'cell_type': 'code', 'execution_count': None, 'id': '2e5b0094', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\\n\\n# _out_continuously_decoded_dict['long_LR']\\na_decoder_name = 'long_LR'\\nactive_decoder: BasePositionDecoder = deepcopy(all_directional_pf1D_Decoder_dict[a_decoder_name])\\nactive_result: DecodedFilterEpochsResult = deepcopy(all_directional_continuously_decoded_dict[a_decoder_name]) # already decoded\\nassert active_result.num_filter_epochs == 1\\nactive_result\"}, {'cell_type': 'code', 'execution_count': None, 'id': '6c24a3e2', 'metadata': {}, 'outputs': [], 'source': 'active_marginals = active_result.marginal_x_list[0]\\nactive_posterior = active_marginals.p_x_given_n\\n# active_marginals\\nactive_posterior.shape'}, {'cell_type': 'code', 'execution_count': None, 'id': 'a67140f5', 'metadata': {}, 'outputs': [], 'source': 'active_marginals = active_decoder.marginal.x\\nactive_posterior = active_marginals.p_x_given_n\\nactive_posterior.shape'}, {'cell_type': 'code', 'execution_count': None, 'id': '7d211130', 'metadata': {}, 'outputs': [], 'source': 'active_bins = active_decoder.xbin\\n\\n# active_most_likely_positions = active_marginals.most_likely_positions_1D # Raw decoded positions\\nactive_most_likely_positions = None\\nactive_posterior = active_marginals.p_x_given_n'}, {'cell_type': 'markdown', 'id': '1a3e71c2', 'metadata': {}, 'source': '# 2024-01-17 - Explore the effect of time_bin_size of decoding performance:'}, {'cell_type': 'code', 'execution_count': None, 'id': 'f608ce9e', 'metadata': {}, 'outputs': [], 'source': '[0.05, 0.01, 0.05, 0.1, 0.5, 1.0, 1.5]\\n\\nnp.linspace(0.125, 1.0, num=20)\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '704d8c5e', 'metadata': {}, 'outputs': [], 'source': '# Updates laps with new column definitions session and filtered versions:\\ncurr_sess = curr_active_pipeline.sess\\ncurr_sess.laps.update_lap_dir_from_smoothed_velocity(pos_input=curr_sess.position)\\ncurr_sess.laps.update_maze_id_if_needed(t_start=t_start, t_delta=t_delta, t_end=t_end)\\n\\nfor an_epoch_name, curr_sess in curr_active_pipeline.filtered_sessions.items():\\n\\tcurr_sess.laps.update_lap_dir_from_smoothed_velocity(pos_input=curr_sess.position)\\n\\tcurr_sess.laps.update_maze_id_if_needed(t_start=t_start, t_delta=t_delta, t_end=t_end)\\n\\ncurr_sess.laps'}, {'cell_type': 'code', 'execution_count': None, 'id': 'b8f7acec', 'metadata': {}, 'outputs': [], 'source': 'from neuropy.analyses.placefields import PfND\\nfrom neuropy.core.laps import Laps\\nfrom pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\\nfrom neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\\nfrom neuropy.utils.mixins.binning_helpers import find_minimum_time_bin_duration\\n# from PendingNotebookCode import _perform_variable_time_bin_lap_groud_truth_performance_testing \\nfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _check_result_laps_epochs_df_performance\\n\\nall_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_laps_decoding_time_bin_size=np.linspace(0.125, 1.0, num=20), use_single_time_bin_per_epoch=[False], desired_ripple_decoding_time_bin_size=[None])\\n# len(all_param_sweep_options)\\nall_param_sweep_options\\n\\n## Perfrom the computations:\\n\\n# DirectionalMergedDecoders: Get the result after computation:\\n## Copy the default result:\\ndirectional_merged_decoders_result: DirectionalMergedDecodersResult = curr_active_pipeline.global_computation_results.computed_data[\\'DirectionalMergedDecoders\\']\\nalt_directional_merged_decoders_result: DirectionalMergedDecodersResult = deepcopy(directional_merged_decoders_result)\\n\\nlaps_decoding_time_bin_size = alt_directional_merged_decoders_result.laps_decoding_time_bin_size\\nnow_day_str: str = DAY_DATE_TO_USE    \\nactive_context: IdentifyingContext = curr_active_pipeline.get_session_context()\\n# data_identifier_str=f\\'(laps_time_bin_marginals_df)\\'\\n\\n# out_path_basename_str: str = f\"{now_day_str}_{active_context}_time_bin_size-{laps_decoding_time_bin_size}_{data_identifier_str}\"\\nout_path_basename_str: str = f\"{now_day_str}_{active_context}_time_bin_size_sweep_results\"\\n# out_path_filenname_str: str = f\"{out_path_basename_str}.csv\"\\n\\nout_path_filenname_str: str = f\"{out_path_basename_str}.h5\"\\nout_path: Path = Path(\\'output\\').resolve().joinpath(out_path_filenname_str).resolve()\\nprint(f\\'\\\\out_path_str: \"{out_path_filenname_str}\"\\')\\nprint(f\\'\\\\tout_path: \"{file_uri_from_path(out_path)}\"\\')\\n\\n# Ensure it has the \\'lap_track\\' column\\n## Compute the ground-truth information using the position information:\\n# adds columns: [\\'maze_id\\', \\'is_LR_dir\\']\\nt_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\\nlaps_obj: Laps = curr_active_pipeline.sess.laps\\nlaps_df = laps_obj.to_dataframe()\\nlaps_df: pd.DataFrame = Laps._update_dataframe_computed_vars(laps_df=laps_df, t_start=t_start, t_delta=t_delta, t_end=t_end, global_session=curr_active_pipeline.sess) # NOTE: .sess is used because global_session is missing the last two laps\\n\\ndef _update_result_laps(a_result: DecodedFilterEpochsResult, laps_df: pd.DataFrame) -> pd.DataFrame:\\n\\t\"\"\" captures nothing. Can reusing the same laps_df as it makes no modifications to it. \\n\\t\\n\\te.g. a_result=output_alt_directional_merged_decoders_result[a_sweep_tuple]\\n\\t\"\"\"\\n\\tresult_laps_epochs_df: pd.DataFrame = a_result.laps_epochs_df\\n\\t## 2024-01-17 - Updates the `a_directional_merged_decoders_result.laps_epochs_df` with both the ground-truth values and the decoded predictions\\n\\tresult_laps_epochs_df[\\'maze_id\\'] = laps_df[\\'maze_id\\'].to_numpy()[np.isin(laps_df[\\'lap_id\\'], result_laps_epochs_df[\\'lap_id\\'])] # this works despite the different size because of the index matching\\n\\t## add the \\'is_LR_dir\\' groud-truth column in:\\n\\tresult_laps_epochs_df[\\'is_LR_dir\\'] = laps_df[\\'is_LR_dir\\'].to_numpy()[np.isin(laps_df[\\'lap_id\\'], result_laps_epochs_df[\\'lap_id\\'])] # this works despite the different size because of the index matching\\n\\t\\n\\tlaps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir = a_result.laps_directional_marginals_tuple\\n\\tlaps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = a_result.laps_track_identity_marginals_tuple\\n\\t## Add the decoded results to the laps df:\\n\\tresult_laps_epochs_df[\\'is_most_likely_track_identity_Long\\'] = laps_is_most_likely_track_identity_Long\\n\\tresult_laps_epochs_df[\\'is_most_likely_direction_LR\\'] = laps_is_most_likely_direction_LR_dir\\n\\treturn result_laps_epochs_df\\n\\t\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '056714f2', 'metadata': {}, 'outputs': [], 'source': 'alt_directional_merged_decoders_result.laps_epochs_df\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'df60017e', 'metadata': {}, 'outputs': [], 'source': \"## Single decode:\\ndef _try_single_decode(owning_pipeline_reference, directional_merged_decoders_result, use_single_time_bin_per_epoch: bool, desired_laps_decoding_time_bin_size: Optional[float], desired_ripple_decoding_time_bin_size: Optional[float]):\\n\\n    ## Decode Laps:\\n    laps_epochs_df = deepcopy(directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result.filter_epochs)\\n    if not isinstance(laps_epochs_df, pd.DataFrame):\\n        laps_epochs_df = laps_epochs_df.to_dataframe()\\n    # global_any_laps_epochs_obj = deepcopy(owning_pipeline_reference.computation_results[global_epoch_name].computation_config.pf_params.computation_epochs) # global_epoch_name='maze_any' (? same as global_epoch_name?)\\n    min_possible_laps_time_bin_size: float = find_minimum_time_bin_duration(laps_epochs_df['duration'].to_numpy())\\n    min_bounded_laps_decoding_time_bin_size: float = min(desired_laps_decoding_time_bin_size, min_possible_laps_time_bin_size) # 10ms # 0.002\\n    \\n    if desired_laps_decoding_time_bin_size < min_bounded_laps_decoding_time_bin_size:\\n        print(f'WARN: desired_laps_decoding_time_bin_size: {desired_laps_decoding_time_bin_size} < min_bounded_laps_decoding_time_bin_size: {min_bounded_laps_decoding_time_bin_size}... hopefully it works.')\\n    laps_decoding_time_bin_size: float = desired_laps_decoding_time_bin_size # allow direct use\\n    if use_single_time_bin_per_epoch:\\n        laps_decoding_time_bin_size = None\\n    directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result = directional_merged_decoders_result.all_directional_pf1D_Decoder.decode_specific_epochs(spikes_df=deepcopy(owning_pipeline_reference.sess.spikes_df), filter_epochs=laps_epochs_df,\\n                                                                                                                                                    decoding_time_bin_size=laps_decoding_time_bin_size, use_single_time_bin_per_epoch=use_single_time_bin_per_epoch, debug_print=False)\\n    directional_merged_decoders_result.perform_compute_marginals()\\n\\n    return directional_merged_decoders_result\\n    \\n\\nsession_ctxt_key:str = active_context.get_description(separator='|', subset_includelist=IdentifyingContext._get_session_context_keys())\\n\\n# Uses: session_ctxt_key, all_param_sweep_options\\n\\noutput_alt_directional_merged_decoders_result = {} # empty dict\\noutput_laps_decoding_accuracy_results_dict = {} # empty dict\\n\\nfor a_sweep_dict in all_param_sweep_options:\\n    a_sweep_tuple = frozenset(a_sweep_dict.items())\\n    print(f'a_sweep_dict: {a_sweep_dict}')\\n    # Convert parameters to string because Parquet supports metadata as string\\n    a_sweep_str_params = {key: str(value) for key, value in a_sweep_dict.items() if value is not None}\\n    \\n    output_alt_directional_merged_decoders_result[a_sweep_tuple] = _try_single_decode(curr_active_pipeline, alt_directional_merged_decoders_result, **a_sweep_dict)\\n\\n    laps_time_bin_marginals_df: pd.DataFrame = output_alt_directional_merged_decoders_result[a_sweep_tuple].laps_time_bin_marginals_df.copy()\\n    laps_all_epoch_bins_marginals_df: pd.DataFrame = output_alt_directional_merged_decoders_result[a_sweep_tuple].laps_all_epoch_bins_marginals_df.copy()\\n\\n    desired_laps_decoding_time_bin_size_str: str = a_sweep_str_params.get('desired_laps_decoding_time_bin_size', None)\\n    laps_decoding_time_bin_size: float = output_alt_directional_merged_decoders_result[a_sweep_tuple].laps_decoding_time_bin_size\\n    actual_laps_decoding_time_bin_size_str: str = str(laps_decoding_time_bin_size)\\n    if actual_laps_decoding_time_bin_size_str is not None:\\n        laps_time_bin_marginals_df.to_hdf(out_path, key=f'{session_ctxt_key}/{actual_laps_decoding_time_bin_size_str}/laps_time_bin_marginals_df', format='table', data_columns=True)\\n        laps_all_epoch_bins_marginals_df.to_hdf(out_path, key=f'{session_ctxt_key}/{actual_laps_decoding_time_bin_size_str}/laps_all_epoch_bins_marginals_df', format='table', data_columns=True)\\n\\n    # get the current lap object and determine the percentage correct:\\n    result_laps_epochs_df = _update_result_laps(a_result=output_alt_directional_merged_decoders_result[a_sweep_tuple], laps_df=laps_df)\\n    (is_decoded_track_correct, is_decoded_dir_correct, are_both_decoded_properties_correct), (percent_laps_track_identity_estimated_correctly, percent_laps_direction_estimated_correctly, percent_laps_estimated_correctly) = _check_result_laps_epochs_df_performance(result_laps_epochs_df)\\n    output_laps_decoding_accuracy_results_dict[laps_decoding_time_bin_size] = (percent_laps_track_identity_estimated_correctly, percent_laps_direction_estimated_correctly, percent_laps_estimated_correctly)\\n    \\n\\n## Output the performance:\\noutput_laps_decoding_accuracy_results_df: pd.DataFrame = pd.DataFrame(output_laps_decoding_accuracy_results_dict.values(), index=output_laps_decoding_accuracy_results_dict.keys(), \\n                  columns=['percent_laps_track_identity_estimated_correctly',\\n                           'percent_laps_direction_estimated_correctly',\\n                           'percent_laps_estimated_correctly'])\\noutput_laps_decoding_accuracy_results_df.index.name = 'laps_decoding_time_bin_size'\\n# output_laps_decoding_accuracy_results_df\\n\\n## Save out the laps peformance result\\n# output_laps_decoding_accuracy_results_df_path = Path('output/output_laps_decoding_accuracy_results_df.csv')\\n# output_laps_decoding_accuracy_results_df.to_csv(output_laps_decoding_accuracy_results_df_path)\\noutput_laps_decoding_accuracy_results_df.to_hdf(out_path, key=f'{session_ctxt_key}/laps_decoding_accuracy_results', format='table', data_columns=True)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '471d9d86', 'metadata': {}, 'outputs': [], 'source': '# ## Unpack the result:\\n# all_directional_laps_filter_epochs_decoder_result_value = alt_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\\n# all_directional_ripple_filter_epochs_decoder_result_value = alt_directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\\n\\n# laps_epochs_df = alt_directional_merged_decoders_result.laps_epochs_df\\n# ripple_epochs_df = alt_directional_merged_decoders_result.ripple_epochs_df\\n\\n# all_directional_laps_filter_epochs_decoder_result_value\\n\\n# laps_decoding_time_bin_size: float = alt_directional_merged_decoders_result.laps_decoding_time_bin_size\\n# ripple_decoding_time_bin_size: float = alt_directional_merged_decoders_result.ripple_decoding_time_bin_size\\n# laps_decoding_time_bin_size, ripple_decoding_time_bin_size'}, {'cell_type': 'code', 'execution_count': None, 'id': '845b96f3', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalMergedDecodersResult\\n\\n\\nresult_laps_epochs_df: pd.DataFrame = alt_directional_merged_decoders_result.laps_epochs_df\\nresult_laps_epochs_df'}, {'cell_type': 'code', 'execution_count': None, 'id': '8edb3737', 'metadata': {}, 'outputs': [], 'source': \"from neuropy.core.laps import Laps\\nfrom PendingNotebookCode import _check_result_laps_epochs_df_performance\\n# takes 'laps_df' and 'result_laps_epochs_df' to add the ground_truth and the decoded posteriors:\\n\\n# Ensure it has the 'lap_track' column\\n## Compute the ground-truth information using the position information:\\n# adds columns: ['maze_id', 'is_LR_dir']\\nt_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\\nlaps_obj: Laps = curr_active_pipeline.sess.laps\\nlaps_obj\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '89a24222', 'metadata': {}, 'outputs': [], 'source': \"\\t\\n# # np.sum(result_laps_epochs_df['is_LR_dir'] == result_laps_epochs_df['is_most_likely_direction_LR'])/np.shape(result_laps_epochs_df)[0]\\n# laps_decoding_time_bin_size = alt_directional_merged_decoders_result.laps_decoding_time_bin_size\\n# print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}')\\n\\t\\n\\nresult_laps_epochs_df: pd.DataFrame = alt_directional_merged_decoders_result.laps_epochs_df\\nresult_laps_epochs_df = _update_result_laps(result_laps_epochs_df=result_laps_epochs_df, laps_df=laps_df)\\n(is_decoded_track_correct, is_decoded_dir_correct, are_both_decoded_properties_correct), (percent_laps_track_identity_estimated_correctly, percent_laps_direction_estimated_correctly, percent_laps_estimated_correctly) = _check_result_laps_epochs_df_performance(result_laps_epochs_df)\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'b07d0306', 'metadata': {}, 'outputs': [], 'source': '## `alt_directional_merged_decoders_result`\\nfrom PendingNotebookCode import test_build_new_marginals_df\\n\\n# `alt_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result`\\n\\n# laps_time_bin_marginals_df = test_build_new_marginals_df(alt_directional_merged_decoders_result)\\nlaps_time_bin_marginals_df: pd.DataFrame = test_build_new_marginals_df(a_decoder_result=deepcopy(alt_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result),\\n\\t\\t\\t\\t\\t\\t\\t\\t a_track_identity_marginals=alt_directional_merged_decoders_result.laps_directional_marginals_tuple[0]\\n\\t\\t\\t\\t\\t\\t\\t )\\nlaps_time_bin_marginals_df\\n\\nripple_time_bin_marginals_df: pd.DataFrame = test_build_new_marginals_df(a_decoder_result=deepcopy(alt_directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result),\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t a_track_identity_marginals=alt_directional_merged_decoders_result.ripple_directional_marginals_tuple[0]\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t)\\nripple_time_bin_marginals_df\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e31563a1', 'metadata': {}, 'outputs': [], 'source': 'alt_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result'}, {'cell_type': 'code', 'execution_count': None, 'id': 'debcee02', 'metadata': {}, 'outputs': [], 'source': 'output_alt_directional_merged_decoders_result'}, {'cell_type': 'markdown', 'id': 'c15d02ad', 'metadata': {}, 'source': '## 2024-01-17 - Updates the `a_directional_merged_decoders_result.laps_epochs_df` with both the ground-truth values and the decoded predictions'}, {'cell_type': 'code', 'execution_count': None, 'id': '2ab95d85', 'metadata': {}, 'outputs': [], 'source': 'curr_active_pipeline.reload_default_display_functions()'}, {'cell_type': 'code', 'execution_count': None, 'id': 'd9dabb0f', 'metadata': {}, 'outputs': [], 'source': \"# Interactive-mode parameters:\\n_interactive_mode_kwargs = dict(should_use_MatplotlibTimeSynchronizedWidget=True, scrollable_figure=True, defer_render=False)\\n_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\\n_curr_interaction_mode_kwargs = _interactive_mode_kwargs # interactive mode\"}, {'cell_type': 'code', 'execution_count': None, 'id': '2f0ca3ae', 'metadata': {}, 'outputs': [], 'source': \"# Non-interactive:\\n_non_interactive_mode_kwargs = dict(should_use_MatplotlibTimeSynchronizedWidget=False, scrollable_figure=False, defer_render=True)\\n_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=False, backend='AGG')\\n_curr_interaction_mode_kwargs = _non_interactive_mode_kwargs # non-interactive mode\"}, {'cell_type': 'markdown', 'id': '2727307e', 'metadata': {}, 'source': '### 2024-01-19 - Marginal Scatter Plots from `alt_directional_merged_decoders_result`'}, {'cell_type': 'code', 'execution_count': None, 'id': 'a8f3d42c', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import plot_all_epoch_bins_marginal_predictions\\nuse_single_time_bin_per_epoch = False\\nactive_display_context = curr_active_pipeline.build_display_context_for_session('plot_all_epoch_bins_marginal_predictions', laps_t_bin=laps_decoding_time_bin_size, ripple_t_bin=ripple_decoding_time_bin_size) # \\nif use_single_time_bin_per_epoch:\\n\\tactive_display_context = active_display_context.adding_context_if_missing(use_single_time_bin_per_epoch=use_single_time_bin_per_epoch)\\n\\n# 'directional_decoded_epochs_marginals'\\ncollector_decoded_epoch_marginals = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs_marginals', curr_active_pipeline.get_session_context(), \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tactive_context=active_display_context,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tsave_figure=True, \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tdirectional_merged_decoders_result=alt_directional_merged_decoders_result, # Custom `directional_merged_decoders_result` to use instead of the computed one.\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t)\\n\"}, {'cell_type': 'markdown', 'id': '7ae85fcb', 'metadata': {}, 'source': '### 2024-01-19 - Marginal Yellow-Blue Plots from `alt_directional_merged_decoders_result`'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e5876c7f', 'metadata': {}, 'outputs': [], 'source': \"# active_context = owning_pipeline_reference.sess.get_context()\\n# Build the active context directly:\\nactive_display_context: IdentifyingContext = curr_active_pipeline.build_display_context_for_session('directional_merged_pf_decoded_epochs', laps_t_bin=laps_decoding_time_bin_size, ripple_t_bin=ripple_decoding_time_bin_size)\\nif use_single_time_bin_per_epoch:\\n\\tactive_display_context = active_display_context.adding_context_if_missing(use_single_time_bin_per_epoch=use_single_time_bin_per_epoch)\\nactive_display_context\\n\\n## Plot the decoded epoch bins of the custom result:\\n_out_decoded_epochs = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs', curr_active_pipeline.get_session_context(), #active_display_context,\\n\\tmax_num_lap_epochs = 80, max_num_ripple_epochs = 100,\\n\\t# render_directional_marginal_laps=True, render_directional_marginal_ripples=True, render_track_identity_marginal_laps=True, render_track_identity_marginal_ripples=True,\\n\\trender_directional_marginal_laps=False, render_directional_marginal_ripples=False, render_track_identity_marginal_laps=False, render_track_identity_marginal_ripples=True,\\n\\t# constrained_layout=True, # layout='none',\\n\\t# build_fn='basic_view', constrained_layout=True, # 25.5s\\n\\tbuild_fn='insets_view', constrained_layout=True, #constrained_layout=None, layout='none', # , constrained_layout=False constrained_layout=None, layout='none', # , constrained_layout=None, layout='none' extrodinarily fast, 4.2s\\n\\t**_curr_interaction_mode_kwargs, # interactive mode\\n\\tskip_plotting_measured_positions=True, skip_plotting_most_likely_positions=True, save_figure=True, \\n\\tdirectional_merged_decoders_result=alt_directional_merged_decoders_result, # Custom `directional_merged_decoders_result` to use instead of the computed one.\\n\\t)\\ncollector_decoded_epochs = _out_decoded_epochs['collector']\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'cddc6584', 'metadata': {}, 'outputs': [], 'source': \"laps_only_keys = [item for item in active_display_context.keys() if 'lap' in item] # items exclusive to laps: ['laps_t_bin']\\nripple_only_keys = [item for item in active_display_context.keys() if 'ripple' in item]\\nlaps_context = active_display_context.get_subset(subset_excludelist=ripple_only_keys) # laps specific context filtering out the ripple keys\\nripple_context = active_display_context.get_subset(subset_excludelist=laps_only_keys) # ripple specific context filtering out the laps keys\\n\"}, {'cell_type': 'markdown', 'id': 'a5c4169a', 'metadata': {}, 'source': '### 2024-01-19 - Build Gneral Marginals'}, {'cell_type': 'code', 'execution_count': None, 'id': 'ac6d8817', 'metadata': {}, 'outputs': [], 'source': '## `alt_directional_merged_decoders_result`\\nfrom PendingNotebookCode import test_build_new_marginals_df\\n\\n# `alt_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result`\\n\\n# laps_time_bin_marginals_df = test_build_new_marginals_df(alt_directional_merged_decoders_result)\\nlaps_time_bin_marginals_df: pd.DataFrame = test_build_new_marginals_df(a_decoder_result=deepcopy(alt_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result),\\n\\t\\t\\t\\t\\t\\t\\t\\t a_track_identity_marginals=alt_directional_merged_decoders_result.laps_directional_marginals_tuple[0]\\n\\t\\t\\t\\t\\t\\t\\t )\\nlaps_time_bin_marginals_df\\n\\nripple_time_bin_marginals_df: pd.DataFrame = test_build_new_marginals_df(a_decoder_result=deepcopy(alt_directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result),\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t a_track_identity_marginals=alt_directional_merged_decoders_result.ripple_directional_marginals_tuple[0]\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t)\\nripple_time_bin_marginals_df'}, {'cell_type': 'code', 'execution_count': None, 'id': 'f8d88744', 'metadata': {}, 'outputs': [], 'source': 'import matplotlib as mpl\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom flexitext import flexitext ## flexitext for formatted matplotlib text\\n\\nfrom pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import FigureCollector\\nfrom pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import PlottingHelpers\\nfrom neuropy.utils.matplotlib_helpers import FormattedFigureText\\n\\n\\nperform_write_to_file_callback = None\\n\\nlaps_all_epoch_bins_marginals_df = deepcopy(laps_time_bin_marginals_df)\\nripple_all_epoch_bins_marginals_df = deepcopy(ripple_time_bin_marginals_df)\\n\\nif active_context is not None:\\n\\tdisplay_context = active_context.adding_context(\\'display_fn\\', display_fn_name=\\'plot_all_epoch_bins_marginal_predictions\\')\\n\\t\\n# These subset contexts are used to filter out lap/ripple only keys.\\n# e.g. active_context=curr_active_pipeline.build_display_context_for_session(\\'directional_merged_pf_decoded_epochs\\', laps_t_bin=laps_decoding_time_bin_size, ripple_t_bin=ripple_decoding_time_bin_size)\\n\\t# only want laps_t_bin on the laps plot and ripple_t_bin on the ripples plot\\nlaps_only_keys = [item for item in display_context.keys() if \\'lap\\' in item] # items exclusive to laps: [\\'laps_t_bin\\']\\nripple_only_keys = [item for item in display_context.keys() if \\'ripple\\' in item]\\nlaps_display_context = display_context.get_subset(subset_excludelist=ripple_only_keys) # laps specific context filtering out the ripple keys\\nripple_display_context = display_context.get_subset(subset_excludelist=laps_only_keys) # ripple specific context filtering out the laps keys\\n\\n\\nwith mpl.rc_context({\\'figure.figsize\\': (12.4, 4.8), \\'figure.dpi\\': \\'220\\', \\'savefig.transparent\\': True, \\'ps.fonttype\\': 42,\\n\\t\\t\\t\\t\\t\\t\"axes.spines.left\": False, \"axes.spines.right\": False, \"axes.spines.bottom\": False, \"axes.spines.top\": False,\\n\\t\\t\\t\\t\\t\\t\"axes.edgecolor\": \"none\", \"xtick.bottom\": False, \"xtick.top\": False, \"ytick.left\": False, \"ytick.right\": False}):\\n\\t# Create a FigureCollector instance\\n\\twith FigureCollector(name=\\'plot_all_epoch_bins_marginal_predictions\\', base_context=display_context) as collector:\\n\\n\\t\\t## Define common operations to do after making the figure:\\n\\t\\tdef setup_common_after_creation(a_collector, fig, axes, sub_context, title=f\\'<size:22> Sig. (>0.95) <weight:bold>Best</> <weight:bold>Quantile Diff</></>\\'):\\n\\t\\t\\t\"\"\" Captures:\\n\\n\\t\\t\\tt_split, t_start, t_end)\\n\\t\\t\\t\"\"\"\\n\\t\\t\\ta_collector.contexts.append(sub_context)\\n\\t\\t\\t\\n\\t\\t\\tfor ax in (axes if isinstance(axes, Iterable) else [axes]):\\n\\t\\t\\t\\t# Update the xlimits with the new bounds\\n\\t\\t\\t\\tax.set_ylim(0.0, 1.0)\\n\\t\\t\\t\\t# Add epoch indicators\\n\\t\\t\\t\\t_tmp_output_dict = PlottingHelpers.helper_matplotlib_add_long_short_epoch_indicator_regions(ax=ax, t_split=t_delta, t_start=t_start, t_end=t_end)\\n\\t\\t\\t\\t# Update the xlimits with the new bounds\\n\\t\\t\\t\\tax.set_xlim(t_start, t_end)\\n\\t\\t\\t\\t# Draw a horizontal line at y=0.5\\n\\t\\t\\t\\tax.axhline(y=0.5, color=(0,0,0,1)) # , linestyle=\\'--\\'\\n\\t\\t\\t\\t## This is figure level stuff and only needs to be done once:\\n\\t\\t\\t\\t# `flexitext` version:\\n\\t\\t\\t\\ttext_formatter = FormattedFigureText()\\n\\t\\t\\t\\tax.set_title(\\'\\')\\n\\t\\t\\t\\tfig.suptitle(\\'\\')\\n\\t\\t\\t\\t# top=0.84, bottom=0.125, left=0.07, right=0.97,\\n\\t\\t\\t\\t# text_formatter.setup_margins(fig, top_margin=1.0, left_margin=0.0, right_margin=1.0, bottom_margin=0.05)\\n\\t\\t\\t\\ttext_formatter.setup_margins(fig, top_margin=0.84, left_margin=0.07, right_margin=0.97, bottom_margin=0.125)\\n\\t\\t\\t\\t# fig.subplots_adjust(top=top_margin, left=left_margin, right=right_margin, bottom=bottom_margin)\\n\\t\\t\\t\\t# title_text_obj = flexitext(text_formatter.left_margin, text_formatter.top_margin, title, va=\"bottom\", xycoords=\"figure fraction\")\\n\\t\\t\\t\\ttitle_text_obj = flexitext(text_formatter.left_margin, 0.98, title, va=\"top\", xycoords=\"figure fraction\") # 0.98, va=\"top\" means the top edge of the title will be aligned to the fig_y=0.98 mark of the figure.\\n\\t\\t\\t\\t# footer_text_obj = flexitext((text_formatter.left_margin * 0.1), (text_formatter.bottom_margin * 0.25),\\n\\t\\t\\t\\t#                             text_formatter._build_footer_string(active_context=sub_context),\\n\\t\\t\\t\\t#                             va=\"top\", xycoords=\"figure fraction\")\\n\\n\\t\\t\\t\\tfooter_text_obj = flexitext((text_formatter.left_margin * 0.1), (0.0025), ## (va=\"bottom\", (0.0025)) - this means that the bottom edge of the footer text is aligned with the fig_y=0.0025 in figure space\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ttext_formatter._build_footer_string(active_context=sub_context),\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tva=\"bottom\", xycoords=\"figure fraction\")\\n\\t\\t\\n\\t\\t\\tif ((perform_write_to_file_callback is not None) and (sub_context is not None)):\\n\\t\\t\\t\\tperform_write_to_file_callback(sub_context, fig)\\n\\t\\t\\t\\n\\t\\t# Plot for BestDir\\n\\t\\tfig, ax = collector.subplots(num=\\'Laps_Marginal\\', clear=True)\\n\\t\\t_out_Laps = sns.scatterplot(\\n\\t\\t\\tax=ax,\\n\\t\\t\\tdata=laps_all_epoch_bins_marginals_df,\\n\\t\\t\\tx=\\'t_bin_center\\',\\n\\t\\t\\ty=\\'P_Long\\',\\n\\t\\t\\t# size=\\'LR_Long_rel_num_cells\\',  # Use the \\'size\\' parameter for variable marker sizes\\n\\t\\t)\\n\\t\\tsetup_common_after_creation(collector, fig=fig, axes=ax, sub_context=laps_display_context.adding_context(\\'subplot\\', subplot_name=\\'Laps all_epoch_binned Marginals\\'), \\n\\t\\t\\t\\t\\t\\t\\t\\t\\ttitle=f\\'<size:22> Laps <weight:bold>all_epoch_binned</> Marginals</>\\')\\n\\t\\t\\n\\t\\tfig, ax = collector.subplots(num=\\'Ripple_Marginal\\', clear=True)\\n\\t\\t_out_Ripple = sns.scatterplot(\\n\\t\\t\\tax=ax,\\n\\t\\t\\tdata=ripple_all_epoch_bins_marginals_df,\\n\\t\\t\\tx=\\'t_bin_center\\',\\n\\t\\t\\ty=\\'P_Long\\',\\n\\t\\t\\t# size=\\'LR_Long_rel_num_cells\\',  # Use the \\'size\\' parameter for variable marker sizes\\n\\t\\t)\\n\\t\\tsetup_common_after_creation(collector, fig=fig, axes=ax, sub_context=ripple_display_context.adding_context(\\'subplot\\', subplot_name=\\'Ripple all_epoch_binned Marginals\\'), \\n\\t\\t\\t\\t\\t\\ttitle=f\\'<size:22> Ripple <weight:bold>all_epoch_binned</> Marginals</>\\')\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '2d655560', 'metadata': {}, 'outputs': [], 'source': \"laps_time_bin_marginals_df['lap_idx'] = laps_time_bin_marginals_df.index.to_numpy()\\nlaps_time_bin_marginals_df['lap_start_t'] = laps_epochs_df['start'].to_numpy()\\nlaps_time_bin_marginals_df\"}, {'cell_type': 'code', 'execution_count': None, 'id': '9e3800d0', 'metadata': {}, 'outputs': [], 'source': \"# 2024-01-19 - Can decode position from the pseudo2D posterior directly, or by using the pseudo2D decoder to determine the best direction and track_id and use the corresponding 1D decoder's predicted position.\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '31f76dfc', 'metadata': {}, 'outputs': [], 'source': \"# 2024-01-19 - Export All Epoch Time bin marginals to CSV also\\n## Laps:\\nlaps_epochs_df: pd.DataFrame = deepcopy(alt_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result.filter_epochs).to_dataframe()\\nlaps_directional_marginals_tuple = DirectionalMergedDecodersResult.determine_directional_likelihoods(alt_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result)\\nlaps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = laps_directional_marginals_tuple\\nlaps_track_identity_marginals = DirectionalMergedDecodersResult.determine_long_short_likelihoods(alt_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result)\\ntrack_identity_marginals, track_identity_all_epoch_bins_marginal, most_likely_track_identity_from_decoder, is_most_likely_track_identity_Long = laps_track_identity_marginals\\n\\nlaps_marginals_df: pd.DataFrame = pd.DataFrame(np.hstack((laps_directional_all_epoch_bins_marginal, track_identity_all_epoch_bins_marginal)), columns=['P_LR', 'P_RL', 'P_Long', 'P_Short'])\\nlaps_marginals_df['lap_idx'] = laps_marginals_df.index.to_numpy()\\nlaps_marginals_df['lap_start_t'] = laps_epochs_df['start'].to_numpy()\\nlaps_marginals_df\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'd78fbcd5', 'metadata': {}, 'outputs': [], 'source': 'display(laps_marginals_df)\\nlaps_marginals_df.to_html()'}, {'cell_type': 'code', 'execution_count': None, 'id': 'd73c79d1', 'metadata': {}, 'outputs': [], 'source': '## Local computation: check laps\\nlaps = curr_active_pipeline.sess.laps\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '3f0d1e98', 'metadata': {}, 'outputs': [], 'source': 'np.arange(start=0.030, step=0.01, stop=0.10) # [0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]'}, {'cell_type': 'markdown', 'id': 'fc018065', 'metadata': {}, 'source': '# Call perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function'}, {'cell_type': 'code', 'execution_count': None, 'id': '82c6522e', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': '# from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function\\n\\nBATCH_DATE_TO_USE: str = \\'2024-02-02_Lab\\' # TODO: Change this as needed, templating isn\\'t actually doing anything rn.\\n# collected_outputs_path = Path(\\'/nfs/turbo/umms-kdiba/Data/Output/collected_outputs\\').resolve() # Linux\\n# collected_outputs_path: Path = Path(\\'/home/halechr/cloud/turbo/Data/Output/collected_outputs\\').resolve() # GreatLakes\\ncollected_outputs_path = Path(r\\'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\collected_outputs\\').resolve() # Apogee\\n\\n\\ndef perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(self, global_data_root_parent_path, curr_session_context, curr_session_basedir, curr_active_pipeline, across_session_results_extended_dict: dict, save_hdf=True, save_csvs=True) -> dict:\\n    print(f\\'<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\\')\\n    print(f\\'perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(curr_session_context: {curr_session_context}, curr_session_basedir: {str(curr_session_basedir)}, ...,across_session_results_extended_dict: {across_session_results_extended_dict})\\')\\n    from copy import deepcopy\\n    import numpy as np\\n    import pandas as pd\\n    from neuropy.utils.debug_helpers import parameter_sweeps\\n    from neuropy.core.laps import Laps\\n    from neuropy.utils.mixins.binning_helpers import find_minimum_time_bin_duration\\n    from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _check_result_laps_epochs_df_performance\\n    from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalMergedDecodersResult\\n    from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\\n\\n    # Export CSVs:\\n    def export_marginals_df_csv(marginals_df: pd.DataFrame, data_identifier_str: str, parent_output_path: Path, active_context):\\n        \"\"\" captures nothing\\n        \"\"\"\\n        # output_date_str: str = get_now_rounded_time_str()\\n        output_date_str: str = get_now_day_str()\\n        # parent_output_path: Path = Path(\\'output\\').resolve()\\n        # active_context = curr_active_pipeline.get_session_context()\\n        session_identifier_str: str = active_context.get_description()\\n        assert output_date_str is not None\\n        out_basename = \\'-\\'.join([output_date_str, session_identifier_str, data_identifier_str]) # \\'2024-01-04|kdiba_gor01_one_2006-6-09_1-22-43|(laps_marginals_df).csv\\'\\n        out_filename = f\"{out_basename}.csv\"\\n        out_path = parent_output_path.joinpath(out_filename).resolve()\\n        marginals_df.to_csv(out_path)\\n        return out_path \\n\\n\\n    def _subfn_process_time_bin_swept_results(curr_active_pipeline, output_extracted_result_tuples):\\n        \"\"\" After the sweeps are complete and multiple (one for each time_bin_size swept) indepdnent dfs are had with the four results types this function concatenates each of the four into a single dataframe for all time_bin_size values with a column \\'time_bin_size\\'. \\n        It also saves them out to CSVs in a manner similar to what `compute_and_export_marginals_dfs_completion_function` did to be compatible with `2024-01-23 - Across Session Point and YellowBlue Marginal CSV Exports.ipynb`\\n        Captures: save_csvs\\n        \\n        \\n        \"\"\"\\n        several_time_bin_sizes_laps_time_bin_marginals_df_list = []\\n        several_time_bin_sizes_laps_per_epoch_marginals_df_list = []\\n\\n        several_time_bin_sizes_ripple_time_bin_marginals_df_list = []\\n        several_time_bin_sizes_ripple_per_epoch_marginals_df_list = []\\n\\n\\n        # for a_sweep_tuple, (a_laps_time_bin_marginals_df, a_laps_all_epoch_bins_marginals_df) in output_extracted_result_tuples.items():\\n        for a_sweep_tuple, (a_laps_time_bin_marginals_df, a_laps_all_epoch_bins_marginals_df, a_ripple_time_bin_marginals_df, a_ripple_all_epoch_bins_marginals_df) in output_extracted_result_tuples.items():\\n            a_sweep_dict = dict(a_sweep_tuple)\\n            \\n            # Shared\\n            desired_laps_decoding_time_bin_size = float(a_sweep_dict[\\'desired_shared_decoding_time_bin_size\\'])\\n            desired_ripple_decoding_time_bin_size = float(a_sweep_dict[\\'desired_shared_decoding_time_bin_size\\'])\\n            \\n            # a_laps_time_bin_marginals_df.\\n            df = a_laps_time_bin_marginals_df\\n            df[\\'time_bin_size\\'] = desired_laps_decoding_time_bin_size # desired_laps_decoding_time_bin_size\\n            # df[\\'session_name\\'] = session_name\\n            df = a_laps_all_epoch_bins_marginals_df\\n            df[\\'time_bin_size\\'] = desired_laps_decoding_time_bin_size\\n\\n            df = a_ripple_time_bin_marginals_df\\n            df[\\'time_bin_size\\'] = desired_ripple_decoding_time_bin_size\\n            df = a_ripple_all_epoch_bins_marginals_df\\n            df[\\'time_bin_size\\'] = desired_ripple_decoding_time_bin_size\\n\\n            several_time_bin_sizes_laps_time_bin_marginals_df_list.append(a_laps_time_bin_marginals_df)\\n            several_time_bin_sizes_laps_per_epoch_marginals_df_list.append(a_laps_all_epoch_bins_marginals_df)\\n            \\n            several_time_bin_sizes_ripple_time_bin_marginals_df_list.append(a_ripple_time_bin_marginals_df)\\n            several_time_bin_sizes_ripple_per_epoch_marginals_df_list.append(a_ripple_all_epoch_bins_marginals_df)\\n\\n\\n        ## Build across_sessions join dataframes:\\n        several_time_bin_sizes_time_bin_laps_df: pd.DataFrame = pd.concat(several_time_bin_sizes_laps_time_bin_marginals_df_list, axis=\\'index\\', ignore_index=True)\\n        several_time_bin_sizes_laps_df: pd.DataFrame = pd.concat(several_time_bin_sizes_laps_per_epoch_marginals_df_list, axis=\\'index\\', ignore_index=True) # per epoch\\n\\n        several_time_bin_sizes_time_bin_ripple_df: pd.DataFrame = pd.concat(several_time_bin_sizes_ripple_time_bin_marginals_df_list, axis=\\'index\\', ignore_index=True)\\n        several_time_bin_sizes_ripple_df: pd.DataFrame = pd.concat(several_time_bin_sizes_ripple_per_epoch_marginals_df_list, axis=\\'index\\', ignore_index=True) # per epoch\\n\\n        # Export time_bin_swept results to CSVs:\\n        if save_csvs:\\n            assert collected_outputs_path.exists()\\n            active_context = curr_active_pipeline.get_session_context()\\n            laps_time_bin_marginals_out_path = export_marginals_df_csv(several_time_bin_sizes_time_bin_laps_df, data_identifier_str=f\\'(laps_time_bin_marginals_df)\\', parent_output_path=collected_outputs_path, active_context=active_context)\\n            laps_out_path = export_marginals_df_csv(several_time_bin_sizes_laps_df, data_identifier_str=f\\'(laps_marginals_df)\\', parent_output_path=collected_outputs_path, active_context=active_context)\\n            ripple_time_bin_marginals_out_path = export_marginals_df_csv(several_time_bin_sizes_time_bin_ripple_df, data_identifier_str=f\\'(ripple_time_bin_marginals_df)\\', parent_output_path=collected_outputs_path, active_context=active_context)\\n            ripple_out_path = export_marginals_df_csv(several_time_bin_sizes_ripple_df, data_identifier_str=f\\'(ripple_marginals_df)\\', parent_output_path=collected_outputs_path, active_context=active_context)\\n        else:\\n            laps_time_bin_marginals_out_path, laps_out_path, ripple_time_bin_marginals_out_path, ripple_out_path = None, None, None, None\\n            \\n        return (several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path)\\n        # (several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path)\\n        \\n\\n\\n    def add_session_df_columns(df: pd.DataFrame, session_name: str, curr_session_t_delta: Optional[float], time_col: str) -> pd.DataFrame:\\n        \"\"\" adds session-specific information to the marginal dataframes \"\"\"\\n        df[\\'session_name\\'] = session_name \\n        if curr_session_t_delta is not None:\\n            df[\\'delta_aligned_start_t\\'] = df[time_col] - curr_session_t_delta\\n        return df\\n\\n\\n    ## Single decode:\\n    def _try_single_decode(owning_pipeline_reference, directional_merged_decoders_result, use_single_time_bin_per_epoch: bool, desired_laps_decoding_time_bin_size: Optional[float]=None, desired_ripple_decoding_time_bin_size: Optional[float]=None, desired_shared_decoding_time_bin_size: Optional[float]=None, minimum_event_duration: Optional[float]=None):\\n        \"\"\" decodes laps and ripples for a single bin size. \\n        \\n        minimum_event_duration: if provided, excludes all events shorter than minimum_event_duration\\n        \"\"\"\\n        if desired_shared_decoding_time_bin_size is not None:\\n            assert desired_laps_decoding_time_bin_size is None\\n            assert desired_ripple_decoding_time_bin_size is None\\n            desired_laps_decoding_time_bin_size = desired_shared_decoding_time_bin_size\\n            desired_ripple_decoding_time_bin_size = desired_shared_decoding_time_bin_size\\n            \\n\\n        ## Decode Laps:\\n        laps_epochs_df = deepcopy(directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result.filter_epochs)\\n        if not isinstance(laps_epochs_df, pd.DataFrame):\\n            laps_epochs_df = laps_epochs_df.to_dataframe()\\n        # global_any_laps_epochs_obj = deepcopy(owning_pipeline_reference.computation_results[global_epoch_name].computation_config.pf_params.computation_epochs) # global_epoch_name=\\'maze_any\\' (? same as global_epoch_name?)\\n        min_possible_laps_time_bin_size: float = find_minimum_time_bin_duration(laps_epochs_df[\\'duration\\'].to_numpy())\\n        min_bounded_laps_decoding_time_bin_size: float = min(desired_laps_decoding_time_bin_size, min_possible_laps_time_bin_size) # 10ms # 0.002\\n        if desired_laps_decoding_time_bin_size < min_bounded_laps_decoding_time_bin_size:\\n            print(f\\'WARN: desired_laps_decoding_time_bin_size: {desired_laps_decoding_time_bin_size} < min_bounded_laps_decoding_time_bin_size: {min_bounded_laps_decoding_time_bin_size}... hopefully it works.\\')\\n        laps_decoding_time_bin_size: float = desired_laps_decoding_time_bin_size # allow direct use\\n        if use_single_time_bin_per_epoch:\\n            laps_decoding_time_bin_size = None\\n        directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result = directional_merged_decoders_result.all_directional_pf1D_Decoder.decode_specific_epochs(spikes_df=deepcopy(owning_pipeline_reference.sess.spikes_df), filter_epochs=laps_epochs_df,\\n                                                                                                                                                        decoding_time_bin_size=laps_decoding_time_bin_size, use_single_time_bin_per_epoch=use_single_time_bin_per_epoch, debug_print=False)\\n        \\n\\n        ## Decode Ripples:\\n        if desired_ripple_decoding_time_bin_size is not None:\\n            # global_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(owning_pipeline_reference.filtered_sessions[global_epoch_name].replay))\\n            replay_epochs_df = deepcopy(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result.filter_epochs)\\n            if not isinstance(replay_epochs_df, pd.DataFrame):\\n                replay_epochs_df = replay_epochs_df.to_dataframe()\\n            # min_possible_ripple_time_bin_size: float = find_minimum_time_bin_duration(replay_epochs_df[\\'duration\\'].to_numpy())\\n            # min_bounded_ripple_decoding_time_bin_size: float = min(desired_ripple_decoding_time_bin_size, min_possible_ripple_time_bin_size) # 10ms # 0.002\\n            # if desired_ripple_decoding_time_bin_size < min_bounded_ripple_decoding_time_bin_size:\\n            #     print(f\\'WARN: desired_ripple_decoding_time_bin_size: {desired_ripple_decoding_time_bin_size} < min_bounded_ripple_decoding_time_bin_size: {min_bounded_ripple_decoding_time_bin_size}... hopefully it works.\\')\\n            ripple_decoding_time_bin_size: float = desired_ripple_decoding_time_bin_size # allow direct use            \\n            ## Drop those less than the time bin duration\\n            print(f\\'DropShorterMode:\\')\\n            pre_drop_n_epochs = len(replay_epochs_df)\\n            if minimum_event_duration is not None:                \\n                replay_epochs_df = replay_epochs_df[replay_epochs_df[\\'duration\\'] > minimum_event_duration]\\n                post_drop_n_epochs = len(replay_epochs_df)\\n                n_dropped_epochs = post_drop_n_epochs - pre_drop_n_epochs\\n                print(f\\'\\\\tminimum_event_duration present (minimum_event_duration={minimum_event_duration}).\\\\n\\\\tdropping {n_dropped_epochs} that are shorter than our minimum_event_duration of {minimum_event_duration}.\\', end=\\'\\\\t\\')\\n            else:\\n                replay_epochs_df = replay_epochs_df[replay_epochs_df[\\'duration\\'] > desired_ripple_decoding_time_bin_size]\\n                post_drop_n_epochs = len(replay_epochs_df)\\n                n_dropped_epochs = post_drop_n_epochs - pre_drop_n_epochs\\n                print(f\\'\\\\tdropping {n_dropped_epochs} that are shorter than our ripple decoding time bin size of {desired_ripple_decoding_time_bin_size}\\', end=\\'\\\\t\\') \\n\\n            print(f\\'{post_drop_n_epochs} remain.\\')\\n            directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result = directional_merged_decoders_result.all_directional_pf1D_Decoder.decode_specific_epochs(spikes_df=deepcopy(owning_pipeline_reference.sess.spikes_df), filter_epochs=replay_epochs_df,\\n                                                                                                                                                                                            decoding_time_bin_size=ripple_decoding_time_bin_size, use_single_time_bin_per_epoch=use_single_time_bin_per_epoch, debug_print=False)\\n\\n        directional_merged_decoders_result.perform_compute_marginals()\\n        return directional_merged_decoders_result\\n        \\n\\n    def _update_result_laps(a_result: DecodedFilterEpochsResult, laps_df: pd.DataFrame) -> pd.DataFrame:\\n        \"\"\" captures nothing. Can reusing the same laps_df as it makes no modifications to it. \\n        \\n        e.g. a_result=output_alt_directional_merged_decoders_result[a_sweep_tuple]\\n        \"\"\"\\n        result_laps_epochs_df: pd.DataFrame = a_result.laps_epochs_df\\n        ## 2024-01-17 - Updates the `a_directional_merged_decoders_result.laps_epochs_df` with both the ground-truth values and the decoded predictions\\n        result_laps_epochs_df[\\'maze_id\\'] = laps_df[\\'maze_id\\'].to_numpy()[np.isin(laps_df[\\'lap_id\\'], result_laps_epochs_df[\\'lap_id\\'])] # this works despite the different size because of the index matching\\n        ## add the \\'is_LR_dir\\' groud-truth column in:\\n        result_laps_epochs_df[\\'is_LR_dir\\'] = laps_df[\\'is_LR_dir\\'].to_numpy()[np.isin(laps_df[\\'lap_id\\'], result_laps_epochs_df[\\'lap_id\\'])] # this works despite the different size because of the index matching\\n        \\n        laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir = a_result.laps_directional_marginals_tuple\\n        laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = a_result.laps_track_identity_marginals_tuple\\n        ## Add the decoded results to the laps df:\\n        result_laps_epochs_df[\\'is_most_likely_track_identity_Long\\'] = laps_is_most_likely_track_identity_Long\\n        result_laps_epochs_df[\\'is_most_likely_direction_LR\\'] = laps_is_most_likely_direction_LR_dir\\n        return result_laps_epochs_df\\n\\n    # BEGIN FUNCTION BODY ________________________________________________________________________________________________ #\\n    assert collected_outputs_path.exists()\\n    curr_session_name: str = curr_active_pipeline.session_name # \\'2006-6-08_14-26-15\\'\\n    CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\\n    print(f\\'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}\\')\\n\\n    active_context = curr_active_pipeline.get_session_context()\\n    session_ctxt_key:str = active_context.get_description(separator=\\'|\\', subset_includelist=IdentifyingContext._get_session_context_keys())\\n    \\n    ## INPUT PARAMETER: time_bin_size sweep paraemters\\n    desired_shared_decoding_time_bin_size = np.linspace(start=0.030, stop=0.10, num=6)\\n    \\n    # Shared time bin sizes\\n    # all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_sizes, use_single_time_bin_per_epoch=[False], desired_ripple_decoding_time_bin_size=[None])\\n    all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_shared_decoding_time_bin_size=desired_shared_decoding_time_bin_size, use_single_time_bin_per_epoch=[False], minimum_event_duration=[desired_shared_decoding_time_bin_size[-1]]) # with Ripples\\n    # len(all_param_sweep_options)\\n    \\n    ## Perfrom the computations:\\n\\n    # DirectionalMergedDecoders: Get the result after computation:\\n    ## Copy the default result:\\n    directional_merged_decoders_result: DirectionalMergedDecodersResult = curr_active_pipeline.global_computation_results.computed_data[\\'DirectionalMergedDecoders\\']\\n    alt_directional_merged_decoders_result: DirectionalMergedDecodersResult = deepcopy(directional_merged_decoders_result)\\n\\n    # out_path_basename_str: str = f\"{now_day_str}_{active_context}_time_bin_size-{laps_decoding_time_bin_size}_{data_identifier_str}\"\\n    # out_path_basename_str: str = f\"{now_day_str}_{active_context}_time_bin_size_sweep_results\"\\n    out_path_basename_str: str = f\"{CURR_BATCH_OUTPUT_PREFIX}_time_bin_size_sweep_results\"\\n    # out_path_filenname_str: str = f\"{out_path_basename_str}.csv\"\\n\\n    out_path_filenname_str: str = f\"{out_path_basename_str}.h5\"\\n    out_path: Path = collected_outputs_path.resolve().joinpath(out_path_filenname_str).resolve()\\n    print(f\\'\\\\out_path_str: \"{out_path_filenname_str}\"\\')\\n    print(f\\'\\\\tout_path: \"{out_path}\"\\')\\n    \\n    # Ensure it has the \\'lap_track\\' column\\n    ## Compute the ground-truth information using the position information:\\n    # adds columns: [\\'maze_id\\', \\'is_LR_dir\\']\\n    t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\\n    laps_obj: Laps = curr_active_pipeline.sess.laps\\n    laps_obj.update_lap_dir_from_smoothed_velocity(pos_input=curr_active_pipeline.sess.position)\\n    laps_obj.update_maze_id_if_needed(t_start=t_start, t_delta=t_delta, t_end=t_end)\\n    laps_df = laps_obj.to_dataframe()\\n    \\n    # Uses: session_ctxt_key, all_param_sweep_options\\n    output_alt_directional_merged_decoders_result = {} # empty dict\\n    output_laps_decoding_accuracy_results_dict = {} # empty dict\\n    output_extracted_result_tuples = {}\\n\\n    for a_sweep_dict in all_param_sweep_options:\\n        a_sweep_tuple = frozenset(a_sweep_dict.items())\\n        print(f\\'a_sweep_dict: {a_sweep_dict}\\')\\n        # Convert parameters to string because Parquet supports metadata as string\\n        a_sweep_str_params = {key: str(value) for key, value in a_sweep_dict.items() if value is not None}\\n        \\n        output_alt_directional_merged_decoders_result[a_sweep_tuple] = _try_single_decode(curr_active_pipeline, alt_directional_merged_decoders_result, **a_sweep_dict)\\n\\n        laps_time_bin_marginals_df: pd.DataFrame = output_alt_directional_merged_decoders_result[a_sweep_tuple].laps_time_bin_marginals_df.copy()\\n        laps_all_epoch_bins_marginals_df: pd.DataFrame = output_alt_directional_merged_decoders_result[a_sweep_tuple].laps_all_epoch_bins_marginals_df.copy()\\n        \\n        ## Ripples:\\n        ripple_time_bin_marginals_df: pd.DataFrame = output_alt_directional_merged_decoders_result[a_sweep_tuple].ripple_time_bin_marginals_df.copy()\\n        ripple_all_epoch_bins_marginals_df: pd.DataFrame = output_alt_directional_merged_decoders_result[a_sweep_tuple].ripple_all_epoch_bins_marginals_df.copy()\\n\\n        session_name = curr_session_name\\n        curr_session_t_delta = t_delta\\n        \\n        for a_df, a_time_bin_column_name in zip((laps_time_bin_marginals_df, laps_all_epoch_bins_marginals_df, ripple_time_bin_marginals_df, ripple_all_epoch_bins_marginals_df), (\\'t_bin_center\\', \\'lap_start_t\\', \\'t_bin_center\\', \\'ripple_start_t\\')):\\n            ## Add the session-specific columns:\\n            a_df = add_session_df_columns(a_df, session_name, curr_session_t_delta, a_time_bin_column_name)\\n\\n        ## Build the output tuple:\\n        output_extracted_result_tuples[a_sweep_tuple] = (laps_time_bin_marginals_df, laps_all_epoch_bins_marginals_df, ripple_time_bin_marginals_df, ripple_all_epoch_bins_marginals_df)\\n        \\n        # desired_laps_decoding_time_bin_size_str: str = a_sweep_str_params.get(\\'desired_laps_decoding_time_bin_size\\', None)\\n        laps_decoding_time_bin_size: float = output_alt_directional_merged_decoders_result[a_sweep_tuple].laps_decoding_time_bin_size\\n        # ripple_decoding_time_bin_size: float = output_alt_directional_merged_decoders_result[a_sweep_tuple].ripple_decoding_time_bin_size\\n        actual_laps_decoding_time_bin_size_str: str = str(laps_decoding_time_bin_size)\\n        if save_hdf and (actual_laps_decoding_time_bin_size_str is not None):\\n            laps_time_bin_marginals_df.to_hdf(out_path, key=f\\'{session_ctxt_key}/{actual_laps_decoding_time_bin_size_str}/laps_time_bin_marginals_df\\', format=\\'table\\', data_columns=True)\\n            laps_all_epoch_bins_marginals_df.to_hdf(out_path, key=f\\'{session_ctxt_key}/{actual_laps_decoding_time_bin_size_str}/laps_all_epoch_bins_marginals_df\\', format=\\'table\\', data_columns=True)\\n\\n        ## TODO: output ripple .h5 here if desired.\\n            \\n\\n        # get the current lap object and determine the percentage correct:\\n        result_laps_epochs_df: pd.DataFrame = _update_result_laps(a_result=output_alt_directional_merged_decoders_result[a_sweep_tuple], laps_df=laps_df)\\n        (is_decoded_track_correct, is_decoded_dir_correct, are_both_decoded_properties_correct), (percent_laps_track_identity_estimated_correctly, percent_laps_direction_estimated_correctly, percent_laps_estimated_correctly) = _check_result_laps_epochs_df_performance(result_laps_epochs_df)\\n        output_laps_decoding_accuracy_results_dict[laps_decoding_time_bin_size] = (percent_laps_track_identity_estimated_correctly, percent_laps_direction_estimated_correctly, percent_laps_estimated_correctly)\\n        \\n\\n    ## Output the performance:\\n    output_laps_decoding_accuracy_results_df: pd.DataFrame = pd.DataFrame(output_laps_decoding_accuracy_results_dict.values(), index=output_laps_decoding_accuracy_results_dict.keys(), \\n                    columns=[\\'percent_laps_track_identity_estimated_correctly\\',\\n                            \\'percent_laps_direction_estimated_correctly\\',\\n                            \\'percent_laps_estimated_correctly\\'])\\n    output_laps_decoding_accuracy_results_df.index.name = \\'laps_decoding_time_bin_size\\'\\n    ## Save out the laps peformance result\\n    if save_hdf:\\n        output_laps_decoding_accuracy_results_df.to_hdf(out_path, key=f\\'{session_ctxt_key}/laps_decoding_accuracy_results\\', format=\\'table\\', data_columns=True)\\n\\n    ## Call the subfunction to process the time_bin_size swept result and produce combined output dataframes:\\n    combined_multi_timebin_outputs_tuple = _subfn_process_time_bin_swept_results(curr_active_pipeline, output_extracted_result_tuples)\\n    # Unpacking:    \\n    # (several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\\n\\n    # add to output dict\\n    # across_session_results_extended_dict[\\'compute_and_export_marginals_dfs_completion_function\\'] = _out\\n    across_session_results_extended_dict[\\'perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function\\'] = (out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple)\\n    # can unpack like:\\n    (several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\\n\\n    print(f\\'>>\\\\t done with {curr_session_context}\\')\\n    print(f\\'>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\\')\\n    print(f\\'>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\\')\\n\\n    return across_session_results_extended_dict\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '773e9f51', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': '_across_session_results_extended_dict = {}'}, {'cell_type': 'code', 'execution_count': None, 'id': '6c0f6b31', 'metadata': {'notebookRunGroups': {'groupValue': ''}}, 'outputs': [], 'source': \"## Combine the output of `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\\n_across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(None, None,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tacross_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=False)\\nout_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\\n(several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '09a71abd', 'metadata': {}, 'outputs': [], 'source': '# get_file_pat\\ncollected_outputs_path'}, {'cell_type': 'code', 'execution_count': None, 'id': '97c0f606', 'metadata': {}, 'outputs': [], 'source': 'output_laps_decoding_accuracy_results_df'}, {'cell_type': 'code', 'execution_count': None, 'id': 'dd970d51', 'metadata': {}, 'outputs': [], 'source': 'import matplotlib.pyplot as plt\\n\\n# def plot_histograms( data_type: str, session_spec: str, data_results_df: pd.DataFrame, time_bin_duration_str: str ) -> None:\\n#     # get the pre-delta epochs\\n#     pre_delta_df = data_results_df[data_results_df[\\'delta_aligned_start_t\\'] <= 0]\\n#     post_delta_df = data_results_df[data_results_df[\\'delta_aligned_start_t\\'] > 0]\\n\\n#     descriptor_str: str = \\'|\\'.join([data_type, session_spec, time_bin_duration_str])\\n    \\n#     # plot pre-delta histogram\\n#     pre_delta_df.hist(column=\\'P_Long\\')\\n#     plt.title(f\\'{descriptor_str} - pre-$\\\\Delta$ time bins\\')\\n#     plt.show()\\n\\n#     # plot post-delta histogram\\n#     post_delta_df.hist(column=\\'P_Long\\')\\n#     plt.title(f\\'{descriptor_str} - post-$\\\\Delta$ time bins\\')\\n#     plt.show()\\n    \\n\\ndef plot_histograms(data_type: str, session_spec: str, data_results_df: pd.DataFrame, time_bin_duration_str: str) -> None:\\n    \"\"\" plots a stacked histogram of the many time-bin sizes \"\"\"\\n    # get the pre-delta epochs\\n    pre_delta_df = data_results_df[data_results_df[\\'delta_aligned_start_t\\'] <= 0]\\n    post_delta_df = data_results_df[data_results_df[\\'delta_aligned_start_t\\'] > 0]\\n\\n    descriptor_str: str = \\'|\\'.join([data_type, session_spec, time_bin_duration_str])\\n    \\n    # plot pre-delta histogram\\n    time_bin_sizes = pre_delta_df[\\'time_bin_size\\'].unique()\\n    \\n    figure_identifier: str = f\"{descriptor_str}_preDelta\"\\n    plt.figure(num=figure_identifier, clear=True, figsize=(6, 2))\\n    for time_bin_size in time_bin_sizes:\\n        df_tbs = pre_delta_df[pre_delta_df[\\'time_bin_size\\']==time_bin_size]\\n        df_tbs[\\'P_Long\\'].hist(alpha=0.5, label=str(time_bin_size)) \\n    \\n    plt.title(f\\'{descriptor_str} - pre-$\\\\Delta$ time bins\\')\\n    plt.legend()\\n    plt.show()\\n\\n    # plot post-delta histogram\\n    time_bin_sizes = post_delta_df[\\'time_bin_size\\'].unique()\\n    figure_identifier: str = f\"{descriptor_str}_postDelta\"\\n    plt.figure(num=figure_identifier, clear=True, figsize=(6, 2))\\n    for time_bin_size in time_bin_sizes:\\n        df_tbs = post_delta_df[post_delta_df[\\'time_bin_size\\']==time_bin_size]\\n        df_tbs[\\'P_Long\\'].hist(alpha=0.5, label=str(time_bin_size)) \\n    \\n    plt.title(f\\'{descriptor_str} - post-$\\\\Delta$ time bins\\')\\n    plt.legend()\\n    plt.show()\\n\\n# # You can use it like this:\\n# plot_histograms(\\'Laps\\', \\'All Sessions\\', all_sessions_laps_time_bin_df, \"75 ms\")\\n# plot_histograms(\\'Ripples\\', \\'All Sessions\\', all_sessions_ripple_time_bin_df, \"75 ms\")\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '49dd6f87', 'metadata': {}, 'outputs': [], 'source': 'import seaborn as sns\\nsns.set_theme(style=\"ticks\")\\ndef pho_jointplot(*args, **kwargs):\\n\\t\"\"\" wraps sns.jointplot to allow adding titles/axis labels/etc.\"\"\"\\n\\ttitle = kwargs.pop(\\'title\\', None)\\n\\t_out = sns.jointplot(*args, **kwargs)\\n\\tif title is not None:\\n\\t\\tplt.suptitle(title)\\n\\treturn _out\\n\\ncommon_kwargs = dict(ylim=(0,1), hue=\\'time_bin_size\\') # , marginal_kws=dict(bins=25, fill=True)\\n# sns.jointplot(data=a_laps_all_epoch_bins_marginals_df, x=\\'lap_start_t\\', y=\\'P_Long\\', kind=\"scatter\", color=\"#4CB391\")\\npho_jointplot(data=several_time_bin_sizes_laps_df, x=\\'delta_aligned_start_t\\', y=\\'P_Long\\', kind=\"scatter\", **common_kwargs, title=\\'Laps: per epoch\\') #color=\"#4CB391\")\\npho_jointplot(data=several_time_bin_sizes_ripple_df, x=\\'delta_aligned_start_t\\', y=\\'P_Long\\', kind=\"scatter\", **common_kwargs, title=\\'Ripple: per epoch\\')\\npho_jointplot(data=several_time_bin_sizes_time_bin_ripple_df, x=\\'delta_aligned_start_t\\', y=\\'P_Long\\', kind=\"scatter\", **common_kwargs, title=\\'Ripple: per time bin\\')\\npho_jointplot(data=several_time_bin_sizes_time_bin_laps_df, x=\\'delta_aligned_start_t\\', y=\\'P_Long\\', kind=\"scatter\", **common_kwargs, title=\\'Laps: per time bin\\')'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c43311ee', 'metadata': {}, 'outputs': [], 'source': '# You can use it like this:\\nplot_histograms(\\'Laps\\', \\'One Session\\', several_time_bin_sizes_time_bin_laps_df, \"several\")\\nplot_histograms(\\'Ripples\\', \\'One Session\\', several_time_bin_sizes_time_bin_ripple_df, \"several\")'}, {'cell_type': 'code', 'execution_count': None, 'id': '6a33b924', 'metadata': {}, 'outputs': [], 'source': 'several_time_bin_sizes_ripple_df'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e102212a', 'metadata': {}, 'outputs': [], 'source': '# sns.displot(\\n#     several_time_bin_sizes_laps_df, x=\"P_Long\", col=\"species\", row=\"time_bin_size\",\\n#     binwidth=3, height=3, facet_kws=dict(margin_titles=True),\\n# )\\n\\nsns.displot(\\n    several_time_bin_sizes_laps_df, x=\\'delta_aligned_start_t\\', y=\\'P_Long\\', row=\"time_bin_size\",\\n    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\\n)\\n'}, {'cell_type': 'markdown', 'id': 'be351c18', 'metadata': {}, 'source': '# 2024-01-31 - Reinvestigation regarding remapping'}, {'cell_type': 'code', 'execution_count': None, 'id': '911d7495', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': '## long_short_endcap_analysis:\\ntruncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\\ntruncation_checking_result'}, {'cell_type': 'code', 'execution_count': None, 'id': '1a5d9b54', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': \"jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\\nneuron_replay_stats_df = deepcopy(jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\\n\\n## try to add the 2D peak information to the cells in `neuron_replay_stats_df`:\\nneuron_replay_stats_df['long_pf2D_peak_x'] = pd.NA\\nneuron_replay_stats_df['short_pf2D_peak_x'] = pd.NA\\nneuron_replay_stats_df['long_pf2D_peak_y'] = pd.NA\\nneuron_replay_stats_df['short_pf2D_peak_y'] = pd.NA\\n\\n# flat_peaks_df: pd.DataFrame = deepcopy(active_peak_prominence_2d_results['flat_peaks_df']).reset_index(drop=True)\\nlong_filtered_flat_peaks_df: pd.DataFrame = deepcopy(curr_active_pipeline.computation_results[long_any_name].computed_data['RatemapPeaksAnalysis']['PeakProminence2D']['filtered_flat_peaks_df']).reset_index(drop=True)\\nshort_filtered_flat_peaks_df: pd.DataFrame = deepcopy(curr_active_pipeline.computation_results[short_any_name].computed_data['RatemapPeaksAnalysis']['PeakProminence2D']['filtered_flat_peaks_df']).reset_index(drop=True)\\n\\nneuron_replay_stats_df.loc[np.isin(neuron_replay_stats_df['aclu'].to_numpy(), long_filtered_flat_peaks_df.neuron_id.to_numpy()), ['long_pf2D_peak_x', 'long_pf2D_peak_y']] = long_filtered_flat_peaks_df[['peak_center_x', 'peak_center_y']].to_numpy()\\nneuron_replay_stats_df.loc[np.isin(neuron_replay_stats_df['aclu'].to_numpy(), short_filtered_flat_peaks_df.neuron_id.to_numpy()), ['short_pf2D_peak_x', 'short_pf2D_peak_y']] = short_filtered_flat_peaks_df[['peak_center_x', 'peak_center_y']].to_numpy()\\n\\nneuron_replay_stats_df\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'b4b93d4a', 'metadata': {}, 'outputs': [], 'source': \"['long_pf_peak_x']\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '2b798e45', 'metadata': {}, 'outputs': [], 'source': 'truncation_checking_result.disappearing_endcap_aclus'}, {'cell_type': 'code', 'execution_count': None, 'id': 'd6183ea2', 'metadata': {}, 'outputs': [], 'source': 'long_epoch_name\\n\\n# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\\n# (long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\\n# long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\\n# (long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\\n# (long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\\n# (long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\\n# (long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\\n# (long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\\n# (long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\\n\\n\\n# global_any_laps_epochs_obj\\nlong_LR_epochs_obj'}, {'cell_type': 'markdown', 'id': '1353b2f7', 'metadata': {}, 'source': '## NEXT 2024-01-31 - TODO - This is the perfect use of pf1D_dt'}, {'cell_type': 'code', 'execution_count': None, 'id': '504580c3', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': \"from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent\\nfrom pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import compute_spatial_binned_activity_via_pfdt\\nfrom pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import compute_trial_by_trial_correlation_matrix\\n\\n\\nif 'pf1D_dt' not in curr_active_pipeline.computation_results[global_epoch_name].computed_data:\\n\\t# if `KeyError: 'pf1D_dt'` recompute\\n\\tcurr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['pfdt_computation'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\\n\\n\\nactive_pf_1D_dt: PfND_TimeDependent = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf1D_dt'])\\nactive_pf_2D_dt: PfND_TimeDependent = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf2D_dt'])\\n\\n\\n## Single Global Laps version:\\nlaps_df = deepcopy(global_any_laps_epochs_obj.to_dataframe())\\nn_laps = len(laps_df)\\n\\nactive_pf_dt: PfND_TimeDependent = deepcopy(active_pf_1D_dt)\\n# active_pf_dt: PfND_TimeDependent = deepcopy(active_pf_2D_dt) # 2D\\n\\nactive_lap_pf_results_dict = compute_spatial_binned_activity_via_pfdt(active_pf_dt=active_pf_dt, epochs_df=laps_df)\\n# Unpack the variables:\\nhistorical_snapshots = active_lap_pf_results_dict['historical_snapshots']\\noccupancy_weighted_tuning_maps_matrix = active_lap_pf_results_dict['occupancy_weighted_tuning_maps'] # .shape: (n_epochs, n_aclus, n_xbins) - (84, 80, 56)\\n\\n# 2024-02-02 - Trial-by-trial Correlation Matrix C\\nC_trial_by_trial_correlation_matrix, z_scored_tuning_map_matrix, aclu_to_matrix_IDX_map = compute_trial_by_trial_correlation_matrix(active_pf_dt, occupancy_weighted_tuning_maps_matrix=occupancy_weighted_tuning_maps_matrix)\\nneuron_ids = np.array(list(aclu_to_matrix_IDX_map.keys()))\\n\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'e0499d39', 'metadata': {}, 'outputs': [], 'source': '# from pyphocorehelpers.programming_helpers import CodeConversion, GeneratedClassDefinitionType\\n# from pyphocorehelpers.programming_helpers import IPythonHelpers\\n\\n# CodeConversion.convert_dictionary_to_class_defn({\\'C_trial_by_trial_correlation_matrix\\':C_trial_by_trial_correlation_matrix, \\'z_scored_tuning_map_matrix\\':z_scored_tuning_map_matrix, \\'aclu_to_matrix_IDX_map\\':aclu_to_matrix_IDX_map},\\n# \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tclass_name=\\'TrialByTrialActivity\\', indent_character=\\'    \\', include_types=True, class_decorators=None, include_initializer_default_values=False)\\n\\n\\n# C_trial_by_trial_correlation_matrix, z_scored_tuning_map_matrix, aclu_to_matrix_IDX_map\\n\\n# result_dict_str_rep, result_dict = CodeConversion.convert_variable_tuple_code_to_dict_with_names(tuple_string=\"C_trial_by_trial_correlation_matrix, z_scored_tuning_map_matrix, aclu_to_matrix_IDX_map\")\\n# print(result_dict_str_rep)\\n\\n\\n# types_replace_dict = {}\\n# types_import_replace_dict = {}\\n\\n# types_replace_dict.update({\\'dict\\':\\'Dict\\'})\\n# types_import_replace_dict.update({\\'import dict\\':\\'from typings import Dict\\'})\\n\\n# types_replace_dict.update({\\'list\\':\\'List\\'})\\n# types_import_replace_dict.update({\\'import list\\':\\'from typings import List\\'})\\n\\n# types_replace_dict.update({\\'tuple\\':\\'Tuple\\'})\\n# types_import_replace_dict.update({\\'import tuple\\':\\'from typings import Tuple\\'})\\n\\n# types_replace_dict.update({\\'np.ndarray\\':\\'NDArray\\'})\\n# types_import_replace_dict.update({\\'import np.ndarray\\':\\'from nptypings import NDArray\\'})\\n\\n# types_import_replace_dict\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '2d89bfe1', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import TrialByTrialActivity'}, {'cell_type': 'code', 'execution_count': None, 'id': '42c1b668', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import TrialByTrialActivity, directional_compute_trial_by_trial_correlation_matrix\\n\\n\\nif 'pf1D_dt' not in curr_active_pipeline.computation_results[global_epoch_name].computed_data:\\n\\t# if `KeyError: 'pf1D_dt'` recompute\\n\\tcurr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['pfdt_computation'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\\n\\n\\nactive_pf_1D_dt: PfND_TimeDependent = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf1D_dt'])\\nactive_pf_2D_dt: PfND_TimeDependent = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf2D_dt'])\\n\\nactive_pf_dt: PfND_TimeDependent = deepcopy(active_pf_1D_dt)\\n# active_pf_dt: PfND_TimeDependent = deepcopy(active_pf_2D_dt) # 2D\\ndirectional_lap_epochs_dict = dict(zip((long_LR_name, long_RL_name, short_LR_name, short_RL_name), (long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj)))\\ndirectional_active_lap_pf_results_dicts = directional_compute_trial_by_trial_correlation_matrix(active_pf_dt=active_pf_dt, directional_lap_epochs_dict=directional_lap_epochs_dict)\\n\\n\\n# # Unpack the variables:\\n# historical_snapshots = active_lap_pf_results_dict['historical_snapshots']\\n# occupancy_weighted_tuning_maps_matrix = active_lap_pf_results_dict['occupancy_weighted_tuning_maps'] # .shape: (n_epochs, n_aclus, n_xbins) - (84, 80, 56)\\n\\n# directional_active_lap_pf_results_dicts[an_epoch_name] = compute_spatial_binned_activity_via_pfdt(active_pf_dt=active_pf_dt, epochs_df=active_laps_df)\\n\\n\"}, {'cell_type': 'markdown', 'id': '0ef13541', 'metadata': {}, 'source': '# 2024-02-02 - Trial-by-trial Correlation Matrix C'}, {'cell_type': 'code', 'execution_count': None, 'id': 'ad72df59', 'metadata': {'notebookRunGroups': {'groupValue': '1'}}, 'outputs': [], 'source': '\\n'}, {'cell_type': 'markdown', 'id': '1ddd735e', 'metadata': {}, 'source': '### 🎨 Show Trial-by-trial Correlation Matrix C in `napari`'}, {'cell_type': 'code', 'execution_count': None, 'id': 'a1f64b82', 'metadata': {}, 'outputs': [], 'source': 'import napari\\nfrom pyphoplacecellanalysis.GUI.Napari.napari_helpers import napari_from_layers_dict\\nfrom pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import napari_trial_by_trial_activity_viz\\nfrom pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import napari_export_image_sequence\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'f9934d4a', 'metadata': {}, 'outputs': [], 'source': \"\\n# viewer, image_layer_dict = napari_trial_by_trial_activity_viz(z_scored_tuning_map_matrix, C_trial_by_trial_correlation_matrix) # GLOBAL\\nviewer, image_layer_dict = napari_trial_by_trial_activity_viz(z_scored_tuning_map_matrix, C_trial_by_trial_correlation_matrix, title='Trial-by-trial Correlation Matrix C', axis_labels=('aclu', 'lap', 'xbin'))\"}, {'cell_type': 'code', 'execution_count': None, 'id': '50c8c115', 'metadata': {}, 'outputs': [], 'source': '## Directional\\ndef napari_plot_trial_by_trial_activity_viz(directional_active_lap_pf_results_dicts):\\n\\t\"\"\" \\n\\t\\n\\t\"\"\"\\n\\tcustom_direction_split_layers_dict = {}\\n\\tlayers_list_sort_order = [\\'maze1_odd_z_scored_tuning_maps\\', \\'maze1_odd_C_trial_by_trial_correlation_matrix\\', \\n\\t\\'maze1_even_z_scored_tuning_maps\\', \\'maze1_even_C_trial_by_trial_correlation_matrix\\',\\n\\t\\'maze2_odd_z_scored_tuning_maps\\', \\'maze2_odd_C_trial_by_trial_correlation_matrix\\', \\n\\t\\'maze2_even_z_scored_tuning_maps\\', \\'maze2_even_C_trial_by_trial_correlation_matrix\\']\\n\\n\\t## Build the image data layers for each\\n\\t# for an_epoch_name, (active_laps_df, C_trial_by_trial_correlation_matrix, z_scored_tuning_map_matrix, aclu_to_matrix_IDX_map, neuron_ids) in directional_active_lap_pf_results_dicts.items():\\n\\tfor an_epoch_name, active_trial_by_trial_activity_obj in directional_active_lap_pf_results_dicts.items():\\n\\t\\t# (active_laps_df, C_trial_by_trial_correlation_matrix, z_scored_tuning_map_matrix, aclu_to_matrix_IDX_map, neuron_ids)\\n\\t\\tz_scored_tuning_map_matrix = active_trial_by_trial_activity_obj.z_scored_tuning_map_matrix\\n\\t\\tC_trial_by_trial_correlation_matrix = active_trial_by_trial_activity_obj.C_trial_by_trial_correlation_matrix\\n\\t\\tcustom_direction_split_layers_dict[f\\'{an_epoch_name}_z_scored_tuning_maps\\'] = dict(blending=\\'translucent\\', colormap=\\'viridis\\', name=f\\'{an_epoch_name}_z_scored_tuning_maps\\', img_data=z_scored_tuning_map_matrix.transpose(1, 0, 2)) # reshape to be compatibile with C_i\\'s dimensions\\n\\t\\tcustom_direction_split_layers_dict[f\\'{an_epoch_name}_C_trial_by_trial_correlation_matrix\\'] = dict(blending=\\'translucent\\', colormap=\\'viridis\\', name=f\\'{an_epoch_name}_C_trial_by_trial_correlation_matrix\\', img_data=C_trial_by_trial_correlation_matrix)\\n\\n\\t# custom_direction_split_layers_dict\\n\\n\\t# directional_viewer, directional_image_layer_dict = napari_trial_by_trial_activity_viz(None, None, layers_dict=custom_direction_split_layers_dict)\\n\\n\\t## sort the layers dict:\\n\\tcustom_direction_split_layers_dict = {k:custom_direction_split_layers_dict[k] for k in reversed(layers_list_sort_order)}\\n\\n\\tdirectional_viewer, directional_image_layer_dict = napari_from_layers_dict(layers_dict=custom_direction_split_layers_dict, title=\\'Directioanl Trial-by-Trial Activity\\', axis_labels=(\\'aclu\\', \\'lap\\', \\'xbin\\'))\\n\\tdirectional_viewer.grid.shape = (-1, 4)\\n\\n\\n\\treturn directional_viewer, directional_image_layer_dict, custom_direction_split_layers_dict\\n\\n\\ndirectional_viewer, directional_image_layer_dict, custom_direction_split_layers_dict = napari_plot_trial_by_trial_activity_viz(directional_active_lap_pf_results_dicts)'}, {'cell_type': 'code', 'execution_count': None, 'id': 'b78ea6cd', 'metadata': {}, 'outputs': [], 'source': 'directional_viewer.grid # GridCanvas(stride=1, shape=(-1, 4), enabled=True)\\n\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '8fe73b59', 'metadata': {}, 'outputs': [], 'source': '\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '5b3cdbc9', 'metadata': {}, 'outputs': [], 'source': '# For the short track, upsample to a scale common with the long track.\\n\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '214d26bb', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.GUI.Napari.napari_helpers import napari_extract_layers_info\\nfrom pyphoplacecellanalysis.GUI.Napari.napari_helpers import extract_layer_info\\nfrom napari.layers import Shapes, Image, base\\n\\n\\nlayers = directional_viewer.layers # [<Shapes layer 'Shapes' at 0x1635a1e8460>, <Shapes layer 'Shapes [1]' at 0x164d5402e50>]\\nout_layers_info_dict = debug_print_layers_info(layers)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '974bfbd6', 'metadata': {}, 'outputs': [], 'source': 'list(out_layers_info_dict.keys())\\n# list(directional_viewer.layers.keys())\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c8ed6dc9', 'metadata': {}, 'outputs': [], 'source': '\\n# grid properties:\\n(1, 4, -1)\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '8782d0a0', 'metadata': {}, 'outputs': [], 'source': ''}, {'cell_type': 'code', 'execution_count': None, 'id': '05139ee9', 'metadata': {}, 'outputs': [], 'source': 'viewer'}, {'cell_type': 'code', 'execution_count': None, 'id': 'fd70d44d', 'metadata': {}, 'outputs': [], 'source': \"{'maze1_odd_z_scored_tuning_maps': {'positioning': {'scale': array([1, 1, 1]),\\n   'translate': array([0, 0, 0]),\\n   'rotate': array([[1, 0, 0],\\n          [0, 1, 0],\\n          [0, 0, 1]]),\\n   'shear': array([0, 0, 0]),\\n   'affine': <napari.utils.transforms.transforms.Affine object at 0x0000028443614580>,\\n   'corner_pixels': array([[ 0,  0,  0],\\n          [ 0, 22, 56]])}},\\n 'maze1_odd_C_trial_by_trial_correlation_matrix': {'positioning': {'scale': array([1, 1, 1]),\\n   'translate': array([0, 0, 0]),\\n   'rotate': array([[1, 0, 0],\\n          [0, 1, 0],\\n          [0, 0, 1]]),\\n   'shear': array([0, 0, 0]),\\n   'affine': <napari.utils.transforms.transforms.Affine object at 0x0000028449702910>,\\n   'corner_pixels': array([[ 0,  0,  0],\\n          [ 0, 22, 22]])}},\\n 'maze1_even_z_scored_tuning_maps': {'positioning': {'scale': array([1, 1, 1]),\\n   'translate': array([0, 0, 0]),\\n   'rotate': array([[1, 0, 0],\\n          [0, 1, 0],\\n          [0, 0, 1]]),\\n   'shear': array([0, 0, 0]),\\n   'affine': <napari.utils.transforms.transforms.Affine object at 0x00000284776C50A0>,\\n   'corner_pixels': array([[ 0,  0,  0],\\n          [ 0, 22, 56]])}},\\n 'maze1_even_C_trial_by_trial_correlation_matrix': {'positioning': {'scale': array([1, 1, 1]),\\n   'translate': array([0, 0, 0]),\\n   'rotate': array([[1, 0, 0],\\n          [0, 1, 0],\\n          [0, 0, 1]]),\\n   'shear': array([0, 0, 0]),\\n   'affine': <napari.utils.transforms.transforms.Affine object at 0x000002847786E3D0>,\\n   'corner_pixels': array([[ 0,  0,  0],\\n          [ 0, 22, 22]])}},\\n 'maze2_odd_z_scored_tuning_maps': {'positioning': {'scale': array([1, 1, 1]),\\n   'translate': array([0, 0, 0]),\\n   'rotate': array([[1, 0, 0],\\n          [0, 1, 0],\\n          [0, 0, 1]]),\\n   'shear': array([0, 0, 0]),\\n   'affine': <napari.utils.transforms.transforms.Affine object at 0x000002847794C9D0>,\\n   'corner_pixels': array([[ 0,  0,  0],\\n          [ 0, 20, 56]])}},\\n 'maze2_odd_C_trial_by_trial_correlation_matrix': {'positioning': {'scale': array([1, 1, 1]),\\n   'translate': array([0, 0, 0]),\\n   'rotate': array([[1, 0, 0],\\n          [0, 1, 0],\\n          [0, 0, 1]]),\\n   'shear': array([0, 0, 0]),\\n   'affine': <napari.utils.transforms.transforms.Affine object at 0x000002840D616280>,\\n   'corner_pixels': array([[ 0,  0,  0],\\n          [ 0, 20, 20]])}},\\n 'maze2_even_z_scored_tuning_maps': {'positioning': {'scale': array([1, 1, 1]),\\n   'translate': array([0, 0, 0]),\\n   'rotate': array([[1, 0, 0],\\n          [0, 1, 0],\\n          [0, 0, 1]]),\\n   'shear': array([0, 0, 0]),\\n   'affine': <napari.utils.transforms.transforms.Affine object at 0x000002842EAB94F0>,\\n   'corner_pixels': array([[ 0,  0,  0],\\n          [ 0, 20, 56]])}},\\n 'maze2_even_C_trial_by_trial_correlation_matrix': {'positioning': {'scale': array([1, 1, 1]),\\n   'translate': array([0, 0, 0]),\\n   'rotate': array([[1, 0, 0],\\n          [0, 1, 0],\\n          [0, 0, 1]]),\\n   'shear': array([0, 0, 0]),\\n   'affine': <napari.utils.transforms.transforms.Affine object at 0x000002840D916610>,\\n   'corner_pixels': array([[ 0,  0,  0],\\n          [ 0, 20, 20]])}}}\"}, {'cell_type': 'code', 'execution_count': None, 'id': '214581dc', 'metadata': {}, 'outputs': [], 'source': \"a_shapes_layer: Shapes = layers['ShapeBlue']\\na_shapes_layer.translate = np.array([0, 10]) # y-position is first for some reason? [10, 0]: moves down 10 units. [0, 10] moves right 10 units.\"}, {'cell_type': 'markdown', 'id': 'fd6f61fa', 'metadata': {}, 'source': '# Napari Plotting Long/Short Track'}, {'cell_type': 'code', 'execution_count': None, 'id': '80146cd1', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.Pho2D.track_shape_drawing import test_LinearTrackDimensions_2D_pyqtgraph, LinearTrackDimensions, LinearTrackInstance\\n\\nlong_track_dims = LinearTrackDimensions(track_length=170.0)\\nshort_track_dims = LinearTrackDimensions(track_length=100.0)'}, {'cell_type': 'code', 'execution_count': None, 'id': '5e63a7e5', 'metadata': {}, 'outputs': [], 'source': '## Get grid_bin_bounds:\\nlong_grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\\nshort_grid_bin_bounds = deepcopy(short_pf2D.config.grid_bin_bounds)\\n\\nlong_grid_bin_bounds\\nshort_grid_bin_bounds\\nlinear_track_instance = LinearTrackInstance.init_from_grid_bin_bounds(grid_bin_bounds=long_grid_bin_bounds)\\nlinear_track_instance'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e26c59b7', 'metadata': {}, 'outputs': [], 'source': '\\napp, w, cw, (long_track_dims, long_rect_items, long_rects), (short_track_dims, short_rect_items, short_rects) = test_LinearTrackDimensions_2D_pyqtgraph()'}, {'cell_type': 'code', 'execution_count': None, 'id': '40aeb712', 'metadata': {}, 'outputs': [], 'source': \"## Napari Shapes Layer Test:\\nfrom pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_napari_track_shapes_layer\\n\\n# add the image\\n# viewer = napari.view_image(data.camera(), name='photographer')\\n\\ntest_shapes_viewer = napari.Viewer() # name='Test Shapes Viewer'\\n# add the tracks\\nlong_rectangles_poly_shapes_layer, short_rectangles_poly_shapes_layer = add_napari_track_shapes_layer(test_shapes_viewer, long_rect_items, short_rect_items)\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'df06a3e6', 'metadata': {}, 'outputs': [], 'source': 'extract_layer_info(long_rectangles_poly_shapes_layer)\\nextract_layer_info(short_rectangles_poly_shapes_layer)'}, {'cell_type': 'code', 'execution_count': None, 'id': '8948d536', 'metadata': {}, 'outputs': [], 'source': '# long_rectangles_poly_shapes_layer.bounding_box\\n# long_rectangles_poly_shapes_layer.interaction_box\\nlong_rectangles_poly_shapes_layer.corner_pixels # np.array([[ 44, 124], [376, 161]])\\n# long_rectangles_poly_shapes_layer.frame\\n\\n\\n# long_rectangles_poly_shapes_layer.rotate = 90\\n# data_to_world, world_to_data'}, {'cell_type': 'code', 'execution_count': None, 'id': '67d1eadc', 'metadata': {}, 'outputs': [], 'source': 'short_rectangles_poly_shapes_layer.rotate = 90'}, {'cell_type': 'code', 'execution_count': None, 'id': '83d701b6', 'metadata': {}, 'outputs': [], 'source': 'a_display_config_man = LongShortDisplayConfigManager()\\na_display_config_man.long_epoch_config.mpl_color\\n\\n# a_display_config_man.'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c924c07f', 'metadata': {}, 'outputs': [], 'source': \"# add polygons\\nlong_rectangles_poly_shapes_layer = test_shapes_viewer.add_shapes(long_extracted_poly_verticies, shape_type='polygon', edge_width=3, edge_color='class', face_color='royalblue', text='Long Track', name='poly_track')\\n# change some attributes of the layer\\nlong_rectangles_poly_shapes_layer.opacity = 1\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '32774822', 'metadata': {}, 'outputs': [], 'source': \"short_rectangles_poly_shapes_layer = test_shapes_viewer.add_shapes(short_extracted_poly_verticies, shape_type='polygon', edge_width=3, edge_color='class', face_color='crimsonred', text='Short Track', name='ShortTrack')\\n# change some attributes of the layer\\nshort_rectangles_poly_shapes_layer.opacity = 1\"}, {'cell_type': 'code', 'execution_count': None, 'id': '9546a4dc', 'metadata': {}, 'outputs': [], 'source': \"# Define coordinates for a rectangle\\ntop_left = np.array([20, 20])\\nbottom_right = np.array([80, 80])\\nrectangle_coords = np.array([top_left, bottom_right])\\n\\n# Create a new shape layer and add a rectangle\\nsimple_test_shape_layer = test_shapes_viewer.add_shapes(rectangle_coords, shape_type='rectangle', edge_color='blue', face_color='red')\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '115475fe', 'metadata': {}, 'outputs': [], 'source': \"import numpy as np\\nfrom skimage import data\\n\\nimport napari\\n\\n# add the image\\nviewer = napari.view_image(data.camera(), name='photographer')\\n\\n# create a list of polygons\\npolygons = [\\n    np.array([[225, 146], [283, 146], [283, 211], [225, 211]]),\\n    np.array([[67, 182], [167, 182], [167, 268], [67, 268]]),\\n    np.array([[111, 336], [220, 336], [220, 240], [111, 240]]),\\n]\\n# polygons[0] # .shape: (4, 2)\\n\\n# create features\\nfeatures = {\\n    'likelihood': [21.23423, 51.2315, 100],\\n    'class': ['hand', 'face', 'camera'],\\n}\\nedge_color_cycle = ['blue', 'magenta', 'green']\\n\\ntext = {\\n    'string': '{class}: {likelihood:0.1f}%',\\n    'anchor': 'upper_left',\\n    'translation': [-5, 0],\\n    'size': 8,\\n    'color': 'green',\\n}\\n\\n# add polygons\\nshapes_layer = viewer.add_shapes(\\n    polygons,\\n    features=features,\\n    shape_type='polygon',\\n    edge_width=3,\\n    edge_color='class',\\n    edge_color_cycle=edge_color_cycle,\\n    face_color='transparent',\\n    text=text,\\n    name='shapes',\\n)\\n\\n# change some attributes of the layer\\nshapes_layer.opacity = 1\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'f16fba7d', 'metadata': {}, 'outputs': [], 'source': ''}, {'cell_type': 'code', 'execution_count': None, 'id': '5dafedcb', 'metadata': {}, 'outputs': [], 'source': \"# create the list of polygons\\ntriangle = np.array([[11, 13], [111, 113], [22, 246]])\\n\\nperson = np.array([[505, 60], [402, 71], [383, 42], [251, 95], [212, 59],\\n                   [131, 137], [126, 187], [191, 204], [171, 248], [211, 260],\\n                   [273, 243], [264, 225], [430, 173], [512, 160]])\\n\\nbuilding = np.array([[310, 382], [229, 381], [209, 401], [221, 411],\\n                     [258, 411], [300, 412], [306, 435], [268, 434],\\n                     [265, 454], [298, 461], [307, 461], [307, 507],\\n                     [349, 510], [352, 369], [330, 366], [330, 366]])\\n\\npolygons = [triangle, person, building]\\n# add the polygons\\nshapes_layer = test_shapes_viewer.add_shapes(polygons, shape_type='polygon', edge_width=5, edge_color='coral', face_color='royalblue', name='test shapes')\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '1cc5c8e1', 'metadata': {}, 'outputs': [], 'source': 'for a_rect in long_rects:\\n\\tpass\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c45358ac', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines\\n\\ngrid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\\nlong_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=None)'}, {'cell_type': 'code', 'execution_count': None, 'id': 'b96494ee', 'metadata': {}, 'outputs': [], 'source': '\\n\\n[np.array([[39, 115.177, 26.5031],\\n        [39, 115.177, 39.1986],\\n        [39, 125.383, 39.1986],\\n        [39, 125.383, 26.5031]]),\\n np.array([[39, 115.608, 63.5726],\\n        [39, 115.608, 75.8572],\\n        [39, 126.168, 75.8572],\\n        [39, 126.168, 63.5726]]),\\n np.array([[39, 117.979, 36.8481],\\n        [39, 117.979, 65.5123],\\n        [39, 123.151, 65.5123],\\n        [39, 123.151, 36.8481]])]'}, {'cell_type': 'code', 'execution_count': None, 'id': 'd5754f69', 'metadata': {}, 'outputs': [], 'source': ''}, {'cell_type': 'code', 'execution_count': None, 'id': '56996786', 'metadata': {}, 'outputs': [], 'source': ''}, {'cell_type': 'code', 'execution_count': None, 'id': 'af347488', 'metadata': {}, 'outputs': [], 'source': '## #TODO 2024-02-02 22:31: - [ ] These need to be update for global support\\ndef on_update_slider(event):\\n    \"\"\" captures: neuron_ids\\n    \\n    Adds a little text label to the bottom right corner\\n    \\n    \"\"\"\\n    # only trigger if update comes from first axis (optional)\\n    # print(\\'inside\\')\\n    #ind_lambda = viewer.dims.indices[0]\\n\\n    time = viewer.dims.current_step[0]\\n    matrix_aclu_IDX = int(time)\\n    # find the aclu value for this index:\\n    aclu: int = neuron_ids[matrix_aclu_IDX]\\n    viewer.text_overlay.text = f\"aclu: {aclu}, IDX: {matrix_aclu_IDX}\"\\n    \\n    # viewer.text_overlay.text = f\"{time:1.1f} time\"\\n\\n\\n# viewer = napari.Viewer()\\n# viewer.add_image(np.random.random((5, 5, 5)), colormap=\\'red\\', opacity=0.8)\\nviewer.text_overlay.visible = True\\nviewer.dims.events.current_step.connect(on_update_slider)\\n# viewer.dims.events.current_step.disconnect(on_update_slider)\\n\\n\\ndef build_filename_from_viewer(viewer, desired_save_parent_path: Path, slider_axis_IDX: int = 0) -> Path:\\n    \"\"\"\\n    Captures: curr_active_pipeline, neuron_ids, global_any_name\\n    \\n     Usage:\\n        file_out_path = build_filename_from_viewer(viewer)\\n        viewer.screenshot(path=file_out_path, canvas_only=True, flash=False)\\n\\n    \"\"\"\\n    # desired_save_parent_path = Path(\\'/home/halechr/Desktop/test_napari_out\\').resolve()\\n\\n    matrix_aclu_IDX: int = int(viewer.dims.current_step[slider_axis_IDX])\\n    # find the aclu value for this index:\\n    aclu: int = int(neuron_ids[matrix_aclu_IDX])\\n    curr_context = curr_active_pipeline.build_display_context_for_filtered_session(global_any_name, \\'napari_trial_by_trial_activity_viz\\', aclu=str(aclu))\\n    curr_context_string: str = curr_context.get_description() #.get_description(suffix_items=[f\\'aclu-{aclu}\\'])\\n    filename_string: str = f\"{curr_context_string}.png\"\\n\\n    file_out_path = desired_save_parent_path.joinpath(filename_string).resolve()\\n    return file_out_path\\n\\n\\n# desired_save_parent_path = Path(\\'/home/halechr/Desktop/test_napari_out\\').resolve()\\ndesired_save_parent_path = Path(r\\'C:\\\\Users\\\\pho\\\\Desktop\\\\test_napari_out\\').resolve()\\nimageseries_output_directory = napari_export_image_sequence(viewer=viewer, imageseries_output_directory=desired_save_parent_path, slider_axis_IDX=0, build_filename_from_viewer_callback_fn=build_filename_from_viewer)\\n'}, {'cell_type': 'markdown', 'metadata': {}, 'source': '### 2024-02-02 - Changepoint detection via `ruptures`', 'id': 'b48a8788'}, {'cell_type': 'code', 'execution_count': None, 'id': 'a7204e12', 'metadata': {}, 'outputs': [], 'source': 'import ruptures as rpt  # our package\\n\\n## Gotta do something, so just focus on the 1D pf peak locations for now:\\n\\n\\n# detection\\nalgo = rpt.Dynp(model=\"l2\").fit(signal)\\nresult = algo.predict(n_bkps=4)\\n\\nprint(result)\\n'}, {'cell_type': 'markdown', 'id': 'adbefbbb', 'metadata': {}, 'source': '### 2024-02-02 - Determining PDF transformation function -- not particularlly useful'}, {'cell_type': 'code', 'execution_count': None, 'id': '7b20dba5', 'metadata': {}, 'outputs': [], 'source': '# viewer.reset_view()'}, {'cell_type': 'code', 'execution_count': None, 'id': 'a17cb50d', 'metadata': {}, 'outputs': [], 'source': '\\nglobal_pf1D_ratemap = global_pf1D.ratemap\\nglobal_pf1D_ratemap.tuning_curve_unsmoothed_peak_firing_rates'}, {'cell_type': 'code', 'execution_count': None, 'id': '098ed0d4', 'metadata': {}, 'outputs': [], 'source': '# global_pf1D_ratemap\\nfrom neuropy.core.flattened_spiketrains import SpikesAccessor\\nfrom neuropy.utils.mixins.binning_helpers import build_df_discretized_binned_position_columns\\nfrom pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import compute_spatial_information\\n\\nan_active_pf = deepcopy(global_pf1D)\\nSI, global_spikes_df, epoch_averaged_activity_per_pos_bin, global_all_spikes_counts = compute_spatial_information(global_spikes_df=global_spikes_df, an_active_pf=an_active_pf, global_session_duration=global_session.duration)\\nSI'}, {'cell_type': 'code', 'execution_count': None, 'id': '9a6ab361', 'metadata': {}, 'outputs': [], 'source': \"\\n\\nimport napari\\n\\nviewer = napari.view_image(occupancy_weighted_tuning_maps_matrix)\\n\\n# viewer.add_image(p_i, name='p_i')\"}, {'cell_type': 'code', 'execution_count': None, 'id': '400177a6', 'metadata': {}, 'outputs': [], 'source': \"# active_laps_epochs = deepcopy(global_any_laps_epochs_obj.to_dataframe())\\n\\n# _out_snapshots = active_pf_2D_dt.batch_snapshotting(combined_records_list=laps_df, reset_at_start=True)\\n_out_snapshots = historical_snapshots\\n\\nactive_lap_pf_results_dict = {'historical_snapshots': _out_snapshots}\\n\\n# active_pf_2D_dt\\n# active_pf1D_dt, active_pf2D_dt = perform_compute_time_dependent_placefields(all_spikes_df, position_df.position., deepcopy(global_pf1D), deepcopy(global_pf2D), deepcopy(an_active_pf.config), # active_config.computation_config\\n# \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tshould_force_recompute_placefields=True)\\n\\n# long_pf1D_dt\\n\\n# global_any_laps_epochs_obj\\n# global_an\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '54cd53e2', 'metadata': {}, 'outputs': [], 'source': '# a_snapshot.smoothed_spikes_maps_matrix\\n# a_snapshot.seconds_occupancy\\n# a_snapshot.occupancy_weighted_tuning_maps_matrix\\n# a_snapshot.normalized_occupancy\\n# a_snapshot.num_position_samples_occupancy\\n# a_snapshot.__doc__\\n# a_snapshot.__annotations__ ## Very good\\n# a_snapshot.__class__\\n# a_snapshot.__dir__()\\n# a_snapshot.'}, {'cell_type': 'code', 'execution_count': None, 'id': '5534a3dc', 'metadata': {}, 'outputs': [], 'source': 'import napari\\n\\n# if \\'snapshot_occupancy_weighted_tuning_maps\\' not in active_lap_pf_results_dict:\\nactive_lap_pf_results_dict[\\'snapshot_occupancy_weighted_tuning_maps\\'] = np.stack([placefield_snapshot.occupancy_weighted_tuning_maps_matrix for placefield_snapshot in active_lap_pf_results_dict[\\'historical_snapshots\\'].values()])\\nactive_lap_pf_results_dict[\\'num_position_samples_occupancy\\'] = np.stack([placefield_snapshot.num_position_samples_occupancy for placefield_snapshot in active_lap_pf_results_dict[\\'historical_snapshots\\'].values()])\\nactive_lap_pf_results_dict[\\'normalized_occupancy\\'] = np.stack([placefield_snapshot.normalized_occupancy for placefield_snapshot in active_lap_pf_results_dict[\\'historical_snapshots\\'].values()])\\nactive_lap_pf_results_dict[\\'spikes_maps_matrix\\'] = np.stack([placefield_snapshot.spikes_maps_matrix for placefield_snapshot in active_lap_pf_results_dict[\\'historical_snapshots\\'].values()])\\n# active_lap_pf_results_dict[\\'snapshot_occupancy_weighted_tuning_maps\\'] = np.stack([placefield_snapshot.occupancy_weighted_tuning_maps_matrix for placefield_snapshot in active_lap_pf_results_dict[\\'historical_snapshots\\'].values()])\\n\\n\\nimage_layer_dict = {}\\nlayer_properties_dict = {\\n\\t\\'snapshot_occupancy_weighted_tuning_maps\\': dict(blending=\\'translucent\\', colormap=\\'viridis\\', name=\\'pf1D_dt\\'),\\n\\t\\'num_position_samples_occupancy\\': dict(blending=\\'translucent\\', colormap=\\'viridis\\', name=\\'num_position_samples_occupancy\\'),\\n\\t\\'normalized_occupancy\\': dict(blending=\\'translucent\\', colormap=\\'viridis\\', name=\\'normalized_occupancy\\'),\\n\\t\\'spikes_maps_matrix\\': dict(blending=\\'translucent\\', colormap=\\'viridis\\', name=\\'spikes_maps\\'),\\n#  \\'flat_jensen_shannon_distance_results\\': dict(blending=\\'additive\\', colormap=\\'gray\\'),\\n\\t# \\'long_short_rel_entr_curves_frames\\': dict(blending=\\'additive\\', colormap=\\'bop blue\\'),\\n\\t# \\'short_long_rel_entr_curves_frames\\': dict(blending=\\'additive\\', colormap=\\'red\\'),\\n}\\n\\nviewer = None\\nfor i, (a_name, layer_properties) in enumerate(layer_properties_dict.items()):\\n\\timg_data = active_lap_pf_results_dict[a_name].astype(float)\\n\\tif viewer is None: #i == 0:\\n\\t\\t# viewer = napari.view_image(img_data) # rgb=True\\n\\t\\tviewer = napari.Viewer(title=\\'Laps Viewer\\')\\n\\t\\t# image_layer_dict[a_name] = viewer.add_image(active_lap_pf_results_dict[a_name].astype(float), **(dict(name=a_name)|layer_properties))\\n\\t# else:\\n\\t\\t# image_layer_dict[a_name] = viewer.add_image(active_relative_entropy_results_xr_dict[a_name].to_numpy().astype(float), name=a_name)\\n\\timage_layer_dict[a_name] = viewer.add_image(img_data, **(dict(name=a_name)|layer_properties))\\n\\n\\nif viewer.dims.ndim == 3:\\n\\t## Set the dimensions appropriately\\n\\tviewer.dims.axis_labels = (\\'lap_id\\', \\'aclu\\', \\'xbin\\')\\nelif viewer.dims.ndim == 4:\\n\\t## Set the dimensions appropriately\\n\\tviewer.dims.axis_labels = (\\'lap_id\\', \\'aclu\\', \\'xbin\\', \\'ybin\\')\\nelse:\\n\\traise ValueError(f\"viewer.dims.ndim is not known: {viewer.dims.ndim}, viewer.dims: {viewer.dims}\")\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '6c517ca7', 'metadata': {}, 'outputs': [], 'source': 'viewer.dims'}, {'cell_type': 'code', 'execution_count': None, 'id': '78b57ec1', 'metadata': {}, 'outputs': [], 'source': '# list(_out_snapshots)'}, {'cell_type': 'code', 'execution_count': None, 'id': 'e5bc8526', 'metadata': {}, 'outputs': [], 'source': \"## Find which position bin each peak falls in and add it to the flat_peaks_df:\\nfrom neuropy.utils.mixins.binning_helpers import build_df_discretized_binned_position_columns\\nfrom neuropy.utils.mixins.time_slicing import add_epochs_id_identity # needed to add laps column\\nfrom pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import compute_spatially_binned_activity\\n\\n\\n# a_spikes_df = None\\n# a_spikes_df: pd.DataFrame = deepcopy(long_one_step_decoder_1D.spikes_df) #.drop(columns=['neuron_type'], inplace=False)\\n\\n# an_active_pf = deepcopy(global_pf2D)\\n# an_active_pf = deepcopy(global_pf1D)\\n# an_active_pf.linear_pos_obj\\n\\n\\n# an_active_pf = active_pf_2D_dt\\nan_active_pf = active_pf_1D_dt\\nposition_binned_activity_matr_dict, split_spikes_df_dict, (neuron_id_to_new_IDX_map, lap_id_to_matrix_IDX_map) = compute_spatially_binned_activity(an_active_pf)\\n# 14.8s\"}, {'cell_type': 'code', 'execution_count': None, 'id': '50ffce8d', 'metadata': {}, 'outputs': [], 'source': 'position_binned_activity_matr_dict = active_out_matr_dict\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '9ee29212', 'metadata': {}, 'outputs': [], 'source': 'position_binned_activity_matr_dict'}, {'cell_type': 'code', 'execution_count': None, 'id': 'a239b0d5', 'metadata': {}, 'outputs': [], 'source': 'an_active_pf.get_by_id([aclu]) # get for a single plot\\na_ratemap = an_active_pf.ratemap\\na_ratemap.ge'}, {'cell_type': 'code', 'execution_count': None, 'id': '9e643f48', 'metadata': {}, 'outputs': [], 'source': 'position_df.lap.nunique()'}, {'cell_type': 'markdown', 'id': '55226f6a', 'metadata': {}, 'source': '### For a single neuron:'}, {'cell_type': 'code', 'execution_count': None, 'id': 'c3166ffe', 'metadata': {}, 'outputs': [], 'source': \"\\n\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nplt.figure(figsize=(10,7))\\nsns.heatmap(active_out_matr, cmap='viridis')\\nplt.show()\"}, {'cell_type': 'code', 'execution_count': None, 'id': '77f08c22', 'metadata': {}, 'outputs': [], 'source': '# list(a_spikes_df_bin_grouped.itertuples(index=False))\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': '6abad004', 'metadata': {}, 'outputs': [], 'source': \"bin_infos\\n\\n# long_pf2D.ratemap\\n\\n# facet_col='aclu'\\n\\n# long_LR_pf1D_Decoder.\\n# long_pf1D\\n# long_pf2D.filtered_spikes_df\\n# long_pf2D.ratemap.occupancy\\n\\n# row=['maze_id','maze_relative_lap']\\n# row='lap'\\n\\n# 'binned_x'\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '950cbad6', 'metadata': {}, 'outputs': [], 'source': \"fig = plt.figure(clear=True)\\nax = long_filtered_flat_peaks_df[['peak_center_x', 'peak_center_y']].plot.scatter(x='peak_center_x', y='peak_center_y')\\n# plt.show()\\nfig\"}, {'cell_type': 'code', 'execution_count': None, 'id': '9c2c035d', 'metadata': {}, 'outputs': [], 'source': \"active_neuron_replay_stats_df = SplitPartitionMembership.convert_dataframe_columns_for_hdf(neuron_replay_stats_df.copy())\\nactive_neuron_replay_stats_df['aclu'] = active_neuron_replay_stats_df['aclu'].astype('str')\\n\\n\\n_temp_long_peak2D_center_label_xy = active_neuron_replay_stats_df[['long_pf2D_peak_x', 'long_pf2D_peak_y']].dropna().to_numpy() # (26, 2) # Continuous\\n_temp_short_peak2D_center_label_xy = active_neuron_replay_stats_df[['short_pf2D_peak_x', 'short_pf2D_peak_y']].dropna().to_numpy() # (26, 2) # Continuous\\n\\n\\n# _temp_peak_center_bin_label_xy = neuron_replay_stats_df[['peak_center_binned_x', 'peak_center_binned_y']].dropna().to_numpy()-1 # (26, 2) # Indicies\\n# _temp_long_peak2D_center_label_xy\\n\\nimport plotly.express as px\\n\\nlong_fig = px.scatter(active_neuron_replay_stats_df, x='long_pf2D_peak_x', y='long_pf2D_peak_y', color='aclu', title='long peak2Ds') # , marker='aclu'\\nshort_fig = px.scatter(active_neuron_replay_stats_df, x='short_pf2D_peak_x', y='short_pf2D_peak_y', color='aclu', title='short peak2Ds') # , marker='aclu'\\n\\n# ax = px.scatter(neuron_replay_stats_df, x=['long_pf2D_peak_x', 'short_pf2D_peak_x'], y=['long_pf2D_peak_y', 'short_pf2D_peak_y'], color='aclu') # , marker='aclu'\\n# ax = active_neuron_replay_stats_df.plot.scatter(x='long_pf_peak_x', y='track_membership', c='aclu')\\nlong_fig\\nshort_fig\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '9f86899b', 'metadata': {}, 'outputs': [], 'source': \"import plotly.graph_objects as go\\nimport matplotlib.cm as cm\\nimport numpy as np\\n\\n# Normalize your 'aclu' values to [0, 1] for color mapping\\nnormalize = lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))\\naclu_norm = normalize(active_neuron_replay_stats_df['aclu'].astype(float))\\n\\n# Convert these normalized values to a list of RGB strings using a colormap\\ncolor_mapping = cm.get_cmap('viridis')  # You can use any colormap here\\naclu_colors = [cm.colors.rgb2hex(color_mapping(val)) for val in aclu_norm]\\n\\nfig = go.Figure()\\n\\n_ = fig.add_trace(\\n    go.Scatter(\\n        x=active_neuron_replay_stats_df['long_pf2D_peak_x'], \\n        y=active_neuron_replay_stats_df['long_pf2D_peak_y'],\\n        mode='markers',\\n        marker_color=aclu_colors,  # Use the mapped colors\\n        name='long peak2Ds', opacity=0.75, marker_size=10, \\n    )\\n)\\n\\n_ = fig.add_trace(\\n    go.Scatter(\\n        x=active_neuron_replay_stats_df['short_pf2D_peak_x'], \\n        y=active_neuron_replay_stats_df['short_pf2D_peak_y'],\\n        mode='markers',\\n        marker_color=aclu_colors,  # Use the mapped colors\\n        name='short peak2Ds', opacity=0.45, marker_size=14, marker_symbol='square',\\n    )\\n)\\n\\n# Arrows trace\\nfor i in range(len(aclu_colors)):\\n    _ = fig.add_trace(\\n        go.Scatter(\\n            x=[active_neuron_replay_stats_df['long_pf2D_peak_x'].iloc[i], active_neuron_replay_stats_df['short_pf2D_peak_x'].iloc[i]], \\n            y=[active_neuron_replay_stats_df['long_pf2D_peak_y'].iloc[i], active_neuron_replay_stats_df['short_pf2D_peak_y'].iloc[i]],\\n            mode='lines',\\n            line=dict(\\n                color=aclu_colors[i],\\n            ),\\n            showlegend=False\\n        )\\n    )\\n\\n_ = fig.update_layout(title='Long and Short peak2Ds')\\nfig.show()\\n\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '74f912d7', 'metadata': {}, 'outputs': [], 'source': \"long_plot_df = deepcopy(active_neuron_replay_stats_df[['aclu', 'long_pf2D_peak_x', 'long_pf2D_peak_y']]).set_index('aclu')\\nlong_plot_df['z'] = 5.6\\nlong_plot_df = long_plot_df.dropna()\\nlong_plot_df.index.name = 'aclu'\\n# long_plot_df.to_records(index='aclu')\\nlong_plot_df\\n# pActiveTuningCurvesPlotter.add_nearest_decoded_position_indicator_circle\\n# _out = pActiveTuningCurvesPlotter.add_points(long_plot_df.to_records(index='aclu'))\\n\\npoints_data = list(long_plot_df.itertuples(index='aclu'))\\npoints_data\\n# curr_debug_point\"}, {'cell_type': 'code', 'execution_count': None, 'id': '0f559096', 'metadata': {}, 'outputs': [], 'source': '# perform_plot_location_point\\n# pActiveSpikesBehaviorPlotter\\n# a_point_tuple = list(points_data[0][1:])\\n\\na_point_tuple_list = [list(a_point_tuple[1:]) for a_point_tuple in points_data]\\na_point_tuple_list'}, {'cell_type': 'code', 'execution_count': None, 'id': '94a92e6a', 'metadata': {}, 'outputs': [], 'source': '# ipcDataExplorer.z_fixed\\nipcDataExplorer.update()'}, {'cell_type': 'code', 'execution_count': None, 'id': '60c11acc', 'metadata': {}, 'outputs': [], 'source': \"_out = ipcDataExplorer.perform_plot_location_point('long_remapping_peaks', a_point_tuple_list, color='orange', render=True)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '16d46829', 'metadata': {}, 'outputs': [], 'source': \"\\n## Add tot he 3D plotter:\\ncurr_debug_point = [curr_x, curr_y, self.z_fixed[-1]]\\nif debug_print:\\n    print(f'tcurr_debug_point: {curr_debug_point}') # \\\\n\\\\tlast_window_time: {last_window_time}\\\\n\\\\tdisplayed_time_offset: {displayed_time_offset}\\nself.perform_plot_location_point('decoded_position_point_plot', curr_debug_point, color='r', render=True)\\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': '3768fc2e', 'metadata': {}, 'outputs': [], 'source': ''}, {'cell_type': 'code', 'execution_count': None, 'id': '3c30b322', 'metadata': {}, 'outputs': [], 'source': \"_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\\nfrom pyphoplacecellanalysis.Pho2D.track_shape_drawing import test_LinearTrackDimensions_2D_Matplotlib\\nfig, ax1, ax2 = test_LinearTrackDimensions_2D_Matplotlib()\\nfig\"}, {'cell_type': 'code', 'execution_count': None, 'id': '1945b6de', 'metadata': {}, 'outputs': [], 'source': \"from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\\n\\nactive_neuron_replay_stats_df = SplitPartitionMembership.convert_dataframe_columns_for_hdf(neuron_replay_stats_df.copy())\\nactive_neuron_replay_stats_df['aclu'] = active_neuron_replay_stats_df['aclu'].astype('str')\\n['long_pf_peak_x']\\n# ['short_pf_peak_x']\\n\\nactive_neuron_replay_stats_df['track_membership']\"}, {'cell_type': 'code', 'execution_count': None, 'id': '11985646', 'metadata': {}, 'outputs': [], 'source': \"import plotly.express as px\\n\\n# error_x\\nax = px.scatter(active_neuron_replay_stats_df, x=['long_pf_peak_x', 'short_pf_peak_x'], y='track_membership', marker='aclu', color='aclu')\\n# ax = active_neuron_replay_stats_df.plot.scatter(x='long_pf_peak_x', y='track_membership', c='aclu')\\nax\"}, {'cell_type': 'code', 'execution_count': None, 'id': '91d7f8cc', 'metadata': {}, 'outputs': [], 'source': \"active_neuron_replay_stats_df.plot.scatter(x='short_pf_peak_x', y='track_membership', ax=ax)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '99cbbb2b', 'metadata': {}, 'outputs': [], 'source': \"figure, ax = curr_active_pipeline.display('_display_pf_peak_prominence2d_plots', long_any_name, neuron_id=5) \"}, {'cell_type': 'code', 'execution_count': None, 'id': 'c960ba8d', 'metadata': {}, 'outputs': [], 'source': \"out_figs, out_axes, out_idxs = curr_active_pipeline.display('_display_pf_peak_prominence2d_default_quadrant_plots', long_any_name) \"}, {'cell_type': 'code', 'execution_count': None, 'id': '2252a427', 'metadata': {}, 'outputs': [], 'source': \"_out_display_3d_interactive_tuning_curves_plotter = curr_active_pipeline.display('_display_3d_interactive_tuning_curves_plotter', long_any_name) \\n\"}, {'cell_type': 'code', 'execution_count': None, 'id': 'bba23f9d', 'metadata': {}, 'outputs': [], 'source': \"_out_display_3d_interactive_custom_data_explorer = curr_active_pipeline.display('_display_3d_interactive_custom_data_explorer', long_any_name) \"}, {'cell_type': 'code', 'execution_count': None, 'id': 'e447c7ac', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.Pho3D.PyVista.peak_prominences import render_all_neuron_peak_prominence_2d_results_on_pyvista_plotter\\n\\nactive_config_name = global_any_name\\ndisplay_output = {}\\nactive_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get(\\'RatemapPeaksAnalysis\\', {}).get(\\'PeakProminence2D\\', None)\\npActiveTuningCurvesPlotter = None\\ndisplay_output = display_output | curr_active_pipeline.display(\\'_display_3d_interactive_tuning_curves_plotter\\', active_config_name, extant_plotter=display_output.get(\\'pActiveTuningCurvesPlotter\\', None), panel_controls_mode=\\'Qt\\', should_nan_non_visited_elements=False, zScalingFactor=2000.0) # Works now!\\nipcDataExplorer = display_output[\\'ipcDataExplorer\\']\\ndisplay_output[\\'pActiveTuningCurvesPlotter\\'] = display_output.pop(\\'plotter\\') # rename the key from the generic \"plotter\" to \"pActiveSpikesBehaviorPlotter\" to avoid collisions with others\\npActiveTuningCurvesPlotter = display_output[\\'pActiveTuningCurvesPlotter\\']\\nroot_dockAreaWindow, placefieldControlsContainerWidget, pf_widgets = display_output[\\'pane\\'] # for Qt mode\\n'}, {'cell_type': 'code', 'execution_count': None, 'id': 'accf5493', 'metadata': {}, 'outputs': [], 'source': \"active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\\nrender_all_neuron_peak_prominence_2d_results_on_pyvista_plotter(ipcDataExplorer, active_peak_prominence_2d_results)\"}, {'cell_type': 'code', 'execution_count': None, 'id': '82a768d7', 'metadata': {}, 'outputs': [], 'source': 'from PendingNotebookCode import display_all_eloy_pf_density_measures_results\\n\\n\\nout_all_eloy_pf_density_fig = display_all_eloy_pf_density_measures_results(active_pf_2D, active_eloy_analysis, active_simpler_pf_densities_analysis, active_peak_prominence_2d_results)'}, {'cell_type': 'code', 'execution_count': None, 'id': 'ee641968', 'metadata': {}, 'outputs': [], 'source': 'from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import _temp_debug_draw_predicted_position_difference'}, {'cell_type': 'markdown', 'metadata': {}, 'source': '# PrettyPrinting Improvements', 'id': 'a5fd961e'}, {'cell_type': 'markdown', 'metadata': {}, 'source': \"I'm having issues with how python and Jupyter lab format outputs (specifically as notebook outputs in VSCode). They seem to strongly prefer linebreaks when this isn't efficient for my screen, as it's a widescreen and is more limited in vertical space than horizontal space. For example, when I call `` on my class the output cell prints:\\n```\\n['num_position_samples_occupancy',\\n 'num_position_samples_smoothed_occupancy',\\n 'seconds_occupancy',\\n 'normalized_occupancy',\\n 'spikes_maps_matrix',\\n 'smoothed_spikes_maps_matrix',\\n 'occupancy_weighted_tuning_maps_matrix',\\n '__module__',\\n '__annotations__',\\n '__doc__',\\n 'to_dict',\\n 'from_dict',\\n '__getstate__',\\n '__setstate__',\\n 'get_by_IDX',\\n '__attrs_attrs__',\\n '__eq__',\\n '__ne__',\\n '__hash__',\\n '__init__',\\n 'deserialize',\\n 'read_hdf',\\n 'get_fields_with_tag',\\n 'get_serialized_fields',\\n 'get_serialized_dataset_fields',\\n 'get_serialized_attribute_fields',\\n '__dict__',\\n '__weakref__',\\n '__repr__',\\n '__str__',\\n '__getattribute__',\\n '__setattr__',\\n '__delattr__',\\n '__lt__',\\n '__le__',\\n '__gt__',\\n '__ge__',\\n '__new__',\\n '__reduce_ex__',\\n '__reduce__',\\n '__subclasshook__',\\n '__init_subclass__',\\n '__format__',\\n '__sizeof__',\\n '__dir__',\\n '__class__',\\n 'is_hdf_serializable',\\n 'to_hdf']\\n```\\nWhere I'd like it to print without all the excessive line breaks, e.g.:\\n```\\n['num_position_samples_occupancy', 'num_position_samples_smoothed_occupancy', 'seconds_occupancy', 'normalized_occupancy', 'spikes_maps_matrix', 'smoothed_spikes_maps_matrix', 'occupancy_weighted_tuning_maps_matrix', '__module__', '__annotations__', '__doc__', 'to_dict', 'from_dict', '__getstate__', '__setstate__', 'get_by_IDX', '__attrs_attrs__', '__eq__', '__ne__', '__hash__', '__init__', 'deserialize', 'read_hdf', 'get_fields_with_tag', 'get_serialized_fields', 'get_serialized_dataset_fields', 'get_serialized_attribute_fields', '__dict__', '__weakref__', '__repr__', '__str__', '__getattribute__', '__setattr__', '__delattr__', '__lt__', '__le__', '__gt__', '__ge__', '__new__', '__reduce_ex__', '__reduce__', '__subclasshook__', '__init_subclass__', '__format__', '__sizeof__', '__dir__', '__class__', 'is_hdf_serializable', 'to_hdf']\\n```\\nWhat setting or configuration option controls when the linebreaks are inserted in the output, and how can I change it generally without having to customize it on a per-class basis?\\n\", 'id': '748ce701'}]\n"
     ]
    }
   ],
   "source": [
    "notebook_path = Path(r'../ReviewOfWork_2024-02-05_CLEAN.ipynb').resolve()\n",
    "assert notebook_path.exists()\n",
    "processor = NotebookProcessor(path=notebook_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m notebook_outline \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_notebook_outline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m notebook_outline\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoCoreHelpers\\src\\pyphocorehelpers\\programming_helpers.py:666\u001b[0m, in \u001b[0;36mNotebookProcessor.get_notebook_outline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cell[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    665\u001b[0m     code_cell_outline \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: cell[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcode_cells\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msection\u001b[49m:\n\u001b[0;32m    667\u001b[0m         section[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode_cells\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    668\u001b[0m     section[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode_cells\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(code_cell_outline)\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "notebook_outline = processor.get_notebook_outline()\n",
    "notebook_outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "notebook_path = Path(r\"C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2024-01-22.ipynb\").resolve()\n",
    "processor = NotebookProcessor(path=notebook_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cells_with_tags = processor.get_cells_with_tags()\n",
    "# print(cells_with_tags)\n",
    "\n",
    "# Find cells with a specific tag\n",
    "# specific_tag_cells = processor.get_cells_with_tag('specific_tag')\n",
    "# print(specific_tag_cells)\n",
    "\n",
    "empty_cells = processor.get_empty_cells()\n",
    "# print(empty_cells)\n",
    "len(empty_cells)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove all empty cells, and save the resultant notebook as the current notebook with the '_cleaned' filename suffix (but same extention)\n",
    "new_path = processor.path.with_stem(f'{processor.path.stem}_cleaned').resolve()\n",
    "processor.remove_empty_cells_and_save(new_path=new_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Usage: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "notebook_path = Path(r\"C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\ReviewOfWork_2024-01-22.ipynb\").resolve()\n",
    "# notebook_path = '../BatchGenerateOutputs_2023-11-13.ipynb'\n",
    "extracted_cells = IPythonHelpers.extract_cells(notebook_path)\n",
    "print(extracted_cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_with_tags = []\n",
    "for cell in extracted_cells:\n",
    "\tcell_content = cell['source']\n",
    "\tcell_tags = cell['metadata'].get('tags', None)\n",
    "\tif (cell_tags is not None) and (len(cell_tags) > 0):\n",
    "\t\tcells_with_tags.append({'content': cell_content, 'tags': cell_tags})\n",
    "\n",
    "cells_with_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import get_ipython # required for IPythonHelpers.cell_vars\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "ipy = get_ipython()\n",
    "ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations, AcrossSessionTables\n",
    "\n",
    "BATCH_DATE_TO_USE = '2023-11-15_GL' # used for filenames throught the notebook\n",
    "\n",
    "active_global_batch_result_filename=f'global_batch_result_{BATCH_DATE_TO_USE}.pkl'\n",
    "\n",
    "debug_print = False\n",
    "known_global_data_root_parent_paths = [Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data')] # , Path(r'/home/halechr/FastData'), Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'/home/halechr/turbo/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data')\n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "## Build Pickle Path:\n",
    "global_batch_result_file_path = Path(global_data_root_parent_path).joinpath(active_global_batch_result_filename).resolve() # Use Default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ## Load the saved across-session results:\n",
    "# Outputs: across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list, neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table\n",
    "\n",
    "inst_fr_output_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "\n",
    "## Load all across-session tables from the pickles:\n",
    "output_path_suffix: str = f'{BATCH_DATE_TO_USE}'\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.load_all_combined_tables(override_output_parent_path=global_data_root_parent_path, output_path_suffix=output_path_suffix) # output_path_suffix=f'2023-10-04-GL-Recomp'\n",
    "num_sessions = len(neuron_replay_stats_table.session_uid.unique().to_numpy())\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "# neuron_replay_stats_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `IPython` helpers Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "# Get the IPython instance\n",
    "ipython = get_ipython()\n",
    "\n",
    "# Access a specific cell's content by its number\n",
    "cell_number = 2  # Replace with the cell number you are interested in\n",
    "cell_content = ipython.user_ns['In'][cell_number]\n",
    "\n",
    "print(cell_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `CodeParsers` testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.programming_helpers import CodeParsers\n",
    "import ast\n",
    "\n",
    "code_block: str = \"\"\"\n",
    "inst_fr_output_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "\n",
    "## Load all across-session tables from the pickles:\n",
    "output_path_suffix: str = f'{BATCH_DATE_TO_USE}'\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.load_all_combined_tables(override_output_parent_path=global_data_root_parent_path, output_path_suffix=output_path_suffix) # output_path_suffix=f'2023-10-04-GL-Recomp'\n",
    "num_sessions = len(neuron_replay_stats_table.session_uid.unique().to_numpy())\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "# neuron_replay_stats_table\n",
    "\"\"\"\n",
    "print(CodeParsers.extract_assigned_variable_names(code_block)) # BUG: returning only: ['num_sessions', 'num_sessions']\n",
    "\n",
    "print(CodeParsers.find_input_variables(code_block))\n",
    "# print(extract_variable_names(code_block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_block: str = '''\n",
    "from pyphocorehelpers.print_helpers import generate_html_string\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "\n",
    "formatted_title_strings_dict = DisplayColorsEnum.get_pyqtgraph_formatted_title_dict()\n",
    "# formatted_title_strings_dict\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "Captures: active_epochs_df, rank_order_results, ripple_result_tuple, rank_order_results_debug_values\n",
    "spikes_df\n",
    "\"\"\"\n",
    "\n",
    "decoder_name_to_column_name_prefix_map = dict(zip(['long_LR', 'long_RL', 'short_LR', 'short_RL'], ['LR_Long', 'RL_Long', 'LR_Short', 'RL_Short']))\n",
    "ripple_combined_epoch_stats_df = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_combined_epoch_stats_df)\n",
    "\n",
    "# def get_epoch_label_row(an_idx: int):\n",
    "# \ta_label = active_epochs_df.label.to_numpy()[an_idx]\n",
    "# \ta_row = active_epochs_df[active_epochs_df.label == a_label]\n",
    "# \treturn list(a_row.itertuples())[0], a_label\n",
    "\n",
    "# def debug_plot_epoch_label_row(a_plotter, an_idx: int):\n",
    "# \ta_row, a_label = get_epoch_label_row(an_idx=an_idx)\n",
    "# \tprint(f'debug_plot_epoch_label_row(an_idx: {an_idx}):\\n\\t{print_formatted_active_epochs_df(a_label, a_row)}')\n",
    "\n",
    "\n",
    "def debug_print_dict_row(a_dict) -> str:\n",
    "return '\\t'.join([': '.join([str(k), f'{float(v):0.3f}']) for k, v in a_dict.items()])\n",
    "\n",
    "def print_formatted_active_epochs_df(curr_epoch_label, corresponding_epoch_values_tuple):\n",
    "\"\"\" 2023-12-13 - NEW - called to print the dataframe at a given index\n",
    "\t['start', 'stop', 'label', 'duration']\n",
    "\t['LR_Long_spearman', 'RL_Long_spearman', 'LR_Short_spearman', 'RL_Short_spearman']\n",
    "\t['LR_Long_Old_Spearman', 'RL_Long_Old_Spearman', 'LR_Short_Old_Spearman', 'RL_Short_Old_Spearman']\n",
    "\t\n",
    "\t['LR_Long_Z', 'RL_Long_Z', 'LR_Short_Z', 'RL_Short_Z']\n",
    "\t['LR_Long_pearson', 'RL_Long_pearson', 'LR_Short_pearson', 'RL_Short_pearson']\n",
    "\t\n",
    "\t['LR_Long_ActuallyIncludedAclus', 'LR_Long_rel_num_cells', 'RL_Long_ActuallyIncludedAclus', 'RL_Long_rel_num_cells']\n",
    "\t['LR_Long_ActuallyIncludedAclus', 'LR_Long_rel_num_cells', 'RL_Long_ActuallyIncludedAclus', 'RL_Long_rel_num_cells']\n",
    "\"\"\"\n",
    "print(f'curr_epoch_label: {curr_epoch_label}') # ,\\ncorresponding_epoch_values_tuple: {corresponding_epoch_values_tuple}\\n'\n",
    "# Extracting the fields\n",
    "out_str = '\\n'.join((\n",
    "\tdebug_print_dict_row({field: getattr(corresponding_epoch_values_tuple, field) for field in ['Index', 'label', 'start', 'stop', 'duration']}),\n",
    "\t# debug_print_dict_row({field: getattr(corresponding_epoch_values_tuple, field) for field in ['LR_Long_spearman', 'RL_Long_spearman', 'LR_Short_spearman', 'RL_Short_spearman']}),\n",
    "\tdebug_print_dict_row({field: getattr(corresponding_epoch_values_tuple, field) for field in ['LR_Long_spearman', 'LR_Short_spearman', 'RL_Long_spearman', 'RL_Short_spearman']}),\n",
    "\t# debug_print_dict_row({field: getattr(corresponding_epoch_values_tuple, field) for field in ['LR_Long_Old_Spearman', 'LR_Short_Old_Spearman', 'RL_Long_Old_Spearman', 'RL_Short_Old_Spearman']}),\n",
    "\t# debug_print_dict_row({field: getattr(corresponding_epoch_values_tuple, field) for field in ['LR_Long_Z', 'LR_Short_Z', 'RL_Long_Z', 'RL_Short_Z']}),\n",
    "\t# debug_print_dict_row({field: getattr(corresponding_epoch_values_tuple, field) for field in ['LR_Long_Old_Spearman', 'RL_Long_Old_Spearman', 'LR_Short_Old_Spearman', 'RL_Short_Old_Spearman']}),\n",
    "\t# debug_print_dict_row({field: getattr(corresponding_epoch_values_tuple, field) for field in ['LR_Long_Z', 'RL_Long_Z', 'LR_Short_Z', 'RL_Short_Z']}),\n",
    "\t# f'LR_relative_num_cells: {LR_relative_num_cells[an_idx]},\\t\\t RL_relative_num_cells: {RL_relative_num_cells[an_idx]}',\n",
    "\t# f'LR_template_epoch_actually_included_aclus: {corresponding_epoch_values_tuple.a[an_idx]},\\nRL_template_epoch_actually_included_aclus: {RL_template_epoch_actually_included_aclus[an_idx]}',\n",
    "\tf'LR_Long rel: num_cells: {corresponding_epoch_values_tuple.LR_Long_rel_num_cells}, \\t aclus: {corresponding_epoch_values_tuple.LR_Long_ActuallyIncludedAclus}', \n",
    "\tf'RL_Long rel: num_cells: {corresponding_epoch_values_tuple.RL_Long_rel_num_cells}, \\t aclus: {corresponding_epoch_values_tuple.RL_Long_ActuallyIncludedAclus}', \n",
    "))\n",
    "print(out_str)\n",
    "\n",
    "\n",
    "\n",
    "def debug_update_plot_titles(a_plotter, an_idx: int):\n",
    "\"\"\" Updates the titles of each of the four rasters with the appropriate spearman rho value.\n",
    "captures: rank_order_results_debug_values || active_epochs_df, formatted_title_strings_dict\n",
    "\"\"\"\n",
    "use_plaintext_title: bool = True\n",
    "\n",
    "curr_epoch_label = a_plotter.lookup_label_from_index(an_idx)\n",
    "curr_new_results_df = ripple_combined_epoch_stats_df[ripple_combined_epoch_stats_df.index == curr_epoch_label]\n",
    "\n",
    "for a_decoder_name, a_root_plot in a_plotter.plots.root_plots.items():\n",
    "\t# a_real_value = rank_order_results_debug_values[a_decoder_name][0][an_idx]\n",
    "\ta_std_column_name: str = decoder_name_to_column_name_prefix_map[a_decoder_name]\n",
    "\ta_formatted_title_string_prefix: str = formatted_title_strings_dict[a_std_column_name]\n",
    "\tactive_column_names = curr_new_results_df.filter(regex=f'^{a_std_column_name}').columns.tolist()\n",
    "\t# print(active_column_names)\n",
    "\n",
    "\tactive_column_values = curr_new_results_df[active_column_names]\n",
    "\tactive_values_dict = active_column_values.iloc[0].to_dict() # {'LR_Long_spearman': -0.34965034965034975, 'LR_Long_pearson': -0.5736588716389961, 'LR_Long_spearman_Z': -0.865774983083525, 'LR_Long_pearson_Z': -1.4243571733839517}\n",
    "\tactive_raw_col_val_dict = {k.replace(f'{a_std_column_name}_', ''):v for k,v in active_values_dict.items()} # remove the \"LR_Long\" prefix so it's just the variable names\n",
    "\t\n",
    "\tactive_formatted_col_val_list = [':'.join([generate_html_string(str(k), color='grey', bold=False), generate_html_string(f'{v:0.3f}', color='white', bold=True)]) for k,v in active_raw_col_val_dict.items()]\n",
    "\tfinal_values_string: str = '; '.join(active_formatted_col_val_list)\n",
    "\n",
    "\tif use_plaintext_title:\n",
    "\t\ttitle_str = generate_html_string(f\"{a_std_column_name}: {final_values_string}\")\n",
    "\telse:\n",
    "\t\t# Color formatted title:\n",
    "\t\ttitle_str = generate_html_string(f\"{a_formatted_title_string_prefix}: {final_values_string}\")\n",
    "\t\n",
    "\ta_root_plot.setTitle(title=title_str)\n",
    "\n",
    "\n",
    "def debug_update_long_short_info_titles(a_plotter, an_idx: int):\n",
    "\"\"\" Updates the titles of each of the four rasters with the appropriate spearman rho value.\n",
    "captures: ripple_result_tuple, \n",
    "\"\"\"\n",
    "has_long_short_info_labels = (hasattr(a_plotter.ui, 'long_info_label') and hasattr(a_plotter.ui, 'short_info_label'))\n",
    "if has_long_short_info_labels:\n",
    "\tdirectional_likelihoods_tuple: DirectionalRankOrderLikelihoods = ripple_result_tuple.directional_likelihoods_tuple\n",
    "\tdirectional_likelihoods_tuple.long_best_direction_indices\n",
    "\tdirectional_likelihoods_tuple.short_best_direction_indices\n",
    "\tdirectional_likelihoods_tuple.long_relative_direction_likelihoods\n",
    "\n",
    "\tlong_info_string_list = []\n",
    "\n",
    "\tif directional_likelihoods_tuple.long_relative_direction_likelihoods is not None:\n",
    "\t\t_long_LR_likelihood = directional_likelihoods_tuple.long_relative_direction_likelihoods[an_idx, 0]\n",
    "\t\t_long_RL_likelihood = directional_likelihoods_tuple.long_relative_direction_likelihoods[an_idx, 1]\n",
    "\t\t_long_LR_likelihood_str = generate_html_string(f'{float(_long_LR_likelihood):0.3f}', color='black', bold=True)\n",
    "\t\t_long_RL_likelihood_str = generate_html_string(f'{float(_long_RL_likelihood):0.3f}', color='black', bold=True)\n",
    "\t\tlong_info_string_list.append(generate_html_string(f'LONG LR likelihood: {_long_LR_likelihood_str}'))\n",
    "\t\tlong_info_string_list.append(generate_html_string(f'LONG RL likelihood: {_long_RL_likelihood_str}'))\n",
    "\n",
    "\tif directional_likelihoods_tuple.long_best_direction_indices is not None:\n",
    "\t\t_long_best_dir_IDX = directional_likelihoods_tuple.long_best_direction_indices[an_idx]\t\t\n",
    "\t\t_long_best_dir_IDX_str = generate_html_string(f'{int(_long_best_dir_IDX)}', color='black', bold=True)\n",
    "\t\tlong_info_string_list.append(generate_html_string(f'LONG best dir IDX: {_long_best_dir_IDX_str}'))\n",
    "\t\t\n",
    "\t# original:\n",
    "\tripple_result_tuple.rank_order_z_score_df\n",
    "\tripple_result_tuple.active_epochs\n",
    "\t\n",
    "\tlong_best_dir_z_score_value_str = generate_html_string(f'{float(ripple_result_tuple.long_best_dir_z_score_values[an_idx]):0.3f}', color='black', bold=True)\n",
    "\tlong_info_string_list.append(generate_html_string(f'LONG best_dir_z_score_value: {long_best_dir_z_score_value_str}'))\n",
    "\n",
    "\tshort_best_dir_z_score_value_str = generate_html_string(f'{float(ripple_result_tuple.short_best_dir_z_score_values[an_idx]):0.3f}', color='black', bold=True)\n",
    "\t# j_str = generate_html_string('j', color='red', bold=True)\n",
    "\ta_plotter.ui.long_info_label.setText('\\n'.join(long_info_string_list))\n",
    "\ta_plotter.ui.short_info_label.setText(generate_html_string(f'SHORT best_dir_z_score_value: {short_best_dir_z_score_value_str}'))\n",
    "else:\n",
    "\tprint(f'WARN: debug_update_long_short_info_titles(...) but plotter does not have the `a_plotter.ui.long_info_label`')\n",
    "\t\n",
    "\n",
    "def plot_attached_directional_templates_pf_debugger():\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "# epoch_active_aclus = np.array([9,  26,  31,  39,  40,  43,  47,  52,  53,  54,  60,  61,  65,  68,  72,  75,  77,  78,  81,  82,  84,  85,  90,  92,  93,  98, 102]) # some test indicies\n",
    "epoch_active_aclus = None\n",
    "_out_directional_template_pfs_debugger = curr_active_pipeline.display(DirectionalPlacefieldGlobalDisplayFunctions._display_directional_template_debugger, included_any_context_neuron_ids=epoch_active_aclus, figure_name=f'<Controlled by RankOrderRastersDebugger>')\n",
    "\n",
    "def debug_update_paired_directional_template_pfs_debugger(a_plotter, an_idx: int):\n",
    "\"\"\" captures: _out_directional_template_pfs_debugger, \"\"\"\n",
    "epoch_active_aclus = deepcopy(a_plotter.get_epoch_active_aclus())\n",
    "# update the displayed cells:\n",
    "directional_template_pfs_debugger_on_update_callback = _out_directional_template_pfs_debugger.get('ui').on_update_callback\n",
    "directional_template_pfs_debugger_on_update_callback(epoch_active_aclus)\n",
    "\n",
    "\n",
    "import io\n",
    "from contextlib import redirect_stdout # used by DocumentationFilePrinter to capture print output\n",
    "\n",
    "def a_debug_callback_fn(a_plotter, an_idx: int, an_epoch=None):\n",
    "global epoch_active_aclus, _out_directional_template_pfs_debugger\n",
    "out = io.StringIO()\n",
    "# _out.on_update_epoch_IDX(an_idx)\n",
    "\n",
    "curr_epoch_label = a_plotter.lookup_label_from_index(an_idx)\n",
    "\n",
    "# DO LR only:\n",
    "LR_ranked_aclus_stats = rank_order_results.LR_ripple.ranked_aclus_stats_dict[curr_epoch_label]\n",
    "LR_extra_info = rank_order_results.LR_ripple.extra_info_dict[curr_epoch_label]\n",
    "\n",
    "RL_ranked_aclus_stats = rank_order_results.LR_ripple.ranked_aclus_stats_dict[curr_epoch_label]\n",
    "RL_extra_info = rank_order_results.RL_ripple.extra_info_dict[curr_epoch_label]\n",
    "\n",
    "\n",
    "# ripple_combined_epoch_stats_df = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_combined_epoch_stats_df)\n",
    "curr_new_results_df = ripple_combined_epoch_stats_df[ripple_combined_epoch_stats_df.index == curr_epoch_label]\n",
    "curr_new_results_df\n",
    "\n",
    "# RL_extra_info_dict = rank_order_results.RL_ripple.extra_info_dict[curr_epoch_label]\n",
    "\n",
    "with redirect_stdout(out):\n",
    "\tprint(f'=====================================================================================\\n\\tactive_epoch_IDX: {an_idx} :::', end='\\t')\n",
    "\t# print(f'')\n",
    "\t# print(f'LR_long_relative_real_values: {LR_long_relative_real_values[an_idx]:.4f},\\t\\t LR_long_relative_real_p_values: {LR_long_relative_real_p_values[an_idx]:.4f}')\n",
    "\t# print(f'LR_short_relative_real_values: {LR_short_relative_real_values[an_idx]:.4f},\\t\\t LR_short_relative_real_p_values: {LR_short_relative_real_p_values[an_idx]:.4f}')\n",
    "\t# print(f'LR_ripple.long_z_score: {rank_order_results.LR_ripple.long_z_score[an_idx]:.4f},\\t\\t LR_ripple.short_z_score: {rank_order_results.LR_ripple.short_z_score[an_idx]:.4f}')\n",
    "\t# print(f'RL_long_relative_real_values: {RL_long_relative_real_values[an_idx]:.4f},\\t\\t RL_long_relative_real_p_values: {RL_long_relative_real_p_values[an_idx]:.4f}')\n",
    "\t# print(f'RL_short_relative_real_values: {RL_short_relative_real_values[an_idx]:.4f},\\t\\t RL_short_relative_real_p_values: {RL_short_relative_real_p_values[an_idx]:.4f}')\n",
    "\t# print(f'RL_ripple.long_z_score: {rank_order_results.RL_ripple.long_z_score[an_idx]:.4f},\\t\\t RL_ripple.short_z_score: {rank_order_results.RL_ripple.short_z_score[an_idx]:.4f}')\n",
    "\t# print(f'LR_relative_num_cells: {LR_relative_num_cells[an_idx]},\\t\\t RL_relative_num_cells: {RL_relative_num_cells[an_idx]}')\n",
    "\t# print(f'LR_template_epoch_actually_included_aclus: {LR_template_epoch_actually_included_aclus[an_idx]},\\nRL_template_epoch_actually_included_aclus: {RL_template_epoch_actually_included_aclus[an_idx]}')\n",
    "\t\n",
    "\n",
    "\t## Simple key-based indexing:\n",
    "\tprint(f'')\n",
    "\t\n",
    "\tlr_long_columns = curr_new_results_df.filter(regex='^LR_Long').columns.tolist()\n",
    "\t# print(lr_long_columns)\n",
    "\tlr_long_columns_stripped = [col.replace('LR_Long_', '') for col in lr_long_columns]\n",
    "\t# print(lr_long_columns_stripped)\n",
    "\n",
    "\tprint(f'curr_new_results_df:\\n{curr_new_results_df[lr_long_columns]}')\n",
    "\t# print(render_dataframe(curr_new_results_df))\n",
    "\t# print(f'LR_long_relative_real_values: {LR_long_relative_real_values[an_idx]:.4f},\\t\\t LR_long_relative_real_p_values: {LR_long_relative_real_p_values[an_idx]:.4f}')\n",
    "\t# print(f'LR_short_relative_real_values: {LR_short_relative_real_values[an_idx]:.4f},\\t\\t LR_short_relative_real_p_values: {LR_short_relative_real_p_values[an_idx]:.4f}')\n",
    "\t# print(f'LR_ripple.long_z_score: {rank_order_results.LR_ripple.long_z_score[an_idx]:.4f},\\t\\t LR_ripple.short_z_score: {rank_order_results.LR_ripple.short_z_score[an_idx]:.4f}')\n",
    "\t# print(f'RL_long_relative_real_values: {RL_long_relative_real_values[an_idx]:.4f},\\t\\t RL_long_relative_real_p_values: {RL_long_relative_real_p_values[an_idx]:.4f}')\n",
    "\t# print(f'RL_short_relative_real_values: {RL_short_relative_real_values[an_idx]:.4f},\\t\\t RL_short_relative_real_p_values: {RL_short_relative_real_p_values[an_idx]:.4f}')\n",
    "\t# print(f'RL_ripple.long_z_score: {rank_order_results.RL_ripple.long_z_score[an_idx]:.4f},\\t\\t RL_ripple.short_z_score: {rank_order_results.RL_ripple.short_z_score[an_idx]:.4f}')\n",
    "\n",
    "\t# print(f'LR_relative_num_cells: {LR_extra_info[1]},\\t\\t RL_relative_num_cells: {RL_extra_info[1]}')\n",
    "\t# print(f'LR_template_epoch_actually_included_aclus: {len(LR_extra_info[1])},\\nRL_template_epoch_actually_included_aclus: {len(RL_extra_info[1])}')\n",
    "\n",
    "\n",
    "\t# 'LR_Long_spearman', 'LR_Long_spearman_Z'\n",
    "\t## Extract Z-score variables:\n",
    "\t\n",
    "\n",
    "\t# \"\"\" captures: active_epochs_df, \"\"\"\n",
    "\t# # corresponding_epoch_value = active_epochs_df.to_records()[active_epochs_df['label'] == curr_epoch_label]\n",
    "\t# corresponding_epoch_values_tuple = list(a_plotter.active_epochs_df[a_plotter.active_epochs_df['label'] == curr_epoch_label].itertuples(name='EpochRow'))[0] # EpochRow(Index=398, start=1714.3077712343074, stop=1714.6516814583447, label=409, duration=0.3439102240372449, end=1714.6516814583447, LR_Long_spearman=0.5269555552418339, RL_Long_spearman=-0.050011483546781, LR_Short_spearman=0.4606822127204283, RL_Short_spearman=-0.2035100246885261, LR_Long_pearson=0.4836286811698692, RL_Long_pearson=-0.003226348316225221, LR_Short_pearson=0.47186014640172635, RL_Short_pearson=-0.13444915290053647)\n",
    "\t# print_formatted_active_epochs_df(curr_epoch_label, corresponding_epoch_values_tuple)\n",
    "\t# LR_Long_pearson[active_epochs_df['label'] == curr_epoch_label].values\n",
    "\t# print(f'corresponding_epoch_value: {corresponding_epoch_value}')\n",
    "\tprint(f'done.\\n')\n",
    "\t# ripple_result_tuple.rank_order_z_score_df.label.to_numpy()[an_idx]\n",
    "\t# except BaseException as e:\n",
    "\t# \tprint(f'ERR\\n\\ta_debug_callback_fn(...): e: {e}')\n",
    "\t# \traise e\n",
    "\t# \t# pass\n",
    "\t\n",
    "\n",
    "\t# a_row, a_label = get_epoch_label_row(an_idx=an_idx)\n",
    "\t# print(f'!!!! debug_plot_epoch_label_row(an_idx: {an_idx}):\\n\\ta_label: {a_label}\\n\\ta_row: {a_row}')\n",
    "\n",
    "\t# display(LR_template_epoch_actually_included_aclus[an_idx])\n",
    "\t# display(RL_template_epoch_actually_included_aclus[an_idx])\n",
    "\t# epoch_active_aclus = np.sort(union_of_arrays(LR_template_epoch_actually_included_aclus[an_idx], RL_template_epoch_actually_included_aclus[an_idx]))\n",
    "\t# print(f'epoch_active_aclus: {epoch_active_aclus}')\n",
    "\tprint(f'______________________________________________________________________________________________________________________\\n')\n",
    "\t\n",
    "a_plotter.write_to_log(str(out.getvalue()))\n",
    "# # update the displayed cells:\n",
    "# directional_template_pfs_debugger_on_update_callback = _out_directional_template_pfs_debugger.get('ui').on_update_callback\n",
    "# directional_template_pfs_debugger_on_update_callback(epoch_active_aclus)\n",
    "# _out_directional_template_pfs_debugger = curr_active_pipeline.display(DirectionalPlacefieldGlobalDisplayFunctions._display_directional_template_debugger, included_any_context_neuron_ids=epoch_active_aclus)\n",
    "\n",
    "# rank_order_results.ripple_most_likely_result_tuple.long_short_best_dir_z_score_diff_values[an_idx]\n",
    "# display(LR_template_epoch_actually_included_aclus[an_idx])\n",
    "# display(RL_template_epoch_actually_included_aclus[an_idx])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_out_rank_order_event_raster_debugger.on_idx_changed_callback_function_dict['a_debug_callback'] = a_debug_callback_fn\n",
    "_out_rank_order_event_raster_debugger.on_idx_changed_callback_function_dict['debug_update_plot_titles_callback'] = debug_update_plot_titles\n",
    "# _out_rank_order_event_raster_debugger.on_idx_changed_callback_function_dict['debug_update_paired_directional_template_pfs_debugger'] = debug_update_paired_directional_template_pfs_debugger\n",
    "# _out_rank_order_event_raster_debugger.on_idx_changed_callback_function_dict['debug_update_long_short_info_titles'] = debug_update_long_short_info_titles\n",
    "# _out_rank_order_event_raster_debugger.on_idx_changed_callback_function_dict['debug_plot_epoch_label_row'] = debug_plot_epoch_label_row\n",
    "\n",
    "\n",
    "\n",
    "_out_rank_order_event_raster_debugger.on_update_epoch_IDX(11)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CodeParsers.extract_assigned_variable_names(code_block)) # BUG: returning only: ['num_sessions', 'num_sessions']\n",
    "\n",
    "# print(CodeParsers.find_input_variables(code_block))\n",
    "# print(extract_variable_names(code_block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_yellow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
