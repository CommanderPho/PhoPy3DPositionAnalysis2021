{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatBaseRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.core.session.Formats.SessionSpecifications import SessionFolderSpec, SessionFileSpec\n",
    "\n",
    "# For specific load functions:\n",
    "from neuropy.core import DataWriter, NeuronType, Neurons, BinnedSpiketrain, Mua, ProbeGroup, Position, Epoch, Signal, Laps, FlattenedSpiketrains, Shank, Probe, ProbeGroup\n",
    "from neuropy.io import OptitrackIO, PhyIO\n",
    "from neuropy.utils.mixins.print_helpers import ProgressMessagePrinter, SimplePrintable, OrderedMeta\n",
    "\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder, DataSessionFormatBaseRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/home/halechr/FastData'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/home/halechr/cloud/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "\n",
    "\n",
    "## Rachel:\n",
    "active_data_mode_name = 'rachel'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('Rachel')\n",
    "\n",
    "# basedir: Path = Path(r'W:\\Data\\Rachel\\20230614_Rachel').resolve()\n",
    "\n",
    "# basedir: Path = Path('/home/halechr/FastData/Rachel/20230614_Rachel/merged_20230614_2crs.GUI').resolve()\n",
    "\n",
    "basedir: Path = Path('/home/halechr/FastData/Rachel/20230614_Rachel').resolve()\n",
    "assert basedir.exists()\n",
    "\n",
    "# filename: str = '20230614_Rachel'\n",
    "# filename: str = '20230614_Rachel_2'\n",
    "filename: str = 'merged_20230614_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id column does not exist in cluster_info.tsv. Using cluster_id column instead.\n",
      "merged_20230614_2.neurons.npy saved\n",
      "start_t: 43339.095\n",
      "brelative.shape: (221455, 4)\n",
      "behaviordf.shape: (221455, 3)\n",
      "merged_20230614_2.position.npy saved\n",
      "merged_20230614_2.paradigm.npy saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# RachelDataSessionFormat.initialize_data_directory(basedir)\n",
    "## Builds the .neurons.npy:\n",
    "# folder = Path('/home/wahlberg/Exp_Data/M1_Nov2021/20211123/merged_M1_20211123_raw/merged_M1_20211123_raw_phy')\n",
    "# folder = Path(r'W:\\Data\\Rachel\\20230614_Rachel')\n",
    "folder = basedir.resolve()\n",
    "phydata = PhyIO(folder)\n",
    "# /home/halechr/FastData/Rachel/20230614_Rachel/params.py\n",
    "\n",
    "\n",
    "# neuronIDs = pd.read_csv(r'W:\\Data\\Rachel\\20230614_Rachel\\cluster_q.tsv');\n",
    "\n",
    "neuronIDs = pd.read_csv(basedir.joinpath('cluster_q.tsv'))\n",
    "neurons = Neurons(spiketrains=phydata.spiketrains, t_stop=2*3600, sampling_rate=30000, neuron_ids = {1:'pyr1',2:'pyr2',3:'pyr3',4:'int1',5:'int2',6:'int3',7:\"mua1\",8:'mua2',9:'mua3'})\n",
    "neurons.filename = folder.joinpath(f'{filename}.neurons.npy')\n",
    "neurons.save()\n",
    "\n",
    "# Probe Groups file\n",
    "# TODO: Probe group generation\n",
    "# shanks = []\n",
    "# # channel_groups = sess.recinfo.channel_groups\n",
    "# for i in range(8):\n",
    "#     shank = Shank.auto_generate(\n",
    "#         columns=1,\n",
    "#         contacts_per_column=128,\n",
    "#         xpitch=90,\n",
    "#         ypitch=0,\n",
    "#         y_shift_per_column=[0, 0],\n",
    "#         channel_id=np.arange(0,128,1)\n",
    "#         ),\n",
    "\t\n",
    "# elec_IDs = np.arange(0,128,1)\n",
    "# shanks = Shank.auto_generate(channels=1, contacts_per_column = 128)\n",
    "# shanks = pd.read_csv('/home/wahlberg/Exp_Data/M1_Nov2021/20211123/merged_M1_20211123_raw/Probe.csv',delimiter=',',usecols=[\"ShankNumber\"])\n",
    "# prb = Probe(shanks)\n",
    "# prbgroup = ProbeGroup()\n",
    "# prbgroup.add_probe(prb)\n",
    "\n",
    "\n",
    "## Builds the .position.npy:\n",
    "# opti_folder = Path(r'W:\\Data\\Rachel\\20230614_Rachel')\n",
    "# opti_folder = basedir.resolve()\n",
    "# opti_data = OptitrackIO(opti_folder)\n",
    "# brelative = pd.read_csv(r'W:\\Data\\Rachel\\20230614_Rachel\\merged_M1_20211123_raw_behavior_relativetoLFP.csv',header = None)\n",
    "\n",
    "csv_path = basedir.joinpath(f'20230614_positionData.csv')\n",
    "# brelative = pd.read_csv(csv_path, header = None)\n",
    "brelative = pd.read_csv(csv_path)\n",
    "brelative\n",
    "# Change column type to timedelta64[ns] for column: 'AbsoluteTime'\n",
    "brelative = brelative.astype({'AbsoluteTime': 'timedelta64[ns]'})\n",
    "\n",
    "brelative_seconds = brelative.AbsoluteTime.dt.total_seconds().to_numpy()\n",
    "start_t = np.min(brelative_seconds)\n",
    "# start_t = np.min(brelative.AbsoluteTime.to_numpy())\n",
    "print(f'start_t: {start_t}')\n",
    "\n",
    "t_relative = brelative_seconds - start_t\n",
    "t_relative\n",
    "\n",
    "print(f'brelative.shape: {brelative.shape}')\n",
    "# d = {'t':brelative[0],'x':opti_data.z,'y':opti_data.x} \n",
    "d = {'t':brelative_seconds,'x':brelative.Z.to_numpy(),'y':brelative.X.to_numpy()} \n",
    "\n",
    "behaviordf = pd.DataFrame(data=d)\n",
    "print(f'behaviordf.shape: {behaviordf.shape}')\n",
    "position = Position(behaviordf)\n",
    "# position.filename = Path(f'W:\\Data\\Rachel\\20230614_Rachel\\{filename}.position.npy')\n",
    "position.filename = basedir.joinpath(f'{filename}.position.npy')\n",
    "position.save()\n",
    "\n",
    "## Builds the .paradigm.npy file from scratch:\n",
    "# starts = [0, 5*60]\n",
    "# stops = [5*60-1, 3.8398632e+03]\n",
    "# labels = ['pre','maze']\n",
    "\n",
    "paradigm_df = pd.DataFrame(dict(label=['Pre','Maze','Post'],\n",
    "\tstart = ['11:15:49.000','12:02:19.095','13:08:37.999'],\n",
    "\tstops = ['11:53:19.384','13:04:54.815','14:53:22.047'],\n",
    "))\n",
    "# Change column type to timedelta64[ns] for columns: 'Starts', 'Stops'\n",
    "paradigm_df = paradigm_df.astype({'start': 'timedelta64[ns]', 'stops': 'timedelta64[ns]'})\n",
    "\n",
    "\n",
    "## Build and save the paradigm.npy\n",
    "d = {'start':paradigm_df.start.dt.total_seconds().to_numpy(),\n",
    "\t 'stop':paradigm_df.stops.dt.total_seconds().to_numpy(),\n",
    "\t 'label':paradigm_df.label.to_list()} \n",
    "paradigmdf = pd.DataFrame(data=d)\n",
    "paradigm = Epoch(paradigmdf)\n",
    "# paradigm.filename = Path('/home/wahlberg/Exp_Data/M1_Nov2021/20211123/merged_M1_20211123_raw/merged_M1_20211123_raw_phy/merged_M1_20211123_raw.paradigm.npy')\n",
    "paradigm.filename = basedir.joinpath(f'{filename}.paradigm.npy')\n",
    "paradigm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RequiredFileError",
     "evalue": "Required File: /home/halechr/FastData/Rachel/20230614_Rachel/merged_20230614_2.probegroup.npy does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRequiredFileError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/halechr/repos/Spike3D/SCRATCH/RachelSessionLoading.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/halechr/repos/Spike3D/SCRATCH/RachelSessionLoading.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m _test_session \u001b[39m=\u001b[39m RachelDataSessionFormat\u001b[39m.\u001b[39;49mbuild_session(basedir)\n",
      "File \u001b[0;32m~/repos/NeuroPy/neuropy/core/session/Formats/BaseDataSessionFormats.py:411\u001b[0m, in \u001b[0;36mDataSessionFormatBaseRegisteredClass.build_session\u001b[0;34m(cls, basedir)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39m# get the default preprocessing parameters:\u001b[39;00m\n\u001b[1;32m    410\u001b[0m preprocessing_parameters \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mbuild_default_preprocessing_parameters()                                                    \n\u001b[0;32m--> 411\u001b[0m session_config \u001b[39m=\u001b[39m SessionConfig(basedir, format_name\u001b[39m=\u001b[39;49mformat_name, session_spec\u001b[39m=\u001b[39;49msession_spec, session_name\u001b[39m=\u001b[39;49msession_name, session_context\u001b[39m=\u001b[39;49msession_context, preprocessing_parameters\u001b[39m=\u001b[39;49mpreprocessing_parameters)\n\u001b[1;32m    412\u001b[0m \u001b[39massert\u001b[39;00m session_config\u001b[39m.\u001b[39mis_resolved, \u001b[39m\"\u001b[39m\u001b[39mactive_sess_config could not be resolved!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m session_obj \u001b[39m=\u001b[39m DataSession(session_config)\n",
      "File \u001b[0;32m<attrs generated init neuropy.core.session.Formats.SessionSpecifications.SessionConfig>:13\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, basepath, session_spec, session_name, session_context, format_name, preprocessing_parameters)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolved_required_filespecs_dict \u001b[39m=\u001b[39m __attr_factory_resolved_required_filespecs_dict()\n\u001b[1;32m     12\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolved_optional_filespecs_dict \u001b[39m=\u001b[39m __attr_factory_resolved_optional_filespecs_dict()\n\u001b[0;32m---> 13\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__attrs_post_init__()\n",
      "File \u001b[0;32m~/repos/NeuroPy/neuropy/core/session/Formats/SessionSpecifications.py:182\u001b[0m, in \u001b[0;36mSessionConfig.__attrs_post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__attrs_post_init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    181\u001b[0m     \u001b[39m# Computed variables:\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_resolved, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolved_required_filespecs_dict, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolved_optional_filespecs_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession_spec\u001b[39m.\u001b[39;49mvalidate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbasepath)\n",
      "File \u001b[0;32m~/repos/NeuroPy/neuropy/core/session/Formats/SessionSpecifications.py:111\u001b[0m, in \u001b[0;36mSessionFolderSpec.validate\u001b[0;34m(self, proposed_session_path)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m a_required_filepath\u001b[39m.\u001b[39mexists():\n\u001b[1;32m    110\u001b[0m         meets_spec \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m                    \n\u001b[0;32m--> 111\u001b[0m         \u001b[39mraise\u001b[39;00m RequiredFileError(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRequired File: \u001b[39m\u001b[39m{\u001b[39;00ma_required_filepath\u001b[39m}\u001b[39;00m\u001b[39m does not exist.\u001b[39m\u001b[39m'\u001b[39m, (a_required_filepath, a_file_spec))\n\u001b[1;32m    112\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39mfor\u001b[39;00m a_required_validation_function \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madditional_validation_requirements:\n",
      "\u001b[0;31mRequiredFileError\u001b[0m: Required File: /home/halechr/FastData/Rachel/20230614_Rachel/merged_20230614_2.probegroup.npy does not exist."
     ]
    }
   ],
   "source": [
    "\n",
    "_test_session = RachelDataSessionFormat.build_session(basedir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_session, loaded_file_record_list = RachelDataSessionFormat.load_session(_test_session)\n",
    "_test_session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
