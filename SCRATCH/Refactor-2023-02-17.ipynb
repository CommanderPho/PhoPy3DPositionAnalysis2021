{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f46fd43-a3f1-4d15-994f-11f0347d918f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb936cf1-cb5f-41e9-a12b-c7e5b1831cef",
   "metadata": {},
   "source": [
    "# 2023-01-26 - 'portion' interval library for doing efficient interval calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e2b88d-23a3-432a-992a-d4d49b6f6291",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import Epoch\n",
    "import portion as P\n",
    "from neuropy.utils.efficient_interval_search import filter_epochs_by_speed\n",
    "from neuropy.utils.efficient_interval_search import convert_PortionInterval_to_Epoch_obj, convert_Epoch_obj_to_PortionInterval_obj\n",
    "# Filter *_replays_Interval by requiring them to be below the speed:\n",
    "speed_thresh = 2.0\n",
    "global_session = curr_active_pipeline.filtered_sessions['maze']\n",
    "global_replays = Epoch(epochs=global_session.replay.epochs.get_valid_df())\n",
    "speed_df = global_session.position.to_dataframe()\n",
    "global_replays, above_speed_threshold_intervals, below_speed_threshold_intervals = filter_epochs_by_speed(speed_df, global_replays, speed_thresh=speed_thresh, debug_print=True)\n",
    "# long_replays, short_replays, global_replays, above_speed_threshold_intervals, below_speed_threshold_intervals = filter_epochs_by_speed(speed_df, long_replays, short_replays, global_replays, speed_thresh=speed_thresh, debug_print=True)\n",
    "global_ripple = global_session.ripple\n",
    "global_pbe = global_session.pbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29920a11-bce0-4b9b-a666-7b21ed30dee0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "high_speed_epochs = convert_PortionInterval_to_Epoch_obj(above_speed_threshold_intervals)\n",
    "low_speed_epochs = convert_PortionInterval_to_Epoch_obj(below_speed_threshold_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189dbc8a-f6c0-43e1-aa9e-07c0bcc8d6d8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## Plot them all on the epoch rect viewer:\n",
    "\n",
    "import srsly\n",
    "output_parent_folder = Path('C:/Users/pho/repos/PhoPy3DPositionAnalysis2021/data')\n",
    "output_path = output_parent_folder.joinpath(f\"{curr_active_pipeline.session_name}\")\n",
    "print(f'writing out to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab36266-5d3a-473a-aa2f-03bc3af86da4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "global_ripple.as_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2336f458-1cee-49a2-9a14-e21f6c255fa5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# srsly.write_gzip_json(path=output_path, data=dict(global_ripples=global_ripple., global_pbes=global_pbe, global_replays=global_replays))\n",
    "# srsly.write_gzip_json(path=output_path, data=dict(global_ripples=global_ripple.to_dataframe(), global_pbes=global_pbe.to_dataframe(), global_replays=global_replays.to_dataframe()))\n",
    "# global_ripple.to_dataframe().to\n",
    "\n",
    "all_df = dict(global_ripples=global_ripple.to_dataframe(), global_pbes=global_pbe.to_dataframe(), global_replays=global_replays.to_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fe4b99-6600-477e-9c45-070b515a207a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#consider all_df as a list of dataframes\n",
    "with pd.HDFStore('df_store.h5') as df_store:\n",
    "    for i in all_df.keys():\n",
    "        df_store[i] = all_df[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df77b3-5c3a-46f5-b838-69adc84a77d6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "new_all_df = dict()\n",
    "with pd.HDFStore('df_store.h5') as df_store:\n",
    "    for i in df_store.keys():\n",
    "        new_all_df[i] = df_store[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44e388-b112-491e-9b10-f3c7b864ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store associated values with `P.IntervalDict()`:\n",
    "d = P.IntervalDict()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0cb825-09fd-4369-b006-584d7526ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for i in range(len(df)):\n",
    "#     print(f'i: {i}')\n",
    "#     print(f'df.index[i]: {df.index[i]}')\n",
    "#     print(f\"df.loc[i, 'speed']: {df.loc[i, 'speed']}\")\n",
    "#     print(f\"df.loc[df.index[i], 'speed']: {df.loc[df.index[i], 'speed']}\")\n",
    "#     assert df.loc[df.index[i], 'speed'] == df.loc[i, 'speed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37665615-f3df-437b-912e-068a5bdb3bf1",
   "metadata": {
    "incorrectly_encoded_metadata": "jp-MarkdownHeadingCollapsed=true",
    "tags": []
   },
   "source": [
    "# 2023-02-10 - _perform_spike_burst_detection_computation to get burst during replay events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8098f0ac-2a11-4532-a7c6-834b9425997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb on\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_spike_burst_detection_computation'], enabled_filter_names=['maze'], debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c0ebc-0d39-47fd-ae91-1c23995508a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_burst_info = curr_active_pipeline.computation_results['maze'].computed_data['burst_detection']\n",
    "active_burst_intervals = active_burst_info['burst_intervals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ebca8e-27a8-4821-a5ed-f5803db4a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the burst_detection burst_intervals to the active_2d_plot:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Render2DEventRectanglesHelper import Render2DEventRectanglesHelper\n",
    "active_2d_plot = spike_raster_plt_2d\n",
    "# active_burst_info = global_results['burst_detection']\n",
    "# active_burst_intervals = active_burst_info['burst_intervals']\n",
    "output_display_items = Render2DEventRectanglesHelper.add_event_rectangles(active_2d_plot, active_burst_intervals) # {'interval_rects_item': active_interval_rects_item}\n",
    "active_interval_rects_item = output_display_items['interval_rects_item']\n",
    "active_interval_rects_item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99b3dca-8710-4eb9-8196-7205f8a098d9",
   "metadata": {
    "incorrectly_encoded_metadata": "jp-MarkdownHeadingCollapsed=true jp-MarkdownHeadingCollapsed=true tags=[] jp-MarkdownHeadingCollapsed=true tags=[] jp-MarkdownHeadingCollapsed=true tags=[] jp-MarkdownHeadingCollapsed=true",
    "tags": []
   },
   "source": [
    "# 2023-02-08 - pynapple exploration and custom `write_neuroscope_intervals` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2452bb84-2c18-4abc-9150-db99b5cc9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pynapple as nap\n",
    "from pynapple.core.interval_set import IntervalSet\n",
    "\n",
    "def write_neuroscope_intervals(isets, name, parent_path, basename, extension='derived.evt'):\n",
    "    \"\"\"Write events to load with neuroscope (e.g. ripples start and ends)\n",
    "    \n",
    "    Written 2023-02-08 to save computed replays out to .evt file to be read in by Neuroscope, but unfortunately it looks like the Epoch.to_neuroscope(...) function already works just as well (if not better) and doesn't require pynapple...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    extension : str\n",
    "        The extension of the file (e.g. basename.evt.py.rip)\n",
    "    isets : IntervalSet\n",
    "        The IntervalSet to write\n",
    "    name : str\n",
    "        The name of the events (e.g. Ripples)\n",
    "    \"\"\"\n",
    "    start = isets.as_units(\"ms\")[\"start\"].values\n",
    "    ends = isets.as_units(\"ms\")[\"end\"].values\n",
    "\n",
    "    datatowrite = np.vstack((start, ends)).T.flatten()\n",
    "\n",
    "    n = len(isets)\n",
    "\n",
    "    texttowrite = np.vstack(\n",
    "        (\n",
    "            (np.repeat(np.array([name + \" start\"]), n)),\n",
    "            (np.repeat(np.array([name + \" end\"]), n)),\n",
    "        )\n",
    "    ).T.flatten()\n",
    "\n",
    "    evt_file = os.path.join(parent_path, basename + extension)\n",
    "\n",
    "    f = open(evt_file, \"w\")\n",
    "    for t, n in zip(datatowrite, texttowrite):\n",
    "        f.writelines(\"{:1.6f}\".format(t) + \"\\t\" + n + \"\\n\")\n",
    "    f.close()\n",
    "\n",
    "    return evt_file\n",
    "\n",
    "outIntervalSet = IntervalSet(start=out.starts, end=out.stops, time_units=\"s\")\n",
    "write_neuroscope_intervals(outIntervalSet, 'pho_replays', str(active_sess.basepath), active_sess.name, extension='.PHO.evt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0fd7cf-10a1-41df-ad7b-ad3b848cbe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynapple.io import write_neuroscope_intervals\n",
    "neurosuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d626d06-992a-419c-8ac9-47f6c7366cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nap_session = nap.load_session(str(active_sess.basepath), 'neurosuite')\n",
    "nap_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e096ee-d822-4330-b80b-0830fc941a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_sess.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1213c7e6-b8db-4c0d-a21e-cb4a65f4e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_sess.basepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607af776-2b51-4d52-a47a-662b94b10bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = active_sess.basepath\n",
    "\n",
    "# parent_path.with_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee0a237-5e38-4073-a0fa-1f2e306f24d3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## Compute estimated replay intervals from the PBEs and export them to a neuroscope file\n",
    "active_sess = curr_active_pipeline.filtered_sessions['maze']\n",
    "out = active_sess.perform_compute_estimated_replay_epochs(min_epoch_included_duration=0.06, maximum_speed_thresh=2.0)\n",
    "out.filename = active_sess.basepath.joinpath(active_sess.name).with_suffix('.derived')\n",
    "final_export_path = out.to_neuroscope()\n",
    "print(f'Exporting estimated replays to Neuroscope .evt file: {final_export_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450b50c-278a-40b9-b6ad-2759f31606eb",
   "metadata": {
    "incorrectly_encoded_metadata": "jp-MarkdownHeadingCollapsed=true jp-MarkdownHeadingCollapsed=true tags=[] jp-MarkdownHeadingCollapsed=true jp-MarkdownHeadingCollapsed=true tags=[] jp-MarkdownHeadingCollapsed=true jp-MarkdownHeadingCollapsed=true",
    "tags": []
   },
   "source": [
    "# 2023-02-08 - Automatic context using function decorators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf782f-0f29-4ee1-8c2b-379ef3a404d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_context_cache = active_sess.perform_compute_estimated_replay_epochs.__cache__()\n",
    "_context_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940a565-54a4-485f-9cbf-f0147600c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_context_cache.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9eaa26-2944-4f13-a4e9-c9c0fb973271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_arguments_from_stringmap_key(a_tuple_str):\n",
    "    \"\"\" rebuilds the arg, kwargs from a cached function call that was cached using the keymap 'stringmap' \"\"\"\n",
    "    NULL = 'NULL'\n",
    "    # each key is a tuple containing (args, kwargs) for the function\n",
    "    # print(f'{a_tuple_str =}, len: {len(a_tuple_str)}')\n",
    "    a_tuple = eval(a_tuple_str) # eval the string back into a real Python tuple\n",
    "    args, kwargs = a_tuple\n",
    "    # remove NULL entries\n",
    "    kwargs = {k:v for k, v in kwargs.items() if v != 'NULL'}\n",
    "    # print(kwargs)\n",
    "    # print(f'{(args, kwargs) =}')\n",
    "    return args, kwargs\n",
    "    \n",
    "_context_cache_recovered_args = {}\n",
    "\n",
    "for a_key_str in _context_cache.keys():\n",
    "    args, kwargs = rebuild_arguments_from_stringmap_key(a_key_str)\n",
    "    _context_cache_recovered_args[a_key_str] = (args, kwargs)\n",
    "    \n",
    "_context_cache_recovered_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c4a25-ce0b-4fcd-bfd0-9fa085042ffa",
   "metadata": {},
   "source": [
    "Ideally could access all of the 'Epoch'-type members (or Epoch-convertable dataframes) the object (session in this case) has. This allows visualizations to \"discover\" the possible types of data they can visualize without having to code a custom menu-item/visualization/etc for each type of epoch. Ideally this like a \"trait\" or something, perhaps a property decorator?\n",
    "Makes the most sense for computed data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359b87ca-75e5-4ca5-8606-65a3f0b97c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_sess.perform_compute_estimated_replay_epochs.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f471b71b-bdce-40ad-9d28-69125af8cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_sess.perform_compute_estimated_replay_epochs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a18ec5a-1250-45d8-9184-9c268ecbb651",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_sess.perform_compute_estimated_replay_epochs.__map__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff2c698-97d9-4f00-8798-3a734ca04baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_sess.perform_compute_estimated_replay_epochs.__mask__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike3d-poetry",
   "language": "python",
   "name": "spike3d-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
