{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd5d37-e658-4133-afa0-a8641b5fecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-05-23 - This code was created to quickly backup all of the good `loadedSessPickle.pkl` files from the session folders into the './output' subfolder in the session:\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-09_21-17-16/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-04_21-20-3/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_21-26-8/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-09_22-4-5/output/loadedSessPickle.pkl already in output folder.\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08951e7-4fef-4226-b3cd-75627533e944",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional, Dict, List\n",
    "\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file, FileList\n",
    "from pyphocorehelpers.Filesystem.path_helpers import convert_filelist_to_new_parent\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_files_metadata\n",
    "\n",
    "# import glob # for finding .whl file after building binary repo\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'/media/MAX/Data'), Path(r'/home/halechr/turbo/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/FastData'), Path(r'/Volumes/MoverNew/data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "\n",
    "completed_pipeline_filename = 'loadedSessPickle.pkl'\n",
    "completed_global_computations_filename = 'global_computation_results.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_data_root_parent_path changed to /home/halechr/FastData\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbfb7fca1d54a26ad3a747d7d998794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Data Root:', layout=Layout(width='auto'), options=(PosixPath('/home/halechr/FastDatâ€¦"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import build_global_data_root_parent_path_selection_widget\n",
    "    \n",
    "all_paths = [Path(r'/home/halechr/turbo/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/FastData'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data')]\n",
    "global_data_root_parent_path = None\n",
    "def on_user_update_path_selection(new_path: Path):\n",
    "\tglobal global_data_root_parent_path\n",
    "\tnew_global_data_root_parent_path = new_path.resolve()\n",
    "\tglobal_data_root_parent_path = new_global_data_root_parent_path\n",
    "\tprint(f'global_data_root_parent_path changed to {global_data_root_parent_path}')\n",
    "\tassert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "\t\t\t\n",
    "global_data_root_parent_path_widget = build_global_data_root_parent_path_selection_widget(all_paths, on_user_update_path_selection)\n",
    "global_data_root_parent_path_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data_root_parent_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_file_metadata\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file, save_copydict_to_text_file, read_copydict_from_text_file, invert_filedict\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import get_file_str_if_file_exists\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import check_output_h5_files, copy_files_in_filelist_to_dest\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import ConcreteSessionFolder, BackupMethods\n",
    "\n",
    "# BATCH_DATE_TO_USE = '2023-10-18_Apogee' # used for filenames throught the notebook\n",
    "# BATCH_DATE_TO_USE = '2023-11-15_Lab' # used for filenames throught the notebook\n",
    "BATCH_DATE_TO_USE = '2024-01-09' # used for filenames throught the notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29978b7c-a1cc-4e6b-bf40-d2f1af0ecee6",
   "metadata": {},
   "source": [
    "## Old (Pre 2023-09-21):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c4083-b7b0-4a4a-ad63-7db9400ff058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use glob to find the first generated .whl file in the dist/ directory\n",
    "found_whl_files = glob.glob('*.whl')\n",
    "found_whl_files = [a for a in found_whl_files if not a.endswith('current.whl')] # exclude the symlink from the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa314cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_computed_ripple_filepath = session.basepath.joinpath('ripple_df.pkl')\n",
    "## try the '.ripple.npy' ripples:\n",
    "active_file_suffix = '.ripple.npy'\n",
    "external_computed_ripple_filepath = fp.with_suffix(active_file_suffix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db0613-f7f6-48a7-9beb-2f17b3eb941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moves all previously saved loadedSessPickle.pkl files to the output folder.\n",
    "correctly_placed_output_files = []\n",
    "search_path: Path = Path(\"/home/halechr/turbo/Data/KDIBA/\").resolve()\n",
    "assert search_path.exists()\n",
    "for p in search_path.rglob(completed_pipeline_filename):\n",
    "    if p.parent.name != 'output':\n",
    "        # If not already in the 'output/' subfolder, move it there.\n",
    "        print(f'p: {p}')\n",
    "        curr_output_dir = p.parent.joinpath('output')\n",
    "        curr_output_dir.mkdir(exist_ok=True)\n",
    "        # print(f'curr_output_dir: {curr_output_dir}')\n",
    "        new_path = p.replace(curr_output_dir.joinpath(p.name))\n",
    "        print(f'\\t new_path: {new_path}')\n",
    "        correctly_placed_output_files.append(p)\n",
    "    else:\n",
    "        print(f'p: {p} already in output folder.')\n",
    "        correctly_placed_output_files.append(p)\n",
    "    \n",
    "correctly_placed_output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_pipeline_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Build Pickle Path:\n",
    "pkl_path = 'global_batch_result_2023-06-08.pkl'\n",
    "csv_path = 'global_batch_result_2023-06-08.csv'\n",
    "h5_path = 'global_batch_result_2023-06-08.h5'\n",
    "\n",
    "global_batch_result_file_path = Path(global_data_root_parent_path).joinpath(h5_path).resolve() # Use Default\n",
    "\n",
    "batch_progress_df = BatchRun.load_batch_progress_df_from_h5(global_batch_result_file_path)\n",
    "batch_progress_df\n",
    "\n",
    "updated_batch_progress_df = BatchRun.rebuild_basedirs(batch_progress_df, global_data_root_parent_path)\n",
    "updated_batch_progress_df\n",
    "\n",
    "updated_good_only_batch_progress_df = updated_batch_progress_df[updated_batch_progress_df['locally_is_ready']].copy()\n",
    "updated_good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate code that can be pasted into the current \"ReviewOfWork-*.ipynb\" notebook to load the good sessions:\n",
    "print(\",\\n\".join([a_ctxt.get_initialization_code_string() for a_ctxt in updated_good_only_batch_progress_df['context'].to_list()]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23cecbf",
   "metadata": {},
   "source": [
    "# 2023-09-21 - Mirror Slow Data files to much faster SSD: , Path(r'/home/halechr/FastData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35d6bc86",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil # used in `restore_symlink_folder`\n",
    "from shutil import copytree # used in `make_specific_items_local`\n",
    "from typing import Optional, Dict, List\n",
    "from datetime import datetime, timedelta\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_file_metadata\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file\n",
    "from attrs import define, field, Factory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_symlink_ancestor_path(path: Path) -> Path or None:\n",
    "    \"\"\"Returns the path of the nearest parent directory of 'path' that is a symbolic link.\n",
    "    If no parent directories are symbolic links, returns None.\n",
    "    \n",
    "    Usage:\n",
    "        existing_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/pin01/one/11-09_22-4-5/11-09_22-4-5IN.5.numclu')\n",
    "        nearest_symlink_ancestor_path(existing_symlink_path)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    for parent in path.parents:\n",
    "        if parent.is_symlink():\n",
    "            return parent\n",
    "    return None\n",
    "\n",
    "def symlinked_item_to_full_local_item(existing_symlink_path: Path, dryrun: bool=False) -> bool:\n",
    "    \"\"\" takes a path to an existing symlink on disk. Replaces that symlink with a local file/folder of the same name, copied from the symlink target.\n",
    "\n",
    "    returns bool: true if symlink was localized\n",
    "        \n",
    "    WARNING:\n",
    "        DO NOT CALL .resolve() on the input path, this resolves the symlink!!!\n",
    "            \n",
    "    Usage:\n",
    "\n",
    "        existing_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/pin01/one/fet11-01_12-58-54') ## DO NOT CALL .resolve() on the input path, this resolves the symlink!!!\n",
    "        print(f'existing_symlink_path: {existing_symlink_path}')\n",
    "        assert existing_symlink_path.exists()\n",
    "        symlinked_item_to_full_local_item(existing_symlink_path, dryrun=False)\n",
    "        \n",
    "        \n",
    "    Potential Issue:\n",
    "        if '/home/halechr/FastData/KDIBA/pin01' is a symlink to '/media/MAX/Data/KDIBA/pin01'\n",
    "            If `symlinked_item_to_full_local_item` is called with existing_symlink_path='/home/halechr/FastData/KDIBA/pin01/one/fet11-01_12-58-54', doesn't it create a symlink to itself?\n",
    "\n",
    "\n",
    "        '/media/MAX/Data/KDIBA/pin01/one/fet11-01_12-58-54'\n",
    "    \"\"\"\n",
    "    # check that existing_symlink_path exists and is a symlink\n",
    "    if existing_symlink_path.is_symlink():\n",
    "        # Resolve the symlink without following it\n",
    "        unlinked_target = existing_symlink_path.resolve(strict=False)\n",
    "        # Check if the target's parent isn't under the symlink itself\n",
    "        if unlinked_target.parent in existing_symlink_path.parents:\n",
    "            print(f\"Error: cannot copy a folder or file into its child '{existing_symlink_path}'!\")\n",
    "            return False\n",
    "        \n",
    "\n",
    "        # resolve the symlink and ensure it exists\n",
    "        symlink_target = existing_symlink_path.resolve()\n",
    "        if not symlink_target.exists():\n",
    "            print(f\"Symlink target {symlink_target} does not exist.\")\n",
    "            return False\n",
    "        \n",
    "        # delete the original symlink and replace with a copy of the symlink target\n",
    "        if symlink_target.is_dir():        # if it's a directory\n",
    "            if dryrun:\n",
    "                print(f'Would delete symlink: {existing_symlink_path}')\n",
    "                print(f'Would copy directory {symlink_target} to {existing_symlink_path}')\n",
    "            else:\n",
    "                os.remove(existing_symlink_path)\n",
    "                shutil.copytree(symlink_target, existing_symlink_path)\n",
    "        else:    # it's a file\n",
    "            if dryrun:\n",
    "                print(f'Would delete symlink: {existing_symlink_path}')\n",
    "                print(f'Would copy file {symlink_target} to {existing_symlink_path}')\n",
    "            else:\n",
    "                os.remove(existing_symlink_path)\n",
    "                shutil.copy(symlink_target, existing_symlink_path)\n",
    "\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"{existing_symlink_path} is not a symlink.\")\n",
    "        \n",
    "        existing_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/pin01/one/11-09_22-4-5/11-09_22-4-5IN.5.numclu')\n",
    "        nearest_symlink_ancestor_path(existing_symlink_path)\n",
    "        nearest_symlink_ancestor_path(existing_symlink_path)\n",
    "        return False\n",
    "\n",
    "\n",
    "def symlinked_folder_to_local_folder_containing_symlinks(existing_symlink_folder_path: Path, dryrun: bool=False) -> bool:\n",
    "\t\"\"\" takes a path to an existing symlink on disk. Replaces that symlink with a local folder it creates in the same place, and then creates symlinks inside the new folder to all items in the symlinked folder.\n",
    "\n",
    "\treturns bool: true if symlink was changed\n",
    "\t\t\n",
    "\tWARNING:\n",
    "\t\tDO NOT CALL .resolve() on the input path, this resolves the symlink!!!\n",
    "            \n",
    "            \n",
    "    Usage:\n",
    "    \n",
    "\t\texisting_symlink_folder_path: Path = Path('/home/halechr/FastData/KDIBA/pin01') ## DO NOT CALL .resolve() on the input path, this resolves the symlink!!!\n",
    "\t\tprint(f'existing_symlink_folder_path: {existing_symlink_folder_path}')\n",
    "\t\tassert existing_symlink_folder_path.exists()\n",
    "\t\tsymlinked_folder_to_local_folder_containing_symlinks(existing_symlink_folder_path, dryrun=False)\n",
    "\n",
    "\t\"\"\"\n",
    "\t# check that existing_symlink_folder_path exists, is a symlink, and links to a folder\n",
    "\tif existing_symlink_folder_path.is_symlink():\n",
    "\t\tdestination_folder = existing_symlink_folder_path.resolve(strict=False)\n",
    "\t\tif destination_folder.is_dir():\n",
    "\t\t\tif dryrun:\n",
    "\t\t\t\tprint(f'Would delete symlink: {existing_symlink_folder_path}')\n",
    "\t\t\t\tprint(f'Would create directory: {existing_symlink_folder_path}')\n",
    "\t\t\t\t# print(f'Would create symlinks in {existing_symlink_folder_path} for all items in {destination_folder}')\n",
    "\t\t\telse:\n",
    "\t\t\t\t# delete the original symlink\n",
    "\t\t\t\tos.unlink(existing_symlink_folder_path)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# create new folder where the symlink was\n",
    "\t\t\t\tos.mkdir(existing_symlink_folder_path)\n",
    "\t\t\t\t\n",
    "\t\t\t# create symlinks in the new folder for each file/folder in the original symlinked folder\n",
    "\t\t\tfor item in destination_folder.iterdir():\n",
    "\t\t\t\tsymlink_path = existing_symlink_folder_path / item.name\n",
    "\t\t\t\tif dryrun:\n",
    "\t\t\t\t\tprint(f'\\t Would create symlinks in {symlink_path}\\t->\\t{item}')\n",
    "\t\t\t\telse:\t\n",
    "\t\t\t\t\tos.symlink(item, symlink_path)\n",
    "\t\t\t\t\t\n",
    "\t\t\treturn True\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"Original symlink destination {destination_folder} is not a directory.\")\n",
    "\t\t\treturn False\n",
    "\n",
    "\telse:\n",
    "\t\tprint(f\"{existing_symlink_folder_path} is not a symlink.\")\n",
    "\t\tprint(f'if this above shows an unexpected path (the target and not the symlink location you thought you passed in), make sure you are not calling `existing_symlink_folder_path.resolve()` on the input, this resolves the symlink!\\n')\n",
    "\t\treturn False\n",
    "\n",
    "\n",
    "def restore_symlink_folder(original_folder_path: Path, dryrun: bool=False) -> bool:\n",
    "    \"\"\"\n",
    "    This function takes a path to an existing directory filled with symlinked files and restores it to be one single symlink.\n",
    "\tInverse of `symlinked_folder_to_local_folder_containing_symlinks`\n",
    "\t\n",
    "\t\n",
    "    It works as follows:\n",
    "    - Check if `original_folder_path` is a directory\n",
    "    - If it is, scan its contents\n",
    "    - All contents should be symbolic links. If not, print an error message/exit\n",
    "    - All symbolic links should direct to the same directory. If not, print an error message/exit\n",
    "    - With the target directory established, delete `original_folder_path` and all contents\n",
    "    - Create a new symlink at `original_folder_path` pointing to the target directory\n",
    "    \n",
    "    \n",
    "    Usage:\n",
    "    \n",
    "    \trestore_symlink_folder(existing_symlink_folder_path, dryrun=False)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if original_folder_path.is_dir():\n",
    "        # Collect all unique destinations this folder points to (should only be one)\n",
    "        destinations = set(path.resolve().parent for path in original_folder_path.iterdir() if path.is_symlink()) # `set(...)` here is what make it so only unique entries are used\n",
    "\n",
    "        if len(destinations) > 1:\n",
    "            print(f'Error: multiple symlink destinations found in directory {original_folder_path}.\\n\\tdestinations: {destinations}')\n",
    "            return False\n",
    "        elif len(destinations) == 0:\n",
    "            print(f'Error: no symlinks found in directory {original_folder_path}.')\n",
    "            return False\n",
    "        else:\n",
    "            target_dir = destinations.pop()\n",
    "\n",
    "            if dryrun:\n",
    "                print(f'Would delete folder {original_folder_path} and its contents.')\n",
    "                print(f'Would create symlink: {original_folder_path} -> {target_dir}')\n",
    "            else:\n",
    "                # delete the directory and its content\n",
    "                shutil.rmtree(original_folder_path)\n",
    "\n",
    "                # create the symlink\n",
    "                os.symlink(target_dir, original_folder_path)\n",
    "      \n",
    "            return True\n",
    "    else:\n",
    "        print(f\"Error: {original_folder_path} is not a directory.\")\n",
    "        return False\n",
    "    \n",
    "\n",
    "\n",
    "def make_specific_items_local(existing_symlink_folder_path: Path, desired_local_folder_paths: List[Path], dryrun: bool=False) -> bool:\n",
    "    \"\"\" \n",
    "    Takes a path you wish to clone to a local folder from a symlink.\n",
    "    It then proceeds to copy the directories from the source directory to the destination directory using `shutil.copytree()`\n",
    "    This will handle going into subdirectories as well.\n",
    "\n",
    "    existing_symlink_folder_path: a path to the symlinked folder.\n",
    "    desired_local_folder_paths: a list of paths you wish to copy locally from the file.\n",
    "    \"\"\"\n",
    "    if existing_symlink_folder_path.is_symlink():\n",
    "        symlink_dest = existing_symlink_folder_path.resolve(strict=False)\n",
    "        \n",
    "        for desired_path in desired_local_folder_paths:\n",
    "            if not desired_path.is_symlink() and desired_path.is_dir():\n",
    "                rel_dest_path = existing_symlink_folder_path / desired_path.relative_to(symlink_dest)\n",
    "                \n",
    "                if dryrun:\n",
    "                    print(f\"Would copy contents of {desired_path} to {rel_dest_path}\")\n",
    "                else:\n",
    "                    copytree(src=str(desired_path), dst=str(rel_dest_path))\n",
    "                \n",
    "        return True\n",
    "    else:\n",
    "        print(f\"{existing_symlink_folder_path} is not a symlink.\")\n",
    "        return False\n",
    "    \n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing_symlink_folder_path: /home/halechr/FastData/KDIBA/pin01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "existing_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/pin01') ## DO NOT CALL .resolve() on the input path, this resolves the symlink!!!\n",
    "print(f'existing_symlink_folder_path: {existing_symlink_path}')\n",
    "assert existing_symlink_path.exists()\n",
    "symlinked_folder_to_local_folder_containing_symlinks(existing_symlink_path, dryrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing_symlink_folder_path: /home/halechr/FastData/KDIBA/pin01/one\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/pin01/one') ## DO NOT CALL .resolve() on the input path, this resolves the symlink!!!\n",
    "print(f'existing_symlink_folder_path: {existing_symlink_path}')\n",
    "assert existing_symlink_path.exists()\n",
    "symlinked_folder_to_local_folder_containing_symlinks(existing_symlink_path, dryrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing_symlink_folder_path: /home/halechr/FastData/KDIBA/pin01\n",
      "/home/halechr/FastData/KDIBA/pin01 is not a symlink.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make_specific_items_local\n",
    "\n",
    "# existing_symlink_folder_path: Path = Path('/home/halechr/FastData/KDIBA/pin01') ## DO NOT CALL .resolve() on the input path, this resolves the symlink!!!\n",
    "existing_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/pin01/one')\n",
    "print(f'existing_symlink_folder_path: {existing_symlink_path}')\n",
    "assert existing_symlink_path.exists()\n",
    "\n",
    "desired_local_folder_paths: List[Path] = [Path(v) for v in ['/media/MAX/Data/KDIBA/pin01/one/fet11-01_12-58-54']]\n",
    "\n",
    "make_specific_items_local(existing_symlink_path, desired_local_folder_paths=desired_local_folder_paths, dryrun=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing_symlink_path: /home/halechr/FastData/KDIBA/pin01/one/fet11-01_12-58-54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/pin01/one/fet11-01_12-58-54') ## DO NOT CALL .resolve() on the input path, this resolves the symlink!!!\n",
    "print(f'existing_symlink_path: {existing_symlink_path}')\n",
    "assert existing_symlink_path.exists()\n",
    "symlinked_item_to_full_local_item(existing_symlink_path, dryrun=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/halechr/FastData/KDIBA/pin01/one/11-09_22-4-5')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/pin01/one/11-09_22-4-5/11-09_22-4-5IN.5.numclu')\n",
    "nearest_symlink_ancestor_path(existing_symlink_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing_symlink_folder_path: /home/halechr/FastData/KDIBA/pin01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/pin01') ## DO NOT CALL .resolve() on the input path, this resolves the symlink!!!\n",
    "print(f'existing_symlink_folder_path: {existing_symlink_path}')\n",
    "assert existing_symlink_path.exists()\n",
    "restore_symlink_folder(existing_symlink_path, dryrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def attribute_is_extant_path(instance, attribute, value):\n",
    "\tif not isinstance(value, Path):\n",
    "\t\traise TypeError(f\"value must be a pathlib.Path but type(value): {type(value)}\")\n",
    "\tif not value.exists():\n",
    "\t\traise ValueError(f\"value must exists on the filesystem!\")\n",
    "\t\n",
    "\n",
    "\n",
    "@define(slots=False)\n",
    "class DataRepository:\n",
    "\tshort_name: str = field()\n",
    "\thost: str = field()\n",
    "\troot_path: Path = field()\n",
    "\n",
    "\t# def __attrs_post_init__(self):\n",
    "\t# \tassert root_path.exists()\n",
    "\t\t\n",
    "\t\t\n",
    "\tdef try_find_files(self):\n",
    "\t\t# Find the files and build the movedicts:\n",
    "\t\tsource_data_root = self.root_path.resolve()\n",
    "\t\tfound_session_pickle_files = discover_data_files(source_data_root, glob_pattern='loadedSessPickle.pkl', recursive=True)\n",
    "\t\tfound_global_computation_results_files = discover_data_files(source_data_root, glob_pattern=f'output/{completed_global_computations_filename}', recursive=True)\n",
    "\t\treturn found_session_pickle_files, found_global_computation_results_files\n",
    "\n",
    "data_repos = {'MAX':DataRepository('MAX', host='LNX00052', root_path=Path(r'/media/MAX/Data')),\n",
    "'FastData':DataRepository('FastData', host='LNX00052', root_path=Path(r'/home/halechr/FastData')),\n",
    "'gen_scripts':DataRepository('gen_scripts', host='LNX00052', root_path=Path(r'/home/halechr/FastData/gen_scripts/')),\n",
    "}\n",
    "\n",
    "\n",
    "included_session_contexts = [\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "\t  IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'), # prev completed\n",
    "]\n",
    "\n",
    "data_repos_good_session_concrete_folders_dict = {}\n",
    "\n",
    "data_repos\n",
    "# run_kdiba_gor01_one_2006-6-08_14-26-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "curr_good_session_concrete_folders = ConcreteSessionFolder.build_concrete_session_folders(data_repos['MAX'].root_path.resolve(), included_session_contexts)\n",
    "curr_good_session_concrete_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_session_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_repos_good_session_concrete_folders_dict['FastData'] = ConcreteSessionFolder.build_concrete_session_folders(data_repos['FastData'].root_path.resolve(), included_session_contexts, allow_create_needed_dirs=True)\n",
    "data_repos_good_session_concrete_folders_dict['FastData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_session_concrete_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_dict = ConcreteSessionFolder.build_backup_copydict(data_repos_good_session_concrete_folders_dict['FastData'], backup_mode=BackupMethods.RenameInSourceDirectory, rename_backup_suffix=BATCH_DATE_TO_USE, only_include_file_types=['global_pkl'])\n",
    "copy_dict_FastData = ConcreteSessionFolder.build_backup_copydict(data_repos_good_session_concrete_folders_dict['FastData'], backup_mode=BackupMethods.RenameInSourceDirectory, rename_backup_suffix=BATCH_DATE_TO_USE, only_include_file_types=['local_pkl', 'global_pkl'])\n",
    "copy_dict_FastData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moved_files_dict_FastData_files = copy_movedict(copy_dict_FastData)\n",
    "moved_files_dict_FastData_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_session_pickle_files, found_global_computation_results_files = data_repos['MAX'].try_find_files()\n",
    "found_session_pickle_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d60f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_data_root = Path(r'/media/MAX/Data')\n",
    "dest_data_root = Path(r'/home/halechr/FastData')\n",
    "assert source_data_root.exists(), f\"source_data_root: {source_data_root} does not exist! Is the right computer's config commented out above?\"\n",
    "assert dest_data_root.exists(), f\"dest_data_root: {dest_data_root} does not exist! Is the right computer's config commented out above?\"\n",
    "\n",
    "oldest_modified_date = (datetime.now() - timedelta(days=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the files and build the movedicts:\n",
    "found_session_pickle_files = discover_data_files(source_data_root, glob_pattern='loadedSessPickle.pkl', recursive=True)\n",
    "found_global_computation_results_files = discover_data_files(source_data_root, glob_pattern=f'output/{completed_global_computations_filename}', recursive=True)\n",
    "file_movedict_session_pickle_files = generate_copydict(source_data_root, dest_data_root, found_files=found_session_pickle_files, only_files_newer_than=oldest_modified_date)\n",
    "file_movedict_global_computation_results_pickle_files = generate_copydict(source_data_root, dest_data_root, found_files=found_global_computation_results_files, only_files_newer_than=oldest_modified_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a22684",
   "metadata": {},
   "source": [
    "### Actually perform copy operations. This will take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0548870",
   "metadata": {},
   "outputs": [],
   "source": [
    "moved_files_dict_session_pickle_files = copy_movedict(file_movedict_session_pickle_files)\n",
    "moved_files_dict_session_pickle_files\n",
    "\n",
    "# moved_files_dict = copy_files(filelist_source, filelist_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7732c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "moved_files_dict_global_computation_results_pickle_files = copy_movedict(file_movedict_global_computation_results_pickle_files)\n",
    "moved_files_dict_global_computation_results_pickle_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various file formats:\n",
    "'global_computation_results_2023-12-07_GL.pkl'\n",
    "'20231012125859-global_computation_results.pkltmp'\n",
    "\"loadedSessPickle_2023-12-07_GL.pkl\"\n",
    "\"backup-20231020190542-loadedSessPickle.pkl\"\n",
    "\"loadedSessPickle_2023-10-25_BidirectionalOnly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hardcoded included_session_contexts:\n",
    "included_session_contexts = [\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'), # prev completed\n",
    "]\n",
    "\n",
    "active_global_batch_result_filename=f'global_batch_result_{BATCH_DATE_TO_USE}.pkl'\n",
    "\n",
    "debug_print = False\n",
    "known_global_data_root_parent_paths = [Path(r'/home/halechr/cloud/turbo/Data'), Path(r'W:\\Data'), Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data')] # , Path(r'/home/halechr/FastData'), Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'/home/halechr/turbo/Data'), \n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "good_session_concrete_folders = ConcreteSessionFolder.build_concrete_session_folders(global_data_root_parent_path, included_session_contexts)\n",
    "\n",
    "## Build Slurm Scripts:\n",
    "session_basedirs_dict: Dict[IdentifyingContext, Path] = {a_session_folder.context:a_session_folder.path for a_session_folder in good_session_concrete_folders}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_files_dict = {}\n",
    "\n",
    "for a_ctxt, a_path in session_basedirs_dict.items():\n",
    "\tfound_any_kind_session_pickle_files = discover_data_files(a_path, glob_pattern='*loadedSessPickle*.pkl', recursive=True)\n",
    "\tfound_any_global_computation_results_files = discover_data_files(a_path, glob_pattern='output/*global_computation_results*.pkl', recursive=True)\n",
    "\tfound_files_dict[a_ctxt] = (found_any_kind_session_pickle_files, found_any_global_computation_results_files)\n",
    "\n",
    "found_files_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_tree(found_files_dict):\n",
    "    tree_str = \"\"\n",
    "    for session, (session_files, global_files) in found_files_dict.items():\n",
    "        tree_str += f\"{session}\\n\"\n",
    "        if session_files:\n",
    "            tree_str += \"  - Session Pickle Files:\\n\"\n",
    "            for file in session_files:\n",
    "                tree_str += f\"    * {file}\\n\"\n",
    "        if global_files:\n",
    "            tree_str += \"  - Global Computation Results Files:\\n\"\n",
    "            for file in global_files:\n",
    "                tree_str += f\"    * {file}\\n\"\n",
    "    return tree_str\n",
    "\n",
    "# Example of usage\n",
    "tree_representation = render_tree(found_files_dict)\n",
    "print(tree_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "def create_tree_view(found_files_dict):\n",
    "    sessions_accordion = widgets.Accordion(children=[widgets.VBox() for _ in found_files_dict])\n",
    "    for i, (session, (session_files, global_files)) in enumerate(found_files_dict.items()):\n",
    "        session_accordion = sessions_accordion.children[i]\n",
    "        \n",
    "        # Convert paths to strings and create session pickle files accordion\n",
    "        session_files_accordion = widgets.Accordion(children=[\n",
    "            widgets.VBox([widgets.Label(str(file)) for file in session_files])\n",
    "        ])\n",
    "        session_files_accordion.set_title(0, 'Session Pickle Files')\n",
    "\n",
    "        # Convert paths to strings and create global computation results files accordion\n",
    "        global_files_accordion = widgets.Accordion(children=[\n",
    "            widgets.VBox([widgets.Label(str(file)) for file in global_files])\n",
    "        ])\n",
    "        global_files_accordion.set_title(0, 'Global Computation Results Files')\n",
    "\n",
    "        # Set session accordion children\n",
    "        session_accordion.children = [session_files_accordion, global_files_accordion]\n",
    "        \n",
    "        # Set main accordion title\n",
    "        sessions_accordion.set_title(i, str(session))\n",
    "\n",
    "    return sessions_accordion\n",
    "\n",
    "# Example usage\n",
    "tree_view = create_tree_view(found_files_dict)\n",
    "tree_view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# search_parent_path = Path(r'W:\\\\Data\\\\Kdiba')\n",
    "# search_parent_path = Path(r'/home/halechr/turbo/Data/KDIBA').resolve() # Greatlakes\n",
    "search_parent_path = Path(r'/home/halechr/cloud/turbo/Data/KDIBA').resolve() # Lab\n",
    "\n",
    "# found_autoversioned_session_pickle_files = discover_data_files(search_parent_path, glob_pattern='*-loadedSessPickle.pkl', recursive=True)\n",
    "# found_global_computation_results_files = discover_data_files(search_parent_path, glob_pattern='output/*.pkl', recursive=True)\n",
    "\n",
    "\n",
    "found_any_kind_session_pickle_files = discover_data_files(search_parent_path, glob_pattern='*loadedSessPickle*.pkl', recursive=True)\n",
    "found_any_global_computation_results_files = discover_data_files(search_parent_path, glob_pattern='output/*global_computation_results*.pkl', recursive=True)\n",
    "\n",
    "# found_session_pickle_files = discover_data_files(source_data_root, glob_pattern='loadedSessPickle.pkl', recursive=True)\n",
    "# found_global_computation_results_files = discover_data_files(source_data_root, glob_pattern=f'output/{completed_global_computations_filename}', recursive=True)\n",
    "\n",
    "found_files = found_any_global_computation_results_files + found_any_kind_session_pickle_files\n",
    "found_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66727ff",
   "metadata": {},
   "source": [
    "# 2023-11-20 - Discovery of folder modification times from matching files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403b3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "Write a python function that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1abc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def determine_directory_modification_time(target_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
