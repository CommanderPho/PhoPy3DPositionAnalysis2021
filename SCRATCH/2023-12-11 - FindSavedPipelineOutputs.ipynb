{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd5d37-e658-4133-afa0-a8641b5fecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-05-23 - This code was created to quickly backup all of the good `loadedSessPickle.pkl` files from the session folders into the './output' subfolder in the session:\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-09_21-17-16/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-04_21-20-3/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_21-26-8/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-09_22-4-5/output/loadedSessPickle.pkl already in output folder.\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08951e7-4fef-4226-b3cd-75627533e944",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional, Dict, List\n",
    "\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file, FileList\n",
    "from pyphocorehelpers.Filesystem.path_helpers import convert_filelist_to_new_parent\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_files_metadata\n",
    "\n",
    "# import glob # for finding .whl file after building binary repo\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'/media/MAX/Data'), Path(r'/home/halechr/turbo/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/FastData'), Path(r'/Volumes/MoverNew/data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "\n",
    "completed_pipeline_filename = 'loadedSessPickle.pkl'\n",
    "completed_global_computations_filename = 'global_computation_results.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_data_root_parent_path changed to W:\\Data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46db57923a834f019b4f906cb040446b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Data Root:', layout=Layout(width='auto'), options=(WindowsPath('W:/Data'),), style=â€¦"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import build_global_data_root_parent_path_selection_widget\n",
    "    \n",
    "all_paths = [Path(r'/home/halechr/turbo/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/FastData'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data')]\n",
    "global_data_root_parent_path = None\n",
    "def on_user_update_path_selection(new_path: Path):\n",
    "\tglobal global_data_root_parent_path\n",
    "\tnew_global_data_root_parent_path = new_path.resolve()\n",
    "\tglobal_data_root_parent_path = new_global_data_root_parent_path\n",
    "\tprint(f'global_data_root_parent_path changed to {global_data_root_parent_path}')\n",
    "\tassert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "\t\t\t\n",
    "global_data_root_parent_path_widget = build_global_data_root_parent_path_selection_widget(all_paths, on_user_update_path_selection)\n",
    "global_data_root_parent_path_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('W:/Data')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_data_root_parent_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_file_metadata\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file, save_copydict_to_text_file, read_copydict_from_text_file, invert_filedict\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import get_file_str_if_file_exists\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import check_output_h5_files, copy_files_in_filelist_to_dest\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import ConcreteSessionFolder, BackupMethods\n",
    "\n",
    "# BATCH_DATE_TO_USE = '2023-10-18_Apogee' # used for filenames throught the notebook\n",
    "# BATCH_DATE_TO_USE = '2023-11-15_Lab' # used for filenames throught the notebook\n",
    "BATCH_DATE_TO_USE = '2024-03-27_Apogee' # used for filenames throught the notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29978b7c-a1cc-4e6b-bf40-d2f1af0ecee6",
   "metadata": {},
   "source": [
    "## Old (Pre 2023-09-21):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c4083-b7b0-4a4a-ad63-7db9400ff058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use glob to find the first generated .whl file in the dist/ directory\n",
    "found_whl_files = glob.glob('*.whl')\n",
    "found_whl_files = [a for a in found_whl_files if not a.endswith('current.whl')] # exclude the symlink from the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa314cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_computed_ripple_filepath = session.basepath.joinpath('ripple_df.pkl')\n",
    "## try the '.ripple.npy' ripples:\n",
    "active_file_suffix = '.ripple.npy'\n",
    "external_computed_ripple_filepath = fp.with_suffix(active_file_suffix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db0613-f7f6-48a7-9beb-2f17b3eb941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moves all previously saved loadedSessPickle.pkl files to the output folder.\n",
    "correctly_placed_output_files = []\n",
    "search_path: Path = Path(\"/home/halechr/turbo/Data/KDIBA/\").resolve()\n",
    "assert search_path.exists()\n",
    "for p in search_path.rglob(completed_pipeline_filename):\n",
    "    if p.parent.name != 'output':\n",
    "        # If not already in the 'output/' subfolder, move it there.\n",
    "        print(f'p: {p}')\n",
    "        curr_output_dir = p.parent.joinpath('output')\n",
    "        curr_output_dir.mkdir(exist_ok=True)\n",
    "        # print(f'curr_output_dir: {curr_output_dir}')\n",
    "        new_path = p.replace(curr_output_dir.joinpath(p.name))\n",
    "        print(f'\\t new_path: {new_path}')\n",
    "        correctly_placed_output_files.append(p)\n",
    "    else:\n",
    "        print(f'p: {p} already in output folder.')\n",
    "        correctly_placed_output_files.append(p)\n",
    "    \n",
    "correctly_placed_output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_pipeline_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Build Pickle Path:\n",
    "pkl_path = 'global_batch_result_2023-06-08.pkl'\n",
    "csv_path = 'global_batch_result_2023-06-08.csv'\n",
    "h5_path = 'global_batch_result_2023-06-08.h5'\n",
    "\n",
    "global_batch_result_file_path = Path(global_data_root_parent_path).joinpath(h5_path).resolve() # Use Default\n",
    "\n",
    "batch_progress_df = BatchRun.load_batch_progress_df_from_h5(global_batch_result_file_path)\n",
    "batch_progress_df\n",
    "\n",
    "updated_batch_progress_df = BatchRun.rebuild_basedirs(batch_progress_df, global_data_root_parent_path)\n",
    "updated_batch_progress_df\n",
    "\n",
    "updated_good_only_batch_progress_df = updated_batch_progress_df[updated_batch_progress_df['locally_is_ready']].copy()\n",
    "updated_good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate code that can be pasted into the current \"ReviewOfWork-*.ipynb\" notebook to load the good sessions:\n",
    "print(\",\\n\".join([a_ctxt.get_initialization_code_string() for a_ctxt in updated_good_only_batch_progress_df['context'].to_list()]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23cecbf",
   "metadata": {},
   "source": [
    "# 2023-09-21 - Mirror Slow Data files to much faster SSD: , Path(r'/home/halechr/FastData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35d6bc86",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil # used in `restore_symlink_folder`\n",
    "from shutil import copytree # used in `make_specific_items_local`\n",
    "from typing import Optional, Dict, List\n",
    "from datetime import datetime, timedelta\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_file_metadata\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file\n",
    "from attrs import define, field, Factory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing_symlink_folder_path: /home/halechr/FastData/KDIBA/pin01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/pin01') ## DO NOT CALL .resolve() on the input path, this resolves the symlink!!!\n",
    "print(f'existing_symlink_folder_path: {a_symlink_path}')\n",
    "assert a_symlink_path.exists()\n",
    "symlinked_folder_to_local_folder_containing_symlinks(a_symlink_path, dryrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing_symlink_folder_path: /home/halechr/FastData/KDIBA/pin01/one\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/pin01/one') ## DO NOT CALL .resolve() on the input path, this resolves the symlink!!!\n",
    "print(f'existing_symlink_folder_path: {a_symlink_path}')\n",
    "assert a_symlink_path.exists()\n",
    "symlinked_folder_to_local_folder_containing_symlinks(a_symlink_path, dryrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing_symlink_folder_path: /home/halechr/FastData/KDIBA/pin01\n",
      "/home/halechr/FastData/KDIBA/pin01 is not a symlink.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make_specific_items_local\n",
    "\n",
    "# existing_symlink_folder_path: Path = Path('/home/halechr/FastData/KDIBA/pin01') ## DO NOT CALL .resolve() on the input path, this resolves the symlink!!!\n",
    "a_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/pin01/one')\n",
    "print(f'existing_symlink_folder_path: {a_symlink_path}')\n",
    "assert a_symlink_path.exists()\n",
    "desired_local_folder_paths: List[Path] = [Path(v) for v in ['/home/halechr/FastData/KDIBA/vvp01/one/2006-4-18_13-6-1/output/global_computation_results.pkl', '/home/halechr/FastData/KDIBA/vvp01/one/2006-4-18_13-6-1/loadedSessPickle.pkl',\n",
    "                                                            '/home/halechr/FastData/KDIBA/vvp01/one/2006-4-18_13-6-1/output/global_computation_results.pkl', '/home/halechr/FastData/KDIBA/vvp01/one/2006-4-18_13-6-1/loadedSessPickle.pkl',\n",
    "                                                            '/home/halechr/FastData/KDIBA/vvp01/one/2006-4-18_13-6-1/output/global_computation_results.pkl', '/home/halechr/FastData/KDIBA/vvp01/one/2006-4-18_13-6-1/loadedSessPickle.pkl',\n",
    "                                                            ]]\n",
    "make_specific_items_local(a_symlink_path, desired_local_folder_paths=desired_local_folder_paths, dryrun=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing_symlink_path: /home/halechr/FastData/KDIBA/pin01/one/fet11-01_12-58-54\n",
      "/home/halechr/FastData/KDIBA/pin01/one/fet11-01_12-58-54 is not a symlink.\n",
      "/home/halechr/FastData/KDIBA/pin01/one/fet11-01_12-58-54 is not a symlink and none of its ancestors are symlinks either.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/pin01/one/fet11-01_12-58-54') ## DO NOT CALL .resolve() on the input path, this resolves the symlink!!!\n",
    "print(f'existing_symlink_path: {a_symlink_path}')\n",
    "assert a_symlink_path.exists()\n",
    "symlinked_item_to_full_local_item(a_symlink_path, dryrun=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing_symlink_path: /home/halechr/FastData/KDIBA/vvp01/one/2006-4-18_13-6-1/output/global_computation_results.pkl\n",
      "/home/halechr/FastData/KDIBA/vvp01/one/2006-4-18_13-6-1/output/global_computation_results.pkl is not a symlink.\n",
      "found symlink ancestor: /home/halechr/FastData/KDIBA/vvp01.\n",
      "relative_to_symlink_ancestor: one/2006-4-18_13-6-1/output\n",
      "num_paths_to_partial_localize: 3\n",
      "ancestor_paths_to_resolve: [PosixPath('/home/halechr/FastData/KDIBA/vvp01'), PosixPath('/home/halechr/FastData/KDIBA/vvp01/one'), PosixPath('/home/halechr/FastData/KDIBA/vvp01/one/2006-4-18_13-6-1'), PosixPath('/home/halechr/FastData/KDIBA/vvp01/one/2006-4-18_13-6-1/output')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# existing_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/pin01/one/11-09_22-4-5/11-09_22-4-5IN.5.numclu')\n",
    "a_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/vvp01/one/2006-4-18_13-6-1/output/global_computation_results.pkl')\n",
    "print(f'existing_symlink_path: {a_symlink_path}')\n",
    "assert a_symlink_path.exists()\n",
    "symlinked_item_to_full_local_item(a_symlink_path, dryrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing_symlink_path: /home/halechr/FastData/KDIBA/vvp01/one/2006-4-18_13-6-1/loadedSessPickle.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/vvp01/one/2006-4-18_13-6-1/loadedSessPickle.pkl')\n",
    "print(f'existing_symlink_path: {a_symlink_path}')\n",
    "assert a_symlink_path.exists()\n",
    "symlinked_item_to_full_local_item(a_symlink_path, dryrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing_symlink_folder_path: /home/halechr/FastData/KDIBA/pin01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_symlink_path: Path = Path('/home/halechr/FastData/KDIBA/pin01') ## DO NOT CALL .resolve() on the input path, this resolves the symlink!!!\n",
    "print(f'existing_symlink_folder_path: {a_symlink_path}')\n",
    "assert a_symlink_path.exists()\n",
    "restore_symlink_folder(a_symlink_path, dryrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def attribute_is_extant_path(instance, attribute, value):\n",
    "\tif not isinstance(value, Path):\n",
    "\t\traise TypeError(f\"value must be a pathlib.Path but type(value): {type(value)}\")\n",
    "\tif not value.exists():\n",
    "\t\traise ValueError(f\"value must exists on the filesystem!\")\n",
    "\t\n",
    "\n",
    "\n",
    "@define(slots=False)\n",
    "class DataRepository:\n",
    "\tshort_name: str = field()\n",
    "\thost: str = field()\n",
    "\troot_path: Path = field()\n",
    "\n",
    "\t# def __attrs_post_init__(self):\n",
    "\t# \tassert root_path.exists()\n",
    "\t\t\n",
    "\t\t\n",
    "\tdef try_find_files(self):\n",
    "\t\t# Find the files and build the movedicts:\n",
    "\t\tsource_data_root = self.root_path.resolve()\n",
    "\t\tfound_session_pickle_files = discover_data_files(source_data_root, glob_pattern='loadedSessPickle.pkl', recursive=True)\n",
    "\t\tfound_global_computation_results_files = discover_data_files(source_data_root, glob_pattern=f'output/{completed_global_computations_filename}', recursive=True)\n",
    "\t\treturn found_session_pickle_files, found_global_computation_results_files\n",
    "\n",
    "data_repos = {'MAX':DataRepository('MAX', host='LNX00052', root_path=Path(r'/media/MAX/Data')),\n",
    "'FastData':DataRepository('FastData', host='LNX00052', root_path=Path(r'/home/halechr/FastData')),\n",
    "'gen_scripts':DataRepository('gen_scripts', host='LNX00052', root_path=Path(r'/home/halechr/FastData/gen_scripts/')),\n",
    "}\n",
    "\n",
    "\n",
    "included_session_contexts = [\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "\t  IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'), # prev completed\n",
    "]\n",
    "\n",
    "data_repos_good_session_concrete_folders_dict = {}\n",
    "\n",
    "data_repos\n",
    "# run_kdiba_gor01_one_2006-6-08_14-26-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "curr_good_session_concrete_folders = ConcreteSessionFolder.build_concrete_session_folders(data_repos['MAX'].root_path.resolve(), included_session_contexts)\n",
    "curr_good_session_concrete_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_session_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_repos_good_session_concrete_folders_dict['FastData'] = ConcreteSessionFolder.build_concrete_session_folders(data_repos['FastData'].root_path.resolve(), included_session_contexts, allow_create_needed_dirs=True)\n",
    "data_repos_good_session_concrete_folders_dict['FastData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_session_concrete_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_dict = ConcreteSessionFolder.build_backup_copydict(data_repos_good_session_concrete_folders_dict['FastData'], backup_mode=BackupMethods.RenameInSourceDirectory, rename_backup_suffix=BATCH_DATE_TO_USE, only_include_file_types=['global_pkl'])\n",
    "copy_dict_FastData = ConcreteSessionFolder.build_backup_copydict(data_repos_good_session_concrete_folders_dict['FastData'], backup_mode=BackupMethods.RenameInSourceDirectory, rename_backup_suffix=BATCH_DATE_TO_USE, only_include_file_types=['local_pkl', 'global_pkl'])\n",
    "copy_dict_FastData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moved_files_dict_FastData_files = copy_movedict(copy_dict_FastData)\n",
    "moved_files_dict_FastData_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_session_pickle_files, found_global_computation_results_files = data_repos['MAX'].try_find_files()\n",
    "found_session_pickle_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d60f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_data_root = Path(r'/media/MAX/Data')\n",
    "dest_data_root = Path(r'/home/halechr/FastData')\n",
    "assert source_data_root.exists(), f\"source_data_root: {source_data_root} does not exist! Is the right computer's config commented out above?\"\n",
    "assert dest_data_root.exists(), f\"dest_data_root: {dest_data_root} does not exist! Is the right computer's config commented out above?\"\n",
    "\n",
    "oldest_modified_date = (datetime.now() - timedelta(days=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the files and build the movedicts:\n",
    "found_session_pickle_files = discover_data_files(source_data_root, glob_pattern='loadedSessPickle.pkl', recursive=True)\n",
    "found_global_computation_results_files = discover_data_files(source_data_root, glob_pattern=f'output/{completed_global_computations_filename}', recursive=True)\n",
    "file_movedict_session_pickle_files = generate_copydict(source_data_root, dest_data_root, found_files=found_session_pickle_files, only_files_newer_than=oldest_modified_date)\n",
    "file_movedict_global_computation_results_pickle_files = generate_copydict(source_data_root, dest_data_root, found_files=found_global_computation_results_files, only_files_newer_than=oldest_modified_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a22684",
   "metadata": {},
   "source": [
    "### Actually perform copy operations. This will take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0548870",
   "metadata": {},
   "outputs": [],
   "source": [
    "moved_files_dict_session_pickle_files = copy_movedict(file_movedict_session_pickle_files)\n",
    "moved_files_dict_session_pickle_files\n",
    "\n",
    "# moved_files_dict = copy_files(filelist_source, filelist_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7732c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "moved_files_dict_global_computation_results_pickle_files = copy_movedict(file_movedict_global_computation_results_pickle_files)\n",
    "moved_files_dict_global_computation_results_pickle_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various file formats:\n",
    "'global_computation_results_2023-12-07_GL.pkl'\n",
    "'20231012125859-global_computation_results.pkltmp'\n",
    "\"loadedSessPickle_2023-12-07_GL.pkl\"\n",
    "\"backup-20231020190542-loadedSessPickle.pkl\"\n",
    "\"loadedSessPickle_2023-10-25_BidirectionalOnly\"\n",
    "\"20230912203733-loadedSessPickle.pkl\"\n",
    "\"backup-20240125143331-loadedSessPickle.pkl.bak\"\n",
    "\"20231129083822-loadedSessPickle.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_computation_results_2023-12-07_GL.pkl --> 2023-12-07, 2023-12-07 00:00:00\n",
      "20231012125859-global_computation_results.pkltmp --> 20231012125859, 2023-10-12 12:58:59\n",
      "loadedSessPickle_2023-12-07_GL.pkl --> 2023-12-07, 2023-12-07 00:00:00\n",
      "backup-20231020190542-loadedSessPickle.pkl --> 20231020190542, 2023-10-20 19:05:42\n",
      "loadedSessPickle_2023-10-25_BidirectionalOnly --> 2023-10-25, 2023-10-25 00:00:00\n",
      "20230912203733-loadedSessPickle.pkl --> 20230912203733, 2023-09-12 20:37:33\n",
      "backup-20240125143331-loadedSessPickle.pkl.bak --> 20240125143331, 2024-01-25 14:33:31\n",
      "20231129083822-loadedSessPickle.pkl --> 20231129083822, 2023-11-29 08:38:22\n"
     ]
    }
   ],
   "source": [
    "from pyphocorehelpers.Filesystem.path_helpers import parse_unique_file_name\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def detect_date_strings(filenames):\n",
    "    # Regular expression pattern for date (YYYY-MM-DD)\n",
    "    date_pattern = r'\\d{4}-\\d{2}-\\d{2}'\n",
    "    # Regular expression pattern for datetime (YYYYMMDDHHMMSS)\n",
    "    datetime_pattern = r'\\d{14}'\n",
    "\n",
    "    detected_dates = []\n",
    "\n",
    "    for filename in filenames:\n",
    "        date_match = re.search(date_pattern, filename)\n",
    "        datetime_match = re.search(datetime_pattern, filename)\n",
    "\n",
    "        if date_match:\n",
    "            date_str = date_match.group()\n",
    "            # Parse the date string\n",
    "            try:\n",
    "                date_value = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "            except ValueError as e:\n",
    "                print(f\"Error parsing date: {e}\")\n",
    "                date_value = None\n",
    "            detected_dates.append((date_str, date_value))\n",
    "        elif datetime_match:\n",
    "            datetime_str = datetime_match.group()\n",
    "            # Parse the datetime string\n",
    "            try:\n",
    "                datetime_value = datetime.strptime(datetime_str, '%Y%m%d%H%M%S')\n",
    "            except ValueError as e:\n",
    "                print(f\"Error parsing datetime: {e}\")\n",
    "                datetime_value = None\n",
    "            detected_dates.append((datetime_str, datetime_value))\n",
    "        else:\n",
    "            detected_dates.append((None, None))  # No date/datetime found\n",
    "\n",
    "    return detected_dates\n",
    "\n",
    "\n",
    "test_filenames = ['global_computation_results_2023-12-07_GL.pkl',\n",
    "'20231012125859-global_computation_results.pkltmp',\n",
    "\"loadedSessPickle_2023-12-07_GL.pkl\",\n",
    "\"backup-20231020190542-loadedSessPickle.pkl\",\n",
    "\"loadedSessPickle_2023-10-25_BidirectionalOnly\",\n",
    "\"20230912203733-loadedSessPickle.pkl\",\n",
    "\"backup-20240125143331-loadedSessPickle.pkl.bak\",\n",
    "\"20231129083822-loadedSessPickle.pkl\"]\n",
    "\n",
    "# [parse_unique_file_name(a_filename) for a_filename in test_filenames]\n",
    "\n",
    "detected_dates = detect_date_strings(test_filenames)\n",
    "for filename, (date_str, date_value) in zip(test_filenames, detected_dates):\n",
    "    print(f'{filename} --> {date_str}, {date_value}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095cd5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98241d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a36a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hardcoded included_session_contexts:\n",
    "included_session_contexts = [\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'), # prev completed\n",
    "]\n",
    "\n",
    "active_global_batch_result_filename=f'global_batch_result_{BATCH_DATE_TO_USE}.pkl'\n",
    "\n",
    "debug_print = False\n",
    "known_global_data_root_parent_paths = [Path(r'/home/halechr/cloud/turbo/Data'), Path(r'W:\\Data'), Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data')] # , Path(r'/home/halechr/FastData'), Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'/home/halechr/turbo/Data'), \n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "good_session_concrete_folders = ConcreteSessionFolder.build_concrete_session_folders(global_data_root_parent_path, included_session_contexts)\n",
    "\n",
    "## Build Slurm Scripts:\n",
    "session_basedirs_dict: Dict[IdentifyingContext, Path] = {a_session_folder.context:a_session_folder.path for a_session_folder in good_session_concrete_folders}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Context(format_name: 'kdiba'\n",
       "         animal: 'gor01'\n",
       "         exper_name: 'one'\n",
       "         session_name: '2006-6-08_14-26-15'): ([WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/20230912203733-loadedSessPickle.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/20230912203734-loadedSessPickle.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/20231129081520-loadedSessPickle.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/20231129084409-loadedSessPickle.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl')],\n",
       "  [WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results_2023-10-06.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results_with_dt.pkl')]),\n",
       " Context(format_name: 'kdiba'\n",
       "         animal: 'gor01'\n",
       "         exper_name: 'one'\n",
       "         session_name: '2006-6-09_1-22-43'): ([WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/20230524092446-loadedSessPickle.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/20231024174601-loadedSessPickle.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/20231031135214-loadedSessPickle.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/20231031135546-loadedSessPickle.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/20231129083822-loadedSessPickle.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/20231129101310-loadedSessPickle.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/20231129103113-loadedSessPickle.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/20240119173418-loadedSessPickle.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_GL.pkl')],\n",
       "  [WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results_2023-10-05.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results_2023-10-06.pkl'),\n",
       "   WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results_GL.pkl')])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_files_dict = {}\n",
    "\n",
    "for a_ctxt, a_path in session_basedirs_dict.items():\n",
    "\tfound_any_kind_session_pickle_files = discover_data_files(a_path, glob_pattern='*loadedSessPickle*.pkl', recursive=True)\n",
    "\tfound_any_global_computation_results_files = discover_data_files(a_path, glob_pattern='output/*global_computation_results*.pkl', recursive=True)\n",
    "\tfound_files_dict[a_ctxt] = (found_any_kind_session_pickle_files, found_any_global_computation_results_files)\n",
    "\n",
    "found_files_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_tree(found_files_dict):\n",
    "    tree_str = \"\"\n",
    "    for session, (session_files, global_files) in found_files_dict.items():\n",
    "        tree_str += f\"{session}\\n\"\n",
    "        if session_files:\n",
    "            tree_str += \"  - Session Pickle Files:\\n\"\n",
    "            for file in session_files:\n",
    "                tree_str += f\"    * {file}\\n\"\n",
    "        if global_files:\n",
    "            tree_str += \"  - Global Computation Results Files:\\n\"\n",
    "            for file in global_files:\n",
    "                tree_str += f\"    * {file}\\n\"\n",
    "    return tree_str\n",
    "\n",
    "# Example of usage\n",
    "tree_representation = render_tree(found_files_dict)\n",
    "print(tree_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "def create_tree_view(found_files_dict):\n",
    "    sessions_accordion = widgets.Accordion(children=[widgets.VBox() for _ in found_files_dict])\n",
    "    for i, (session, (session_files, global_files)) in enumerate(found_files_dict.items()):\n",
    "        session_accordion = sessions_accordion.children[i]\n",
    "        \n",
    "        # Convert paths to strings and create session pickle files accordion\n",
    "        session_files_accordion = widgets.Accordion(children=[\n",
    "            widgets.VBox([widgets.Label(str(file)) for file in session_files])\n",
    "        ])\n",
    "        session_files_accordion.set_title(0, 'Session Pickle Files')\n",
    "\n",
    "        # Convert paths to strings and create global computation results files accordion\n",
    "        global_files_accordion = widgets.Accordion(children=[\n",
    "            widgets.VBox([widgets.Label(str(file)) for file in global_files])\n",
    "        ])\n",
    "        global_files_accordion.set_title(0, 'Global Computation Results Files')\n",
    "\n",
    "        # Set session accordion children\n",
    "        session_accordion.children = [session_files_accordion, global_files_accordion]\n",
    "        \n",
    "        # Set main accordion title\n",
    "        sessions_accordion.set_title(i, str(session))\n",
    "\n",
    "    return sessions_accordion\n",
    "\n",
    "# Example usage\n",
    "tree_view = create_tree_view(found_files_dict)\n",
    "tree_view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# search_parent_path = Path(r'W:\\\\Data\\\\Kdiba')\n",
    "# search_parent_path = Path(r'/home/halechr/turbo/Data/KDIBA').resolve() # Greatlakes\n",
    "search_parent_path = Path(r'/home/halechr/cloud/turbo/Data/KDIBA').resolve() # Lab\n",
    "\n",
    "# found_autoversioned_session_pickle_files = discover_data_files(search_parent_path, glob_pattern='*-loadedSessPickle.pkl', recursive=True)\n",
    "# found_global_computation_results_files = discover_data_files(search_parent_path, glob_pattern='output/*.pkl', recursive=True)\n",
    "\n",
    "\n",
    "found_any_kind_session_pickle_files = discover_data_files(search_parent_path, glob_pattern='*loadedSessPickle*.pkl', recursive=True)\n",
    "found_any_global_computation_results_files = discover_data_files(search_parent_path, glob_pattern='output/*global_computation_results*.pkl', recursive=True)\n",
    "\n",
    "# found_session_pickle_files = discover_data_files(source_data_root, glob_pattern='loadedSessPickle.pkl', recursive=True)\n",
    "# found_global_computation_results_files = discover_data_files(source_data_root, glob_pattern=f'output/{completed_global_computations_filename}', recursive=True)\n",
    "\n",
    "found_files = found_any_global_computation_results_files + found_any_kind_session_pickle_files\n",
    "found_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66727ff",
   "metadata": {},
   "source": [
    "# 2023-11-20 - Discovery of folder modification times from matching files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403b3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "Write a python function that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1abc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def determine_directory_modification_time(target_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
