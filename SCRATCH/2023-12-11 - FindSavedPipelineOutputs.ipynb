{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd5d37-e658-4133-afa0-a8641b5fecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-05-23 - This code was created to quickly backup all of the good `loadedSessPickle.pkl` files from the session folders into the './output' subfolder in the session:\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-09_21-17-16/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-04_21-20-3/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_21-26-8/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-09_22-4-5/output/loadedSessPickle.pkl already in output folder.\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08951e7-4fef-4226-b3cd-75627533e944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional, Dict, List\n",
    "\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file, FileList\n",
    "from pyphocorehelpers.Filesystem.path_helpers import convert_filelist_to_new_parent\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_files_metadata\n",
    "\n",
    "# import glob # for finding .whl file after building binary repo\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'/media/MAX/Data'), Path(r'/home/halechr/turbo/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/FastData'), Path(r'/Volumes/MoverNew/data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "\n",
    "completed_pipeline_filename = 'loadedSessPickle.pkl'\n",
    "completed_global_computations_filename = 'global_computation_results.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4735ad3f934947deb1596ebfa5687b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Data Root:', layout=Layout(width='auto'), options=(PosixPath('/home/halechr/FastDatâ€¦"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_data_root_parent_path changed to /media/MAX/Data\n",
      "global_data_root_parent_path changed to /home/halechr/FastData\n",
      "global_data_root_parent_path changed to /media/MAX/Data\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "\n",
    "\n",
    "def build_global_data_root_parent_path_selection_widget():\n",
    "\tall_paths = [Path(r'/home/halechr/turbo/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/FastData'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data')]\n",
    "\textant_paths = [a_path for a_path in all_paths if a_path.exists()]\n",
    "\tassert len(extant_paths) > 0, f\"NO EXTANT PATHS FOUND AT ALL!\"\n",
    "\tglobal_data_root_parent_path = extant_paths[0]        \n",
    "\n",
    "\n",
    "\t# widgets.ToggleButtons\n",
    "\tglobal_data_root_parent_path_widget = widgets.ToggleButtons(\n",
    "\t\t\t\t\t\t\t\t\t\t\toptions=extant_paths,\n",
    "\t\t\t\t\t\t\t\t\t\t\tdescription='Data Root:',\n",
    "\t\t\t\t\t\t\t\t\t\t\tdisabled=False,\n",
    "\t\t\t\t\t\t\t\t\t\t\tbutton_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "\t\t\t\t\t\t\t\t\t\t\ttooltip='global_data_root_parent_path',\n",
    "\t\t\t\t\t\t\t\t\t\t\tlayout=widgets.Layout(width='auto'),\n",
    "\t\t\t\t\t\t\t\t\t\t\tstyle={\"button_width\": 'max-content'}, # \"190px\"\n",
    "\t\t\t\t\t\t\t\t\t\t#     icon='check'\n",
    "\t\t\t\t\t\t\t\t\t\t)\n",
    "\n",
    "\tdef on_global_data_root_parent_path_selection_change(change):\n",
    "\t\tglobal global_data_root_parent_path\n",
    "\t\tnew_global_data_root_parent_path = Path(str(change['new'])).resolve()\n",
    "\t\tglobal_data_root_parent_path = new_global_data_root_parent_path\n",
    "\t\tprint(f'global_data_root_parent_path changed to {global_data_root_parent_path}')\n",
    "\t\tassert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "\n",
    "\tglobal_data_root_parent_path_widget.observe(on_global_data_root_parent_path_selection_change, names='value')\n",
    "\treturn global_data_root_parent_path_widget\n",
    "\n",
    "global_data_root_parent_path_widget = build_global_data_root_parent_path_selection_widget()\n",
    "global_data_root_parent_path_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/media/MAX/Data')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_data_root_parent_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_file_metadata\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file, save_copydict_to_text_file, read_copydict_from_text_file, invert_filedict\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import get_file_str_if_file_exists\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import check_output_h5_files, copy_files_in_filelist_to_dest\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import ConcreteSessionFolder, BackupMethods\n",
    "\n",
    "# BATCH_DATE_TO_USE = '2023-10-18_Apogee' # used for filenames throught the notebook\n",
    "# BATCH_DATE_TO_USE = '2023-11-15_Lab' # used for filenames throught the notebook\n",
    "BATCH_DATE_TO_USE = '2023-12-19' # used for filenames throught the notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29978b7c-a1cc-4e6b-bf40-d2f1af0ecee6",
   "metadata": {},
   "source": [
    "## Old (Pre 2023-09-21):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c4083-b7b0-4a4a-ad63-7db9400ff058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use glob to find the first generated .whl file in the dist/ directory\n",
    "found_whl_files = glob.glob('*.whl')\n",
    "found_whl_files = [a for a in found_whl_files if not a.endswith('current.whl')] # exclude the symlink from the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa314cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_computed_ripple_filepath = session.basepath.joinpath('ripple_df.pkl')\n",
    "## try the '.ripple.npy' ripples:\n",
    "active_file_suffix = '.ripple.npy'\n",
    "external_computed_ripple_filepath = fp.with_suffix(active_file_suffix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db0613-f7f6-48a7-9beb-2f17b3eb941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moves all previously saved loadedSessPickle.pkl files to the output folder.\n",
    "correctly_placed_output_files = []\n",
    "search_path: Path = Path(\"/home/halechr/turbo/Data/KDIBA/\").resolve()\n",
    "assert search_path.exists()\n",
    "for p in search_path.rglob(completed_pipeline_filename):\n",
    "    if p.parent.name != 'output':\n",
    "        # If not already in the 'output/' subfolder, move it there.\n",
    "        print(f'p: {p}')\n",
    "        curr_output_dir = p.parent.joinpath('output')\n",
    "        curr_output_dir.mkdir(exist_ok=True)\n",
    "        # print(f'curr_output_dir: {curr_output_dir}')\n",
    "        new_path = p.replace(curr_output_dir.joinpath(p.name))\n",
    "        print(f'\\t new_path: {new_path}')\n",
    "        correctly_placed_output_files.append(p)\n",
    "    else:\n",
    "        print(f'p: {p} already in output folder.')\n",
    "        correctly_placed_output_files.append(p)\n",
    "    \n",
    "correctly_placed_output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_pipeline_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Build Pickle Path:\n",
    "pkl_path = 'global_batch_result_2023-06-08.pkl'\n",
    "csv_path = 'global_batch_result_2023-06-08.csv'\n",
    "h5_path = 'global_batch_result_2023-06-08.h5'\n",
    "\n",
    "global_batch_result_file_path = Path(global_data_root_parent_path).joinpath(h5_path).resolve() # Use Default\n",
    "\n",
    "batch_progress_df = BatchRun.load_batch_progress_df_from_h5(global_batch_result_file_path)\n",
    "batch_progress_df\n",
    "\n",
    "updated_batch_progress_df = BatchRun.rebuild_basedirs(batch_progress_df, global_data_root_parent_path)\n",
    "updated_batch_progress_df\n",
    "\n",
    "updated_good_only_batch_progress_df = updated_batch_progress_df[updated_batch_progress_df['locally_is_ready']].copy()\n",
    "updated_good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate code that can be pasted into the current \"ReviewOfWork-*.ipynb\" notebook to load the good sessions:\n",
    "print(\",\\n\".join([a_ctxt.get_initialization_code_string() for a_ctxt in updated_good_only_batch_progress_df['context'].to_list()]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23cecbf",
   "metadata": {},
   "source": [
    "# 2023-09-21 - Mirror Slow Data files to much faster SSD: , Path(r'/home/halechr/FastData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35d6bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, List\n",
    "from datetime import datetime, timedelta\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_file_metadata\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file\n",
    "from attrs import define, field, Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAX': DataRepository(short_name='MAX', host='LNX00052', root_path=PosixPath('/media/MAX/Data')),\n",
       " 'FastData': DataRepository(short_name='FastData', host='LNX00052', root_path=PosixPath('/home/halechr/FastData')),\n",
       " 'gen_scripts': DataRepository(short_name='gen_scripts', host='LNX00052', root_path=PosixPath('/home/halechr/FastData/gen_scripts'))}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def attribute_is_extant_path(instance, attribute, value):\n",
    "\tif not isinstance(value, Path):\n",
    "\t\traise TypeError(f\"value must be a pathlib.Path but type(value): {type(value)}\")\n",
    "\tif not value.exists():\n",
    "\t\traise ValueError(f\"value must exists on the filesystem!\")\n",
    "\t\n",
    "\n",
    "\n",
    "@define(slots=False)\n",
    "class DataRepository:\n",
    "\tshort_name: str = field()\n",
    "\thost: str = field()\n",
    "\troot_path: Path = field()\n",
    "\n",
    "\t# def __attrs_post_init__(self):\n",
    "\t# \tassert root_path.exists()\n",
    "\t\t\n",
    "\t\t\n",
    "\tdef try_find_files(self):\n",
    "\t\t# Find the files and build the movedicts:\n",
    "\t\tsource_data_root = self.root_path.resolve()\n",
    "\t\tfound_session_pickle_files = discover_data_files(source_data_root, glob_pattern='loadedSessPickle.pkl', recursive=True)\n",
    "\t\tfound_global_computation_results_files = discover_data_files(source_data_root, glob_pattern=f'output/{completed_global_computations_filename}', recursive=True)\n",
    "\t\treturn found_session_pickle_files, found_global_computation_results_files\n",
    "\n",
    "data_repos = {'MAX':DataRepository('MAX', host='LNX00052', root_path=Path(r'/media/MAX/Data')),\n",
    "'FastData':DataRepository('FastData', host='LNX00052', root_path=Path(r'/home/halechr/FastData')),\n",
    "'gen_scripts':DataRepository('gen_scripts', host='LNX00052', root_path=Path(r'/home/halechr/FastData/gen_scripts/')),\n",
    "}\n",
    "\n",
    "\n",
    "included_session_contexts = [\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'), # prev completed\n",
    "]\n",
    "\n",
    "\n",
    "data_repos_good_session_concrete_folders_dict = {}\n",
    "\n",
    "data_repos\n",
    "# run_kdiba_gor01_one_2006-6-08_14-26-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_good_session_concrete_folders = ConcreteSessionFolder.build_concrete_session_folders(data_repos['MAX'].root_path.resolve(), included_session_contexts)\n",
    "curr_good_session_concrete_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_session_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConcreteSessionFolder(context=IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-08_14-26-15')>, path=PosixPath('/home/halechr/FastData/KDIBA/gor01/one/2006-6-08_14-26-15')),\n",
       " ConcreteSessionFolder(context=IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-09_1-22-43')>, path=PosixPath('/home/halechr/FastData/KDIBA/gor01/one/2006-6-09_1-22-43'))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_repos_good_session_concrete_folders_dict['FastData'] = ConcreteSessionFolder.build_concrete_session_folders(data_repos['FastData'].root_path.resolve(), included_session_contexts)\n",
    "data_repos_good_session_concrete_folders_dict['FastData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'good_session_concrete_folders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/halechr/repos/Spike3D/SCRATCH/2023-12-11 - FindSavedPipelineOutputs.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/halechr/repos/Spike3D/SCRATCH/2023-12-11%20-%20FindSavedPipelineOutputs.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m good_session_concrete_folders\n",
      "\u001b[0;31mNameError\u001b[0m: name 'good_session_concrete_folders' is not defined"
     ]
    }
   ],
   "source": [
    "good_session_concrete_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{PosixPath('/home/halechr/FastData/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl'): PosixPath('/home/halechr/FastData/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle_2023-12-19.pkl'),\n",
       " PosixPath('/home/halechr/FastData/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl'): PosixPath('/home/halechr/FastData/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results_2023-12-19.pkl'),\n",
       " PosixPath('/home/halechr/FastData/gen_scripts/run_kdiba_gor01_one_2006-6-09_1-22-43/loadedSessPickle.pkl'): PosixPath('/home/halechr/FastData/gen_scripts/run_kdiba_gor01_one_2006-6-09_1-22-43/loadedSessPickle_2023-12-19.pkl'),\n",
       " PosixPath('/home/halechr/FastData/gen_scripts/run_kdiba_gor01_one_2006-6-09_1-22-43/global_computation_results.pkl'): PosixPath('/home/halechr/FastData/gen_scripts/run_kdiba_gor01_one_2006-6-09_1-22-43/global_computation_results_2023-12-19.pkl')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy_dict = ConcreteSessionFolder.build_backup_copydict(data_repos_good_session_concrete_folders_dict['FastData'], backup_mode=BackupMethods.RenameInSourceDirectory, rename_backup_suffix=BATCH_DATE_TO_USE, only_include_file_types=['global_pkl'])\n",
    "copy_dict_FastData = ConcreteSessionFolder.build_backup_copydict(data_repos_good_session_concrete_folders_dict['FastData'], backup_mode=BackupMethods.RenameInSourceDirectory, rename_backup_suffix=BATCH_DATE_TO_USE, only_include_file_types=['local_pkl', 'global_pkl'])\n",
    "copy_dict_FastData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moved_files_dict_FastData_files = copy_movedict(copy_dict_FastData)\n",
    "moved_files_dict_FastData_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_session_pickle_files, found_global_computation_results_files = data_repos['MAX'].try_find_files()\n",
    "found_session_pickle_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d60f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_data_root = Path(r'/media/MAX/Data')\n",
    "dest_data_root = Path(r'/home/halechr/FastData')\n",
    "assert source_data_root.exists(), f\"source_data_root: {source_data_root} does not exist! Is the right computer's config commented out above?\"\n",
    "assert dest_data_root.exists(), f\"dest_data_root: {dest_data_root} does not exist! Is the right computer's config commented out above?\"\n",
    "\n",
    "oldest_modified_date = (datetime.now() - timedelta(days=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the files and build the movedicts:\n",
    "found_session_pickle_files = discover_data_files(source_data_root, glob_pattern='loadedSessPickle.pkl', recursive=True)\n",
    "found_global_computation_results_files = discover_data_files(source_data_root, glob_pattern=f'output/{completed_global_computations_filename}', recursive=True)\n",
    "file_movedict_session_pickle_files = generate_copydict(source_data_root, dest_data_root, found_files=found_session_pickle_files, only_files_newer_than=oldest_modified_date)\n",
    "file_movedict_global_computation_results_pickle_files = generate_copydict(source_data_root, dest_data_root, found_files=found_global_computation_results_files, only_files_newer_than=oldest_modified_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a22684",
   "metadata": {},
   "source": [
    "### Actually perform copy operations. This will take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0548870",
   "metadata": {},
   "outputs": [],
   "source": [
    "moved_files_dict_session_pickle_files = copy_movedict(file_movedict_session_pickle_files)\n",
    "moved_files_dict_session_pickle_files\n",
    "\n",
    "# moved_files_dict = copy_files(filelist_source, filelist_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7732c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "moved_files_dict_global_computation_results_pickle_files = copy_movedict(file_movedict_global_computation_results_pickle_files)\n",
    "moved_files_dict_global_computation_results_pickle_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various file formats:\n",
    "'global_computation_results_2023-12-07_GL.pkl'\n",
    "'20231012125859-global_computation_results.pkltmp'\n",
    "\"loadedSessPickle_2023-12-07_GL.pkl\"\n",
    "\"backup-20231020190542-loadedSessPickle.pkl\"\n",
    "\"loadedSessPickle_2023-10-25_BidirectionalOnly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hardcoded included_session_contexts:\n",
    "included_session_contexts = [\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'), # prev completed\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "    # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'), # prev completed\n",
    "]\n",
    "\n",
    "active_global_batch_result_filename=f'global_batch_result_{BATCH_DATE_TO_USE}.pkl'\n",
    "\n",
    "debug_print = False\n",
    "known_global_data_root_parent_paths = [Path(r'/home/halechr/cloud/turbo/Data'), Path(r'W:\\Data'), Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data')] # , Path(r'/home/halechr/FastData'), Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'/home/halechr/turbo/Data'), \n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "good_session_concrete_folders = ConcreteSessionFolder.build_concrete_session_folders(global_data_root_parent_path, included_session_contexts)\n",
    "\n",
    "## Build Slurm Scripts:\n",
    "session_basedirs_dict: Dict[IdentifyingContext, Path] = {a_session_folder.context:a_session_folder.path for a_session_folder in good_session_concrete_folders}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_files_dict = {}\n",
    "\n",
    "for a_ctxt, a_path in session_basedirs_dict.items():\n",
    "\tfound_any_kind_session_pickle_files = discover_data_files(a_path, glob_pattern='*loadedSessPickle*.pkl', recursive=True)\n",
    "\tfound_any_global_computation_results_files = discover_data_files(a_path, glob_pattern='output/*global_computation_results*.pkl', recursive=True)\n",
    "\tfound_files_dict[a_ctxt] = (found_any_kind_session_pickle_files, found_any_global_computation_results_files)\n",
    "\n",
    "found_files_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_tree(found_files_dict):\n",
    "    tree_str = \"\"\n",
    "    for session, (session_files, global_files) in found_files_dict.items():\n",
    "        tree_str += f\"{session}\\n\"\n",
    "        if session_files:\n",
    "            tree_str += \"  - Session Pickle Files:\\n\"\n",
    "            for file in session_files:\n",
    "                tree_str += f\"    * {file}\\n\"\n",
    "        if global_files:\n",
    "            tree_str += \"  - Global Computation Results Files:\\n\"\n",
    "            for file in global_files:\n",
    "                tree_str += f\"    * {file}\\n\"\n",
    "    return tree_str\n",
    "\n",
    "# Example of usage\n",
    "tree_representation = render_tree(found_files_dict)\n",
    "print(tree_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "def create_tree_view(found_files_dict):\n",
    "    sessions_accordion = widgets.Accordion(children=[widgets.VBox() for _ in found_files_dict])\n",
    "    for i, (session, (session_files, global_files)) in enumerate(found_files_dict.items()):\n",
    "        session_accordion = sessions_accordion.children[i]\n",
    "        \n",
    "        # Convert paths to strings and create session pickle files accordion\n",
    "        session_files_accordion = widgets.Accordion(children=[\n",
    "            widgets.VBox([widgets.Label(str(file)) for file in session_files])\n",
    "        ])\n",
    "        session_files_accordion.set_title(0, 'Session Pickle Files')\n",
    "\n",
    "        # Convert paths to strings and create global computation results files accordion\n",
    "        global_files_accordion = widgets.Accordion(children=[\n",
    "            widgets.VBox([widgets.Label(str(file)) for file in global_files])\n",
    "        ])\n",
    "        global_files_accordion.set_title(0, 'Global Computation Results Files')\n",
    "\n",
    "        # Set session accordion children\n",
    "        session_accordion.children = [session_files_accordion, global_files_accordion]\n",
    "        \n",
    "        # Set main accordion title\n",
    "        sessions_accordion.set_title(i, str(session))\n",
    "\n",
    "    return sessions_accordion\n",
    "\n",
    "# Example usage\n",
    "tree_view = create_tree_view(found_files_dict)\n",
    "tree_view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# search_parent_path = Path(r'W:\\\\Data\\\\Kdiba')\n",
    "# search_parent_path = Path(r'/home/halechr/turbo/Data/KDIBA').resolve() # Greatlakes\n",
    "search_parent_path = Path(r'/home/halechr/cloud/turbo/Data/KDIBA').resolve() # Lab\n",
    "\n",
    "# found_autoversioned_session_pickle_files = discover_data_files(search_parent_path, glob_pattern='*-loadedSessPickle.pkl', recursive=True)\n",
    "# found_global_computation_results_files = discover_data_files(search_parent_path, glob_pattern='output/*.pkl', recursive=True)\n",
    "\n",
    "\n",
    "found_any_kind_session_pickle_files = discover_data_files(search_parent_path, glob_pattern='*loadedSessPickle*.pkl', recursive=True)\n",
    "found_any_global_computation_results_files = discover_data_files(search_parent_path, glob_pattern='output/*global_computation_results*.pkl', recursive=True)\n",
    "\n",
    "# found_session_pickle_files = discover_data_files(source_data_root, glob_pattern='loadedSessPickle.pkl', recursive=True)\n",
    "# found_global_computation_results_files = discover_data_files(source_data_root, glob_pattern=f'output/{completed_global_computations_filename}', recursive=True)\n",
    "\n",
    "found_files = found_any_global_computation_results_files + found_any_kind_session_pickle_files\n",
    "found_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66727ff",
   "metadata": {},
   "source": [
    "# 2023-11-20 - Discovery of folder modification times from matching files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403b3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "Write a python function that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1abc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def determine_directory_modification_time(target_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
