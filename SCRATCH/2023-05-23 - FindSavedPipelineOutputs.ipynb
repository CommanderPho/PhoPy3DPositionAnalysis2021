{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd5d37-e658-4133-afa0-a8641b5fecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-05-23 - This code was created to quickly backup all of the good `loadedSessPickle.pkl` files from the session folders into the './output' subfolder in the session:\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_12-3-25/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-09_21-17-16/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/fet11-04_21-20-3/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-03_21-26-8/output/loadedSessPickle.pkl already in output folder.\n",
    "# p: /nfs/turbo/umms-kdiba/Data/KDIBA/pin01/one/11-09_22-4-5/output/loadedSessPickle.pkl already in output folder.\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08951e7-4fef-4226-b3cd-75627533e944",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, get_file_metadata, FileList\n",
    "# import glob # for finding .whl file after building binary repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29978b7c-a1cc-4e6b-bf40-d2f1af0ecee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "./KDIBA/vvp01/one/2006-4-18_13-6-1/loadedSessPickle.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c4083-b7b0-4a4a-ad63-7db9400ff058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use glob to find the first generated .whl file in the dist/ directory\n",
    "found_whl_files = glob.glob('*.whl')\n",
    "found_whl_files = [a for a in found_whl_files if not a.endswith('current.whl')] # exclude the symlink from the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2088d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_pipeline_filename = 'loadedSessPickle.pkl'\n",
    "completed_global_computations_filename = 'global_computation_results.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa314cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_computed_ripple_filepath = session.basepath.joinpath('ripple_df.pkl')\n",
    "## try the '.ripple.npy' ripples:\n",
    "active_file_suffix = '.ripple.npy'\n",
    "external_computed_ripple_filepath = fp.with_suffix(active_file_suffix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db0613-f7f6-48a7-9beb-2f17b3eb941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moves all previously saved loadedSessPickle.pkl files to the output folder.\n",
    "correctly_placed_output_files = []\n",
    "search_path: Path = Path(\"/home/halechr/turbo/Data/KDIBA/\").resolve()\n",
    "assert search_path.exists()\n",
    "for p in search_path.rglob(completed_pipeline_filename):\n",
    "    if p.parent.name != 'output':\n",
    "        # If not already in the 'output/' subfolder, move it there.\n",
    "        print(f'p: {p}')\n",
    "        curr_output_dir = p.parent.joinpath('output')\n",
    "        curr_output_dir.mkdir(exist_ok=True)\n",
    "        # print(f'curr_output_dir: {curr_output_dir}')\n",
    "        new_path = p.replace(curr_output_dir.joinpath(p.name))\n",
    "        print(f'\\t new_path: {new_path}')\n",
    "        correctly_placed_output_files.append(p)\n",
    "    else:\n",
    "        print(f'p: {p} already in output folder.')\n",
    "        correctly_placed_output_files.append(p)\n",
    "    \n",
    "correctly_placed_output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0247e456-9178-440f-9131-377449784e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1a6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "\n",
    "## Build Pickle Path:\n",
    "pkl_path = 'global_batch_result_2023-06-08.pkl'\n",
    "csv_path = 'global_batch_result_2023-06-08.csv'\n",
    "h5_path = 'global_batch_result_2023-06-08.h5'\n",
    "\n",
    "global_batch_result_file_path = Path(global_data_root_parent_path).joinpath(h5_path).resolve() # Use Default\n",
    "\n",
    "batch_progress_df = BatchRun.load_batch_progress_df_from_h5(global_batch_result_file_path)\n",
    "batch_progress_df\n",
    "\n",
    "updated_batch_progress_df = BatchRun.rebuild_basedirs(batch_progress_df, global_data_root_parent_path)\n",
    "updated_batch_progress_df\n",
    "\n",
    "updated_good_only_batch_progress_df = updated_batch_progress_df[updated_batch_progress_df['locally_is_ready']].copy()\n",
    "updated_good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate code that can be pasted into the current \"ReviewOfWork-*.ipynb\" notebook to load the good sessions:\n",
    "print(\",\\n\".join([a_ctxt.get_initialization_code_string() for a_ctxt in updated_good_only_batch_progress_df['context'].to_list()]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
