"""
This type stub file was generated by pyright.
"""

import numpy as np
import pandas as pd
import abc
from enum import Enum, unique
from typing import Optional, Tuple
from datetime import datetime

class NonStringIterable(metaclass=abc.ABCMeta):
    __slots__ = ...
    @abc.abstractmethod
    def __iter__(self): # -> Generator[None, Any, None]:
        ...
    
    @classmethod
    def __subclasshook__(cls, c): # -> _NotImplementedType | Literal[False]:
        ...
    


def is_iterable(value): # -> bool:
    """Returns true if the value is iterable but not a string.
    Args:
        value ([type]): [description]
    Returns:
        [type]: [description]
    """
    ...

class AutoNameEnum(Enum):
    """ Inheriting enums will be able to auto generate their name from a string value.

    Usage:
        class Ordinal(AutoNameEnum):
            NORTH = auto()
            SOUTH = auto()
            EAST = auto()
            WEST = auto()
    """
    ...


def chunks(iterable, size=...): # -> Generator[Generator[Any, Any, None], Any, None]:
    """[summary]

    Args:
        iterable ([type]): [description]
        size (int, optional): [description]. Defaults to 10.

    Usage:
        laps_pages = [list(chunk) for chunk in _chunks(sess.laps.lap_id, curr_num_subplots)]
    """
    ...

RowColTuple = ...
PaginatedGridIndexSpecifierTuple = ...
RequiredSubplotsTuple = ...
def compute_paginated_grid_config(num_required_subplots, max_num_columns, max_subplots_per_page, data_indicies=..., last_figure_subplots_same_layout=..., debug_print=...): # -> tuple[RequiredSubplotsTuple, list[list[Any]], list[RowColTuple]]:
    """ Fills row-wise first 

    Args:
        num_required_subplots ([type]): [description]
        max_num_columns ([type]): [description]
        max_subplots_per_page ([type]): [description]
        data_indicies ([type], optional): your indicies into your original data that will also be accessible in the main loop. Defaults to None, in which case they will be the same as the linear indicies unless otherwise specified
    """
    ...

def get_interval(self, period, nwindows): # -> list[list[Any]]:
    ...

def print_seconds_human_readable(seconds): # -> tuple[int, int, int, Any | None]:
    """ prints the seconds arguments as a human-redable HH::MM:SS.FRACTIONAL time. """
    ...

def copy_if_not_none(val): # -> None:
    """ solves the problem of AttributeError: 'NoneType' object has no attribute 'copy', gracefully passing None through if the value is None and copying it otherwise. """
    ...

def shuffle_ids(neuron_ids, seed: Optional[int] = ...): # -> tuple[Any, NDArray[Any]]:
    """ Shuffles the neuron_ids list, and returns the shuffled list and the shuffle indicies. The shuffle indicies can be used to shuffle other lists in the same way. 

    Input:

        neuron_ids: a list of neuron ids to shuffle
    
    Usage:
        from neuropy.utils.misc import shuffle_ids
        shuffled_aclus, shuffle_IDXs = shuffle_ids(original_1D_decoder.neuron_IDs)
    """
    ...

def build_shuffled_ids(neuron_ids, num_shuffles: int = ..., seed: Optional[int] = ..., debug_print=...) -> Tuple[np.ndarray, np.ndarray]:
    """ Builds `num_shuffles` of the neuron_ids and returns both shuffled_aclus and shuffled_IDXs
	
	Uses numpy 2023-10-20 best practices for random number generation.
	
	Shuffled.
    
    Returns:
        shuffled_aclus.shape # .shape: (num_shuffles, n_neurons)
        shuffled_IDXs.shape # .shape: (num_shuffles, n_neurons)
        
        
    Usage:
        from neuropy.utils.misc import build_shuffled_ids

        num_shuffles = 1000
        shuffled_aclus, shuffled_IDXs = build_shuffled_ids(shared_aclus_only_neuron_IDs, num_shuffles=num_shuffles, seed=1337) # .shape: ((num_shuffles, n_neurons), (num_shuffles, n_neurons))

	"""
    ...

def split_list_of_dicts(list_of_dicts: list) -> dict:
    """ Converts of a list<dict> (a list of dictionaries) where each element dictionary has the same keys to a dictionary of equal-length lists.
    
    Input:
        [{'smooth': (None, None), 'grid_bin': (0.5, 0.5)},
         {'smooth': (None, None), 'grid_bin': (1.0, 1.0)},
         {'smooth': (None, None), 'grid_bin': (2.0, 2.0)},
         {'smooth': (None, None), 'grid_bin': (5.0, 5.0)},
         {'smooth': (0.5, 0.5), 'grid_bin': (0.5, 0.5)},
         {'smooth': (0.5, 0.5), 'grid_bin': (1.0, 1.0)},
         {'smooth': (0.5, 0.5), 'grid_bin': (2.0, 2.0)},
         {'smooth': (0.5, 0.5), 'grid_bin': (5.0, 5.0)},
         {'smooth': (1.0, 1.0), 'grid_bin': (0.5, 0.5)},
         {'smooth': (1.0, 1.0), 'grid_bin': (1.0, 1.0)},
         {'smooth': (1.0, 1.0), 'grid_bin': (2.0, 2.0)},
         {'smooth': (1.0, 1.0), 'grid_bin': (5.0, 5.0)}]

    from neuropy.utils.misc import split_list_of_dicts
    split_list_of_dicts(all_param_sweep_options)

    Output:
        {'smooth': [(None, None), (None, None), (None, None), (None, None), (0.5, 0.5), (0.5, 0.5), (0.5, 0.5), (0.5, 0.5), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0)], 
         'grid_bin': [(0.5, 0.5), (1.0, 1.0), (2.0, 2.0), (5.0, 5.0), (0.5, 0.5), (1.0, 1.0), (2.0, 2.0), (5.0, 5.0), (0.5, 0.5), (1.0, 1.0), (2.0, 2.0), (5.0, 5.0)]
         }

    """
    ...

def safe_item(arr: np.ndarray, *args, default=...): # -> None:
    """ a version of .item() for ndarrays that returns the scalar if there's a single item in a list, otherwise returns default_value
    Usage:
        safe_item(np.array([0]), default=None) # 0
        safe_item(np.array([]), default=-1) # -1
    """
    ...

def split_array(arr: np.ndarray, sub_element_lengths: np.ndarray) -> list:
    """ 2023-03-25 - Takes a numpy array `arr` of length N and splits it into len(sub_element_lengths) pieces where piece i has length sub_element_lengths[i].
    
    Args:
        arr (np.ndarray): Input numpy array of length N.
        sub_element_lengths (np.ndarray): Array of integers indicating the length of each sub-element.
        
    Returns:
        np.ndarray: A numpy array of shape (len(sub_element_lengths), sub_element_lengths[i]) containing the sub-elements.
        
    Raises:
        ValueError: If the sum of sub_element_lengths is not equal to N.

    Usage:
        from neuropy.utils.misc import split_array
        

    """
    ...

def safe_pandas_get_group(dataframe_group, key):
    """ returns an empty dataframe if the key isn't found in the group.
    Usage:
        from neuropy.utils.misc import safe_pandas_get_group
        safe_pandas_get_group(grouped_rdf, False)
    """
    ...

def convert_dataframe_columns_to_datatype_if_possible(df: pd.DataFrame, datatype_str_column_names_list_dict, debug_print=...): # -> None:
    """ If the columns specified in datatype_str_column_names_list_dict exist in the dataframe df, their type is changed to the key of the dict. See usage example below:
    
    Inputs:
        df: Pandas.DataFrame 
        datatype_str_column_names_list_dict: {'int':['shank', 'cluster', 'aclu', 'qclu', 'traj', 'lap']}

    Usage:
        from neuropy.utils.misc import convert_dataframe_columns_to_datatype_if_possible
        convert_dataframe_columns_to_datatype_if_possible(curr_active_pipeline.sess.spikes_df, {'int':['shank', 'cluster', 'aclu', 'qclu', 'traj', 'lap']})
    """
    ...

def add_explicit_dataframe_columns_from_lookup_df(df, lookup_properties_map_df, join_column_name=...): # -> DataFrame[Any]:
    """ Uses a value (specified by `join_column_name`) in each row of `df` to lookup the appropriate values in `lookup_properties_map_df` to be explicitly added as columns to `df`
    df: a dataframe. Each row has a join_column_name value (e.g. 'aclu')
    
    lookup_properties_map_df: a dataframe with one row for each `join_column_name` value (e.g. one row for each 'aclu', describing various properties of that neuron)
    
    
    By default lookup_properties_map_df can be obtained from curr_active_pipeline.sess.neurons._extended_neuron_properties_df and has the columns:
        ['aclu', 'qclu', 'neuron_type', 'shank', 'cluster']
    Which will be added to the spikes_df
    
    WARNING: the df will be unsorted after this operation, and you'll need to sort it again if you want it sorted
    
    
    Usage:
        from neuropy.utils.misc import add_explicit_dataframe_columns_from_lookup_df
        curr_active_pipeline.sess.flattened_spiketrains._spikes_df = add_explicit_dataframe_columns_from_lookup_df(curr_active_pipeline.sess.spikes_df, curr_active_pipeline.sess.neurons._extended_neuron_properties_df)
        curr_active_pipeline.sess.spikes_df.sort_values(by=['t_seconds'], inplace=True) # Need to re-sort by timestamps once done
        curr_active_pipeline.sess.spikes_df

    """
    ...

@unique
class DateTimeFormat(Enum):
    """Converts between datetime and string
    
    Usage:
    
        from neuropy.utils.misc import DateTimeFormat
        
        now = datetime.now()

        # Convert datetime to string
        s = DateTimeFormat.WHOLE_SECONDS.datetime_to_string(now)
        print(s)

        # Convert string back to datetime
        dt = DateTimeFormat.WHOLE_SECONDS.string_to_datetime(s)
        print(dt)

    """
    WHOLE_SECONDS = ...
    FRACTIONAL_SECONDS = ...
    def datetime_to_string(self, dt: datetime) -> str:
        ...
    
    def string_to_datetime(self, s: str) -> datetime:
        ...
    
    @property
    def now_string(self) -> str:
        """Get the current date and time as an appropriately formatted string
        Usage:
            from neuropy.utils.misc import DateTimeFormat
            DateTimeFormat.WHOLE_SECONDS.now_string
        """
        ...
    


