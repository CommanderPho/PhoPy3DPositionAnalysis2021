{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext viztracer\n",
    "from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import neptune # for logging progress and results\n",
    "from pyphoplacecellanalysis.General.Batch.NeptuneAiHelpers import set_environment_variables, neptune_output_figures\n",
    "neptune_kwargs = {'project':\"commander.pho/PhoDibaLongShort2023\",\n",
    "'api_token':\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGIxODU2My1lZTNhLTQ2ZWMtOTkzNS02ZTRmNzM5YmNjNjIifQ==\"}\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from attrs import define, field, fields, Factory\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import CodeConversion\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible, print_value_overview_only, document_active_variables, objsize, print_object_memory_usage, debug_dump_object_member_shapes, TypePrintMode\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "\n",
    "from pyphocorehelpers.print_helpers import generate_html_string\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot, create_daily_programmatic_display_function_testing_folder_if_needed, session_context_to_relative_path\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import build_pyqtgraph_epoch_indicator_regions # Add session indicators to pyqtgraph plot\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _helper_add_long_short_session_indicator_regions\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "\n",
    "# Plotting\n",
    "import pylustrator\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.helpers import _helper_make_scatterplot_clickable\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from scripts.run_BatchAnalysis import post_compute_validate, _on_complete_success_execution_session\n",
    "from PendingNotebookCode import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full\n",
    "from PendingNotebookCode import PAPER_FIGURE_figure_3\n",
    "\n",
    "session_batch_status = {}\n",
    "session_batch_errors = {}\n",
    "enable_saving_to_disk = False\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl.\n",
      "property already present in pickled version. No need to save.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\global_computation_results.pkl... done.\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "#     neuropy/data_session_pre_processing_scripts/KDIBA/IIDataMat_Export_ToPython_2022_08_01.m\n",
    "# From pre-computed .mat files:\n",
    "\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # DONE. Very good. Many good Pfs, many good replays.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays!\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3') # DONE, Good Pfs, no good epochs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # BAD, Good Pfs strangely despite horrible map, no good epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # DONE\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "\n",
    "\n",
    "    # ==================================================================================================================== #\n",
    "    # Load Pipeline                                                                                                        #\n",
    "    # ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=[#'_perform_estimated_epochs_computation',  # AL:WAYS OFF\n",
    "                                            '_perform_baseline_placefield_computation',\n",
    "                                        # '_perform_time_dependent_placefield_computation', # AL:WAYS OFF\n",
    "                                        '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        # '_perform_time_dependent_pf_sequential_surprise_computation' # AL:WAYS OFF\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding' # AL:WAYS OFF\n",
    "                                    ]\n",
    "# active_computation_functions_name_includelist=['_perform_baseline_placefield_computation']\n",
    "\n",
    "curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        curr_active_pipeline.load_pickled_global_computation_results()\n",
    "    except Exception as e:\n",
    "        print(f'cannot load global results: {e}')\n",
    "\n",
    "# 6m 1.1s\n",
    "# 12m 15.6s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8aab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "from neuropy.utils.matplotlib_helpers import interactive_select_grid_bin_bounds_2D\n",
    "# fig, ax, rect_selector, set_extents = interactive_select_grid_bin_bounds_2D(curr_active_pipeline, epoch_name='maze', should_block_for_input=True)\n",
    "\n",
    "grid_bin_bounds = interactive_select_grid_bin_bounds_2D(curr_active_pipeline, epoch_name='maze', should_block_for_input=True, should_apply_updates_to_pipeline=False)\n",
    "print(f'grid_bin_bounds: {grid_bin_bounds}')\n",
    "print(f\"Add this to `specific_session_override_dict`:\\n\\n{curr_active_pipeline.get_session_context().get_initialization_code_string()}:dict(grid_bin_bounds=({(grid_bin_bounds[0], grid_bin_bounds[1]), (grid_bin_bounds[2], grid_bin_bounds[3])})),\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a29b890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis already computed.\n",
      "long_short_fr_indicies_analyses already computed.\n",
      "long_short_decoding_analyses already computed.\n",
      "long_short_post_decoding already computed.\n",
      "done with all batch_extended_computations(...).\n",
      "no changes in global results.\n"
     ]
    }
   ],
   "source": [
    "## Post Compute Validate 2023-05-16:\n",
    "from scripts.run_BatchAnalysis import post_compute_validate\n",
    "post_compute_validate(curr_active_pipeline)\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "extended_computations_include_includelist=['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'] # do only specifiedl , 'long_short_rate_remapping'\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "# extended_computations_include_includelist=['long_short_post_decoding'] # do only specifiedl\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=force_recompute_global, debug_print=False)\n",
    "if len(newly_computed_values) > 0:\n",
    "\tprint(f'newly_computed_values: {newly_computed_values}. Saving global results...')\n",
    "\ttry:\n",
    "\t\t# curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "\t\t# Try to write out the global computation function results:\n",
    "\t\tcurr_active_pipeline.save_global_computation_results()\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "\t\tprint(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "\tprint(f'no changes in global results.')\n",
    "# 10m 29.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "neptuner = batch_perform_all_plots(curr_active_pipeline, enable_neptune=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e7106ef",
   "metadata": {},
   "source": [
    "### Pipeline Loading/Saving [Optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f3fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE) # AttributeError: 'PfND_TimeDependent' object has no attribute '_included_thresh_neurons_indx'\n",
    "# TypeError: cannot pickle 'MplMultiTab' object\n",
    "# PicklingError: Can't pickle .set_closure_cell at 0x000002BF248F50D0>: it's not found as attr._compat.make_set_closure_cell..set_closure_cell\n",
    "# TypeError: cannot pickle 'PyQt5.QtCore.pyqtSignal' object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c2afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results() # PicklingError: Can't pickle .set_closure_cell at 0x000002BF248F50D0>: it's not found as attr._compat.make_set_closure_cell..set_closure_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.load_pickled_global_computation_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241dc49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba716fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c850782f",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda48261",
   "metadata": {
    "tags": [
     "load",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good_example_epoch_indicies_L: [ 13  25  27  31  37  42  48  57  61  62  63  76  79  82  89  90 111 112\n",
      " 115]\n",
      "good_example_epoch_indicies_S: [ 25  37  40  45  61  62  76  79  84  93  94 111 112 113 115 121]\n"
     ]
    }
   ],
   "source": [
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "## Extract variables from results object:\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global\n",
    "\n",
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result['Flat_epoch_time_bins_mean'], expected_v_observed_result['Flat_decoder_time_bin_centers'], expected_v_observed_result['num_neurons'], expected_v_observed_result['num_timebins_in_epoch'], expected_v_observed_result['num_total_flat_timebins'], expected_v_observed_result['is_short_track_epoch'], expected_v_observed_result['is_long_track_epoch'], expected_v_observed_result['short_short_diff'], expected_v_observed_result['long_long_diff']\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9e59bdb",
   "metadata": {},
   "source": [
    "# Figure 1) pf1D Ratemaps, Active set, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77377ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: new_all_aclus_sort_indicies: [56 65 43 21 30 47 55 27 60 67 39  3 53 14 62 44 61 25  9 16 19  8 18 20\n",
      " 31 49  1 15 26 52  5 50 59 40 37 48  4 54  0 24 46 29 64 58 10 35 57 32\n",
      " 66 41 36 63 23 17 11 22 38 33  6 12 13 45 34  2 51 28 42  7]\n",
      "\t saved C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\2023-06-29\\kdiba_gor01_one_2006-6-08_14-26-15_display_short_long_pf1D_comparison_long.png\n",
      "\t saved C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\2023-06-29\\kdiba_gor01_one_2006-6-08_14-26-15_display_short_long_pf1D_comparison_short.png\n",
      "good_example_epoch_indicies_L: [ 13  25  27  31  37  42  48  57  61  62  63  76  79  82  89  90 111 112\n",
      " 115]\n",
      "good_example_epoch_indicies_S: [ 25  37  40  45  61  62  76  79  84  93  94 111 112 113 115 121]\n",
      "merged_kwargs: {'name': 'spikeRasterOverviewWindowScatterPlotItem', 'pxMode': True, 'symbol': <PyQt5.QtGui.QPainterPath object at 0x0000021A2715C350>, 'size': 6, 'pen': {'color': 'white', 'width': 1}, 'hoverable': True}\n",
      "merged_kwargs: {'name': 'spikeRasterOverviewWindowScatterPlotItem', 'pxMode': True, 'symbol': <PyQt5.QtGui.QPainterPath object at 0x0000021A2715C350>, 'size': 6, 'pen': {'color': 'white', 'width': 1}, 'hoverable': True}\n",
      "active_identifying_ctx_string: \"kdiba|gor01|one|2006-6-08_14-26-15|DecodedEpochSlices|replays|long_results_obj|[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121]\"\n",
      "active_identifying_ctx_string: \"kdiba|gor01|one|2006-6-08_14-26-15|DecodedEpochSlices|replays|long_results_obj|[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121]\"\n",
      "active_identifying_ctx_string: \"kdiba|gor01|one|2006-6-08_14-26-15|DecodedEpochSlices|replays|short_results_obj|[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121]\"\n",
      "active_identifying_ctx_string: \"kdiba|gor01|one|2006-6-08_14-26-15|DecodedEpochSlices|replays|short_results_obj|[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121]\"\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from PendingNotebookCode import PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_1_add_replay_epoch_rasters\n",
    "\n",
    "pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics = PAPER_FIGURE_figure_1_full(curr_active_pipeline) # did not display the pf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stacked Epoch Plot\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e11a3476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "\n",
    "# active_curves = long_pf1D.ratemap.normalized_tuning_curves[np.isin(long_pf1D.ratemap.neuron_ids, EITHER_subset.track_exclusive_aclus)]\n",
    "# is_included = np.isin(long_pf1D.ratemap.neuron_ids, EITHER_subset.track_exclusive_aclus)\n",
    "is_included_idxs = np.isin(EITHER_subset.track_exclusive_aclus, long_pf1D.ratemap.neuron_ids)\n",
    "included_new_all_aclus_sort_indicies = new_all_aclus_sort_indicies[is_included_idxs] # got only the target sort indicies that are in the neuron_ids\n",
    "\n",
    "# included_only_new_all_aclus = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1526691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_A_sort_indices(B, B_sort_indices, A):\n",
    "    \"\"\" \n",
    "        # Known that A is a subset of B.\n",
    "        Given B and a list of indicies that sort B, find the indicies that sort A.\n",
    "        B = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "        A = [1, 3, 5, 7, 9]\n",
    "        B_sort_indicies = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "        A_sort_indicies = [0, 2, 4, 6, 8]\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(B, np.ndarray):\n",
    "        B = B.tolist()\n",
    "    if isinstance(B_sort_indices, np.ndarray):\n",
    "        B_sort_indices = B_sort_indices.tolist()\n",
    "    A_sort_indices = []\n",
    "    for a in A:\n",
    "        index_in_B = B.index(a)  # Find the index of 'a' in B\n",
    "        A_sort_indices.append(B_sort_indices.index(index_in_B))  # Find the index of the index_in_B in B_sort_indices\n",
    "\n",
    "    A_sort_indices = np.array(A_sort_indices)\n",
    "    return A_sort_indices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5cafd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 87, 102,  34,  54,  74,  86,  92, 109,  63,   5,  96,  69,  93,\n",
       "        49,  15,  26,  32,  14,  31,  33,  55,  76,   3,  25,  82,  10,\n",
       "        78,  90,  64,  75,   8,  85,   2,  41,  73,  53,  89,  16,  88,\n",
       "        56, 108,  66,  60,  37,  28,  19,  36,  62,  57,  11,  21,  23,\n",
       "        70,  58,   4,  81,  52,  67,  13], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorted_aclus = EITHER_subset.track_exclusive_aclus[new_all_aclus_sort_indicies]\n",
    "sorted_aclus = EITHER_subset.track_exclusive_aclus[included_new_all_aclus_sort_indicies]\n",
    "sorted_aclus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3f4c673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included_final_neuron_ids.shape: (50,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  2,   3,   5,   8,  10,  11,  14,  15,  16,  19,  25,  26,  28,\n",
       "        31,  32,  33,  34,  36,  37,  41,  49,  53,  54,  55,  56,  57,\n",
       "        60,  62,  63,  64,  66,  69,  73,  74,  75,  76,  78,  82,  85,\n",
       "        86,  87,  88,  89,  90,  92,  93,  96, 102, 108, 109])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_target_aclus = np.array(long_pf1D.ratemap.neuron_ids)\n",
    "is_included = np.isin(all_target_aclus, sorted_aclus)\n",
    "included_final_neuron_ids = all_target_aclus[is_included] # now we should have completely cut down the targets that were not in the sorted_aclus, now just need to sort them with the existing function to get the indicies\n",
    "print(f'included_final_neuron_ids.shape: {np.shape(included_final_neuron_ids)}')\n",
    "included_final_neuron_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b53f63bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_sort_indices.shape: (50,)\n",
      "[38 26 11 36 30 58 21 18 44 54 27 19 53 22 20 23  3 55 52 39 17 41  4 24\n",
      " 47 57 50 56 10 33 49 15 40  5 35 25 31 29 37  6  0 46 43 32  8 16 14  1\n",
      " 48  9]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 58 is out of bounds for axis 0 with size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mA_sort_indices.shape: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mshape(A_sort_indices)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(A_sort_indices)\n\u001b[1;32m----> 5\u001b[0m included_final_sorted_neuron_ids \u001b[39m=\u001b[39m included_final_neuron_ids[A_sort_indices]\n\u001b[0;32m      6\u001b[0m included_final_sorted_neuron_ids\n\u001b[0;32m      8\u001b[0m \u001b[39m\"\"\" doesn't work.\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 58 is out of bounds for axis 0 with size 50"
     ]
    }
   ],
   "source": [
    "A_sort_indices = get_A_sort_indices(B=EITHER_subset.track_exclusive_aclus, B_sort_indices=new_all_aclus_sort_indicies, A=included_final_neuron_ids) # do I use `included_new_all_aclus_sort_indicies` or `new_all_aclus_sort_indicies`?\n",
    "print(f'A_sort_indices.shape: {np.shape(A_sort_indices)}')\n",
    "print(A_sort_indices)\n",
    "\n",
    "included_final_sorted_neuron_ids = included_final_neuron_ids[A_sort_indices]\n",
    "included_final_sorted_neuron_ids\n",
    "\n",
    "\"\"\" doesn't work.\n",
    "---------------------------------------------------------------------------\n",
    "IndexError                                Traceback (most recent call last)\n",
    "Cell In[56], line 5\n",
    "      2 print(f'A_sort_indices.shape: {np.shape(A_sort_indices)}')\n",
    "      3 print(A_sort_indices)\n",
    "----> 5 included_final_sorted_neuron_ids = included_final_neuron_ids[A_sort_indices]\n",
    "      6 included_final_sorted_neuron_ids\n",
    "\n",
    "IndexError: index 58 is out of bounds for axis 0 with size 50\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d322e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_curves = long_pf1D.ratemap.normalized_tuning_curves[is_included]\n",
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(active_curves, show_yticks=False, title=f\"pf1D Visualization\", defer_show=True)\n",
    "# , included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3433718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 6 8 3 1]\n"
     ]
    }
   ],
   "source": [
    "B = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "A = np.array([1, 3, 5, 7, 9])\n",
    "# B_sort_indices = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "B_sort_indices = np.array([5, 8, 0, 6, 7, 1, 2, 3, 4])\n",
    "\n",
    "A_sort_indices = get_A_sort_indices(B, B_sort_indices, A)\n",
    "print(A_sort_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9fcd9677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 1, 7, 8, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Start by sorting B, the B_sort_indicies are not at all relevent to the sorting of A.\n",
    "B_sorted = B[B_sort_indices]\n",
    "B_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96232699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A is not a subset of B because it has elements that are not in B.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "290c4779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sort_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf42c9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38 26 11 36 30 58 21 18 44 54 13 27 19 53 22 20 23  3 55 52 39 17 28  7\n",
      " 41  4 24 47 57 45 50 34 56 10 33 49  2 15 40  5 35 25 31 29 12 37  6  0\n",
      " 46 43 32  8 16 14 51 42  1 48  9]\n"
     ]
    }
   ],
   "source": [
    "A_sort_indices = get_A_sort_indices(B=EITHER_subset.track_exclusive_aclus, B_sort_indices=new_all_aclus_sort_indicies, A=long_pf1D.ratemap.neuron_ids)\n",
    "print(A_sort_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6cdffe9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 73,  55,  25,  68,  60, 109,  49,  36,  83,  98,  28,  56,  37,\n",
       "        96,  50,  41,  51,   8, 100,  93,  74,  34,  57,  15,  76,  10,\n",
       "        53,  87, 108,  85,  90,  64, 102,  24,  63,  89,   5,  32,  75,\n",
       "        11,  66,  54,  61,  59,  26,  69,  14,   2,  86,  82,  62,  16,\n",
       "        33,  31,  92,  78,   3,  88,  19])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(long_pf1D.ratemap.neuron_ids)[A_sort_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82d09101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 87, 102,  68,  34,  54,  74,  86,  51,  92, 109,  63,   5,  83,\n",
       "        24,  96,  69,  93,  49,  15,  26,  32,  14,  31,  33,  55,  76,\n",
       "         3,  25,  50,  82,  10,  78,  90,  64,  61,  75,   8,  85,   2,\n",
       "        41,  73,  53, 100,  89,  16,  59,  88,  56, 108,  66,  60,  98,\n",
       "        37,  28,  19,  36,  62,  57,  11,  21,  23,  70,  58,   4,  81,\n",
       "        52,  67,  13], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EITHER_subset.track_exclusive_aclus[new_all_aclus_sort_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EITHER_subset.is_aclu_pf_track_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e66369f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 65 is out of bounds for axis 0 with size 59",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m active_curves_sorted \u001b[39m=\u001b[39m long_pf1D\u001b[39m.\u001b[39;49mratemap\u001b[39m.\u001b[39;49mnormalized_tuning_curves[is_included][included_new_all_aclus_sort_indicies]\n\u001b[0;32m      2\u001b[0m heatmap_pf1D_win, heatmap_pf1D_img \u001b[39m=\u001b[39m visualize_heatmap_pyqtgraph(active_curves_sorted, show_yticks\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, title\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpf1D Sorted Visualization\u001b[39m\u001b[39m\"\u001b[39m, defer_show\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 65 is out of bounds for axis 0 with size 59"
     ]
    }
   ],
   "source": [
    "active_curves_sorted = long_pf1D.ratemap.normalized_tuning_curves[is_included][included_new_all_aclus_sort_indicies]\n",
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(active_curves_sorted, show_yticks=False, title=f\"pf1D Sorted Visualization\", defer_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f0066",
   "metadata": {
    "tags": [
     "unwrap_figure_output",
     "interactive"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "pagination_controller_L, pagination_controller_S = example_stacked_epoch_graphics.plot_data['controllers']\n",
    "ax_L, ax_S = example_stacked_epoch_graphics.axes\n",
    "final_figure_context_L, final_context_S = example_stacked_epoch_graphics.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b8b4b",
   "metadata": {
    "tags": [
     "selections",
     "user_annotations"
    ]
   },
   "outputs": [],
   "source": [
    "from PendingNotebookCode import UserAnnotationsManager\n",
    "\n",
    "user_anootations = UserAnnotationsManager.get_user_annotations()\n",
    "user_anootations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e130b",
   "metadata": {
    "tags": [
     "selections",
     "user_annotations"
    ]
   },
   "outputs": [],
   "source": [
    "## Update the currently displayed selections with the user annotations:\n",
    "\n",
    "\n",
    "## Capture current user selection\n",
    "saved_selection_L = pagination_controller_L.save_selection()\n",
    "saved_selection_S = pagination_controller_S.save_selection()\n",
    "\n",
    "saved_selection_L = UserAnnotationsManager.update_selections_from_annotations(saved_selection_L, user_anootations)\n",
    "saved_selection_S = UserAnnotationsManager.update_selections_from_annotations(saved_selection_S, user_anootations)\n",
    "## re-apply the selections:\n",
    "pagination_controller_L.restore_selections(saved_selection_L)\n",
    "pagination_controller_S.restore_selections(saved_selection_S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8858abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_tip_fn(...): data_string: t:\t1530.618055363535\n",
      "aclu:\t52\n",
      "neuron_IDX:\t24\n",
      "_tip_fn(...): data_string: t:\t799.9981260809582\n",
      "aclu:\t86\n",
      "neuron_IDX:\t49\n",
      "_tip_fn(...): data_string: t:\t799.9994163203519\n",
      "aclu:\t49\n",
      "neuron_IDX:\t20\n",
      "_tip_fn(...): data_string: t:\t857.3767283831257\n",
      "aclu:\t49\n",
      "neuron_IDX:\t20\n",
      "_tip_fn(...): data_string: t:\t857.3823808602756\n",
      "aclu:\t92\n",
      "neuron_IDX:\t54\n",
      "_tip_fn(...): data_string: t:\t857.3823808602756\n",
      "aclu:\t92\n",
      "neuron_IDX:\t54\n",
      "_tip_fn(...): data_string: t:\t857.3823808602756\n",
      "aclu:\t92\n",
      "neuron_IDX:\t54\n",
      "_tip_fn(...): data_string: t:\t906.1706925206818\n",
      "aclu:\t2\n",
      "neuron_IDX:\t0\n",
      "_tip_fn(...): data_string: t:\t906.1706925206818\n",
      "aclu:\t2\n",
      "neuron_IDX:\t0\n",
      "_tip_fn(...): data_string: t:\t906.1706925206818\n",
      "aclu:\t2\n",
      "neuron_IDX:\t0\n",
      "_tip_fn(...): data_string: t:\t906.1706925206818\n",
      "aclu:\t2\n",
      "neuron_IDX:\t0\n",
      "_tip_fn(...): data_string: t:\t906.1706925206818\n",
      "aclu:\t2\n",
      "neuron_IDX:\t0\n",
      "_tip_fn(...): data_string: t:\t906.1706925206818\n",
      "aclu:\t2\n",
      "neuron_IDX:\t0\n",
      "_tip_fn(...): data_string: t:\t906.1706925206818\n",
      "aclu:\t2\n",
      "neuron_IDX:\t0\n",
      "_tip_fn(...): data_string: t:\t906.1706925206818\n",
      "aclu:\t2\n",
      "neuron_IDX:\t0\n",
      "_tip_fn(...): data_string: t:\t906.1706925206818\n",
      "aclu:\t2\n",
      "neuron_IDX:\t0\n",
      "_tip_fn(...): data_string: t:\t906.1706925206818\n",
      "aclu:\t2\n",
      "neuron_IDX:\t0\n"
     ]
    }
   ],
   "source": [
    "# unit_colors_list = None # default rainbow of colors for the raster plots\n",
    "neuron_qcolors_list = [pg.mkColor('black') for aclu in EITHER_subset.track_exclusive_aclus] # solid green for all\n",
    "unit_colors_list = DataSeriesColorHelpers.qColorsList_to_NDarray(neuron_qcolors_list, is_255_array=True)\n",
    "\n",
    "# Copy and modify the colors for the cells that are long/short exclusive:\n",
    "unit_colors_list_L = deepcopy(unit_colors_list)\n",
    "is_L_exclusive = np.isin(EITHER_subset.track_exclusive_aclus, long_exclusive.track_exclusive_aclus) # get long exclusive\n",
    "unit_colors_list_L[0, is_L_exclusive] = 255 # [1.0, 0.0, 0.0, 1.0]\n",
    "unit_colors_list_L[1, is_L_exclusive] = 0.0\n",
    "unit_colors_list_L[2, is_L_exclusive] = 0.0\n",
    "\n",
    "unit_colors_list_S = deepcopy(unit_colors_list)\n",
    "is_S_exclusive = np.isin(EITHER_subset.track_exclusive_aclus, short_exclusive.track_exclusive_aclus) # get short exclusive\n",
    "unit_colors_list_S[0, is_S_exclusive] = 0.0 # [1.0, 0.0, 0.0, 1.0]\n",
    "unit_colors_list_S[1, is_S_exclusive] = 0.0\n",
    "unit_colors_list_S[2, is_S_exclusive] = 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d92bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spikes_df = an_epoch_spikes_df.copy()\n",
    "scatterplot_tooltips_kwargs = Render2DScrollWindowPlotMixin._build_spike_data_tuples_from_spikes_df(spikes_df)\n",
    "override_scatter_plot_kwargs = {**scatterplot_tooltips_kwargs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8334bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import asdict, astuple\n",
    "\n",
    "data = scatterplot_tooltips_kwargs['data'][0]\n",
    "# asdict(scatterplot_tooltips_kwargs['data'][0])\n",
    "# astuple(scatterplot_tooltips_kwargs['data'][0])\n",
    "\n",
    "data_string:str = '\\n'.join([f\"{k}:\\t{str(v)}\" for k, v in asdict(data).items()])\n",
    "print(f'_tip_fn(...): data_string: {data_string}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e594d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "override_scatter_plot_kwargs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vtick = _build_default_tick(tick_width=1.0)\n",
    "\n",
    "# pxMode: If True, spots are always the same size regardless of scaling, and size is given in px. Otherwise, size is in scene coordinates and the spots scale with the view. To ensure effective caching, QPen and QBrush objects should be reused as much as possible. Default is True\n",
    "\n",
    "# size: The size (or list of sizes) of spots. If pxMode is True, this value is in pixels. Otherwise, it is in the item’s local coordinate system.\n",
    "\n",
    "override_scatter_plot_kwargs = dict(pxMode=True, symbol=vtick, size=10, pen={'color': 'w', 'width': 1.0})\n",
    "\n",
    "# override_scatter_plot_kwargs = dict(pxMode=False, symbol=vtick, size=1, pen={'color': 'w', 'width': 1.0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the symbol properties\n",
    "# symbol = pg.mkPen('w', width=1)  # Pen for the lines\n",
    "size = 1.0  # Fixed x-width\n",
    "symbol_brush = None  # No brush for the symbol (transparent fill)\n",
    "\n",
    "# override_scatter_plot_kwargs = dict(pxMode=False, symbol='|', size=size, pen={'color': 'w', 'width': 1.0}) # , brush=symbol_brush\n",
    "\n",
    "override_scatter_plot_kwargs = dict(pxMode=False, symbol='arrow_up', size=1.0, pen={'color': 'w', 'width': 1.0}, hoverable=True) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bb530",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epoch_spikes_df_L.spikes.rebuild_fragile_linear_neuron_IDXs();\n",
    "filter_epoch_spikes_df_S.spikes.rebuild_fragile_linear_neuron_IDXs();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_L, win_L, plots_L, plots_data_L = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "\t\t\t\t\t\t\t\t\t\tepoch_id_key_name='replay_epoch_id', scatter_app_name=\"Long Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee132b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_S, win_S, plots_S, plots_data_S = plot_multiple_raster_plot(epochs_df_S, filter_epoch_spikes_df_S, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                 epoch_id_key_name='replay_epoch_id', scatter_app_name=\"Short Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26dd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single `plot_raster_plot` calls\n",
    "an_epoch = list(epochs_df_L.itertuples())[0]\n",
    "an_epoch_spikes_df = filter_epoch_spikes_df_L[filter_epoch_spikes_df_L['replay_epoch_id'] == an_epoch.Index]\n",
    "\n",
    "_out_single_raster_plot = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test1\")\n",
    "_out_single_raster_plot2 = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6071c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_alt, win_alt, plots_alt, plots_data_alt = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                         epoch_id_key_name='replay_epoch_id', scatter_app_name=\"ALT Long Decoded Example Replays\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d20407c",
   "metadata": {},
   "source": [
    "### Testing `plot_kourosh_activity_style_figure` for debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69512447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import plot_kourosh_activity_style_figure\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.helpers import _helper_make_scatterplot_clickable\n",
    "\n",
    "# plot_aclus = EITHER_subset.track_exclusive_aclus.copy()\n",
    "plot_aclus = EITHER_subset.track_exclusive_aclus[new_all_aclus_sort_indicies].copy()\n",
    "_out_A = plot_kourosh_activity_style_figure(long_results_obj, long_session, plot_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_idx=13, callout_epoch_IDXs=None, skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, plots, plots_data = _out_A\n",
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 2023-06-23 07:52: - [ ] This GridItem method seems to actually work unlike the other showGrid methods and stuff.\n",
    "\n",
    "plot_item = plots.root_plot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grid = _build_units_y_grid(plot_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cac5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dedcdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clickable/Selectable Spikes:\n",
    "# global lastClicked  # Declare lastClicked as a global variable\n",
    "# Will make all plots clickable\n",
    "# clickedPen = pg.mkPen('#DDD', width=2)\n",
    "# lastClicked = []\n",
    "# def _test_scatter_plot_clicked(points, ev):\n",
    "# \t\"\"\" captures `lastClicked` \"\"\"\n",
    "# \t# global lastClicked  # Declare lastClicked as a global variable\n",
    "# \t# for p in lastClicked:\n",
    "# \t# \tp.resetPen()\n",
    "# \tprint(\"clicked points\", points)\n",
    "# \t# for p in points:\n",
    "# \t# \tp.setPen(clickedPen)\n",
    "# \t# lastClicked = points\n",
    "\n",
    "# main_scatter_clicked_connection = plots.scatter_plot.sigClicked.connect(_test_scatter_plot_clicked)\n",
    "\n",
    "_conn_hov = plots.scatter_plot.sigHovered.connect(lambda points, ev: print(f\"hovered points: {points}\\t event: {ev[0].pos()}\")) # \\t pos: {ev.pos()}, scenePos: {ev.scenePos()}\n",
    "_conn_clicked = plots.scatter_plot.sigClicked.connect(lambda points, ev: print(f\"clicked points {points}\\t event: {ev[0].pos()}\")) # \\t pos: {ev.pos()}, scenePos: {ev.scenePos()}\n",
    "\n",
    "# @define()\n",
    "# class ScatterEventHandler(QObject):\n",
    "\t\n",
    "\n",
    "# lastClicked, clickedPen, (main_scatter_hovered_connection, main_scatter_clicked_connection) = _helper_make_scatterplot_clickable(plots.scatter_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d18d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate testing data with only 1 neuron active during the period to see where it is sorted.\n",
    "\n",
    "# Add neuron IDs to each of the callout placefields for a given time bin. Could also color them by the neuron ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d4092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 2023-06-27 10:42: - [ ] Desperitely need a class that \"explodes\" the important variables and their types out of a DynamicParameters (dict-like) or other object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_n = plot_kourosh_activity_style_figure(long_results_obj, long_session, EITHER_subset.track_exclusive_aclus, epoch_idx=49, callout_epoch_IDXs=np.arange(6), skip_rendering_callouts=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a7c05d1",
   "metadata": {},
   "source": [
    "# Figure 2) Firing Rate Bar Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cf1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from neuropy.core.neuron_identities import PlotStringBrevityModeEnum\n",
    "from neuropy.plotting.ratemaps import BackgroundRenderingOptions\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots\n",
    "\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# mpl.rcParams['toolbar'] = 'None' # disable toolbars\n",
    "%matplotlib qt\n",
    "\n",
    "# Instantaneous versions:\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from PendingNotebookCode import PaperFigureTwo\n",
    "\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # 10ms\n",
    "_out_fig_2.compute(curr_active_pipeline=curr_active_pipeline)\n",
    "_out_fig_2.display()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d7b230c",
   "metadata": {},
   "source": [
    "# Figure 3) `PAPER_FIGURE_figure_3`: Firing Rate Index and Long/Short Firing Rate Replays v. Laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6008da8",
   "metadata": {
    "tags": [
     "figure_3",
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "_out, _out2 = PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd3546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out2.figures\n",
    "_out.axes\n",
    "_out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd17dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = _out.figures\n",
    "fig\n",
    "\n",
    "\n",
    "# Computed long ($L$)|short($S$) firing rate indicies\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e08475",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_text = \"Computed track_replay|track_laps firing rate\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(fig)  # Set the specified figure as the current one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f93139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Computed track_replay|track_laps firing rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e723612",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e403366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'kdiba/gor01/one/2006-6-08_14-26-15/long_short_firing_rate_indicies/display_long_short_laps'\n",
    "\n",
    "formatted_text = (\n",
    "    \"<size:10>kdiba/gor01/one/<weight:bold>2006-6-08_14-26-15</>/long_short_firing_rate_indicies/display_long_short_laps\\n\"\n",
    "    \"<size:18>the values for the \"\n",
    "    \"<color:royalblue, weight:bold>blues</> and the <color:crimson, weight:bold>reds</></></>\"\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fb3785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexitext import flexitext ## flexitext version\n",
    "\n",
    "# Add flexitext\n",
    "text = (\n",
    "    \"<size:24>A <weight:bold>great chart</> showing\\n\"\n",
    "    \"<size:18>the values for the \"\n",
    "    \"<color:royalblue, weight:bold>blues</> and the <color:crimson, weight:bold>reds</></></>\"\n",
    ")\n",
    "flexitext(0.025, 0.8, text, va=\"bottom\", xycoords=\"figure fraction\")\n",
    "# fig.sca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae50d706",
   "metadata": {},
   "source": [
    "# 2023-06-27 - Test how many can actually be sorted by active_set criteria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175d19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First filter by only those user-included replays (in the future this won't be done)\n",
    "\n",
    "from PendingNotebookCode import TrackAssignmentDecision, TrackAssignmentState, AssigningEpochs\n",
    "\n",
    "## Initialize to unassigned\n",
    "assigning_epochs_obj.filter_epochs_df['track_assignment'] = TrackAssignmentDecision(TrackAssignmentState.UNASSIGNED, 0.0)\n",
    "assigning_epochs_obj.debug_print_assignment_statuses()\n",
    "assigning_epochs_obj.plot_epoch_track_assignments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dfc06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Partition based on whether the user included the epoch in the long or short track in the user-included epochs:\n",
    "is_user_exclusive_L = np.logical_and(assigning_epochs_obj.unassigned_epochs_df['long_is_user_included'], np.logical_not(assigning_epochs_obj.unassigned_epochs_df['short_is_user_included']))\n",
    "is_user_exclusive_S = np.logical_and(assigning_epochs_obj.unassigned_epochs_df['short_is_user_included'], np.logical_not(assigning_epochs_obj.unassigned_epochs_df['long_is_user_included']))\n",
    "is_user_unassigned_in_both_epochs = np.logical_and(np.logical_not(assigning_epochs_obj.unassigned_epochs_df['short_is_user_included']), np.logical_not(assigning_epochs_obj.unassigned_epochs_df['long_is_user_included'])) # the user said it was bad in both epochs, so assign it to neither with high confidence\n",
    "\n",
    "# NOTE: be sure to assign to the filter_epochs_df, not the unassigned_epochs_df, because the unassigned_epochs_df is a subset of the filter_epochs_df, and we want to assign to the filter_epochs_df so that the unassigned_epochs_df will be a subset of the filter_epochs_df:\n",
    "# assign the user_exclusive_L to long_track:\n",
    "assigning_epochs_obj.filter_epochs_df.loc[is_user_exclusive_L, 'track_assignment'] = TrackAssignmentDecision(TrackAssignmentState.LONG_TRACK, 1.0)\n",
    "# assign the user_exclusive_S to short_track:\n",
    "assigning_epochs_obj.filter_epochs_df.loc[is_user_exclusive_S, 'track_assignment'] = TrackAssignmentDecision(TrackAssignmentState.SHORT_TRACK, 1.0)\n",
    "# assign the user_unassigned_in_both_epochs to neither:\n",
    "assigning_epochs_obj.filter_epochs_df.loc[is_user_unassigned_in_both_epochs, 'track_assignment'] = TrackAssignmentDecision(TrackAssignmentState.NEITHER, 1.0)\n",
    "\n",
    "# assigning_epochs_obj.filter_epochs_df[is_user_exclusive_S]\n",
    "# assigning_epochs_obj.filter_epochs_df[is_user_exclusive_L]\n",
    "assigning_epochs_obj.debug_print_assignment_statuses()\n",
    "assigning_epochs_obj.plot_epoch_track_assignments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d177275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter based on the active_set cells (LxC, SxC):\n",
    "assigning_epochs_obj.unassigned_epochs_df.loc[np.logical_and(assigning_epochs_obj.unassigned_epochs_df['has_LONG_exclusive_aclu'], np.logical_not(assigning_epochs_obj.unassigned_epochs_df['has_SHORT_exclusive_aclu'])), 'track_assignment'] = TrackAssignmentDecision(TrackAssignmentState.LONG_TRACK, 1.0)\n",
    "assigning_epochs_obj.debug_print_assignment_statuses()\n",
    "# assign the user_exclusive_S to short_track:\n",
    "assigning_epochs_obj.unassigned_epochs_df.loc[np.logical_and(np.logical_not(assigning_epochs_obj.unassigned_epochs_df['has_LONG_exclusive_aclu']), assigning_epochs_obj.unassigned_epochs_df['has_SHORT_exclusive_aclu']), 'track_assignment'] = TrackAssignmentDecision(TrackAssignmentState.SHORT_TRACK, 1.0)\n",
    "assigning_epochs_obj.debug_print_assignment_statuses()\n",
    "assigning_epochs_obj.plot_epoch_track_assignments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d50f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Assess whether interneurons separate the active set as well:\n",
    "\n",
    "jonathan_firing_rate_analysis_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d9fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "assigning_epochs_obj.plot_epoch_track_assignments()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22399cfb",
   "metadata": {},
   "source": [
    "# 2023-06-27 - Other"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fe80559",
   "metadata": {},
   "source": [
    "# 2023-04-13 - Find Good looking epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9a519",
   "metadata": {
    "tags": [
     "ACTIVE_NOW"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import LeaveOneOutDecodingAnalysisResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dfa486",
   "metadata": {
    "tags": [
     "decoded_epochs",
     "figure_1"
    ]
   },
   "outputs": [],
   "source": [
    "_out_pagination_controller_L = DecodedEpochSlicesPaginatedFigureController.init_from_decoder_data(long_results_obj.active_filter_epochs, long_results_obj.all_included_filter_epochs_decoder_result, included_epoch_indicies=good_epoch_indicies_L, \n",
    "\txbin=long_results_obj.original_1D_decoder.xbin, global_pos_df=global_session.position.df, a_name='Long SubsetEpochs', active_context=long_epoch_context,  max_subplots_per_page=200) # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8054d5e",
   "metadata": {
    "tags": [
     "figure_1",
     "decoded_epochs"
    ]
   },
   "outputs": [],
   "source": [
    "_out_pagination_controller_S = DecodedEpochSlicesPaginatedFigureController.init_from_decoder_data(short_results_obj.active_filter_epochs, short_results_obj.all_included_filter_epochs_decoder_result, included_epoch_indicies=good_epoch_indicies_S, \n",
    "\txbin=short_results_obj.original_1D_decoder.xbin, global_pos_df=global_session.position.df, a_name='Short SubsetEpochs', active_context=short_epoch_context,  max_subplots_per_page=200) # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5280cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting selections out of DecoedEpochSlicesPaginationController\n",
    "curr_active_pipeline.display_output_history_list\n",
    "# Ideally could search like: '_display_long_and_short_stacked_epoch_slices'\n",
    "active_result_backup = curr_active_pipeline.last_added_display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f7829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(active_result_backup.keys()) # ['name', 'context', 'figures', 'axes', 'plot_data']\n",
    "\n",
    "active_result_backup['context'] # (IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-08_14-26-15', 'DecodedEpochSlices', 'replays', 'long_results_obj')>,\n",
    "\t\t\t\t\t\t\t\t#  IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-08_14-26-15', 'DecodedEpochSlices', 'replays', 'short_results_obj')>)\n",
    "\n",
    "pagination_controllers = active_result_backup.plot_data['controllers']\n",
    "long_controller = pagination_controllers[0]\n",
    "short_controller = pagination_controllers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e85d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_controller.selected_indicies # np.array([ 13,  14,  15,  25,  27,  28,  31,  37,  42,  45,  48,  57,  61,  62,  63,  76,  79,  82,  89,  90, 111, 112, 113, 115])\n",
    "\n",
    "# np.array([5,  13,  15,  17,  20,  21,  24,  31,  33,  43,  44,  49,  63, 64,  66,  68,  70,  71,  74,  76,  77,  78,  84,  90,  94,  95, 104, 105, 122, 123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_controller.selected_indicies # np.array([  9,  11,  13,  14,  15,  20,  22,  25,  37,  40,  45,  48,  61, 62,  76,  79,  84,  89,  90,  93,  94, 111, 112, 113, 115, 121])\n",
    "\n",
    "# np.array([ 12,  13,  15,  17,  20,  24,  30,  31,  32,  33,  41,  43,  49, 54,  55,  68,  70,  71,  73,  76,  77,  78,  84,  89,  94, 100, 104, 105, 111, 114, 115, 117, 118, 122, 123, 131])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5bcc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_context_L = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj')\n",
    "final_context_S = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj')\n",
    "# _out_pagination_controller.params.active_identifying_figure_ctx.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_L = final_context_L.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_S = final_context_S.adding_context(None,  user_annotation=\"selections\")\n",
    "\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='long_results_obj',user_annotation='selections')\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='short_results_obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd249e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the `long_results_obj.active_filter_epochs` and `short_results_obj.active_filter_epochs` objects with the selection information\n",
    "assert long_controller.is_selected.shape[0] == long_results_obj.active_filter_epochs.n_epochs\n",
    "assert short_controller.is_selected.shape[0] == short_results_obj.active_filter_epochs.n_epochs\n",
    "# for some reason the active_filter_epochs on both the long and the short objects contain properties about the other one as well, so keep with tradition and add them to both as well\n",
    "long_results_obj.active_filter_epochs._df['long_is_user_included'] = long_controller.is_selected\n",
    "long_results_obj.active_filter_epochs._df['short_is_user_included'] = short_controller.is_selected\n",
    "short_results_obj.active_filter_epochs._df['long_is_user_included'] = long_controller.is_selected\n",
    "short_results_obj.active_filter_epochs._df['short_is_user_included'] = short_controller.is_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636184b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(long_controller.params.keys())) # ['name', 'window_title', 'num_slices', '_debug_test_max_num_slices', 'active_num_slices', 'global_epoch_start_t', 'global_epoch_end_t', 'single_plot_fixed_height', 'all_plots_height', 'epoch_labels', 'variable_name', 'xbin', 'enable_flat_line_drawing', 'debug_print', 'active_identifying_figure_ctx', 'flat_all_data_indicies', 'is_selected', 'callback_id', 'on_render_page_callbacks']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eacd1d90",
   "metadata": {},
   "source": [
    "# TODO 2023-06-19 14:31: - [ ] Come up with system for storing user-annotations:\n",
    " Need to store user-annotations and labeled selections for Epochs:\n",
    "\n",
    "\tdate_annotated: datetime - the date the annotations were made\n",
    "\tannotation_author: str - the person who made the annotations\n",
    "\tannotation_content: Any - the content of the annotation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf36a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PendingNotebookCode import UserAnnotationsManager\n",
    "\n",
    "# Get the manual user annotations to determine the good replays for both long/short decoding:\n",
    "user_annotations = UserAnnotationsManager.get_user_annotations()\n",
    "\n",
    "final_context_L = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj')\n",
    "final_context_S = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj')\n",
    "# _out_pagination_controller.params.active_identifying_figure_ctx.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_L = final_context_L.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_S = final_context_S.adding_context(None,  user_annotation=\"selections\")\n",
    "\n",
    "## try to get the user annotations for this session:\n",
    "selection_idxs_L = user_annotations[selections_context_L]\n",
    "selection_idxs_S = user_annotations[selections_context_S]\n",
    "\n",
    "selection_idxs_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e794a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_idxs_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f58d5",
   "metadata": {
    "tags": [
     "LEGACY"
    ]
   },
   "outputs": [],
   "source": [
    "# For updating the controller from the selected indicies:\n",
    "for a_selected_index in selection_idxs_L:\n",
    "\t_out_pagination_controller.params.is_selected[a_selected_index] = True\n",
    "\n",
    "_out_pagination_controller.perform_update_selections(defer_render=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0409e08",
   "metadata": {},
   "source": [
    "# Other Programmatic Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe831b56",
   "metadata": {
    "tags": [
     "ACTIVE"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "\n",
    "## Builds proper sort indicies for '_display_short_long_pf1D_comparison'\n",
    "long_ratemap = long_pf1D.ratemap\n",
    "short_ratemap = short_pf1D.ratemap\n",
    "\n",
    "curr_any_context_neurons = _find_any_context_neurons(*[k.neuron_ids for k in [long_ratemap, short_ratemap]])\n",
    "curr_any_context_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402834bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.plotting.ratemaps import plot_ratemap_1D\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_short_v_long_pf1D_comparison, LongShortTrackComparingDisplayFunctions\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "long_single_cell_pfmap_processing_fn = None\n",
    "short_single_cell_pfmap_processing_fn = None\n",
    "# sort_idx = None\n",
    "# sort_idx = sort_ind\n",
    "# sort_idx = sort_indicies\n",
    "# sort_idx = new_all_aclus_sort_indicies\n",
    "sort_idx = 'peak_long'\n",
    "# sort_idx = 'bad'\n",
    "\n",
    "# out = curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_identifying_session_ctx, single_figure=False, debug_print=True, fignum='Short v Long pf1D Comparison',\n",
    "#                                    long_kwargs={'included_unit_neuron_IDs': curr_any_context_neurons, 'included_unit_indicies': None, 'sortby': sort_idx, 'single_cell_pfmap_processing_fn': long_single_cell_pfmap_processing_fn},\n",
    "#                                    short_kwargs={'included_unit_neuron_IDs': curr_any_context_neurons, 'included_unit_indicies': None,'sortby': sort_idx, 'single_cell_pfmap_processing_fn': short_single_cell_pfmap_processing_fn, 'curve_hatch_style': {'hatch':'///', 'edgecolor':'k'}},\n",
    "#                                   )\n",
    "\n",
    "out = curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_identifying_session_ctx, single_figure=False, debug_print=False, fignum='Short v Long pf1D Comparison',\n",
    "                                   long_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': long_single_cell_pfmap_processing_fn},\n",
    "                                   short_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': short_single_cell_pfmap_processing_fn, 'curve_hatch_style': {'hatch':'///', 'edgecolor':'k'}},\n",
    "                                  )\n",
    "                                  \n",
    "\n",
    "# ax = out.axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5653100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_short_long_pf1D_comparison', single_figure=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1906e5a",
   "metadata": {},
   "source": [
    "# 2023-06-01 - Testing new metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3fb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "## Extract variables from results object:\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result['Flat_epoch_time_bins_mean'], expected_v_observed_result['Flat_decoder_time_bin_centers'], expected_v_observed_result['num_neurons'], expected_v_observed_result['num_timebins_in_epoch'], expected_v_observed_result['num_total_flat_timebins'], expected_v_observed_result['is_short_track_epoch'], expected_v_observed_result['is_long_track_epoch'], expected_v_observed_result['short_short_diff'], expected_v_observed_result['long_long_diff']\n",
    "\n",
    "print(f'long_test: {np.mean(long_long_diff)}')\n",
    "print(f'short_test: {np.mean(short_short_diff)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e65f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_results_obj.original_1D_decoder\n",
    "replay_result_df = deepcopy(long_results_obj.active_filter_epochs.to_dataframe())\n",
    "replay_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67e3b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_results_obj.active_filter_epochs.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59838cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at lap speed over time - doesn't look like there's a difference between the long and the short track speeds\n",
    "global_session.position.compute_higher_order_derivatives()\n",
    "running_pos_df = global_session.position.to_dataframe()\n",
    "ax = running_pos_df.plot(x='t', y=['lin_pos','speed'], title='Running Speed over Time')\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627282a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "fig, ax = plot_lines(replay_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d92a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a36fd092",
   "metadata": {},
   "source": [
    "# 2023-06-29 - Test Cell Peak Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f84b582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_sorted_aclus: [ 87 102  68  34  54  74  86  51  92 109  63   5  83  24  96  69  93  49\n",
      "  15  26  32  14  31  33  55  76   3  25  50  82  10  78  90  64  61  75\n",
      "   8  85   2  41  73  53 100  89  16  59  88  56 108  66  60  98  37  28\n",
      "  19  36  62  57  11  21  23  70  58   4  81  52  67  13]\n",
      "_sorted_neuron_IDXs: [ 85 100  66  32  52  72  84  49  90 107  61   3  81  22  94  67  91  47\n",
      "  13  24  30  12  29  31  53  74   1  23  48  80   8  76  88  62  59  73\n",
      "   6  83   0  39  71  51  98  87  14  57  86  54 106  64  58  96  35  26\n",
      "  17  34  60  55   9  19  21  68  56   2  79  50  65  11]\n",
      "new_all_aclus_sort_indicies: [56 65 43 21 30 47 55 27 60 67 39  3 53 14 62 44 61 25  9 16 19  8 18 20\n",
      " 31 49  1 15 26 52  5 50 59 40 37 48  4 54  0 24 46 29 64 58 10 35 57 32\n",
      " 66 41 36 63 23 17 11 22 38 33  6 12 13 45 34  2 51 28 42  7]\n"
     ]
    }
   ],
   "source": [
    "@define()\n",
    "class SortOrderer:\n",
    "\tall_ids: np.ndarray\n",
    "\tsort_idxs: np.ndarray\n",
    "\n",
    "\tdesired_sort_arr: np.ndarray\n",
    "\n",
    "\t@classmethod\n",
    "\tdef _subfn_sort_desired(cls, extant_arr, desired_sort_arr):\n",
    "\t\t\"\"\" \n",
    "\t\tWant to find the set of sort indicies that can be applied to `extant_arr` s.t.\n",
    "\t\t(`extant_arr[out_sort_idxs] == desired_sort_arr`)\n",
    "\t\t\n",
    "\t\tINEFFICIENT: O^n^2\n",
    "\t\t\n",
    "\t\tUsage:\n",
    "\t\t\n",
    "\t\t\tnew_all_aclus_sort_indicies = _sort_desired(active_2d_plot.neuron_ids, all_sorted_aclus)\n",
    "\t\t\tassert len(new_all_aclus_sort_indicies) == len(active_2d_plot.neuron_ids), f\"need to have one new_all_aclus_sort_indicies value for each neuron_id\"\n",
    "\t\t\tassert np.all(active_2d_plot.neuron_ids[new_all_aclus_sort_indicies] == all_sorted_aclus), f\"must sort \"\n",
    "\t\t\tnew_all_aclus_sort_indicies\n",
    "\t\t\"\"\"\n",
    "\t\tif not isinstance(desired_sort_arr, np.ndarray):\n",
    "\t\t\tdesired_sort_arr = np.array(desired_sort_arr)\n",
    "\t\t\t\n",
    "\t\tif not isinstance(extant_arr, np.ndarray):\n",
    "\t\t\textant_arr = np.array(extant_arr)\n",
    "\t\tmissing_aclu_indicies = np.isin(extant_arr, desired_sort_arr, invert=True)\n",
    "\t\tmissing_aclus = extant_arr[missing_aclu_indicies] # array([ 3,  4,  8, 13, 24, 34, 56, 87])\n",
    "\t\tif len(missing_aclus) > 0:\n",
    "\t\t\tprint(f'modifying `desired_sort_arr` to include missing aclus: {missing_aclus}')\n",
    "\t\t\tdesired_sort_arr = np.concatenate((desired_sort_arr, missing_aclus)) # the final desired output order of aclus. Want to compute the indicies that are required to sort an ordered array of indicies in this order\n",
    "\t\t\t## TODO: what about entries in `desired_sort_arr` that might be missing in `extant_arr`?? Hopefully never happens.\n",
    "\n",
    "\t\t# Calculate reverse missing aclus:\n",
    "\t\treverse_missing_aclu_indicies = np.isin(desired_sort_arr, extant_arr, invert=True)\n",
    "\t\treverse_missing_aclus = desired_sort_arr[reverse_missing_aclu_indicies] # `reverse_missing_aclus` these are the set of aclus that are unique to the desired_sort_arr and thus cannot be sorted.\n",
    "\n",
    "\n",
    "\t\tassert len(desired_sort_arr) == len(extant_arr), f\"need to have one `all_sorted_aclu` value for each neuron_id but len(desired_sort_arr): {len(desired_sort_arr)} and len(extant_arr): {len(extant_arr)}\"\n",
    "\t\t# sort_idxs = np.array([desired_sort_arr.tolist().index(v) for v in extant_arr])\n",
    "\t\tout_sort_idxs = np.array([extant_arr.tolist().index(v) for v in desired_sort_arr])\n",
    "\t\tassert len(out_sort_idxs) == len(extant_arr), f\"need to have one new_all_aclus_sort_indicies value for each neuron_id\"\n",
    "\t\tassert np.all(extant_arr[out_sort_idxs] == desired_sort_arr), f\"must sort: extant_arr[sort_idxs]: {extant_arr[out_sort_idxs]}\\n desired_sort_arr: {desired_sort_arr}\"\n",
    "\t\treturn out_sort_idxs, desired_sort_arr\n",
    "\n",
    "\n",
    "\n",
    "#### BEGIN FUNCTION BODY ###\n",
    "\n",
    "debug_print = True\n",
    "curr_any_context_neurons = EITHER_subset.track_exclusive_aclus.copy()\n",
    "## Sorts aclus using `neuron_replay_stats_df`'s columns (  neuron_replay_stats_df = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']['neuron_replay_stats_df'] -- this is produced by '_perform_jonathan_replay_firing_rate_analyses') :\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "neuron_replay_stats_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df.copy()\n",
    "_sorted_neuron_stats_df = neuron_replay_stats_df.sort_values(by=[\"long_pf_peak_x\", \"short_pf_peak_x\", 'neuron_IDX'], ascending=[True, True, True], inplace=False).copy() # also did test_df = neuron_replay_stats_df.sort_values(by=['long_pf_peak_x'], inplace=False, ascending=True).copy()\n",
    "_sorted_neuron_stats_df = _sorted_neuron_stats_df[np.isin(_sorted_neuron_stats_df.index, curr_any_context_neurons)] # clip to only those neurons included in `curr_any_context_neurons`\n",
    "_sorted_aclus = _sorted_neuron_stats_df.index.to_numpy()\n",
    "_sorted_neuron_IDXs = _sorted_neuron_stats_df.neuron_IDX.to_numpy()\n",
    "if debug_print:\n",
    "\tprint(f'_sorted_aclus: {_sorted_aclus}')\n",
    "\tprint(f'_sorted_neuron_IDXs: {_sorted_neuron_IDXs}')\n",
    "\n",
    "## Use this sort for the 'curr_any_context_neurons' sort order:\n",
    "new_all_aclus_sort_indicies, desired_sort_arr = SortOrderer._subfn_sort_desired(curr_any_context_neurons, _sorted_aclus)\n",
    "if debug_print:\n",
    "\tprint(f'new_all_aclus_sort_indicies: {new_all_aclus_sort_indicies}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06f96f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_out_sort_idxs, _test_desired_sort_arr = SortOrderer._subfn_sort_desired(EITHER_subset.track_exclusive_aclus.copy(), _sorted_aclus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43cff1f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "need to have one `all_sorted_aclu` value for each neuron_id but len(desired_sort_arr): 68 and len(extant_arr): 59",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _test_out_sort_idxs, _test_desired_sort_arr \u001b[39m=\u001b[39m SortOrderer\u001b[39m.\u001b[39;49m_subfn_sort_desired(long_pf1D\u001b[39m.\u001b[39;49mratemap\u001b[39m.\u001b[39;49mneuron_ids, _sorted_aclus)\n",
      "Cell \u001b[1;32mIn[26], line 40\u001b[0m, in \u001b[0;36mSortOrderer._subfn_sort_desired\u001b[1;34m(cls, extant_arr, desired_sort_arr)\u001b[0m\n\u001b[0;32m     36\u001b[0m reverse_missing_aclu_indicies \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misin(desired_sort_arr, extant_arr, invert\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m reverse_missing_aclus \u001b[39m=\u001b[39m desired_sort_arr[reverse_missing_aclu_indicies] \u001b[39m# `reverse_missing_aclus` these are the set of aclus that are unique to the desired_sort_arr and thus cannot be sorted.\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(desired_sort_arr) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(extant_arr), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mneed to have one `all_sorted_aclu` value for each neuron_id but len(desired_sort_arr): \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(desired_sort_arr)\u001b[39m}\u001b[39;00m\u001b[39m and len(extant_arr): \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(extant_arr)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[39m# sort_idxs = np.array([desired_sort_arr.tolist().index(v) for v in extant_arr])\u001b[39;00m\n\u001b[0;32m     42\u001b[0m out_sort_idxs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([extant_arr\u001b[39m.\u001b[39mtolist()\u001b[39m.\u001b[39mindex(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m desired_sort_arr])\n",
      "\u001b[1;31mAssertionError\u001b[0m: need to have one `all_sorted_aclu` value for each neuron_id but len(desired_sort_arr): 68 and len(extant_arr): 59"
     ]
    }
   ],
   "source": [
    "_test_out_sort_idxs, _test_desired_sort_arr = SortOrderer._subfn_sort_desired(long_pf1D.ratemap.neuron_ids, _sorted_aclus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "073d2446",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "need to have one `all_sorted_aclu` value for each neuron_id but len(desired_sort_arr): 68 and len(extant_arr): 59",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m curr_any_context_neurons \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m long_pf1D\u001b[39m.\u001b[39mratemap\u001b[39m.\u001b[39mneuron_ids \u001b[39mif\u001b[39;00m v \u001b[39min\u001b[39;00m EITHER_subset\u001b[39m.\u001b[39mtrack_exclusive_aclus]) \u001b[39m# constrain to `EITHER_subset.track_exclusive_aclus`\u001b[39;00m\n\u001b[0;32m      2\u001b[0m curr_any_context_neurons\u001b[39m.\u001b[39mshape\n\u001b[1;32m----> 3\u001b[0m _test_out_sort_idxs, _test_desired_sort_arr \u001b[39m=\u001b[39m SortOrderer\u001b[39m.\u001b[39;49m_subfn_sort_desired(curr_any_context_neurons, _sorted_aclus)\n",
      "Cell \u001b[1;32mIn[26], line 40\u001b[0m, in \u001b[0;36mSortOrderer._subfn_sort_desired\u001b[1;34m(cls, extant_arr, desired_sort_arr)\u001b[0m\n\u001b[0;32m     36\u001b[0m reverse_missing_aclu_indicies \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misin(desired_sort_arr, extant_arr, invert\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m reverse_missing_aclus \u001b[39m=\u001b[39m desired_sort_arr[reverse_missing_aclu_indicies] \u001b[39m# `reverse_missing_aclus` these are the set of aclus that are unique to the desired_sort_arr and thus cannot be sorted.\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(desired_sort_arr) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(extant_arr), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mneed to have one `all_sorted_aclu` value for each neuron_id but len(desired_sort_arr): \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(desired_sort_arr)\u001b[39m}\u001b[39;00m\u001b[39m and len(extant_arr): \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(extant_arr)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[39m# sort_idxs = np.array([desired_sort_arr.tolist().index(v) for v in extant_arr])\u001b[39;00m\n\u001b[0;32m     42\u001b[0m out_sort_idxs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([extant_arr\u001b[39m.\u001b[39mtolist()\u001b[39m.\u001b[39mindex(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m desired_sort_arr])\n",
      "\u001b[1;31mAssertionError\u001b[0m: need to have one `all_sorted_aclu` value for each neuron_id but len(desired_sort_arr): 68 and len(extant_arr): 59"
     ]
    }
   ],
   "source": [
    "curr_any_context_neurons = np.array([v for v in long_pf1D.ratemap.neuron_ids if v in EITHER_subset.track_exclusive_aclus]) # constrain to `EITHER_subset.track_exclusive_aclus`\n",
    "curr_any_context_neurons.shape\n",
    "_test_out_sort_idxs, _test_desired_sort_arr = SortOrderer._subfn_sort_desired(curr_any_context_neurons, _sorted_aclus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "925372a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sorted_aclus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e40ecd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_pf1D.ratemap.neuron_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1b918ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EITHER_subset.track_exclusive_aclus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6410c234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_out_sort_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aac231f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 87, 102,  68,  34,  54,  74,  86,  51,  92, 109,  63,   5,  83,\n",
       "        24,  96,  69,  93,  49,  15,  26,  32,  14,  31,  33,  55,  76,\n",
       "         3,  25,  50,  82,  10,  78,  90,  64,  61,  75,   8,  85,   2,\n",
       "        41,  73,  53, 100,  89,  16,  59,  88,  56, 108,  66,  60,  98,\n",
       "        37,  28,  19,  36,  62,  57,  11,  21,  23,  70,  58,   4,  81,\n",
       "        52,  67,  13], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EITHER_subset.track_exclusive_aclus[_test_out_sort_idxs]\n",
    "_sorted_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1da39de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_desired_sort_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c14487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 87, 102,  68,  34,  54,  74,  86,  51,  92, 109,  63,   5,  83,\n",
       "        24,  96,  69,  93,  49,  15,  26,  32,  14,  31,  33,  55,  76,\n",
       "         3,  25,  50,  82,  10,  78,  90,  64,  61,  75,   8,  85,   2,\n",
       "        41,  73,  53, 100,  89,  16,  59,  88,  56, 108,  66,  60,  98,\n",
       "        37,  28,  19,  36,  62,  57,  11,  21,  23,  70,  58,   4,  81,\n",
       "        52,  67,  13], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_sort_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "_sorted_neuron_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b334dd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ab0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a simple figure that shows the `long_pf_peak_x`` and `short_pf_peak_x` values for each neuron on a single plot. Plots a heatmap-style stack of the placefields for these cells, with a line overlayed for the peak position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0451cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_raster_plot # used in `plot_kourosh_activity_style_figure`\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomLinearRegionItem import CustomLinearRegionItem # used in `plot_kourosh_activity_style_figure`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c04ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epoch_p_x_given_n = results_obj.all_included_filter_epochs_decoder_result.p_x_given_n_list[epoch_idx] # all decoded posteriors for curent epoch\n",
    "    # active_epoch_p_x_given_n.shape # (63, 13)\n",
    "    epoch_posterior_win, epoch_posterior_img = visualize_heatmap_pyqtgraph(active_epoch_p_x_given_n, win=plots.epoch_posterior_plot, title=f\"Epoch[{epoch_idx}]\") # .T\n",
    "    # Apply the colormap\n",
    "    epoch_posterior_img.setLookupTable(lut)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
