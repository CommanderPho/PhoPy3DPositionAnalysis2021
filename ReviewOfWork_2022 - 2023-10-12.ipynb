{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ce022a",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "from attrs import define, field, fields, Factory\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field, custom_define\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin, HDF_Converter\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, CapturedException\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, fullwidth_path_widget, interactive_pipeline_files\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/home/halechr/FastData'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/home/halechr/cloud/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T16:05:43.785201Z",
     "start_time": "2023-07-29T16:05:34.880381100Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: /home/halechr/FastData/KDIBA/gor01/two/2006-6-07_16-40-19\n",
      "Loading loaded session pickle file results : /home/halechr/FastData/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl... WARN: SpikesAccessor._validate(...): renaming \"cell_type\" column to \"neuron_type\".\n",
      "WARN: SpikesAccessor._validate(...): renaming \"cell_type\" column to \"neuron_type\".\n",
      "WARN: SpikesAccessor._validate(...): renaming \"cell_type\" column to \"neuron_type\".\n",
      "WARN: SpikesAccessor._validate(...): renaming \"cell_type\" column to \"neuron_type\".\n",
      "WARN: SpikesAccessor._validate(...): renaming \"cell_type\" column to \"neuron_type\".\n",
      "WARN: SpikesAccessor._validate(...): renaming \"cell_type\" column to \"neuron_type\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:NeuropyPipeline.__setstate__(state=\"{'pipeline_name': 'kdiba_pipeline', 'session_data_type': 'kdiba', '_stage': DisplayPipelineStage(stage_name='kdiba_pipeline_input', identity=<PipelineStage.Displayed: 4>)}\")\n",
      "INFO:com.PhoHale.Spike3D.pipeline:select_filters(...) with: []\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing global computations...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:NeuropyPipeline.on_stage_changed(new_stage=\"PipelineStage.Displayed\")\n",
      "WARNING:com.PhoHale.Spike3D.pipeline:WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Loading pickled pipeline success: /home/halechr/FastData/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl.\n",
      "WARN: SpikesAccessor._validate(...): renaming \"cell_type\" column to \"neuron_type\".\n",
      "WARN: SpikesAccessor._validate(...): renaming \"cell_type\" column to \"neuron_type\".\n",
      "pipeline_needs_resave but skip_save_on_initial_load == True, so saving will be skipped entirely. Be sure to save manually if there are changes.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "Loading loaded session pickle file results : /home/halechr/FastData/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl... done.\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation, maze already computed.\n",
      "pf_dt_sequential_surprise, maze already computed.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses, maze already computed.\n",
      "long_short_fr_indicies_analyses, maze already computed.\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "\t done.\n",
      "long_short_post_decoding, maze already computed.\n",
      "long_short_endcap_analysis, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('jonathan_firing_rate_analysis', 'maze')].\n",
      "\n",
      "\n",
      "!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"\n",
      "\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895fd44bbbee4397acad3bf743374e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Box(children=(Label(value='session path:', layout=Layout(width='auto')), Label(value='/home/hal…"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pdb off\n",
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # DONE. Very good. Many good Pfs, many good replays.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # DONE, might be the BEST SESSION, good example session with lots of place cells, clean replays, and clear bar graphs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD, 2023-07-14, unsure why still.\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays!\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE, Added replay selections. Very \"jumpy\" between the starts and ends of the track.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # DONE, Added replay selections. A TON of putative replays in general, most bad, but some good.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # DONE, added replay selections. Very few (like 12) replays each.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3') # DONE, Good Pfs, no good epochs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') # DONE, okay replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # DONE, very few replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # DONE, one replay each (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # BAD, Good Pfs strangely despite horrible map, no good epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # DONE, good. Many good pfs, many good replays. Noticed very strange jumping off the track in the 3D behavior/spikes viewer. Is there something wrong with this session?\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE, good?, replays selected, few\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE, very few replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # DONE, replays selected, quite a few replays but few are very good.\n",
    "\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25')\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# # Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # Force write:\n",
    "# # saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=['pf_computation', 'pfdt_computation', \n",
    "                                                'firing_rate_trends',\n",
    "                                                # 'pf_dt_sequential_surprise', \n",
    "                                            #    'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                # 'position_decoding_two_step', \n",
    "                                            #    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                            #     'long_short_inst_spike_rate_groups',\n",
    "                                            #     'long_short_endcap_analysis'\n",
    "]\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        curr_active_pipeline.load_pickled_global_computation_results()\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "\n",
    "# 6m 1.1s\n",
    "# 12m 15.6s\n",
    "\n",
    "\n",
    "# try:\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated\n",
    "if was_updated:\n",
    "    try:\n",
    "        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "extended_computations_include_includelist=['pf_computation', 'pfdt_computation', 'firing_rate_trends',\n",
    "    'pf_dt_sequential_surprise',\n",
    "    #  'ratemap_peaks_prominence2d',\n",
    "    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "    # 'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis'\n",
    "] # do only specified\n",
    "\n",
    "\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=force_recompute_global, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# except Exception as e:\n",
    "#     exception_info = sys.exc_info()\n",
    "#     e = CapturedException(e, exception_info)\n",
    "#     print(f'second half threw: {e}')\n",
    "\n",
    "\n",
    "# 4m 5.2s for inst fr computations\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, fullwidth_path_widget, interactive_pipeline_files\n",
    "\n",
    "_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\n",
    "# display(_pipeline_jupyter_widget)\n",
    "_pipeline_jupyter_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b90aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if curr_active_pipeline.updated_since_last_pickle:\n",
    "\t_bak_saving_mode = saving_mode\n",
    "\n",
    "saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "try:\n",
    "\tcurr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "\tcurr_active_pipeline.save_global_computation_results()\n",
    "\n",
    "except Exception as e:\n",
    "\t## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "\texception_info = sys.exc_info()\n",
    "\te = CapturedException(e, exception_info)\n",
    "\tprint(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "finally:\n",
    "\tsaving_mode = _bak_saving_mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b647dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb9b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.neuron_identities import NeuronIdentityDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionTables\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import build_merged_neuron_firing_rate_indicies\n",
    "\n",
    "BATCH_DATE_TO_USE = '2023-10-10'\n",
    "curr_session_context = curr_active_pipeline.get_session_context()\n",
    "output_file_prefix = curr_session_context.get_description(separator=\"-\", include_property_names=False)\n",
    "# global_replays.filename = Path(f\"output/{output_file_prefix}_global_replays\").resolve()\n",
    "# print(f'global_replays.filename: {global_replays.filename}')\n",
    "# global_replays.to_neuroscope()\n",
    "\n",
    "# global_PBEs.filename = Path(f\"output/{output_file_prefix}_global_PBEs\").resolve()\n",
    "# print(f'global_PBEs.filename: {global_PBEs.filename}')\n",
    "# global_PBEs.to_neuroscope('PBE')\n",
    "\n",
    "joined_neruon_fri_df = build_merged_neuron_firing_rate_indicies(curr_active_pipeline, enable_display_intermediate_results=False)\n",
    "AcrossSessionTables.write_table_to_files(joined_neruon_fri_df, global_data_root_parent_path=global_data_root_parent_path, output_basename=f'{BATCH_DATE_TO_USE}_{output_file_prefix}_joined_neruon_fri_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de445956",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_neruon_fri_df = AcrossSessionTables.load_table_from_file(global_data_root_parent_path=global_data_root_parent_path, output_basename=f'{BATCH_DATE_TO_USE}_{output_file_prefix}_joined_neruon_fri_df')\n",
    "joined_neruon_fri_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc798052",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_man = curr_active_pipeline.get_output_manager()\n",
    "# out_man.get_figure_output_parent_path(\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c850782f",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87dc7ae9",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n"
     ]
    }
   ],
   "source": [
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global \n",
    "\n",
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name)) for an_epoch_name in [long_epoch_name, short_epoch_name]]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "## Get global `long_short_fr_indicies_analysis`:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n",
    "long_short_fr_indicies_df = long_short_fr_indicies_analysis_results['long_short_fr_indicies_df']\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result.Flat_epoch_time_bins_mean, expected_v_observed_result.Flat_decoder_time_bin_centers, expected_v_observed_result.num_neurons, expected_v_observed_result.num_timebins_in_epoch, expected_v_observed_result.num_total_flat_timebins, expected_v_observed_result.is_short_track_epoch, expected_v_observed_result.is_long_track_epoch, expected_v_observed_result.short_short_diff, expected_v_observed_result.long_long_diff\n",
    "\n",
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.05)\n",
    "\n",
    "## Update long_exclusive/short_exclusive properties with `long_short_fr_indicies_df`\n",
    "# long_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n",
    "# short_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n",
    "\n",
    "# inst_spike_rate_groups_result: InstantaneousSpikeRateGroupsComputation = curr_active_pipeline.global_computation_results.computed_data.long_short_inst_spike_rate_groups\n",
    "# custom_InstSpikeRateTrends_df = inst_spike_rate_groups_result.all_incl_endPlatforms_InstSpikeRateTrends_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f78f27b5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Relative Entropy/Surprise Results:\n",
    "active_extended_stats = global_results['extended_stats']\n",
    "active_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise'] # DynamicParameters\n",
    "historical_snapshots = active_relative_entropy_results['historical_snapshots']\n",
    "post_update_times: np.ndarray = active_relative_entropy_results['post_update_times'] # (4152,) = (n_post_update_times,)\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals: np.ndarray = active_relative_entropy_results['time_intervals']\n",
    "surprise_time_bin_duration = (post_update_times[2]-post_update_times[1])\n",
    "long_short_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "flat_relative_entropy_results: np.ndarray = active_relative_entropy_results['flat_relative_entropy_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_results: np.ndarray = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_across_all_positions: np.ndarray = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "flat_surprise_across_all_positions: np.ndarray = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\n",
    "## Get the placefield dt matrix:\n",
    "if 'snapshot_occupancy_weighted_tuning_maps' not in active_relative_entropy_results:\n",
    "\t## Compute it if missing:\n",
    "\toccupancy_weighted_tuning_maps_over_time = np.stack([placefield_snapshot.occupancy_weighted_tuning_maps_matrix for placefield_snapshot in historical_snapshots.values()])\n",
    "\tactive_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] = occupancy_weighted_tuning_maps_over_time\n",
    "else:\n",
    "\toccupancy_weighted_tuning_maps_over_time = active_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] # (n_post_update_times, n_neurons, n_xbins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e5db7a",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a4a4645",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "## long_short_endcap_analysis: checks for cells localized to the endcaps that have their placefields truncated after shortening the track\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "# disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "# trivially_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "# significant_distant_remapping_endcap_aclus\n",
    "appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n",
    "# appearing_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_distant_remapping_endcap_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc520e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = curr_active_pipeline.sess\n",
    "sess.neurons.shank_ids[np.isin(sess.neuron_ids, significant_distant_remapping_endcap_aclus)]\n",
    "\n",
    "print(curr_active_pipeline.sess.get_context())\n",
    "# Context(format_name: 'kdiba', animal: 'gor01', exper_name: 'one', session_name: '2006-6-09_1-22-43')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_pf1D.neuron_extended_ids[np.isin(long_pf1D.included_neuron_IDs, significant_distant_remapping_endcap_aclus)]\n",
    "\n",
    "[v for v in long_pf1D.neuron_extended_ids if v.id in significant_distant_remapping_endcap_aclus]\n",
    "# long_pf1D.neuron_extended_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14947cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf1D.included_neuron_IDXs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145484f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_neruon_fri_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f01e2a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "override_sortby: peak_long is being used.\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEBUG: new_all_aclus_sort_indicies: [0 1]\n",
      "active_context: kdiba_gor01_two_2006-6-07_16-40-19_disappear_endcap\n",
      "\t saved /home/halechr/repos/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-10-12/kdiba/gor01/two/2006-6-07_16-40-19/disappear_endcap_display_short_long_pf1D_comparison.png\n",
      "override_sortby: peak_long is being used.\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEBUG: new_all_aclus_sort_indicies: [2 1 0 3 4]\n",
      "active_context: kdiba_gor01_two_2006-6-07_16-40-19_sig_remap_endcap\n",
      "\t saved /home/halechr/repos/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-10-12/kdiba/gor01/two/2006-6-07_16-40-19/sig_remap_endcap_display_short_long_pf1D_comparison.png\n",
      "override_sortby: peak_long is being used.\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEBUG: new_all_aclus_sort_indicies: [ 1  4 13  0 11 10  7  9 12  8  2  3  6  5]\n",
      "active_context: kdiba_gor01_two_2006-6-07_16-40-19_triv_remap_endcap\n",
      "\t saved /home/halechr/repos/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2023-10-12/kdiba/gor01/two/2006-6-07_16-40-19/triv_remap_endcap_display_short_long_pf1D_comparison.png\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_remapping_cells\n",
    "\n",
    "graphics_output_dict = fig_remapping_cells(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf122d95",
   "metadata": {},
   "source": [
    "## 2023-10-11 - Plot Peak Position on the Long Track vs. LapFRI to see where the remapping occurs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb95f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-11-10 - Adds \"LxC_PBEsDeltaMinus\" for PBEs \n",
    "\n",
    "\n",
    "temp = add_extra_spike_rate_trends(curr_active_pipeline)\n",
    "temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2f63af",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "## 2023-10-04 - Compare the decoded result of each replay epoch between the long/short decoder to determine which is better for that Epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "# neuron_replay_stats_df.reset_index()\n",
    "# neuron_replay_stats_df.index = neuron_replay_stats_df['aclu']\n",
    "\n",
    "a_long_decoder_result: DecodedFilterEpochsResult = long_results_obj.all_included_filter_epochs_decoder_result\n",
    "a_short_decoder_result: DecodedFilterEpochsResult = short_results_obj.all_included_filter_epochs_decoder_result\n",
    "\n",
    "\n",
    "# filter_epochs_decoder_result\n",
    "# curr_results_obj.active_filter_epochs, curr_results_obj.all_included_filter_epochs_decoder_result, xbin=curr_results_obj.original_1D_decoder.xbin\n",
    "\n",
    "\n",
    "# image_layer_dict = {}\n",
    "# layer_properties_dict = {\n",
    "# \t# 'snapshot_occupancy_weighted_tuning_maps': dict(blending='additive', colormap='viridis', name='pf1D_dt'),\n",
    "# #  'flat_jensen_shannon_distance_results': dict(blending='additive', colormap='gray'),\n",
    "# \t'long_p_x_given_n': dict(blending='additive', colormap='bop blue'),\n",
    "# \t'short_p_x_given_n': dict(blending='additive', colormap='red'),\n",
    "\t\n",
    "# }\n",
    "\n",
    "# for a_name, layer_properties in layer_properties_dict.items():\n",
    "# \t# image_layer_dict[a_name] = viewer.add_image(active_relative_entropy_results_xr_dict[a_name].to_numpy().astype(float), name=a_name)\n",
    "# \timage_layer_dict[a_name] = viewer.add_image(active_relative_entropy_results[a_name].astype(float), **(dict(name=a_name)|layer_properties))\n",
    "\n",
    "# assert viewer.dims.ndim == 3\n",
    "# ## Set the dimensions appropriately\n",
    "# viewer.dims.axis_labels = ('t', 'neuron_id', 'xbin')\n",
    "\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(1,1)\n",
    "for decoded_epoch_idx in np.arange(a_long_decoder_result.num_filter_epochs):\n",
    "\n",
    "\tif decoded_epoch_idx < 5:\n",
    "\t\t# decoded_epoch_idx:int = 0\n",
    "\t\tcurr_epoch_time_bin_container = a_long_decoder_result.time_bin_containers[decoded_epoch_idx]\n",
    "\t\tcurr_time_bins = curr_epoch_time_bin_container.centers\n",
    "\n",
    "\t\t## Long Decoding:\n",
    "\t\tcurr_long_epoch_p_x_given_n = a_long_decoder_result.p_x_given_n_list[decoded_epoch_idx] # .shape: (239, 5) - (n_x_bins, n_epoch_time_bins)\n",
    "\t\t## Need to exclude estimates from bins that didn't have any spikes in them (in general these glitch around):\n",
    "\t\t# curr_total_spike_counts_per_window = np.sum(a_decoder_result.spkcount[decoded_epoch_idx], axis=0) # left_out_decoder_result.spkcount[i].shape # (69, 222) - (nCells, nTimeWindowCenters)\n",
    "\t\t# curr_is_time_bin_non_firing = (curr_total_spike_counts_per_window == 0) # this would mean that no cells fired in this time bin\n",
    "\t\tcurr_long_most_likely_position_indicies = np.squeeze(a_long_decoder_result.most_likely_position_indicies_list[decoded_epoch_idx]) # (n_epoch_time_bins, ) one position for each time bin in the replay\n",
    "\t\t# curr_most_likely_positions = a_decoder_result.most_likely_positions_list[decoded_epoch_idx]\n",
    "\t\tcurr_long_most_likely_position_confidence = np.max(curr_long_epoch_p_x_given_n, axis=0) # (n_epoch_time_bins, )\n",
    "\n",
    "\n",
    "\t\t## Short Decoding:\n",
    "\t\tcurr_short_epoch_p_x_given_n = a_short_decoder_result.p_x_given_n_list[decoded_epoch_idx] # .shape: (239, 5) - (n_x_bins, n_epoch_time_bins)\n",
    "\t\t## Need to exclude estimates from bins that didn't have any spikes in them (in general these glitch around):\n",
    "\t\t# curr_total_spike_counts_per_window = np.sum(a_decoder_result.spkcount[decoded_epoch_idx], axis=0) # left_out_decoder_result.spkcount[i].shape # (69, 222) - (nCells, nTimeWindowCenters)\n",
    "\t\t# curr_is_time_bin_non_firing = (curr_total_spike_counts_per_window == 0) # this would mean that no cells fired in this time bin\n",
    "\t\tcurr_short_most_likely_position_indicies = np.squeeze(a_short_decoder_result.most_likely_position_indicies_list[decoded_epoch_idx]) # (n_epoch_time_bins, ) one position for each time bin in the replay\n",
    "\t\tcurr_short_most_likely_position_confidence = np.max(curr_short_epoch_p_x_given_n, axis=0) # (n_epoch_time_bins, )\n",
    "\n",
    "\t\t# _long_short_decoding_comparison_df = pd.DataFrame({'t': curr_time_bins,\n",
    "\t\t# \t'x_bin_long': curr_long_most_likely_position_indicies, 'x_bin_long_confidence': curr_long_most_likely_position_confidence,\n",
    "\t\t# \t'x_bin_short': curr_short_most_likely_position_indicies, 'x_bin_short_confidence': curr_short_most_likely_position_confidence}) # , 'x': curr_most_likely_positions\n",
    "\n",
    "\t\tviewer.add_image(curr_long_epoch_p_x_given_n.astype(float), **(dict(name=f'long_p_x_given_n[{decoded_epoch_idx}]', blending='additive', colormap='red')))\n",
    "\t\tviewer.add_image(curr_short_epoch_p_x_given_n.astype(float), **(dict(name=f'short_p_x_given_n[{decoded_epoch_idx}]', blending='additive', colormap='bop blue')))\n",
    "\n",
    "\t# np.shape(curr_long_epoch_p_x_given_n)\n",
    "\t# _long_short_decoding_comparison_df.plot(y=['x_bin_long', 'x_bin_short'], color=['r','g'], ax=ax)\n",
    "\n",
    "# _long_short_decoding_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e173de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max([np.shape(a_long_decoder_result.p_x_given_n_list[decoded_epoch_idx]) for decoded_epoch_idx in np.arange(a_long_decoder_result.num_filter_epochs)], axis=0)\n",
    "# np.max([np.shape(a_short_decoder_result.p_x_given_n_list[decoded_epoch_idx]) for decoded_epoch_idx in np.arange(a_short_decoder_result.num_filter_epochs)], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de2edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_long_decoder_result.p_x_given_n_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_decoder_result.p_x_given_n_list[decoded_epoch_idx]\n",
    "# a_decoder_result.most_likely_position_indicies_list\n",
    "\n",
    "\n",
    "# curr_most_likely_positions\n",
    "\n",
    "_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c62e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_time_bins.shape\n",
    "curr_most_likely_positions.shape\n",
    "curr_most_likely_position_indicies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoder_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd9f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for decoded_epoch_idx in np.arange(a_decoder_result.num_filter_epochs):\n",
    "\tcurr_epoch_time_bin_container = a_decoder_result.time_bin_containers[decoded_epoch_idx]\n",
    "\tcurr_cell_decoded_epoch_time_bins.append(curr_epoch_time_bin_container)\n",
    "\tcurr_time_bins = curr_epoch_time_bin_container.centers\n",
    "\tcurr_epoch_p_x_given_n = a_decoder_result.p_x_given_n_list[decoded_epoch_idx] # .shape: (239, 5) - (n_x_bins, n_epoch_time_bins)\n",
    "\tassert curr_epoch_p_x_given_n.shape[0] == curr_cell_pf_curve.shape[0]\n",
    "\t\n",
    "\t## Need to exclude estimates from bins that didn't have any spikes in them (in general these glitch around):\n",
    "\tcurr_total_spike_counts_per_window = np.sum(a_decoder_result.spkcount[decoded_epoch_idx], axis=0) # left_out_decoder_result.spkcount[i].shape # (69, 222) - (nCells, nTimeWindowCenters)\n",
    "\tcurr_is_time_bin_non_firing = (curr_total_spike_counts_per_window == 0) # this would mean that no cells fired in this time bin\n",
    "\tcurr_most_likely_position_indicies = a_decoder_result.most_likely_position_indicies_list[decoded_epoch_idx] # (n_epoch_time_bins, ) one position for each time bin in the replay\n",
    "\t\n",
    "\t# From the firing map of the placefields for this neuron (`decoder_1D.F.T[left_out_neuron_IDX]`) get the value for each position bin index in the epoch\n",
    "\tcurr_epoch_expected_fr = np.squeeze(a_decoder_1D.F.T[left_out_neuron_IDX][curr_most_likely_position_indicies])\n",
    "\t# expected_num_spikes = curr_epoch_expected_fr * decoder_result.decoding_time_bin_size\n",
    "\n",
    "\t# Eqn 1:\n",
    "\t# p_n_given_x = lambda n: (1.0/factorial(n)) * pow(expected_num_spikes, n) * np.exp(-expected_num_spikes) # likelihood function\n",
    "\t\n",
    "\tall_cells_decoded_expected_firing_rates[left_out_aclu].append(curr_epoch_expected_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2fbcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049bf938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.neuron_identities import NeuronIdentityDataframeAccessor\n",
    "\n",
    "neuron_replay_stats_df = neuron_replay_stats_df.neuron_identity.make_neuron_indexed_df_global(curr_active_pipeline.get_session_context(), add_expanded_session_context_keys=False, add_extended_aclu_identity_columns=False)\n",
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29710ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df.neuron_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88beb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager, SessionCellExclusivityRecord\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "\n",
    "\n",
    "\n",
    "# for a_ctx, a_val in annotation_man.get_hardcoded_specific_session_override_dict().items():\n",
    "# \tannotation_man.annotations[a_ctx] = a_val\n",
    "\n",
    "# for a_ctx, a_val in UserAnnotationsManager.get_user_annotations().items():\n",
    "# \tannotation_man.annotations[a_ctx] = a_val\n",
    "\n",
    "# for a_ctx, a_val in session_cell_exclusivity_annotations.items():\n",
    "# \t# Not ideal. Adds a key 'session_cell_exclusivity' to the extant session context instead of being indexable by an entirely new context\n",
    "# \tannotation_man.annotations[a_ctx] = annotation_man.annotations.get(a_ctx, {}) | dict(session_cell_exclusivity=a_val)\n",
    "# \t# annotation_man.annotations[a_ctx.overwriting_context(user_annotation='session_cell_exclusivity')] = a_val\n",
    "\n",
    "annotation_man = UserAnnotationsManager()\n",
    "session_cell_exclusivity: SessionCellExclusivityRecord = annotation_man.annotations[curr_active_pipeline.get_session_context()].get('session_cell_exclusivity', None)\n",
    "session_cell_exclusivity.LxC\n",
    "session_cell_exclusivity.SxC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0f270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-10-03 - My metric comes from the number of laps with an active long place vs. number of laps with an active short place\n",
    "# curr_active_pipeline.sess.laps\n",
    "# active_long_spikes_df = active_spikes_df[active_spikes_df.is_included_long_pf1D]\n",
    "# active_short_spikes_df = active_spikes_df[active_spikes_df.is_included_short_pf1D]\n",
    "\n",
    "# active_spikes_df: pd.DataFrame = long_session.spikes_df.copy()\n",
    "active_spikes_df: pd.DataFrame = global_session.spikes_df.copy()\n",
    "# active_spikes_df[active_spikes_df['lap'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb48f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.neuron_identities import NeuronExtendedIdentityTuple, NeuronType\n",
    "\n",
    "\n",
    "def pho_long_short_exclusivity_index(active_spikes_df: pd.DataFrame) -> pd.DataFrame:\n",
    "\t\"\"\" 2023-10-03 - Long/Short Exclusivity Metric based off of Pho's intuition. Looks at the total number of spikes over laps. Pletny of room for improvement. \n",
    "\n",
    "\t\"\"\"\n",
    "\t# active_spikes_df['neuron_type'] = active_spikes_df.map(\n",
    "\n",
    "\t# Drop rows with missing data in columns: 'lin_pos', 't' and 8 other columns\n",
    "\tactive_spikes_df = active_spikes_df.dropna(subset=['lin_pos', 't', 't_seconds', 't_rel_seconds', 'x', 'y', 'aclu', 'maze_id', 'lap', 'maze_relative_lap'])\n",
    "\t# Filter rows based on columns: 'lap', 'maze_id'\n",
    "\tactive_spikes_df = active_spikes_df[(active_spikes_df['lap'] != -1) & (active_spikes_df['maze_id'] != -1)]\n",
    "\n",
    "\t# Convert the 'neuron_type' column of the dataframe to the categorical type if needed\n",
    "\tcat_type = NeuronType.get_pandas_categories_type()\n",
    "\tif active_spikes_df[\"neuron_type\"].dtype != cat_type:\n",
    "\t\t# If this type check ever becomes a problem and we want a more liberal constraint, All instances of CategoricalDtype compare equal to the string 'category'.\n",
    "\t\tactive_spikes_df[\"neuron_type\"] = active_spikes_df[\"neuron_type\"].apply(lambda x: x.hdfcodingClassName).astype(cat_type) # NeuronType can't seem to be cast directly to the new categorical type, it results in the column being filled with NaNs. Instead cast to string first.\n",
    "\n",
    "\tactive_spikes_df = active_spikes_df.astype({'maze_id': 'category', 'lap': 'category', 'maze_relative_lap': 'category', 'aclu': 'category'})\n",
    "\t# display(active_spikes_df)\n",
    "\n",
    "\t# Performed 5 aggregations grouped on columns: 'aclu', 'maze_id', 'lap'\n",
    "\tactive_spikes_df_agg = active_spikes_df.groupby(['aclu', 'maze_id', 'maze_relative_lap']).agg(t_count=('t', 'count'), lin_pos_mean=('lin_pos', 'mean'), lin_pos_std=('lin_pos', 'std'), lin_pos_min=('lin_pos', 'min'), lin_pos_max=('lin_pos', 'max')).reset_index()\n",
    "\n",
    "\tcurr_unique_aclus = active_spikes_df_agg['aclu'].unique()\n",
    "\tcurr_unique_maze_relative_laps = active_spikes_df_agg['maze_relative_lap'].unique()\n",
    "\tn_total_entries: int = len(active_spikes_df_agg['maze_relative_lap'].unique()) * len(active_spikes_df_agg['aclu'].unique())\n",
    "\n",
    "\t# Static lists of columns:\n",
    "\trelevant_columns_list = ['aclu', 'maze_relative_lap', 't_count', 'lin_pos_mean', 'lin_pos_std', 'lin_pos_min', 'lin_pos_max']\n",
    "\trelevant_index_column_names = ['aclu', 'maze_relative_lap']\n",
    "\tnumerical_column_names = ['t_count', 'lin_pos_mean', 'lin_pos_std', 'lin_pos_min', 'lin_pos_max']\n",
    "\n",
    "\tlong_maze_df = active_spikes_df_agg[active_spikes_df_agg['maze_id'] == 1][relevant_columns_list].reset_index()\n",
    "\tshort_maze_df = active_spikes_df_agg[active_spikes_df_agg['maze_id'] == 2][relevant_columns_list].reset_index() #.set_index(['aclu', 'maze_relative_lap'])\n",
    "\n",
    "\tn_laps = len(active_spikes_df_agg['maze_relative_lap'].unique())\n",
    "\tn_long_laps = len(long_maze_df['maze_relative_lap'].unique()) \n",
    "\tn_short_laps = len(short_maze_df['maze_relative_lap'].unique()) \n",
    "\n",
    "\tn_min_laps = min(n_long_laps, n_short_laps)\n",
    "\tsafe_lap_indicies = np.arange(n_min_laps) + 1\n",
    "\tif n_long_laps > n_min_laps:\n",
    "\t\t# truncate the long laps\n",
    "\t\tlong_maze_df = long_maze_df[np.isin(long_maze_df['maze_relative_lap'], safe_lap_indicies)]\n",
    "\tif n_short_laps > n_min_laps:\n",
    "\t\t# truncate the short laps\n",
    "\t\tshort_maze_df = short_maze_df[np.isin(short_maze_df['maze_relative_lap'], safe_lap_indicies)]\n",
    "\n",
    "\t## Compute the difference between the two\n",
    "\tlong_short_maze_diff_df = long_maze_df[numerical_column_names] - short_maze_df[numerical_column_names]\n",
    "\tlong_short_maze_diff_df[relevant_index_column_names] = long_maze_df[relevant_index_column_names].copy()\n",
    "\t# long_short_maze_diff_df = long_short_maze_diff_df.set_index(relevant_index_column_names)\n",
    "\tlong_short_maze_diff_df = long_short_maze_diff_df.groupby(['aclu']).agg(t_count_sum=('t_count', 'sum'), t_count_mean=('t_count', 'mean')).reset_index() # Aggregate across all columns to get a value for each 'aclu'\n",
    "\t# , t_count_max=('t_count', 'max')\n",
    "\t# long_short_maze_diff_df.set_index('aclu')\n",
    "\t# Sort by column: 't_count_sum' (ascending)\n",
    "\tlong_short_maze_diff_df = long_short_maze_diff_df.sort_values(['t_count_sum'], na_position='first')\n",
    "\treturn long_short_maze_diff_df\n",
    "\n",
    "\n",
    "active_spikes_df: pd.DataFrame = global_session.spikes_df.copy()\n",
    "long_short_maze_diff_df = pho_long_short_exclusivity_index(active_spikes_df=active_spikes_df)\n",
    "long_short_maze_diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b6acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import partition, safe_pandas_get_group\n",
    "from pyphocorehelpers.indexing_helpers import partition_df\n",
    "\n",
    "unique_aclu_values, aclu_group_dfs = partition_df(long_short_maze_diff_df, 'aclu')\n",
    "n_aclus = len(unique_aclu_values)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=n_aclus, ncols=1, sharex=True, sharey=False)\n",
    "\n",
    "for i, (aclu, aclu_df) in enumerate(zip(unique_aclu_values, aclu_group_dfs)):\n",
    "\taclu_df.plot(x='maze_relative_lap', y='t_count', label=f'{aclu}', ax=axes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_maze_diff_df = long_maze_df['t_count'].to_numpy() - short_maze_df['t_count'].to_numpy()\n",
    "long_short_maze_diff_df.set_index()\n",
    "long_short_maze_diff_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f086f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_spikes_df_agg.reindex([active_spikes_df_agg['aclu'].unique(), active_spikes_df_agg['maze_relative_lap'].unique()], fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import partition, safe_pandas_get_group\n",
    "\n",
    "unique_values, group_dfs = partition(active_spikes_df_agg, 'maze_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f06f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_values, group_dfs = partition(active_spikes_df_agg, 'maze_id')\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf8721",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values, group_dfs = partition(active_spikes_df, 'aclu')\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06339961",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df = group_dfs[unique_values[0]]\n",
    "# type(a_df)\n",
    "a_df.shape # (4320, 8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21e3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_spikes_df_agg[active_spikes_df_agg['maze_id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0bde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_spikes_df_agg['maze_id'].eq(1).astype(int).groupby(active_spikes_df_agg['aclu']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performed 2 aggregations grouped on columns: 'aclu', 'maze_id', 'lap'\n",
    "active_spikes_df = active_spikes_df.groupby(['aclu', 'maze_id', 'lap']).agg(flat_spike_idx_count=('flat_spike_idx', 'count'), lin_pos_var=('lin_pos', 'var')).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae5e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performed 5 aggregations grouped on columns: 'aclu', 'maze_id'\n",
    "active_spikes_df = active_spikes_df.groupby(['aclu', 'maze_id']).agg(t_count=('t', 'count'), lin_pos_mean=('lin_pos', 'mean'), lin_pos_std=('lin_pos', 'std'), lin_pos_min=('lin_pos', 'min'), lin_pos_max=('lin_pos', 'max')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ee8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "'maze_id'==1\n",
    "\n",
    "active_spikes_df[active_spikes_df['lap'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2340733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f47f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_laps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff2939c",
   "metadata": {},
   "source": [
    "# 2023-10-03 - Recompute `long_short_inst_spike_rate_groups`, fixing result for empty LxC/SxC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74aa3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce4dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if curr_active_pipeline.global_computation_results.computation_config is None:\n",
    "\tglobal_computation_results.computation_config = DynamicContainer(instantaneous_time_bin_size_seconds=0.01)\n",
    "else:\n",
    "\t# update the existing value\n",
    "\tcurr_active_pipeline.global_computation_results.computation_config.instantaneous_time_bin_size_seconds = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4f5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=['long_short_inst_spike_rate_groups'], include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=True, debug_print=False)\n",
    "newly_computed_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf4d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903acc7",
   "metadata": {},
   "source": [
    "## 2023-09-29 - Plot the LxC/SxC PhoJonathanPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots, BatchPhoJonathanFiguresHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5922fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## all cells, sorted by custom_frs_index:\n",
    "# fig_1c_figures_all_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df.sort_values('custom_frs_index', ascending=True, inplace=False), included_unit_neuron_IDs=None,\n",
    "# \tn_max_page_rows=20, write_vector_format=False, write_png=False,\n",
    "# \tshow_only_refined_cells=False, disable_top_row=True, split_by_short_long_shared=False)\n",
    "\n",
    "fig_1c_figures_all_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=None,\n",
    "\tn_max_page_rows=20, write_vector_format=False, write_png=True,\n",
    "\tshow_only_refined_cells=False, disable_top_row=False, split_by_short_long_shared=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba5b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1c_figures_out_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=long_exclusive.get_refined_track_exclusive_aclus(), n_max_page_rows=20, write_vector_format=False, write_png=True, show_only_refined_cells=True, disable_top_row=True)\n",
    "fig_1c_figures_out_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=short_exclusive.get_refined_track_exclusive_aclus(), n_max_page_rows=20, write_vector_format=False, write_png=True, show_only_refined_cells=True, disable_top_row=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac53d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1c_figures_out_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=save_figure, disable_top_row=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_1c_figures_out_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.get_refined_track_exclusive_aclus(), n_max_page_rows=20, write_vector_format=False, write_png=True, show_only_refined_cells=True, disable_top_row=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e290fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df.copy()\n",
    "\n",
    "np.sum(np.logical_xor(neuron_replay_stats_df['is_refined_LxC'], neuron_replay_stats_df['is_refined_SxC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941cc7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.logical_and(neuron_replay_stats_df['is_refined_LxC'], neuron_replay_stats_df['is_refined_SxC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460c6e5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# uses global's 'extended_stats' results for relative entropy (surprise) analyses:\n",
    "\n",
    "import tables as tb\n",
    "\n",
    "\n",
    "# {\n",
    "# 't': Tuple[float, float],\n",
    "# 'snapshots': Tuple[PlacefieldSnapshot, PlacefieldSnapshot],\n",
    "# 'relative_entropy_result_dict': {\n",
    "# \t\t'long_short_rel_entr_curve': np.array,\n",
    "# \t\t...\n",
    "# \t\t'jensen_shannon_distance': np.array,\n",
    "# \t} # 5 items\n",
    "# } # 3 items\n",
    "# Dict[float, PlacefieldSnapshot]\n",
    "\n",
    "def relative_entropy_to_h5(global_results, file_path='output/test_relative_entropy_numpy_arrays.h5'):\n",
    "\tprint(f'relative_entropy_to_h5(...)')\n",
    "\n",
    "\tactive_extended_stats = global_results['extended_stats']\n",
    "\tactive_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise'] # DynamicParameters\n",
    "\tpost_update_times: np.ndarray = active_relative_entropy_results['post_update_times'] # (4152,) = (n_post_update_times,)\n",
    "\tsnapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "\ttime_intervals: np.ndarray = active_relative_entropy_results['time_intervals']\n",
    "\tlong_short_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "\tshort_long_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "\tflat_relative_entropy_results: np.ndarray = active_relative_entropy_results['flat_relative_entropy_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "\tflat_jensen_shannon_distance_results: np.ndarray = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "\tflat_jensen_shannon_distance_across_all_positions: np.ndarray = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\tflat_surprise_across_all_positions: np.ndarray = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\t\n",
    "\t# Create an HDF5 file\n",
    "\twith tb.open_file(file_path, mode=\"w\") as hdf5_file:\n",
    "\t\tprint(f'trying to write to \"{file_path}\"...')\n",
    "\t\t# Create groups for organization\n",
    "\t\troot = hdf5_file.root\n",
    "\t\tgroup = hdf5_file.create_group(root, 'relative_entropy_results')\n",
    "\t\t\n",
    "\t\t# Store np.ndarrays in the HDF5 file\n",
    "\t\thdf5_file.create_array(group, 'post_update_times', post_update_times)\n",
    "\t\thdf5_file.create_array(group, 'time_intervals', time_intervals)\n",
    "\t\thdf5_file.create_array(group, 'long_short_rel_entr_curves_frames', long_short_rel_entr_curves_frames)\n",
    "\t\thdf5_file.create_array(group, 'short_long_rel_entr_curves_frames', short_long_rel_entr_curves_frames)\n",
    "\t\thdf5_file.create_array(group, 'flat_relative_entropy_results', flat_relative_entropy_results)\n",
    "\t\thdf5_file.create_array(group, 'flat_jensen_shannon_distance_results', flat_jensen_shannon_distance_results)\n",
    "\t\thdf5_file.create_array(group, 'flat_jensen_shannon_distance_across_all_positions', flat_jensen_shannon_distance_across_all_positions)\n",
    "\t\thdf5_file.create_array(group, 'flat_surprise_across_all_positions', flat_surprise_across_all_positions)\n",
    "\t\n",
    "\tprint(f'\\t done!')\n",
    "\t\n",
    "\n",
    "relative_entropy_to_h5(global_results, file_path='output/test_relative_entropy_numpy_arrays.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c6b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_differences_result_dict\n",
    "\n",
    "flat_jensen_shannon_distance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06537c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_relative_entropy_results\n",
    "# type(active_relative_entropy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd2f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "neuron_replay_stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d613474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test classifying various x-positions as belonging to outside the outside_maze, the track_endcaps, or the track_body\n",
    "from enum import Enum\n",
    "\n",
    "class TrackPositionClassification(Enum):\n",
    "    OUTSIDE_MAZE = \"outside_maze\"\n",
    "    TRACK_ENDCAPS = \"track_endcaps\"\n",
    "    TRACK_BODY = \"track_body\"\n",
    "\n",
    "\n",
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "short_pf_peak_x = neuron_replay_stats_df.short_pf_peak_x\n",
    "long_pf_peak_x = neuron_replay_stats_df.long_pf_peak_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b2a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_remapping_df[np.isin(rate_remapping_df.index, significant_distant_remapping_endcap_aclus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51571ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_spike_rate_groups_result: InstantaneousSpikeRateGroupsComputation = curr_active_pipeline.global_computation_results.computed_data.long_short_inst_spike_rate_groups\n",
    "# custom_InstSpikeRateTrends_df = inst_spike_rate_groups_result.all_incl_endPlatforms_InstSpikeRateTrends_df\n",
    "# if not hasattr(inst_spike_rate_groups_result, 'all_incl_endPlatforms_InstSpikeRateTrends_df'):\n",
    "# \tinst_spike_rate_groups_result.all_incl_endPlatforms_InstSpikeRateTrends_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c789f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2023-09-14 - Find cells outside the bounds of the short track\n",
    "# Modifies the `jonathan_firing_rate_analysis_result.neuron_replay_stats_df` in-place instead of creating a copy:\n",
    "# neuron_replay_stats_df = deepcopy(jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "# Extract the peaks of the long placefields to find ones that have peaks outside the boundaries\n",
    "# long_pf_peaks = neuron_replay_stats_df[neuron_replay_stats_df['has_long_pf']]['long_pf_peak_x'] - 150.0 # this shift of 150.0 is to center the midpoint of the track at 0. \n",
    "# # display(long_pf_peaks)\n",
    "# is_left_cap = (long_pf_peaks < -72.0)\n",
    "# is_right_cap = (long_pf_peaks > 72.0)\n",
    "# is_either_cap =  np.logical_or(is_left_cap, is_right_cap)\n",
    "\n",
    "# # Adds ['is_long_peak_left_cap', 'is_long_peak_right_cap', 'is_long_peak_either_cap'] columns: \n",
    "# neuron_replay_stats_df['is_long_peak_left_cap'] = False\n",
    "# neuron_replay_stats_df['is_long_peak_right_cap'] = False\n",
    "# neuron_replay_stats_df.loc[is_left_cap.index, 'is_long_peak_left_cap'] = is_left_cap # True\n",
    "# neuron_replay_stats_df.loc[is_right_cap.index, 'is_long_peak_right_cap'] = is_right_cap # True\n",
    "# neuron_replay_stats_df['is_long_peak_either_cap'] = np.logical_or(neuron_replay_stats_df['is_long_peak_left_cap'], neuron_replay_stats_df['is_long_peak_right_cap'])\n",
    "# adds ['LS_pf_peak_x_diff'] column\n",
    "# neuron_replay_stats_df['LS_pf_peak_x_diff'] = neuron_replay_stats_df['long_pf_peak_x'] - neuron_replay_stats_df['short_pf_peak_x']\n",
    "neuron_replay_stats_df.is_long_peak_either_cap\n",
    "\n",
    "## Extract just the endcap cells:\n",
    "cap_cells_df = neuron_replay_stats_df[np.logical_and(neuron_replay_stats_df['has_long_pf'], neuron_replay_stats_df['is_long_peak_either_cap'])]\n",
    "cap_aclus = cap_cells_df.index\n",
    "num_total_endcap_cells = len(cap_aclus)\n",
    "display(num_total_endcap_cells)\n",
    "\n",
    "# \"Disppearing\" cells fall below the 1Hz firing criteria on the short track:\n",
    "disappearing_endcap_cells_df = cap_cells_df[np.logical_not(cap_cells_df['has_short_pf'])]\n",
    "disappearing_endcap_aclus = disappearing_endcap_cells_df.index\n",
    "num_disappearing_endcap_cells = len(disappearing_endcap_aclus)\n",
    "print(f'num_disappearing_endcap_cells/num_total_endcap_cells: {num_disappearing_endcap_cells}/{num_total_endcap_cells}')\n",
    "\n",
    "non_disappearing_endcap_cells_df = cap_cells_df[cap_cells_df['has_short_pf']] # \"non_disappearing\" cells are those with a placefield on the short track as well\n",
    "num_non_disappearing_endcap_cells = len(non_disappearing_endcap_cells_df)\n",
    "print(f'num_non_disappearing_endcap_cells/num_total_endcap_cells: {num_non_disappearing_endcap_cells}/{num_total_endcap_cells}')\n",
    "\n",
    "# display(non_disappearing_endcap_cells_df)\n",
    "# non_disappearing_endcap_cells_df['LS_pf_peak_x_diff'] = non_disappearing_endcap_cells_df['long_pf_peak_x'] - non_disappearing_endcap_cells_df['short_pf_peak_x']\n",
    "# display(non_disappearing_endcap_cells_df)\n",
    "\n",
    "# Classify the non_disappearing cells into two groups:\n",
    "# 1. Those that exhibit significant remapping onto somewhere else on the track\n",
    "non_disappearing_endcap_cells_df['has_significant_distance_remapping'] = (np.abs(non_disappearing_endcap_cells_df['LS_pf_peak_x_diff']) >= 40.0) # The most a placefield could translate intwards would be (35 + (pf_width/2.0)) I think.\n",
    "num_significant_position_remappping_endcap_cells = len(non_disappearing_endcap_cells_df[non_disappearing_endcap_cells_df['has_significant_distance_remapping'] == True])\n",
    "print(f'num_significant_position_remappping_endcap_cells/num_non_disappearing_endcap_cells: {num_significant_position_remappping_endcap_cells}/{num_non_disappearing_endcap_cells}')\n",
    "\n",
    "# 2. Those that seem to remain where they were on the long track, perhaps being \"sampling-clipped\" or translated adjacent to the platform. These two subcases can be distinguished by a change in the placefield's length (truncated cells would be a fraction of the length, although might need to account for scaling with new track length)\n",
    "minorly_changed_endcap_cells_df = non_disappearing_endcap_cells_df[non_disappearing_endcap_cells_df['has_significant_distance_remapping'] == False]\n",
    "\n",
    "non_disappearing_endcap_cells_df\n",
    "# endcaps:\n",
    "significant_distant_remapping_endcap_aclus = non_disappearing_endcap_cells_df[non_disappearing_endcap_cells_df['has_significant_distance_remapping']].index.to_numpy() # Int64Index([3, 5, 7, 11, 14, 38, 41, 53, 57, 61, 62, 75, 78, 79, 82, 83, 85, 95, 98, 100, 102], dtype='int64')\n",
    "significant_distant_remapping_endcap_aclus\n",
    "minor_remapping_endcap_aclus = minorly_changed_endcap_cells_df.index.to_numpy()\n",
    "minor_remapping_endcap_aclus\n",
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_distant_remapping_endcap_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[np.isin(jonathan_firing_rate_analysis_result.neuron_replay_stats_df.index, significant_distant_remapping_endcap_aclus)]\n",
    "significant_distant_remapping_endcap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will these remapped cells be included in replays after the delta?\n",
    "num_short_replays = non_disappearing_endcap_cells_df['short_num_replays']\n",
    "short_replay_mean_fr_Hz = non_disappearing_endcap_cells_df['replay_diff']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb68efff",
   "metadata": {},
   "source": [
    "# 2023-10-11 - sanity check the Jensen-Shannon distance metric by computing for each placefield curve:\n",
    "As a sanity check, compute the Jensen-Shannon Distance between each of the distributions for the long/short curve. Expected to see that non-trivially remapping cells had a greater JS-distance than the others.\n",
    "### NO: It doesn't work, not even a little bit. Returns inf values for curves containing no infs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc7b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "# (epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "\n",
    "## long_short_endcap_analysis:\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11685400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_pf1D.ratemap.unsmoothed_tuning_maps.shape\n",
    "\n",
    "long_1DMaps = long_pf1D.get_by_id(trivially_remapping_endcap_aclus).ratemap.unsmoothed_tuning_maps # (15, 107)\n",
    "short_1DMaps = short_pf1D.get_by_id(trivially_remapping_endcap_aclus).ratemap.unsmoothed_tuning_maps # .shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: these results are NOT the same as the ones calculated in compute_snapshot_relative_entropy_surprise_differences.compute_surprise_relative_entropy_divergence, and I'm not quite sure why:\n",
    "# Jensen-Shannon distance is an average of KL divergence:\n",
    "\n",
    "from scipy.special import rel_entr\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "# 2023-10-11 - Earth mover's distance\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# def compute_surprise_relative_entropy_divergence(long_curve, short_curve):\n",
    "# \t\"\"\" Pre 2023-03-10 Refactoring:\n",
    "# \tGiven two tuning maps, computes the surprise (in terms of the KL-divergence a.k.a. relative entropy) between the two\n",
    "# \tReturns a dictionary containing the results in both directions\n",
    "\n",
    "# \tTODO 2023-03-08 02:41: - [ ] Convert naming convention from long_, short_ to lhs_, rhs_ to be general\n",
    "# \tTODO 2023-03-08 02:47: - [ ] Convert output dict to a dataclass\n",
    "\n",
    "# \tfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ExtendedStats import compute_surprise_relative_entropy_divergence\n",
    "\n",
    "# \t\"\"\"\n",
    "# \tlong_short_rel_entr_curve = rel_entr(long_curve, short_curve)\n",
    "# \tlong_short_relative_entropy = sum(long_short_rel_entr_curve) \n",
    "# \tshort_long_rel_entr_curve = rel_entr(short_curve, long_curve)\n",
    "# \tshort_long_relative_entropy = sum(short_long_rel_entr_curve)\n",
    "# \t# Jensen-Shannon distance is an average of KL divergence:\n",
    "# \tmixture_distribution = 0.5 * (long_curve + short_curve)\n",
    "# \tjensen_shannon_distance = 0.5 * (sum(rel_entr(mixture_distribution, long_curve)) + sum(rel_entr(mixture_distribution, short_curve))) # is this right? I'm confused by sum(...)\n",
    "\n",
    "# \treturn dict(long_short_rel_entr_curve=long_short_rel_entr_curve, long_short_relative_entropy=long_short_relative_entropy, short_long_rel_entr_curve=short_long_rel_entr_curve, short_long_relative_entropy=short_long_relative_entropy,\n",
    "# \t\t\tjensen_shannon_distance=jensen_shannon_distance)\n",
    "\n",
    "\n",
    "\n",
    "# def JS_Distance(long_short_rel_entr_curves_frames, short_long_rel_entr_curves_frames):\n",
    "# \t\"\"\" seems incorrect. Returns a vector of Inf values for JS-Distance\"\"\"\n",
    "# \tmixture_distribution = 0.5 * (long_short_rel_entr_curves_frames + short_long_rel_entr_curves_frames)\n",
    "# \tprint(f'mixture_distribution.shape: {np.shape(mixture_distribution)}') # (nSnapshots, n_neurons, n_xbins)\n",
    "# \t# jensen_shannon_distance = 0.5 * (sum(rel_entr(mixture_distribution, long_short_rel_entr_curves_frames)) + sum(rel_entr(mixture_distribution, short_long_rel_entr_curves_frames))) # is this right? I'm confused by sum(...) # (n_neurons, n_xbins)\n",
    "# \tjensen_shannon_distance = 0.5 * (np.sum(rel_entr(mixture_distribution, long_short_rel_entr_curves_frames), axis=1) + np.sum(rel_entr(mixture_distribution, short_long_rel_entr_curves_frames), axis=1)) # alt version: (nSnapshots, n_xbins)\n",
    "# \tprint(f'jensen_shannon_distance.shape: {np.shape(jensen_shannon_distance)}') # (n_neurons, n_xbins)\n",
    "# \treturn jensen_shannon_distance, mixture_distribution\n",
    "\n",
    "\n",
    "def earth_movers_distance(long_1DMaps, short_1DMaps):\n",
    "\tn_cells = np.shape(short_1DMaps)[0]\n",
    "\t# return np.array([cdist(np.atleast_2d(np.squeeze(long_1DMaps[i,:])), np.atleast_2d(np.squeeze(short_1DMaps[i,:])), 'jensenshannon')[0,0] for i in np.arange(n_cells)])\n",
    "\treturn np.array([wasserstein_distance(np.squeeze(long_1DMaps[i,:]), np.squeeze(short_1DMaps[i,:])) for i in np.arange(n_cells)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# i = 0\n",
    "# js_result_dict = compute_surprise_relative_entropy_divergence(np.squeeze(long_1DMaps[i,:]), np.squeeze(short_1DMaps[i,:]))\n",
    "# js_result_dict\n",
    "# js_result_dict['jensen_shannon_distance']\n",
    "# js_result_dict['long_short_rel_entr_curve']\n",
    "\n",
    "# jensen_shannon_distance, mixture_distribution = JS_Distance(long_1DMaps, short_1DMaps)\n",
    "# jensen_shannon_distance\n",
    "\n",
    "# earth_movers_distance = cdist(long_1DMaps, short_1DMaps, 'jensenshannon')\n",
    "\n",
    "# n_cells = np.shape(short_1DMaps)[0]\n",
    "# earth_movers_distance = np.array([cdist(np.atleast_2d(np.squeeze(long_1DMaps[i,:])), np.atleast_2d(np.squeeze(short_1DMaps[i,:])), 'jensenshannon')[0,0] for i in np.arange(n_cells)])\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e930baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# long_1DMaps = long_pf1D.get_by_id(trivially_remapping_endcap_aclus).ratemap.unsmoothed_tuning_maps # (15, 107)\n",
    "# short_1DMaps = short_pf1D.get_by_id(trivially_remapping_endcap_aclus).ratemap.unsmoothed_tuning_maps # .shape\n",
    "\n",
    "# appearing_earth_movers_distance = earth_movers_distance(long_pf1D.get_by_id(appearing_aclus).ratemap.unsmoothed_tuning_maps, short_pf1D.get_by_id(appearing_aclus).ratemap.unsmoothed_tuning_maps)\n",
    "\n",
    "# get_curve_fn = lambda x: x.unsmoothed_tuning_maps\n",
    "get_curve_fn = lambda x: x.unsmoothed_tuning_maps\n",
    "\n",
    "trivially_remapping_endcap_earth_movers_distance = earth_movers_distance(get_curve_fn(long_pf1D.get_by_id(trivially_remapping_endcap_aclus).ratemap), get_curve_fn(short_pf1D.get_by_id(trivially_remapping_endcap_aclus).ratemap))\n",
    "significant_distant_remapping_earth_movers_distance = earth_movers_distance(get_curve_fn(long_pf1D.get_by_id(significant_distant_remapping_endcap_aclus).ratemap), get_curve_fn(short_pf1D.get_by_id(significant_distant_remapping_endcap_aclus).ratemap))\n",
    "disappearing_endcap_earth_movers_distance = earth_movers_distance(get_curve_fn(long_pf1D.get_by_id(disappearing_endcap_aclus).ratemap), get_curve_fn(short_pf1D.get_by_id(disappearing_endcap_aclus).ratemap))\n",
    "\n",
    "\n",
    "# earth_movers_distance = cdist(np.atleast_2d(np.squeeze(long_1DMaps[i,:])), np.atleast_2d(np.squeeze(short_1DMaps[i,:])), 'jensenshannon')[0]\n",
    "# trivially_remapping_endcap_earth_movers_distance\n",
    "# earth_movers_distance.shape\n",
    "\n",
    "trivially_remapping_endcap_earth_movers_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c0aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_distant_remapping_earth_movers_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65765e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(trivially_remapping_endcap_earth_movers_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d139cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(significant_distant_remapping_earth_movers_distance)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcb50e6",
   "metadata": {},
   "source": [
    "## 2023-09-20 - Plot the significantly remapping cells using the lower-level `plot_short_v_long_pf1D_comparison` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ebc2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_short_v_long_pf1D_comparison\n",
    "from neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines, add_track_shapes\n",
    "from neuropy.plotting.ratemaps import plot_ratemap_1D\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import LongShortDisplayConfigManager\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "graphics_output_dict = {}\n",
    "active_context: IdentifyingContext = curr_active_pipeline.get_session_context()\n",
    "\n",
    "long_short_display_config_manager = LongShortDisplayConfigManager()\n",
    "long_epoch_config = long_short_display_config_manager.long_epoch_config.as_pyqtgraph_kwargs()\n",
    "short_epoch_config = long_short_display_config_manager.short_epoch_config.as_pyqtgraph_kwargs()\n",
    "\n",
    "long_epoch_matplotlib_config = long_short_display_config_manager.long_epoch_config.as_matplotlib_kwargs()\n",
    "short_epoch_matplotlib_config = long_short_display_config_manager.short_epoch_config.as_matplotlib_kwargs()\n",
    "\n",
    "shared_kwargs = dict(pad=1, cmap='hsv', active_context=curr_active_pipeline.get_session_context(), plot_zero_baselines=True, skip_figure_titles=True, use_flexitext_titles=True, flat_stack_mode=False)\n",
    "top_level_shared_kwargs = dict(should_plot_vertical_track_bounds_lines=True, sortby='peak_long')\n",
    "# top_level_shared_kwargs = dict(should_plot_vertical_track_bounds_lines=False, should_plot_linear_track_shapes=True) # Renders the linear track shape on the maze. Assumes `flat_stack_mode=True`\n",
    "\n",
    "\n",
    "# # flat_stack_mode: all placefields are stacked up (z-wise) on top of each other on a single axis with no offsets:\n",
    "# shared_kwargs = dict(pad=1, active_context=curr_active_pipeline.get_session_context(), plot_zero_baselines=True, skip_figure_titles=True, use_flexitext_titles=True, flat_stack_mode=True)\n",
    "# top_level_shared_kwargs = dict(should_plot_vertical_track_bounds_lines=False, should_plot_linear_track_shapes=True) # Renders the linear track shape on the maze. Assumes `flat_stack_mode=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec159e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-09-21 - Plot All\n",
    "graphics_output_dict = graphics_output_dict | fig_remapping_cells(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfab342",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle('Translation Remapping Cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_surprise_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a009cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.active_sess_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8231cfbe",
   "metadata": {},
   "source": [
    "## 2023-10-11 - Refined PBE results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c436b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_short_fr_indicies_analysis_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e177daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = curr_active_pipeline.sess\n",
    "global_session.replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e29fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_session.laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_session.pbe #.epochs.to_epoch_obj()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b767cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "owning_pipeline_reference = curr_active_pipeline\n",
    "\n",
    "non_running_periods = Epoch.from_PortionInterval(owning_pipeline_reference.sess.laps.as_epoch_obj().to_PortionInterval().complement())\n",
    "non_replay_periods: Epoch = Epoch(Epoch.from_PortionInterval(owning_pipeline_reference.sess.replay.epochs.to_PortionInterval().complement()).time_slice(t_start=long_epoch_obj.t_start, t_stop=short_epoch_obj.t_stop).to_dataframe()[:-1]) #[:-1] # any period except the replay ones, drop the infinite last entry\n",
    "\n",
    "\n",
    "# Split into long/short only periods:\n",
    "long_only_non_replay_periods: Epoch  = non_replay_periods.time_slice(t_start=long_epoch_obj.t_start, t_stop=long_epoch_obj.t_stop) # any period except the replay ones\n",
    "short_only_non_replay_periods: Epoch  = non_replay_periods.time_slice(t_start=short_epoch_obj.t_start, t_stop=short_epoch_obj.t_stop) # any period except the replay ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e9bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_running_periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffe8d9f",
   "metadata": {},
   "source": [
    "## pre 2023-10-11 - Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e11c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_example_nontopo_remap\n",
    "\n",
    "graphics_output_dict = fig_example_nontopo_remap(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "255ef3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_short_long_pf1D_scalar_overlap_comparison', active_identifying_session_ctx, save_figure=False)\n",
    "# fig, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['axs'], graphics_output_dict['plot_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e146d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _display_long_short_expected_v_observed_firing_rate\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_long_short_expected_v_observed_firing_rate', curr_active_pipeline.sess.get_context(), included_neuron_IDs=significant_distant_remapping_endcap_aclus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6bc6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_temp_force_recompute=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recompute 'long_short_fr_indicies_analyses'\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_computations\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "# _temp_force_recompute=True\n",
    "_temp_force_recompute=False\n",
    "# extended_computations_include_includelist = ['_perform_time_dependent_placefield_computation', 'long_short_fr_indicies_analyses', 'pf_dt_sequential_surprise', 'short_long_pf_overlap_analyses'] # do only specifiedl\n",
    "extended_computations_include_includelist = ['jonathan_firing_rate_analysis', 'short_long_pf_overlap_analyses']\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=_temp_force_recompute, debug_print=False)\n",
    "newly_computed_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed12881",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.rdf.rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab18fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.irdf.irdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a269239",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ce6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_long_short_fr_indicies_analysis_bak = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "\n",
    "curr_long_short_fr_indicies_analysis = curr_active_pipeline.global_computation_results.computed_data.pop('long_short_fr_indicies_analysis')\n",
    "\n",
    "print(list(curr_long_short_fr_indicies_analysis.keys())) # ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays', 'long_non_replays', 'short_non_replays', 'global_non_replays', 'long_mean_non_replays_frs', 'short_mean_non_replays_frs', 'long_mean_non_replays_all_frs', 'short_mean_non_replays_all_frs', 'non_replays_frs_index', 'long_mean_non_replays_all_inst_frs', 'short_mean_non_replays_all_inst_frs', 'non_replays_inst_frs_index', 'active_context']\n",
    "\n",
    "print_keys_if_possible('curr_long_short_fr_indicies_analysis', curr_long_short_fr_indicies_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6411650",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320f02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a621ba9",
   "metadata": {},
   "source": [
    "# 2023-09-12 - Assemble all neuron-level properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.neuron_identities import NeuronIdentityDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import build_merged_neuron_firing_rate_indicies\n",
    "\n",
    "joined_neruon_fri_df = build_merged_neuron_firing_rate_indicies(curr_active_pipeline, enable_display_intermediate_results=False)\n",
    "joined_neruon_fri_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_neruon_fri_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c78c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(joined_neruon_fri_df.columns)) # ['aclu', 'lsfria_laps_frs_index', 'lsfria_laps_inst_frs_index', 'lsfria_replays_frs_index', 'lsfria_replays_inst_frs_index', 'lsfria_non_replays_frs_index', 'lsfria_non_replays_inst_frs_index', 'jfra_long_pf_peak_x', 'jfra_has_long_pf', 'jfra_short_pf_peak_x', 'jfra_has_short_pf', 'jfra_has_na', 'jfra_track_membership', 'jfra_long_non_replay_mean', 'jfra_short_non_replay_mean', 'jfra_non_replay_diff', 'jfra_long_replay_mean', 'jfra_short_replay_mean', 'jfra_replay_diff', 'jfra_long_mean', 'jfra_short_mean', 'jfra_mean_diff', 'jfra_neuron_IDX', 'jfra_num_replays', 'jfra_long_num_replays', 'jfra_short_num_replays', 'jfra_neuron_type', 'lspd_laps', 'lspd_replays', 'lspd_skew', 'lspd_max_axis_distance_from_center', 'lspd_distance_from_center', 'lspd_has_considerable_remapping']\n",
    "\n",
    "recast_columns=['track_membership','neuron_type']\n",
    "\n",
    "drop_columns=['jfra_aclu']\n",
    "joined_neuron_fri_df.drop(columns=drop_columns)\n",
    "['aclu', 'laps_frs_index', 'replays_frs_index', 'non_replays_frs_index', 'long_pf_peak_x', 'has_long_pf', 'short_pf_peak_x', 'has_short_pf', 'has_na', 'track_membership', 'long_non_replay_mean', 'short_non_replay_mean', 'non_replay_diff', 'long_replay_mean', 'short_replay_mean', 'replay_diff', 'long_mean', 'short_mean', 'mean_diff', 'neuron_IDX', 'num_replays', 'long_num_replays', 'short_num_replays', 'neuron_type', 'jfra_aclu', 'custom_frs_index', 'is_rate_extrema', 'is_refined_exclusive', 'is_refined_LxC', 'is_refined_SxC', 'laps', 'replays', 'skew', 'max_axis_distance_from_center', 'distance_from_center', 'has_considerable_remapping', 'session_uid', 'neuron_uid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bd0afa",
   "metadata": {},
   "source": [
    "# Computing consolidated `long_short_fr_indicies_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be486bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'long_short_fr_indicies_analysis'\n",
    "curr_long_short_fr_indicies_analysis = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "_curr_aclus = list(curr_long_short_fr_indicies_analysis['laps_frs_index'].keys()) # extract one set of keys for the aclus\n",
    "_curr_frs_indicies_dict = {k:v.values() for k,v in curr_long_short_fr_indicies_analysis.items() if k in ['laps_frs_index', 'laps_inst_frs_index', 'replays_frs_index', 'replays_inst_frs_index', 'non_replays_frs_index', 'non_replays_inst_frs_index']} # extract the values\n",
    "long_short_fr_indicies_df = pd.DataFrame(_curr_frs_indicies_dict, index=_curr_aclus)\n",
    "long_short_fr_indicies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_fr_indicies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca0c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.perform_specific_computation('long_short_fr_indicies_analyses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc450f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62734a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = long_short_fr_indicies_df.plot.scatter(x='non_replays_inst_frs_index' , y='replays_inst_frs_index', title='Replays v. Non-replay Firing Rate Index Comparison')\n",
    "# long_short_fr_indicies_df.plot.scatter(x='laps_inst_frs_index' , y='replays_inst_frs_index', title='Replays v. Laps Firing Rate Index Comparison', ax=ax)\n",
    "\n",
    "ax = long_short_fr_indicies_df.plot.scatter(x='non_replays_frs_index' , y='replays_frs_index', title='Replays v. Non-replay Firing Rate Index Comparison')\n",
    "long_short_fr_indicies_df.plot.scatter(x='laps_frs_index' , y='replays_frs_index', title='Replays v. Laps Firing Rate Index Comparison', ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8f1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# scatter_matrix(long_short_fr_indicies_df, figsize=(10, 10))\n",
    "scatter_matrix(joined_neruon_fri_df, figsize=(10, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a9146",
   "metadata": {},
   "source": [
    "## Plots the RateRemappingFiringRateIndex Number Line Figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Extract rr_* variables from rate_remapping_df\n",
    "# rr_aclus = rate_remapping_df.index.values\n",
    "# rr_laps, rr_replays, rr_skew, rr_neuron_type = [rate_remapping_df[n].values for n in ['laps', 'replays', 'skew', 'neuron_type']]\n",
    "\n",
    "\n",
    "## Extract rr_* variables from joined_neruon_fri_df\n",
    "rr_aclus = joined_neruon_fri_df.index.values\n",
    "rr_laps, rr_replays, rr_skew, rr_neuron_type = [joined_neruon_fri_df[n].values for n in ['lspd_laps', 'lspd_replays', 'lspd_skew', 'jfra_neuron_type']]\n",
    "\n",
    "## Display:\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_rr_aclu\n",
    "n_debug_limit = 10\n",
    "fig, axs, sort_indicies = plot_rr_aclu([str(aclu) for aclu in rr_aclus[:n_debug_limit]], rr_laps=rr_laps[:n_debug_limit], rr_replays=rr_replays[:n_debug_limit], rr_neuron_types=rr_neuron_type[:n_debug_limit])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad336e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fri_index_dicts_list = [dict(x=rr_laps, marker=r'$\\theta$', markersize=10, color='black', label='rr_laps'),\n",
    "\tdict(x=rr_replays, marker='o', markersize=10, fillstyle='none', color='black', label='rr_replays'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc67e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Display Paginated multi-plot\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_rr_aclu\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import RateRemappingPaginatedFigureController\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context()\n",
    "_out_rr_pagination_controller = RateRemappingPaginatedFigureController.init_from_rr_data(rr_aclus, rr_laps, rr_replays, rr_neuron_type, max_subplots_per_page=30, a_name='TestRateRemappingPaginatedFigureController', active_context=active_identifying_session_ctx)\n",
    "a_paginator = _out_rr_pagination_controller.plots_data.paginator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6768b355",
   "metadata": {},
   "source": [
    "# 2023-09-28 - InstFrRate-based classification of LxC and SxC\n",
    "2023-09-28 10:39am: We looked at the results and determined that it was much worse than the placefield critiera I had previously. This analysis should be used as a secondary refinement for the existing placefield-based LxC/SxC exclusion critiera. It includes information about non-lap endcap activity that the other analysis omits. Can be used with a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the selected LxC/SxC cells cells on the PhoJonathan plots\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "refined_LxC_aclus = long_exclusive.get_refined_track_exclusive_aclus()\n",
    "print(f'refined_LxC_aclus: {refined_LxC_aclus}')\n",
    "if len(refined_LxC_aclus):\n",
    "\t_out_LxC = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', n_max_plot_rows=10, save_figure=False, included_unit_neuron_IDs=refined_LxC_aclus) # , included_unit_neuron_IDs=[4, 58]\n",
    "\n",
    "refined_SxC_aclus = short_exclusive.get_refined_track_exclusive_aclus()\n",
    "print(f'refined_SxC_aclus: {refined_SxC_aclus}')\n",
    "if len(refined_SxC_aclus):\n",
    "\t_out_SxC = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', n_max_plot_rows=10, save_figure=False, included_unit_neuron_IDs=refined_SxC_aclus) # , included_unit_neuron_IDs=[4, 58]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a08e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_df = pd.read_csv(Path(r'W:\\Data\\neuron_replay_stats_table_2023-09-29-GL.csv'))\n",
    "loaded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dbed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data_root_parent_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionTables\n",
    " \n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.load_all_combined_tables(override_output_parent_path=global_data_root_parent_path, output_path_suffix=f'_{BATCH_DATE_TO_USE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6aacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import _fr_index\n",
    "instantaneous_time_bin_size_seconds = 0.1\n",
    "owning_pipeline_reference = curr_active_pipeline\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(owning_pipeline_reference.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name)) for an_epoch_name in [long_epoch_name, short_epoch_name]]\n",
    "\n",
    "# non_running_periods = Epoch.from_PortionInterval(owning_pipeline_reference.sess.laps.as_epoch_obj().to_PortionInterval().complement())\n",
    "non_replay_periods: Epoch = Epoch(Epoch.from_PortionInterval(owning_pipeline_reference.sess.replay.epochs.to_PortionInterval().complement()).time_slice(t_start=long_epoch_obj.t_start, t_stop=short_epoch_obj.t_stop).to_dataframe()[:-1]) #[:-1] # any period except the replay ones, drop the infinite last entry\n",
    "long_only_non_replay_periods: Epoch  = non_replay_periods.time_slice(t_start=long_epoch_obj.t_start, t_stop=long_epoch_obj.t_stop) # any period except the replay ones\n",
    "short_only_non_replay_periods: Epoch  = non_replay_periods.time_slice(t_start=short_epoch_obj.t_start, t_stop=short_epoch_obj.t_stop) # any period except the replay ones\n",
    "\n",
    "# ~20sec computation\n",
    "long_custom_InstSpikeRateTrends: SpikeRateTrends = SpikeRateTrends.init_from_spikes_and_epochs(spikes_df=deepcopy(owning_pipeline_reference.sess.spikes_df),\n",
    "                                                                                        filter_epochs=long_only_non_replay_periods,\n",
    "                                                                                        #    included_neuron_ids=long_exclusive.track_exclusive_aclus,\n",
    "                                                                                        instantaneous_time_bin_size_seconds=instantaneous_time_bin_size_seconds)\n",
    "\n",
    "short_custom_InstSpikeRateTrends: SpikeRateTrends = SpikeRateTrends.init_from_spikes_and_epochs(spikes_df=deepcopy(owning_pipeline_reference.sess.spikes_df),\n",
    "                                                                                        filter_epochs=short_only_non_replay_periods,\n",
    "                                                                                        #    included_neuron_ids=long_exclusive.track_exclusive_aclus,\n",
    "                                                                                        instantaneous_time_bin_size_seconds=instantaneous_time_bin_size_seconds)\n",
    "\n",
    "# # Note custom_InstSpikeRateTrends is global, not really needed:\n",
    "# global_custom_InstSpikeRateTrends: SpikeRateTrends = SpikeRateTrends.init_from_spikes_and_epochs(spikes_df=deepcopy(owning_pipeline_reference.sess.spikes_df),\n",
    "#                                                                                            filter_epochs=non_replay_periods,\n",
    "#                                                                                         #    included_neuron_ids=long_exclusive.track_exclusive_aclus,\n",
    "#                                                                                            instantaneous_time_bin_size_seconds=instantaneous_time_bin_size_seconds)\n",
    "\n",
    "## Determine the included percentiles for `joined_neruon_fri_df`\n",
    "custom_InstSpikeRateTrends_df = pd.DataFrame({'aclu': long_custom_InstSpikeRateTrends.included_neuron_ids, 'long_inst_fr': long_custom_InstSpikeRateTrends.cell_agg_inst_fr_list, 'short_inst_fr': short_custom_InstSpikeRateTrends.cell_agg_inst_fr_list}) #\n",
    "# custom_InstSpikeRateTrends_df['global_inst_fr'] = global_custom_InstSpikeRateTrends.cell_agg_inst_fr_list\n",
    "\n",
    "# Compute the single-dimensional firing rate index for the custom epochs and add it as a column to the dataframe:\n",
    "custom_InstSpikeRateTrends_df['custom_frs_index'] = _fr_index(long_fr=long_custom_InstSpikeRateTrends.cell_agg_inst_fr_list, short_fr=short_custom_InstSpikeRateTrends.cell_agg_inst_fr_list)\n",
    "\n",
    "# # Calculate 10th and 90th percentiles\n",
    "# lower_bound = custom_InstSpikeRateTrends_df['custom_frs_index'].quantile(0.10)\n",
    "# upper_bound = custom_InstSpikeRateTrends_df['custom_frs_index'].quantile(0.90)\n",
    "\n",
    "# # Filter rows\n",
    "# bottom_10_percent = custom_InstSpikeRateTrends_df[custom_InstSpikeRateTrends_df['custom_frs_index'] <= lower_bound]\n",
    "# top_10_percent = custom_InstSpikeRateTrends_df[custom_InstSpikeRateTrends_df['custom_frs_index'] >= upper_bound]\n",
    "\n",
    "# # Extract the aclus from these rows:\n",
    "# LxC_10_percent_aclus = top_10_percent.aclu.to_numpy()\n",
    "# SxC_10_percent_aclus = bottom_10_percent.aclu.to_numpy()\n",
    "\n",
    "# print(f'LxC_10_percent_aclus: {LxC_10_percent_aclus}')\n",
    "# print(f'SxC_10_percent_aclus: {SxC_10_percent_aclus}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Really want to penalize for any firing on the opposite track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a867b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wanna look at the suprise metrics again please.\n",
    "\n",
    "# can align each of the sessions (across days) to the track transition point (the \"Delta\") as the zero.\n",
    "\n",
    "# print_keys_if_possible(\"global_computation_results\", curr_active_pipeline.global_computation_results, max_depth=2)\n",
    "\n",
    "# computed_data: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "# \t\t│   ├── jonathan_firing_rate_analysis: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "# \t\t│   ├── long_short_fr_indicies_analysis: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "# \t\t│   ├── long_short_leave_one_out_decoding_analysis: pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.LeaveOneOutDecodingAnalysis\n",
    "# \t\t│   ├── long_short_post_decoding: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "\n",
    "\n",
    "print_keys_if_possible(\"global_computation_results\", curr_active_pipeline.global_computation_results.computed_data, max_depth=3)\n",
    "\n",
    "# jonathan_firing_rate_analysis_result.rdf\n",
    "\n",
    "# long_short_leave_one_out_decoding_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d33a7c",
   "metadata": {
    "tags": [
     "NOW",
     "load",
     "plot"
    ]
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pyphocorehelpers.indexing_helpers import partition, safe_pandas_get_group\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor, AcrossSessionsVisualizations\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import SingleBarResult\n",
    "\n",
    "common_file_path = Path('output/active_across_session_scatter_plot_results.h5')\n",
    "print(f'common_file_path: {common_file_path}')\n",
    "\n",
    "# InstantaneousSpikeRateGroupsComputation, : pd.DataFrame\n",
    "_shell_obj, loaded_result_df = InstantaneousFiringRatesDataframeAccessor.load_and_prepare_for_plot(common_file_path)\n",
    "# Perform the actual plotting:\n",
    "AcrossSessionsVisualizations.across_sessions_bar_graphs(_shell_obj, num_sessions=13, save_figure=False, enable_tiny_point_labels=False, enable_hover_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624326b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Serialization of preprocessing parameters test\n",
    "file_path = 'output/preprocessing_parameters.h5'\n",
    "\n",
    "with h5py.File(file_path, \"w\") as f:\n",
    "\tpreprocessing_group = f.create_group(\"preprocessing_parameters\")\n",
    "\n",
    "\t# Serialize epoch_estimation_parameters\n",
    "\tepoch_estimation_group = preprocessing_group.create_group(\"epoch_estimation_parameters\")\n",
    "\n",
    "\tlaps_group = epoch_estimation_group.create_group(\"laps\")\n",
    "\tlaps_group.attrs[\"N\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"laps\"][\"N\"]\n",
    "\tlaps_group.attrs[\"should_backup_extant_laps_obj\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"laps\"][\"should_backup_extant_laps_obj\"]\n",
    "\n",
    "\tPBEs_group = epoch_estimation_group.create_group(\"PBEs\")\n",
    "\tPBEs_group.attrs[\"thresh\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"thresh\"]\n",
    "\tPBEs_group.attrs[\"min_dur\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"min_dur\"]\n",
    "\tPBEs_group.attrs[\"merge_dur\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"merge_dur\"]\n",
    "\tPBEs_group.attrs[\"max_dur\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"max_dur\"]\n",
    "\n",
    "\treplays_group = epoch_estimation_group.create_group(\"replays\")\n",
    "\treplay_data = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"replays\"]\n",
    "\t# replay_dataframe = pd.DataFrame(replay_data)\n",
    "\t# replay_data.to_hdf(f, \"/preprocessing_parameters/epoch_estimation_parameters/replays\")\n",
    "\t## TODO: add the data here using Epoch's .to_hdf\n",
    "\t\n",
    "\t# Check for \"None\" values before setting attributes\n",
    "\tdef check_and_set(key, value):\n",
    "\t\tif value is not None:\n",
    "\t\t\treplays_group.attrs[key] = value\n",
    "\n",
    "\t# Set attributes if not \"None\", otherwise skip writing\n",
    "\tcheck_and_set(\"min_epoch_included_duration\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"min_epoch_included_duration\"))\n",
    "\tcheck_and_set(\"max_epoch_included_duration\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"max_epoch_included_duration\"))\n",
    "\tcheck_and_set(\"maximum_speed_thresh\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"maximum_speed_thresh\"))\n",
    "\tcheck_and_set(\"min_inclusion_fr_active_thresh\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"min_inclusion_fr_active_thresh\"))\n",
    "\tcheck_and_set(\"min_num_unique_aclu_inclusions\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"min_num_unique_aclu_inclusions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc30a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_default_neptune_plots = False\n",
    "# enable_default_neptune_plots = True\n",
    "\n",
    "## To file only:\n",
    "with matplotlib_file_only():\n",
    "\t# Perform non-interactive Matplotlib operations with 'AGG' backend\n",
    "\tmain_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=enable_default_neptune_plots, save_figures_only=True, save_figure=True)\n",
    "\n",
    "## Clear the Programmatically open figures:\n",
    "plt.close('all') # this takes care of the matplotlib-backed figures.\n",
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44783dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_out_figures = main_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=False, save_figures_only=False, save_figure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943b8f18",
   "metadata": {},
   "source": [
    "# Common Display Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ef70fb2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": [
     "plot_cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67358/2087523286.py:3: MatplotlibDeprecationWarning: Auto-close()ing of figures upon backend switching is deprecated since 3.8 and will be removed two minor releases later.  To suppress this warning, explicitly call plt.close('all') first.\n",
      "  matplotlib.use('Qt5Agg')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "# configure backend here\n",
    "matplotlib.use('Qt5Agg')\n",
    "# backend_qt5agg\n",
    "# %matplotlib qt5\n",
    "# %matplotlib qt\n",
    "# matplotlib.use('AGG') # non-interactive backend ## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# mpl.rcParams['toolbar'] = 'None' # disable toolbars\n",
    "\n",
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0fbf214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "# configure backend here\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "import pylustrator # call `pylustrator.start()` before creating your first figure in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d8eddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b490781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot The laps:\n",
    "from neuropy.utils.matplotlib_helpers import plot_position_curves_figure\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "pylustrator.start()\n",
    "fig, out_axes_list = plot_laps_2d(global_session, legacy_plotting_mode=False, include_velocity=False, include_accel=False, figsize=(24, 10))\n",
    "out_axes_list[0].set_title('Estimated Laps')\n",
    "fig.canvas.manager.set_window_title('Estimated Laps')\n",
    "ax = out_axes_list[0]\n",
    "ax.set_xlim((1036.242685185441, 1441.769668184419))\n",
    "\n",
    "# Hide y-axis ticklabels\n",
    "plt.tick_params(axis='y', which='both', labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb32cee1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/halechr/repos/Spike3D/ReviewOfWork_2022 - 2023-10-12.ipynb Cell 143\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/halechr/repos/Spike3D/ReviewOfWork_2022%20-%202023-10-12.ipynb#Y310sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mgcf()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/halechr/repos/Spike3D/ReviewOfWork_2022%20-%202023-10-12.ipynb#Y310sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ax \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39;49maxes[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/halechr/repos/Spike3D/ReviewOfWork_2022%20-%202023-10-12.ipynb#Y310sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ax\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/halechr/repos/Spike3D/ReviewOfWork_2022%20-%202023-10-12.ipynb#Y310sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ax\u001b[39m.\u001b[39mget_xlim()\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "fig = plt.gcf()\n",
    "ax = fig.axes[0]\n",
    "ax\n",
    "ax.get_xlim()\n",
    "\n",
    "\n",
    "laps_example_region_xlims = (1036.242685185441, 1441.769668184419)\n",
    "\n",
    "fig, out_axes_list = plot_position_curves_figure(global_session.position, include_velocity=False, include_accel=False, figsize=(24, 10))\n",
    "\n",
    "_out1 = curr_active_pipeline.display('_display_long_short_laps', include_velocity=False, include_accel=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51c59882",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/halechr/repos/Spike3D/ReviewOfWork_2022 - 2023-10-12.ipynb Cell 144\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/halechr/repos/Spike3D/ReviewOfWork_2022%20-%202023-10-12.ipynb#Y311sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m curr_active_pipeline\u001b[39m.\u001b[39;49mplot\u001b[39m.\u001b[39;49m_display_decoder_result()\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Display.py:69\u001b[0m, in \u001b[0;36mPlot.__getattr__.<locals>.display_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(active_session_configuration_context, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     67\u001b[0m         \u001b[39m# if first arg is context, remove it from args:\u001b[39;00m\n\u001b[1;32m     68\u001b[0m         active_session_configuration_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline_reference\u001b[39m.\u001b[39mfiltered_contexts[active_session_configuration_context] \u001b[39m# if the passed argument is a string (like 'maze1'), find it in the filtered contexts dict\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipeline_reference\u001b[39m.\u001b[39;49mdisplay(display_function\u001b[39m=\u001b[39;49mk, active_session_configuration_context\u001b[39m=\u001b[39;49mactive_session_configuration_context, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Display.py:425\u001b[0m, in \u001b[0;36mPipelineWithDisplayPipelineStageMixin.display\u001b[0;34m(self, display_function, active_session_configuration_context, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[39mif\u001b[39;00m kwarg_active_config_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    423\u001b[0m         \u001b[39massert\u001b[39;00m kwarg_active_config_name \u001b[39m==\u001b[39m active_session_configuration_name \u001b[39m# they better be equal or else there is a conflict.\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     curr_display_output \u001b[39m=\u001b[39m display_function(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcomputation_results[active_session_configuration_name], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactive_configs[active_session_configuration_name], owning_pipeline\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, active_config_name\u001b[39m=\u001b[39;49mactive_session_configuration_name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    428\u001b[0m \u001b[39m## Build the final display context: \u001b[39;00m\n\u001b[1;32m    429\u001b[0m found_display_fcn_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregistered_display_functions\u001b[39m.\u001b[39mindex(display_function)\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/DisplayFunctions/DecoderPredictionError.py:60\u001b[0m, in \u001b[0;36mDefaultDecoderDisplayFunctions._display_decoder_result\u001b[0;34m(computation_result, active_config, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39m@function_attributes\u001b[39m(short_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdecoder_result\u001b[39m\u001b[39m'\u001b[39m, tags\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mdisplay\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39muntested\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mdecoder\u001b[39m\u001b[39m'\u001b[39m], input_requires\u001b[39m=\u001b[39m[], output_provides\u001b[39m=\u001b[39m[], uses\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mDecoderResultDisplayingPlot2D\u001b[39m\u001b[39m'\u001b[39m], creation_date\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m2023-03-23 15:49\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_display_decoder_result\u001b[39m(computation_result, active_config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 60\u001b[0m     renderer \u001b[39m=\u001b[39m DecoderResultDisplayingPlot2D(computation_result\u001b[39m.\u001b[39;49mcomputed_data[\u001b[39m'\u001b[39;49m\u001b[39mpf2D_Decoder\u001b[39;49m\u001b[39m'\u001b[39;49m], computation_result\u001b[39m.\u001b[39;49msess\u001b[39m.\u001b[39;49mposition\u001b[39m.\u001b[39;49mto_dataframe())\n\u001b[1;32m     61\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39manimate\u001b[39m(i):\n\u001b[1;32m     62\u001b[0m         \u001b[39m# print(f'animate({i})')\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[39mreturn\u001b[39;00m renderer\u001b[39m.\u001b[39mdisplay(i)\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/decoder_result.py:121\u001b[0m, in \u001b[0;36mDecoderResultDisplayingPlot2D.__init__\u001b[0;34m(self, decoder, position_df)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, decoder: BayesianPlacemapPositionDecoder, position_df):\n\u001b[1;32m    120\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_df \u001b[39m=\u001b[39m position_df\n\u001b[0;32m--> 121\u001b[0m     \u001b[39msuper\u001b[39;49m(DecoderResultDisplayingPlot2D, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(decoder)\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/decoder_result.py:56\u001b[0m, in \u001b[0;36mDecoderResultDisplayingBaseClass.__init__\u001b[0;34m(self, decoder)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39msuper\u001b[39m(DecoderResultDisplayingBaseClass, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     55\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder \u001b[39m=\u001b[39m decoder\n\u001b[0;32m---> 56\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup()\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/decoder_result.py:130\u001b[0m, in \u001b[0;36mDecoderResultDisplayingPlot2D.setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m# self.title_string = f'2D Decoded Positions'\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m# self.fig.suptitle(self.title_string)\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 130\u001b[0m active_window, active_p_x_given_n, active_most_likely_x_position, active_nearest_measured_position \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex) \u001b[39m# get the first item\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactive_im \u001b[39m=\u001b[39m DecoderResultDisplayingPlot2D\u001b[39m.\u001b[39mplot_single_decoder_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mxbin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mybin, active_p_x_given_n, drop_below_threshold\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, final_string_components\u001b[39m=\u001b[39m[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDecoder Result[i: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m}\u001b[39;00m\u001b[39m]: time window: \u001b[39m\u001b[39m{\u001b[39;00mactive_window\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m], ax\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxs)\n\u001b[1;32m    133\u001b[0m \u001b[39m# self.active_most_likely_pos = self.axs.plot([], [], lw=2) # how to use a plot(...)\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/decoder_result.py:154\u001b[0m, in \u001b[0;36mDecoderResultDisplayingPlot2D.get_data\u001b[0;34m(self, window_idx)\u001b[0m\n\u001b[1;32m    151\u001b[0m active_window \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mactive_time_windows[window_idx] \u001b[39m# a tuple with a start time and end time\u001b[39;00m\n\u001b[1;32m    152\u001b[0m active_p_x_given_n \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mp_x_given_n[:,:,window_idx]) \u001b[39m# same size as occupancy\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m active_most_likely_x_indicies \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder\u001b[39m.\u001b[39;49mmost_likely_position_indicies[:,window_idx]\n\u001b[1;32m    155\u001b[0m active_most_likely_x_position \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mxbin_centers[active_most_likely_x_indicies[\u001b[39m0\u001b[39m]], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mybin_centers[active_most_likely_x_indicies[\u001b[39m1\u001b[39m]])\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_df \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.plot._display_decoder_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737539d",
   "metadata": {},
   "source": [
    "# 2023-09-07 - Track Graphics Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a866b1b",
   "metadata": {
    "tags": [
     "ACTIVE",
     "track_graphics"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundsRect(xmin=22.397021260868584, xmax=245.3970212608686, ymin=133.66465594522782, ymax=155.97244934208123)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearTrackDimensions(track_width=0.1, track_length=170.0, platform_side_length=22.0, minor_axis_platform_side_width=0.25, alignment_axis='x', axis_scale_factors=ScaleFactors(major=1.0, minor=1.0))\n",
      "LinearTrackDimensions(track_width=0.1, track_length=100.0, platform_side_length=22.0, minor_axis_platform_side_width=0.25, alignment_axis='x', axis_scale_factors=ScaleFactors(major=1.0, minor=1.0))\n"
     ]
    }
   ],
   "source": [
    "from pyphocorehelpers.geometry_helpers import BoundsRect, point_tuple_mid_point, map_value\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines, add_track_shapes, test_LinearTrackDimensions_2D_pyqtgraph\n",
    "from neuropy.utils.mathutil import contiguous_regions, threshPeriods, compute_grid_bin_bounds, map_value\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import test_LinearTrackDimensions_2D_Matplotlib\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackInstance\n",
    "\n",
    "grid_bin_bounds = BoundsRect.init_from_grid_bin_bounds(global_pf2D.config.grid_bin_bounds)\n",
    "display(grid_bin_bounds)\n",
    "\n",
    "# long_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(grid_bin_bounds)\n",
    "# short_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(grid_bin_bounds)\n",
    "\n",
    "long_track_dims = LinearTrackDimensions(track_length=170.0)\n",
    "short_track_dims = LinearTrackDimensions(track_length=100.0)\n",
    "\n",
    "common_1D_platform_height = 0.25\n",
    "common_1D_track_height = 0.1\n",
    "long_track_dims.minor_axis_platform_side_width = common_1D_platform_height\n",
    "long_track_dims.track_width = common_1D_track_height # (short_track_dims.minor_axis_platform_side_width\n",
    "\n",
    "short_track_dims.minor_axis_platform_side_width = common_1D_platform_height\n",
    "short_track_dims.track_width = common_1D_track_height # (short_track_dims.minor_axis_platform_side_width\n",
    "\n",
    "# instances:\n",
    "long_track = LinearTrackInstance(long_track_dims, grid_bin_bounds=grid_bin_bounds)\n",
    "short_track = LinearTrackInstance(short_track_dims, grid_bin_bounds=grid_bin_bounds)\n",
    "\n",
    "print(long_track_dims)\n",
    "print(short_track_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c12b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "# global_pf1D_dt.config.grid_bin_bounds\n",
    "\n",
    "\n",
    "def napari_add_grid_bin_bounds_rect(viewer: napari.viewer.Viewer, grid_bin_bounds):\n",
    "\t\"\"\" adds the animal's position as a track and a point layer to the napari viewer.\n",
    "\n",
    "\n",
    "\tUsage:\n",
    "\n",
    "\tfrom pyphoplacecellanalysis.GUI.Napari.napari_helpers import napari_add_animal_position\n",
    "\tnapari_add_animal_position(viewer=viewer, position_df=global_pf1D_dt.all_time_filtered_pos_df[['t','x','binned_x']], time_intervals)\n",
    "\n",
    "\n",
    "\t\"\"\"\n",
    "\t# rect = np.array([[0, 0], [3, 1]])\n",
    "\tgrid_bin_bounds_rect = grid_bin_bounds\n",
    "\tviewer.add_shapes(grid_bin_bounds_rect, shape_type='grid_bin_bounds_rect', edge_width=0.1)\n",
    "    \n",
    "napari_add_grid_bin_bounds_rect(viewer, grid_bin_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b29b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For napari need to map onto xbins axis:\n",
    "#TODO: Not working, did manual rect drawing below instead.\n",
    "\n",
    "assert len(viewer.dims.range) == 3\n",
    "t_range_tuple, neuron_id_range_tuple, xbin_range_tuple = viewer.dims.range\n",
    "# ((0.0, 3309.0, 1.0),\n",
    "#  (-0.2906298631133275, 85.0, 1.0),\n",
    "#  (-0.24635407377607876, 108.0, 1.0))\n",
    "xbin_min, xbin_max = (xbin_range_tuple[0], (xbin_range_tuple[1]-xbin_range_tuple[2])) # the max range isn't included, so we need to subtract off the step to get the real max\n",
    "xbin_width = (xbin_max - xbin_min) # total width in number of xbins\n",
    "x_to_xbins_multiplier: float = xbin_width/grid_bin_bounds.size[0] # multiply a number in normal coordinates to get the equivalent number of xbins\n",
    "x_to_xbins_multiplier\n",
    "\n",
    "map_track_coords_to_xbins_space = lambda v: map_value(v, (grid_bin_bounds.xmin, grid_bin_bounds.xmax), (xbin_min, xbin_max)) # same map\n",
    "# map_track_coords_to_ybins_space = lambda v: map_value(v, (grid_bin_bounds.ymin, grid_bin_bounds.ymax), (ybin_min, ybin_max)) # same map\n",
    "\n",
    "bin_space_grid_bin_bounds = deepcopy(grid_bin_bounds)\n",
    "bin_space_grid_bin_bounds.xmin = map_track_coords_to_xbins_space(grid_bin_bounds.xmin)\n",
    "bin_space_grid_bin_bounds.xmax = map_track_coords_to_xbins_space(grid_bin_bounds.xmax)\n",
    "\n",
    "bin_space_grid_bin_bounds.ymin = 0.0\n",
    "bin_space_grid_bin_bounds.ymax = 5.0\n",
    "\n",
    "bin_space_grid_bin_bounds\n",
    "\n",
    "# map_track_coords_to_xbins_space(grid_bin_bounds.xmin), map_track_coords_to_xbins_space(grid_bin_bounds.xmax)\n",
    "# bin_space_long_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(bin_space_grid_bin_bounds)\n",
    "# bin_space_short_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(bin_space_grid_bin_bounds)\n",
    "\n",
    "# common_1D_platform_height = 0.25\n",
    "# common_1D_track_height = 0.1\n",
    "# bin_space_long_track_dims.minor_axis_platform_side_width = common_1D_platform_height\n",
    "# bin_space_long_track_dims.track_width = common_1D_track_height # (short_track_dims.minor_axis_platform_side_width\n",
    "\n",
    "# bin_space_short_track_dims.minor_axis_platform_side_width = common_1D_platform_height\n",
    "# bin_space_short_track_dims.track_width = common_1D_track_height # (short_track_dims.minor_axis_platform_side_width\n",
    "\n",
    "bin_space_long_track_dims = deepcopy(long_track_dims)\n",
    "bin_space_short_track_dims = deepcopy(short_track_dims)\n",
    "\n",
    "bin_space_long_track_dims.axis_scale_factors = (x_to_xbins_multiplier, 1.0)\n",
    "bin_space_short_track_dims.axis_scale_factors = (x_to_xbins_multiplier, 1.0)\n",
    "\n",
    "bin_space_long_track = LinearTrackInstance(bin_space_long_track_dims, grid_bin_bounds=bin_space_grid_bin_bounds)\n",
    "bin_space_short_track = LinearTrackInstance(bin_space_short_track_dims, grid_bin_bounds=bin_space_grid_bin_bounds)\n",
    "\n",
    "bin_space_short_track\n",
    "\n",
    "t_range_tuple, neuron_id_range_tuple, xbin_range_tuple = viewer.dims.range\n",
    "t_range_tuple\n",
    "\n",
    "\n",
    "bin_space_grid_bin_bounds\n",
    "half_xbin_width = float(xbin_width)/2.0\n",
    "half_xbin_width\n",
    "bin_space_short_track.track_dimensions.scaled_total_length\n",
    "# vertices are top-left and bottom-right corners\n",
    "# [(x, 0.0, w, h) for x, y, w, h, *_unused in bin_space_short_track.rects]\n",
    "# short_track_rectangle_data = [BoundsRect.init_from_x_y_w_h_tuple((x+np.abs(x), y, w, h)).corner_points for x, y, w, h, *_unused in bin_space_short_track.rects]\n",
    "short_track_rectangle_data = [np.hstack((np.zeros((4,1)), BoundsRect.init_from_x_y_w_h_tuple((x+half_xbin_width, y, w, h)).corner_points))[:, :][:, [0, 2, 1]] for x, y, w, h, *_unused in bin_space_short_track.rects]\n",
    "long_track_rectangle_data = np.vstack([np.hstack((np.zeros((4,1)), BoundsRect.init_from_x_y_w_h_tuple((x+half_xbin_width, y, w, h)).corner_points))[:, [0, 2, 1]] for x, y, w, h, *_unused in bin_space_long_track.rects])\n",
    "\n",
    "# short_track_rectangle_data = np.vstack(short_track_rectangle_data)\n",
    "short_track_rectangle_data\n",
    "\n",
    "# array([[0, 2.375, 35], # bottom-left\n",
    "    #    [0, 2.625, 35], # bottom-right\n",
    "    #    [0, 2.375, 46.112], # top-left\n",
    "    #    [0, 2.625, 46.112], # top-right\n",
    "\n",
    "# [0,2,3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb201f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# sync_point_y = -0.750314\n",
    "sync_point_y = 0.0 # the bottom (y-axis) value of the track\n",
    "track_platform_height_y = -5.19389 # the top coordinate (y-axis) value of the platforms\n",
    "\n",
    "## Time indicies for tracks:\n",
    "time_index = 0\n",
    "long_short_change_time_index = 2097 # APPROXIMATE\n",
    "t_range_tuple, neuron_id_range_tuple, xbin_range_tuple = viewer.dims.range\n",
    "long_time_indicies = np.arange(t_range_tuple[0], long_short_change_time_index)\n",
    "short_time_indicies = np.arange(long_short_change_time_index, (t_range_tuple[1]-t_range_tuple[2]))\n",
    "\n",
    "### Long Track Shape Layer:\n",
    "# Where the platform and the track connect:\n",
    "track_platform_connect_x_min = 14.157\n",
    "track_platform_connect_x_max = 91.6898\n",
    "long_track_shapes_data = list(itertools.chain.from_iterable([\n",
    "[\n",
    "np.array([[time_index, track_platform_height_y, track_platform_connect_x_max],\n",
    "        [time_index, track_platform_height_y, 106.093],\n",
    "        [time_index, sync_point_y, 106.093],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_max]]),\n",
    " np.array([[time_index, -3.66162, 14.0037],\n",
    "        [time_index, -3.66162, track_platform_connect_x_max],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_max],\n",
    "        [time_index, sync_point_y, 14.0037]]),\n",
    " np.array([[time_index, track_platform_height_y, -0.246354],\n",
    "        [time_index, track_platform_height_y, track_platform_connect_x_min],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_min],\n",
    "        [time_index, sync_point_y, -0.246354]])\n",
    "]\n",
    "for time_index in long_time_indicies]))\n",
    "long_track_shapes_layer = viewer.add_shapes(long_track_shapes_data, shape_type='rectangle', name='long_track', edge_width=0, face_color='#aa0000ff')\n",
    "long_track_shapes_layer.editable = False\n",
    "\n",
    "\n",
    "### Short Track Shape Layer:\n",
    "# Where the platform and the track connect:\n",
    "track_platform_connect_x_min = 28.2539\n",
    "track_platform_connect_x_max = 73.7623\n",
    "\n",
    "short_track_shapes_data =  list(itertools.chain.from_iterable([\n",
    "[\n",
    "np.array([[time_index, track_platform_height_y, track_platform_connect_x_max],\n",
    "        [time_index, track_platform_height_y, 88.1655],\n",
    "        [time_index, sync_point_y, 88.1655],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_max]]),\n",
    "np.array([[time_index, -3.66162, 28.1006],\n",
    "        [time_index, -3.66162, track_platform_connect_x_max],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_max],\n",
    "        [time_index, sync_point_y, 28.1006]]),\n",
    "np.array([[time_index, track_platform_height_y, 13.8505],\n",
    "        [time_index, track_platform_height_y, track_platform_connect_x_min],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_min],\n",
    "        [time_index, sync_point_y, 13.8505]])\n",
    "]\n",
    "for time_index in short_time_indicies]))\n",
    "\n",
    "short_track_shapes_layer = viewer.add_shapes(short_track_shapes_data, shape_type='rectangle', name='short_track', edge_width=0, face_color='royalblue')\n",
    "short_track_shapes_layer.editable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b12bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_shapes_layer.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc1240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_layer = viewer.layers['short_track_rectangle_data']\n",
    "shapes_layer.data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb9ebf9",
   "metadata": {},
   "source": [
    "# Test classifying various x-positions as belonging to outside the outside_maze, the track_endcaps, or the track_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ce4a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_rects_outputs, short_rects_outputs = add_track_shapes(grid_bin_bounds, ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7494b78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " [<matplotlib.patches.Rectangle at 0x7fa5a2c5bd90>,\n",
       "  <matplotlib.patches.Rectangle at 0x7fa468781640>,\n",
       "  <matplotlib.patches.Rectangle at 0x7fa59bd91940>],\n",
       " [(61.8970212608686,\n",
       "   -0.625,\n",
       "   22.0,\n",
       "   0.25,\n",
       "   <PyQt5.QtGui.QPen at 0x7fa3fc8517b0>,\n",
       "   <PyQt5.QtGui.QBrush at 0x7fa3fc851900>),\n",
       "  (83.8970212608686,\n",
       "   -0.55,\n",
       "   100.0,\n",
       "   0.1,\n",
       "   <PyQt5.QtGui.QPen at 0x7fa3fc8517b0>,\n",
       "   <PyQt5.QtGui.QBrush at 0x7fa3fc851900>),\n",
       "  (183.8970212608686,\n",
       "   -0.625,\n",
       "   22.0,\n",
       "   0.25,\n",
       "   <PyQt5.QtGui.QPen at 0x7fa3fc8517b0>,\n",
       "   <PyQt5.QtGui.QBrush at 0x7fa3fc851900>)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# long_offset=(150.0, 0.5)\n",
    "# short_offset=(150.0, -0.5)\n",
    "\n",
    "long_offset=(grid_bin_bounds.center_point[0], 0.5)\n",
    "short_offset=(grid_bin_bounds.center_point[0], -0.5)\n",
    "\n",
    "# # Create a second y-axis sharing the same x-axis as ax\n",
    "# ax2 = ax.twinx()\n",
    "# # ax2.plot(x, y2, 'b-')\n",
    "# ax2.set_ylabel('Track data', color='b')\n",
    "# # Set the adjustable attribute to 'datalim'\n",
    "# ax.set_adjustable('datalim')\n",
    "# ax2.set_adjustable('datalim')\n",
    "# long_track_dims.plot_rects(ax2, offset=long_offset)\n",
    "# short_track_dims.plot_rects(ax2, offset=short_offset)\n",
    "\n",
    "combined_item, rect_items, rects = long_track_dims.plot_rects(ax, offset=long_offset)\n",
    "short_track_dims.plot_rects(ax, offset=short_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36198209",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1, ax2 = test_LinearTrackDimensions_2D_Matplotlib(long_track_dims, short_track_dims, long_offset=(150.0, 0.5), short_offset=(150.0, -0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find center from `grid_bin_bounds`\n",
    "# long_pf2D.bin_info\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "\n",
    "x_diff = (grid_bin_bounds[0][1] - grid_bin_bounds[0][0])\n",
    "y_diff = (grid_bin_bounds[1][1] - grid_bin_bounds[1][0])\n",
    "print(f'x_diff: {x_diff}, y_diff: {y_diff}')\n",
    "\n",
    "# Find the x, y midpoints:\n",
    "x_midpoint = grid_bin_bounds[0][0] + (x_diff/2.0)\n",
    "y_midpoint = grid_bin_bounds[1][0] + (y_diff/2.0)\n",
    "print(f'x_midpoint: {x_midpoint}, y_midpoint: {y_midpoint}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_bin_bounds_center_point = (point_tuple_mid_point(grid_bin_bounds[0]), point_tuple_mid_point(grid_bin_bounds[1])) # (145.43, 140.61)\n",
    "x_midpoint, y_midpoint = grid_bin_bounds_center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# long_track_dims.total_length # 214.0\n",
    "# short_track_dims.total_length # 144.0\n",
    "# zero_alignment_point = self.total_length/2.0\n",
    "long_notable_x_positions, _long_notable_y_positions = long_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))\n",
    "short_notable_x_positions, _short_notable_y_positions = short_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc254a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _add_vertical_track_bounds_lines(grid_bin_bounds, ax=None):\n",
    "# \t\"\"\" \n",
    "# \tCaptures: long_notable_x_positions, short_notable_x_positions\n",
    "\t\n",
    "# \tUsage:\n",
    "# \t\tgrid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "# \t\tlong_track_line_collection, short_track_line_collection = _add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=ax)\n",
    "\n",
    "# \t\"\"\"\n",
    "# \tlong_track_dims = LinearTrackDimensions(track_length=170.0)\n",
    "# \tshort_track_dims = LinearTrackDimensions(track_length=100.0)\n",
    "\n",
    "# \t# Find center from `grid_bin_bounds` using `point_tuple_mid_point`\n",
    "# \tx_midpoint, y_midpoint = (point_tuple_mid_point(grid_bin_bounds[0]), point_tuple_mid_point(grid_bin_bounds[1])) # grid_bin_bounds_center_point: (145.43, 140.61)\n",
    "\n",
    "# \tlong_notable_x_positions, _long_notable_y_positions = long_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))\n",
    "# \tshort_notable_x_positions, _short_notable_y_positions = short_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))\n",
    "\n",
    "# \t# Omit the midpoint\n",
    "# \tlong_notable_x_platform_positions = long_notable_x_positions[[0,1,3,4]]\n",
    "# \tshort_notable_x_platform_positions = short_notable_x_positions[[0,1,3,4]]\n",
    "\n",
    "# \t## Adds to current axes:\n",
    "# \tif ax is None:\n",
    "# \t\tfig = plt.gcf()\n",
    "# \t\taxs = fig.get_axes()\n",
    "# \t\tax = axs[0]\n",
    "# \tlong_track_line_collection: matplotlib.collections.LineCollection = plt.vlines(long_notable_x_platform_positions, label='long_track_x_pos_lines', ymin=ax.get_ybound()[0], ymax=ax.get_ybound()[1], colors='#0000FFAA', linestyles='dashed') # matplotlib.collections.LineCollection\n",
    "# \tshort_track_line_collection: matplotlib.collections.LineCollection = plt.vlines(short_notable_x_platform_positions, label='short_track_x_pos_lines', ymin=ax.get_ybound()[0], ymax=ax.get_ybound()[1], colors='#FF0000AA', linestyles='dashed') # matplotlib.collections.LineCollection\n",
    "# \treturn long_track_line_collection, short_track_line_collection\n",
    "\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2650ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_items, rects = long_track_dims.plot_rects(axs[0]) # , offset=(x, y) # , offset=(0.1, 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20cfaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_line_collection.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_track_line_collection.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdae8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_dims.plot_rects(ax, offset=)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a25f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "axs = fig.get_axes()\n",
    "ax = axs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a48933",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_line_collection.remove()\n",
    "short_track_line_collection.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a142c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_1D_placecell_validation\n",
    "\n",
    "_out = plot_1D_placecell_validation(long_pf1D, 0)\n",
    "\n",
    "axes = _out[1]\n",
    "ax = axes[0]\n",
    "# ax = axes[1]\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(grid_bin_bounds=grid_bin_bounds, debug_print=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1)\n",
    "\n",
    "rect_items, rects = long_track_dims.plot_rects(axs[0]) # , offset=(x, y) # , offset=(0.1, 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5cf4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# long_track_dims.plot_rects(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4064c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_grid_bin_bounds_validation', curr_active_pipeline.get_session_context(), defer_render=False, save_figure=True)\n",
    "fig = _out.figures[0]\n",
    "ax = _out.axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the bounding box coordinates and dimensions\n",
    "bbox = ax.bbox\n",
    "x, y, width, height = bbox.x0, bbox.y0, bbox.width, bbox.height\n",
    "x, y, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_empty = ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e6b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_items, rects = long_track_dims.plot_rects(ax_empty) # , offset=(x, y) # , offset=(0.1, 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "(320.0, 983.7668560462606, 901.8181818181818, 91.99628790747863)\n",
    "active_track_dims = LinearTrackDimensions(width=901.8181818181818)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6645194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.transforms import Bbox\n",
    "\n",
    "# Step 2: Define a simple vector graphic (an arrow in this case)\n",
    "def draw_arrow(ax, x, y, width, height):\n",
    "    arrow = patches.FancyArrow(x, y, width, height, width=0.2*height, color=\"red\")\n",
    "    ax.add_patch(arrow)\n",
    "\n",
    "# Step 3: Scale and draw the arrow within a bounding box\n",
    "def draw_scaled_arrow_in_bbox(ax, bbox):\n",
    "    # Extract the bounding box coordinates and dimensions\n",
    "    x, y, width, height = bbox.x0, bbox.y0, bbox.width, bbox.height\n",
    "\n",
    "    # Draw the bounding box (for visualization)\n",
    "    rect = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor='black', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    # Draw the scaled arrow within the bounding box\n",
    "    draw_arrow(ax, x, y, width, height)\n",
    "\n",
    "# Main code\n",
    "fig, ax = plt.subplots()\n",
    "bbox = Bbox.from_bounds(0.2, 0.2, 0.6, 0.6)  # Define bounding box with [x, y, width, height]\n",
    "\n",
    "draw_scaled_arrow_in_bbox(ax, bbox)\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_aspect('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b365b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8f5ab",
   "metadata": {},
   "source": [
    "# 2023-09-21 - Continuous Surprise Figure - How do I display it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dbe065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_long_short_surprise_difference_plot, plot_long_short, plot_long_short_any_values\n",
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_surprise_results\n",
    "\n",
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import LongShortDisplayConfigManager\n",
    "long_short_display_config_manager = LongShortDisplayConfigManager()\n",
    "long_epoch_config = long_short_display_config_manager.long_epoch_config.as_matplotlib_kwargs()\n",
    "short_epoch_config = long_short_display_config_manager.short_epoch_config.as_matplotlib_kwargs()\n",
    "\n",
    "graphics_outputs_list = fig_surprise_results(curr_active_pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d58220",
   "metadata": {},
   "source": [
    "### FOUND! 2023-09-21 - Found code that generated surprise plots, strangely not stored anywhere!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: nSnapshots == n_post_update_times\n",
    "active_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise']\n",
    "post_update_times = active_relative_entropy_results['post_update_times'] # (4123,) = (nSnapshots,)\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals = active_relative_entropy_results['time_intervals']\n",
    "long_short_rel_entr_curves_frames = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4123, 108, 63) = (nSnapshots, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4123, 108, 63) = (nSnapshots, n_neurons, n_xbins)\n",
    "flat_relative_entropy_results = active_relative_entropy_results['flat_relative_entropy_results'] # (4123, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_results = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (4123, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_across_all_positions = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4123,) - (nSnapshots)\n",
    "flat_surprise_across_all_positions = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4123,) - (nSnapshots)\n",
    "nSnapshots, n_neurons, n_xbins = np.shape(long_short_rel_entr_curves_frames)\n",
    "print(f'nSnapshots: {nSnapshots}, n_neurons: {n_neurons}, n_xbins: {n_xbins}') # nSnapshots: 3308, n_neurons: 85, n_xbins: 107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61282cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(flat_jensen_shannon_distance_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d8d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(flat_relative_entropy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a7718",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(flat_jensen_shannon_distance_across_all_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(long_short_rel_entr_curves_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7205c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: these results are NOT the same as the ones calculated in compute_snapshot_relative_entropy_surprise_differences.compute_surprise_relative_entropy_divergence, and I'm not quite sure why:\n",
    "# Jensen-Shannon distance is an average of KL divergence:\n",
    "from scipy.special import rel_entr\n",
    "mixture_distribution = 0.5 * (long_short_rel_entr_curves_frames + short_long_rel_entr_curves_frames)\n",
    "print(f'mixture_distribution.shape: {np.shape(mixture_distribution)}') # (nSnapshots, n_neurons, n_xbins)\n",
    "# jensen_shannon_distance = 0.5 * (sum(rel_entr(mixture_distribution, long_short_rel_entr_curves_frames)) + sum(rel_entr(mixture_distribution, short_long_rel_entr_curves_frames))) # is this right? I'm confused by sum(...) # (n_neurons, n_xbins)\n",
    "jensen_shannon_distance = 0.5 * (np.sum(rel_entr(mixture_distribution, long_short_rel_entr_curves_frames), axis=1) + np.sum(rel_entr(mixture_distribution, short_long_rel_entr_curves_frames), axis=1)) # alt version: (nSnapshots, n_xbins)\n",
    "print(f'jensen_shannon_distance.shape: {np.shape(jensen_shannon_distance)}') # (n_neurons, n_xbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(flat_jensen_shannon_distance_results, jensen_shannon_distance).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1fd095",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(flat_jensen_shannon_distance_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb518301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from silx.gui.plot import Plot2D\n",
    "\n",
    "plot = Plot2D()  # Create the plot widget\n",
    "plot.addImage(flat_jensen_shannon_distance_results, legend='flat_jensen_shannon_distance_results')  # Plot the 2D data set with default colormap\n",
    "plot.setGraphTitle('flat_jensen_shannon_distance_results')\n",
    "plot.getXAxis().setLabel('Position Bin')\n",
    "plot.getYAxis().setLabel('Snapshot Timebin')\n",
    "plot.show()  # Make the plot widget visible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9eca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = Plot2D()  # Create the plot widget\n",
    "plot.addImage(jensen_shannon_distance, legend='jensen_shannon_distance')  # Plot the 2D data set with default colormap\n",
    "plot.setGraphTitle('jensen_shannon_distance')\n",
    "plot.getXAxis().setLabel('Position Bin')\n",
    "plot.getYAxis().setLabel('Snapshot Timebin')\n",
    "plot.show()  # Make the plot widget visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot = Plot2D()  # Create the plot widget\n",
    "plot.addImage(long_short_rel_entr_curves_frames, legend='image')  # Plot the 2D data set with default colormap\n",
    "plot.setGraphTitle('long_short_rel_entr_curves_frames')\n",
    "# plot.getXAxis().setLabel('Position Bin')\n",
    "# plot.getYAxis().setLabel('Snapshot Timebin')\n",
    "plot.show()  # Make the plot widget visible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from silx.gui.plot.StackView import StackViewMainWindow\n",
    "\n",
    "# synthetic data, stack of 100 images of size 200x300\n",
    "# mystack = np.fromfunction(\n",
    "#     lambda i, j, k: np.sin(i/15.) + np.cos(j/4.) + 2 * np.sin(k/6.),\n",
    "#     (100, 200, 300)\n",
    "# )\n",
    "\n",
    "sv = StackViewMainWindow()\n",
    "sv.setColormap(\"jet\", autoscale=True)\n",
    "sv.setStack(long_short_rel_entr_curves_frames)\n",
    "# (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "sv.setLabels([\"post_update_time\", \"aclu\", \"Position (xbin)\"])\n",
    "sv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa37de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(flat_jensen_shannon_distance_results, show_yticks=False, title=f\"flat_jensen_shannon_distance_results\", defer_show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa164de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(flat_jensen_shannon_distance_across_all_positions, show_yticks=False, title=f\"flat_jensen_shannon_distance_across_all_positions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2295dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "from neuropy.core.epoch import Epoch\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(post_update_times, flat_surprise_across_all_positions)\n",
    "ax.set_ylabel('Relative Entropy across all positions')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('r','cyan'), alpha=0.1, edgecolors=None, labels_kwargs={'y_offset': -0.05, 'size': 14}, defer_render=True, debug_print=False)\n",
    "laps_epochs_collection, laps_epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='r', edgecolors='black', labels_kwargs={'y_offset': -16.0, 'size':8}, defer_render=True, debug_print=False)\n",
    "# replays_epochs_collection, replays_epoch_labels = draw_epoch_regions(active_filter_epoch_obj, ax, facecolor='orange', edgecolors=None, labels_kwargs=None, defer_render=False, debug_print=False)\n",
    "fig.suptitle('flat_surprise_across_all_positions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(post_update_times, flat_jensen_shannon_distance_across_all_positions, label='JS_Distance')\n",
    "ax.set_ylabel('J-S Distance across all positions')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), alpha=0.1, edgecolors=None, labels_kwargs={'y_offset': -0.05, 'size': 14}, defer_render=True, debug_print=False)\n",
    "laps_epochs_collection, laps_epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='red', edgecolors='black', labels_kwargs={'y_offset': -16.0, 'size':8}, defer_render=True, debug_print=False)\n",
    "# replays_epochs_collection, replays_epoch_labels = draw_epoch_regions(active_filter_epoch_obj, ax, facecolor='orange', edgecolors=None, labels_kwargs=None, defer_render=False, debug_print=False)\n",
    "fig.suptitle('flat_jensen_shannon_distance_across_all_positions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df587d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic relative entropy vs. time plot:\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(post_update_times, flat_relative_entropy_results)\n",
    "ax.set_ylabel('Relative Entropy')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), alpha=0.1, edgecolors=None, labels_kwargs={'y_offset': -0.05, 'size': 14}, defer_render=False, debug_print=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ffda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "win, plots = plot_long_short_surprise_difference_plot(curr_active_pipeline, long_results_obj, short_results_obj, long_epoch_name, short_epoch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "win, (ax_long, ax_short), legend = plot_long_short(long_results_obj, short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fn = lambda a_results_obj: a_results_obj.all_epochs_decoded_epoch_time_bins_mean[:,0]\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_scrambled_pf_surprises_mean\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "y_fn = lambda a_results_obj: a_results_obj.all_epochs_computed_one_left_out_posterior_to_pf_surprises\n",
    "\n",
    "# (time_bins, neurons), (epochs, neurons), (epochs)\n",
    "# all_epochs_computed_one_left_out_posterior_to_pf_surprises, all_epochs_computed_cell_one_left_out_posterior_to_pf_surprises_mean, all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "win, plots_tuple, legend = plot_long_short_any_values(long_results_obj, short_results_obj, x=x_fn, y=y_fn) #  limit_aclus=[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO 2023-09-21 16:19: - [ ] Does not work due to QCode issue\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions import _context_nested_docks\n",
    "\n",
    "\n",
    "# active_display_output = {}\n",
    "# active_identifying_filtered_session_ctx = global_epoch_context\n",
    "# display_output = active_display_output | curr_active_pipeline.display('_display_context_nested_docks', active_identifying_filtered_session_ctx, enable_gui=False, debug_print=False) # returns {'master_dock_win': master_dock_win, 'app': app, 'out_items': out_items}\n",
    "# master_dock_win = display_output['master_dock_win']\n",
    "# app = display_output['app']\n",
    "# out_items = display_output['out_items']\n",
    "\n",
    "include_includelist = curr_active_pipeline.active_completed_computation_result_names # ['maze', 'sprinkle']\n",
    "\n",
    "out_items = {}\n",
    "master_dock_win, app, out_items = _context_nested_docks(curr_active_pipeline, active_config_names=include_includelist, **{'enable_gui': True, 'debug_print': False})\n",
    "master_dock_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7326d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "short_pf_peak_x = neuron_replay_stats_df.short_pf_peak_x.values\n",
    "long_pf_peak_x = neuron_replay_stats_df.long_pf_peak_x.values\n",
    "\n",
    "# long_pf_peak_x_maze_classification = [classify_x_position(test_x, long_rects) for test_x in long_pf_peak_x.values]\n",
    "# short_pf_peak_x_maze_classification = [classify_x_position(test_x, short_rects) for test_x in short_pf_peak_x.values]\n",
    "# [classify_x_position(test_x, short_rects) for test_x in long_pf_peak_x.values]\n",
    "\n",
    "long_track.is_on_maze(long_pf_peak_x)\n",
    "# long_track.is_on_endcap(long_pf_peak_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bc1b6",
   "metadata": {},
   "source": [
    "## NOW TODO 2023-09-20 22:33: - [ ] Need to fix tests and determing why some peaks are falling outside the bounds (as assessed by the is_on_maze function to see if implementation is valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# assert short_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))].all(), f\"all valid short peaks should be located on the short track\" # should all be true yeah?\n",
    "assert long_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))].all(), f\"all valid short peaks should be located on the long track\"\n",
    "assert long_track.is_on_maze(long_pf_peak_x)[np.logical_not(np.isnan(long_pf_peak_x))].all(), f\"all valid long peaks should be located on the long track. {long_track.is_on_maze(long_pf_peak_x)[np.logical_not(np.isnan(long_pf_peak_x))]}\" # not working\n",
    "assert short_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))].all(), f\"all valid short peaks should be located on the short track. {short_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))]}\" # not working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec27b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track.is_on_endcap(long_pf_peak_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1bc2ae",
   "metadata": {},
   "source": [
    "## Debug Plots for `LinearTrackDimensions` and `LinearTrackInstance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ece7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, w, cw, (long_track_dims, long_rect_items, long_rects), (short_track_dims, short_rect_items, short_rects) = test_LinearTrackDimensions_2D_pyqtgraph(long_track_dims, short_track_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cdcb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "axs = fig.get_axes()\n",
    "ax = axs[0]\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d49be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "## Adds a new subplot to an existing (fig, ax) without requiring modifications in the original code!\n",
    "\n",
    "# Get the current gridspec from ax\n",
    "gs = ax.get_subplotspec().get_gridspec()\n",
    "\n",
    "# Create a new gridspec with an additional column\n",
    "gs_new = gridspec.GridSpec(1, 2, width_ratios=[1, 0.5]) # new column is half the width of the current one\n",
    "\n",
    "# Reposition the existing ax using the new gridspec\n",
    "ax.set_position(gs_new[0, 0].get_position(fig))\n",
    "\n",
    "# Add a new subplot in the new column\n",
    "ax2 = fig.add_subplot(gs_new[0, 1])\n",
    "\n",
    "\n",
    "ax2.plot(np.cos(np.linspace(0, 10, 100)))\n",
    "# ax2.cla()\n",
    "# long_track_dims.plot_rects(ax2)\n",
    "\n",
    "# long_track_dims.plot_rects(ax2, offset=(0.1, 0.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out2 = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', included_unit_neuron_IDs=[2], n_max_plot_rows=2, save_figure=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_example_handpicked_pho_jonathan_active_set_cells\n",
    "\n",
    "_LxC_out, _SxC_out = fig_example_handpicked_pho_jonathan_active_set_cells(curr_active_pipeline, save_figure=True, included_LxC_example_neuron_IDs=[4, 58], included_SxC_example_neuron_IDs=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6907963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuropy.analyses.placefields import PfnDMixin, plotRaw_v_time\n",
    "from neuropy.analyses.placefields import PfnDMixin\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out3 = long_pf1D.plotRaw_v_time(0, should_include_trajectory=True, should_include_spikes=False, should_include_labels=True, use_filtered_positions=True, use_pandas_plotting=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a88a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out4 = long_pf1D.plotRaw_v_time(0, should_include_trajectory=True, should_include_spikes=False, should_include_labels=True, use_filtered_positions=False, use_pandas_plotting=False)\n",
    "# _out4 = long_pf1D.plotRaw_v_time(0, should_include_trajectory=True, should_include_spikes=False, should_include_labels=True, use_filtered_positions=False, use_pandas_plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff3397",
   "metadata": {},
   "source": [
    "# 🟢👁️‍🗨️ PhoKamran2023Paper Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e59bdb",
   "metadata": {},
   "source": [
    "## Figure 1) pf1D Ratemaps, Active set, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77377ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_1_add_replay_epoch_rasters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics, fig_1c_figures_out_dict = PAPER_FIGURE_figure_1_full(curr_active_pipeline) # did not display the pf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05664e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = jonathan_firing_rate_analysis_result.rdf.rdf\n",
    "rdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b2335",
   "metadata": {},
   "source": [
    "## Figure 2) `PaperFigureTwo`: LxC/SxC Analyses\n",
    "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63d9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo\n",
    "\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # 10ms\n",
    "_out_fig_2.compute(curr_active_pipeline=curr_active_pipeline)\n",
    "_out_fig_2.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403e5c60",
   "metadata": {},
   "source": [
    "## Figure 3) `PAPER_FIGURE_figure_3`: Firing Rate Index and Long/Short Firing Rate Replays v. Laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6932845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import FormattedFigureText\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _plot_long_short_firing_rate_indicies\n",
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out, _out2 = PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9796ffb1",
   "metadata": {},
   "source": [
    "## Other Paper-related explorations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90dda8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out2.figures\n",
    "_out.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "['start']\n",
    "\n",
    "\n",
    "# Any change in duration over the recording session duration?\n",
    "rdf['duration']\n",
    "\n",
    "# rdf.plot.scatter('start', 'duration')\n",
    "\n",
    "# rdf.plot.scatter('duration', 'num_neuron_participating') # strong positive trend\n",
    "\n",
    "# rdf.plot.scatter('start', 'num_neuron_participating') # num neurons participating seems to increase over time, especially after the short track is introduced. Contrary to my hypothesis.\n",
    "\n",
    "rdf.plot.scatter('start', 'num_short_only_neuron_participating')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ['num_neuron_participating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "a_plot_obj = curr_active_pipeline.plot\n",
    "a_plot_obj._display_spike_rasters_pyqtplot_2D()\n",
    "# '_display_spike_rasters_pyqtplot_2D': ' Plots a standalone 2D raster plot\\n        ',\n",
    "# '_display_spike_rasters_pyqtplot_3D': ' Plots a standalone 3D raster plot with independent/standalone controls built-in\\n        ',\n",
    "# '_display_spike_rasters_pyqtplot_3D_with_2D_controls': ' Plots a standalone 3D raster plot (via pyqtgraph) with a separate 2D raster plot as the window with which you can adjust the viewed window. \\n        ',\n",
    "# '_display_spike_rasters_vedo_3D': ' Plots a standalone 3D raster plot with independent/standalone controls built-in\\n        ',\n",
    "# '_display_spike_rasters_vedo_3D_with_2D_controls': ' Plots a standalone 3D raster plot (via Vedo) with a separate 2D raster plot as the window with which you can adjust the viewed window. \\n        ',\n",
    "# '_display_spike_rasters_window': ' Displays a Spike3DRasterWindowWidget with a configurable set of raster widgets and controls in it.\\n        ',type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3877d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1d_compare_fig_L, pf1d_compare_fig_S = pf1d_compare_graphics.figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ffa57",
   "metadata": {
    "tags": [
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import build_shared_sorted_neuronIDs\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph\n",
    "\n",
    "ratemap = long_pf1D.ratemap\n",
    "included_unit_neuron_IDs = EITHER_subset.track_exclusive_aclus\n",
    "rediculous_final_sorted_all_included_neuron_ID, rediculous_final_sorted_all_included_pfmap = build_shared_sorted_neuronIDs(ratemap, included_unit_neuron_IDs, sort_ind=new_all_aclus_sort_indicies.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(rediculous_final_sorted_all_included_pfmap, show_yticks=False, title=f\"pf1D Sorted Visualization\", defer_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66369f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_curves_sorted = long_pf1D.ratemap.normalized_tuning_curves[is_included][included_new_all_aclus_sort_indicies]\n",
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(active_curves_sorted, show_yticks=False, title=f\"pf1D Sorted Visualization\", defer_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f0066",
   "metadata": {
    "tags": [
     "unwrap_figure_output",
     "interactive"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "## Stacked Epoch Plot\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=True)\n",
    "pagination_controller_L, pagination_controller_S = example_stacked_epoch_graphics.plot_data['controllers']\n",
    "ax_L, ax_S = example_stacked_epoch_graphics.axes\n",
    "final_figure_context_L, final_context_S = example_stacked_epoch_graphics.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cbb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## After launching the interactive Stacked Epoch Plots for user epoch selection, try to update the selection with previously added annotations:\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.GUI.Qt.Mixins.PaginationMixins import SelectionsObject\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "user_annotation_man = UserAnnotationsManager()\n",
    "user_annotations = user_annotation_man.get_user_annotations()\n",
    "\n",
    "final_context_L = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj')\n",
    "final_context_S = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj')\n",
    "# _out_pagination_controller.params.active_identifying_figure_ctx.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_L = final_context_L.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_S = final_context_S.adding_context(None,  user_annotation=\"selections\")\n",
    "\n",
    "saved_selection_L: SelectionsObject = pagination_controller_L.save_selection()\n",
    "saved_selection_S: SelectionsObject = pagination_controller_S.save_selection()\n",
    "# saved_selection_L = user_annotation_man.update_selections_from_annotations(saved_selection_L, user_annotations)\n",
    "# saved_selection_S = user_annotation_man.update_selections_from_annotations(saved_selection_S, user_annotations)\n",
    "\n",
    "saved_selection_L = saved_selection_L.update_selections_from_annotations(user_annotations, debug_print=False)\n",
    "saved_selection_S = saved_selection_S.update_selections_from_annotations(user_annotations, debug_print=False)\n",
    "\n",
    "## re-apply the selections:\n",
    "pagination_controller_L.restore_selections(saved_selection_L, defer_render=True)\n",
    "pagination_controller_S.restore_selections(saved_selection_S, defer_render=True)\n",
    "\n",
    "ax_L[0].figure.canvas.draw()  # .figures.canvas.draw()\n",
    "ax_S[0].figure.canvas.draw()  # .figures.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b2f39d",
   "metadata": {
    "tags": [
     "TODO"
    ]
   },
   "source": [
    "# 2023-09-06 - Plot the decoded positions for each replay on the track:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592c55f",
   "metadata": {
    "tags": [
     "TODO"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions\n",
    "\n",
    "\n",
    "long_track_dims = LinearTrackDimensions(track_length=100.0)\n",
    "short_track_dims = LinearTrackDimensions(track_length=70.0)\n",
    "\n",
    "\n",
    "# long_track_dims.plot_rects(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import _test_LinearTrackDimensions_2D\n",
    "\n",
    "app, w, cw, (long_track_dims, long_rect_items, long_rects), (short_track_dims, short_rect_items, short_rects) = _test_LinearTrackDimensions_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48faca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_3_a, _out_fig_3_b = PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = _out_fig_3_a.axes[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c872e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_dims.plot_rects(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination_controller_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the symbol properties\n",
    "# symbol = pg.mkPen('w', width=1)  # Pen for the lines\n",
    "size = 1.0  # Fixed x-width\n",
    "symbol_brush = None  # No brush for the symbol (transparent fill)\n",
    "\n",
    "# override_scatter_plot_kwargs = dict(pxMode=False, symbol='|', size=size, pen={'color': 'w', 'width': 1.0}) # , brush=symbol_brush\n",
    "\n",
    "override_scatter_plot_kwargs = dict(pxMode=False, symbol='arrow_up', size=1.0, pen={'color': 'w', 'width': 1.0}, hoverable=True) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bb530",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epoch_spikes_df_L.spikes.rebuild_fragile_linear_neuron_IDXs();\n",
    "filter_epoch_spikes_df_S.spikes.rebuild_fragile_linear_neuron_IDXs();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_L, win_L, plots_L, plots_data_L = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "\t\t\t\t\t\t\t\t\t\tepoch_id_key_name='replay_epoch_id', scatter_app_name=\"Long Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee132b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_S, win_S, plots_S, plots_data_S = plot_multiple_raster_plot(epochs_df_S, filter_epoch_spikes_df_S, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                 epoch_id_key_name='replay_epoch_id', scatter_app_name=\"Short Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26dd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single `plot_raster_plot` calls\n",
    "an_epoch = list(epochs_df_L.itertuples())[0]\n",
    "an_epoch_spikes_df = filter_epoch_spikes_df_L[filter_epoch_spikes_df_L['replay_epoch_id'] == an_epoch.Index]\n",
    "\n",
    "_out_single_raster_plot = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test1\")\n",
    "_out_single_raster_plot2 = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6071c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_alt, win_alt, plots_alt, plots_data_alt = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                         epoch_id_key_name='replay_epoch_id', scatter_app_name=\"ALT Long Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d20407c",
   "metadata": {},
   "source": [
    "### Testing `plot_kourosh_activity_style_figure` for debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69512447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import plot_kourosh_activity_style_figure\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.helpers import _helper_make_scatterplot_clickable\n",
    "\n",
    "plot_aclus = EITHER_subset.track_exclusive_aclus.copy()\n",
    "# plot_aclus = EITHER_subset.track_exclusive_aclus[new_all_aclus_sort_indicies].copy()\n",
    "_out_A = plot_kourosh_activity_style_figure(long_results_obj, long_session, plot_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_idx=13, callout_epoch_IDXs=None, skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, plots, plots_data = _out_A\n",
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d4092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 2023-06-27 10:42: - [ ] Desperitely need a class that \"explodes\" the important variables and their types out of a DynamicParameters (dict-like) or other object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_n = plot_kourosh_activity_style_figure(long_results_obj, long_session, EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_idx=49, callout_epoch_IDXs=np.arange(6), skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af748f5c",
   "metadata": {},
   "source": [
    "# 2023-07-14 - LxC and SxC PhoJonathanSession plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_display_BatchPhoJonathanFiguresHelper_PlusPDF_20.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\n",
    "# print(f'active_out_figures_dict: {active_out_figures_dict}')\n",
    "\n",
    "# BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset\n",
    "active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=EITHER_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\n",
    "print(f'active_out_figures_dict: {active_out_figures_dict}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e072b346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec1c4bb",
   "metadata": {
    "tags": [
     "ACTIVE_2023-09-07"
    ]
   },
   "outputs": [],
   "source": [
    "# 2023-09-07 - Build Example LxC/SxC cells from handpicked examples: aclus = [4, 58]\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import build_extra_cell_info_label_string\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out2 = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', n_max_plot_rows=2, save_figure=False, included_unit_neuron_IDs=[4, 58]) # , included_unit_neuron_IDs=[4, 58]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.display(display_function='_display_2d_placefield_result_plot_ratemaps_2D', active_session_configuration_context=long_epoch_context)\n",
    "\n",
    "\n",
    "# curr_active_pipeline.display(display_function='_display_placemaps_pyqtplot_2D', active_session_configuration_context=long_epoch_context)\n",
    "curr_active_pipeline.display(display_function='_display_1d_placefields', active_session_configuration_context=long_epoch_context)\n",
    "# curr_active_pipeline.display(display_function='_display_2d_placefield_occupancy', active_session_configuration_context=long_epoch_context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_occupancy', active_session_configuration_context=long_epoch_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be309d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_occupancy', active_session_configuration_context=short_epoch_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_result_plot_ratemaps_2D', active_session_configuration_context=short_epoch_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5115fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_result_plot_ratemaps_2D', active_session_configuration_context=long_epoch_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d12ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() # new figure to hold the result\n",
    "# can show the figures by looping through and calling\n",
    "for a_ctxt, a_fig in active_out_figures_dict.items():\n",
    "    print(f'showing: {a_ctxt}')\n",
    "    a_fig.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edea79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]] # only uses global_session\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d085cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ab296",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exclusive.track_exclusive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exclusive.track_exclusive_df['lap_delta_minus_inst_fr'] = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n",
    "long_exclusive.track_exclusive_df['lap_delta_plus_inst_fr'] = LxC_ThetaDeltaPlus.cell_agg_inst_fr_list # (n_cells, )\n",
    "long_exclusive.track_exclusive_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3077438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = LxC_ThetaDeltaMinus.epoch_agg_inst_fr_list # (n_epochs, n_cells)\n",
    "# d = d[:,1]\n",
    "d = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n",
    "d\n",
    "long_exclusive.track_exclusive_df['lap_delta_minus_inst_fr'] = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop out the very low (inactive) Epochs... I guess? But we want it to be influenced by the inactive epochs.\n",
    "curr_active_pipeline.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(LxC_ThetaDeltaMinus.inst_fr_signals_list) # n_epochs\n",
    "d = LxC_ThetaDeltaMinus.inst_fr_df_list\n",
    "d[0]\n",
    "# (n_epochs, n_cells)\n",
    "# print(f'{d.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b2901",
   "metadata": {},
   "source": [
    "## NOW: 2023-07-11 - Testing Batch-computed inst_firing_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "\n",
    "## Load the saved across-session results:\n",
    "inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=0) # some global context across all of the sessions, not sure what to put here.\n",
    "\n",
    "# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\n",
    "\n",
    "## Display the aggregate across sessions:\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn't save this info\n",
    "_out_fig_2.computation_result = across_session_inst_fr_computation\n",
    "_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\n",
    "# Set callback, the only self-specific property\n",
    "_out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f71cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\n",
    "\t\n",
    "_out_fig_2.perform_save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed322ee",
   "metadata": {},
   "source": [
    "# `active_pf_nD`, `active_pf_nD_dt` visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8606b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedOccupancyPlotter import TimeSynchronizedOccupancyPlotter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d478ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_sync_occupancy_plotter = TimeSynchronizedOccupancyPlotter(global_pf2D_dt)\n",
    "curr_sync_occupancy_plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14388eec",
   "metadata": {},
   "source": [
    "# 2023-07-07 - `batch_extended_programmatic_figures` Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "neptuner = batch_perform_all_plots(curr_active_pipeline, enable_neptune=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126028b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb off\n",
    "%load_ext viztracer\n",
    "from viztracer import VizTracer\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a065e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-batch_extended_programmatic_figures.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    batch_extended_programmatic_figures(curr_active_pipeline, write_vector_format=False, write_png=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9f9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_extended_programmatic_figures(curr_active_pipeline, write_vector_format=False, write_png=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.logical_or(neuron_replay_stats_df['is_refined_LxC'], neuron_replay_stats_df['is_refined_SxC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a49741",
   "metadata": {},
   "outputs": [],
   "source": [
    "JonathanFiringRateAnalysisResult = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc366f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "\n",
    "jonathan_firing_rate_analysis_result.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0710f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720dda5d",
   "metadata": {},
   "source": [
    "# 2023-09-26 - Interactive `napari` testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from pyphoplacecellanalysis.GUI.Napari.napari_helpers import napari_add_surprise_data_layers, napari_add_animal_position, napari_set_time_windw_index\n",
    "\n",
    "# create the viewer and window\n",
    "viewer = napari.Viewer()\n",
    "# napari_add_surprise_data_layers(viewer, active_relative_entropy_results)\n",
    "napari_add_animal_position(viewer=viewer, position_df=global_pf1D_dt.all_time_filtered_pos_df[['t','x','binned_x']], time_intervals=time_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0815fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_below_threshold:float=0.0000001\n",
    "active_time_dependent_placefields = deepcopy(global_pf1D_dt)\n",
    "curr_ratemap = active_time_dependent_placefields.ratemap\n",
    "images = curr_ratemap.tuning_curves.copy() # 1D: (82, 112), 2D:(43, 63, 63)\n",
    "print(f'images.shape: {np.shape(images)}')\n",
    "occupancy = curr_ratemap.occupancy\n",
    "print(f'occupancy: {occupancy.shape}')\n",
    "# Compute Images:\n",
    "included_unit_indicies = np.arange(np.shape(images)[0]) # include all unless otherwise specified\n",
    "nMapsToShow = len(included_unit_indicies)\n",
    "print(f'nMapsToShow: {nMapsToShow}')\n",
    "# Get single cell info:\n",
    "# neuron_IDX = curr_included_unit_index\n",
    "# cell_ID = active_time_dependent_placefields.ratemap.neuron_ids[neuron_IDX]\n",
    "# curr_cell_identifier_string = f'Cell[{cell_ID}]'\n",
    "# curr_plot_identifier_string = f'TimeSynchronizedPlacefieldsPlotter.{curr_cell_identifier_string}'\n",
    "\n",
    "# Build the image item:\n",
    "# Update the image:\n",
    "# image = np.squeeze(images[a_linear_index,:,:])\n",
    "image = np.squeeze(images)\n",
    "# Pre-filter the data:\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\timage = np.array(image) / np.nanmax(image) # note scaling by maximum here!\n",
    "\tif drop_below_threshold is not None:\n",
    "\t\timage[:, np.where(occupancy < drop_below_threshold)] = np.nan # null out the occupancy\n",
    "\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Napari.napari_helpers import napari_export_video_frames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd056119",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.layers['short_long_rel_entr_curves_frames'].blending # 'additive'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa129b",
   "metadata": {},
   "source": [
    "# 2023-09-27 - Exporting surprise ndarray to a video file for visualization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add the animal's closest current position (binned) as a single colored pixel along the top of the array:\n",
    "len(global_pf1D_dt.historical_snapshots)\n",
    "\n",
    "global_pf1D_dt.historical_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_pf1D_dt.complete_time_range_computation(\n",
    "\n",
    "custom_pf1D_dt = deepcopy(global_pf1D_dt)\n",
    "custom_pf1D_dt.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab56fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out = custom_pf1D_dt.complete_time_range_computation(global_session.t_start, global_session.t_stop, assign_results_to_member_variables=True, should_snapshot=True)\n",
    "\n",
    "_out = custom_pf1D_dt.batch_snapshotting(\n",
    "\n",
    ".complete_time_range_computation(global_session.t_start, global_session.t_stop, assign_results_to_member_variables=True, should_snapshot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a4f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_session.t_start\t\t\t\t   \n",
    "global_session.t_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a38ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pyphocorehelpers.plotting.video_output_helpers import save_array_as_video\n",
    "\n",
    "colormap = cv2.COLORMAP_JET\n",
    "\n",
    "\n",
    "array = active_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'].copy()\n",
    "gray_frames = cv2.normalize(array, None, 255, 0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U) # same size as array\n",
    "\n",
    "# color_array = cv2.applyColorMap(gray_frames, colormap)\n",
    "# video_out_path = save_array_as_video(array=color_array, video_filename='output/videos/snapshot_occupancy_weighted_tuning_maps_color.avi', isColor=True)\n",
    "video_out_path = save_array_as_video(array=gray_frames, video_filename='output/videos/snapshot_occupancy_weighted_tuning_maps_gray.avi', isColor=False)\n",
    "print(f'video_out_path: {video_out_path}')\n",
    "reveal_in_system_file_manager(video_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import export_active_relative_entropy_results_videos\n",
    "\n",
    "video_output_parent_path = export_active_relative_entropy_results_videos(active_relative_entropy_results, active_context=curr_active_pipeline.get_session_context())\n",
    "reveal_in_system_file_manager(video_output_parent_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba227418",
   "metadata": {},
   "source": [
    "# 2023-09-26 - Interactive `Spike3DRasterWindowWidget` exploration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ca4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg # Used to get the app for TopLevelWindowHelper.top_level_windows\n",
    "## For searching with `TopLevelWindowHelper.all_widgets(...)`:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike3DRaster import Spike3DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "found_spike_raster_windows = TopLevelWindowHelper.all_widgets(pg.mkQApp(), searchType=Spike3DRasterWindowWidget)\n",
    "\n",
    "if len(found_spike_raster_windows) < 1:\n",
    "\t# no existing spike_raster_windows. Make a new one\n",
    "\tprint(f'no existing SpikeRasterWindow. Creating a new one.')\n",
    "\t# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "\tactive_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D(included_neuron_ids=EITHER_subset.track_exclusive_aclus).values()\n",
    "\n",
    "else:\n",
    "\tprint(f'found {len(found_spike_raster_windows)} existing Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...). Will use the most recent.')\n",
    "\t# assert len(found_spike_raster_windows) == 1, f\"found {len(found_spike_raster_windows)} Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...) but require exactly one.\"\n",
    "\t# Get the most recent existing one and reuse that:\n",
    "\tspike_raster_window = found_spike_raster_windows[0]\n",
    "\t# Extras:\n",
    "\tactive_2d_plot = spike_raster_window.spike_raster_plt_2d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "\tactive_3d_plot = spike_raster_window.spike_raster_plt_3d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13fde68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.\n",
    "\n",
    "EITHER_subset.track_exclusive_aclus\n",
    "# , neuron_colors=neuron_colors, neuron_sort_order=neuron_sort_order, application_name=application_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ce291",
   "metadata": {},
   "source": [
    "# Interactive SpikeRasterWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dbe020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307d5dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedOccupancyPlotter import TimeSynchronizedOccupancyPlotter\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.Mixins.helpers import build_combined_time_synchronized_plotters_window\n",
    "\n",
    "active_pf_2D_dt = global_pf2D_dt\n",
    "active_pf_2D_dt.reset()\n",
    "active_pf_2D_dt.update(t=500.0, start_relative_t=True)\n",
    "all_plotters, root_dockAreaWindow, app = build_combined_time_synchronized_plotters_window(active_pf_2D_dt, fixed_window_duration = 15.0)\n",
    "controlling_widget, curr_sync_occupancy_plotter, curr_placefields_plotter = all_plotters # end up in some sort of `linkedViewChanged` loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a VERY simple and efficient 1D plot of the animal on the track.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306542c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "_out = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2878ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg # Used to get the app for TopLevelWindowHelper.top_level_windows\n",
    "## For searching with `TopLevelWindowHelper.all_widgets(...)`:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike3DRaster import Spike3DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "found_spike_raster_windows = TopLevelWindowHelper.all_widgets(pg.mkQApp(), searchType=Spike3DRasterWindowWidget)\n",
    "# assert len(found_spike_raster_windows) == 1, f\"found {len(found_spike_raster_windows)} Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...) but require exactly one.\"\n",
    "if len(found_spike_raster_windows) > 1:\n",
    "\tprint(f'found {len(found_spike_raster_windows)} widgets with the searchType provided:')\n",
    "\tprint(f'{found_spike_raster_windows}')\n",
    "\tprint(f'defaulting to using the most recent [-1]...')\n",
    "spike_raster_window = found_spike_raster_windows[-1]\n",
    "\n",
    "# Extras:\n",
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "active_3d_plot = spike_raster_window.spike_raster_plt_3d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2011a",
   "metadata": {
    "tags": [
     "spike_raster_window_defaults"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "\n",
    "active_pf_2D = global_pf2D\n",
    "## Example 1: De-emphasize spikes excluded from the placefield calculations:\n",
    "is_spike_included_in_pf = np.isin(spike_raster_window.spike_raster_plt_2d.spikes_df.index, active_pf_2D.filtered_spikes_df.index)\n",
    "spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not(is_spike_included_in_pf), SpikeEmphasisState.Deemphasized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.EpochRenderingMixin import EpochRenderingMixin\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, Ripples_2DRenderTimeEpochs, inline_mkColor\n",
    "\n",
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.Session.Epochs']\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0ac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inline Concise: Position Replays, PBEs, and Ripples all below the scatter:\n",
    "# active_2d_plot.interval_datasources.Replays.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-10.0, height=7.5, pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5), **kwargs)) ## Fully inline\n",
    "# active_2d_plot.interval_datasources.PBEs.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-2.0, height=1.5, pen_color=inline_mkColor('pink', 0.8), brush_color=inline_mkColor('pink', 0.5), **kwargs)) ## Fully inline\n",
    "# active_2d_plot.interval_datasources.Ripples.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5), **kwargs)) ## Fully inline\n",
    "# active_2d_plot.interval_datasources.SessionEpochs .update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5), **kwargs)) ## Fully inline\n",
    "epochs_update_dict = {\n",
    "    'Replays':dict(y_location=-10.0, height=7.5, pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5)),\n",
    "    'PBEs':dict(y_location=-2.0, height=1.5, pen_color=inline_mkColor('pink', 0.8), brush_color=inline_mkColor('pink', 0.5)),\n",
    "    'Ripples':dict(y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5)),\n",
    "    'SessionEpochs ':dict(y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5)),\n",
    "}\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(epochs_update_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26350f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interval_info = active_2d_plot.list_all_rendered_intervals() ## get the existing intervals\n",
    "rendered_interval_keys = list(interval_info.keys())\n",
    "desired_interval_height_ratios = [2.0, 2.0, 1.0, 0.1, 1.0, 1.0, 1.0] # ratio of heights to each interval\n",
    "required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout(desired_interval_height_ratios, epoch_render_stack_height=20.0, interval_stack_location='below')\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(rendered_interval_keys, required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(stacked_epoch_layout_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_spike_included_in_pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb21806",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf_2D_dt.update(t=1000.0, start_relative_t=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc70ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "\n",
    "curr_sync_occupancy_plotter = TimeSynchronizedOccupancyPlotter(global_pf2D_dt)\n",
    "curr_sync_occupancy_plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67793210",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pf2D_dt.historical_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a3382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "\n",
    "curr_sync_placefield_plotter = TimeSynchronizedPlacefieldsPlotter(global_pf2D_dt)\n",
    "curr_sync_placefield_plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c722971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "\n",
    "curr_sync_placefield_plotter1D = TimeSynchronizedPlacefieldsPlotter(global_pf1D_dt)\n",
    "curr_sync_placefield_plotter1D.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a0f86",
   "metadata": {},
   "source": [
    "# 2023-07-19 - Validation with 3D tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ecde32c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "display_output = {}\n",
    "# active_config_name = long_epoch_name\n",
    "active_config_name = global_epoch_name\n",
    "active_config = curr_active_pipeline.active_configs[active_config_name]\n",
    "active_config.plotting_config.should_use_linear_track_geometry = True # indicate that it's a linear track so the better geometry can be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80672dec",
   "metadata": {},
   "source": [
    "# 3D Plotters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f0e7a",
   "metadata": {},
   "source": [
    "## 📣 Programmatically adding several epoch rectangles by calling the addRenderable context menu functions all at once for SpikeRaster2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb05977",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.Session.Epochs']\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, Ripples_2DRenderTimeEpochs, inline_mkColor\n",
    "## Inline Concise: Position Replays, PBEs, and Ripples all below the scatter:\n",
    "# active_2d_plot.interval_datasources.Replays.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-10.0, height=7.5, pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5), **kwargs)) ## Fully inline\n",
    "# active_2d_plot.interval_datasources.PBEs.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-2.0, height=1.5, pen_color=inline_mkColor('pink', 0.8), brush_color=inline_mkColor('pink', 0.5), **kwargs)) ## Fully inline\n",
    "# active_2d_plot.interval_datasources.Ripples.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5), **kwargs)) ## Fully inline\n",
    "# active_2d_plot.interval_datasources.SessionEpochs .update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5), **kwargs)) ## Fully inline\n",
    "epochs_update_dict = {\n",
    "    'Replays':dict(y_location=-10.0, height=7.5, pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5)),\n",
    "    'PBEs':dict(y_location=-2.0, height=1.5, pen_color=inline_mkColor('pink', 0.8), brush_color=inline_mkColor('pink', 0.5)),\n",
    "    'Ripples':dict(y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5)),\n",
    "    'SessionEpochs ':dict(y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5)),\n",
    "}\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(epochs_update_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8e16b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered_interval_keys = list(interval_info.keys())\n",
    "desired_interval_height_ratios = [2.0, 2.0, 1.0, 0.1, 1.0, 1.0, 1.0] # ratio of heights to each interval\n",
    "required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout(desired_interval_height_ratios, epoch_render_stack_height=20.0, interval_stack_location='below')\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(rendered_interval_keys, required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(stacked_epoch_layout_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd240080",
   "metadata": {},
   "source": [
    "## 🪟 ipcDataExplorer - 3D Interactive Tuning Curves Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5568d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict\n",
    "\n",
    "'_display_3d_image_plotter'\n",
    "'_display_long_short_laps'\n",
    "'_display_3d_interactive_custom_data_explorer'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveDataExplorerBase import InteractiveDataExplorerBase\n",
    "# from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer # TypeError: super(type, obj): obj must be an instance or subtype of type\n",
    "\n",
    "active_config_name = global_epoch_context\n",
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "# _out = curr_active_pipeline.display('_display_3d_interactive_custom_data_explorer', long_epoch_name) # long_epoch_context\n",
    "display_dict = curr_active_pipeline.display('_display_3d_interactive_custom_data_explorer', active_config_name) # does not work, missing color info?\n",
    "iplapsDataExplorer = display_dict['iplapsDataExplorer']\n",
    "# plotter is available at\n",
    "p = display_dict['plotter']\n",
    "iplapsDataExplorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ac39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "# df = pd.DataFrame([curr_active_pipeline.registered_display_function_docs_dict])\n",
    "# df = curr_active_pipeline.registered_display_function_docs_dict\n",
    "df = pd.DataFrame.from_dict(curr_active_pipeline.registered_display_function_docs_dict, orient='index', columns=['Value'])\n",
    "display_widget = widgets.Output()\n",
    "with display_widget:\n",
    "\tdisplay(df)\n",
    "display_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import plot_position_curves_figure\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_long_short_laps', active_identifying_session_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# _out3 = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', included_epoch_indicies=None, save_figure=False)\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=False, included_epoch_indicies=selection_idxs_L[:50], enable_radon_transform_info=False, max_subplots_per_page=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_stacked_epoch_graphics.figures[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b3d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination_controller_L, pagination_controller_S = example_stacked_epoch_graphics.plot_data['controllers']\n",
    "ax_L, ax_S = example_stacked_epoch_graphics.axes\n",
    "final_figure_context_L, final_context_S = example_stacked_epoch_graphics.context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_3d\n",
    "# ## single_combined_plot == True mode (mode 1.):\n",
    "# p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=True)\n",
    "# p.show()\n",
    "\n",
    "## single_combined_plot == False mode (mode 2.):        \n",
    "p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=False, curr_num_subplots=len(curr_active_pipeline.sess.laps.lap_id), active_page_index=0)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ec90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_2d\n",
    "\n",
    "p_laps_2D, axs_laps_2D, laps_2D_pages = plot_lap_trajectories_2d(curr_active_pipeline.sess, curr_num_subplots=5, active_page_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ddaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_laps_2D.suptitle('plot_lap_trajectories_2d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c4da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = axs_laps_2D[0,0]\n",
    "ax_empty = axs_laps_2D[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_position_offset = 1.0 * long_track_dims.compute_position_offset(grid_bin_bounds=grid_bin_bounds) # array([49.43, 140.61])\n",
    "long_track_position_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_bin_bounds_center_point = (point_tuple_mid_point(grid_bin_bounds[0]), point_tuple_mid_point(grid_bin_bounds[1])) # (145.43, 140.61)\n",
    "print(f'grid_bin_bounds_center_point: {grid_bin_bounds_center_point}')\n",
    "x_midpoint, y_midpoint = grid_bin_bounds_center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77188bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_annotation_man = UserAnnotationsManager()\n",
    "user_annotations = user_annotation_man.annotations # .get_user_annotations()\n",
    "\n",
    "allow_interactive_selection = False\n",
    "\n",
    "final_context_L = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj')\n",
    "final_context_S = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj')\n",
    "# _out_pagination_controller.params.active_identifying_figure_ctx.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_L = final_context_L.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_S = final_context_S.adding_context(None,  user_annotation=\"selections\")\n",
    "\n",
    "## try to get the user annotations for this session:\n",
    "try:\n",
    "\tselection_idxs_L = user_annotations[selections_context_L]\n",
    "\tselection_idxs_S = user_annotations[selections_context_S]\n",
    "except KeyError as e:\n",
    "\tif allow_interactive_selection:\n",
    "\t\tprint(f'user annotations <good replay selections> are not found. Creating them interactively...')\n",
    "\t\tuser_annotations = interactive_good_epoch_selections(annotations_man=user_annotation_man, curr_active_pipeline=curr_active_pipeline)  # perform interactive selection. Should block here.\n",
    "\t\tselection_idxs_L = user_annotations[selections_context_L]\n",
    "\t\tselection_idxs_S = user_annotations[selections_context_S]\n",
    "\telse:\n",
    "\t\tprint(f'interactive annotation is not permitted. Failing.')\n",
    "\t\traise e\n",
    "except Exception as e:\n",
    "\tprint('Unhandled exception: {e}')\n",
    "\traise\n",
    "\n",
    "\n",
    "(selection_idxs_L, selection_idxs_S)\n",
    "# # for updating the filter_epochs_df (`filter_epochs_df`) from the selections:\n",
    "# self.filter_epochs_df['long_is_user_included'] = np.isin(self.filter_epochs_df.index, selection_idxs_L)\n",
    "# self.filter_epochs_df['short_is_user_included'] = np.isin(self.filter_epochs_df.index, selection_idxs_S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices_paginated, plot_decoded_epoch_slices, _subfn_update_decoded_epoch_slices\n",
    "\n",
    "\n",
    "## Stacked Epoch Plot\n",
    "defer_render=False\n",
    "save_figure=False\n",
    "included_epoch_indicies=selection_idxs_L[:50]\n",
    "enable_radon_transform_info=False\n",
    "max_subplots_per_page=25\n",
    "kwargs = {}\n",
    "\n",
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "## Extract variables from results object:\n",
    "long_results_obj, short_results_obj = curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "pagination_controller_L, active_out_figure_paths_L, final_context_L = plot_decoded_epoch_slices_paginated(curr_active_pipeline, long_results_obj, curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj'), included_epoch_indicies=included_epoch_indicies, save_figure=save_figure, **kwargs)\n",
    "fig_L = pagination_controller_L.plots.fig\n",
    "ax_L = fig_L.get_axes()\n",
    "if defer_render:\n",
    "\twidget_L = pagination_controller_L.ui.mw # MatplotlibTimeSynchronizedWidget\n",
    "\twidget_L.close()\n",
    "\tpagination_controller_L = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b89982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _subfn_update_decoded_epoch_slices(params, plots_data, plots, ui, debug_print=False):\n",
    "    \"\"\" attempts to update existing plots created by:\n",
    "    \n",
    "       params, plots_data, plots, ui = stacked_epoch_slices_matplotlib_build_view(epoch_slices, epoch_labels=epoch_labels, name=name, plot_function_name=plot_function_name, debug_test_max_num_slices=debug_test_max_num_slices, debug_print=debug_print)\n",
    "\n",
    "       Requires: `plots_data.filter_epochs_decoder_result`\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, curr_ax in enumerate(plots.axs):\n",
    "        curr_time_bin_container = plots_data.filter_epochs_decoder_result.time_bin_containers[i]\n",
    "        curr_time_bins = curr_time_bin_container.centers\n",
    "        curr_posterior_container = plots_data.filter_epochs_decoder_result.marginal_x_list[i]\n",
    "        curr_posterior = curr_posterior_container.p_x_given_n\n",
    "        curr_most_likely_positions = curr_posterior_container.most_likely_positions_1D\n",
    "        \n",
    "        params, plots_data, plots, ui = _helper_update_decoded_single_epoch_slice_plot(curr_ax, params, plots_data, plots, ui, i, curr_time_bins, curr_posterior, curr_most_likely_positions, debug_print=debug_print)\n",
    "        on_render_page_callbacks = params.get('on_render_page_callbacks', {})\n",
    "        for a_callback_name, a_callback in on_render_page_callbacks.items():\n",
    "            try:\n",
    "                params, plots_data, plots, ui = a_callback(curr_ax, params, plots_data, plots, ui, i, curr_time_bins, curr_posterior, curr_most_likely_positions, debug_print=debug_print)\n",
    "            except Exception as e:\n",
    "                print(f'\\t encountered exception in callback: {e}')\n",
    "                pass            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0190db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pagination_controller_S, active_out_figure_paths_S, final_context_S = plot_decoded_epoch_slices_paginated(curr_active_pipeline, short_results_obj, curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj'), included_epoch_indicies=included_epoch_indicies, save_figure=save_figure, **kwargs)\n",
    "fig_S = pagination_controller_S.plots.fig\n",
    "ax_S = fig_S.get_axes()\n",
    "if defer_render:\n",
    "\twidget_S = pagination_controller_S.ui.mw # MatplotlibTimeSynchronizedWidget\n",
    "\twidget_S.close()\n",
    "\tpagination_controller_S = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a222ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from neuropy.utils.mixins.binning_helpers import transition_matrix\n",
    "\n",
    "### 1D Transition Matrix:\n",
    "\n",
    "def _compute_position_transition_matrix(xbin_labels, binned_x: np.ndarray, n_powers:int=3):\n",
    "\t\"\"\"  1D Transition Matrix from binned positions (e.g. 'binned_x')\n",
    "\n",
    "\t\tpf1D.xbin_labels # array([  1,   2,   3,   4,  ...)\n",
    "\t\tpf1D.filtered_pos_df['binned_x'].to_numpy() # array([116, 115, 115, ...,  93,  93,  93], dtype=int64)\n",
    "\t\"\"\"\n",
    "\tnum_position_states = len(xbin_labels)\n",
    "\t# binned_x = pos_1D.to_numpy()\n",
    "\tbinned_x_indicies = binned_x - 1\n",
    "\tbinned_x_transition_matrix = transition_matrix(deepcopy(binned_x_indicies), markov_order=1, max_state_index=num_position_states)\n",
    "\t# binned_x_transition_matrix_higher_order_list = [binned_x_transition_matrix, transition_matrix(deepcopy(binned_x_indicies), markov_order=2, max_state_index=num_position_states), transition_matrix(deepcopy(binned_x_indicies), markov_order=3, max_state_index=num_position_states)]\n",
    "\n",
    "\tbinned_x_transition_matrix[np.isnan(binned_x_transition_matrix)] = 0.0\n",
    "\tbinned_x_transition_matrix_higher_order_list = [binned_x_transition_matrix] + [np.linalg.matrix_power(binned_x_transition_matrix, n) for n in np.arange(2, n_powers+1)]\n",
    "\t# , np.linalg.matrix_power(binned_x_transition_matrix, 2), np.linalg.matrix_power(binned_x_transition_matrix, 3)\n",
    "\t# binned_x_transition_matrix.shape # (64, 64)\n",
    "\treturn binned_x_transition_matrix_higher_order_list\n",
    "\n",
    "def _build_decoded_positions_transition_matrix(active_one_step_decoder):\n",
    "\t\"\"\" Compute the transition_matrix from the decoded positions \n",
    "\n",
    "\tTODO: make sure that separate events (e.g. separate replays) are not truncated creating erronious transitions\n",
    "\n",
    "\t\"\"\"\n",
    "\t# active_time_window_variable = active_one_step_decoder.time_window_centers # get time window centers (n_time_window_centers,) # (4060,)\n",
    "\t# active_most_likely_positions = active_one_step_decoder.most_likely_positions.T # (4060, 2) NOTE: the most_likely_positions for the active_one_step_decoder are tranposed compared to the active_two_step_decoder\n",
    "\t# active_most_likely_positions = active_two_step_decoder.most_likely_positions # (2, 4060)\n",
    "\tactive_one_step_decoder.most_likely_position_flat_indicies\n",
    "\t# active_most_likely_positions = active_one_step_decoder.revised_most_likely_positions.T\n",
    "\t# active_most_likely_positions #.shape # (36246,)\n",
    "\n",
    "\tmost_likely_position_indicies = np.squeeze(np.array(np.unravel_index(active_one_step_decoder.most_likely_position_flat_indicies, active_one_step_decoder.original_position_data_shape))) # convert back to an array\n",
    "\tmost_likely_position_xbins = most_likely_position_indicies + 1 # add 1 to convert back to a bin label from an index\n",
    "\t# most_likely_position_indicies # (1, 36246)\n",
    "\n",
    "\txbin_labels = np.arange(active_one_step_decoder.original_position_data_shape[0]) + 1\n",
    "\n",
    "\tdecoded_binned_x_transition_matrix_higher_order_list = _compute_position_transition_matrix(xbin_labels, most_likely_position_indicies)\n",
    "\treturn decoded_binned_x_transition_matrix_higher_order_list, xbin_labels\n",
    "\n",
    "\n",
    "# pf1D = deepcopy(curr_active_pipeline.computation_results['maze1'].computed_data['pf1D'])\n",
    "pf1D = deepcopy(global_pf1D)\n",
    "# pf1D = deepcopy(short_pf1D)\n",
    "# pf1D = deepcopy(long_pf1D)\n",
    "binned_x_transition_matrix_higher_order_list = _compute_position_transition_matrix(pf1D.xbin_labels, pf1D.filtered_pos_df['binned_x'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1D.filtered_pos_df.plot(x='t',y='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb355dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization ______________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "out = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[0], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix', title=\"Transition Matrix for binned x (from, to)\", variable_label='Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n",
    "# out.add_data(row=1, col=0, matrix=active_eloy_analysis.pf_overlapDensity_2D, xbins=active_pf_2D_dt.xbin_labels, ybins=active_pf_2D_dt.ybin_labels, name='pf_overlapDensity', title='pf overlapDensity metric', variable_label='pf overlapDensity')\n",
    "\n",
    "# out.add_data(row=1, col=0, matrix=binned_x_transition_matrix_higher_order_list[1], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^2', title='2nd Order Transition Matrix for binned x (from, to)', variable_label='2nd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n",
    "# out.add_data(row=2, col=0, matrix=binned_x_transition_matrix_higher_order_list[2], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^3', title='3rd Order Transition Matrix for binned x (from, to)', variable_label='3rd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n",
    "\n",
    "# Separate Windows for each:\n",
    "# out2 = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[1], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix^2', title=\"2nd Order Transition Matrix for binned x (from, to)\", variable_label='2nd Order Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n",
    "# out3 = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[2], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix^3', title=\"3rd Order Transition Matrix for binned x (from, to)\", variable_label='3rd Order Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e5f54",
   "metadata": {},
   "source": [
    "# 1. Compute the transition_matrix from the decoded positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e5db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayesianPlacemapPositionDecoder\n",
    "# active_one_step_decoder = deepcopy(long_one_step_decoder_1D) # long_results_obj.original_1D_decoder\n",
    "long_decoded_binned_x_transition_matrix_higher_order_list, long_xbin_labels = _build_decoded_positions_transition_matrix(active_one_step_decoder=deepcopy(long_one_step_decoder_1D))\n",
    "short_decoded_binned_x_transition_matrix_higher_order_list, short_xbin_labels = _build_decoded_positions_transition_matrix(active_one_step_decoder=deepcopy(short_one_step_decoder_1D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcddd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_decoded = BasicBinnedImageRenderingWindow(decoded_binned_x_transition_matrix_higher_order_list[0], active_one_step_decoder.xbin_centers, active_one_step_decoder.xbin_centers, name='decoded_binned_x_transition_matrix', title=\"DECODED Transition Matrix for binned x (from, to)\", variable_label='Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea34522",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "out = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[i], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix', title=\"Transition Matrix for binned x (from, to)\", variable_label='Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n",
    "out.add_data(row=1, col=0, matrix=long_decoded_binned_x_transition_matrix_higher_order_list[i], xbins=long_xbin_labels, ybins=long_xbin_labels, name='long_decoded_binned_x_transition_matrix', title='Long DECODED Transition Matrix', variable_label='long decoded')\n",
    "out.add_data(row=2, col=0, matrix=short_decoded_binned_x_transition_matrix_higher_order_list[i], xbins=short_xbin_labels, ybins=short_xbin_labels, name='short_decoded_binned_x_transition_matrix', title='Short DECODED Transition Matrix', variable_label='short decoded')\n",
    "# out.add_data(row=1, col=0, matrix=binned_x_transition_matrix_higher_order_list[1], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^2', title='2nd Order Transition Matrix for binned x (from, to)', variable_label='2nd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n",
    "# out.add_data(row=2, col=0, matrix=binned_x_transition_matrix_higher_order_list[2], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^3', title='3rd Order Transition Matrix for binned x (from, to)', variable_label='3rd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.most_likely_position_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 2. Use the position transition matrix to determine how likely each decoded position's transition is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87cd169",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_binned_instantaneous_unit_specific_spike_rate = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.time_binned_instantaneous_unit_specific_spike_rate\n",
    "timestamps = time_binned_instantaneous_unit_specific_spike_rate.time_bins\n",
    "\n",
    "value_df = time_binned_instantaneous_unit_specific_spike_rate.instantaneous_unit_specific_spike_rate_values\n",
    "value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0807be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of spikes version:\n",
    "time_binned_unit_specific_spike_rate = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.time_binned_unit_specific_spike_rate\n",
    "timestamps = time_binned_unit_specific_spike_rate.time_bins\n",
    "value_df = time_binned_unit_specific_spike_rate.time_binned_unit_specific_binned_spike_rate\n",
    "value_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265e769",
   "metadata": {},
   "source": [
    "# 2023-10-12 - Ultimate Linear Track Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cc7eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines, add_track_shapes, test_LinearTrackDimensions_2D_pyqtgraph\n",
    "from neuropy.utils.mathutil import contiguous_regions, threshPeriods, compute_grid_bin_bounds, map_value\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import test_LinearTrackDimensions_2D_Matplotlib\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackInstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.path import Path\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import _build_track_1D_verticies\n",
    "\n",
    "path = _build_track_1D_verticies(platform_length=22.0, track_length=70.0, track_1D_height=1.0, platform_1D_height=1.1, track_center_midpoint_x=135.0, track_center_midpoint_y=0.0, debug_print=False)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "patch = patches.PathPatch(path, facecolor='orange', lw=2)\n",
    "ax.add_patch(patch)\n",
    "ax.autoscale()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad73e26",
   "metadata": {},
   "source": [
    "## Test getting grid_bin_bounds for all sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd69170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphocorehelpers.geometry_helpers import BoundsRect, point_tuple_mid_point, map_value\n",
    "\n",
    "# Hardcoded included_session_contexts:\n",
    "included_session_contexts = [\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'), # prev completed\n",
    "]\n",
    "\n",
    "## Get specific grid_bin_bounds overrides from UserAnnotationsManager:\n",
    "session_grid_bin_bounds = [BoundsRect.init_from_grid_bin_bounds(UserAnnotationsManager.get_hardcoded_specific_session_override_dict().get(a_ctxt, {}).get('grid_bin_bounds', None)) for a_ctxt in included_session_contexts]\n",
    "session_grid_bin_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e88adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_rect = session_grid_bin_bounds[0]\n",
    "[a_rect.center_point[0] for a_rect in session_grid_bin_bounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c155f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_rect.center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b9378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
