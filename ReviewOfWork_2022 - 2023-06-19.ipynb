{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39239c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import neptune # for logging progress and results\n",
    "from pyphoplacecellanalysis.General.Batch.NeptuneAiHelpers import set_environment_variables, neptune_output_figures\n",
    "neptune_kwargs = {'project':\"commander.pho/PhoDibaLongShort2023\",\n",
    "'api_token':\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGIxODU2My1lZTNhLTQ2ZWMtOTkzNS02ZTRmNzM5YmNjNjIifQ==\"}\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from attrs import define, field, fields, Factory\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import CodeConversion\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible, print_value_overview_only, document_active_variables, objsize, print_object_memory_usage, debug_dump_object_member_shapes, TypePrintMode\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "\n",
    "from pyphocorehelpers.print_helpers import generate_html_string\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot, create_daily_programmatic_display_function_testing_folder_if_needed, session_context_to_relative_path\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import build_pyqtgraph_epoch_indicator_regions # Add session indicators to pyqtgraph plot\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _helper_add_long_short_session_indicator_regions\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "# 'time_bin_indices': valid_time_bin_indicies, 'posterior_to_pf_mean_surprise': one_left_out_posterior_to_pf_surprises_mean, 'posterior_to_scrambled_pf_mean_surprise': one_left_out_posterior_to_scrambled_pf_surprises_mean}\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_long_short_expected_vs_observed_firing_rates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_long_short_surprise_difference_plot\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import _update_pipeline_missing_preprocessing_parameters\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "\n",
    "from scripts.run_BatchAnalysis import post_compute_validate, _on_complete_success_execution_session\n",
    "\n",
    "session_batch_status = {}\n",
    "session_batch_errors = {}\n",
    "enable_saving_to_disk = False\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle.pkl.\n",
      "property already present in pickled version. No need to save.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\output\\global_computation_results.pkl... done.\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "#     neuropy/data_session_pre_processing_scripts/KDIBA/IIDataMat_Export_ToPython_2022_08_01.m\n",
    "# From pre-computed .mat files:\n",
    "\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "good_contexts_list = [\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54')\n",
    "]\n",
    "\n",
    "# %%viztracer\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # DONE. Very good. Many good Pfs, many good replays.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays!\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3') # DONE, Good Pfs, no good epochs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # BAD, Good Pfs strangely despite horrible map, no good epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # DONE\n",
    "\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "\n",
    "\n",
    "    # ==================================================================================================================== #\n",
    "    # Load Pipeline                                                                                                        #\n",
    "    # ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=[#'_perform_estimated_epochs_computation',  # AL:WAYS OFF\n",
    "                                            '_perform_baseline_placefield_computation',\n",
    "                                        # '_perform_time_dependent_placefield_computation', # AL:WAYS OFF\n",
    "                                        '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        # '_perform_time_dependent_pf_sequential_surprise_computation' # AL:WAYS OFF\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding' # AL:WAYS OFF\n",
    "                                    ]\n",
    "# active_computation_functions_name_includelist=['_perform_baseline_placefield_computation']\n",
    "\n",
    "curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        curr_active_pipeline.load_pickled_global_computation_results()\n",
    "    except Exception as e:\n",
    "        print(f'cannot load global results: {e}')\n",
    "\n",
    "# 6m 1.1s\n",
    "# 12m 15.6s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8aab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "from neuropy.utils.matplotlib_helpers import interactive_select_grid_bin_bounds_2D\n",
    "# fig, ax, rect_selector, set_extents = interactive_select_grid_bin_bounds_2D(curr_active_pipeline, epoch_name='maze', should_block_for_input=True)\n",
    "\n",
    "grid_bin_bounds = interactive_select_grid_bin_bounds_2D(curr_active_pipeline, epoch_name='maze', should_block_for_input=True, should_apply_updates_to_pipeline=False)\n",
    "print(f'grid_bin_bounds: {grid_bin_bounds}')\n",
    "print(f\"Add this to `specific_session_override_dict`:\\n\\n{curr_active_pipeline.get_session_context().get_initialization_code_string()}:dict(grid_bin_bounds=({(grid_bin_bounds[0], grid_bin_bounds[1]), (grid_bin_bounds[2], grid_bin_bounds[3])})),\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a29b890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "were pipeline preprocessing parameters missing and updated?: False\n"
     ]
    }
   ],
   "source": [
    "## Post Compute Validate 2023-05-16:\n",
    "from scripts.run_BatchAnalysis import post_compute_validate\n",
    "\n",
    "post_compute_validate(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7f4bc79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis already computed.\n",
      "long_short_fr_indicies_analyses already computed.\n",
      "long_short_decoding_analyses already computed.\n",
      "long_short_post_decoding already computed.\n",
      "done with all batch_extended_computations(...).\n",
      "no changes in global results.\n"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "extended_computations_include_includelist=['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'] # do only specifiedl , 'long_short_rate_remapping'\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "# extended_computations_include_includelist=['long_short_post_decoding'] # do only specifiedl\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=force_recompute_global, debug_print=False)\n",
    "if len(newly_computed_values) > 0:\n",
    "\tprint(f'newly_computed_values: {newly_computed_values}. Saving global results...')\n",
    "\ttry:\n",
    "\t\t# curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "\t\t# Try to write out the global computation function results:\n",
    "\t\tcurr_active_pipeline.save_global_computation_results()\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "\t\tprint(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "\tprint(f'no changes in global results.')\n",
    "# 10m 29.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "neptuner = batch_perform_all_plots(curr_active_pipeline, enable_neptune=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e7106ef",
   "metadata": {},
   "source": [
    "### Pipeline Loading/Saving [Optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f3fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE) # AttributeError: 'PfND_TimeDependent' object has no attribute '_included_thresh_neurons_indx'\n",
    "# TypeError: cannot pickle 'MplMultiTab' object\n",
    "# PicklingError: Can't pickle .set_closure_cell at 0x000002BF248F50D0>: it's not found as attr._compat.make_set_closure_cell..set_closure_cell\n",
    "# TypeError: cannot pickle 'PyQt5.QtCore.pyqtSignal' object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c2afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results() # PicklingError: Can't pickle .set_closure_cell at 0x000002BF248F50D0>: it's not found as attr._compat.make_set_closure_cell..set_closure_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.load_pickled_global_computation_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241dc49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba716fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c850782f",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dda48261",
   "metadata": {
    "tags": [
     "load",
     "ACTIVE"
    ]
   },
   "outputs": [],
   "source": [
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "## Extract variables from results object:\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global\n",
    "\n",
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result['Flat_epoch_time_bins_mean'], expected_v_observed_result['Flat_decoder_time_bin_centers'], expected_v_observed_result['num_neurons'], expected_v_observed_result['num_timebins_in_epoch'], expected_v_observed_result['num_total_flat_timebins'], expected_v_observed_result['is_short_track_epoch'], expected_v_observed_result['is_long_track_epoch'], expected_v_observed_result['short_short_diff'], expected_v_observed_result['long_long_diff']\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8de2e3da",
   "metadata": {},
   "source": [
    "# 2023-05-19 - Testing S-only emergence, L-only replays in S, peak position remappings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d082385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership, SetPartition\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import TrackExclusivePartitionSubset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# @define(slots=False)\n",
    "# class TrackPartitioningResult:\n",
    "# \tis_S_pf_only: np.ndarray\n",
    "# \tis_S_only: np.ndarray\n",
    "# \tS_only_aclus: np.ndarray\n",
    "# \tS_only_df: pd.DataFrame\n",
    "\n",
    "# Four distinct subgroups are formed:  pf on neither, pf on both, pf on only long, pf on only short\n",
    "# L_only_aclus, S_only_aclus\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions()\n",
    "\n",
    "# neuron_replay_stats_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df.copy()\n",
    "# neuron_replay_stats_df\n",
    "# neuron_replay_stats_df.sort_values(by=['long_pf_peak_x'], inplace=False, ascending=True)\n",
    "\n",
    "# ## 2023-05-19 - Get S-only pfs\n",
    "# is_S_pf_only = np.logical_and(np.logical_not(neuron_replay_stats_df['has_long_pf']), neuron_replay_stats_df['has_short_pf'])\n",
    "# _is_S_only = neuron_replay_stats_df.track_membership == SplitPartitionMembership.RIGHT_ONLY\n",
    "# assert (is_S_pf_only == _is_S_only).all()\n",
    "# S_only_aclus = neuron_replay_stats_df.index[_is_S_only].to_numpy()\n",
    "# S_only_df = neuron_replay_stats_df[is_S_pf_only]\n",
    "\n",
    "# ## Show L-only pfs stop replaying on S\n",
    "# is_L_pf_only = np.logical_and(np.logical_not(neuron_replay_stats_df['has_short_pf']), neuron_replay_stats_df['has_long_pf'])\n",
    "# _is_L_only = neuron_replay_stats_df.track_membership == SplitPartitionMembership.LEFT_ONLY\n",
    "# assert (is_L_pf_only == _is_L_only).all()\n",
    "# L_only_aclus = neuron_replay_stats_df.index[_is_L_only].to_numpy()\n",
    "# L_only_df = neuron_replay_stats_df[_is_L_only]\n",
    "\n",
    "\n",
    "# ## For ('kdiba', 'gor01', 'one', '2006-6-09_1-22-43') - Have L-only cells [24, 98] that have ['short_num_replays'] = [8, 7]. We were hoping that there would be few to no replays on the S-track that involved L-only cells.\n",
    "# ## 2023-05-23 - Get Common (SHARED) placefields\n",
    "# ## Goal 1: From the cells with the placefields on both tracks, compute the degree to which they remap in position and sort them according to their distance.\n",
    "# is_BOTH_pf_only = np.logical_and(neuron_replay_stats_df['has_short_pf'], neuron_replay_stats_df['has_long_pf']) # (63,)\n",
    "# BOTH_pf_only_aclus = neuron_replay_stats_df.index[is_BOTH_pf_only].to_numpy()\n",
    "\n",
    "# ## NOTE: is_BOTH_pf_only is a much more stringent requirement (and a strict subset) than `is_BOTH_only`\n",
    "# _is_BOTH_only = neuron_replay_stats_df.track_membership == SplitPartitionMembership.SHARED # (99,)\n",
    "# _BOTH_only_aclus = neuron_replay_stats_df.index[_is_BOTH_only].to_numpy()\n",
    "# assert _BOTH_only_aclus.shape[0] >= BOTH_pf_only_aclus.shape[0]\n",
    "\n",
    "# BOTH_pf_only_df = neuron_replay_stats_df[is_BOTH_pf_only].copy()\n",
    "# BOTH_pf_only_df['long_short_pf_peak_x_displacement'] = BOTH_pf_only_df['long_pf_peak_x'].values - BOTH_pf_only_df['short_pf_peak_x'].values\n",
    "# BOTH_pf_only_df['long_short_pf_peak_x_distance'] = BOTH_pf_only_df['long_short_pf_peak_x_displacement'].abs()\n",
    "# BOTH_pf_only_df.sort_values(by=['long_short_pf_peak_x_distance'], inplace=True, ascending=False)\n",
    "# BOTH_pf_only_df\n",
    "\n",
    "# #TODO 2023-05-23 - Can do more detailed peaks analysis with: long_results.RatemapPeaksAnalysis and short_results.RatemapPeaksAnalysis\n",
    "\n",
    "# # 2023-06-19 - Look at the Long and Short only aclus and find replays in which they replay\n",
    "# # L_only_aclus, S_only_aclus\n",
    "\n",
    "# # long_replays\n",
    "\n",
    "# is_EITHER_pf_only = np.logical_or(neuron_replay_stats_df['has_short_pf'], neuron_replay_stats_df['has_long_pf']) # (63,)\n",
    "# EITHER_pf_only_aclus = neuron_replay_stats_df.index[is_EITHER_pf_only].to_numpy()\n",
    "\n",
    "# exclusive_aclus = np.hstack((L_only_aclus, S_only_aclus)) # [  2,   8,  19,  28,  36,  54,  63,  68,  73,  74, 109,   4,  13,  21,  23,  52,  58,  67,  70,  81]\n",
    "# exclusive_aclus\n",
    "\n",
    "\n",
    "# is_XOR_pf_only = np.logical_xor(neuron_replay_stats_df['has_short_pf'], neuron_replay_stats_df['has_long_pf'])\n",
    "# # XOR_pf_only_aclus = np.hstack((L_only_aclus, S_only_aclus))\n",
    "# XOR_pf_only_aclus = neuron_replay_stats_df.index[is_XOR_pf_only].to_numpy()\n",
    "# XOR_only_df = neuron_replay_stats_df[is_XOR_pf_only]\n",
    "# # find the cells that fire in each replay. I think this is already computed/used somewhere\n",
    "\n",
    "# is_NEITHER_pf_only = np.logical_and(np.logical_not(neuron_replay_stats_df['has_short_pf']), np.logical_not(neuron_replay_stats_df['has_long_pf'])) # (63,)\n",
    "# NEITHER_pf_only_aclus = neuron_replay_stats_df.index[is_NEITHER_pf_only].to_numpy()\n",
    "# NEITHER_pf_only_aclus\n",
    "\n",
    "# # is_S_pf_only, is_L_pf_only, is_BOTH_pf_only, is_EITHER_pf_only\n",
    "# # S_only_aclus, L_only_aclus, BOTH_pf_only_aclus, EITHER_pf_only_aclus\n",
    "# # S_only_df, L_only_df, BOTH_pf_only_df\n",
    "# short_exclusive = TrackExclusivePartitionSubset(is_S_pf_only, S_only_aclus, S_only_df)\n",
    "# long_exclusive = TrackExclusivePartitionSubset(is_L_pf_only, L_only_aclus, L_only_df)\n",
    "# BOTH_subset = TrackExclusivePartitionSubset(is_BOTH_pf_only, BOTH_pf_only_aclus, BOTH_pf_only_df)\n",
    "# EITHER_subset = TrackExclusivePartitionSubset(is_EITHER_pf_only, EITHER_pf_only_aclus, BOTH_pf_only_df)\n",
    "# XOR_subset = TrackExclusivePartitionSubset(is_XOR_pf_only, XOR_pf_only_aclus, XOR_only_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd91c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _prepare_spikes_df_from_filter_epochs\n",
    "# approach copied from `pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations._epoch_unit_avg_firing_rates`\n",
    "from pyphocorehelpers.indexing_helpers import partition\n",
    "\n",
    "\n",
    "def _find_example_epochs(spikes_df, filter_epochs, exclusive_aclus, included_neuron_ids=None):\n",
    "\tif included_neuron_ids is None:\n",
    "\t\tincluded_neuron_ids = spikes_df.spikes.neuron_ids\n",
    "\n",
    "\tif isinstance(filter_epochs, pd.DataFrame):\n",
    "\t\tfilter_epochs_df = filter_epochs\n",
    "\telse:\n",
    "\t\tfilter_epochs_df = filter_epochs.to_dataframe()\n",
    "\t\t\n",
    "\tfilter_epoch_spikes_df = deepcopy(spikes_df)\n",
    "\tfilter_epoch_spikes_df = _prepare_spikes_df_from_filter_epochs(filter_epoch_spikes_df, filter_epochs=filter_epochs_df, included_neuron_ids=included_neuron_ids, epoch_id_key_name='replay_epoch_id', debug_print=False) # replay_epoch_id\n",
    "\n",
    "\tunique_replay_epoch_id_values, epoch_split_spikes_df_list = partition(filter_epoch_spikes_df, 'replay_epoch_id')\n",
    "\t# filter_epoch_spikes_df.groupby('replay_epoch_id')\n",
    "\t# unique_replay_epoch_id_values # (198,)\n",
    "\tepoch_spikes_unique_aclus_list = [] # a list of each aclu that fires at least once in the epoch\n",
    "\tepoch_contains_any_exclusive_aclus = []\n",
    "\n",
    "\tfor an_epoch_id, epoch_specific_spikes_df in zip(unique_replay_epoch_id_values, epoch_split_spikes_df_list):\n",
    "\t\t# Loop through the epochs\n",
    "\t\t# find epochs containing at least one in `exclusive_aclus`:\n",
    "\t\tepoch_spikes_unique_aclus = epoch_specific_spikes_df.aclu.unique()\n",
    "\t\tepoch_spikes_unique_aclus_list.append(epoch_spikes_unique_aclus)\n",
    "\t\t# epoch_spikes_unique_aclus # finds lists of all the active aclus in the given epoch\n",
    "\t\tif len(epoch_spikes_unique_aclus) > 0:\t\n",
    "\t\t\tepoch_contains_any_exclusive_aclus.append(np.isin(epoch_spikes_unique_aclus, exclusive_aclus).any())\n",
    "\t\telse:\n",
    "\t\t\tepoch_contains_any_exclusive_aclus.append(False)\n",
    "\t\t# epoch_contains_any_exclusive_aclus # returns True if the epoch contains one ore more spikes from the search list `exclusive_aclus`\n",
    "\n",
    "\tassert len(epoch_contains_any_exclusive_aclus) == np.shape(filter_epochs_df)[0]\n",
    "\tfilter_epochs_df['contains_one_exclusive_aclu'] = epoch_contains_any_exclusive_aclus # adds the appropriate column to the filter_epochs_df\n",
    "\treturn filter_epoch_spikes_df, filter_epochs_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# included_neuron_ids = deepcopy(exclusive_aclus)\n",
    "# included_neuron_ids = None\n",
    "included_neuron_ids = EITHER_pf_only_aclus\n",
    "spikes_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.spikes_df).spikes.sliced_by_neuron_type('pyr')\n",
    "# filter_epochs = deepcopy(curr_active_pipeline.sess.replay)\n",
    "# spikes_df = deepcopy(long_results_obj.spikes_df) # LeaveOneOutDecodingAnalysisResult\n",
    "# spikes_df[np.isin(spikes_df.aclu, included_neuron_ids)]\n",
    "filter_epochs = deepcopy(long_results_obj.active_filter_epochs)\n",
    "\n",
    "filter_epoch_spikes_df, filter_epochs_df = _find_example_epochs(spikes_df, filter_epochs, exclusive_aclus, included_neuron_ids=included_neuron_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fce367",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 24 cells, 133 Epochs, 789 Total Timebins\n",
    "# Other\n",
    "\t\n",
    "\t- is_non_firing_time_bin: numpy.ndarray - (24, 789)\n",
    "\t- all_epochs_num_epoch_time_bins: numpy.ndarray - (133,)\n",
    "\t\n",
    "    ## Indexing Helpers:\n",
    "\t\t- all_epochs_reverse_flat_epoch_indicies_array: numpy.ndarray - (789,)\n",
    "\t\t- split_by_epoch_reverse_flattened_time_bin_indicies: list - (133,)\n",
    "    \n",
    "\t- original_1D_decoder: pyphoplacecellanalysis.Analysis.Decoder.reconstruction.BasePositionDecoder\n",
    "\t\t- pf: neuropy.analyses.placefields.PfND\n",
    "\t\t- neuron_IDXs: numpy.ndarray - (24,)\n",
    "\t\t- neuron_IDs: numpy.ndarray - (24,)\n",
    "\t\t- F: numpy.ndarray - (119, 24)\n",
    "\t\t- P_x: numpy.ndarray - (119, 1)\n",
    "        \n",
    "\t- flat_all_epochs_decoded_epoch_time_bins: numpy.ndarray - (24, 789)\n",
    "\n",
    "# Measured\n",
    "\t- flat_all_epochs_measured_cell_spike_counts: numpy.ndarray - (24, 789)\n",
    "\t- flat_all_epochs_measured_cell_firing_rates: numpy.ndarray - (24, 789)\n",
    "\n",
    "\n",
    "# Expected\n",
    "\t- flat_all_epochs_computed_expected_cell_firing_rates: numpy.ndarray - (24, 789)\n",
    "\t- flat_all_epochs_difference_from_expected_cell_spike_counts: numpy.ndarray - (24, 789)\n",
    "\t- flat_all_epochs_difference_from_expected_cell_firing_rates: numpy.ndarray - (24, 789)\n",
    "    \n",
    "    \n",
    "    \n",
    "## Epoch-based\n",
    "\t- all_epochs_decoded_epoch_time_bins_mean: numpy.ndarray - (133, 24)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "- flat_all_epochs_measured_cell_firing_rates: numpy.ndarray - .shape: (24, 789) \n",
    "- flat_all_epochs_computed_expected_cell_firing_rates: numpy.ndarray - .shape: (24, 789)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fe80559",
   "metadata": {},
   "source": [
    "# 2023-04-13 - Find Good looking epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa9a519",
   "metadata": {
    "tags": [
     "ACTIVE_NOW"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_identifying_ctx_string: \"kdiba|gor01|two|2006-6-07_16-40-19|1of1|[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132]\"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "curr_results_obj = long_results_obj\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context()\n",
    "_out_pagination_controller = DecodedEpochSlicesPaginatedFigureController.init_from_decoder_data(curr_results_obj.active_filter_epochs, curr_results_obj.all_included_filter_epochs_decoder_result, \n",
    "\txbin=curr_results_obj.original_1D_decoder.xbin, global_pos_df=global_session.position.df, a_name='TestDecodedEpochSlicesPaginationController', active_context=active_identifying_session_ctx,  max_subplots_per_page=200) # 10\n",
    "# _out_pagination_controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5280cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting selections out of DecoedEpochSlicesPaginationController\n",
    "curr_active_pipeline.display_output_history_list\n",
    "# Ideally could search like: '_display_long_and_short_stacked_epoch_slices'\n",
    "active_result_backup = curr_active_pipeline.last_added_display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f7829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(active_result_backup.keys()) # ['name', 'context', 'figures', 'axes', 'plot_data']\n",
    "\n",
    "active_result_backup['context'] # (IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-08_14-26-15', 'DecodedEpochSlices', 'replays', 'long_results_obj')>,\n",
    "\t\t\t\t\t\t\t\t#  IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-08_14-26-15', 'DecodedEpochSlices', 'replays', 'short_results_obj')>)\n",
    "\n",
    "pagination_controllers = active_result_backup.plot_data['controllers']\n",
    "long_controller = pagination_controllers[0]\n",
    "short_controller = pagination_controllers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e85d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_controller.selected_indicies # np.array([ 13,  14,  15,  25,  27,  28,  31,  37,  42,  45,  48,  57,  61,  62,  63,  76,  79,  82,  89,  90, 111, 112, 113, 115])\n",
    "\n",
    "# np.array([5,  13,  15,  17,  20,  21,  24,  31,  33,  43,  44,  49,  63, 64,  66,  68,  70,  71,  74,  76,  77,  78,  84,  90,  94,  95, 104, 105, 122, 123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_controller.selected_indicies # np.array([  9,  11,  13,  14,  15,  20,  22,  25,  37,  40,  45,  48,  61, 62,  76,  79,  84,  89,  90,  93,  94, 111, 112, 113, 115, 121])\n",
    "\n",
    "# np.array([ 12,  13,  15,  17,  20,  24,  30,  31,  32,  33,  41,  43,  49, 54,  55,  68,  70,  71,  73,  76,  77,  78,  84,  89,  94, 100, 104, 105, 111, 114, 115, 117, 118, 122, 123, 131])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd5bcc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_context_L = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj')\n",
    "final_context_S = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj')\n",
    "# _out_pagination_controller.params.active_identifying_figure_ctx.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_L = final_context_L.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_S = final_context_S.adding_context(None,  user_annotation=\"selections\")\n",
    "\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='long_results_obj',user_annotation='selections')\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='short_results_obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd249e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the `long_results_obj.active_filter_epochs` and `short_results_obj.active_filter_epochs` objects with the selection information\n",
    "assert long_controller.is_selected.shape[0] == long_results_obj.active_filter_epochs.n_epochs\n",
    "assert short_controller.is_selected.shape[0] == short_results_obj.active_filter_epochs.n_epochs\n",
    "# for some reason the active_filter_epochs on both the long and the short objects contain properties about the other one as well, so keep with tradition and add them to both as well\n",
    "long_results_obj.active_filter_epochs._df['long_is_user_included'] = long_controller.is_selected\n",
    "long_results_obj.active_filter_epochs._df['short_is_user_included'] = short_controller.is_selected\n",
    "short_results_obj.active_filter_epochs._df['long_is_user_included'] = long_controller.is_selected\n",
    "short_results_obj.active_filter_epochs._df['short_is_user_included'] = short_controller.is_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636184b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(long_controller.params.keys())) # ['name', 'window_title', 'num_slices', '_debug_test_max_num_slices', 'active_num_slices', 'global_epoch_start_t', 'global_epoch_end_t', 'single_plot_fixed_height', 'all_plots_height', 'epoch_labels', 'variable_name', 'xbin', 'enable_flat_line_drawing', 'debug_print', 'active_identifying_figure_ctx', 'flat_all_data_indicies', 'is_selected', 'callback_id', 'on_render_page_callbacks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d5dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_controller.selected_epoch_times\n",
    "# array([[ 292.62367098,  292.80826736],\n",
    "#        [ 528.48329294,  528.68561475],\n",
    "#        [ 572.24842637,  572.44236163],\n",
    "#        [ 677.99306343,  678.25522777],\n",
    "#        [ 802.91157867,  803.11436129],\n",
    "#        [ 831.70962856,  831.90743454],\n",
    "#        [ 888.22678107,  888.46492239],\n",
    "#        [ 945.48035303,  945.68543965],\n",
    "#        [ 954.00517939,  954.2546871 ],\n",
    "#        [1033.05203044, 1033.22639707],\n",
    "#        [1061.35727035, 1061.5943979 ],\n",
    "#        [1214.61082388, 1214.834834  ],\n",
    "#        [1722.78022002, 1722.95406441],\n",
    "#        [1741.58530479, 1741.79413924],\n",
    "#        [1743.25171034, 1743.53445707]])\n",
    "short_controller.selected_epoch_times\n",
    "# array([[ 489.42507549,  489.65575186],\n",
    "#        [ 528.48329294,  528.68561475],\n",
    "#        [ 572.24842637,  572.44236163],\n",
    "#        [ 677.99306343,  678.25522777],\n",
    "#        [ 802.91157867,  803.11436129],\n",
    "#        [ 888.22678107,  888.46492239],\n",
    "#        [ 931.21227202,  931.45262518],\n",
    "#        [ 945.48035303,  945.68543965],\n",
    "#        [ 950.18327543,  950.44046313],\n",
    "#        [ 954.00517939,  954.2546871 ],\n",
    "#        [1024.83173129, 1025.10320379],\n",
    "#        [1033.05203044, 1033.22639707],\n",
    "#        [1214.61082388, 1214.834834  ],\n",
    "#        [1326.54476977, 1326.76506278],\n",
    "#        [1329.84606216, 1330.0684134 ],\n",
    "#        [1732.09310613, 1732.29060491],\n",
    "#        [1741.58530479, 1741.79413924],\n",
    "#        [1743.25171034, 1743.53445707],\n",
    "#        [1751.03108555, 1751.22059714],\n",
    "#        [1769.90424581, 1770.10497019],\n",
    "#        [1776.56793264, 1776.78871716],\n",
    "#        [1871.00426701, 1871.21629634],\n",
    "#        [1917.09385877, 1917.2703758 ],\n",
    "#        [1994.07242543, 1994.2525367 ],\n",
    "#        [2038.53127755, 2038.70899266],\n",
    "#        [2064.36693792, 2064.54016792],\n",
    "#        [2111.52742834, 2111.80120484],\n",
    "#        [2125.54830564, 2125.73772506]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab793819",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_results_obj.active_filter_epochs.n_epochs # 122"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eacd1d90",
   "metadata": {},
   "source": [
    "# TODO 2023-06-19 14:31: - [ ] Come up with system for storing user-annotations:\n",
    " Need to store user-annotations and labeled selections for Epochs:\n",
    "\n",
    "\tdate_annotated: datetime - the date the annotations were made\n",
    "\tannotation_author: str - the person who made the annotations\n",
    "\tannotation_content: Any - the content of the annotation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b97c7348",
   "metadata": {
    "tags": [
     "user_annotations",
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Mixins.PaginationMixins import SelectionsObject\n",
    "\n",
    "user_annotations = {}\n",
    "\n",
    "## IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15')\n",
    "user_annotations[IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='long_results_obj',user_annotation='selections')] = np.array([ 13,  14,  15,  25,  27,  28,  31,  37,  42,  45,  48,  57,  61,  62,  63,  76,  79,  82,  89,  90, 111, 112, 113, 115])\n",
    "user_annotations[IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='short_results_obj',user_annotation='selections')] = np.array([  9,  11,  13,  14,  15,  20,  22,  25,  37,  40,  45,  48,  61, 62,  76,  79,  84,  89,  90,  93,  94, 111, 112, 113, 115, 121])\n",
    "\n",
    "## IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19')\n",
    "user_annotations[IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='long_results_obj',user_annotation='selections')] = np.array([5,  13,  15,  17,  20,  21,  24,  31,  33,  43,  44,  49,  63, 64,  66,  68,  70,  71,  74,  76,  77,  78,  84,  90,  94,  95, 104, 105, 122, 123])\n",
    "user_annotations[IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='short_results_obj',user_annotation='selections')] = np.array([ 12,  13,  15,  17,  20,  24,  30,  31,  32,  33,  41,  43,  49, 54,  55,  68,  70,  71,  73,  76,  77,  78,  84,  89,  94, 100, 104, 105, 111, 114, 115, 117, 118, 122, 123, 131])\n",
    "\n",
    "\n",
    "## try to get the user annotations for this session:\n",
    "selection_idxs_L = user_annotations[selections_context_L]\n",
    "selection_idxs_S = user_annotations[selections_context_S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdf36a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All epochs are shown for both decoders. So the result should be an epochs table with separate columns for the inclusion in each decoder.\n",
    "@define(slots=False, eq=False)\n",
    "class EpochSelectionSet:\n",
    "    selected_indicies: np.ndarray # a list of the selected inidices\n",
    "\n",
    "long_selection = EpochSelectionSet(selected_indicies=np.array([5,  13,  15,  17,  20,  21,  24,  31,  33,  43,  44,  49,  63, 64,  66,  68,  70,  71,  74,  76,  77,  78,  84,  90,  94,  95, 104, 105, 122, 123]))\n",
    "short_selection = EpochSelectionSet(selected_indicies=np.array([ 12,  13,  15,  17,  20,  24,  30,  31,  32,  33,  41,  43,  49, 54,  55,  68,  70,  71,  73,  76,  77,  78,  84,  89,  94, 100, 104, 105, 111, 114, 115, 117, 118, 122, 123, 131]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c20f58d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_selected_index in long_selection.selected_indicies:\n",
    "\t_out_pagination_controller.params.is_selected[a_selected_index] = True\n",
    "\n",
    "_out_pagination_controller.perform_update_selections(defer_render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aff36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filter_epochs_df['long_is_user_included'] = np.isin(filter_epochs_df.index, long_selection.selected_indicies)\n",
    "filter_epochs_df['short_is_user_included'] = np.isin(filter_epochs_df.index, short_selection.selected_indicies)\n",
    "\n",
    "## Finally filter to find the potential example epochs:\n",
    "\n",
    "# only include those with one or more exclusive aclu:\n",
    "considered_filter_epochs_df = filter_epochs_df[filter_epochs_df.contains_one_exclusive_aclu].copy()\n",
    "# require inclusion for long or short:\n",
    "considered_filter_epochs_df = considered_filter_epochs_df[np.logical_xor(filter_epochs_df['long_is_user_included'], filter_epochs_df['short_is_user_included'])]\n",
    "considered_filter_epochs_df\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0409e08",
   "metadata": {},
   "source": [
    "# Other Programmatic Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe831b56",
   "metadata": {
    "tags": [
     "ACTIVE"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "\n",
    "## Builds proper sort indicies for '_display_short_long_pf1D_comparison'\n",
    "long_ratemap = long_pf1D.ratemap\n",
    "short_ratemap = short_pf1D.ratemap\n",
    "\n",
    "curr_any_context_neurons = _find_any_context_neurons(*[k.neuron_ids for k in [long_ratemap, short_ratemap]])\n",
    "curr_any_context_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402834bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.plotting.ratemaps import plot_ratemap_1D\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_short_v_long_pf1D_comparison, LongShortTrackComparingDisplayFunctions\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "long_single_cell_pfmap_processing_fn = None\n",
    "short_single_cell_pfmap_processing_fn = None\n",
    "# sort_idx = None\n",
    "# sort_idx = sort_ind\n",
    "# sort_idx = sort_indicies\n",
    "# sort_idx = new_all_aclus_sort_indicies\n",
    "sort_idx = 'peak_long'\n",
    "# sort_idx = 'bad'\n",
    "\n",
    "# out = curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_identifying_session_ctx, single_figure=False, debug_print=True, fignum='Short v Long pf1D Comparison',\n",
    "#                                    long_kwargs={'included_unit_neuron_IDs': curr_any_context_neurons, 'included_unit_indicies': None, 'sortby': sort_idx, 'single_cell_pfmap_processing_fn': long_single_cell_pfmap_processing_fn},\n",
    "#                                    short_kwargs={'included_unit_neuron_IDs': curr_any_context_neurons, 'included_unit_indicies': None,'sortby': sort_idx, 'single_cell_pfmap_processing_fn': short_single_cell_pfmap_processing_fn, 'curve_hatch_style': {'hatch':'///', 'edgecolor':'k'}},\n",
    "#                                   )\n",
    "\n",
    "out = curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_identifying_session_ctx, single_figure=False, debug_print=False, fignum='Short v Long pf1D Comparison',\n",
    "                                   long_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': long_single_cell_pfmap_processing_fn},\n",
    "                                   short_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': short_single_cell_pfmap_processing_fn, 'curve_hatch_style': {'hatch':'///', 'edgecolor':'k'}},\n",
    "                                  )\n",
    "                                  \n",
    "\n",
    "# ax = out.axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5653100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_short_long_pf1D_comparison', single_figure=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1906e5a",
   "metadata": {},
   "source": [
    "# 2023-06-01 - Testing new metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3fb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "## Extract variables from results object:\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result['Flat_epoch_time_bins_mean'], expected_v_observed_result['Flat_decoder_time_bin_centers'], expected_v_observed_result['num_neurons'], expected_v_observed_result['num_timebins_in_epoch'], expected_v_observed_result['num_total_flat_timebins'], expected_v_observed_result['is_short_track_epoch'], expected_v_observed_result['is_long_track_epoch'], expected_v_observed_result['short_short_diff'], expected_v_observed_result['long_long_diff']\n",
    "\n",
    "print(f'long_test: {np.mean(long_long_diff)}')\n",
    "print(f'short_test: {np.mean(short_short_diff)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e65f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_results_obj.original_1D_decoder\n",
    "replay_result_df = deepcopy(long_results_obj.active_filter_epochs.to_dataframe())\n",
    "replay_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67e3b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_results_obj.active_filter_epochs.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59838cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at lap speed over time - doesn't look like there's a difference between the long and the short track speeds\n",
    "global_session.position.compute_higher_order_derivatives()\n",
    "running_pos_df = global_session.position.to_dataframe()\n",
    "ax = running_pos_df.plot(x='t', y=['lin_pos','speed'], title='Running Speed over Time')\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627282a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "fig, ax = plot_lines(replay_result_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39e5020d",
   "metadata": {},
   "source": [
    "# 2023-06-13 11:01: - [ ] New display function testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6008da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# from pyphoplacecellanalysis.General.Mixins.ExportHelpers import create_daily_programmatic_display_function_testing_folder_if_needed, session_context_to_relative_path, programmatic_display_to_PDF\n",
    "# from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_pdf_metadata_from_display_context # newer version of build_pdf_export_metadata\n",
    "from neuropy.core.neuron_identities import PlotStringBrevityModeEnum\n",
    "from neuropy.plotting.ratemaps import BackgroundRenderingOptions\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# mpl.rcParams['toolbar'] = 'None' # disable toolbars\n",
    "# matplotlib.use('AGG') # non-interactive backend ## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import programmatic_render_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f47ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be73cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap, visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_raster_plot # used in `plot_kourosh_activity_style_figure`\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg # used in `plot_kourosh_activity_style_figure`\n",
    "\n",
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(long_pf1D.ratemap.normalized_tuning_curves, title=f\"pf1D Visualization\")\n",
    "# Apply the colormap\n",
    "# heatmap_pf1D_img.setLookupTable(lut)\n",
    "heatmap_pf1D_win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbecb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _prepare_spikes_df_from_filter_epochs\n",
    "\n",
    "long_ratemap = long_pf1D.ratemap\n",
    "short_ratemap = short_pf1D.ratemap\n",
    "curr_any_context_neurons = _find_any_context_neurons(*[k.neuron_ids for k in [long_ratemap, short_ratemap]])\n",
    "\n",
    "# filter_epochs = deepcopy(long_replays)\n",
    "\n",
    "filter_epochs = deepcopy(long_results_obj.active_filter_epochs.to_dataframe())\n",
    "filter_epoch_spikes_df = _prepare_spikes_df_from_filter_epochs(long_session.spikes_df, filter_epochs=filter_epochs, included_neuron_ids=curr_any_context_neurons, epoch_id_key_name='replay_epoch_id', debug_print=False) # replay_epoch_id\n",
    "filter_epoch_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c36ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4df49394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, _prepare_spikes_df_from_filter_epochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import determine_long_short_pf1D_indicies_sort_by_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fde77360",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "34",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m app, win, plots, plots_data \u001b[39m=\u001b[39m plot_multiple_raster_plot(filter_epochs_df, filter_epoch_spikes_df, included_neuron_ids\u001b[39m=\u001b[39;49mshared_aclus, epoch_id_key_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mreplay_epoch_id\u001b[39;49m\u001b[39m'\u001b[39;49m, scatter_app_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPho Stacked Replays\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\DisplayFunctions\\SpikeRasters.py:517\u001b[0m, in \u001b[0;36mplot_multiple_raster_plot\u001b[1;34m(filter_epochs_df, filter_epoch_spikes_df, included_neuron_ids, unit_sort_order, epoch_id_key_name, scatter_app_name)\u001b[0m\n\u001b[0;32m    515\u001b[0m raster_plot_manager\u001b[39m.\u001b[39m_build_cell_configs()\n\u001b[0;32m    516\u001b[0m \u001b[39m# Update the dataframe\u001b[39;00m\n\u001b[1;32m--> 517\u001b[0m filter_epoch_spikes_df \u001b[39m=\u001b[39m _add_spikes_df_visualization_columns(manager, filter_epoch_spikes_df)\n\u001b[0;32m    519\u001b[0m \u001b[39m# Common Tick Label\u001b[39;00m\n\u001b[0;32m    520\u001b[0m vtick \u001b[39m=\u001b[39m QtGui\u001b[39m.\u001b[39mQPainterPath()\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\DisplayFunctions\\SpikeRasters.py:156\u001b[0m, in \u001b[0;36m_add_spikes_df_visualization_columns\u001b[1;34m(manager, spikes_df)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_add_spikes_df_visualization_columns\u001b[39m(manager, spikes_df):\n\u001b[0;32m    155\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mvisualization_raster_y_location\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m spikes_df\u001b[39m.\u001b[39mcolumns:\n\u001b[1;32m--> 156\u001b[0m         all_y \u001b[39m=\u001b[39m [manager\u001b[39m.\u001b[39my_fragile_linear_neuron_IDX_map[a_cell_IDX] \u001b[39mfor\u001b[39;00m a_cell_IDX \u001b[39min\u001b[39;00m spikes_df[\u001b[39m'\u001b[39m\u001b[39mfragile_linear_neuron_IDX\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto_numpy()]\n\u001b[0;32m    157\u001b[0m         spikes_df[\u001b[39m'\u001b[39m\u001b[39mvisualization_raster_y_location\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m all_y \u001b[39m# adds as a column to the dataframe. Only needs to be updated when the number of active units changes. BUG? NO, RESOLVED: actually, this should be updated when anything that would change .y_fragile_linear_neuron_IDX_map would change, right? Meaning: .y, ... oh, I see. y doesn't change because params.center_mode, params.bin_position_mode, and params.side_bin_margins aren't expected to change. \u001b[39;00m\n\u001b[0;32m    159\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mvisualization_raster_emphasis_state\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m spikes_df\u001b[39m.\u001b[39mcolumns:\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\DisplayFunctions\\SpikeRasters.py:156\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_add_spikes_df_visualization_columns\u001b[39m(manager, spikes_df):\n\u001b[0;32m    155\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mvisualization_raster_y_location\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m spikes_df\u001b[39m.\u001b[39mcolumns:\n\u001b[1;32m--> 156\u001b[0m         all_y \u001b[39m=\u001b[39m [manager\u001b[39m.\u001b[39;49my_fragile_linear_neuron_IDX_map[a_cell_IDX] \u001b[39mfor\u001b[39;00m a_cell_IDX \u001b[39min\u001b[39;00m spikes_df[\u001b[39m'\u001b[39m\u001b[39mfragile_linear_neuron_IDX\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto_numpy()]\n\u001b[0;32m    157\u001b[0m         spikes_df[\u001b[39m'\u001b[39m\u001b[39mvisualization_raster_y_location\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m all_y \u001b[39m# adds as a column to the dataframe. Only needs to be updated when the number of active units changes. BUG? NO, RESOLVED: actually, this should be updated when anything that would change .y_fragile_linear_neuron_IDX_map would change, right? Meaning: .y, ... oh, I see. y doesn't change because params.center_mode, params.bin_position_mode, and params.side_bin_margins aren't expected to change. \u001b[39;00m\n\u001b[0;32m    159\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mvisualization_raster_emphasis_state\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m spikes_df\u001b[39m.\u001b[39mcolumns:\n",
      "\u001b[1;31mKeyError\u001b[0m: 34"
     ]
    }
   ],
   "source": [
    "app, win, plots, plots_data = plot_multiple_raster_plot(filter_epochs_df, filter_epoch_spikes_df, included_neuron_ids=shared_aclus, epoch_id_key_name='replay_epoch_id', scatter_app_name=\"Pho Stacked Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6500572",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_aclus_sort_indicies = determine_long_short_pf1D_indicies_sort_by_peak(curr_active_pipeline=curr_active_pipeline, curr_any_context_neurons=EITHER_pf_only_aclus)\n",
    "new_all_aclus_sort_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6039bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epoch_spikes_df = _prepare_spikes_df_from_filter_epochs(filter_epoch_spikes_df, filter_epochs=considered_filter_epochs_df, included_neuron_ids=EITHER_pf_only_aclus, epoch_id_key_name='replay_epoch_id', debug_print=True) # replay_epoch_id\n",
    "filter_epoch_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f8851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, plots, plots_data = plot_multiple_raster_plot(considered_filter_epochs_df, filter_epoch_spikes_df, included_neuron_ids=EITHER_pf_only_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_id_key_name='replay_epoch_id', scatter_app_name=\"Pho Custom Selected Stacked Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_filter_epochs_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
