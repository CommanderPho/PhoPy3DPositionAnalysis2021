{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:20.608442900Z",
     "start_time": "2023-11-16T23:21:20.217442100Z"
    },
    "collapsed": true,
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Verbose\n",
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%xmode Verbose\n",
    "%pdb off\n",
    "%load_ext viztracer\n",
    "from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "from attrs import define, field, fields, Factory\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "from pyphocorehelpers.print_helpers import get_now_time_str, get_now_day_str\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field, custom_define\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin, HDF_Converter\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_subsession_neuron_differences, debug_print_ratemap, debug_print_spike_counts, debug_plot_2d_binning, print_aligned_columns\n",
    "from neuropy.utils.debug_helpers import parameter_sweeps, _plot_parameter_sweep, compare_placefields_info\n",
    "\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, CapturedException, document_active_variables\n",
    "from pyphocorehelpers.general_helpers import GeneratedClassDefinitionType, CodeConversion, inspect_callable_arguments\n",
    "\n",
    "## Pho Programming Helpers:\n",
    "import inspect\n",
    "from pyphocorehelpers.general_helpers import inspect_callable_arguments, get_arguments_as_optional_dict, GeneratedClassDefinitionType, CodeConversion\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter, TypePrintMode, print_keys_if_possible, debug_dump_object_member_shapes, print_value_overview_only, document_active_variables, CapturedException\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers, PythonDictionaryDefinitionFormat, MemoryManagement\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper, print_widget_hierarchy\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsResult, TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions\n",
    "from neuropy.utils.indexing_helpers import union_of_arrays, intersection_of_arrays, find_desired_sort_indicies, paired_incremental_sorting\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "# %matplotlib inline\n",
    "\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, fullwidth_path_widget, interactive_pipeline_files\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import render_colors\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/home/halechr/FastData'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/home/halechr/cloud/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db844b",
   "metadata": {},
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233d2b8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:36.073368600Z",
     "start_time": "2023-11-16T23:21:27.575793Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:NeuropyPipeline.__init__(name=\"kdiba_pipeline\", session_data_type=\"kdiba\", basedir=\"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\")\n",
      "INFO:com.PhoHale.Spike3D.pipeline:basedir is already Path object.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:NeuropyPipeline.on_stage_changed(new_stage=\"PipelineStage.Input\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\2006-6-09_1-22-43.epochs_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\2006-6-09_1-22-43.position_info.mat... done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\2006-6-09_1-22-43.spikes.mat... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\core\\session\\Formats\\SessionSpecifications.py:123: UserWarning: WARNING: Optional File: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\2006-6-09_1-22-43.dat does not exist. Continuing without it.\n",
      "  warnings.warn(f'WARNING: Optional File: {an_optional_filepath} does not exist. Continuing without it.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Saving updated position results results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\2006-6-09_1-22-43.position.npy... 2006-6-09_1-22-43.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results : spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\2006-6-09_1-22-43.interpolated_spike_positions.npy... 2006-6-09_1-22-43.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\2006-6-09_1-22-43.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\2006-6-09_1-22-43.replay_info.mat... done.\n",
      "session.replays loaded successfully!\n",
      "Loading success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\ripple_df.pkl.\n",
      "force_recompute is True, recomputing...\n",
      "computing neurons mua for session...\n",
      "\n",
      "Saving mua results results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\2006-6-09_1-22-43.mua.npy... 2006-6-09_1-22-43.mua.npy saved\n",
      "done.\n",
      "force_recompute is True, recomputing...\n",
      "computing PBE epochs for session...\n",
      "\n",
      "Saving pbe results results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\2006-6-09_1-22-43.pbe.npy... 2006-6-09_1-22-43.pbe.npy saved\n",
      "done.\n",
      "Computing spikes_df PBEs column results : spikes_df... done.\n",
      "Computing added spike scISI column results : spikes_df... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:NeuropyPipeline.on_stage_changed(new_stage=\"PipelineStage.Loaded\")\n",
      "DEBUG:com.PhoHale.Spike3D.pipeline:Performing on_post_load(...) with 1 post_load_functions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "POSTLOAD_estimate_laps_and_replays()...\n",
      "WARN: Laps.from_estimated_laps(...) found 7 indicies to change:\n",
      "\tindicies_to_change: {0: 67, 1: 118, 9: 8406, 37: 27617, 75: 46766, 78: 47718, 84: 49508}\n",
      ".POSTLOAD_estimate_laps_and_replays(...): WARN: True\n",
      "computing PBE epochs for session...\n",
      "\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:NeuropyPipeline.on_stage_changed(new_stage=\"PipelineStage.Computed\")\n",
      "INFO:com.PhoHale.Spike3D.pipeline:select_filters(...) with: [<function DataSessionFormatBaseRegisteredClass.build_default_filter_functions.<locals>.<dictcomp>.<lambda> at 0x000002E46B75E940>, <function DataSessionFormatBaseRegisteredClass.build_default_filter_functions.<locals>.<dictcomp>.<lambda> at 0x000002E46DAF1EE0>, <function DataSessionFormatBaseRegisteredClass.build_global_epoch_filter_config_dict.<locals>.<lambda> at 0x000002E46DDB5D30>]\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\tApplying session filter named \"maze1_odd\"...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t curr_replays: 412\n",
      "skip_save_on_initial_load is True so resultant pipeline will not be saved to the pickle file.\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'firing_rate_trends', 'position_decoding']\n",
      "Applying session filter named \"maze1_odd\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1029.316608761903)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\tApplying session filter named \"maze2_odd\"...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze2_odd\"...\n",
      "Constraining to epoch with times (start: 1029.316608761903, end: 1737.1968310000375)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\tApplying session filter named \"maze_odd\"...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze_odd\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1737.1968310000375)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing _execute_computation_functions(...) with 3 registered_computation_functions...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [0/3]: <function PlacefieldComputations._perform_baseline_placefield_computation at 0x000002E4552FCCA0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "due to includelist, including only 3 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [1/3]: <function DefaultComputationFunctions._perform_position_decoding_computation at 0x000002E4552FC280>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [2/3]: <function SpikeAnalysisComputations._perform_firing_rate_trends_computation at 0x000002E45585B820>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (524075,) should be less than time_window_edges: (2060,)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\t all computations complete! (Computed 3 with no errors!.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing _execute_computation_functions(...) with 3 registered_computation_functions...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [0/3]: <function PlacefieldComputations._perform_baseline_placefield_computation at 0x000002E4552FCCA0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11292,) should be less than time_window_edges: (1896,)!\n",
      "due to includelist, including only 3 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [1/3]: <function DefaultComputationFunctions._perform_position_decoding_computation at 0x000002E4552FC280>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [2/3]: <function SpikeAnalysisComputations._perform_firing_rate_trends_computation at 0x000002E45585B820>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (344561,) should be less than time_window_edges: (1417,)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\t all computations complete! (Computed 3 with no errors!.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing _execute_computation_functions(...) with 3 registered_computation_functions...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [0/3]: <function PlacefieldComputations._perform_baseline_placefield_computation at 0x000002E4552FCCA0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10597,) should be less than time_window_edges: (1219,)!\n",
      "due to includelist, including only 3 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [1/3]: <function DefaultComputationFunctions._perform_position_decoding_computation at 0x000002E4552FC280>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [2/3]: <function SpikeAnalysisComputations._perform_firing_rate_trends_computation at 0x000002E45585B820>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (868636,) should be less than time_window_edges: (3476,)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\t all computations complete! (Computed 3 with no errors!.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing global computations...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:novel_filter_names: ['maze1_even' 'maze2_even' 'maze_even']\n",
      "INFO:com.PhoHale.Spike3D.pipeline:select_filters(...) with: [<function DataSessionFormatBaseRegisteredClass.build_default_filter_functions.<locals>.<dictcomp>.<lambda> at 0x000002E46B75E940>, <function DataSessionFormatBaseRegisteredClass.build_default_filter_functions.<locals>.<dictcomp>.<lambda> at 0x000002E46DAF1EE0>, <function DataSessionFormatBaseRegisteredClass.build_global_epoch_filter_config_dict.<locals>.<lambda> at 0x000002E46DDB5D30>]\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\tApplying session filter named \"maze1_even\"...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (21889,) should be less than time_window_edges: (3176,)!\n",
      "novel_filter_names: ['maze1_even' 'maze2_even' 'maze_even']\n",
      "Applying session filter named \"maze1_even\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1029.316608761903)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\tApplying session filter named \"maze2_even\"...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze2_even\"...\n",
      "Constraining to epoch with times (start: 1029.316608761903, end: 1737.1968310000375)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\tApplying session filter named \"maze_even\"...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze_even\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1737.1968310000375)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing _execute_computation_functions(...) with 3 registered_computation_functions...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [0/3]: <function PlacefieldComputations._perform_baseline_placefield_computation at 0x000002E4552FCCA0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "due to includelist, including only 3 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [1/3]: <function DefaultComputationFunctions._perform_position_decoding_computation at 0x000002E4552FC280>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [2/3]: <function SpikeAnalysisComputations._perform_firing_rate_trends_computation at 0x000002E45585B820>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (524075,) should be less than time_window_edges: (2060,)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\t all computations complete! (Computed 3 with no errors!.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing _execute_computation_functions(...) with 3 registered_computation_functions...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [0/3]: <function PlacefieldComputations._perform_baseline_placefield_computation at 0x000002E4552FCCA0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15323,) should be less than time_window_edges: (1996,)!\n",
      "due to includelist, including only 3 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [1/3]: <function DefaultComputationFunctions._perform_position_decoding_computation at 0x000002E4552FC280>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [2/3]: <function SpikeAnalysisComputations._perform_firing_rate_trends_computation at 0x000002E45585B820>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (344561,) should be less than time_window_edges: (1417,)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\t all computations complete! (Computed 3 with no errors!.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing _execute_computation_functions(...) with 3 registered_computation_functions...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [0/3]: <function PlacefieldComputations._perform_baseline_placefield_computation at 0x000002E4552FCCA0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10660,) should be less than time_window_edges: (1226,)!\n",
      "due to includelist, including only 3 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [1/3]: <function DefaultComputationFunctions._perform_position_decoding_computation at 0x000002E4552FC280>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [2/3]: <function SpikeAnalysisComputations._perform_firing_rate_trends_computation at 0x000002E45585B820>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (868636,) should be less than time_window_edges: (3476,)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\t all computations complete! (Computed 3 with no errors!.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing global computations...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:novel_filter_names: ['maze1_any' 'maze2_any' 'maze_any']\n",
      "INFO:com.PhoHale.Spike3D.pipeline:select_filters(...) with: [<function DataSessionFormatBaseRegisteredClass.build_default_filter_functions.<locals>.<dictcomp>.<lambda> at 0x000002E46B75E940>, <function DataSessionFormatBaseRegisteredClass.build_default_filter_functions.<locals>.<dictcomp>.<lambda> at 0x000002E46DAF1EE0>, <function DataSessionFormatBaseRegisteredClass.build_global_epoch_filter_config_dict.<locals>.<lambda> at 0x000002E46DDB5D30>]\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\tApplying session filter named \"maze1_any\"...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (25983,) should be less than time_window_edges: (3298,)!\n",
      "novel_filter_names: ['maze1_any' 'maze2_any' 'maze_any']\n",
      "Applying session filter named \"maze1_any\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1029.316608761903)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\tApplying session filter named \"maze2_any\"...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze2_any\"...\n",
      "Constraining to epoch with times (start: 1029.316608761903, end: 1737.1968310000375)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\tApplying session filter named \"maze_any\"...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze_any\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1737.1968310000375)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing _execute_computation_functions(...) with 3 registered_computation_functions...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [0/3]: <function PlacefieldComputations._perform_baseline_placefield_computation at 0x000002E4552FCCA0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "due to includelist, including only 3 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [1/3]: <function DefaultComputationFunctions._perform_position_decoding_computation at 0x000002E4552FC280>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (34393,) should be less than time_window_edges: (30460,)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [2/3]: <function SpikeAnalysisComputations._perform_firing_rate_trends_computation at 0x000002E45585B820>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (524075,) should be less than time_window_edges: (2060,)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\t all computations complete! (Computed 3 with no errors!.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing _execute_computation_functions(...) with 3 registered_computation_functions...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [0/3]: <function PlacefieldComputations._perform_baseline_placefield_computation at 0x000002E4552FCCA0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (26615,) should be less than time_window_edges: (2029,)!\n",
      "due to includelist, including only 3 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [1/3]: <function DefaultComputationFunctions._perform_position_decoding_computation at 0x000002E4552FC280>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (24701,) should be less than time_window_edges: (18541,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (21257,) should be less than time_window_edges: (18538,)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [2/3]: <function SpikeAnalysisComputations._perform_firing_rate_trends_computation at 0x000002E45585B820>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (344561,) should be less than time_window_edges: (1417,)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\t all computations complete! (Computed 3 with no errors!.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing _execute_computation_functions(...) with 3 registered_computation_functions...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [0/3]: <function PlacefieldComputations._perform_baseline_placefield_computation at 0x000002E4552FCCA0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (21257,) should be less than time_window_edges: (1237,)!\n",
      "due to includelist, including only 3 out of 16 registered computation functions.\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [1/3]: <function DefaultComputationFunctions._perform_position_decoding_computation at 0x000002E4552FC280>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t done.\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (59094,) should be less than time_window_edges: (49657,)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:Executing [2/3]: <function SpikeAnalysisComputations._perform_firing_rate_trends_computation at 0x000002E45585B820>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (868636,) should be less than time_window_edges: (3476,)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\t all computations complete! (Computed 3 with no errors!.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing global computations...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:NeuropyPipeline.on_stage_changed(new_stage=\"PipelineStage.Displayed\")\n",
      "INFO:com.PhoHale.Spike3D.pipeline:save_pipeline(): Attempting to save pipeline to disk...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\tfinalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (47872,) should be less than time_window_edges: (3309,)!\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:com.PhoHale.Spike3D.pipeline:WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl will be overwritten even though exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl... \tmoving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\20231210200652-loadedSessPickle.pkltmp' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\t save complete.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:save_pipeline(): Attempting to save pipeline to disk...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\tfinalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts['maze1_odd']'s actual context name is incorrect. \n",
      "\ta_filtered_ctxt.filter_name: 'maze2' != desired_filter_name: 'maze1_odd'\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "WARNING: filtered_contexts['maze2_odd']'s actual context name is incorrect. \n",
      "\ta_filtered_ctxt.filter_name: 'maze2' != desired_filter_name: 'maze2_odd'\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "WARNING: filtered_contexts['maze_odd']'s actual context name is incorrect. \n",
      "\ta_filtered_ctxt.filter_name: 'maze' != desired_filter_name: 'maze_odd'\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "WARNING: filtered_contexts['maze1_even']'s actual context name is incorrect. \n",
      "\ta_filtered_ctxt.filter_name: 'maze2' != desired_filter_name: 'maze1_even'\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "WARNING: filtered_contexts['maze2_even']'s actual context name is incorrect. \n",
      "\ta_filtered_ctxt.filter_name: 'maze2' != desired_filter_name: 'maze2_even'\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "WARNING: filtered_contexts['maze_even']'s actual context name is incorrect. \n",
      "\ta_filtered_ctxt.filter_name: 'maze' != desired_filter_name: 'maze_even'\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "WARNING: filtered_contexts['maze1_any']'s actual context name is incorrect. \n",
      "\ta_filtered_ctxt.filter_name: 'maze2' != desired_filter_name: 'maze1_any'\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "WARNING: filtered_contexts['maze2_any']'s actual context name is incorrect. \n",
      "\ta_filtered_ctxt.filter_name: 'maze2' != desired_filter_name: 'maze2_any'\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "WARNING: filtered_contexts['maze_any']'s actual context name is incorrect. \n",
      "\ta_filtered_ctxt.filter_name: 'maze' != desired_filter_name: 'maze_any'\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "was_updated: True\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:com.PhoHale.Spike3D.pipeline:WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl will be overwritten even though exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: saving_mode is OVERWRITE_IN_PLACE so W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl will be overwritten even though exists.\n",
      "Saving (file mode 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl... \tmoving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\20231210200707-loadedSessPickle.pkltmp' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\t save complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # DONE. Very good. Many good Pfs, many good replays.\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # DONE, might be the BEST SESSION, good example session with lots of place cells, clean replays, and clear bar graphs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD, 2023-07-14, unsure why still.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays!\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE, Added replay selections. Very \"jumpy\" between the starts and ends of the track.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # DONE, Added replay selections. A TON of putative replays in general, most bad, but some good.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # DONE, added replay selections. Very few (like 12) replays each.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3') # DONE, Good Pfs, no good epochs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') # DONE, okay replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # DONE, very few replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # DONE, one replay each (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # BAD, Good Pfs strangely despite horrible map, no good epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # DONE, good. Many good pfs, many good replays. Noticed very strange jumping off the track in the 3D behavior/spikes viewer. Is there something wrong with this session?\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE, good?, replays selected, few\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE, very few replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # DONE, replays selected, quite a few replays but few are very good.\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25')\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "# saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "# force_reload = False\n",
    "\n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "force_reload = True\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=['pf_computation',\n",
    "                                            #    'pfdt_computation',\n",
    "                                                'firing_rate_trends',\n",
    "                                                # 'pf_dt_sequential_surprise', \n",
    "                                            #    'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                # 'position_decoding_two_step', \n",
    "                                            #    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                            #     'long_short_inst_spike_rate_groups',\n",
    "                                            #     'long_short_endcap_analysis',\n",
    "                                            # 'split_to_directional_laps',\n",
    "]\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "\n",
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acba46b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:40.574268400Z",
     "start_time": "2023-11-16T23:21:35.966373700Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included includelist is specified: ['pf_computation', 'firing_rate_trends', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_endcap_analysis', 'split_to_directional_laps', 'rank_order_shuffle_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze_any\"\n",
      "pf_computation, maze_any already computed.\n",
      "\tforce_recompute is true so recomputing anyway\n",
      "pf_computation missing.\n",
      "\t Recomputing pf_computation...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "\t done.\n",
      "firing_rate_trends, maze_any already computed.\n",
      "\tforce_recompute is true so recomputing anyway\n",
      "firing_rate_trends missing.\n",
      "\t Recomputing firing_rate_trends...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_odd\"...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (524075,) should be less than time_window_edges: (2060,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11292,) should be less than time_window_edges: (1896,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_odd\"...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (344561,) should be less than time_window_edges: (1417,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10597,) should be less than time_window_edges: (1219,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze_odd\"...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (868636,) should be less than time_window_edges: (3476,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (21889,) should be less than time_window_edges: (3176,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_even\"...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (524075,) should be less than time_window_edges: (2060,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (15323,) should be less than time_window_edges: (1996,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_even\"...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (344561,) should be less than time_window_edges: (1417,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (10660,) should be less than time_window_edges: (1226,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze_even\"...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (868636,) should be less than time_window_edges: (3476,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (25983,) should be less than time_window_edges: (3298,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1_any\"...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (524075,) should be less than time_window_edges: (2060,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (26615,) should be less than time_window_edges: (2029,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2_any\"...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (344561,) should be less than time_window_edges: (1417,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (21257,) should be less than time_window_edges: (1237,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze_any\"...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (868636,) should be less than time_window_edges: (3476,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (47872,) should be less than time_window_edges: (3309,)!\n",
      "\t done.\n",
      "split_to_directional_laps missing.\n",
      "\t Recomputing split_to_directional_laps...\n",
      "WARN: _split_to_directional_laps(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "build_global_directional_result_from_natural_epochs(...): was_modified: False\n",
      "n_neurons: 42, shared_aclus: [  9  11  15  16  18  24  25  26  31  39  40  43  44  47  48  51  52  53  56  60  61  66  68  70  72  75  77  79  80  81  82  84  85  87  89  90  92  93  98 101 102 104]\n",
      "\t done.\n",
      "rank_order_shuffle_analysis missing.\n",
      "\t Recomputing rank_order_shuffle_analysis...\n",
      "WARN: perform_rank_order_shuffle_analysis(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "perform_rank_order_shuffle_analysis(..., num_shuffles=1000)\n",
      "\tcomputing Laps rank-order shuffles:\n",
      "\t\tnum_shuffles: 1000, minimum_inclusion_fr_Hz: 2.0 Hz\n",
      "WARN: .trim_overlapping_laps(...): need to recompute  ['start_position_index', 'end_position_index', 'start_spike_index', 'end_spike_index', 'num_spikes'] for the laps after calling self.trim_overlapping_laps()!\n",
      "laps_paired_tests: [TtestResult(statistic=16.031762295820847, pvalue=3.843001352680544e-27, df=83), TtestResult(statistic=15.518030986340687, pvalue=2.940301741925267e-26, df=83)]\n",
      "\tcomputing Ripple rank-order shuffles:\n",
      "ripple_evts_paired_tests: [TtestResult(statistic=-2.9069638429317495, pvalue=0.0038590309284383434, df=388), TtestResult(statistic=-1.5941260107179787, pvalue=0.11172204693755326, df=388)]\n",
      "\tdone. building global result.\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "Exception occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\n",
      " Inner exception: centers must be of at least length 2 to re-derive center_info, but it is of length 1. centers: [1231.56]\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "`is_certain_properly_constrained`: True - Correctly initialized pipelines (pfs limited to laps, decoders already long/short constrainted by default, replays already the estimated versions\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\scipy\\spatial\\distance.py:1259: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(js / 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n_neurons = 66, n_all_epoch_timebins = 1618)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\scipy\\spatial\\distance.py:1259: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(js / 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n_neurons = 66, n_all_epoch_timebins = 1618)\n",
      "\t done.\n",
      "short_long_pf_overlap_analyses missing.\n",
      "\t Recomputing short_long_pf_overlap_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "pipeline_complete_compute_long_short_fr_indicies is lacking a required computation config parameter! creating a new curr_active_pipeline.global_computation_results.computation_config\n",
      "_generalized_compute_long_short_firing_rate_indicies(...): processing key: \"laps\"\n",
      "_generalized_compute_long_short_firing_rate_indicies(...): processing key: \"replays\"\n",
      "_generalized_compute_long_short_firing_rate_indicies(...): processing key: \"non_replays\"\n",
      "\t done.\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n",
      "\t done.\n",
      "long_short_endcap_analysis missing.\n",
      "\t Recomputing long_short_endcap_analysis...\n",
      "num_disappearing_endcap_cells/num_total_endcap_cells: 4/31\n",
      "num_non_disappearing_endcap_cells/num_total_endcap_cells: 27/31\n",
      "num_significant_position_remappping_endcap_cells/num_non_disappearing_endcap_cells: 14/27\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('pf_computation', 'maze_any'), ('firing_rate_trends', 'maze_any'), ('split_to_directional_laps', 'maze_any'), ('long_short_decoding_analyses', 'maze_any'), ('short_long_pf_overlap_analyses', 'maze_any'), ('long_short_fr_indicies_analyses', 'maze_any'), ('jonathan_firing_rate_analysis', 'maze_any'), ('long_short_post_decoding', 'maze_any'), ('long_short_endcap_analysis', 'maze_any')].\n",
      "Saving global results...\n",
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\global_computation_results.pkl') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\global_computation_results.pkl... \tmoving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\20231210201815-global_computation_results.pkltmp' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\global_computation_results.pkl'\n",
      "done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20f521af97f47e98f7d60610eab327b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Box(children=(Label(value='session path:', layout=Layout(width='auto')), Label(value='W:\\\\Data\\…"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GLOBAL COMPUTATIONS:\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        curr_active_pipeline.load_pickled_global_computation_results()\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "extended_computations_include_includelist=['pf_computation', 'firing_rate_trends', # 'pfdt_computation',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "    #  'ratemap_peaks_prominence2d',\n",
    "    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding',\n",
    "    # 'long_short_rate_remapping',\n",
    "    # 'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    # 'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'rank_order_shuffle_analysis'\n",
    "] # do only specified\n",
    "\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True, force_recompute=force_recompute_global, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# except Exception as e:\n",
    "#     exception_info = sys.exc_info()\n",
    "#     e = CapturedException(e, exception_info)\n",
    "#     print(f'second half threw: {e}')\n",
    "\n",
    "\n",
    "# 4m 5.2s for inst fr computations\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, fullwidth_path_widget, interactive_pipeline_files\n",
    "\n",
    "_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\n",
    "# display(_pipeline_jupyter_widget)\n",
    "_pipeline_jupyter_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d4f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24adda73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cbb6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f06d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe54599",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a533ba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:40.700275900Z",
     "start_time": "2023-11-16T23:21:40.584273Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "\n",
    "assert short_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "assert long_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9071e94f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:43.601382Z",
     "start_time": "2023-11-16T23:21:40.702275600Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "WARNING: PAPER_FIGURE_figure_1_add_replay_epoch_rasters(...): no user-assigned manually labeled replay epochs. Reeturning all epochs.\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n"
     ]
    }
   ],
   "source": [
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global \n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "## Get global `long_short_fr_indicies_analysis`:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n",
    "long_short_fr_indicies_df = long_short_fr_indicies_analysis_results['long_short_fr_indicies_df']\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result.Flat_epoch_time_bins_mean, expected_v_observed_result.Flat_decoder_time_bin_centers, expected_v_observed_result.num_neurons, expected_v_observed_result.num_timebins_in_epoch, expected_v_observed_result.num_total_flat_timebins, expected_v_observed_result.is_short_track_epoch, expected_v_observed_result.is_long_track_epoch, expected_v_observed_result.short_short_diff, expected_v_observed_result.long_long_diff\n",
    "\n",
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.05)\n",
    "\n",
    "## Update long_exclusive/short_exclusive properties with `long_short_fr_indicies_df`\n",
    "# long_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n",
    "# short_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395e294e98e2f59e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:43.820890500Z",
     "start_time": "2023-11-16T23:21:43.722893300Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Most popular\n",
    "# long_LR_name, short_LR_name, long_RL_name, short_RL_name, global_any_name\n",
    "\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260739a4f36c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_burst_intervals = curr_active_pipeline.computation_results[global_epoch_name].computed_data['burst_detection']['burst_intervals']\n",
    "# active_burst_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a1c6006aba5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Entropy/Surprise Results:\n",
    "active_extended_stats = global_results['extended_stats']\n",
    "active_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise'] # DynamicParameters\n",
    "historical_snapshots = active_relative_entropy_results['historical_snapshots']\n",
    "post_update_times: np.ndarray = active_relative_entropy_results['post_update_times'] # (4152,) = (n_post_update_times,)\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals: np.ndarray = active_relative_entropy_results['time_intervals']\n",
    "surprise_time_bin_duration = (post_update_times[2]-post_update_times[1])\n",
    "long_short_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "flat_relative_entropy_results: np.ndarray = active_relative_entropy_results['flat_relative_entropy_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_results: np.ndarray = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_across_all_positions: np.ndarray = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "flat_surprise_across_all_positions: np.ndarray = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\n",
    "## Get the placefield dt matrix:\n",
    "if 'snapshot_occupancy_weighted_tuning_maps' not in active_relative_entropy_results:\n",
    "\t## Compute it if missing:\n",
    "\toccupancy_weighted_tuning_maps_over_time = np.stack([placefield_snapshot.occupancy_weighted_tuning_maps_matrix for placefield_snapshot in historical_snapshots.values()])\n",
    "\tactive_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] = occupancy_weighted_tuning_maps_over_time\n",
    "else:\n",
    "\toccupancy_weighted_tuning_maps_over_time = active_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] # (n_post_update_times, n_neurons, n_xbins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554d3bf5955d9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8624c62d5c18c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "## long_short_endcap_analysis: checks for cells localized to the endcaps that have their placefields truncated after shortening the track\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "# disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "# trivially_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "# significant_distant_remapping_endcap_aclus\n",
    "appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n",
    "# appearing_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabbbaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_active_aclus = np.array([9,  26,  31,  39,  40,  43,  47,  52,  53,  54,  60,  61,  65,  68,  72,  75,  77,  78,  81,  82,  84,  85,  90,  92,  93,  98, 102])\n",
    "\n",
    "\n",
    "curr_active_pipeline.filtered_contexts['maze1_odd']\n",
    "curr_active_pipeline.computation_results['maze1_odd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf30c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "curr_active_pipeline.display('_display_1d_placefields') # , 'maze1_odd'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc832fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import programmatic_render_to_file\n",
    "\n",
    "programmatic_render_to_file(curr_active_pipeline, curr_display_function_name='_display_1d_placefields', write_vector_format=True, write_png=True, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "curr_active_pipeline.prepare_for_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ccab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_active_pipeline.display('_display_1d_placefields', 'maze_any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_1d_placefields', 'maze_any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546f7639",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_placemaps_pyqtplot_2D', 'maze2_odd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_1d_placefields', 'maze2_odd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a6994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_3d_interactive_spike_and_behavior_browser', 'maze1_odd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971436c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ecb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_placemaps_pyqtplot_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a1db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc7dfe",
   "metadata": {},
   "source": [
    "## Set matplotlib rcparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a1bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('ggplot')\n",
    "matplotlib_configuration_update(is_interactive=True)\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import programmatic_display_to_PDF, programmatic_render_to_file\n",
    "\n",
    "\n",
    "# plt.style.use(['Solarize_Light2']) # , 'presentation'\n",
    "plt.style.use('bmh')\n",
    "\n",
    "# size=(8.5, 11)\n",
    "# fontsize=8\n",
    "# axis_color=\"#545454\"\n",
    "# axis_lw=1.2\n",
    "# tick_size=3.5\n",
    "# constrained_layout=True\n",
    "# fontname=\"Arial\"\n",
    "\n",
    "# # --- plot settings --------\n",
    "# mpl.rcParams[\"font.family\"] = fontname\n",
    "# mpl.rcParams[\"font.sans-serif\"] = \"Arial\"\n",
    "mpl.rcParams[\"pdf.fonttype\"] = 42\n",
    "mpl.rcParams[\"ps.fonttype\"] = 42\n",
    "mpl.rcParams[\"svg.fonttype\"] = \"none\"\n",
    "# mpl.rcParams[\"axes.linewidth\"] = axis_lw\n",
    "# mpl.rcParams[\"axes.labelsize\"] = fontsize\n",
    "# mpl.rcParams[\"axes.titlesize\"] = fontsize\n",
    "# mpl.rcParams[\"axes.edgecolor\"] = axis_color\n",
    "# mpl.rcParams[\"xtick.labelsize\"] = fontsize\n",
    "# mpl.rcParams[\"xtick.major.pad\"] = 2\n",
    "# mpl.rcParams[\"ytick.labelsize\"] = fontsize\n",
    "# mpl.rcParams[\"axes.spines.top\"] = False\n",
    "# mpl.rcParams[\"axes.spines.right\"] = False\n",
    "# mpl.rcParams[\"xtick.major.width\"] = axis_lw\n",
    "# # mpl.rcParams[\"axes.autolimit_mode\"] = \"round_numbers\"\n",
    "# mpl.rcParams[\"axes.ymargin\"] = 0\n",
    "# mpl.rcParams[\"xtick.major.size\"] = tick_size\n",
    "# mpl.rcParams[\"ytick.major.size\"] = tick_size\n",
    "# mpl.rcParams[\"xtick.color\"] = axis_color\n",
    "# mpl.rcParams[\"xtick.labelcolor\"] = \"k\"\n",
    "# mpl.rcParams[\"ytick.major.width\"] = axis_lw\n",
    "# mpl.rcParams[\"ytick.color\"] = axis_color\n",
    "# mpl.rcParams[\"ytick.labelcolor\"] = \"k\"\n",
    "# mpl.rcParams[\"figure.constrained_layout.use\"] = constrained_layout\n",
    "# mpl.rcParams[\"axes.prop_cycle\"] = cycler(\n",
    "# \t\"color\",\n",
    "# \t[\n",
    "# \t\t\"#5cc0eb\",\n",
    "# \t\t\"#faa49d\",\n",
    "# \t\t\"#05d69e\",\n",
    "# \t\t\"#253237\",\n",
    "# \t\t\"#ef6e4e\",\n",
    "# \t\t\"#f0a8e6\",\n",
    "# \t\t\"#aaa8f0\",\n",
    "# \t\t\"#f0a8af\",\n",
    "# \t\t\"#dfe36b\",\n",
    "# \t\t\"#825265\",\n",
    "# \t\t\"#e8594f\",\n",
    "# \t],\n",
    "# )\n",
    "# figure.titlesize\n",
    "# axes.titlesize\n",
    "# axes.labelsize\n",
    "\n",
    "mpl.rcParams[\"figure.titlesize\"] = 12\n",
    "mpl.rcParams[\"axes.titlesize\"] = 10\n",
    "mpl.rcParams[\"axes.labelsize\"] = 8\n",
    "\n",
    "# def set_pub():\n",
    "#     rcParams.update({\n",
    "#         \"font.weight\": \"bold\",  # bold fonts\n",
    "#         \"tick.labelsize\": 15,   # large tick labels\n",
    "#         \"lines.linewidth\": 1,   # thick lines\n",
    "#         \"lines.color\": \"k\",     # black lines\n",
    "#         \"grid.color\": \"0.5\",    # gray gridlines\n",
    "#         \"grid.linestyle\": \"-\",  # solid gridlines\n",
    "#         \"grid.linewidth\": 0.5,  # thin gridlines\n",
    "#         \"savefig.dpi\": 300,     # higher resolution output.\n",
    "#     })\n",
    "    \n",
    "# restore_rc()\n",
    "\n",
    "# data = np.random.randn(50)\n",
    "\n",
    "# fig = plt.plot(data)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b558758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_multitab import MplMultiTab, MplMultiTab2D\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import programmatic_display_to_PDF, programmatic_render_to_file\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_single_cell_1D_placecell_validation\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_1d_placecell_validations\n",
    "\n",
    "\n",
    "# matplotlib_configuration_update(is_interactive=True)\n",
    "\n",
    "# curr_active_pipeline.display('_display_grid_bin_bounds_validation')\n",
    "_out = curr_active_pipeline.display('_display_1d_placefield_validations', 'maze1_odd')\n",
    "_out.ui.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f301b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "programmatic_display_to_PDF(curr_active_pipeline, curr_display_function_name='_display_1d_placefield_validations', filter_name='maze1_odd', debug_print=True)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5d7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_1d_placefields', 'maze1_odd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77344ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_1d_placefields', 'maze2_even')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66fdc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO 2023-11-29 09:18: - [ ] Not good, the self.filtered_contexts are not unique!\n",
    "list(curr_active_pipeline.filtered_contexts.values())\n",
    "# [IdentifyingContext<(... 'maze2')>, IdentifyingContext<(... 'maze2')>, IdentifyingContext<(..., 'maze')>, IdentifyingContext<(... 'maze2')>, IdentifyingContext<(... 'maze2')>, IdentifyingContext<(..., 'maze')>, IdentifyingContext<(...ze1_any')>, IdentifyingContext<(... 'maze2')>, IdentifyingContext<(..., 'maze')>]\n",
    "[(v == curr_active_pipeline.filtered_contexts['maze1_even']) for v in list(curr_active_pipeline.filtered_contexts.values())]\n",
    "# [True, True, False, True, True, False, False, True, False]\n",
    "# meaning `curr_active_pipeline.display('_display_1d_placefields', curr_active_pipeline.filtered_contexts['maze1_even'])` doesn't work\n",
    "curr_active_pipeline.filtered_contexts.index(curr_active_pipeline.filtered_contexts['maze1_even'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4e9d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_1d_placefields', 'maze2_odd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a44c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_contexts['maze1_even']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcd14e5",
   "metadata": {},
   "source": [
    "# TODO 2023-11-27 18:20: - [ ] Generalized ordered sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac58b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "curr_active_pipeline.prepare_for_display()\n",
    "_out = curr_active_pipeline.display(DirectionalPlacefieldGlobalDisplayFunctions._display_directional_laps_overview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38faf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# recieves lists of identities (such as cell aclus) and a function that returns a sortable value for each identity:\n",
    "directional_laps_results = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=None) # non-shared-only\n",
    "decoders_dict = track_templates.get_decoders_dict() # decoders_dict = {'long_LR': track_templates.long_LR_decoder, 'long_RL': track_templates.long_RL_decoder, 'short_LR': track_templates.short_LR_decoder, 'short_RL': track_templates.short_RL_decoder, }\n",
    "\n",
    "neuron_IDs_lists = [a_decoder.neuron_IDs for a_decoder in decoders_dict.values()] # [A, B, C, D, ...]\n",
    "neuron_ID_sets = [set(a_list) for a_list in neuron_IDs_lists]\n",
    "individual_List_sort_indicies = [a_decoder.pf.ratemap.get_sort_indicies() for a_decoder in decoders_dict.values()] # [a_s, b_s, c_s, d_s, ...] individual sort indicies that can be applied to A, B, C, D, ..\n",
    "individual_sorted_neuron_IDs_lists = [a_list[a_sort] for a_list, a_sort in zip(neuron_IDs_lists, individual_List_sort_indicies)] # [A[a_s], B[b_s], C[c_s], D[d_s], ...]\n",
    "sortable_values_lists = [np.argmax(a_decoder.pf.ratemap.normalized_tuning_curves, axis=1) for a_decoder in decoders_dict.values()]\n",
    "# decoders_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.indexing_helpers import paired_incremental_sorting\n",
    "\n",
    "# epoch_active_aclus = np.array([9,  26,  31,  39,  40,  43,  47,  52,  53,  54,  60,  61,  65,  68,  72,  75,  77,  78,  81,  82,  84,  85,  90,  92,  93,  98, 102])\n",
    "\n",
    "neuron_IDs_lists = [a_decoder.neuron_IDs for a_decoder in decoders_dict.values()] # [A, B, C, D, ...]\n",
    "sort_helper_original_neuron_id_to_IDX_dicts = [dict(zip(neuron_ids, np.arange(len(neuron_ids)))) for neuron_ids in neuron_IDs_lists] # just maps each neuron_id in the list to a fragile_linear_IDX \n",
    "sortable_values_lists = [np.argmax(a_decoder.pf.ratemap.normalized_tuning_curves, axis=1) for a_decoder in decoders_dict.values()]\n",
    "sorted_neuron_IDs_lists = paired_incremental_sorting(neuron_IDs_lists, sortable_values_lists)\n",
    "# `sort_helper_neuron_id_to_sort_IDX_dicts` dictionaries in the appropriate order (sorted order) with appropriate indexes. Its .values() can be used to index into things originally indexed with aclus.\n",
    "sort_helper_neuron_id_to_sort_IDX_dicts = [{aclu:a_sort_helper_neuron_id_to_IDX_map[aclu] for aclu in sorted_neuron_ids} for a_sort_helper_neuron_id_to_IDX_map, sorted_neuron_ids in zip(sort_helper_original_neuron_id_to_IDX_dicts, sorted_neuron_IDs_lists)]\n",
    "\n",
    "print(sorted_neuron_IDs_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b05dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a set of values that can be larger than the entries in each list:\n",
    "any_list_neuron_IDs = np.sort(union_of_arrays(*neuron_IDs_lists)) # neuron_IDs as they appear in any list\n",
    "## build color values from these:\n",
    "n_neurons = len(any_list_neuron_IDs)\n",
    "_neuron_qcolors_list, neuron_colors_ndarray = DataSeriesColorHelpers.build_cell_colors(n_neurons, colormap_name='PAL-relaxed_bright', colormap_source=None)\n",
    "unit_colors_map: Dict = dict(zip(any_list_neuron_IDs, neuron_colors_ndarray.copy().T)) # Int:NDArray[(4,)] - {5: array([255, 157, 0.278431, 1]), 7: array([252.817, 175.545, 0.202502, 1]), ...}\n",
    "\n",
    "# `unit_colors_map` is main output\n",
    "# So unlike other attempts, these colors are sorted along with the aclus for each decoder, and we don't try to keep them separate. Since they're actually in a dict (where conceptually the order doesn't really matter) this should be indistinguishable performance-wise from other implementation.\n",
    "sort_helper_neuron_id_to_sort_IDX_dicts = [{aclu:unit_colors_map[aclu] for aclu in sorted_neuron_ids} for sorted_neuron_ids in sorted_neuron_IDs_lists] # [{72: array([11.2724, 145.455, 0.815335, 1]), 84: array([165, 77, 1, 1]), ...}, {72: array([11.2724, 145.455, 0.815335, 1]), 84: array([165, 77, 1, 1]), ...}, ...]\n",
    "sort_helper_neuron_id_to_sort_IDX_dicts\n",
    "# `sort_helper_neuron_id_to_sort_IDX_dicts` is main output here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604c2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# sorted_pf_tuning_curves = [a_decoder.pf.ratemap.pdf_normalized_tuning_curves[a_sort_list, :] for a_decoder, a_sort_list in zip(decoders_dict.values(), sorted_neuron_IDs_lists)]\n",
    "\n",
    "sorted_pf_tuning_curves = [a_decoder.pf.ratemap.pdf_normalized_tuning_curves[np.array(list(a_sort_helper_neuron_id_to_IDX_dict.values())), :] for a_decoder, a_sort_helper_neuron_id_to_IDX_dict in zip(decoders_dict.values(), sort_helper_neuron_id_to_sort_IDX_dicts)]\n",
    "sorted_pf_tuning_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fbdb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared_sort_IDX = _get_decoder_sorted_pfs(track_templates.long_LR_decoder)\n",
    "# track_templates.long_LR_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a572825",
   "metadata": {},
   "source": [
    "# EVEN: \"RL\", ODD: \"LR\"\n",
    "Starts with Even (idx=0)\n",
    "- EVEN: \"RL\"\n",
    "shared_RL_aclus_only_neuron_IDs\n",
    "`is_even = (an_epoch.lap_dir == 0)`\n",
    "- ODD: \"LR\"\n",
    "shared_LR_aclus_only_neuron_IDs\n",
    "`is_odd = (an_epoch.lap_dir == 1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac0ef2b",
   "metadata": {},
   "source": [
    "# 🟢 2023-10-20 - Z-Score Comparisons with Neuron_ID Shuffled templates\n",
    "1. Take the intersection of the long and short templates to get only the common cells\n",
    "2. Determine the long and short \"tempaltes\": this is done by ranking the aclus for each by their placefields' center of mass. `compute_placefield_center_of_masses`\n",
    "\t2a. `long_pf_peak_ranks`, `short_pf_peak_ranks` - there are one of each of these for each shared aclu.\n",
    "3. Generate the unit_id shuffled (`shuffled_aclus`, `shuffle_IDXs`) ahead of time to use to shuffle the two templates during the epochs.\n",
    "4. For each replay event, take each shuffled template\n",
    "\t4a. Iterate through each shuffle and obtain the shuffled templates like `long_pf_peak_ranks[epoch_specific_shuffled_indicies]`, `short_pf_peak_ranks[epoch_specific_shuffled_indicies]`\n",
    "\t4b. compute the spearman rank-order of the event and each shuffled template, and accumulate the results in `long_spearmanr_rank_stats_results`, `short_spearmanr_rank_stats_results`\n",
    "\n",
    "5. After we're done with the shuffle loop, accumulate the results and convert to the right output format.\n",
    "\n",
    "6. When all epochs are done, loop through the results (the epochs again) and compute the z-scores for each epoch so they can be compared to each other. Keep track of the means and std_dev for comparisons later, and subtract the two sets of z-scores (long/short) to get the delta_Z for each template.\n",
    "\n",
    "7. TODO: Next figure out what to do with the array of z-scores and delta_Z. We have:\n",
    "\tn_epochs sets of results\n",
    "\t\tn_shuffles scores of delta_Z\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd9d61",
   "metadata": {},
   "source": [
    "## Convo with Kamran 2023-10-23:\n",
    "- Use directional templates **\n",
    "- No need to worry about re-ranking\n",
    "[X] Plot the long and short separately in addition to the difference, so we show significant reqplay on each as a sanity check\n",
    "[X] Absolute value difference?\n",
    "[X] Fisher transform the correlation values (check if there is a difference) because correlation coefficients aren't going to be normally distributed.\n",
    "\t[ ] Then Z-score releative to fisher.\n",
    "\n",
    "- T-test to compare to mean of zero (if looking at the difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ffd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concerns:\n",
    "# 1. Permutation recommended over shuffling for small numbers of ids\n",
    "# 2.\n",
    "\n",
    "# 5Hz thresholding of templates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec58689d",
   "metadata": {},
   "source": [
    "## Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd86cb20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:22:34.093953500Z",
     "start_time": "2023-11-16T23:22:33.960957900Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nptyping import NDArray\n",
    "from attrs import define, field, Factory, astuple\n",
    "import scipy.stats\n",
    "from scipy import ndimage\n",
    "from neuropy.utils.misc import build_shuffled_ids # used in _SHELL_analyze_leave_one_out_decoding_results\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import pho_stats_paired_t_test\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer, RankOrderResult\n",
    "\n",
    "# minimum_inclusion_fr_Hz: float = 2.0\n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "\n",
    "# Recover from the saved global result:\n",
    "directional_laps_results = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "# NEW 2023-11-22 method: Get the templates (which can be filtered by frate first) and the from those get the decoders):        \n",
    "# track_templates: TrackTemplates = directional_laps_results.get_shared_aclus_only_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # shared-only\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only\n",
    "long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = track_templates.get_decoders()\n",
    "\n",
    "## Pre 2023-11-22 method: building a TrackTemplates object after getting the raw decoders:\n",
    "# long_LR_one_step_decoder_1D, long_RL_one_step_decoder_1D, short_LR_one_step_decoder_1D, short_RL_one_step_decoder_1D = directional_laps_results.get_decoders()\n",
    "# long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = directional_laps_results.get_shared_aclus_only_decoders()\n",
    "# track_templates: TrackTemplates = TrackTemplates.init_from_paired_decoders(LR_decoder_pair=(long_LR_decoder, short_LR_decoder), RL_decoder_pair=(long_RL_decoder, short_RL_decoder))\n",
    "# # track_templates: TrackTemplates = TrackTemplates.init_from_paired_decoders(LR_decoder_pair=(long_LR_one_step_decoder_1D, short_LR_one_step_decoder_1D), RL_decoder_pair=(long_RL_one_step_decoder_1D, short_RL_one_step_decoder_1D)) # NOTE: now use the un-constrained versions\n",
    "\n",
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n",
    "\n",
    "LR_results_real_values = np.array([(long_stats_z_scorer.real_value, short_stats_z_scorer.real_value) for epoch_id, (long_stats_z_scorer, short_stats_z_scorer, long_short_z_diff, long_short_naive_z_diff, is_forward_replay) in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "RL_results_real_values = np.array([(long_stats_z_scorer.real_value, short_stats_z_scorer.real_value) for epoch_id, (long_stats_z_scorer, short_stats_z_scorer, long_short_z_diff, long_short_naive_z_diff, is_forward_replay) in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n",
    "\n",
    "LR_results_long_short_z_diffs = np.array([long_short_z_diff for epoch_id, (long_stats_z_scorer, short_stats_z_scorer, long_short_z_diff, long_short_naive_z_diff, is_forward_replay) in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "RL_results_long_short_z_diff = np.array([long_short_z_diff for epoch_id, (long_stats_z_scorer, short_stats_z_scorer, long_short_z_diff, long_short_naive_z_diff, is_forward_replay) in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n",
    "\n",
    "\n",
    "# LR_results_real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a383a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_order_results.LR_laps.spikes_df\n",
    "\n",
    "track_templates.filtered_by_frate(minimum_inclusion_fr_Hz=10.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71203955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.neuron_identities import NeuronType\n",
    "\n",
    "def determine_good_aclus_by_qclu(curr_active_pipeline, included_qclu_values=[1,2,4,9]):\n",
    "\t\"\"\" \n",
    "\tFrom all neuron_IDs in the session, get the ones that meet the new qclu criteria (their value is in) `included_qclu_values`\n",
    "\t\n",
    "\tincluded_aclus = determine_good_aclus_by_qclu(curr_active_pipeline, included_qclu_values=[1,2,4,9])\n",
    "\tincluded_aclus\n",
    "\n",
    "\t\"\"\"\n",
    "\tfrom neuropy.core.neuron_identities import NeuronType\n",
    "\t\n",
    "\tneuron_identities: pd.DataFrame = curr_active_pipeline.get_session_unique_aclu_information()\n",
    "\tprint(f\"original {len(neuron_identities)}\")\n",
    "\tfiltered_neuron_identities: pd.DataFrame = neuron_identities[neuron_identities.neuron_type == NeuronType.PYRAMIDAL]\n",
    "\tprint(f\"post PYRAMIDAL filtering {len(filtered_neuron_identities)}\")\n",
    "\tfiltered_neuron_identities = filtered_neuron_identities[['aclu', 'shank', 'cluster', 'qclu']]\n",
    "\tfiltered_neuron_identities = filtered_neuron_identities[np.isin(filtered_neuron_identities.qclu, included_qclu_values)] # drop [6, 7], which are said to have double fields - 80 remain\n",
    "\tprint(f\"post (qclu != [6, 7]) filtering {len(filtered_neuron_identities)}\")\n",
    "\treturn filtered_neuron_identities.aclu.to_numpy()\n",
    "\n",
    "\n",
    "included_aclus = determine_good_aclus_by_qclu(curr_active_pipeline, included_qclu_values=[1,2,4,9])\n",
    "included_aclus\n",
    "\n",
    "track_templates.fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c59b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "track_templates.shared_LR_aclus_only_neuron_IDs\n",
    "track_templates.shared_RL_aclus_only_neuron_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.long_LR_decoder.neuron_IDs\n",
    "ratemap = track_templates.long_LR_decoder.ratemap\n",
    "# ratemap.neuron_extended_ids\n",
    "\n",
    "track_templates.long_LR_decoder.spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.shared_LR_aclus_only_neuron_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c66001",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_results_long_short_z_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms:\n",
    "\n",
    "def plot_rank_order_histograms(number_of_bins: int = 21):\n",
    "    \"\"\" plots 1D histograms from the rank-order shuffled data during the ripples. \n",
    "    \n",
    "    https://pandas.pydata.org/pandas-docs/version/0.24.1/user_guide/visualization.html\n",
    "    \n",
    "    Captures: rank_order_results, minimum_inclusion_fr_Hz, curr_active_pipeline.get_session_context().get_description()\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # fig = build_or_reuse_figure(fignum=f'1D Histograms')\n",
    "    # ax1 = fig.add_subplot(3, 1, 1)\n",
    "    # ax2 = fig.add_subplot(3, 1, 2)\n",
    "    # ax3 = fig.add_subplot(3, 1, 3)\n",
    "\n",
    "    ax1, ax2, ax3 = None, None, None\n",
    "    _out_z_score = pd.DataFrame({'LR_long_z_scores': rank_order_results.LR_ripple.long_z_score, 'LR_short_z_scores': rank_order_results.LR_ripple.short_z_score,\n",
    "              'RL_long_z_scores': rank_order_results.RL_ripple.long_z_score, 'RL_short_z_scores': rank_order_results.RL_ripple.short_z_score}).hist(bins=number_of_bins, ax=ax1, sharex=True, sharey=True)\n",
    "    plt.suptitle(f'Ripple Z-scores: {minimum_inclusion_fr_Hz} Hz\\n{curr_active_pipeline.get_session_context().get_description()}')\n",
    "\n",
    "    _out_real = pd.DataFrame({'LR_long_real_corr': np.squeeze(LR_results_real_values[:,0]), 'LR_short_real_corr': np.squeeze(LR_results_real_values[:,1]),\n",
    "              'RL_long_real_corr': np.squeeze(RL_results_real_values[:,0]), 'RL_short_real_corr': np.squeeze(RL_results_real_values[:,1])}).hist(bins=number_of_bins, ax=ax2, sharex=True, sharey=True)\n",
    "    plt.suptitle(f'Ripple real correlations: {minimum_inclusion_fr_Hz} Hz\\n{curr_active_pipeline.get_session_context().get_description()}')\n",
    "\n",
    "    _out_most_likely_z = pd.DataFrame({'most_likely_long_z_scores': rank_order_results.ripple_most_likely_result_tuple.long_best_dir_z_score_values, 'most_likely_short_z_scores': rank_order_results.ripple_most_likely_result_tuple.short_best_dir_z_score_values}).hist(bins=number_of_bins, ax=ax3, sharex=True, sharey=True)\n",
    "    plt.suptitle(f'Ripple Most-likely z-scores: {minimum_inclusion_fr_Hz} Hz\\n{curr_active_pipeline.get_session_context().get_description()}')\n",
    "\n",
    "    return _out_z_score, _out_real, _out_most_likely_z\n",
    "\n",
    "_out_z_score, _out_real, _out_most_likely_z = plot_rank_order_histograms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 2023-12-10 19:56: - [ ] Histogram Display Helpers\n",
    "#TODO 2023-12-10 19:56: - [ ] Pf1D Helpers\n",
    "#TODO 2023-12-10 19:57: - [ ] Variant Saving\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56890830",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = pg.GraphicsLayoutWidget(show=True)\n",
    "win.resize(800,350)\n",
    "win.setWindowTitle('Pho pyqtgraph marginal histogram testing')\n",
    "plt1 = win.addPlot()\n",
    "plt2 = win.addPlot()\n",
    "\n",
    "## compute standard histogram\n",
    "number_of_bins: int = 21\n",
    "vals = deepcopy(LR_results_long_short_z_diffs)\n",
    "# y,x = np.histogram(vals, bins=np.linspace(-3, 8, 40))\n",
    "\n",
    "y,x = np.histogram(vals, bins=number_of_bins)\n",
    "\n",
    "# plt1.plot(vals, y, pen=None, symbol='o', symbolSize=5, symbolPen=(255,255,255,200), symbolBrush=(0,0,255,150))\n",
    "\n",
    "## Using stepMode=\"center\" causes the plot to draw two lines for each sample.\n",
    "## notice that len(x) == len(y)+1\n",
    "plt1.plot(x, y, stepMode=\"center\", fillLevel=0, fillOutline=True, brush=(0,0,255,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f150d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the histogram\n",
    "hist, bins = np.histogram(y, bins='auto')\n",
    "\n",
    "# Create a new axis\n",
    "axis = pg.AxisItem('right')\n",
    "plot.layout.addItem(axis, 2, 1)\n",
    "axis.linkToView(plot.getViewBox())\n",
    "\n",
    "# Create a bar graph item\n",
    "hist_plot = pg.BarGraphItem(x=bins[:-1], height=hist, width=np.diff(bins), brush='r')\n",
    "plot.addItem(hist_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9036d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_active_pipeline.get_session_context().get_description()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59639f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qtpy import QtGui # for QColor\n",
    "from qtpy.QtGui import QColor, QBrush, QPen\n",
    "from pyphocorehelpers.gui.Qt.color_helpers import ColorFormatConverter\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import DataSeriesColorHelpers\n",
    "\n",
    "[ColorFormatConverter.qColor_to_hexstring(a_qcolor, include_alpha=False) for a_qcolor in RL_unit_colors_list]\n",
    "\n",
    "['#ff9d47', '#fdab39', '#fcb82b', '#fac61c', '#f9d30e', '#f7e100', '#e9dd00', '#dcda00', '#ced600', '#c1d300', '#b3cf00', '#95cc0c', '#77ca17', '#5ac723', '#3cc52e', '#1ec23a', '#18bb53', '#12b46b', '#0cae84', '#06a79c', '#00a0b5', '#0698c4', '#0c90d3', '#1388e1', '#1980f0', '#1f78ff', '#3a6fff', '#5567ff', '#6f5eff', '#8a56ff', '#a54dff', '#b146ee', '#bd40dc', '#ca39cb', '#d633b9', '#e22ca8', '#e8348f', '#ee3c76', '#f3435d', '#f94b44', '#ff532b', '#ff6231', '#ff7136', '#ff7f3c', '#ff8e41', '#ff9d47']\n",
    "\n",
    "\n",
    "render_colors([ColorFormatConverter.qColor_to_hexstring(a_qcolor, include_alpha=False) for a_qcolor in RL_unit_colors_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ed6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_decoder_list = [filtered_by_frate(a_decoder, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, debug_print=True) for a_decoder in (long_LR_one_step_decoder_1D, long_RL_one_step_decoder_1D, short_LR_one_step_decoder_1D, short_RL_one_step_decoder_1D)]\n",
    "original_neuron_ids_list = [a_decoder.pf.ratemap.neuron_ids for a_decoder in (long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder)]\n",
    "is_aclu_included_list = [a_decoder.pf.ratemap.tuning_curve_unsmoothed_peak_firing_rates >= minimum_inclusion_fr_Hz for a_decoder in (long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder)]\n",
    "filtered_aclus_list = [np.array(a_decoder.pf.ratemap.neuron_ids)[a_decoder.pf.ratemap.tuning_curve_unsmoothed_peak_firing_rates >= minimum_inclusion_fr_Hz] for a_decoder in (long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder)]\n",
    "\n",
    "## For a given run direction (LR/RL) let's require inclusion in either (OR) long v. short to be included.\n",
    "filtered_included_LR_aclus = np.union1d(filtered_aclus_list[0], filtered_aclus_list[2])\n",
    "filtered_included_RL_aclus = np.union1d(filtered_aclus_list[1], filtered_aclus_list[3])\n",
    "# build the final shared aclus:\n",
    "filtered_direction_shared_aclus_list = [filtered_included_LR_aclus, filtered_included_RL_aclus, filtered_included_LR_aclus, filtered_included_RL_aclus] # contains the shared aclus for that direction\n",
    "# rebuild the is_aclu_included_list from the shared aclus\n",
    "is_aclu_included_list = [np.isin(an_original_neuron_ids, a_filtered_neuron_ids) for an_original_neuron_ids, a_filtered_neuron_ids in zip(original_neuron_ids_list, filtered_direction_shared_aclus_list)]\n",
    "\n",
    "# is_aclu_included_list[0]\n",
    "filtered_direction_shared_aclus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017813cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for 5Hz:\n",
    "# [array([  5,   7,  31,  39,  41,  45,  46,  48,  50,  55,  61,  62,  64,  69,  72,  75,  76,  78,  79,  83,  84,  86,  88,  90,  91,  92,  95,  99, 100, 108]),\n",
    "#  array([  5,   7,   9,  31,  32,  39,  41,  45,  46,  48,  50,  55,  61,  62,  64,  69,  72,  75,  76,  78,  79,  83,  84,  86,  88,  90,  91,  92,  93,  95,  99, 101, 108]),\n",
    "#  array([  5,   7,  31,  39,  41,  45,  46,  48,  50,  55,  61,  62,  64,  69,  72,  75,  76,  78,  79,  83,  84,  86,  88,  90,  91,  92,  95,  99, 100, 108]),\n",
    "#  array([  5,   7,   9,  31,  32,  39,  41,  45,  46,  48,  50,  55,  61,  62,  64,  69,  72,  75,  76,  78,  79,  83,  84,  86,  88,  90,  91,  92,  93,  95,  99, 101, 108])]\n",
    "\n",
    "# # for 20Hz:\n",
    "# [array([  5,  41,  46,  48,  69,  78,  79,  83,  86,  88,  90, 108]),\n",
    "#  array([ 62,  64,  75,  78,  83,  91, 101]),\n",
    "#  array([  5,  41,  46,  48,  69,  78,  79,  83,  86,  88,  90, 108]),\n",
    "#  array([ 62,  64,  75,  78,  83,  91, 101])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ccfe1f",
   "metadata": {},
   "source": [
    "# 2023-11-22 - RECOMPUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22e7090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalLapsHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "## clear the old values to prepare for the new ones:\n",
    "curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'] = None\n",
    "curr_active_pipeline.global_computation_results.computed_data['RankOrder'] = None\n",
    "del curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "del curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "\n",
    "curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'] = DirectionalLapsHelpers.build_global_directional_result_from_natural_epochs(curr_active_pipeline, progress_print=True) # repalce the directional laps object\n",
    "\n",
    "\n",
    "minimum_inclusion_fr_Hz = 2.0\n",
    "\n",
    "# perform_rank_order_shuffle_analysis\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-perform_rank_order_shuffle_analysis_{curr_active_pipeline.session_name}.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "RankOrderGlobalComputationFunctions.perform_rank_order_shuffle_analysis(curr_active_pipeline, curr_active_pipeline.global_computation_results, None, None, include_includelist=None, debug_print=False,\n",
    "                                                                        num_shuffles=1000, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, skip_laps=True)\n",
    "\n",
    "\n",
    "# 10m 29.5s for 1000 shuffles.  c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\viztracer_2023-11-22_16-11-perform_rank_order_shuffle_analysis.json\n",
    "\n",
    "# 3m 33.9s - 500\n",
    "# 3m 26.4s - 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f0638",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Result tuples come from `RankOrderAnalyses.most_likely_directional_rank_order_shuffling`\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses\n",
    "\n",
    "\n",
    "curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_most_likely_result_tuple, curr_active_pipeline.global_computation_results.computed_data['RankOrder'].laps_most_likely_result_tuple = RankOrderAnalyses.most_likely_directional_rank_order_shuffling(curr_active_pipeline, decoding_time_bin_size=0.01) # 10ms bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8bf34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_spikes_df, (odd_shuffle_helper, even_shuffle_helper) = RankOrderAnalyses.common_analysis_helper(curr_active_pipeline=curr_active_pipeline, num_shuffles=num_shuffles, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426c292d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Saving/Loading `DirectionalLaps_2Hz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8cd6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-11-27 - I'd like to be able to save/load single results a time, (meaning specific to their parameters):\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData\n",
    "\n",
    "# list = ['2Hz', '12Hz']\n",
    "\n",
    "day_date_str: str = '2023-12-08_'\n",
    "directional_laps_output_path = curr_active_pipeline.get_output_path().joinpath(f'{day_date_str}DirectionalLaps_2Hz.pkl').resolve()\n",
    "saveData(directional_laps_output_path, (curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'], curr_active_pipeline.global_computation_results.computed_data['RankOrder']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2230163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import loadData\n",
    "\n",
    "\n",
    "# Load the data from a file into the pipeline:\n",
    "day_date_str: str = '2023-12-08_'\n",
    "# day_date_str: str = ''\n",
    "directional_laps_output_path = curr_active_pipeline.get_output_path().joinpath(f'{day_date_str}DirectionalLaps_2Hz.pkl').resolve()\n",
    "assert directional_laps_output_path.exists()\n",
    "loaded_directional_laps, loaded_rank_order = loadData(directional_laps_output_path)\n",
    "assert (loaded_directional_laps is not None)\n",
    "assert (loaded_rank_order is not None)\n",
    "# Apply the loaded data to the pipeline:\n",
    "curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'], curr_active_pipeline.global_computation_results.computed_data['RankOrder'] = loaded_directional_laps, loaded_rank_order\n",
    "curr_active_pipeline.global_computation_results.computed_data['RankOrder']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec24467335a760",
   "metadata": {},
   "source": [
    "# POST-Compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "728c46e6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum_inclusion_fr_Hz: 2.0\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multi_sort_raster_browser\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import paired_separately_sort_neurons, paired_incremental_sort_neurons # _display_directional_template_debugger\n",
    "from neuropy.utils.indexing_helpers import paired_incremental_sorting, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ScrollBarWithSpinBox.ScrollBarWithSpinBox import ScrollBarWithSpinBox\n",
    "\n",
    "# pg.setConfigOption('background', 'w')\n",
    "# pg.setConfigOption('foreground', 'k')\n",
    "\n",
    "spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "ripple_result_tuple, laps_result_tuple = rank_order_results.ripple_most_likely_result_tuple, rank_order_results.laps_most_likely_result_tuple\n",
    "directional_laps_results = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "ripple_result_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef2701",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_order_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a722e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_order_results.LR_laps.long_z_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfbe341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find only the significant events (|z| > 1.96):\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses\n",
    "\n",
    "filtered_z_score_df, (n_events, n_significant_events, percent_significant_events) = RankOrderAnalyses.find_only_significant_events(rank_order_results, high_z_criteria=1.96)\n",
    "filtered_z_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86532662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-11-20 - Finding high-significance periods for Kamran:\n",
    "z_threshold = 1.96\n",
    "is_greater_than_z_threshold_long = (np.abs(ripple_result_tuple.long_best_dir_z_score_values) > z_threshold)\n",
    "is_greater_than_z_threshold_short = (np.abs(ripple_result_tuple.short_best_dir_z_score_values) > z_threshold)\n",
    "is_significant_either = np.logical_or(is_greater_than_z_threshold_long, is_greater_than_z_threshold_short)\n",
    "\n",
    "# is_greater_than_3std_long = (np.abs(ripple_result_tuple.long_best_dir_z_score_values) >= 3.0)\n",
    "# is_greater_than_3std_short = (np.abs(ripple_result_tuple.short_best_dir_z_score_values) >= 3.0)\n",
    "# is_significant_either = np.logical_or(is_greater_than_3std_long, is_greater_than_3std_short)\n",
    "\n",
    "significant_ripple_epochs = deepcopy(global_replays).boolean_indicies_slice(is_significant_either)\n",
    "significant_ripple_epochs.to_dataframe()\n",
    "\n",
    "# significant_ripple_epochs.filename = Path(f'output/2023-11-27_SignificantReplayRipples').resolve()\n",
    "# significant_ripple_epochs.to_neuroscope()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8beece",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_result_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616af69",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "## RankOrderRastersDebugger: \n",
    "_out_rank_order_event_raster_debugger = RankOrderRastersDebugger.init_rank_order_debugger(spikes_df, ripple_result_tuple.active_epochs, track_templates, rank_order_results.RL_ripple.selected_spikes_fragile_linear_neuron_IDX_dict, rank_order_results.LR_ripple.selected_spikes_fragile_linear_neuron_IDX_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac746d8",
   "metadata": {},
   "source": [
    "## Connects TemplatesDebugger to RasterDebugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4e5be",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import generate_html_string\n",
    "\n",
    "## Unpacks `rank_order_results`: \n",
    "spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "global_replays = Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# global_replays.filename = Path('output/2023-11-16_phoEvents.mew.evt').resolve()\n",
    "# global_replays.to_neuroscope()\n",
    "\n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "ripple_result_tuple, laps_result_tuple = rank_order_results.ripple_most_likely_result_tuple, rank_order_results.laps_most_likely_result_tuple\n",
    "\n",
    "# Extract the real spearman-values/p-values:\n",
    "LR_long_relative_real_p_values = np.array([x[0].real_p_value for x in rank_order_results.LR_ripple.ranked_aclus_stats_dict.values()])\n",
    "LR_long_relative_real_values = np.array([x[0].real_value for x in rank_order_results.LR_ripple.ranked_aclus_stats_dict.values()])\n",
    "\n",
    "LR_short_relative_real_p_values = np.array([x[1].real_p_value for x in rank_order_results.LR_ripple.ranked_aclus_stats_dict.values()])\n",
    "LR_short_relative_real_values = np.array([x[1].real_value for x in rank_order_results.LR_ripple.ranked_aclus_stats_dict.values()])\n",
    "\n",
    "LR_template_epoch_actually_included_aclus = [v[1] for v in rank_order_results.LR_ripple.extra_info_dict.values()] # (template_epoch_neuron_IDXs, template_epoch_actually_included_aclus, epoch_neuron_IDX_ranks)\n",
    "LR_relative_num_cells = np.array([len(v[1]) for v in rank_order_results.LR_ripple.extra_info_dict.values()])\n",
    "\n",
    "RL_long_relative_real_p_values = np.array([x[0].real_p_value for x in rank_order_results.RL_ripple.ranked_aclus_stats_dict.values()])\n",
    "RL_long_relative_real_values = np.array([x[0].real_value for x in rank_order_results.RL_ripple.ranked_aclus_stats_dict.values()])\n",
    "\n",
    "RL_short_relative_real_p_values = np.array([x[1].real_p_value for x in rank_order_results.RL_ripple.ranked_aclus_stats_dict.values()])\n",
    "RL_short_relative_real_values = np.array([x[1].real_value for x in rank_order_results.RL_ripple.ranked_aclus_stats_dict.values()])\n",
    "\n",
    "RL_template_epoch_actually_included_aclus = [v[1] for v in rank_order_results.RL_ripple.extra_info_dict.values()] # (template_epoch_neuron_IDXs, template_epoch_actually_included_aclus, epoch_neuron_IDX_ranks)\n",
    "RL_relative_num_cells = np.array([len(v[1]) for v in rank_order_results.RL_ripple.extra_info_dict.values()])\n",
    "\n",
    "# LR_relative_num_cells = np.array([len(x) for x in rank_order_results.LR_ripple.selected_spikes_fragile_linear_neuron_IDX_dict.values()])\n",
    "# RL_relative_num_cells = np.array([len(x) for x in rank_order_results.RL_ripple.selected_spikes_fragile_linear_neuron_IDX_dict.values()])\n",
    "\n",
    "rank_order_results_debug_values = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'), ([LR_long_relative_real_values, LR_long_relative_real_p_values], [RL_long_relative_real_values, RL_long_relative_real_p_values], [LR_short_relative_real_values, LR_short_relative_real_p_values], [RL_short_relative_real_values, RL_short_relative_real_p_values])))\n",
    "\n",
    "def debug_update_plot_titles(a_plotter, an_idx: int):\n",
    "\t\"\"\" Updates the titles of each of the four rasters with the appropriate spearman rho value.\n",
    "\tcaptures: rank_order_results_debug_values, \n",
    "\t\"\"\"\n",
    "\tfor a_decoder_name, a_root_plot in a_plotter.plots.root_plots.items():\n",
    "\t\ta_real_value = rank_order_results_debug_values[a_decoder_name][0][an_idx]\n",
    "\t\tprint(f'a_decoder_name: {a_decoder_name}, a_real_value: {a_real_value:0.3f}')\n",
    "\t\treal_value_str = generate_html_string(f'{a_real_value:0.3f}', color='white', bold=True)\n",
    "\t\t# j_str = generate_html_string('j', color='red', bold=True)\n",
    "\t\ttitle_str = generate_html_string(f'{a_decoder_name}: spearman: {real_value_str}')\n",
    "\t\ta_root_plot.setTitle(title=title_str)\n",
    "\n",
    "\n",
    "def debug_update_long_short_info_titles(a_plotter, an_idx: int):\n",
    "\t\"\"\" Updates the titles of each of the four rasters with the appropriate spearman rho value.\n",
    "\tcaptures: ripple_result_tuple, \n",
    "\t\"\"\"\n",
    "\thas_long_short_info_labels = (hasattr(a_plotter.ui, 'long_info_label') and hasattr(a_plotter.ui, 'short_info_label'))\n",
    "\tif has_long_short_info_labels:\n",
    "\t\tlong_best_dir_z_score_value_str = generate_html_string(f'{float(ripple_result_tuple.long_best_dir_z_score_values[an_idx]):0.3f}', color='black', bold=True)\n",
    "\t\tshort_best_dir_z_score_value_str = generate_html_string(f'{float(ripple_result_tuple.short_best_dir_z_score_values[an_idx]):0.3f}', color='black', bold=True)\n",
    "\t\t# j_str = generate_html_string('j', color='red', bold=True)\n",
    "\t\ta_plotter.ui.long_info_label.setText(generate_html_string(f'LONG best_dir_z_score_value: {long_best_dir_z_score_value_str}'))\n",
    "\t\ta_plotter.ui.short_info_label.setText(generate_html_string(f'SHORT best_dir_z_score_value: {short_best_dir_z_score_value_str}'))\n",
    "\telse:\n",
    "\t\tprint(f'WARN: debug_update_long_short_info_titles(...) but plotter does not have the `a_plotter.ui.long_info_label`')\n",
    "\t\t\n",
    "\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "# epoch_active_aclus = np.array([9,  26,  31,  39,  40,  43,  47,  52,  53,  54,  60,  61,  65,  68,  72,  75,  77,  78,  81,  82,  84,  85,  90,  92,  93,  98, 102]) # some test indicies\n",
    "epoch_active_aclus = None\n",
    "_out_directional_template_pfs_debugger = curr_active_pipeline.display(DirectionalPlacefieldGlobalDisplayFunctions._display_directional_template_debugger, included_any_context_neuron_ids=epoch_active_aclus, figure_name=f'<Controlled by RankOrderRastersDebugger>')\n",
    "\n",
    "\n",
    "def debug_update_paired_directional_template_pfs_debugger(a_plotter, an_idx: int):\n",
    "\t\"\"\" captures: _out_directional_template_pfs_debugger, \"\"\"\n",
    "\tepoch_active_aclus = deepcopy(a_plotter.get_epoch_active_aclus())\n",
    "\t# update the displayed cells:\n",
    "\tdirectional_template_pfs_debugger_on_update_callback = _out_directional_template_pfs_debugger.get('ui').on_update_callback\n",
    "\tdirectional_template_pfs_debugger_on_update_callback(epoch_active_aclus)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import io\n",
    "from contextlib import redirect_stdout # used by DocumentationFilePrinter to capture print output\n",
    "\n",
    "def a_debug_callback_fn(a_plotter, an_idx: int):\n",
    "\tglobal epoch_active_aclus, _out_directional_template_pfs_debugger\n",
    "\tout = io.StringIO()\n",
    "\t# _out.on_update_epoch_IDX(an_idx)\n",
    "\twith redirect_stdout(out):\n",
    "\t\tprint(f'active_epoch_IDX: {an_idx}')\n",
    "\t\tprint(f'')\n",
    "\t\tprint(f'LR_long_relative_real_values[an_idx]: {LR_long_relative_real_values[an_idx]}, LR_long_relative_real_p_values[an_idx]: {LR_long_relative_real_p_values[an_idx]}')\n",
    "\t\tprint(f'LR_short_relative_real_values[an_idx]: {LR_short_relative_real_values[an_idx]}, LR_short_relative_real_p_values[an_idx]: {LR_short_relative_real_p_values[an_idx]}')\n",
    "\t\tprint(f'LR_ripple.long_z_score[an_idx]: {rank_order_results.LR_ripple.long_z_score[an_idx]}, LR_ripple.short_z_score[an_idx]: {rank_order_results.LR_ripple.short_z_score[an_idx]}')\n",
    "\t\tprint(f'RL_long_relative_real_values[an_idx]: {RL_long_relative_real_values[an_idx]}, RL_long_relative_real_p_values[an_idx]: {RL_long_relative_real_p_values[an_idx]}')\n",
    "\t\tprint(f'RL_short_relative_real_values[an_idx]: {RL_short_relative_real_values[an_idx]}, RL_short_relative_real_p_values[an_idx]: {RL_short_relative_real_p_values[an_idx]}')\n",
    "\t\tprint(f'RL_ripple.long_z_score[an_idx]: {rank_order_results.RL_ripple.long_z_score[an_idx]}, RL_ripple.short_z_score[an_idx]: {rank_order_results.RL_ripple.short_z_score[an_idx]}')\n",
    "\t\tprint(f'LR_relative_num_cells[an_idx]: {LR_relative_num_cells[an_idx]}, RL_relative_num_cells[an_idx]: {RL_relative_num_cells[an_idx]}')\n",
    "\t\tprint(f'LR_template_epoch_actually_included_aclus[an_idx]: {LR_template_epoch_actually_included_aclus[an_idx]}, RL_template_epoch_actually_included_aclus[an_idx]: {RL_template_epoch_actually_included_aclus[an_idx]}')\n",
    "\t\t# display(LR_template_epoch_actually_included_aclus[an_idx])\n",
    "\t\t# display(RL_template_epoch_actually_included_aclus[an_idx])\n",
    "\t\tepoch_active_aclus = np.sort(union_of_arrays(LR_template_epoch_actually_included_aclus[an_idx], RL_template_epoch_actually_included_aclus[an_idx]))\n",
    "\t\tprint(f'epoch_active_aclus: {epoch_active_aclus}')\n",
    "\t\t\n",
    "\ta_plotter.write_to_log(str(out.getvalue()))\n",
    "\t# # update the displayed cells:\n",
    "\t# directional_template_pfs_debugger_on_update_callback = _out_directional_template_pfs_debugger.get('ui').on_update_callback\n",
    "\t# directional_template_pfs_debugger_on_update_callback(epoch_active_aclus)\n",
    "\t# _out_directional_template_pfs_debugger = curr_active_pipeline.display(DirectionalPlacefieldGlobalDisplayFunctions._display_directional_template_debugger, included_any_context_neuron_ids=epoch_active_aclus)\n",
    "\t\n",
    "\t# rank_order_results.ripple_most_likely_result_tuple.long_short_best_dir_z_score_diff_values[an_idx]\n",
    "\t# display(LR_template_epoch_actually_included_aclus[an_idx])\n",
    "\t# display(RL_template_epoch_actually_included_aclus[an_idx])\n",
    "\n",
    "\n",
    "_out_rank_order_event_raster_debugger.on_idx_changed_callback_function_dict['a_debug_callback'] = a_debug_callback_fn\n",
    "_out_rank_order_event_raster_debugger.on_idx_changed_callback_function_dict['debug_update_plot_titles_callback'] = debug_update_plot_titles\n",
    "_out_rank_order_event_raster_debugger.on_idx_changed_callback_function_dict['debug_update_paired_directional_template_pfs_debugger'] = debug_update_paired_directional_template_pfs_debugger\n",
    "_out_rank_order_event_raster_debugger.on_idx_changed_callback_function_dict['debug_update_long_short_info_titles'] = debug_update_long_short_info_titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c9ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.matplotlib_fname() # '/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/mpl-data/matplotlibrc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba29ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a2ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36883563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db858d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "_out_rank_order_event_raster_debugger.on_update_epoch_IDX(298)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0787873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_result_tuple.directional_likelihoods_tuple[0][248]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cef07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig\n",
    "\n",
    "root_dockAreaWindow = _out_rank_order_event_raster_debugger.ui.root_dockAreaWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ab10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_LR_dock = root_dockAreaWindow.find_display_dock('long_LR')\n",
    "short_LR_dock = root_dockAreaWindow.find_display_dock('short_LR')\n",
    "\n",
    "\n",
    "long_short_info_layout = pg.LayoutWidget()\n",
    "\n",
    "long_info_label = long_short_info_layout.addLabel(text='LONG', row=0, col=0)\n",
    "short_info_label = long_short_info_layout.addLabel(text='SHORT', row=0, col=1)\n",
    "\n",
    "# ['left', long_LR_dock]\n",
    "# \n",
    "_out_rank_order_event_raster_debugger.plots.dock_widgets['left_Long_best_result_dock'] = root_dockAreaWindow.add_display_dock(identifier='left_Long_best_result_dock', widget=long_short_info_layout, dockSize=(600,60), dockAddLocationOpts=['top'], display_config=CustomDockDisplayConfig(showCloseButton=False, corner_radius='0px'))\n",
    "_out_rank_order_event_raster_debugger.plots.dock_widgets['left_Long_best_result_dock'][1].hideTitleBar() # hide the dock title bar\n",
    "\n",
    "# Add the widgets to the .ui:\n",
    "_out_rank_order_event_raster_debugger.ui.long_short_info_layout = long_short_info_layout\n",
    "_out_rank_order_event_raster_debugger.ui.long_info_label = long_info_label\n",
    "_out_rank_order_event_raster_debugger.ui.short_info_label = short_info_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a7a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a839f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_rank_order_event_raster_debugger.ui.ctrls_widget.setValue(298)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a91522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unit_sort_orders_dict = dict(zip(['long_LR', 'long_RL', 'short_LR', 'short_RL'], (long_LR, long_RL, short_LR, short_RL)))\n",
    "display('unit_sort_orders_dict')\n",
    "display(unit_sort_orders_dict)\n",
    "unit_unordered_neuron_IDs_dict = dict(zip(['long_LR', 'long_RL', 'short_LR', 'short_RL'], (track_templates.long_LR_decoder.neuron_IDs, track_templates.long_RL_decoder.neuron_IDs, track_templates.short_LR_decoder.neuron_IDs, track_templates.short_RL_decoder.neuron_IDs)))\n",
    "unit_ordered_neuron_IDs_dict = {a_decoder_name:neuron_IDs[unit_sort_orders_dict[a_decoder_name]] for a_decoder_name, neuron_IDs in unit_unordered_neuron_IDs_dict.items()}\n",
    "unit_ordered_neuron_IDs_dict\n",
    "\n",
    "display(f'unit_unordered_neuron_IDs_dict')\n",
    "display(unit_unordered_neuron_IDs_dict)\n",
    "# unit_unordered_neuron_IDs_dict:\n",
    "# {'long_RL': array([  9,  10,  11,  15,  16,  18,  24,  25,  26,  31,  39,  40,  43,  44,  47,  48,  51,  52,  53,  54,  56,  60,  61,  65,  66,  68,  70,  72,  75,  77,  78,  79,  80,  81,  82,  84,  85,  87,  89,  90,  92,  93,  98, 101, 102, 104]),\n",
    "#  'long_LR': array([  9,  10,  11,  15,  16,  18,  24,  25,  26,  31,  39,  40,  43,  44,  47,  48,  51,  52,  53,  54,  56,  60,  61,  65,  66,  68,  70,  72,  75,  77,  78,  79,  80,  81,  82,  84,  85,  87,  89,  90,  92,  93,  98, 101, 102, 104]),\n",
    "#  'short_RL': array([  9,  10,  11,  15,  16,  18,  24,  25,  26,  31,  39,  40,  43,  44,  47,  48,  51,  52,  53,  54,  56,  60,  61,  65,  66,  68,  70,  72,  75,  77,  78,  79,  80,  81,  82,  84,  85,  87,  89,  90,  92,  93,  98, 101, 102, 104]),\n",
    "#  'short_LR': array([  9,  10,  11,  15,  16,  18,  24,  25,  26,  31,  39,  40,  43,  44,  47,  48,  51,  52,  53,  54,  56,  60,  61,  65,  66,  68,  70,  72,  75,  77,  78,  79,  80,  81,  82,  84,  85,  87,  89,  90,  92,  93,  98, 101, 102, 104])}\n",
    "\n",
    "# unit_ordered_neuron_IDs_dict:\n",
    "# {'long_RL': np.array([ 81,  70,  60,  11, 101,  85,  52,  10, 102,  77,  56,  82,  31,  44,  39,  47,  16,  78,  61,  43,  24,  92,  87,  80,  75,  84,   9,  54,  72, 104,  89,  40,  51,  79,  48,  25,  90,  15,  18,  65,  26,  68,  53,  93,  98,  66]),\n",
    "#  'long_LR': np.array([ 53,  52,  54,  18,  84,  65,  79,  16, 104,  60,  87,  85,  39,  25,  51,  31,  11,  92,  56,  75,  44,  93,  89,  68,  77,  98,   9,  47,  82, 102,  80,  40,  78,  43,  66,  15,  90,  10,  24,  72,  26,  61,  48,  81, 101,  70]),\n",
    "#  'short_RL': np.array([ 68,  75,  54,  10, 104,  90,  44,  15,  93,  79,  56,  84,  78,  31,  16,  40,  25,  81,  70,  66,  24,  98,  80,  77,  60,  39,   9,  82,  85, 101,  87,  26,  43,  65,  48,  52,  92,  11,  51,  72,  18,  53,  47,  89, 102,  61]),\n",
    "#  'short_LR': np.array([ 53,  51,  16,  15,  81,  87,  54,  11, 104,  65,  82,  84,  31,  26,  24,  40,  61, 101,  80,  77,  44,  90,  79,  70,  75,  93,  10,  52,  85, 102,  89,  47,  78,  43,  72,  48,  92,   9,  18,  66,  25,  60,  56,  68,  98,  39])}\n",
    "\n",
    "## TemplateDebugger way of getting neuron_ids:\n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "decoders_dict = track_templates.get_decoders_dict() # decoders_dict = {'long_LR': track_templates.long_LR_decoder, 'long_RL': track_templates.long_RL_decoder, 'short_LR': track_templates.short_LR_decoder, 'short_RL': track_templates.short_RL_decoder, }\n",
    "\n",
    "# INDIVIDUAL SORTING:\n",
    "sorted_neuron_IDs_lists, sort_helper_neuron_id_to_neuron_colors_dicts, sort_helper_neuron_id_to_sort_IDX_dicts = paired_separately_sort_neurons(decoders_dict, None)\n",
    "\n",
    "display(sorted_neuron_IDs_lists)\n",
    "\n",
    "# [array([ 25,  47,  56,  70,  89,  92, 101,  15,  43,  84,  87,  10,  51,  53,  44,  48,  79,  81,  72,  98,   9,  93,  82,  31,  11,  66,  90,  78,  16, 104,  80,  24,  75,  40,  60,  85,  52, 102,  65,  18,  26,  39,  54,  61,  68,  77]),\n",
    "#  array([ 25,  56,  70,  89,  47,  15,  87,  54,  84,  43,  51,  92,  44,  72,  79,  48,  24,  39,  53,  80,  98,  31,  75,  11,  66,  81,  82,  90, 104,   9,  93,  10,  78, 101,  16,  18,  26,  40,  52,  60,  61,  65,  68,  77,  85, 102]),\n",
    "#  array([ 11,  47,  87,  25,  56,  70,  92,  15,  89,  43, 104,  10,  84,  81,  24,  44,  48,  79,   9,  72,  93,  31,  98,  66,  90,  82,  16,  51,  61,  75,  53,  80,  65,  78,  40,  60,  85, 102,  39,  52, 101,  26,  68,  18,  54,  77]),\n",
    "#  array([ 70,  25,  47,  51,  56,  87,  15,  92,  68,  44,  48,  79,  24,  80,  53,  39,  89,   9,  93,  98,  66,  11,  81,  82, 104,  90,  61,  65,  84,  31,  75,  10,  72, 101,  40,  43,  60,  16,  26,  52,  54,  77,  78,  85, 102,  18])]\n",
    "\n",
    "required_sort_indicies = [find_desired_sort_indicies(neuron_ids, sorted_neuron_IDs)[0] for neuron_ids, sorted_neuron_IDs in zip(list(unit_unordered_neuron_IDs_dict.values()), sorted_neuron_IDs_lists)]   \n",
    "display(required_sort_indicies)\n",
    "# [array([ 7, 14, 20, 26, 38, 40, 43,  3, 12, 35, 37,  1, 16, 18, 13, 15, 31, 33, 27, 42,  0, 41, 34,  9,  2, 24, 39, 30,  4, 45, 32,  6, 28, 11, 21, 36, 17, 44, 23,  5,  8, 10, 19, 22, 25, 29]),\n",
    "#  array([ 7, 20, 26, 38, 14,  3, 37, 19, 35, 12, 16, 40, 13, 27, 31, 15,  6, 10, 18, 32, 42,  9, 28,  2, 24, 33, 34, 39, 45,  0, 41,  1, 30, 43,  4,  5,  8, 11, 17, 21, 22, 23, 25, 29, 36, 44]),\n",
    "#  array([ 2, 14, 37,  7, 20, 26, 40,  3, 38, 12, 45,  1, 35, 33,  6, 13, 15, 31,  0, 27, 41,  9, 42, 24, 39, 34,  4, 16, 22, 28, 18, 32, 23, 30, 11, 21, 36, 44, 10, 17, 43,  8, 25,  5, 19, 29]),\n",
    "#  array([26,  7, 14, 16, 20, 37,  3, 40, 25, 13, 15, 31,  6, 32, 18, 10, 38,  0, 41, 42, 24,  2, 33, 34, 45, 39, 22, 23, 35,  9, 28,  1, 27, 43, 11, 12, 21,  4,  8, 17, 19, 29, 30, 36, 44,  5])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_sorted_neuron_ids, unit_sort_orders_dict=an_unit_sort_orders, unit_colors_list=a_decoder_color_list\n",
    "\n",
    "\n",
    "# Get only the spikes for the shared_aclus:\n",
    "a_spikes_df = deepcopy(spikes_df).spikes.sliced_by_neuron_id(LR_neuron_ids)\n",
    "a_spikes_df, neuron_id_to_new_IDX_map = a_spikes_df.spikes.rebuild_fragile_linear_neuron_IDXs() # rebuild the fragile indicies afterwards\n",
    "\n",
    "rasters_display_outputs = plot_raster_plot(a_spikes_df, LR_neuron_ids, unit_sort_order=np.arange(len(LR_neuron_ids)), scatter_app_name=f'pho_directional_laps_rasters', defer_show=False, active_context=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec97c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing no colors at all, passing a different `unit_sort_order` produces a different location for the color rows (the color stays with the spikes), as desired but perhaps not expected.\n",
    "rasters_display_outputs2 = plot_raster_plot(a_spikes_df, LR_neuron_ids, unit_sort_order=np.array(list(reversed(np.arange(len(LR_neuron_ids))))), scatter_app_name=f'pho_directional_laps_rasters2', defer_show=False, active_context=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e909cd",
   "metadata": {},
   "source": [
    "# 2023-12-01 - Working manual 4 raster plots??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_neuron_ids = np.array([  9,  10,  11,  15,  16,  18,  24,  25,  26,  31,  39,  40,  43,  44,  47,  48,  51,  52,  53,  54,  56,  60,  61,  65,  66,  68,  70,  72,  75,  77,  78,  79,  80,  81,  82,  84,  85,  87,  89,  90,  92,  93,  98, 101, 102, 104])\n",
    "active_sort_idxs = np.arange(len(active_neuron_ids))\n",
    "# Get only the spikes for the shared_aclus:\n",
    "a_spikes_df = deepcopy(spikes_df).spikes.sliced_by_neuron_id(active_neuron_ids)\n",
    "a_spikes_df, neuron_id_to_new_IDX_map = a_spikes_df.spikes.rebuild_fragile_linear_neuron_IDXs() # rebuild the fragile indicies afterwards\n",
    "\n",
    "rasters_display_outputs_unsorted = plot_raster_plot(a_spikes_df, active_neuron_ids, unit_sort_order=active_sort_idxs, scatter_app_name=f'pho_directional_laps_rasters_unsorted', defer_show=False, active_context=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a51a2a",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "outputs": [],
   "source": [
    "from attrs import asdict\n",
    "from qtpy import QtGui # for QColor\n",
    "from qtpy.QtGui import QColor, QBrush, QPen\n",
    "from pyphocorehelpers.gui.Qt.color_helpers import ColorFormatConverter\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import DataSeriesToSpatial, RasterPlotSetupTuple, _build_scatter_plotting_managers, _build_units_y_grid, _plot_empty_raster_plot_frame\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import new_plot_raster_plot, NewSimpleRaster\n",
    "\n",
    "active_neuron_ids = np.array([  9,  10,  11,  15,  16,  18,  24,  25,  26,  31,  39,  40,  43,  44,  47,  48,  51,  52,  53,  54,  56,  60,  61,  65,  66,  68,  70,  72,  75,  77,  78,  79,  80,  81,  82,  84,  85,  87,  89,  90,  92,  93,  98, 101, 102, 104])\n",
    "active_sort_idxs = np.array([18, 17, 19,  5, 35, 23, 31,  4, 45, 21, 37, 36, 10,  7, 16,  9,  2, 40, 20, 28, 13, 41, 38, 25, 29, 42,  0, 14, 34, 44, 32, 11, 30, 12, 24,  3, 39,  1,  6, 27,  8, 22, 15, 33, 43, 26])\n",
    "active_sorted_neuron_ids = active_neuron_ids[active_sort_idxs] # [ 53  52  54  18  84  65  79  16 104  60  87  85  39  25  51  31  11  92  56  75  44  93  89  68  77  98   9  47  82 102  80  40  78  43  66  15  90  10  24  72  26  61  48  81 101  70]\n",
    "print(f\"active_sorted_neuron_ids: {active_sorted_neuron_ids}\")\n",
    "\n",
    "## Do this just once:\n",
    "global_neuron_qcolors_list = DataSeriesColorHelpers._build_cell_qcolor_list(np.arange(len(active_neuron_ids)), mode=UnitColoringMode.PRESERVE_FRAGILE_LINEAR_NEURON_IDXS, provided_cell_colors=None)\n",
    "global_neuron_colors_dict = dict(zip(active_neuron_ids, global_neuron_qcolors_list))\n",
    "\n",
    "# # test_raster = NewRaster.init_from_neuron_ids(active_neuron_ids)\n",
    "# test_sorted_raster = NewRaster.init_from_neuron_ids(active_sorted_neuron_ids, neuron_colors=global_neuron_colors_dict)\n",
    "# # test_sorted_raster\n",
    "\n",
    "# a_spikes_df = test_sorted_raster.update_spikes_df_visualization_columns(spikes_df=spikes_df)\n",
    "# display(a_spikes_df)\n",
    "# all_spots, all_scatterplot_tooltips_kwargs = test_sorted_raster.build_spikes_all_spots_from_df(spikes_df=a_spikes_df, should_return_data_tooltips_kwargs=True, generate_debug_tuples=False)\n",
    "# rasters_display_outputs3 = new_plot_raster_plot(spikes_df, active_neuron_ids, unit_sort_order=active_sort_idxs, unit_colors_list=global_neuron_colors_dict, scatter_plot_kwargs=None, scatter_app_name='pho_directional_laps_rasters3', defer_show=False, active_context=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf647d0",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "outputs": [],
   "source": [
    "active_neuron_ids = np.array([  9,  10,  11,  15,  16,  18,  24,  25,  26,  31,  39,  40,  43,  44,  47,  48,  51,  52,  53,  54,  56,  60,  61,  65,  66,  68,  70,  72,  75,  77,  78,  79,  80,  81,  82,  84,  85,  87,  89,  90,  92,  93,  98, 101, 102, 104])\n",
    "active_sort_idxs = np.array([18, 17, 19,  5, 35, 23, 31,  4, 45, 21, 37, 36, 10,  7, 16,  9,  2, 40, 20, 28, 13, 41, 38, 25, 29, 42,  0, 14, 34, 44, 32, 11, 30, 12, 24,  3, 39,  1,  6, 27,  8, 22, 15, 33, 43, 26])\n",
    "active_sorted_neuron_ids = active_neuron_ids[active_sort_idxs] # [ 53  52  54  18  84  65  79  16 104  60  87  85  39  25  51  31  11  92  56  75  44  93  89  68  77  98   9  47  82 102  80  40  78  43  66  15  90  10  24  72  26  61  48  81 101  70]\n",
    "print(f\"active_sorted_neuron_ids: {active_sorted_neuron_ids}\")\n",
    "# Get only the spikes for the shared_aclus:\n",
    "# a_spikes_df = deepcopy(spikes_df).spikes.sliced_by_neuron_id(active_neuron_ids)\n",
    "# a_spikes_df, neuron_id_to_new_IDX_map = a_spikes_df.spikes.rebuild_fragile_linear_neuron_IDXs() # rebuild the fragile indicies afterwards\n",
    "# a_spikes_df = deepcopy(spikes_df).spikes.sliced_by_neuron_id(active_neuron_ids)\n",
    "\n",
    "rasters_display_outputs3 = new_plot_raster_plot(spikes_df, active_neuron_ids, unit_sort_order=active_sort_idxs, unit_colors_list=global_neuron_colors_dict, scatter_plot_kwargs=None, scatter_app_name='pho_directional_laps_rasters3', defer_show=False, active_context=None)\n",
    "# rasters_display_outputs3 = plot_raster_plot(a_spikes_df, active_neuron_ids, unit_sort_order=active_sort_idxs, scatter_app_name=f'pho_directional_laps_rasters3', defer_show=False, active_context=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e32625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasters_display_outputs3.plots_data\n",
    "rasters_display_outputs3.plots.debug_header_label.setText('TEST LABEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558cce3f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "outputs": [],
   "source": [
    "active_neuron_ids = np.array([  9,  10,  11,  15,  16,  18,  24,  25,  26,  31,  39,  40,  43,  44,  47,  48,  51,  52,  53,  54,  56,  60,  61,  65,  66,  68,  70,  72,  75,  77,  78,  79,  80,  81,  82,  84,  85,  87,  89,  90,  92,  93,  98, 101, 102, 104])\n",
    "active_sort_idxs = np.array([33, 26, 21,  2, 43, 36, 17,  1, 44, 29, 20, 34,  9, 13, 10, 14,  4, 30, 22, 12,  6, 40, 37, 32, 28, 35,  0, 19, 27, 45, 38, 11, 16, 31, 15,  7, 39,  3,  5, 23,  8, 25, 18, 41, 42, 24])\n",
    "# Get only the spikes for the shared_aclus:\n",
    "# a_spikes_df = deepcopy(spikes_df).spikes.sliced_by_neuron_id(active_neuron_ids)\n",
    "# a_spikes_df, neuron_id_to_new_IDX_map = a_spikes_df.spikes.rebuild_fragile_linear_neuron_IDXs() # rebuild the fragile indicies afterwards\n",
    "\n",
    "# rasters_display_outputs4 = plot_raster_plot(a_spikes_df, active_neuron_ids, unit_sort_order=active_sort_idxs, scatter_app_name=f'pho_directional_laps_rasters4', defer_show=False, active_context=None)\n",
    "rasters_display_outputs4 = new_plot_raster_plot(spikes_df, active_neuron_ids, unit_sort_order=active_sort_idxs, unit_colors_list=global_neuron_colors_dict, scatter_plot_kwargs=None, scatter_app_name='pho_directional_laps_rasters4', defer_show=False, active_context=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5394427",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "outputs": [],
   "source": [
    "active_neuron_ids = np.array([  9,  10,  11,  15,  16,  18,  24,  25,  26,  31,  39,  40,  43,  44,  47,  48,  51,  52,  53,  54,  56,  60,  61,  65,  66,  68,  70,  72,  75,  77,  78,  79,  80,  81,  82,  84,  85,  87,  89,  90,  92,  93,  98, 101, 102, 104])\n",
    "active_sort_idxs = np.array([18, 16,  4,  3, 33, 37, 19,  2, 45, 23, 34, 35,  9,  8,  6, 11, 22, 43, 32, 29, 13, 39, 31, 26, 28, 41,  1, 17, 36, 44, 38, 14, 30, 12, 27, 15, 40,  0,  5, 24,  7, 21, 20, 25, 42, 10])\n",
    "# Get only the spikes for the shared_aclus:\n",
    "# a_spikes_df = deepcopy(spikes_df).spikes.sliced_by_neuron_id(active_neuron_ids)\n",
    "# a_spikes_df, neuron_id_to_new_IDX_map = a_spikes_df.spikes.rebuild_fragile_linear_neuron_IDXs() # rebuild the fragile indicies afterwards\n",
    "\n",
    "# rasters_display_outputs5 = plot_raster_plot(a_spikes_df, active_neuron_ids, unit_sort_order=active_sort_idxs, scatter_app_name=f'pho_directional_laps_rasters5', defer_show=False, active_context=None)\n",
    "rasters_display_outputs5 = new_plot_raster_plot(spikes_df, active_neuron_ids, unit_sort_order=active_sort_idxs, unit_colors_list=global_neuron_colors_dict, scatter_plot_kwargs=None, scatter_app_name='pho_directional_laps_rasters5', defer_show=False, active_context=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1271b2a0",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "outputs": [],
   "source": [
    "active_neuron_ids = np.array([  9,  10,  11,  15,  16,  18,  24,  25,  26,  31,  39,  40,  43,  44,  47,  48,  51,  52,  53,  54,  56,  60,  61,  65,  66,  68,  70,  72,  75,  77,  78,  79,  80,  81,  82,  84,  85,  87,  89,  90,  92,  93,  98, 101, 102, 104])\n",
    "active_sort_idxs = np.array([25, 28, 19,  1, 45, 39, 13,  3, 41, 31, 20, 35, 30,  9,  4, 11,  7, 33, 26, 24,  6, 42, 32, 29, 21, 10,  0, 34, 36, 43, 37,  8, 12, 23, 15, 17, 40,  2, 16, 27,  5, 18, 14, 38, 44, 22])\n",
    "# Get only the spikes for the shared_aclus:\n",
    "# a_spikes_df = deepcopy(spikes_df).spikes.sliced_by_neuron_id(active_neuron_ids)\n",
    "# a_spikes_df, neuron_id_to_new_IDX_map = a_spikes_df.spikes.rebuild_fragile_linear_neuron_IDXs() # rebuild the fragile indicies afterwards\n",
    "\n",
    "# rasters_display_outputs6 = plot_raster_plot(a_spikes_df, active_neuron_ids, unit_sort_order=active_sort_idxs, scatter_app_name=f'pho_directional_laps_rasters6', defer_show=False, active_context=None)\n",
    "rasters_display_outputs6 = new_plot_raster_plot(spikes_df, active_neuron_ids, unit_sort_order=active_sort_idxs, unit_colors_list=global_neuron_colors_dict, scatter_plot_kwargs=None, scatter_app_name='pho_directional_laps_rasters6', defer_show=False, active_context=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ecdc2d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "outputs": [],
   "source": [
    "main_plot3 = rasters_display_outputs3[2]['root_plot']\n",
    "main_plot4 = rasters_display_outputs4[2]['root_plot']\n",
    "main_plot5 = rasters_display_outputs5[2]['root_plot']\n",
    "main_plot6 = rasters_display_outputs6[2]['root_plot']\n",
    "\n",
    "# Link em' up my friend:\n",
    "main_plot4.setXLink(main_plot3)\n",
    "main_plot5.setXLink(main_plot3)\n",
    "main_plot6.setXLink(main_plot3)\n",
    "\n",
    "# y-links, yum:\n",
    "main_plot4.setYLink(main_plot3)\n",
    "main_plot5.setYLink(main_plot3)\n",
    "main_plot6.setYLink(main_plot3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04326fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if index > 0 and index < len(data1):\n",
    "debug_footer_label.setText(\"test\")\n",
    "# <span style='font-size: 12pt'>x=%0.1f,   <span style='color: red'>y1=%0.1f</span>,   <span style='color: green'>y2=%0.1f</span>\" % (mousePoint.x(), data1[index], data2[index]))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c42f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters_display_outputs_unsorted.plots_data.raster_plot_manager.unit_sort_manager.y_fragile_linear_neuron_IDX_map\n",
    "# rasters_display_outputs_unsorted.plots_data.raster_plot_manager.unit_sort_manager.params.config_items\n",
    "# rasters_display_outputs_unsorted.plots_data.raster_plot_manager.config_fragile_linear_neuron_IDX_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7700bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters_display_outputs3.plots_data.raster_plot_manager.unit_sort_manager.y_fragile_linear_neuron_IDX_map\n",
    "# rasters_display_outputs3.plots_data.raster_plot_manager.unit_sort_manager.params.config_items\n",
    "# rasters_display_outputs3.plots_data.raster_plot_manager.config_fragile_linear_neuron_IDX_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15364325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomLinearRegionItem import CustomLinearRegionItem\n",
    "\n",
    "kwargs = {}\n",
    "\n",
    "neuron_label = f\"{9}\"\n",
    "epoch_linear_region:CustomLinearRegionItem = CustomLinearRegionItem(**(dict(pen=pg.mkPen('#fff'), brush=pg.mkBrush('#f004'), hoverBrush=pg.mkBrush('#fff4'), hoverPen=pg.mkPen('#f00'))|kwargs), movable=False) #, clipItem=plots['difference']  bound the LinearRegionItem to the plotted data\n",
    "epoch_linear_region.setObjectName(f'neuron_region[{neuron_label}]')\n",
    "epoch_linear_region.setZValue(-3) # put it in the back\n",
    "epoch_region_label:pg.InfLineLabel = pg.InfLineLabel(epoch_linear_region.lines[0], f\"{neuron_label}\", position=0.95, rotateAxis=(1,0), anchor=(1, 1)) # add the label for the short epoch\n",
    "# Add the LinearRegionItem to the ViewBox, but tell the ViewBox to exclude this item when doing auto-range calculations.\n",
    "a_main_plot.addItem(epoch_linear_region, ignoreBounds=True)\n",
    "# Set the position:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ce211",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lower_uppder_y_pairs = [(lower_y, upper_y) for lower_y, upper_y in zip(a_raster_plot_manager.unit_sort_manager._series_identity_lower_y_values, a_raster_plot_manager.unit_sort_manager._series_identity_upper_y_values)]\n",
    "lower_uppder_y_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epoch_linear_region.setRegion([t_start, t_stop]) # adjust scroll control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ab55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One issue seems to be just ascending vs. descending expectation order!\n",
    "sorted_neuron_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6347c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_neuron_ids_list = a_raster_plot_manager.unit_sort_manager.find_cell_ids_from_neuron_IDXs(a_raster_plot_manager.unit_sort_manager.fragile_linear_neuron_IDXs)\n",
    "curr_neuron_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b48f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_neuron_ids = a_raster_plot_manager.unit_sort_manager.neuron_ids[a_raster_plot_manager.unit_sort_manager.unit_sort_order] ## This finally matches the order of the labels\n",
    "sorted_neuron_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9416c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `y_fragile_linear_neuron_IDX_map` gives map for fragile_linear_neuron_IDXs, not neuron_IDs\n",
    "sorted_y_fragile_linear_neuron_IDX_map = dict(sorted(deepcopy(a_raster_plot_manager.unit_sort_manager.y_fragile_linear_neuron_IDX_map).items(), key=lambda item: item[1]))\n",
    "print(sorted_y_fragile_linear_neuron_IDX_map) # {26: 0.5, 37: 1.5, 16: 2.5, 35: 3.5, 7: 4.5, 3: 5.5, 38: 6.5, 13: 7.5, 40: 8.5, 15: 9.5, 12: 10.5, 31: 11.5, 33: 12.5, 20: 13.5, 27: 14.5, 42: 15.5, 14: 16.5, 1: 17.5, 0: 18.5, 2: 19.5, 18: 20.5, 9: 21.5, 41: 22.5, 5: 23.5, 34: 24.5, 23: 25.5, 45: 26.5, 39: 27.5, 19: 28.5, 24: 29.5, 32: 30.5, 6: 31.5, 30: 32.5, 43: 33.5, 28: 34.5, 4: 35.5, 11: 36.5, 10: 37.5, 22: 38.5, 36: 39.5, 17: 40.5, 21: 41.5, 25: 42.5, 44: 43.5, 29: 44.5, 8: 45.5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ceaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = rasters_display_outputs_list[0].win # GraphicsLayoutWidget \n",
    "saved_window_geometry = []\n",
    "\n",
    "\n",
    "saved_pos0 = win.saveGeometry() # QByteArray\n",
    "saved_pos0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f357d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_window_geometry = [deepcopy(a_rasters_display_output.win.saveGeometry()) for a_rasters_display_output in rasters_display_outputs_list] # QByteArray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "win.restoreGeometry(saved_pos0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b1dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_font = pg.QtGui.QFont()\n",
    "custom_font.setPixelSize(30)\n",
    "\n",
    "a_main_plot.getAxis(\"bottom\").tickFont = custom_font\n",
    "a_main_plot.getAxis(\"bottom\").setStyle(tickTextOffset = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ay.tickSpacing() # tickSpacing() missing 3 required positional arguments: 'minVal', 'maxVal', and 'size'\n",
    "# ay.tickValues() # tickValues() missing 3 required positional arguments: 'minVal', 'maxVal', and 'size'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fd2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unsorted_neuron_ids = np.array([  9,  10,  11,  15,  16,  18,  24,  25,  26,  31,  39,  40,  43,  44,  47,  48,  51,  52,  53,  54,  56,  60,  61,  65,  66,  68,  70,  72,  75,  77,  78,  79,  80,  81,  82,  84,  85,  87,  89,  90,  92,  93,  98, 101, 102, 104])\n",
    "\n",
    "sort_list = np.array([ 7, 14, 20, 26, 38, 40, 43,  3, 12, 35, 37,  1, 16, 18, 13, 15, 31, 33, 27, 42,  0, 41, 34,  9,  2, 24, 39, 30,  4, 45, 32,  6, 28, 11, 21, 36, 17, 44, 23,  5,  8, 10, 19, 22, 25, 29])\n",
    "\n",
    "\n",
    "# np.all(\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f22dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_rank_order_event_raster_debugger.get_epoch_active_aclus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f02e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_rank_order_event_raster_debugger.active_epoch_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7931c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_update_plot_titles(_out_rank_order_event_raster_debugger, an_idx=309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0536617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "epoch_active_aclus = None\n",
    "_out_directional_template_pfs_debugger = curr_active_pipeline.display(DirectionalPlacefieldGlobalDisplayFunctions._display_directional_template_debugger, included_any_context_neuron_ids=epoch_active_aclus)\n",
    "directional_template_pfs_debugger_on_update_callback = _out_directional_template_pfs_debugger.get('ui').on_update_callback\n",
    "directional_template_pfs_debugger_on_update_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd973981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_template_pfs_debugger_on_update_callback(np.array([77, 18, 25]))\n",
    "\n",
    "directional_template_pfs_debugger_on_update_callback(np.array([9,  26,  31,  39,  40,  43,  47,  52,  53,  54,  60,  61,  65,  68,  72,  75,  77,  78,  81,  82,  84,  85,  90,  92,  93,  98, 102]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04124521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_directional_template_pfs_debugger\n",
    "\n",
    "win = _out_directional_template_pfs_debugger.get('win')\n",
    "app = _out_directional_template_pfs_debugger.get('app')\n",
    "ui = _out_directional_template_pfs_debugger.get('ui')\n",
    "plots = _out_directional_template_pfs_debugger.get('plots')\n",
    "data = _out_directional_template_pfs_debugger.get('data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce86d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.unsorted_included_any_context_neuron_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoder_name = 'short_RL'\n",
    "curr_win, curr_img = plots.pf1D_heatmaps[a_decoder_name] # pyphoplacecellanalysis.External.pyqtgraph.widgets.PlotWidget.PlotWidget\n",
    "\n",
    "# a_text_item = ui.text_items_dict[a_decoder_name][31] # pyqtgraph.graphicsItems.TextItem.TextItem\n",
    "\n",
    "unused_text_items_dict = {aclu:a_text_item for aclu, a_text_item in ui.text_items_dict[a_decoder_name].items() if aclu not in data.unsorted_included_any_context_neuron_ids}\n",
    "\n",
    "for aclu, a_text_item in unused_text_items_dict.items():\n",
    "\ta_text_item.hide()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for aclu, a_text_item in ui.text_items_dict[a_decoder_name].items():\n",
    "\tcurr_win.removeItem(a_text_item)\n",
    "\ta_text_item.deleteLater()\n",
    "\n",
    "# curr_win.addItem(text)\n",
    "# curr_win.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6027b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data #'sorted_neuron_IDs_lists'\n",
    "curr_active_pipeline.display('_display_1d_placefield_occupancy', 'maze_any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e9a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_2d_placefield_occupancy', 'maze_any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f353f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict\n",
    "\n",
    "_display_1d_placefield_occupancy\n",
    "_display_2d_placefield_occupancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4b438c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    }
   },
   "source": [
    "### Independent DirectionalTemplatePFsDebugger for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f7ac4e",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "outputs": [],
   "source": [
    "# _display_directional_laps_overview:\n",
    "curr_active_pipeline.prepare_for_display()\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "session_description: str = curr_active_pipeline.get_session_context().get_description()\n",
    "print(f'session_description: {session_description}')\n",
    "# _out = curr_active_pipeline.display(DirectionalPlacefieldGlobalDisplayFunctions._display_directional_laps_overview)\n",
    "_out_all_cells_directional_template_pfs_debugger = curr_active_pipeline.display(DirectionalPlacefieldGlobalDisplayFunctions._display_directional_template_debugger, included_any_context_neuron_ids=None, figure_name='All Cells (Independent)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b612abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_rank_order_event_raster_debugger.on_update_epoch_IDX(298)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb7f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_seconds(minutes: int, seconds: float) -> float:\n",
    "\t\"\"\" returns fractional seconds \"\"\"\n",
    "\treturn (60.0 * float(minutes)) + seconds\n",
    "\n",
    "convert_to_seconds(18, 37.5) # 1117.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set spike emphasis on debug rasters?\n",
    "\n",
    "# Get debug rasters to match the colors in template viewer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973dd266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "# 2023-11-17: Displays a slider that allows the user to select the epoch_IDX instead of having to type it and call it manually\n",
    "# https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20Events.html#throttling\n",
    "\n",
    "active_epoch_IDX = 0\n",
    "# Define the update function\n",
    "def update_function(change):\n",
    "    global active_epoch_IDX\n",
    "    new_value = change['new']\n",
    "    active_epoch_IDX = new_value\n",
    "    # convert to good value:\n",
    "\n",
    "    # significant_ripple_epochs = deepcopy(global_replays)\n",
    "    active_epoch_IDX = significant_ripple_epochs.to_dataframe().index[new_value]\n",
    "\n",
    "    # Add your update logic here\n",
    "    print(f\"Slider value updated to: {new_value}\")\n",
    "    _out.on_update_epoch_IDX(active_epoch_IDX) # call the update\n",
    "    # print(f'n_unique_cells_participating_in_replay[{active_epoch_IDX}]: {n_unique_cells_participating_in_replay[active_epoch_IDX]}')\n",
    "    selected_epoch_df = global_replays.to_dataframe()[global_replays.to_dataframe().index == active_epoch_IDX] # should only contain one entry, the selected epoch.\n",
    "    curr_epoch = list(selected_epoch_df.itertuples())[0] # extract the interval of interest as a namedtuple object\n",
    "    print(f\"curr_epoch: {curr_epoch}\")\n",
    "\n",
    "    \n",
    "# Create a slider widget\n",
    "slider = widgets.IntSlider(value=0, min=0, max=np.shape(_out.active_epochs_df)[0], step=1, description='Test Slider')\n",
    "\n",
    "# Link the update function to value changes in the slider\n",
    "slider.observe(update_function, names='value')\n",
    "\n",
    "# Display the slider\n",
    "display(slider)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c19f9",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "# Plot the z-scores differences and their raw-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36856cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter events by (|z| > 1.0)\n",
    "ripple_result_tuple.active_epochs\n",
    "ripple_result_tuple.long_best_dir_z_score_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5402b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ripple_result_tuple.directional_likelihoods_tuple\n",
    "ripple_result_tuple.directional_likelihoods_tuple.long_best_direction_indices[105] # 1, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac85b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_result_tuple.directional_likelihoods_tuple.short_best_direction_indices[105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751e2ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_result_tuple.long_best_dir_z_score_values[105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9372e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_result_tuple.short_best_dir_z_score_values[105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1cad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import plot_rank_order_epoch_inst_fr_result_tuples\n",
    "\n",
    "ripple_outputs = plot_rank_order_epoch_inst_fr_result_tuples(curr_active_pipeline, ripple_result_tuple, 'Ripple')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usage of the function for Lap\n",
    "lap_outputs = plot_rank_order_epoch_inst_fr_result_tuples(curr_active_pipeline, laps_result_tuple, 'Lap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905e6b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(ripple_result_tuple.long_best_dir_z_score_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(ripple_result_tuple.short_best_dir_z_score_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_replays.n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e99e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_replays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d468a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratemap = long_pf1D.ratemap\n",
    "ratemap.tuning_curve_unsmoothed_peak_firing_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b025f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "\n",
    "type(ripple_result_tuple)\n",
    "ripple_result_tuple.plot_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5965ce17bb581dd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:23:47.022252100Z",
     "start_time": "2023-11-16T23:23:46.862250100Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'long_best_z_scores': ripple_result_tuple.long_best_dir_z_score_values, 'short_best_z_scores': ripple_result_tuple.short_best_dir_z_score_values}).hist()\n",
    "plt.suptitle('Ripple Rank-Order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3213cd164073dbb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:24:06.810860500Z",
     "start_time": "2023-11-16T23:24:06.644858700Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2023-11-16_LapsRankOrderHistogram Figure:\n",
    "pd.DataFrame({'long_z_scores': laps_result_tuple.long_best_dir_z_score_values, 'short_z_scores': laps_result_tuple.short_best_dir_z_score_values}).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f2a9a6",
   "metadata": {},
   "source": [
    "# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc87fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "# active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\n",
    "\n",
    "active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.display('_display_spike_rasters_pyqtplot_2D', 'maze_any') # 'maze_any'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39840338",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75eb376",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_window = spike_raster_window.spikes_window # SpikesDataframeWindow\n",
    "\n",
    "bottomPlaybackControlBarWidget = spike_raster_window.ui.bottomPlaybackControlBarWidget # Spike3DRasterBottomPlaybackControlBar \n",
    "\n",
    "doubleSpinBox_ActiveWindowStartTime = bottomPlaybackControlBarWidget.ui.doubleSpinBox_ActiveWindowStartTime\n",
    "doubleSpinBox_ActiveWindowEndTime = bottomPlaybackControlBarWidget.ui.doubleSpinBox_ActiveWindowEndTime\n",
    "\n",
    "\n",
    "# spikes_window.timeWindow.start\n",
    "# spikes_window.active_window_start_time\n",
    "# spikes_window.update_window_start_end(451.8908457518555, 451.9895490613999) ## Works but does not trigger refresh/update of the window. The changes are reflected as soon as you try to scroll at all though.\n",
    "# spikes_window.active_window_end_time\n",
    "\n",
    "print(f'spikes_window.active_window_start_time: {spikes_window.active_window_start_time}, spikes_window.active_window_end_time: {spikes_window.active_window_end_time}')\n",
    "# need to block signals:\n",
    "# doubleSpinBox_ActiveWindowStartTime.blockSignals(True)\n",
    "# doubleSpinBox_ActiveWindowEndTime.blockSignals(True)\n",
    "doubleSpinBox_ActiveWindowStartTime.setValue(spikes_window.active_window_start_time)\n",
    "doubleSpinBox_ActiveWindowEndTime.setValue(spikes_window.active_window_end_time)\n",
    "# doubleSpinBox_ActiveWindowStartTime.blockSignals(False) # unblock the signals when done\n",
    "# doubleSpinBox_ActiveWindowEndTime.blockSignals(False)\n",
    "\n",
    "\n",
    "# @pyqtExceptionPrintingSlot(float, float)\n",
    "def on_active_window_changed(start_t, end_t, _obj):\n",
    "\t# need to block signals:\n",
    "\t# doubleSpinBox_ActiveWindowStartTime.blockSignals(True)\n",
    "\t# doubleSpinBox_ActiveWindowEndTime.blockSignals(True)\n",
    "\tif start_t is not None:\n",
    "\t\tdoubleSpinBox_ActiveWindowStartTime.setValue(start_t)\n",
    "\tif end_t is not None:\n",
    "\t\tdoubleSpinBox_ActiveWindowEndTime.setValue(end_t)\n",
    "\t# doubleSpinBox_ActiveWindowStartTime.blockSignals(False) # unblock the signals when done\n",
    "\t# doubleSpinBox_ActiveWindowEndTime.blockSignals(False)\n",
    "\n",
    "curr_window_ctrls_connection = spikes_window.windowed_data_window_updated_signal.connect(on_active_window_changed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doubleSpinBox_ActiveWindowStartTime.setReadOnly(True)\n",
    "doubleSpinBox_ActiveWindowEndTime.setReadOnly(True)\n",
    "\n",
    "spikes_window.on_window_changed.connect("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8319e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "doubleSpinBox_ActiveWindowStartTime.setVisible(False)\n",
    "bottomPlaybackControlBarWidget.setVisible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d043d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_epoch_context\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "# curr_active_pipeline.prepare_for_display()\n",
    "curr_active_pipeline.clear_display_outputs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baddcf94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2441e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg # Used to get the app for TopLevelWindowHelper.top_level_windows\n",
    "## For searching with `TopLevelWindowHelper.all_widgets(...)`:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike3DRaster import Spike3DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "found_spike_raster_windows = TopLevelWindowHelper.all_widgets(pg.mkQApp(), searchType=Spike3DRasterWindowWidget)\n",
    "\n",
    "if len(found_spike_raster_windows) < 1:\n",
    "\t# no existing spike_raster_windows. Make a new one\n",
    "\tprint(f'no existing SpikeRasterWindow. Creating a new one.')\n",
    "\t# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "\t# active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\n",
    "\n",
    "\tactive_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\n",
    "\n",
    "else:\n",
    "\tprint(f'found {len(found_spike_raster_windows)} existing Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...). Will use the most recent.')\n",
    "\t# assert len(found_spike_raster_windows) == 1, f\"found {len(found_spike_raster_windows)} Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...) but require exactly one.\"\n",
    "\t# Get the most recent existing one and reuse that:\n",
    "\tspike_raster_window = found_spike_raster_windows[0]\n",
    "\n",
    "\n",
    "# Extras:\n",
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "active_3d_plot = spike_raster_window.spike_raster_plt_3d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "main_graphics_layout_widget = active_2d_plot.ui.main_graphics_layout_widget # GraphicsLayoutWidget\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "background_static_scroll_plot_widget = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6338da",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.isVisible() # False\n",
    "# spike_raster_window.show()\n",
    "spike_raster_window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bafe4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.connection_man.active_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a801d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_any_window = TopLevelWindowHelper.top_level_windows(pg.mkQApp())\n",
    "found_any_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d815bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print windows:\n",
    "[print_widget_hierarchy(v) for k, v in found_any_window.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_out = curr_active_pipeline.last_added_display_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06ea13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer = _display_out['ipspikesDataExplorer']\n",
    "pActiveSpikesBehaviorPlotter = _display_out['plotter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0cd1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    " = curr_active_pipeline.last_added_display_output\n",
    "_display_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02ac639",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ipspikesDataExplorer = self._display_output['ipspikesDataExplorer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd461fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adjusting Spike Emphasis:\n",
    "#### Usage Examples:\n",
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "from neuropy.core.neuron_identities import NeuronType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dd5449",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Example 1: De-emphasize spikes excluded from the placefield calculations:\n",
    "is_spike_included_in_pf = np.isin(spike_raster_window.spike_raster_plt_2d.spikes_df.index, active_pf_2D.filtered_spikes_df.index)\n",
    "spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not(is_spike_included_in_pf), SpikeEmphasisState.Deemphasized)\n",
    "\n",
    "## Example 2: De-emphasize spikes that don't have their 'aclu' from a given set of indicies:\n",
    "is_spike_included = spike_raster_window.spike_raster_plt_2d.spikes_df.aclu.to_numpy() == 2\n",
    "spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not(is_spike_included), SpikeEmphasisState.Deemphasized)\n",
    "\n",
    "## Example 3: De-emphasize all spikes \n",
    "active_2d_plot.update_spike_emphasis(new_emphasis_state=SpikeEmphasisState.Deemphasized)\n",
    "\n",
    "## Example 4: Hide all spikes entirely\n",
    "active_2d_plot.update_spike_emphasis(new_emphasis_state=SpikeEmphasisState.Hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b9a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup: Hide all non-pyramidal spikes entirely\n",
    "spikes_df = spike_raster_window.spikes_df\n",
    "spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not((spikes_df.neuron_type == NeuronType.from_string('pyr'))), SpikeEmphasisState.Hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3feb699",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_window = spike_raster_window.spikes_window # SpikesDataframeWindow\n",
    "# spikes_window.update_window_start_end(451.8908457518555, 451.9895490613999) ## Works but does not trigger refresh/update of the window. The changes are reflected as soon as you try to scroll at all though.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae85b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20*60.0 + 50.0 +  0.218 = 1250.218\n",
    "\n",
    "spikes_window.update_window_start_end(1250.218, (1250.218 + 3.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325548b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_window.window_duration # Prints the current window's duration. The win. dur. label control in the left bar is not updated.\n",
    "\n",
    "desired_window_fraction: float = 0.1 # 10% of the window is the default jump size\n",
    "relevant_jump_duration: float = spikes_window.window_duration * desired_window_fraction\n",
    "relevant_jump_duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc81002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.spikes_mixins import SpikeRenderingPyVistaMixin\n",
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractivePlaceCellTuningCurvesDataExplorer import InteractivePlaceCellTuningCurvesDataExplorer\n",
    "# from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractivePlaceCellTuningCurvesDataExplorer import InteractivePlaceCellTuningCurvesDataExplorer\n",
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractivePlaceCellDataExplorer import InteractivePlaceCellDataExplorer\n",
    "\n",
    "found_windows_of_type = TopLevelWindowHelper.all_widgets(pg.mkQApp(), searchType=InteractivePlaceCellDataExplorer)\n",
    "found_windows_of_type\n",
    "TopLevelWindowHelper.top_level_windows(pg.mkQApp(), only_visible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2abd93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(451.8908457518555, 451.9895490613999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c418968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "fig_1c_figures_out_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=True, disable_top_row=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2f309",
   "metadata": {},
   "source": [
    "# PhoKamran2023Paper Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a7dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.setConfigOptions(background='white', foreground='black') # black on white background (more traditional) color scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d813d",
   "metadata": {},
   "source": [
    "## Figure 1) pf1D Ratemaps, Active set, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273696fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_1_add_replay_epoch_rasters\n",
    "\n",
    "curr_active_pipeline.prepare_for_display()\n",
    "pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics, fig_1c_figures_out_dict = PAPER_FIGURE_figure_1_full(curr_active_pipeline) # did not display the pf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fa9acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdf = jonathan_firing_rate_analysis_result.rdf.rdf\n",
    "# rdf\n",
    "# ==================================================================================================================== #\n",
    "# Fig 1c) 2023-07-14 - LxC and SxC PhoJonathanSession plots                                                            #\n",
    "# ==================================================================================================================== #\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\n",
    "\n",
    "fig_1c_figures_out_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=True, disable_top_row=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba3c7a",
   "metadata": {},
   "source": [
    "## Figure 2) `PaperFigureTwo`: LxC/SxC Analyses\n",
    "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d3e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PaperFigureTwo\n",
    "\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # 10ms\n",
    "_out_fig_2.compute(curr_active_pipeline=curr_active_pipeline)\n",
    "_out_fig_2.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a52142",
   "metadata": {},
   "source": [
    "## Figure 3) `PAPER_FIGURE_figure_3`: Firing Rate Index and Long/Short Firing Rate Replays v. Laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f765ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import FormattedFigureText\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _plot_long_short_firing_rate_indicies\n",
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out, _out2 = PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
