{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "import pyphoplacecellanalysis.General.Batch.runBatch\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun, BatchResultDataframeAccessor, run_diba_batch, BatchComputationProcessOptions, BatchSessionCompletionHandler\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import SessionBatchProgress\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef5938c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# active_global_batch_result_filename='global_batch_result_2023-07-12.pkl'\n",
    "# active_global_batch_result_filename='global_batch_result_2023-07-07.pkl'\n",
    "# active_global_batch_result_filename='global_batch_result_2023-07-07_extra.pkl'\n",
    "# active_global_batch_result_filename='global_batch_result_2023-07-20.pkl'\n",
    "active_global_batch_result_filename='global_batch_result_2023-07-21_Greatlakes.pkl'\n",
    "debug_print = False\n",
    "enable_neptune = False\n",
    "\n",
    "if enable_neptune:\n",
    "    import neptune # for logging progress and results\n",
    "    from neptune.types import File\n",
    "    from pyphoplacecellanalysis.General.Batch.NeptuneAiHelpers import set_environment_variables, neptune_output_figures\n",
    "    neptune_kwargs = {'project':\"commander.pho/PhoDibaLongShort2023\",\n",
    "    'api_token':\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGIxODU2My1lZTNhLTQ2ZWMtOTkzNS02ZTRmNzM5YmNjNjIifQ==\"}\n",
    "    set_environment_variables(neptune_kwargs)\n",
    "\"\"\" \n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import main, BatchRun, run_diba_batch, run_specific_batch\n",
    "\n",
    "\"\"\"\n",
    "known_global_data_root_parent_paths = [Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/nfs/turbo/umms-kdiba/Data')]\n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "\n",
    "## NEPTUNE:\n",
    "if enable_neptune:\n",
    "\tproject = neptune.init_project(**neptune_kwargs)\n",
    "\tproject[\"general/global_batch_result_filename\"] = active_global_batch_result_filename\n",
    "\tproject[\"general/global_data_root_parent_path\"] = global_data_root_parent_path.as_posix()\n",
    "\n",
    "## TODO: load the batch result initially:\n",
    "\n",
    "## Build Pickle Path:\n",
    "global_batch_result_file_path = Path(global_data_root_parent_path).joinpath(active_global_batch_result_filename).resolve() # Use Default\n",
    "\n",
    "if enable_neptune:\n",
    "\trun = neptune.init_run() # rember to run.stop()\n",
    "\trun['parameters/global_batch_result_file_path'] = global_batch_result_file_path.as_posix()\n",
    "\t# project[\"general/data_analysis\"].upload(\"data_analysis.ipynb\")\n",
    "\trun[\"dataset/latest\"].track_files(f\"file://{global_batch_result_file_path}\") # \"s3://datasets/images\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dddddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# try to load an existing batch result:\n",
    "with set_posix_windows():\n",
    "\tglobal_batch_run = BatchRun.try_init_from_file(global_data_root_parent_path, active_global_batch_result_filename=active_global_batch_result_filename,\n",
    "\t\t\t\t\t\t\tskip_root_path_conversion=False, debug_print=debug_print) # on_needs_create_callback_fn=run_diba_batch\n",
    "\n",
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "batch_progress_df.batch_results.build_all_columns()\n",
    "good_only_batch_progress_df.batch_results.build_all_columns()\n",
    "if enable_neptune:\n",
    "\trun[\"dataset/global_batch_run_progress_df\"].upload(File.as_html(batch_progress_df)) # \"path/to/test_preds.csv\"\n",
    "\trun[\"dataset/global_batch_run_good_only_df\"].upload(File.as_html(good_only_batch_progress_df)) # \"path/to/test_preds.csv\"\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    # display(batch_progress_df)\n",
    "    # display(good_only_batch_progress_df)\n",
    "    display(batch_progress_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f42b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Build `global_batch_run` pre-loading results (before execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496a7c6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# global_batch_result = loadData('global_batch_result.pkl')\n",
    "global_batch_run = run_diba_batch(global_data_root_parent_path, execute_all=False, extant_batch_run=global_batch_run, debug_print=False)\n",
    "# print(f'global_batch_result: {global_batch_run}')\n",
    "global_batch_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab824348",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Batch Executions/Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd73b8d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## I got it doing the bare-minimum loading and computations, so it should be ready to update the laps and constraint the placefields to those. Then we should be able to set up the replays at the same time.\n",
    "# finally, we then finish by computing.\n",
    "\n",
    "# included_session_contexts = batch_progress_df[np.logical_and(batch_progress_df['has_user_replay_annotations'], batch_progress_df['is_ready'])]['context'].to_numpy().tolist()\n",
    "\n",
    "# Only require sessions to have replay annotations:\n",
    "# included_session_contexts = batch_progress_df[batch_progress_df['has_user_replay_annotations']]['context'].to_numpy().tolist()\n",
    "\n",
    "## No filtering the sessions:\n",
    "included_session_contexts = None\n",
    "\n",
    "if included_session_contexts is not None:\n",
    "    print(f'len(included_session_contexts): {len(included_session_contexts)}')\n",
    "else:\n",
    "    print(f'included_session_contexts is None so all session contexts will be included.')\n",
    "\n",
    "# included_session_contexts\n",
    "\n",
    "# No Reloading\n",
    "# result_handler = BatchSessionCompletionHandler(force_reload_all=False,\n",
    "#                                                 session_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=False, should_save=False),\n",
    "#                                                 global_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=False, should_save=False),\n",
    "#                                                 should_perform_figure_generation_to_file=False, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_global_recompute=False)\n",
    "\n",
    "# Forced Reloading:\n",
    "result_handler = BatchSessionCompletionHandler(force_reload_all=True,\n",
    "                                                session_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=True),\n",
    "                                                global_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=True),\n",
    "                                                should_perform_figure_generation_to_file=True, saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE, force_global_recompute=True)\n",
    "\n",
    "# multiprocessing_kwargs = dict(use_multiprocessing=False, num_processes=1)\n",
    "multiprocessing_kwargs = dict(use_multiprocessing=True, num_processes=6)\n",
    "\n",
    "## Execute with the custom arguments.\n",
    "active_computation_functions_name_includelist=['_perform_baseline_placefield_computation',\n",
    "                                        # '_perform_time_dependent_placefield_computation',\n",
    "                                        '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        # '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding'\n",
    "                                    ]\n",
    "# active_computation_functions_name_includelist=['_perform_baseline_placefield_computation']\n",
    "global_batch_run.execute_all(force_reload=result_handler.force_reload_all, saving_mode=result_handler.saving_mode, skip_extended_batch_computations=True, post_run_callback_fn=result_handler.on_complete_success_execution_session,\n",
    "                             fail_on_exception=False, included_session_contexts=included_session_contexts,\n",
    "                                                                                        **{'computation_functions_name_includelist': active_computation_functions_name_includelist,\n",
    "                                                                                            'active_session_computation_configs': None,\n",
    "                                                                                            'allow_processing_previously_completed': True}, **multiprocessing_kwargs) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 4m 39.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab00d2-66a4-4087-81ed-7db2aec94aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to file:\n",
    "saveData(global_batch_result_file_path, global_batch_run) # Update the global batch run dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511725ed-4794-44f4-b398-cf25dcb06201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list(global_batch_run.session_batch_outputs.keys())\n",
    "\n",
    "# Somewhere in there there are `InstantaneousSpikeRateGroupsComputation` results to extract\n",
    "across_sessions_instantaneous_fr_dict = {} # InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "for a_ctxt, a_result in global_batch_run.session_batch_outputs.items():\n",
    "    if a_result is not None:\n",
    "        a_good_result = a_result.get('across_sessions_batch_results', {}).get('inst_fr_comps', None)\n",
    "        if a_good_result is not None:\n",
    "            across_sessions_instantaneous_fr_dict[a_ctxt] = a_good_result\n",
    "            # print(a_result['across_sessions_batch_results']['inst_fr_comps'])\n",
    "            \n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "# When done, `result_handler.across_sessions_instantaneous_fr_dict` is now equivalent to what it would have been before. It can be saved using the normal `.save_across_sessions_data(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2131bc6-efb9-4768-87de-374d857c8227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-07-19.pkl'\n",
    "global_batch_result_inst_fr_file_path = Path(global_data_root_parent_path).joinpath(inst_fr_output_filename).resolve() # Use Default\n",
    "print(f'global_batch_result_inst_fr_file_path: {global_batch_result_inst_fr_file_path}')\n",
    "# Save the all sessions instantaneous firing rate dict to the path:\n",
    "saveData(global_batch_result_inst_fr_file_path, across_sessions_instantaneous_fr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf462d87-76a1-4a3b-b077-5215f433deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the instantaneous firing rate results dict: (# Dict[IdentifyingContext] = InstantaneousSpikeRateGroupsComputation)\n",
    "#TODO 2023-07-12 10:12: - [ ] New save way after we save out current result and reload\n",
    "result_handler.save_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-07-19.pkl')\n",
    "num_sessions = len(result_handler.across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be651cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2023-07-14 - Load Saved across-sessions-data and testing Batch-computed inst_firing_rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ad5bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_batch_result_inst_fr_file_path: W:\\Data\\across_session_result_handler_2023-07-21.pkl\n",
      "Loading loaded session pickle file results : W:\\Data\\across_session_result_handler_2023-07-21.pkl... done.\n",
      "num_sessions: 12\n",
      "num_sessions: 12\n"
     ]
    }
   ],
   "source": [
    "from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import list_of_dicts_to_dict_of_lists\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "## Load the saved across-session results:\n",
    "# inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "# inst_fr_output_filename = 'across_session_result_long_short_inst_firing_rate.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-07-21.pkl'\n",
    "inst_fr_output_filename='across_session_result_handler_2023-07-21.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc1152c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_sessions: 12\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m## Hacks the `PaperFigureTwo` and `InstantaneousSpikeRateGroupsComputation` \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m global_multi_session_context, _out_aggregate_fig_2 \u001b[39m=\u001b[39m AcrossSessionsVisualizations\u001b[39m.\u001b[39;49macross_sessions_bar_graphs(across_session_inst_fr_computation, num_sessions, enable_tiny_point_labels\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, enable_hover_labels\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\AcrossSessionResults.py:281\u001b[0m, in \u001b[0;36mAcrossSessionsVisualizations.across_sessions_bar_graphs\u001b[1;34m(cls, across_session_inst_fr_computation, num_sessions, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m matplotlib_configuration_update(is_interactive\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, backend\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mQt5Agg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    280\u001b[0m \u001b[39m# Perform interactive Matplotlib operations with 'Qt5Agg' backend\u001b[39;00m\n\u001b[1;32m--> 281\u001b[0m _fig_2_theta_out, _fig_2_replay_out \u001b[39m=\u001b[39m _out_aggregate_fig_2\u001b[39m.\u001b[39mdisplay(active_context\u001b[39m=\u001b[39mglobal_multi_session_context, title_modifier_fn\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m original_title: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00moriginal_title\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00mnum_sessions\u001b[39m}\u001b[39;00m\u001b[39m sessions)\u001b[39m\u001b[39m\"\u001b[39m, save_figure\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    283\u001b[0m _out_aggregate_fig_2\u001b[39m.\u001b[39mperform_save()\n\u001b[0;32m    285\u001b[0m global_multi_session_context, _out_aggregate_fig_2\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\utils\\result_context.py:515\u001b[0m, in \u001b[0;36mproviding_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    513\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    514\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 515\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    516\u001b[0m \u001b[39m## TODO: update the returned context poentially?\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\utils\\result_context.py:509\u001b[0m, in \u001b[0;36mproviding_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    507\u001b[0m func\u001b[39m.\u001b[39mactive_context \u001b[39m=\u001b[39m updated_context\n\u001b[0;32m    508\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 509\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    510\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    511\u001b[0m     \u001b[39m# TypeError: __init__() got an unexpected keyword argument 'active_context'\u001b[39;00m\n\u001b[0;32m    512\u001b[0m     \u001b[39mdel\u001b[39;00m kwargs[\u001b[39m'\u001b[39m\u001b[39mactive_context\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m# remove from the **kwargs, it can't handle it\u001b[39;00m\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\PhoDiba2023Paper.py:997\u001b[0m, in \u001b[0;36mPaperFigureTwo.display\u001b[1;34m(self, defer_show, save_figure, enable_tiny_point_labels, enable_hover_labels, **kwargs)\u001b[0m\n\u001b[0;32m    990\u001b[0m top_margin, left_margin, bottom_margin \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtop_margin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.8\u001b[39m), kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mleft_margin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.090\u001b[39m), kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mbottom_margin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.150\u001b[39m)\n\u001b[0;32m    992\u001b[0m _fig_2_theta_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfig_2_Theta_FR_matplotlib(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomputation_result\u001b[39m.\u001b[39mFig2_Laps_FR, defer_show\u001b[39m=\u001b[39mdefer_show,\n\u001b[0;32m    993\u001b[0m                                                 active_context\u001b[39m=\u001b[39mactive_context, top_margin\u001b[39m=\u001b[39mtop_margin,\n\u001b[0;32m    994\u001b[0m                                                 left_margin\u001b[39m=\u001b[39mleft_margin, bottom_margin\u001b[39m=\u001b[39mbottom_margin,\n\u001b[0;32m    995\u001b[0m                                                 title_modifier\u001b[39m=\u001b[39mtitle_modifier)\n\u001b[1;32m--> 997\u001b[0m _fig_2_replay_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfig_2_Replay_FR_matplotlib(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcomputation_result\u001b[39m.\u001b[39;49mFig2_Replay_FR, defer_show\u001b[39m=\u001b[39;49mdefer_show,\n\u001b[0;32m    998\u001b[0m                                                     active_context\u001b[39m=\u001b[39;49mactive_context, top_margin\u001b[39m=\u001b[39;49mtop_margin,\n\u001b[0;32m    999\u001b[0m                                                     left_margin\u001b[39m=\u001b[39;49mleft_margin, bottom_margin\u001b[39m=\u001b[39;49mbottom_margin,\n\u001b[0;32m   1000\u001b[0m                                                     title_modifier\u001b[39m=\u001b[39;49mtitle_modifier)\n\u001b[0;32m   1003\u001b[0m \u001b[39mif\u001b[39;00m enable_hover_labels \u001b[39mor\u001b[39;00m enable_tiny_point_labels:\n\u001b[0;32m   1004\u001b[0m     LxC_aclus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomputation_result\u001b[39m.\u001b[39mLxC_aclus\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\PhoDiba2023Paper.py:916\u001b[0m, in \u001b[0;36mPaperFigureTwo.fig_2_Replay_FR_matplotlib\u001b[1;34m(cls, Fig2_Replay_FR, defer_show, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m all_scatter_props \u001b[39m=\u001b[39m Fig2_Replay_FR[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mLxC_scatter_props \u001b[39m+\u001b[39m Fig2_Replay_FR[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mLxC_scatter_props \u001b[39m+\u001b[39m Fig2_Replay_FR[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mSxC_scatter_props \u001b[39m+\u001b[39m Fig2_Replay_FR[\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mSxC_scatter_props \u001b[39m# the LxC_scatter_props and SxC_scatter_props are actually the same for all entries in this list, but get em like this anyway. \u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[39m# label_list = [LxC_aclus, LxC_aclus, SxC_aclus, SxC_aclus]\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_plot(x_labels, all_data_points, all_scatter_props, \u001b[39m'\u001b[39;49m\u001b[39mReplay Firing Rates (Hz)\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mReplay\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfig_2_Replay_FR_matplotlib\u001b[39;49m\u001b[39m'\u001b[39;49m, active_context, defer_show, kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mtitle_modifier\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\PhoDiba2023Paper.py:858\u001b[0m, in \u001b[0;36mPaperFigureTwo.create_plot\u001b[1;34m(cls, x_labels, y_values, scatter_props, ylabel, title, fig_name, active_context, defer_show, title_modifier)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(x)):\n\u001b[0;32m    857\u001b[0m     x_values \u001b[39m=\u001b[39m (x[i] \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandom(y_values[i]\u001b[39m.\u001b[39msize) \u001b[39m*\u001b[39m width \u001b[39m-\u001b[39m width \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m--> 858\u001b[0m     scatter_plot \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39mscatter(x_values, y_values[i], color\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_bar_colors()[i], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mlist_of_dicts_to_dict_of_lists(scatter_props[i])) \u001b[39m# the np.random part is to spread the points out along the x-axis within their bar so they're visible and don't overlap.\u001b[39;00m\n\u001b[0;32m    859\u001b[0m     scatter_plots\u001b[39m.\u001b[39mappend(scatter_plot)\n\u001b[0;32m    860\u001b[0m     x_values_list\u001b[39m.\u001b[39mappend(x_values)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\PhoDiba2023Paper.py:63\u001b[0m, in \u001b[0;36mlist_of_dicts_to_dict_of_lists\u001b[1;34m(list_of_dicts)\u001b[0m\n\u001b[0;32m     61\u001b[0m dict_of_lists \u001b[39m=\u001b[39m {}\n\u001b[0;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m list_of_dicts:\n\u001b[1;32m---> 63\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m item\u001b[39m.\u001b[39;49mitems():\n\u001b[0;32m     64\u001b[0m         \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m dict_of_lists:\n\u001b[0;32m     65\u001b[0m             dict_of_lists[key]\u001b[39m.\u001b[39mappend(value)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "## Hacks the `PaperFigureTwo` and `InstantaneousSpikeRateGroupsComputation` \n",
    "global_multi_session_context, _out_aggregate_fig_2 = AcrossSessionsVisualizations.across_sessions_bar_graphs(across_session_inst_fr_computation, num_sessions, enable_tiny_point_labels=False, enable_hover_labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381fcf5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "across_session_inst_fr_computation.LxC_scatter_props\n",
    "across_session_inst_fr_computation.SxC_scatter_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db1ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45d728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the unique scatter plot dictionaries:\n",
    "across_session_contexts = list(across_sessions_instantaneous_fr_dict.keys())\n",
    "unique_animals = IdentifyingContext.find_unique_values(across_session_contexts)['animal'] # {'gor01', 'pin01', 'vvp01'}\n",
    "# Get number of animals to plot\n",
    "marker_list = [(5, i) for i in np.arange(len(unique_animals))] # [(5, 0), (5, 1), (5, 2)]\n",
    "scatter_props = [{'marker': mkr} for mkr in marker_list]  # Example, you should provide your own scatter properties\n",
    "scatter_props_dict = dict(zip(unique_animals, scatter_props))\n",
    "# {'pin01': {'marker': (5, 0)},\n",
    "#  'gor01': {'marker': (5, 1)},\n",
    "#  'vvp01': {'marker': (5, 2)}}\n",
    "scatter_props_dict\n",
    "\n",
    "# Pass a function that will return a set of kwargs for a given context\n",
    "def _return_scatter_props_fn(ctxt: IdentifyingContext):\n",
    "\t\"\"\" captures `scatter_props_dict` \"\"\"\n",
    "\tanimal_id = str(ctxt.animal)\n",
    "\treturn scatter_props_dict[animal_id]\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63258151",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=num_sessions) # some global context across all of the sessions, not sure what to put here.\n",
    "\n",
    "# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\n",
    "\n",
    "## Display the aggregate across sessions:\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn't save this info\n",
    "_out_fig_2.computation_result = across_session_inst_fr_computation # the result loaded from the file\n",
    "_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\n",
    "# Set callback, the only self-specific property\n",
    "# _out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)\n",
    "_out_fig_2.scatter_props_fn = _return_scatter_props_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LxC_aclus = _out_fig_2.computation_result.LxC_aclus\n",
    "SxC_aclus = _out_fig_2.computation_result.SxC_aclus\n",
    "\n",
    "LxC_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c498f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureOutputManager, FigureOutputLocation, ContextToPathMode\n",
    "\n",
    "registered_output_files = {}\n",
    "\n",
    "def output_figure(final_context: IdentifyingContext, fig, write_vector_format:bool=False, write_png:bool=True, debug_print=True):\n",
    "    \"\"\" outputs the figure using the provided context. \"\"\"\n",
    "    from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_and_write_to_file\n",
    "    def register_output_file(output_path, output_metadata=None):\n",
    "        \"\"\" registers a new output file for the pipeline \"\"\"\n",
    "        print(f'register_output_file(output_path: {output_path}, ...)')\n",
    "        registered_output_files[output_path] = output_metadata or {}\n",
    "\n",
    "    fig_out_man = FigureOutputManager(figure_output_location=FigureOutputLocation.DAILY_PROGRAMMATIC_OUTPUT_FOLDER, context_to_path_mode=ContextToPathMode.HIERARCHY_UNIQUE)\n",
    "    active_out_figure_paths = build_and_write_to_file(fig, final_context, fig_out_man, write_vector_format=write_vector_format, write_png=write_png, register_output_file_fn=register_output_file)\n",
    "    return active_out_figure_paths, final_context\n",
    "\n",
    "\n",
    "# Set callback, the only self-specific property\n",
    "_out_fig_2._pipeline_file_callback_fn = output_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17b920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\n",
    "\t\n",
    "_out_fig_2.perform_save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32781c8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Single Session testing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_out = global_batch_run.execute_session(session_context=curr_sess_context, force_reload=True, skip_extended_batch_computations=True, computation_functions_name_includelist =['_perform_baseline_placefield_computation'], active_session_computation_configs=None) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "_test_out\n",
    "\n",
    "# global_batch_run.execute_session(session_context=curr_sess_context, force_reload=True, skip_extended_batch_computations=True, **{'computation_functions_name_includelist': ['_perform_baseline_placefield_computation'], 'active_session_computation_configs': None}) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 23.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf2bb67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "full_good_dirs = [k for k, v in global_batch_run.session_batch_errors.items() if v is None]\n",
    "bad_dirs = [k for k, v in global_batch_run.session_batch_errors.items() if v is not None]\n",
    "full_good_dirs\n",
    "bad_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f73f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_batch_run.session_batch_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcad70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_run.session_batch_status\n",
    "global_batch_run.session_batch_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15faf2bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get good sessions for use in the specific session processing notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed516134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf02efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get the list of sessions that are completely ready to process:\n",
    "full_good_ready_to_process_sessions = list(good_only_batch_progress_df['context'].to_numpy())\n",
    "full_good_ready_to_process_sessions\n",
    "# Get good sessions for use in the specific session processing notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ad809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run[\"good_sessions_list\"].extend(full_good_ready_to_process_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636e3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.stop()\n",
    "project.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf1322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\",\\n\".join([ctx.get_initialization_code_string() for ctx in full_good_ready_to_process_sessions])) # List definitions\n",
    "\n",
    "# [IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a4bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\ncurr_context = \".join([ctx.get_initialization_code_string() for ctx in full_good_ready_to_process_sessions])) # Line definitions\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5689d1d-6400-4f87-be0e-a184a1d5bee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82aedf-b024-4f07-b1a9-350730b4db8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "save_time = datetime.now()\n",
    " \n",
    "print(\"save_time =\", save_time)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = save_time.strftime(\"%Y-%m-%d_%I-%M%p\")\n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7bc6bd-5b34-41d0-b906-b0ad9927b08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get output file paths:\n",
    "completed_pipeline_filename = 'loadedSessPickle.pkl'\n",
    "completed_global_computations_filename = 'outputs/global_computation_results.pkl'\n",
    "\n",
    "full_good_ready_to_process_session_paths = list(good_only_batch_progress_df['basedirs'].to_numpy())\n",
    "session_paths_output_folders = [sess_path.joinpath('outputs').resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "\n",
    "completed_pipeline_file_paths = [sess_path.joinpath(completed_pipeline_filename).resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "completed_global_computations_file_paths = [sess_path.joinpath(completed_global_computations_filename).resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "completed_global_computations_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab75122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countable Additivity \n",
    "# Any countable collections of points is size 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af06e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
