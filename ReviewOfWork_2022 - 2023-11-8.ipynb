{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ce022a",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "from attrs import define, field, fields, Factory\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field, custom_define\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin, HDF_Converter\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_subsession_neuron_differences, debug_print_ratemap, debug_print_spike_counts, debug_plot_2d_binning, print_aligned_columns\n",
    "from neuropy.utils.debug_helpers import parameter_sweeps, _plot_parameter_sweep, compare_placefields_info\n",
    "\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, CapturedException, document_active_variables\n",
    "from pyphocorehelpers.general_helpers import GeneratedClassDefinitionType, CodeConversion, inspect_callable_arguments\n",
    "\n",
    "## Pho Programming Helpers:\n",
    "import inspect\n",
    "from pyphocorehelpers.general_helpers import inspect_callable_arguments, get_arguments_as_optional_dict, GeneratedClassDefinitionType, CodeConversion\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter, TypePrintMode, print_keys_if_possible, debug_dump_object_member_shapes, print_value_overview_only, document_active_variables, CapturedException\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers, PythonDictionaryDefinitionFormat\n",
    "\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions\n",
    "\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, fullwidth_path_widget, interactive_pipeline_files\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import render_colors\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/home/halechr/FastData'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/home/halechr/cloud/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0898448c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:NeuropyPipeline.__setstate__(state=\"{'pipeline_name': 'kdiba_pipeline', 'session_data_type': 'kdiba', '_stage': <pyphoplacecellanalysis.General.Pipeline.Stages.Display.DisplayPipelineStage object at 0x0000022950E04AF0>}\")\n",
      "INFO:com.PhoHale.Spike3D.pipeline:select_filters(...) with: []\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing global computations...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:select_filters(...) with: []\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing global computations...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:select_filters(...) with: []\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing global computations...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:NeuropyPipeline.on_stage_changed(new_stage=\"PipelineStage.Displayed\")\n",
      "WARNING:com.PhoHale.Spike3D.pipeline:WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "WARNING:com.PhoHale.Spike3D.pipeline:WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "WARNING: filtered_contexts['maze1_any']'s actual context name is incorrect. \n",
      "\ta_filtered_ctxt.filter_name: maze1_any != a_name: maze1_any\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "WARNING: filtered_contexts[long_epoch_name]'s actual context name is incorrect. \n",
      "\tlong_epoch_context.filter_name: maze1 != long_epoch_name: maze1_any\n",
      "\tUpdating it. (THIS IS A HACK)\n",
      "was_updated: True\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # DONE. Very good. Many good Pfs, many good replays.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # DONE, might be the BEST SESSION, good example session with lots of place cells, clean replays, and clear bar graphs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD, 2023-07-14, unsure why still.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays!\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE, Added replay selections. Very \"jumpy\" between the starts and ends of the track.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # DONE, Added replay selections. A TON of putative replays in general, most bad, but some good.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # DONE, added replay selections. Very few (like 12) replays each.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3') # DONE, Good Pfs, no good epochs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') # DONE, okay replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # DONE, very few replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # DONE, one replay each (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # BAD, Good Pfs strangely despite horrible map, no good epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # DONE, good. Many good pfs, many good replays. Noticed very strange jumping off the track in the 3D behavior/spikes viewer. Is there something wrong with this session?\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE, good?, replays selected, few\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE, very few replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # DONE, replays selected, quite a few replays but few are very good.\n",
    "\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25')\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=['pf_computation',\n",
    "                                               'pfdt_computation', \n",
    "                                                'firing_rate_trends',\n",
    "                                                # 'pf_dt_sequential_surprise', \n",
    "                                            #    'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                # 'position_decoding_two_step', \n",
    "                                            #    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                            #     'long_short_inst_spike_rate_groups',\n",
    "                                            #     'long_short_endcap_analysis',\n",
    "                                            # 'split_to_directional_laps',\n",
    "]\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "\n",
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ddabf5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\global_computation_results.pkl... done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'ratemap_peaks_prominence2d', 'long_short_endcap_analysis', 'spike_burst_detection', 'split_to_directional_laps', 'rank_order_shuffle_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze_any\"\n",
      "pf_computation, maze_any already computed.\n",
      "pfdt_computation, maze_any already computed.\n",
      "ratemap_peaks_prominence2d, maze_any already computed.\n",
      "spike_burst_detection, maze_any already computed.\n",
      "firing_rate_trends, maze_any already computed.\n",
      "split_to_directional_laps missing.\n",
      "\t Recomputing split_to_directional_laps...\n",
      "WARN: _split_to_directional_laps(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "odd_n_neurons: 52, odd_shared_aclus: [  5   7   9  17  22  24  25  26  31  32  34  38  39  41  45  46  48  50  51  53  55  56  59  61  62  64  66  68  69  72  75  76  78  79  81  82  83  84  86  87  88  89  90  91  92  93  95  96  99 100 101 108]\n",
      "even_n_neurons: 54, even_shared_aclus: [  3   5   7   9  10  11  14  15  16  31  32  33  35  36  37  39  41  45  46  48  49  50  52  55  57  60  61  62  64  69  70  71  72  75  76  78  79  83  84  85  86  88  90  91  92  93  95  98  99 100 101 102 107 108]\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "\t done.\n",
      "Exception occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\n",
      " Inner exception: 'DirectionalLapsResult' object is not subscriptable\n",
      "rank_order_shuffle_analysis, maze_any already computed.\n",
      "long_short_endcap_analysis missing.\n",
      "\t Recomputing long_short_endcap_analysis...\n",
      "Exception occured while computing (`perform_specific_computation(...)`) or validating (`validate_computation_test(...)`) after recomputation:\n",
      " Inner exception: 'jonathan_firing_rate_analysis'\n",
      "done with all batch_extended_computations(...).\n",
      "no changes in global results.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7795ee1981e4e599a1e24c0b94ed838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Box(children=(Label(value='session path:', layout=Layout(width='auto')), Label(value='W:\\\\Data\\…"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GLOBAL COMPUTATIONS:\n",
    "\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        curr_active_pipeline.load_pickled_global_computation_results()\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "extended_computations_include_includelist=['pf_computation', 'pfdt_computation', 'firing_rate_trends',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "     'ratemap_peaks_prominence2d',\n",
    "    # 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding',\n",
    "    # 'long_short_rate_remapping',\n",
    "    # 'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'rank_order_shuffle_analysis'\n",
    "] # do only specified\n",
    "\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True, force_recompute=force_recompute_global, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# except Exception as e:\n",
    "#     exception_info = sys.exc_info()\n",
    "#     e = CapturedException(e, exception_info)\n",
    "#     print(f'second half threw: {e}')\n",
    "\n",
    "\n",
    "# 4m 5.2s for inst fr computations\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, fullwidth_path_widget, interactive_pipeline_files\n",
    "\n",
    "_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\n",
    "# display(_pipeline_jupyter_widget)\n",
    "_pipeline_jupyter_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b90aad",
   "metadata": {
    "tags": [
     "SAVE"
    ]
   },
   "outputs": [],
   "source": [
    "# Saving (file mode 'None') saved session pickle file results : None... pickling exception occured while using safeSaveData(pkl_path: None, ..., , should_append=False) but original file was NOT overwritten!\n",
    "# Exception: Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x000001BB46F39820>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell\n",
    "# done.\n",
    "# ERROR RE-SAVING PIPELINE after update. error: !! Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x000001BB46F39820>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell ::::: (<class '_pickle.PicklingError'>, PicklingError(\"Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x000001BB46F39820>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell\"), <traceback object at 0x000001BE821E4100>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c444a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if curr_active_pipeline.updated_since_last_pickle:\n",
    "\t_bak_saving_mode = saving_mode\n",
    "\n",
    "saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "try:\n",
    "\tcurr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "\tcurr_active_pipeline.save_global_computation_results()\n",
    "\n",
    "except Exception as e:\n",
    "\t## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "\texception_info = sys.exc_info()\n",
    "\te = CapturedException(e, exception_info)\n",
    "\tprint(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "finally:\n",
    "\tsaving_mode = _bak_saving_mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1188c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results() # Exception: Can't pickle <built-in function input>: it's not the same object as builtins.input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896622b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5aadb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_name, short_epoch_name, global_epoch_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49862630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lap_estimation_parameters = curr_active_pipeline.sess.config.preprocessing_parameters.epoch_estimation_parameters.laps\n",
    "lap_estimation_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7909e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.config.preprocessing_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.active_config_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2edf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c850782f",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87dc7ae9",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n"
     ]
    }
   ],
   "source": [
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name)) for an_epoch_name in [long_epoch_name, short_epoch_name]]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a45ff559",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'long_short_leave_one_out_decoding_analysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\ReviewOfWork_2022 - 2023-11-8.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2022%20-%202023-11-8.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## long_short_decoding_analyses:\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2022%20-%202023-11-8.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m curr_long_short_decoding_analyses \u001b[39m=\u001b[39m curr_active_pipeline\u001b[39m.\u001b[39;49mglobal_computation_results\u001b[39m.\u001b[39;49mcomputed_data[\u001b[39m'\u001b[39;49m\u001b[39mlong_short_leave_one_out_decoding_analysis\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2022%20-%202023-11-8.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global \u001b[39m=\u001b[39m curr_long_short_decoding_analyses\u001b[39m.\u001b[39mlong_decoder, curr_long_short_decoding_analyses\u001b[39m.\u001b[39mshort_decoder, curr_long_short_decoding_analyses\u001b[39m.\u001b[39mlong_replays, curr_long_short_decoding_analyses\u001b[39m.\u001b[39mshort_replays, curr_long_short_decoding_analyses\u001b[39m.\u001b[39mglobal_replays, curr_long_short_decoding_analyses\u001b[39m.\u001b[39mlong_shared_aclus_only_decoder, curr_long_short_decoding_analyses\u001b[39m.\u001b[39mshort_shared_aclus_only_decoder, curr_long_short_decoding_analyses\u001b[39m.\u001b[39mshared_aclus, curr_long_short_decoding_analyses\u001b[39m.\u001b[39mlong_short_pf_neurons_diff, curr_long_short_decoding_analyses\u001b[39m.\u001b[39mn_neurons, curr_long_short_decoding_analyses\u001b[39m.\u001b[39mlong_results_obj, curr_long_short_decoding_analyses\u001b[39m.\u001b[39mshort_results_obj, curr_long_short_decoding_analyses\u001b[39m.\u001b[39mis_global \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2022%20-%202023-11-8.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m decoding_time_bin_size \u001b[39m=\u001b[39m long_one_step_decoder_1D\u001b[39m.\u001b[39mtime_bin_size \u001b[39m# 1.0/30.0 # 0.03333333333333333\u001b[39;00m\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoCoreHelpers\\src\\pyphocorehelpers\\DataStructure\\dynamic_parameters.py:33\u001b[0m, in \u001b[0;36mDynamicParameters.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mif\u001b[39;00m DynamicParameters\u001b[39m.\u001b[39mdebug_enabled:\n\u001b[0;32m     32\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDynamicParameters.__getitem__(self, key): key \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mapping[key]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'long_short_leave_one_out_decoding_analysis'"
     ]
    }
   ],
   "source": [
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global \n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "## Get global `long_short_fr_indicies_analysis`:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n",
    "long_short_fr_indicies_df = long_short_fr_indicies_analysis_results['long_short_fr_indicies_df']\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result.Flat_epoch_time_bins_mean, expected_v_observed_result.Flat_decoder_time_bin_centers, expected_v_observed_result.num_neurons, expected_v_observed_result.num_timebins_in_epoch, expected_v_observed_result.num_total_flat_timebins, expected_v_observed_result.is_short_track_epoch, expected_v_observed_result.is_long_track_epoch, expected_v_observed_result.short_short_diff, expected_v_observed_result.long_long_diff\n",
    "\n",
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.05)\n",
    "\n",
    "## Update long_exclusive/short_exclusive properties with `long_short_fr_indicies_df`\n",
    "# long_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n",
    "# short_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7cf349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "odd_ripple_rank_order_result, even_ripple_rank_order_result, odd_laps_rank_order_result, even_laps_rank_order_result = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b9bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(curr_active_pipeline.global_computation_results.computed_data['RankOrder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1cc2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.active_config_names # ['maze1', 'maze2', 'maze', 'maze_odd', 'maze_even', 'maze_any']\n",
    "# curr_active_pipeline.active_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43117c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e13129",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.active_incomplete_computation_result_status_dicts\n",
    "print(curr_active_pipeline.filtered_session_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_config.pf_params.computation_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a6a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "# Unwrap the naturally produced directional placefields:\n",
    "long_odd_name, short_odd_name, global_odd_name, long_even_name, short_even_name, global_even_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Most popular\n",
    "# long_odd_name, long_even_name, short_odd_name, short_even_name, global_any_name\n",
    "long_odd_laps_name, long_even_laps_name, short_odd_laps_name, short_even_laps_name = long_odd_name, long_even_name, short_odd_name, short_even_name\n",
    "long_odd_laps_obj, long_even_laps_obj, short_odd_laps_obj, short_even_laps_obj, global_any_laps_obj = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'].pf_params.computation_epochs for an_epoch_name in (long_odd_name, long_even_name, short_odd_name, short_even_name, global_any_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46924c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpacking for `(long_odd_laps_name, long_even_laps_name, short_odd_laps_name, short_even_laps_name)`\n",
    "(long_odd_laps_context, long_even_laps_context, short_odd_laps_context, short_even_laps_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_odd_laps_name, long_even_laps_name, short_odd_laps_name, short_even_laps_name)]\n",
    "(long_odd_laps_obj, long_even_laps_obj, short_odd_laps_obj, short_even_laps_obj) = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name)) for an_epoch_name in (long_odd_laps_name, long_even_laps_name, short_odd_laps_name, short_even_laps_name)]\n",
    "(long_odd_laps_session, long_even_laps_session, short_odd_laps_session, short_even_laps_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_odd_laps_name, long_even_laps_name, short_odd_laps_name, short_even_laps_name)]\n",
    "(long_odd_laps_results, long_even_laps_results, short_odd_laps_results, short_even_laps_results) = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in (long_odd_laps_name, long_even_laps_name, short_odd_laps_name, short_even_laps_name)]\n",
    "(long_odd_laps_computation_config, long_even_laps_computation_config, short_odd_laps_computation_config, short_even_laps_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'] for an_epoch_name in (long_odd_laps_name, long_even_laps_name, short_odd_laps_name, short_even_laps_name)]\n",
    "(long_odd_laps_pf1D, long_even_laps_pf1D, short_odd_laps_pf1D, short_even_laps_pf1D) = (long_odd_laps_results.pf1D, long_even_laps_results.pf1D, short_odd_laps_results.pf1D, short_even_laps_results.pf1D)\n",
    "(long_odd_laps_pf2D, long_even_laps_pf2D, short_odd_laps_pf2D, short_even_laps_pf2D) = (long_odd_laps_results.pf2D, long_even_laps_results.pf2D, short_odd_laps_results.pf2D, short_even_laps_results.pf2D)\n",
    "\n",
    "# Validate:\n",
    "assert not (curr_active_pipeline.computation_results[long_odd_laps_name]['computation_config']['pf_params'].computation_epochs is curr_active_pipeline.computation_results[long_even_laps_name]['computation_config']['pf_params'].computation_epochs)\n",
    "assert not (curr_active_pipeline.computation_results[short_odd_laps_name]['computation_config']['pf_params'].computation_epochs is curr_active_pipeline.computation_results[long_even_laps_name]['computation_config']['pf_params'].computation_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ca98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder # used for `complete_directional_pfs_computations`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalLapsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalLapsHelpers\n",
    "\n",
    "\n",
    "directional_laps_result = DirectionalLapsHelpers.build_global_directional_result_from_natural_epochs(curr_active_pipeline)\n",
    "\n",
    "# build the four `*_shared_aclus_only_one_step_decoder_1D` versions of the decoders constrained only to common aclus:\n",
    "# long_odd_shared_aclus_only_one_step_decoder_1D, long_even_shared_aclus_only_one_step_decoder_1D, short_odd_shared_aclus_only_one_step_decoder_1D, short_even_shared_aclus_only_one_step_decoder_1D  = DirectionalLapsHelpers.build_directional_constrained_decoders(curr_active_pipeline)\n",
    "\n",
    "## Build the `BasePositionDecoder` for each of the four templates analagous to what is done in `_long_short_decoding_analysis_from_decoders`:\n",
    "# long_odd_laps_one_step_decoder_1D, long_even_laps_one_step_decoder_1D, short_odd_laps_one_step_decoder_1D, short_even_laps_one_step_decoder_1D  = [BasePositionDecoder.init_from_stateful_decoder(deepcopy(results_data.get('pf1D_Decoder', None))) for results_data in (long_odd_laps_results, long_even_laps_results, short_odd_laps_results, short_even_laps_results)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47afcbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-10-31 - 4pm - Two sets of templates for (Odd/Even) shared aclus:\n",
    "# Kamran says odd and even sets should be shared\n",
    "## Odd Laps:\n",
    "odd_active_neuron_IDs_list = [a_decoder.neuron_IDs for a_decoder in (long_odd_laps_one_step_decoder_1D, short_odd_laps_one_step_decoder_1D)]\n",
    "odd_shared_aclus = np.array(list(set.intersection(*map(set,odd_active_neuron_IDs_list)))) # array([ 6,  7,  8, 11, 15, 16, 20, 24, 25, 26, 31, 33, 34, 35, 39, 40, 45, 46, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 63, 64])\n",
    "odd_n_neurons = len(odd_shared_aclus)\n",
    "print(f'odd_n_neurons: {odd_n_neurons}, odd_shared_aclus: {odd_shared_aclus}')\n",
    "\n",
    "## Even Laps:\n",
    "even_active_neuron_IDs_list = [a_decoder.neuron_IDs for a_decoder in (long_even_laps_one_step_decoder_1D, short_even_laps_one_step_decoder_1D)]\n",
    "even_shared_aclus = np.array(list(set.intersection(*map(set,even_active_neuron_IDs_list)))) # array([ 6,  7,  8, 11, 15, 16, 20, 24, 25, 26, 31, 33, 34, 35, 39, 40, 45, 46, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 63, 64])\n",
    "even_n_neurons = len(even_shared_aclus)\n",
    "print(f'even_n_neurons: {even_n_neurons}, even_shared_aclus: {even_shared_aclus}')\n",
    "\n",
    "# Direction Separate shared_aclus decoders: Odd set is limited to odd_shared_aclus and even set is limited to even_shared_aclus:\n",
    "long_odd_shared_aclus_only_one_step_decoder_1D, short_odd_shared_aclus_only_one_step_decoder_1D = [a_decoder.get_by_id(odd_shared_aclus) for a_decoder in (long_odd_laps_one_step_decoder_1D, short_odd_laps_one_step_decoder_1D)]\n",
    "long_even_shared_aclus_only_one_step_decoder_1D, short_even_shared_aclus_only_one_step_decoder_1D = [a_decoder.get_by_id(even_shared_aclus) for a_decoder in (long_even_laps_one_step_decoder_1D, short_even_laps_one_step_decoder_1D)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8bc98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-10-30 - All four templates with same shared_aclus version:\n",
    "\n",
    "# Prune to the shared aclus in both epochs (short/long):\n",
    "active_neuron_IDs_list = [a_decoder.neuron_IDs for a_decoder in (long_odd_laps_one_step_decoder_1D, long_even_laps_one_step_decoder_1D, short_odd_laps_one_step_decoder_1D, short_even_laps_one_step_decoder_1D)]\n",
    "\n",
    "# Find only the common aclus amongst all four templates:\n",
    "shared_aclus = np.array(list(set.intersection(*map(set,active_neuron_IDs_list)))) # array([ 6,  7,  8, 11, 15, 16, 20, 24, 25, 26, 31, 33, 34, 35, 39, 40, 45, 46, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 63, 64])\n",
    "n_neurons = len(shared_aclus)\n",
    "print(f'n_neurons: {n_neurons}, shared_aclus: {shared_aclus}')\n",
    "\n",
    "# build the four `*_shared_aclus_only_one_step_decoder_1D` versions of the decoders constrained only to common aclus:\n",
    "long_odd_shared_aclus_only_one_step_decoder_1D, long_even_shared_aclus_only_one_step_decoder_1D, short_odd_shared_aclus_only_one_step_decoder_1D, short_even_shared_aclus_only_one_step_decoder_1D = [a_decoder.get_by_id(shared_aclus) for a_decoder in (long_odd_laps_one_step_decoder_1D, long_even_laps_one_step_decoder_1D, short_odd_laps_one_step_decoder_1D, short_even_laps_one_step_decoder_1D)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10075f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Encode/Decode from global result:\n",
    "# # Unpacking:\n",
    "# directional_laps_results = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "# directional_lap_specific_configs, split_directional_laps_dict, split_directional_laps_config_names, computed_base_epoch_names = [directional_laps_results[k] for k in ['directional_lap_specific_configs', 'split_directional_laps_dict', 'split_directional_laps_names', 'computed_base_epoch_names']]\n",
    "# # split_directional_laps_config_names\n",
    "\n",
    "## Build a `ComputedResult` container object to hold the result:\n",
    "# directional_laps_result = ComputedResult()\n",
    "directional_laps_result = DirectionalLapsResult()\n",
    "# directional_laps_result.directional_lap_specific_configs = directional_lap_specific_configs\n",
    "# directional_laps_result.split_directional_laps_dict = split_directional_laps_dict\n",
    "# directional_laps_result.split_directional_laps_contexts_dict = split_directional_laps_contexts_dict\n",
    "directional_laps_result.split_directional_laps_config_names = (long_odd_laps_name, long_even_laps_name, short_odd_laps_name, short_even_laps_name) # split_directional_laps_config_names\n",
    "# directional_laps_result.computed_base_epoch_names = computed_base_epoch_names\n",
    "\n",
    "# directional_lap_specific_configs, split_directional_laps_dict, split_directional_laps_contexts_dict, split_directional_laps_config_names, computed_base_epoch_names\n",
    "directional_laps_result.long_odd_shared_aclus_only_one_step_decoder_1D = long_odd_shared_aclus_only_one_step_decoder_1D\n",
    "directional_laps_result.long_even_shared_aclus_only_one_step_decoder_1D = long_even_shared_aclus_only_one_step_decoder_1D\n",
    "directional_laps_result.short_odd_shared_aclus_only_one_step_decoder_1D = short_odd_shared_aclus_only_one_step_decoder_1D\n",
    "directional_laps_result.short_even_shared_aclus_only_one_step_decoder_1D = short_even_shared_aclus_only_one_step_decoder_1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c490235",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_even_laps_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c55a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_odd_laps_computation_config.pf_params.computation_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2545b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_even_laps_computation_config.pf_params.computation_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_print_placefield(long_odd_laps_pf1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa66951",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_print_placefield(long_even_laps_pf1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ba572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_contexts = curr_active_pipeline.filtered_contexts\n",
    "filtered_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539fdbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f801dd2",
   "metadata": {},
   "source": [
    "## 🟢 2023-10-25 - Recomputing Directional Laps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b236bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalLapsHelpers\n",
    "\n",
    "# directional_laps_result = DirectionalLapsHelpers.complete_directional_pfs_computations(curr_active_pipeline) ## OLD:\n",
    "\n",
    "directional_laps_result = DirectionalLapsHelpers.build_global_directional_result_from_natural_epochs(curr_active_pipeline)\n",
    "\n",
    "# Set the global result:\n",
    "curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'] = directional_laps_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1454c9fe",
   "metadata": {},
   "source": [
    "### 2023-10-26 - Extract Directional Laps Outputs and computed items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be18691",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "outputs": [],
   "source": [
    "# Recover from the saved global result:\n",
    "# Unpacking:\n",
    "directional_laps_results = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "# directional_lap_specific_configs, split_directional_laps_dict, split_directional_laps_config_names, computed_base_epoch_names = [directional_laps_results[k] for k in ['directional_lap_specific_configs', 'split_directional_laps_dict', 'split_directional_laps_names', 'computed_base_epoch_names']]\n",
    "directional_lap_specific_configs, split_directional_laps_dict, split_directional_laps_contexts_dict, split_directional_laps_config_names, computed_base_epoch_names = [directional_laps_results.__dict__[k] for k in ['directional_lap_specific_configs', 'split_directional_laps_dict', 'split_directional_laps_contexts_dict', 'split_directional_laps_config_names', 'computed_base_epoch_names']]\n",
    "long_odd_shared_aclus_only_one_step_decoder_1D, long_even_shared_aclus_only_one_step_decoder_1D, short_odd_shared_aclus_only_one_step_decoder_1D, short_even_shared_aclus_only_one_step_decoder_1D = [directional_laps_results.__dict__[k] for k in ['long_odd_shared_aclus_only_one_step_decoder_1D', 'long_even_shared_aclus_only_one_step_decoder_1D', 'short_odd_shared_aclus_only_one_step_decoder_1D', 'short_even_shared_aclus_only_one_step_decoder_1D']]\n",
    "long_odd_laps_obj, long_even_laps_obj, short_odd_laps_obj, short_even_laps_obj = list(directional_laps_results.split_directional_laps_dict.values())\n",
    "\n",
    "# print(list(directional_laps_results.__dict__.keys()))\n",
    "# ['directional_lap_specific_configs', 'split_directional_laps_dict', 'split_directional_laps_contexts_dict', 'split_directional_laps_config_names', 'computed_base_epoch_names', 'long_odd_shared_aclus_only_one_step_decoder_1D', 'long_even_shared_aclus_only_one_step_decoder_1D', 'short_odd_shared_aclus_only_one_step_decoder_1D', 'short_even_shared_aclus_only_one_step_decoder_1D']\n",
    "\n",
    "split_directional_laps_config_names\n",
    "# split_directional_laps_config_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required to fix the display functions for directionally filtered epochs:\n",
    "for a_name in list(curr_active_pipeline.filtered_contexts.keys()):\n",
    "\tcurr_active_pipeline.filtered_contexts[a_name].filter_name = a_name # required for successful display function use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfe3d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_1d_placefields', 'maze1_odd')\n",
    "curr_active_pipeline.display('_display_1d_placefields', 'maze1_even')\n",
    "curr_active_pipeline.display('_display_1d_placefields', 'maze2_even')\n",
    "curr_active_pipeline.display('_display_1d_placefields', 'maze2_odd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ee7b51",
   "metadata": {},
   "source": [
    "### 2023-10-26 - Purging bad directional results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b24632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions\n",
    "\n",
    "# curr_active_pipeline.perform_drop_entire_computed_config(config_names_to_drop=['maze1_odd_laps', 'maze1_even_laps', 'maze2_odd_laps', 'maze2_even_laps'])\n",
    "\n",
    "curr_active_pipeline.perform_drop_entire_computed_config(config_names_to_drop=['maze_odd_laps', 'maze_even_laps', 'maze1_odd_laps', 'maze1_even_laps', 'maze2_odd_laps', 'maze2_even_laps', 'maze1_odd_laps_odd_laps', 'maze1_odd_laps_even_laps', 'maze1_even_laps_odd_laps', 'maze1_even_laps_even_laps', 'maze2_odd_laps_odd_laps', 'maze2_odd_laps_even_laps', 'maze2_even_laps_odd_laps', 'maze2_even_laps_even_laps'])\n",
    "\n",
    "del curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6833f5",
   "metadata": {},
   "source": [
    "## 2023-10-18 - Investigate getting spike raster during the replay epochs for use with spike timing analyses like the weighted correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98293a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratemap = deepcopy(long_pf1D.ratemap)\n",
    "ratemap.spikes_maps\n",
    "ratemap.unsmoothed_tuning_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2656e3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratemap.tuning_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94407cd",
   "metadata": {},
   "source": [
    "## 2023-10-19 - Test Instantaneous Spike Rates and their visualizations during the Replay Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import BinningContainer\n",
    "\n",
    "replay_instantaneous_time_bin_size_seconds = 0.01\n",
    "inst_replay_frs: SpikeRateTrends = SpikeRateTrends.init_from_spikes_and_epochs(spikes_df=global_session.spikes_df, filter_epochs=global_replays, included_neuron_ids=EITHER_subset.track_exclusive_aclus.copy(), instantaneous_time_bin_size_seconds=replay_instantaneous_time_bin_size_seconds)\n",
    "neuron_labels = [str(aclu) for aclu in inst_replay_frs.included_neuron_ids] # labels for plotting the epochs using `BasicBinnedImageRenderingWindow`\n",
    "# 26 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74859ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_idx = 1\n",
    "a_replay_inst_frs = inst_replay_frs.inst_fr_df_list[epoch_idx].to_numpy() # (n_epoch_time_bins, n_cells)   ## OLD: #.T # (n_cells, n_epoch_time_bins)\n",
    "display(a_replay_inst_frs.shape)\n",
    "a_epoch_timebin_labels = [str(v) for v in np.arange(np.shape(a_replay_inst_frs)[0])]\n",
    "assert len(a_epoch_timebin_labels) == np.shape(a_replay_inst_frs)[0]\n",
    "assert len(neuron_labels) == np.shape(a_replay_inst_frs)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "out = BasicBinnedImageRenderingWindow(a_replay_inst_frs, None, None, name='a_replay_inst_frs', title=\"Inst Fr for Replay Epoch\", variable_label='Inst FR', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5f4fe",
   "metadata": {},
   "source": [
    "## Weighted Correlation can only be applied to decoded posteriors, not spikes themselves.\n",
    "### It works by assessing the degree to which a change in position corresponds to a change in time. For a simple diagonally increasing trajectory across the track at early timebins position will start at the bottom of the track, and as time increases the position also increases. The \"weighted\" part just corresponds to making use of the confidence probabilities of the decoded posterior: instead of relying on only the most-likely position we can include all information returned. Naturally will emphasize sharp decoded positions and de-emphasize diffuse ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e70e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get decoded posteriors for each replay epoch:\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from PendingNotebookCode import add_weighted_correlation_result, _add_maze_id_to_epochs\n",
    "\n",
    "## 2023-10-19 - Weighted Correlation:\n",
    "a_long_decoder_result: DecodedFilterEpochsResult = long_results_obj.all_included_filter_epochs_decoder_result\n",
    "a_short_decoder_result: DecodedFilterEpochsResult = short_results_obj.all_included_filter_epochs_decoder_result\n",
    "# Get the xbin_centers which are the same for long/short:\n",
    "xbin_centers = long_results_obj.original_1D_decoder.xbin_centers.copy()\n",
    "# Compute the weighte correlation:\n",
    "epoch_long_weighted_corr_results, epoch_short_weighted_corr_results = add_weighted_correlation_result(xbin_centers, a_long_decoder_result, a_short_decoder_result, debug_print=False)\n",
    "epoch_long_weighted_corr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddde694",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_long_weighted_corr_results.shape # (151, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a29f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Add new weighted correlation results as new columns in existing filter_epochs df:\n",
    "active_filter_epochs = long_results_obj.active_filter_epochs\n",
    "# Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "active_filter_epochs = _add_maze_id_to_epochs(active_filter_epochs, short_session.t_start)\n",
    "active_filter_epochs._df['weighted_corr_LONG'] = epoch_long_weighted_corr_results[:,0]\n",
    "active_filter_epochs._df['weighted_corr_SHORT'] = epoch_short_weighted_corr_results[:,0]\n",
    "active_filter_epochs._df['weighted_corr_spearman_LONG'] = epoch_long_weighted_corr_results[:,1]\n",
    "active_filter_epochs._df['weighted_corr_spearman_SHORT'] = epoch_short_weighted_corr_results[:,1]\n",
    "\n",
    "\n",
    "active_filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d7ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_filter_epochs.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe651ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the `weighted_corr_LONG` over time\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=active_num_rows, sharex=True, sharey=sharey, figsize=figsize)\n",
    "\n",
    "## Weighted Correlation during replay epochs:\n",
    "_out_ax = active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_LONG', title='weighted_corr during replay events', marker=\"s\",  s=5, label=f'Long', alpha=0.8)\n",
    "active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_SHORT', xlabel='Replay Epoch Time', ylabel='Weighted Correlation', ax=_out_ax, marker=\"s\", c='r', s=5, label=f'Short', alpha=0.8)\n",
    "_out_ax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weighted Spearman Correlation during replay epochs:\n",
    "_out_ax = active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_spearman_LONG', title='weighted_spearman_corr during replay events', marker=\"s\",  s=5, label=f'Long', alpha=0.8)\n",
    "active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_spearman_SHORT', xlabel='Replay Epoch Time', ylabel='Weighted Spearman Correlation', ax=_out_ax, marker=\"s\", c='r', s=5, label=f'Short', alpha=0.8)\n",
    "_out_ax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75167fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_ax = active_filter_epochs._df.plot.scatter(x='start', y='score_LONG', title='Radon Transform Score during replay events', marker=\"s\",  s=5, label=f'Long', alpha=0.8)\n",
    "active_filter_epochs._df.plot.scatter(x='start', y='score_SHORT', xlabel='Replay Epoch Time', ylabel='Replay Radon Transform Score', ax=_out_ax, marker=\"s\", c='r', s=5, label=f'Short', alpha=0.8)\n",
    "_out_ax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e5d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df = active_filter_epochs._df\n",
    "# # Performed 6 aggregations grouped on column: 'maze_id'\n",
    "# a_df = a_df.groupby(['maze_id']).agg(weighted_corr_LONG_mean=('weighted_corr_LONG', 'mean'), weighted_corr_SHORT_mean=('weighted_corr_SHORT', 'mean'), velocity_mean=('velocity', 'mean'), speed_mean=('speed', 'mean'), score_LONG_mean=('score_LONG', 'mean'), score_SHORT_mean=('score_SHORT', 'mean')).reset_index()\n",
    "a_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_burst_intervals = curr_active_pipeline.computation_results[global_epoch_name].computed_data['burst_detection']['burst_intervals']\n",
    "active_burst_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f27b5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# Relative Entropy/Surprise Results:\n",
    "active_extended_stats = global_results['extended_stats']\n",
    "active_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise'] # DynamicParameters\n",
    "historical_snapshots = active_relative_entropy_results['historical_snapshots']\n",
    "post_update_times: np.ndarray = active_relative_entropy_results['post_update_times'] # (4152,) = (n_post_update_times,)\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals: np.ndarray = active_relative_entropy_results['time_intervals']\n",
    "surprise_time_bin_duration = (post_update_times[2]-post_update_times[1])\n",
    "long_short_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "flat_relative_entropy_results: np.ndarray = active_relative_entropy_results['flat_relative_entropy_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_results: np.ndarray = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_across_all_positions: np.ndarray = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "flat_surprise_across_all_positions: np.ndarray = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\n",
    "## Get the placefield dt matrix:\n",
    "if 'snapshot_occupancy_weighted_tuning_maps' not in active_relative_entropy_results:\n",
    "\t## Compute it if missing:\n",
    "\toccupancy_weighted_tuning_maps_over_time = np.stack([placefield_snapshot.occupancy_weighted_tuning_maps_matrix for placefield_snapshot in historical_snapshots.values()])\n",
    "\tactive_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] = occupancy_weighted_tuning_maps_over_time\n",
    "else:\n",
    "\toccupancy_weighted_tuning_maps_over_time = active_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] # (n_post_update_times, n_neurons, n_xbins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e5db7a",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a4645",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "## long_short_endcap_analysis: checks for cells localized to the endcaps that have their placefields truncated after shortening the track\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "# disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "# trivially_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "# significant_distant_remapping_endcap_aclus\n",
    "appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n",
    "# appearing_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_distant_remapping_endcap_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e2a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_remapping_cells\n",
    "\n",
    "graphics_output_dict = fig_remapping_cells(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb95f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-11-10 - Adds \"LxC_PBEsDeltaMinus\" for PBEs \n",
    "\n",
    "\n",
    "temp = add_extra_spike_rate_trends(curr_active_pipeline)\n",
    "temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b377ccf",
   "metadata": {},
   "source": [
    "# 🟢 2023-10-20 - Z-Score Comparisons with Neuron_ID Shuffled templates\n",
    "1. Take the intersection of the long and short templates to get only the common cells\n",
    "2. Determine the long and short \"tempaltes\": this is done by ranking the aclus for each by their placefields' center of mass. `compute_placefield_center_of_masses`\n",
    "\t2a. `long_pf_peak_ranks`, `short_pf_peak_ranks` - there are one of each of these for each shared aclu.\n",
    "3. Generate the unit_id shuffled (`shuffled_aclus`, `shuffle_IDXs`) ahead of time to use to shuffle the two templates during the epochs.\n",
    "4. For each replay event, take each shuffled template\n",
    "\t4a. Iterate through each shuffle and obtain the shuffled templates like `long_pf_peak_ranks[epoch_specific_shuffled_indicies]`, `short_pf_peak_ranks[epoch_specific_shuffled_indicies]`\n",
    "\t4b. compute the spearman rank-order of the event and each shuffled template, and accumulate the results in `long_spearmanr_rank_stats_results`, `short_spearmanr_rank_stats_results`\n",
    "\n",
    "5. After we're done with the shuffle loop, accumulate the results and convert to the right output format.\n",
    "\n",
    "6. When all epochs are done, loop through the results (the epochs again) and compute the z-scores for each epoch so they can be compared to each other. Keep track of the means and std_dev for comparisons later, and subtract the two sets of z-scores (long/short) to get the delta_Z for each template.\n",
    "\n",
    "7. TODO: Next figure out what to do with the array of z-scores and delta_Z. We have:\n",
    "\tn_epochs sets of results\n",
    "\t\tn_shuffles scores of delta_Z\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c80b6e0",
   "metadata": {},
   "source": [
    "## Convo with Kamran 2023-10-23:\n",
    "- Use directional templates **\n",
    "- No need to worry about re-ranking\n",
    "- Plot the long and short separately in addition to the difference, so we show significant reqplay on each as a sanity check\n",
    "- Absolute value difference?\n",
    "- Fisher transform the correlation values (check if there is a difference) because correlation coefficients aren't going to be normally distributed.\n",
    "- Then Z-score releative to fisher.\n",
    "\n",
    "- T-test to compare to mean of zero (if looking at the difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6dbc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concerns:\n",
    "# 1. Permutation recommended over shuffling for small numbers of ids\n",
    "# 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a51d15e6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "from nptyping import NDArray\n",
    "from attrs import define, field, Factory, astuple\n",
    "import scipy.stats\n",
    "from scipy import ndimage\n",
    "from neuropy.utils.misc import build_shuffled_ids # used in _SHELL_analyze_leave_one_out_decoding_results\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import pho_stats_paired_t_test\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import compute_shuffled_rankorder_analyses, build_track_templates_for_shuffle, compute_shuffled_rankorder_analyses\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import TrackTemplates, RankOrderAnalyses, ShuffleHelper, Zscorer\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import build_pyqtgraph_epoch_indicator_regions\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _helper_add_long_short_session_indicator_regions\n",
    "from pyphocorehelpers.DataStructure.general_parameter_containers import VisualizationParameters, RenderPlotsData, RenderPlots # PyqtgraphRenderPlots\n",
    "from pyphocorehelpers.gui.PhoUIContainer import PhoUIContainer\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.PyqtgraphRenderPlots import PyqtgraphRenderPlots\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderDebugger import GenericPyQtGraphContainer\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderDebugger import GenericPyQtGraphScatterClicker\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.DockAreaWrapper import DockAreaWrapper, PhoDockAreaContainingWindow\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer, RankOrderResult\n",
    "\n",
    "def find_nearest_idx(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "# def find_nearest(array,value):\n",
    "#     idx = np.searchsorted(array, value, side=\"left\")\n",
    "#     if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "#         return array[idx-1]\n",
    "#     else:\n",
    "#         return array[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32563cb8",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# Recover from the saved global result:\n",
    "directional_laps_results = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "long_odd_shared_aclus_only_one_step_decoder_1D, long_even_shared_aclus_only_one_step_decoder_1D, short_odd_shared_aclus_only_one_step_decoder_1D, short_even_shared_aclus_only_one_step_decoder_1D = [directional_laps_results.__dict__[k] for k in ['long_odd_shared_aclus_only_one_step_decoder_1D', 'long_even_shared_aclus_only_one_step_decoder_1D', 'short_odd_shared_aclus_only_one_step_decoder_1D', 'short_even_shared_aclus_only_one_step_decoder_1D']]\n",
    "track_templates: TrackTemplates = TrackTemplates.init_from_paired_decoders(LR_decoder_pair=(long_odd_shared_aclus_only_one_step_decoder_1D, short_odd_shared_aclus_only_one_step_decoder_1D), RL_decoder_pair=(long_even_shared_aclus_only_one_step_decoder_1D, short_even_shared_aclus_only_one_step_decoder_1D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18de1f27",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "rank_order_results = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "\n",
    "odd_laps_epoch_ranked_aclus_stats_dict, odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, odd_laps_long_z_score_values, odd_laps_short_z_score_values, odd_laps_long_short_z_score_diff_values = rank_order_results.odd_laps\n",
    "even_laps_epoch_ranked_aclus_stats_dict, even_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, even_laps_long_z_score_values, even_laps_short_z_score_values, even_laps_long_short_z_score_diff_values = rank_order_results.even_laps\n",
    "\n",
    "odd_ripple_evts_epoch_ranked_aclus_stats_dict, odd_ripple_evts_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, odd_ripple_evts_long_z_score_values, odd_ripple_evts_short_z_score_values, odd_ripple_evts_long_short_z_score_diff_values = rank_order_results.odd_ripple\n",
    "even_ripple_evts_epoch_ranked_aclus_stats_dict, even_ripple_evts_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, even_ripple_evts_long_z_score_values, even_ripple_evts_short_z_score_values, even_ripple_evts_long_short_z_score_diff_values = rank_order_results.even_ripple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0366148f",
   "metadata": {},
   "source": [
    "##  🟢 Plot a debug view for directional laps. Shows the laps, the pf1Ds, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80a4a867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhoDockAreaContainingWindow.GlobalConnectionManagerAccessingMixin_on_setup()\n",
      "PhoDockAreaContainingWindow.try_register_any_control_widgets()\n",
      "\tflat_widgets_list contains 0 items\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.DockAreaWrapper import DockAreaWrapper, PhoDockAreaContainingWindow\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum, LongShortDisplayConfigManager\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig\n",
    "\n",
    "epochs_editor = EpochsEditor.init_from_session(global_session, include_velocity=True, include_accel=False)\n",
    "root_dockAreaWindow, app = DockAreaWrapper.wrap_with_dockAreaWindow(epochs_editor.plots.win, None, title='Pho Directional Laps Templates')\n",
    "\n",
    "# track_templates.long_LR_decoder.pf\n",
    "\n",
    "def _get_decoder_sorted_pfs(a_decoder):\n",
    "\tratemap = a_decoder.pf.ratemap\n",
    "\tCoM_sort_indicies = np.argsort(ratemap.peak_tuning_curve_center_of_masses) # get the indicies to sort the placefields by their center-of-mass (CoM) location\n",
    "\t# CoM_sort_indicies.shape # (n_neurons,)\n",
    "\treturn ratemap.pdf_normalized_tuning_curves[CoM_sort_indicies, :]\n",
    "\n",
    "decoders_dict = {'long_LR': track_templates.long_LR_decoder,\n",
    "\t'long_RL': track_templates.long_RL_decoder,\n",
    "\t'short_LR': track_templates.short_LR_decoder,\n",
    "\t'short_RL': track_templates.short_RL_decoder,\n",
    "}\n",
    "\n",
    "## Plot the placefield 1Ds as heatmaps and then wrap them in docks and add them to the window:\n",
    "_out_pf1D_heatmaps = {}\n",
    "for a_decoder_name, a_decoder in decoders_dict.items():\n",
    "\t_out_pf1D_heatmaps[a_decoder_name] = visualize_heatmap_pyqtgraph(_get_decoder_sorted_pfs(a_decoder), title=f'{a_decoder_name}_pf1Ds', show_value_labels=False, show_xticks=False, show_yticks=False, show_colorbar=False, win=None, defer_show=True)\n",
    "\n",
    "even_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_even_dock_colors)\n",
    "odd_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_odd_dock_colors)\n",
    "\n",
    "\n",
    "_out_dock_widgets = {}\n",
    "dock_configs = (even_dock_config, odd_dock_config, even_dock_config, odd_dock_config)\n",
    "dock_add_locations = (['left'], ['left'], ['right'], ['right'])\n",
    "\n",
    "for i, (a_decoder_name, a_heatmap) in enumerate(_out_pf1D_heatmaps.items()):\n",
    "\t_out_dock_widgets[a_decoder_name] = root_dockAreaWindow.add_display_dock(identifier=a_decoder_name, widget=a_heatmap[0], dockSize=(300,200), dockAddLocationOpts=dock_add_locations[i], display_config=dock_configs[i])\n",
    "\n",
    "\n",
    "# Outputs: root_dockAreaWindow, app, epochs_editor, _out_pf1D_heatmaps, _out_dock_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71975cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out = visualize_heatmap_pyqtgraph(np.vstack([odd_shuffle_helper.long_pf_peak_ranks, odd_shuffle_helper.short_pf_peak_ranks, even_shuffle_helper.long_pf_peak_ranks, even_shuffle_helper.short_pf_peak_ranks]), show_value_labels=True, show_xticks=True, show_yticks=True, show_colorbar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa8570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.shared_LR_aclus_only_neuron_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597bab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.long_LR_decoder.neuron_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the circle thingy. NOW.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75354ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.decoder_LR_pf_peak_ranks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb815932",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.decoder_RL_pf_peak_ranks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f14f37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.odd_shuffle_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd890c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ripple Rank-Order Analysis:\n",
    "_ripples_outputs = RankOrderAnalyses.main_ripples_analysis(curr_active_pipeline, num_shuffles=1000, rank_alignment='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46107d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RankOrderAnalyses.validate_has_rank_order_results(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ef964",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "## Show Ripple Helper:\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch = curr_active_pipeline.filtered_epochs[long_epoch_name]\n",
    "short_epoch = curr_active_pipeline.filtered_epochs[short_epoch_name]\n",
    "\n",
    "global_spikes_df, (odd_shuffle_helper, even_shuffle_helper) = RankOrderAnalyses.common_analysis_helper(curr_active_pipeline=curr_active_pipeline, num_shuffles=1000)\n",
    "spikes_df = deepcopy(global_spikes_df) #.spikes.sliced_by_neuron_id(track_templates.shared_aclus_only_neuron_IDs)\n",
    "global_replays = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay)\n",
    "if isinstance(global_replays, pd.DataFrame):\n",
    "\tglobal_replays = Epoch(global_replays.epochs.get_valid_df())\n",
    "\n",
    "# x_values = global_replays.labels.astype(float)\n",
    "# x_axis_name_suffix='Index'\n",
    "x_values = global_replays.midtimes\n",
    "x_axis_name_suffix='Mid-time (Sec)'\n",
    "_display_replay_z_score_diff_outputs = RankOrderAnalyses._perform_plot_z_score_diff(x_values, even_ripple_evts_long_short_z_score_diff_values, odd_ripple_evts_long_short_z_score_diff_values, variable_name='Ripple', x_axis_name_suffix=x_axis_name_suffix)\n",
    "_display_replay_z_score_raw_outputs = RankOrderAnalyses._perform_plot_z_score_raw(x_values, odd_ripple_evts_long_z_score_values, even_ripple_evts_long_z_score_values, odd_ripple_evts_short_z_score_values, even_ripple_evts_short_z_score_values, variable_name='Ripple', x_axis_name_suffix=x_axis_name_suffix)\n",
    "\n",
    "ripple_app, ripple_win, ripple_diff_p1, (ripple_even_out_plot_1D, ripple_odd_out_plot_1D) = _display_replay_z_score_diff_outputs\n",
    "long_epoch_indicator_region_items, short_epoch_indicator_region_items = _helper_add_long_short_session_indicator_regions(ripple_diff_p1, long_epoch, short_epoch)\n",
    "ripple_raw_app, ripple_raw_win, ripple_raw_p1, (ripple_long_even_out_plot_1D, ripple_long_odd_out_plot_1D, ripple_short_even_out_plot_1D, ripple_short_odd_out_plot_1D) = _display_replay_z_score_raw_outputs\n",
    "long_epoch_indicator_region_items, short_epoch_indicator_region_items = _helper_add_long_short_session_indicator_regions(ripple_raw_p1, long_epoch, short_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a807334",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lastClicked = []\n",
    "def _test_scatter_plot_clicked(plot, evt):\n",
    "\t\"\"\" captures `lastClicked` , `x_values`, `on_update_epoch_IDX`\n",
    "\tplot: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem object at 0x0000023C7D74C8B0>\n",
    "\tclicked points <MouseClickEvent (78.6115,-2.04825) button=1>\n",
    "\n",
    "\t\"\"\"\n",
    "\tglobal lastClicked  # Declare lastClicked as a global variable\n",
    "\t# for p in lastClicked:\n",
    "\t# \tp.resetPen()\n",
    "\t# print(f'plot: {plot}') # plot: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem object at 0x0000023C7D74C8B0>\n",
    "\t# print(f'\\tevt: {evt}')\t\n",
    "\t# print(\"clicked points\", evt.pos()) # clicked points <MouseClickEvent (48.2713,1.32425) button=1>\n",
    "\t# print(f'args: {args}')\n",
    "\tpt_x, pt_y = evt.pos()\n",
    "\tprint(f'\\tpt_x: {pt_x}')\n",
    "\tnearest_epoch_idx = find_nearest_idx(x_values, pt_x)\n",
    "\tprint(f'\\tnearest_epoch_idx: {nearest_epoch_idx}')\n",
    "\t\n",
    "\t# idx_x = int(round(pt_x))\n",
    "\t# print(f'\\tidx_x: {idx_x}')\n",
    "\t# # pts = plot.pointsAt(evt.pos())\n",
    "\t# print(f'pts: {pts}')\n",
    "\t# for p in points:\n",
    "\t# \tp.setPen(clickedPen)\n",
    "\n",
    "\ton_update_epoch_IDX(nearest_epoch_idx)\n",
    "\n",
    "\tlastClicked = idx_x\n",
    "\n",
    "\n",
    "active_connections_dict = {}\n",
    "for a_plot in _display_replay_z_score_raw_outputs[3]:\n",
    "\tmain_scatter_clicked_connection = a_plot.sigClicked.connect(_test_scatter_plot_clicked)\n",
    "\tactive_connections_dict[a_plot] = main_scatter_clicked_connection\n",
    "\n",
    "for a_plot in _display_replay_z_score_diff_outputs[3]:\n",
    "\tmain_scatter_clicked_connection = a_plot.sigClicked.connect(_test_scatter_plot_clicked)\n",
    "\tactive_connections_dict[a_plot] = main_scatter_clicked_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d3b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "GenericPyQtGraphContainer(plots=PyqtgraphRenderPlots(app=PyqtgraphRenderPlots, parent_root_widget=ripple_p1, display_outputs=(ripple_even_out_plot_1D, ripple_odd_out_plot_1D)), plot_data=)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffafb04",
   "metadata": {},
   "source": [
    "## Laps Rank-Order Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5835754",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "## Laps Rank-Order Analysis:\n",
    "# _laps_outputs = RankOrderAnalyses.main_laps_analysis(curr_active_pipeline, num_shuffles=200, rank_alignment='center_of_mass')\n",
    "_laps_outputs = RankOrderAnalyses.main_laps_analysis(curr_active_pipeline, num_shuffles=1000, rank_alignment='median')\n",
    "# _laps_outputs = RankOrderAnalyses.main_laps_analysis(curr_active_pipeline, num_shuffles=300, rank_alignment='first')\n",
    "\n",
    "# Unwrap:\n",
    "(odd_laps_outputs, even_laps_outputs, laps_paired_tests), laps_plots_outputs  = _laps_outputs\n",
    "\n",
    "if laps_plots_outputs is not None:\n",
    "    (laps_fig_odd, laps_ax_odd, laps_fig_even, laps_ax_even, _display_laps_z_score_raw_outputs, _display_laps_z_score_diff_outputs) = laps_plots_outputs\n",
    "\n",
    "odd_laps_epoch_ranked_aclus_stats_dict, odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, odd_laps_long_z_score_values, odd_laps_short_z_score_values, odd_laps_long_short_z_score_diff_values = odd_laps_outputs\n",
    "even_laps_epoch_ranked_aclus_stats_dict, even_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, even_laps_long_z_score_values, even_laps_short_z_score_values, even_laps_long_short_z_score_diff_values = even_laps_outputs\n",
    "\n",
    "# odd_laps_rank_order_result = RankOrderResult.init_from_analysis_output_tuple(odd_laps_outputs)\n",
    "# even_laps_rank_order_result = RankOrderResult.init_from_analysis_output_tuple(even_laps_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340e4644",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_laps_z_score_diff_outputs = RankOrderAnalyses._perform_plot_z_score_diff(global_laps.lap_id.astype(float), even_laps_long_short_z_score_diff_values, odd_laps_long_short_z_score_diff_values, variable_name='Lap')\n",
    "_display_laps_z_score_raw_outputs = RankOrderAnalyses._perform_plot_z_score_raw(global_laps.lap_id.astype(float), odd_laps_long_z_score_values, odd_laps_short_z_score_values, even_laps_long_z_score_values, even_laps_short_z_score_values, variable_name='Lap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b12eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Want to exhalt the ones that are correct for each epoch with a special emphasis, I think via pen.\n",
    "\n",
    "## Could more easily emphasize the highest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702fdf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_df = global_laps.to_dataframe()\n",
    "\n",
    "for a_lap in laps_df.itertuples():\n",
    "\tprint(f'a_lap: {a_lap}') # lap_id, label, lap_dir\n",
    "\ta_lap.lap_dir # 0 or 1\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d9a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about short/long? Need to add a column for that?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c11aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioral_epochs = deepcopy(curr_active_pipeline.sess.epochs)\n",
    "#          start         stop  label     duration\n",
    "# 0     0.000000  1029.316609  maze1  1029.316609\n",
    "# 1  1029.316609  1737.196831  maze2   707.880222\n",
    "behavioral_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320250e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_laps_df = deepcopy(global_laps.to_dataframe())\n",
    "global_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b06c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_column_name: str = 'maze_id'\n",
    "no_interval_fill_value = '' # empty string\n",
    "# new_column_epoch_conditions: pd.DataFrame = deepcopy(behavioral_epochs.to_dataframe())\n",
    "provided_epochs_df: pd.DataFrame = deepcopy(behavioral_epochs.to_dataframe())\n",
    "epochs_df: pd.DataFrame = global_laps_df\n",
    "if new_column_name in epochs_df.columns:\n",
    "\tprint(f'WARN: column \"{epochs_df}\" already exists in epochs_df!')\n",
    "\n",
    "epochs_df[new_column_name] = no_interval_fill_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722cfcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "provided_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daf41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.efficient_interval_search import OverlappingIntervalsFallbackBehavior, determine_event_interval_identity, determine_event_interval_is_included # numba acceleration\n",
    "\n",
    "\n",
    "# epochs_df, epoch_id_key_name='temp_epoch_id', epoch_label_column_name='label', override_time_variable_name=None, no_interval_fill_value=np.nan, overlap_behavior=OverlappingIntervalsFallbackBehavior.ASSERT_FAIL\n",
    "epochs_df\n",
    "epoch_id_key_name = new_column_name # 'maze_id' # TODO: rename\n",
    "# epoch_label_column_name: Optional[str] = 'label'\n",
    "epoch_label_column_name: Optional[str] = None\n",
    "override_time_variable_name = None\n",
    "# no_interval_fill_value = np.nan\n",
    "\n",
    "# overlap_behavior = OverlappingIntervalsFallbackBehavior.ASSERT_FAIL # note that we get \"AssertionError: Intervals in start_stop_times_arr must be non-overlapping\", even for Epochs which have the same end_t of epoch[0] and start_t of epoch[1].\n",
    "overlap_behavior = OverlappingIntervalsFallbackBehavior.FALLBACK_TO_SLOW_SEARCH\n",
    "\n",
    "debug_print = True\n",
    "\n",
    "\n",
    "## Code was from spk_df:\n",
    "\n",
    "## Extract epochs:\n",
    "provided_epochs_start_stop_arr = provided_epochs_df[['start','stop']].to_numpy()\n",
    "\n",
    "provided_epochs_start_stop_arr[0,1] += 0.001\n",
    "\n",
    "# active_time_variable_name: str = (override_time_variable_name or spk_df.spikes.time_variable_name) # by default use spk_df.spikes.time_variable_name, but an optional override can be provided (to ensure compatibility with PBEs)\n",
    "# event_times_arr = spk_df[active_time_variable_name].to_numpy()\n",
    "\n",
    "\n",
    "event_times_arr = epochs_df['start'].to_numpy()\n",
    "\n",
    "if epoch_label_column_name is None:\n",
    "\tprovided_epoch_identity_labels = provided_epochs_df.index.to_numpy() # currently using the index instead of the label.\n",
    "else:\n",
    "\tassert epoch_label_column_name in provided_epochs_df.columns, f\"if epoch_label_column_name is specified (not None) than the column {epoch_label_column_name} must exist in the provided_epochs_df, but provided_epochs_df.columns: {list(provided_epochs_df.columns)}!\"\n",
    "\tprovided_epoch_identity_labels = provided_epochs_df[epoch_label_column_name].to_numpy().astype(float)\n",
    "\t\n",
    "if debug_print:\n",
    "\tprint(f'np.shape(event_times_arr): {np.shape(event_times_arr)}, p.shape(provided_epochs_start_stop_arr): {np.shape(provided_epochs_start_stop_arr)}, p.shape(provided_epoch_identity_labels): {np.shape(provided_epoch_identity_labels)}')\n",
    "spike_epoch_identity_arr = determine_event_interval_identity(event_times_arr, provided_epochs_start_stop_arr, provided_epoch_identity_labels, no_interval_fill_value=no_interval_fill_value, overlap_behavior=overlap_behavior)\n",
    "# inclusion_mask = determine_event_interval_is_included(event_times_arr, provided_epochs_start_stop_arr)\n",
    "\n",
    "# inclusion_mask\n",
    "spike_epoch_identity_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad57a1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a451669",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_epoch_identity_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b720374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_df are the epochs you want to classify:\n",
    "start_times_arr = epochs_df['start'].to_numpy()\n",
    "end_times_arr = epochs_df['stop'].to_numpy()\n",
    "\n",
    "## provided_epochs_df are the ones to be used for classification:\n",
    "\n",
    "# curr_epochs_start_stop_arr = provided_epochs_df[['start','stop']].to_numpy()\n",
    "\n",
    "\n",
    "starts_within_epoch = start_times_arr >= provided_epochs_start_stop_arr[0,0]\n",
    "starts_within_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa4e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Data for Epochs\n",
    "\n",
    "# Since we sort by start time always, cases: \"Earlier Start Time\" will never happen.\n",
    "\n",
    "# Same Start Time:\n",
    "t00 = [[0.0, 1.0], [0.0, 0.9]] # earlier end time\n",
    "t01 = [[0.0, 1.0], [0.0, 1.0]] # same end time\n",
    "t02 = [[0.0, 1.0], [0.0, 1.1]] # later end time\n",
    "\n",
    "# Later Start Time:\n",
    "t10 = [[0.0, 1.0], [0.1, 0.9]] # earlier end time\n",
    "t11 = [[0.0, 1.0], [0.1, 1.0]] # same end time\n",
    "t12 = [[0.0, 1.0], [0.1, 1.1]] # later end time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Later Start Time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_epoch_identity_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9128da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df.epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df.loc[new_column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae1f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.laps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4265bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_session.epochs\n",
    "\n",
    "\n",
    "# behavioral_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9499a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Want to add a column_id to a general epochs-style dataframe to indicate which epoch falls into.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6022cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76790758",
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict\n",
    "len(track_templates.shared_LR_aclus_only_neuron_IDs) # 53, associated with odd\n",
    "\n",
    "\n",
    "# [track_templates.shared_LR_aclus_only_neuron_IDs[np.squeeze(v[:,0])] for k, v in odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict.items()]\n",
    "\n",
    "# [np.squeeze(v[:,0]).astype(int) for k, v in odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict.items()]\n",
    "\n",
    "odd_lists_of_aclus = [track_templates.shared_LR_aclus_only_neuron_IDs[np.squeeze(v[:,0]).astype(int)] for k, v in odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict.items()]\n",
    "even_lists_of_aclus = [track_templates.shared_RL_aclus_only_neuron_IDs[np.squeeze(v[:,0]).astype(int)] for k, v in even_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict.items()]\n",
    "even_lists_of_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2341125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clickedPen = pg.mkPen('#DDD', width=2)\n",
    "lastClicked = []\n",
    "def _test_scatter_plot_clicked(plot, evt):\n",
    "\t\"\"\" captures `lastClicked` \n",
    "\tplot: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem object at 0x0000023C7D74C8B0>\n",
    "\tclicked points <MouseClickEvent (78.6115,-2.04825) button=1>\n",
    "\n",
    "\t\"\"\"\n",
    "\tglobal lastClicked  # Declare lastClicked as a global variable\n",
    "\t# for p in lastClicked:\n",
    "\t# \tp.resetPen()\n",
    "\t# print(f'plot: {plot}') # plot: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem object at 0x0000023C7D74C8B0>\n",
    "\t# print(f'\\tevt: {evt}')\t\n",
    "\t# print(\"clicked points\", evt.pos()) # clicked points <MouseClickEvent (48.2713,1.32425) button=1>\n",
    "\t# print(f'args: {args}')\n",
    "\tpt_x, pt_y = evt.pos()\n",
    "\tidx_x = int(round(pt_x))\n",
    "\tprint(f'\\tidx_x: {idx_x}')\n",
    "\t# pts = plot.pointsAt(evt.pos())\n",
    "\t# print(f'pts: {pts}')\n",
    "\t# for p in points:\n",
    "\t# \tp.setPen(clickedPen)\n",
    "\tlastClicked = idx_x\n",
    "\n",
    "\n",
    "active_connections_dict = {}\n",
    "for a_plot in _display_z_score_diff_outputs[3]:\n",
    "\tmain_scatter_clicked_connection = a_plot.sigClicked.connect(_test_scatter_plot_clicked)\n",
    "\tactive_connections_dict[a_plot] = main_scatter_clicked_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b81eaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# even_out_plot_1D.sigClicked.disconnect(main_scatter_clicked_connection)\n",
    "\n",
    "for a_plot, a_connection in active_connections_dict.items():\n",
    "\ta_plot.sigClicked.disconnect(a_connection)\n",
    "\n",
    "active_connections_dict.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd32e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_laps_epoch_ranked_aclus_stats_dict\n",
    "\n",
    "# even_laps_epoch_ranked_aclus_stats_dict\n",
    "\n",
    "epoch_id_list = list(odd_laps_epoch_ranked_aclus_stats_dict.keys())\n",
    "epoch_id_list\n",
    "\n",
    "\n",
    "# for epoch_id, epoch_stats in odd_laps_epoch_ranked_aclus_stats_dict.items():\n",
    "for epoch_id in epoch_id_list:\n",
    "\todd_long_stats_z_scorer, odd_short_stats_z_scorer, odd_long_short_z_diff = odd_laps_epoch_ranked_aclus_stats_dict[epoch_id]\n",
    "\teven_long_stats_z_scorer, even_short_stats_z_scorer, even_long_short_z_diff = even_laps_epoch_ranked_aclus_stats_dict[epoch_id]\n",
    "    selected_spike_times = np.squeeze(odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict[epoch_id][:,1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e62b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'shared_aclus_only_neuron_IDs:\\t{print_array(shared_aclus_only_neuron_IDs)}')\n",
    "print(f'long_pf_peak_ranks:\\t{print_array(odd_shuffle_helper.long_pf_peak_ranks)}')\n",
    "print(f'short_pf_peak_ranks:\\t{print_array(odd_shuffle_helper.short_pf_peak_ranks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94ac886",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = visualize_heatmap_pyqtgraph(np.vstack([odd_shuffle_helper.long_pf_peak_ranks, odd_shuffle_helper.short_pf_peak_ranks, even_shuffle_helper.long_pf_peak_ranks, even_shuffle_helper.short_pf_peak_ranks]), show_value_labels=True, show_xticks=True, show_yticks=True, show_colorbar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb1478e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f5b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(np.arange(len(long_short_z_score_diff_values)), long_short_z_score_diff_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ef994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78167c30",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbd4843",
   "metadata": {},
   "source": [
    "epoch_id: 506\n",
    "epoch_neuron_IDXs: [15,19,25,52]\n",
    "epoch_neuron_IDX_ranks: [3,1,2,4]\n",
    "active_epoch_aclu_long_ranks[506]: [10,48,50,45]\n",
    "active_epoch_aclu_short_ranks[506]: [37,47,50,49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaab9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ranks0 = np.array([10,48,50,45])\n",
    "test_ranks1 = np.array([37,47,50,49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dbfe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_ranks0 = scipy.stats.rankdata(test_ranks0) # computes the relative ranks\n",
    "re_ranks0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a607502",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_re_ranks0 = np.array([0, 2, 3, 1])+1\n",
    "display(re_ranks0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e766c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_ranks1 = np.array([0, 1, 3, 2])+1\n",
    "display(re_ranks1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69738af",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.rankdata(test_ranks1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed08454",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_ranks0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9506adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_epoch_aclu_long_ranks[18]: [46 38 28 11 45]\n",
    "# active_epoch_aclu_short_ranks[18]: [44 46 32 10 49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1af1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_z_score_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda1267",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_z_score_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810dc016",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-10-23 - Future - Number of Swaps-basded ranking\n",
    "# https://www.interviewbit.com/blog/minimum-swaps-problem/ \n",
    "# Time Complexity: O(n * logn)\n",
    "# Space Complexity: O(n)\n",
    "\n",
    "\n",
    "def dfs(vec, vis, node, compSize):\n",
    "    vis[node] = True\n",
    "    compSize[0] += 1\n",
    "    for x in vec[node]:\n",
    "        if not vis[x]:\n",
    "            dfs(vec, vis, x, compSize)\n",
    "\n",
    "\n",
    "def minimumSwaps(a, n):\n",
    "    aux = [*enumerate(a)]\n",
    "    aux.sort(key=lambda it: it[1])\n",
    "    vis = [False] * (n + 1)\n",
    "    vec = [[] for i in range(n + 1)]\n",
    "    for i in range(n):\n",
    "        vec[aux[i][0] + 1].append(i + 1)\n",
    "    ans = 0\n",
    "    for i in range(1, n + 1):\n",
    "        compSize = [0]\n",
    "        if not vis[i]:\n",
    "            dfs(vec, vis, i, compSize)\n",
    "            ans += compSize[0] - 1\n",
    "    return ans\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1ae50",
   "metadata": {},
   "source": [
    "# 2023-11-1 - FINAL LAP FIXING (preventing overlaps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b0aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.DataStructure.general_parameter_containers import VisualizationParameters, RenderPlotsData, RenderPlots\n",
    "from pyphocorehelpers.gui.PhoUIContainer import PhoUIContainer\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import build_scrollable_graphics_layout_widget_ui, build_scrollable_graphics_layout_widget_with_nested_viewbox_ui\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomLinearRegionItem import CustomLinearRegionItem\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import build_pyqtgraph_epoch_indicator_regions\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "\n",
    "from neuropy.core.laps import Laps\n",
    "from neuropy.analyses.laps import _subfn_perform_estimate_lap_splits_1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "\n",
    "epochs_editor = EpochsEditor.init_from_session(global_session, include_velocity=True, include_accel=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e5b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lap_change_indicies = _subfn_perform_estimate_lap_splits_1D(pos_df, hardcoded_track_midpoint_x=None, debug_print=True) # allow smart midpoint determiniation\n",
    "(desc_crossing_begining_idxs, desc_crossing_midpoint_idxs, desc_crossing_ending_idxs), (asc_crossing_begining_idxs, asc_crossing_midpoint_idxs, asc_crossing_ending_idxs), hardcoded_track_midpoint_x = lap_change_indicies\n",
    "# Build a new laps object\n",
    "custom_test_laps_obj = Laps.from_estimated_laps(pos_df['t'].to_numpy(), desc_crossing_begining_idxs, desc_crossing_ending_idxs, asc_crossing_begining_idxs, asc_crossing_ending_idxs)\n",
    "custom_test_laps_df = custom_test_laps_obj.to_dataframe()\n",
    "\n",
    "custom_epochs_editor = EpochsEditor.init_laps_diagnoser(pos_df, custom_test_laps_df, include_velocity=True, include_accel=True)\n",
    "custom_epochs_editor.add_lap_split_points(lap_change_indicies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c05bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c5fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for an_item in \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1d055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.plots[scatter_plot_name_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877b7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_item = build_indicies_points_scatter(desc_crossing_begining_idxs, points_name_str='desc_crossing_begining_idxs', points_kwargs=dict(symbol='o', size=5, pen={'color': 'w', 'width': 1}))\n",
    "v1.addItem(an_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1b7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "# long_epoch_context, short_epoch_context, global_epoch_context = [owning_pipeline_reference.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "fig, out_axes_list = plot_laps_2d(global_session, legacy_plotting_mode=False)\n",
    "out_axes_list[0].set_title('Estimated Laps')\n",
    "fig.canvas.manager.set_window_title('Estimated Laps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d4310",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_editor.plots[scatter_plot_name_str] = build_indicies_points_scatter(asc_crossing_midpoint_idxs, points_name_str='asc_crossing_midpoint_idxs', points_kwargs=dict(symbol='o', size=10, pen={'color': 'w', 'width': 1}))\n",
    "v1.addItem(epochs_editor.plots[scatter_plot_name_str])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41112a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2226194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Extract changes from `epochs_editor`\n",
    "user_labeled_laps_df: pd.DataFrame = epochs_editor.get_user_labeled_epochs_df()\n",
    "# curr_active_pipeline.output\n",
    "# user_labeled_laps_df.to_csv('user_labeled_laps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dabe92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_user_labeled_laps_df: pd.DataFrame = pd.read_csv('user_labeled_laps.csv')\n",
    "read_user_labeled_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c55420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b4168",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labeled_csv_path = curr_active_pipeline.get_output_path().joinpath('user_labeled_laps.csv')\n",
    "read_user_labeled_laps_df.to_csv(user_labeled_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b48c09c",
   "metadata": {},
   "source": [
    "## 2023-10-19 - Rank-Order Spike Timing in Replay epoch analyses:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f4190",
   "metadata": {
    "tags": [
     "spike_laps"
    ]
   },
   "outputs": [],
   "source": [
    "from PendingNotebookCode import SpikesRankOrder\n",
    "from neuropy.utils.efficient_interval_search import filter_epochs_by_num_active_units\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "\n",
    "# active_sess = curr_active_pipeline.filtered_sessions['maze']\n",
    "# active_epochs = active_sess.perform_compute_estimated_replay_epochs(min_epoch_included_duration=None, max_epoch_included_duration=None, maximum_speed_thresh=None) # filter on nothing basically\n",
    "# active_spikes_df = active_sess.spikes_df.spikes.sliced_by_neuron_type('pyr') # only look at pyramidal cells\n",
    "\n",
    "# active_epochs = deepcopy(global_replays)\n",
    "active_epochs = deepcopy(global_laps).trimmed_to_non_overlapping()\n",
    "active_spikes_df = deepcopy(global_pf1D.spikes_df)\n",
    "\n",
    "# spike_trimmed_active_epochs, _extra_outputs = filter_epochs_by_num_active_units(active_spikes_df, active_epochs, min_inclusion_fr_active_thresh=2.0, min_num_unique_aclu_inclusions=1)\n",
    "epoch_ranked_aclus_dict, active_spikes_df, all_probe_epoch_ids, all_aclus = SpikesRankOrder.compute_rankordered_spikes_during_epochs(active_spikes_df, active_epochs)\n",
    "epoch_ranked_aclus_stats_corr_values, epoch_ranked_aclus_stats_p_values, (outside_epochs_ranked_aclus_stats_corr_value, outside_epochs_ranked_aclus_stats_p_value) = SpikesRankOrder.compute_rankordered_stats(epoch_ranked_aclus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edea52a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_session.replace_session_laps_with_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a15e803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0d75cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_laps_2d(global_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926132fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epoch_ranked_aclus_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bce2ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(global_laps._df.columns)) # ['start_position_index', 'end_position_index', 'lap_dir', 'start_t_rel_seconds', 'end_t_rel_seconds', 'start', 'stop', 'lap_id', 'label', 'start_spike_index', 'end_spike_index', 'num_spikes', 'duration']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db80a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "['start_position_index', 'end_position_index', 'start_spike_index', 'end_spike_index', 'num_spikes']\n",
    "\n",
    "active_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155810d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(global_laps) # neuropy.core.laps.Laps\n",
    "global_laps_df: pd.DataFrame = global_laps.as_epoch_obj().to_dataframe().epochs.get_valid_df()\n",
    "global_laps_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8319c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(global_laps) # neuropy.core.epoch.Epoch\n",
    "# it is becoming a Laps object somehow, and then getting each epoch duplicated\n",
    "\n",
    "# Drop duplicate rows in column: 'start'\n",
    "global_laps_df = global_laps_df.drop_duplicates(subset=['start'])\n",
    "# Filter rows based on column: 'duration'\n",
    "global_laps_df = global_laps_df[global_laps_df['duration'] > 0] # drop zero duration rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42be3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_laps_df.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1c5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_session.laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfeced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_session.laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_session.laps_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8767d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e31b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_laps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65896de",
   "metadata": {},
   "source": [
    "### Compute numerical data ranks (1 through n) along axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4725d80d",
   "metadata": {},
   "source": [
    "```\n",
    "## {aclu: rank_index, ...} # ignore the fact that the indicies are shown as floating point values, they aren't actually.\n",
    "Epoch[0]: {16: 12.0, 46: 17.0, 48: 4.0, 51: 9.0, 53: 5.0, 55: 8.0, 59: 1.0, 62: 10.0, 67: 15.0, 73: 16.0, 78: 14.0, 81: 7.0, 88: 2.0, 91: 6.0, 95: 13.0, 101: 11.0, 108: 3.0}\n",
    "...\n",
    "Epoch[404]: {7: 14.0, 17: 4.0, 21: 16.0, 33: 11.0, 34: 3.0, 39: 9.0, 45: 7.0, 48: 20.0, 54: 15.0, 61: 13.0, 63: 5.0, 71: 21.0, 72: 12.0, 74: 6.0, 84: 8.0, 86: 1.0, 88: 2.0, 90: 18.0, 95: 19.0, 99: 17.0, 102: 10.0}\n",
    "Epoch[405]: {10: 15.0, 14: 10.0, 15: 9.0, 17: 1.0, 31: 7.0, 33: 12.0, 34: 2.0, 39: 22.0, 45: 4.0, 49: 5.0, 50: 6.0, 54: 20.0, 55: 8.0, 63: 3.0, 64: 21.0, 72: 11.0, 75: 18.0, 76: 25.0, 78: 23.0, 83: 17.0, 85: 19.0, 90: 16.0, 91: 13.0, 101: 24.0, 107: 14.0}\n",
    "```\n",
    "### So here I have unequal lists of observations with only some of the cells present in each epoch. How should I analyze this, it still seems to me like there's an issue with unequal sampling in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64206a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PendingNotebookCode import _scramble_curve\n",
    "\n",
    "\n",
    "curr_random_not_firing_cell_pf_curve = _scramble_curve(curr_cell_pf_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f3b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_ranked_aclus_stats_corr_values, epoch_ranked_aclus_stats_p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846fc779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_ranked_aclus_stats_corr_values: .shape: (n_epochs,)\n",
    "# epoch_ranked_aclus_stats_p_values: .shape: (n_epochs,)\n",
    "\n",
    "np.shape(epoch_ranked_aclus_stats_corr_values)\n",
    "# epoch_ranked_aclus_stats_p_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29172a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epochs.starts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb0e65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=active_num_rows, sharex=True, sharey=sharey, figsize=figsize)\n",
    "\n",
    "axes[0].scatter(active_epochs.starts, epoch_ranked_aclus_stats_corr_values, label='CorrValues', marker=\"s\", s=5, alpha=0.8) # , title='Rank-Order p-values'\n",
    "axes[1].scatter(active_epochs.starts, epoch_ranked_aclus_stats_p_values, label='p-values', marker=\"s\", s=5, alpha=0.8) # , ylabel='Corr Values'\n",
    "plt.suptitle('Rank-Order of Replay Epochs')\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0a9881",
   "metadata": {},
   "source": [
    "# Starts with Even (idx=0)\n",
    "\n",
    "## EVEN: \"RL\"\n",
    "shared_RL_aclus_only_neuron_IDs\n",
    "`is_even = (an_epoch.lap_dir == 0)`\n",
    "\n",
    "## ODD: \"LR\"\n",
    "shared_LR_aclus_only_neuron_IDs\n",
    "`is_odd = (an_epoch.lap_dir == 1)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7988cca",
   "metadata": {},
   "source": [
    "# 🟢🖼️ 2023-10-27 - Example validation of directional shuffles with multi-raster plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a36a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.DirectionalTemplatesRastersDebugger import _debug_plot_directional_template_rasters\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.DirectionalTemplatesRastersDebugger import build_selected_spikes_df\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.DirectionalTemplatesRastersDebugger import add_selected_spikes_df_points_to_scatter_plot\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.DockAreaWrapper import DockAreaWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8491b1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "PhoDockAreaContainingWindow.GlobalConnectionManagerAccessingMixin_on_setup()\n",
      "PhoDockAreaContainingWindow.try_register_any_control_widgets()\n",
      "\tflat_widgets_list contains 0 items\n"
     ]
    }
   ],
   "source": [
    "## Inputs: curr_active_pipeline, track_templates, global_replays, owning_pipeline_reference\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "active_epochs_df = global_laps_epochs_df.copy()\n",
    "\n",
    "odd_display_outputs, even_display_outputs = _debug_plot_directional_template_rasters(global_spikes_df, active_epochs_df, track_templates)\n",
    "odd_app, odd_win, odd_plots, odd_plots_data, odd_on_update_active_epoch, odd_on_update_active_scatterplot_kwargs = odd_display_outputs\n",
    "even_app, even_win, even_plots, even_plots_data, even_on_update_active_epoch, even_on_update_active_scatterplot_kwargs = even_display_outputs\n",
    "# Build the wrapping window using `DockAreaWrapper`:\n",
    "active_root_main_widget = odd_win.window()\n",
    "root_dockAreaWindow, app = DockAreaWrapper.wrap_with_dockAreaWindow(active_root_main_widget, even_win, title='Pho Rank-Order Epochs Debugger')\n",
    "\n",
    "\n",
    "def on_update_active_epoch(an_epoch_idx, an_epoch):\n",
    "    \"\"\" captures: odd_on_update_active_epoch, even_on_update_active_epoch, root_dockAreaWindow \"\"\"\n",
    "    odd_on_update_active_epoch(an_epoch_idx, an_epoch=an_epoch)\n",
    "    even_on_update_active_epoch(an_epoch_idx, an_epoch=an_epoch)\n",
    "    root_dockAreaWindow.setWindowTitle(f'Pho Rank-Order Epochs Debugger: Epoch[{an_epoch_idx}]')\n",
    "\n",
    "def on_update_epoch_IDX(an_epoch_idx):\n",
    "    \"\"\" captures on_update_active_epoch, active_epochs_df to extract the epoch time range and call `on_update_active_epoch` \"\"\"\n",
    "    # curr_epoch_spikes = spikes_df[(spikes_df.new_lap_IDX == an_epoch_idx)]\n",
    "    curr_epoch_df = active_epochs_df[(active_epochs_df.lap_id == (an_epoch_idx+1))]\n",
    "    curr_epoch = list(curr_epoch_df.itertuples())[0]\n",
    "\n",
    "    on_update_active_epoch(an_epoch_idx, curr_epoch)\n",
    "\n",
    "## Build the selected spikes df:\n",
    "\n",
    "## Laps:\n",
    "## Ripples: even_ripple_evts_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, odd_ripple_evts_epoch_selected_spikes_fragile_linear_neuron_IDX_dict\n",
    "\n",
    "(even_selected_spike_df, even_neuron_id_to_new_IDX_map), (odd_selected_spike_df, odd_neuron_id_to_new_IDX_map) = build_selected_spikes_df(track_templates, active_epochs_df, even_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict)\n",
    "\n",
    "## Add the spikes\n",
    "add_selected_spikes_df_points_to_scatter_plot(plots_data=odd_plots_data, plots=odd_plots, selected_spikes_df=deepcopy(odd_selected_spike_df), _active_plot_identifier = 'long_odd')\n",
    "add_selected_spikes_df_points_to_scatter_plot(plots_data=odd_plots_data, plots=odd_plots, selected_spikes_df=deepcopy(odd_selected_spike_df), _active_plot_identifier = 'short_odd')\n",
    "add_selected_spikes_df_points_to_scatter_plot(plots_data=even_plots_data, plots=even_plots, selected_spikes_df=deepcopy(even_selected_spike_df), _active_plot_identifier = 'long_even')\n",
    "add_selected_spikes_df_points_to_scatter_plot(plots_data=even_plots_data, plots=even_plots, selected_spikes_df=deepcopy(even_selected_spike_df), _active_plot_identifier = 'short_even')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7574df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderDebugger import GenericPyQtGraphContainer\n",
    "\n",
    "ripples_rank_debugger = GenericPyQtGraphContainer()\n",
    "ripples_rank_debugger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0e7e4",
   "metadata": {},
   "source": [
    "### Ripples Debugger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inputs: curr_active_pipeline, track_templates, global_replays, owning_pipeline_reference\n",
    "\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].spikes_df)\n",
    "\n",
    "global_ripples_epochs_df = global_replays.to_dataframe()\n",
    "active_epochs_df = global_ripples_epochs_df.copy()\n",
    "\n",
    "odd_display_outputs, even_display_outputs = _debug_plot_directional_template_rasters(global_spikes_df, active_epochs_df, track_templates)\n",
    "odd_app, odd_win, odd_plots, odd_plots_data, odd_on_update_active_epoch, odd_on_update_active_scatterplot_kwargs = odd_display_outputs\n",
    "even_app, even_win, even_plots, even_plots_data, even_on_update_active_epoch, even_on_update_active_scatterplot_kwargs = even_display_outputs\n",
    "\n",
    "# Build the wrapping window using `DockAreaWrapper`:\n",
    "active_root_main_widget = odd_win.window()\n",
    "root_dockAreaWindow, app = DockAreaWrapper.wrap_with_dockAreaWindow(active_root_main_widget, even_win, title='Pho Rank-Order Epochs Debugger')\n",
    "\n",
    "def on_update_active_epoch(an_epoch_idx, an_epoch):\n",
    "    \"\"\" captures: odd_on_update_active_epoch, even_on_update_active_epoch, root_dockAreaWindow \"\"\"\n",
    "    odd_on_update_active_epoch(an_epoch_idx, an_epoch=an_epoch)\n",
    "    even_on_update_active_epoch(an_epoch_idx, an_epoch=an_epoch)\n",
    "    root_dockAreaWindow.setWindowTitle(f'Pho Rank-Order Epochs Debugger: Epoch[{an_epoch_idx}]')\n",
    "\n",
    "\n",
    "def on_update_epoch_IDX(an_epoch_idx):\n",
    "    \"\"\" captures on_update_active_epoch, active_epochs_df to extract the epoch time range and call `on_update_active_epoch` \"\"\"\n",
    "    # curr_epoch_spikes = spikes_df[(spikes_df.new_lap_IDX == an_epoch_idx)]\n",
    "    # curr_epoch_df = active_epochs_df[(active_epochs_df.lap_id == (an_epoch_idx+1))]\n",
    "    # curr_epoch_df = active_epochs_df[(active_epochs_df.label.astype(float) == float(an_epoch_idx))]\n",
    "    curr_epoch_df = active_epochs_df[(active_epochs_df.index.astype(float) == float(an_epoch_idx))]\n",
    "    curr_epoch = list(curr_epoch_df.itertuples())[0]\n",
    "    on_update_active_epoch(an_epoch_idx, curr_epoch)\n",
    "\n",
    "## Build the selected spikes df:\n",
    "\n",
    "## Laps: even_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict\n",
    "## Ripples: even_ripple_evts_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, odd_ripple_evts_epoch_selected_spikes_fragile_linear_neuron_IDX_dict\n",
    "\n",
    "(even_selected_spike_df, even_neuron_id_to_new_IDX_map), (odd_selected_spike_df, odd_neuron_id_to_new_IDX_map) = build_selected_spikes_df(track_templates, active_epochs_df, even_ripple_evts_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, odd_ripple_evts_epoch_selected_spikes_fragile_linear_neuron_IDX_dict)\n",
    "\n",
    "## Add the spikes\n",
    "add_selected_spikes_df_points_to_scatter_plot(plots_data=odd_plots_data, plots=odd_plots, selected_spikes_df=deepcopy(odd_selected_spike_df), _active_plot_identifier = 'long_odd')\n",
    "add_selected_spikes_df_points_to_scatter_plot(plots_data=odd_plots_data, plots=odd_plots, selected_spikes_df=deepcopy(odd_selected_spike_df), _active_plot_identifier = 'short_odd')\n",
    "add_selected_spikes_df_points_to_scatter_plot(plots_data=even_plots_data, plots=even_plots, selected_spikes_df=deepcopy(even_selected_spike_df), _active_plot_identifier = 'long_even')\n",
    "add_selected_spikes_df_points_to_scatter_plot(plots_data=even_plots_data, plots=even_plots, selected_spikes_df=deepcopy(even_selected_spike_df), _active_plot_identifier = 'short_even')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2011cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dockAreaWindow.setWindowTitle(f'Pho Rank-Order Epochs Debugger: Epoch[{an_epoch_idx}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_update_epoch_IDX(410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.DockAreaWrapper import DockAreaWrapper\n",
    "# Wrap:\n",
    "active_root_main_widget = odd_win.window()\n",
    "root_dockAreaWindow, app = DockAreaWrapper.wrap_with_dockAreaWindow(active_root_main_widget, even_win, title='Pho Rank-Order Epochs Debugger')\n",
    "# pane = (root_dockAreaWindow, placefieldControlsContainerWidget, pf_widgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b06f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@define(slots=False)\n",
    "class RankOrderDebugger(GenericPyQtGraphContainer):\n",
    "    \"\"\" RankOrderDebugger displays four rasters showing the same spikes but sorted according to four different templates (RL_odd, RL_even, LR_odd, LR_even)\n",
    "\n",
    "    \"\"\"\n",
    "    global_spikes_df: pd.DataFrame = field()\n",
    "    active_epochs_df: pd.DataFrame = field()\n",
    "    track_templates: TrackTemplates = field()\n",
    "    even_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict: Dict = field()\n",
    "    odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict: Dict = field()\n",
    "    \n",
    "    @classmethod\n",
    "    def init_rank_order_debugger(cls, global_spikes_df: pd.DataFrame, global_epochs_df: pd.DataFrame, track_templates: TrackTemplates, even_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict: Dict, odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict: Dict):\n",
    "        \"\"\" NOT YET FINISHED!\n",
    "        long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "        global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "        global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "        global_laps_epochs_df = global_laps.to_dataframe()\n",
    "          \n",
    "        \"\"\"\n",
    "        _obj = cls(global_spikes_df=global_spikes_df, active_epochs_df=global_epochs_df.copy(), track_templates=track_templates,\n",
    "             even_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict=even_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict=odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict)\n",
    "\n",
    "\n",
    "        # odd_display_outputs, even_display_outputs = _debug_plot_directional_template_rasters(global_spikes_df, self.active_epochs_df, self.track_templates)\n",
    "        # odd_app, odd_win, odd_plots, odd_plots_data, odd_on_update_active_epoch, odd_on_update_active_scatterplot_kwargs = odd_display_outputs\n",
    "        # even_app, even_win, even_plots, even_plots_data, even_on_update_active_epoch, even_on_update_active_scatterplot_kwargs = even_display_outputs\n",
    "\n",
    "        # ## Build the selected spikes df:\n",
    "\n",
    "        # (even_selected_spike_df, even_neuron_id_to_new_IDX_map), (odd_selected_spike_df, odd_neuron_id_to_new_IDX_map) = build_selected_spikes_df(self.track_templates, self.active_epochs_df, self.even_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, self.odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict)\n",
    "\n",
    "        # ## Add the spikes\n",
    "        # add_selected_spikes_df_points_to_scatter_plot(plots_data=odd_plots_data, plots=odd_plots, selected_spikes_df=deepcopy(odd_selected_spike_df), _active_plot_identifier = 'long_odd')\n",
    "        # add_selected_spikes_df_points_to_scatter_plot(plots_data=odd_plots_data, plots=odd_plots, selected_spikes_df=deepcopy(odd_selected_spike_df), _active_plot_identifier = 'short_odd')\n",
    "        # add_selected_spikes_df_points_to_scatter_plot(plots_data=even_plots_data, plots=even_plots, selected_spikes_df=deepcopy(even_selected_spike_df), _active_plot_identifier = 'long_even')\n",
    "        # add_selected_spikes_df_points_to_scatter_plot(plots_data=even_plots_data, plots=even_plots, selected_spikes_df=deepcopy(even_selected_spike_df), _active_plot_identifier = 'short_even')\n",
    "\n",
    "        return _obj\n",
    "\n",
    "\n",
    "\n",
    "    def on_update_active_epoch(self, an_epoch_idx, an_epoch):\n",
    "        \"\"\" captures: odd_on_update_active_epoch, even_on_update_active_epoch \"\"\"\n",
    "        self.odd_on_update_active_epoch(an_epoch_idx, an_epoch=an_epoch)\n",
    "        self.even_on_update_active_epoch(an_epoch_idx, an_epoch=an_epoch)\n",
    "\n",
    "\n",
    "    def on_update_epoch_IDX(self, an_epoch_idx):\n",
    "        \"\"\" captures on_update_active_epoch, active_epochs_df to extract the epoch time range and call `on_update_active_epoch` \"\"\"\n",
    "        # curr_epoch_spikes = spikes_df[(spikes_df.new_lap_IDX == an_epoch_idx)]\n",
    "        curr_epoch_df = self.active_epochs_df[(self.active_epochs_df.lap_id == (an_epoch_idx+1))]\n",
    "        curr_epoch = list(curr_epoch_df.itertuples())[0]\n",
    "\n",
    "        self.on_update_active_epoch(an_epoch_idx, curr_epoch)\n",
    "\n",
    "\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "\n",
    "ripples_rank_debugger = RankOrderDebugger.init_rank_order_debugger(global_spikes_df, global_laps_epochs_df, track_templates, even_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict)\n",
    "ripples_rank_debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55985cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict, odd_laps_epoch_selected_spikes_fragile_linear_neuron_IDX_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b5a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc18447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_epoch_idx: int = 4\n",
    "on_update_epoch_IDX(active_epoch_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2f63af",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "## 2023-10-04 - Compare the decoded result of each replay epoch between the long/short decoder to determine which is better for that Epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "# neuron_replay_stats_df.reset_index()\n",
    "# neuron_replay_stats_df.index = neuron_replay_stats_df['aclu']\n",
    "\n",
    "a_long_decoder_result: DecodedFilterEpochsResult = long_results_obj.all_included_filter_epochs_decoder_result\n",
    "a_short_decoder_result: DecodedFilterEpochsResult = short_results_obj.all_included_filter_epochs_decoder_result\n",
    "\n",
    "# filter_epochs_decoder_result\n",
    "# curr_results_obj.active_filter_epochs, curr_results_obj.all_included_filter_epochs_decoder_result, xbin=curr_results_obj.original_1D_decoder.xbin\n",
    "\n",
    "\n",
    "# image_layer_dict = {}\n",
    "# layer_properties_dict = {\n",
    "# \t# 'snapshot_occupancy_weighted_tuning_maps': dict(blending='additive', colormap='viridis', name='pf1D_dt'),\n",
    "# #  'flat_jensen_shannon_distance_results': dict(blending='additive', colormap='gray'),\n",
    "# \t'long_p_x_given_n': dict(blending='additive', colormap='bop blue'),\n",
    "# \t'short_p_x_given_n': dict(blending='additive', colormap='red'),\n",
    "\t\n",
    "# }\n",
    "\n",
    "# for a_name, layer_properties in layer_properties_dict.items():\n",
    "# \t# image_layer_dict[a_name] = viewer.add_image(active_relative_entropy_results_xr_dict[a_name].to_numpy().astype(float), name=a_name)\n",
    "# \timage_layer_dict[a_name] = viewer.add_image(active_relative_entropy_results[a_name].astype(float), **(dict(name=a_name)|layer_properties))\n",
    "\n",
    "# assert viewer.dims.ndim == 3\n",
    "# ## Set the dimensions appropriately\n",
    "# viewer.dims.axis_labels = ('t', 'neuron_id', 'xbin')\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(1,1)\n",
    "for decoded_epoch_idx in np.arange(a_long_decoder_result.num_filter_epochs):\n",
    "\n",
    "\tif decoded_epoch_idx < 5:\n",
    "\t\t# decoded_epoch_idx:int = 0\n",
    "\t\tcurr_epoch_time_bin_container = a_long_decoder_result.time_bin_containers[decoded_epoch_idx]\n",
    "\t\tcurr_time_bins = curr_epoch_time_bin_container.centers\n",
    "\n",
    "\t\t## Long Decoding:\n",
    "\t\tcurr_long_epoch_p_x_given_n = a_long_decoder_result.p_x_given_n_list[decoded_epoch_idx] # .shape: (239, 5) - (n_x_bins, n_epoch_time_bins)\n",
    "\t\t## Need to exclude estimates from bins that didn't have any spikes in them (in general these glitch around):\n",
    "\t\t# curr_total_spike_counts_per_window = np.sum(a_decoder_result.spkcount[decoded_epoch_idx], axis=0) # left_out_decoder_result.spkcount[i].shape # (69, 222) - (nCells, nTimeWindowCenters)\n",
    "\t\t# curr_is_time_bin_non_firing = (curr_total_spike_counts_per_window == 0) # this would mean that no cells fired in this time bin\n",
    "\t\tcurr_long_most_likely_position_indicies = np.squeeze(a_long_decoder_result.most_likely_position_indicies_list[decoded_epoch_idx]) # (n_epoch_time_bins, ) one position for each time bin in the replay\n",
    "\t\t# curr_most_likely_positions = a_decoder_result.most_likely_positions_list[decoded_epoch_idx]\n",
    "\t\tcurr_long_most_likely_position_confidence = np.max(curr_long_epoch_p_x_given_n, axis=0) # (n_epoch_time_bins, )\n",
    "\n",
    "\n",
    "\t\t## Short Decoding:\n",
    "\t\tcurr_short_epoch_p_x_given_n = a_short_decoder_result.p_x_given_n_list[decoded_epoch_idx] # .shape: (239, 5) - (n_x_bins, n_epoch_time_bins)\n",
    "\t\t## Need to exclude estimates from bins that didn't have any spikes in them (in general these glitch around):\n",
    "\t\t# curr_total_spike_counts_per_window = np.sum(a_decoder_result.spkcount[decoded_epoch_idx], axis=0) # left_out_decoder_result.spkcount[i].shape # (69, 222) - (nCells, nTimeWindowCenters)\n",
    "\t\t# curr_is_time_bin_non_firing = (curr_total_spike_counts_per_window == 0) # this would mean that no cells fired in this time bin\n",
    "\t\tcurr_short_most_likely_position_indicies = np.squeeze(a_short_decoder_result.most_likely_position_indicies_list[decoded_epoch_idx]) # (n_epoch_time_bins, ) one position for each time bin in the replay\n",
    "\t\tcurr_short_most_likely_position_confidence = np.max(curr_short_epoch_p_x_given_n, axis=0) # (n_epoch_time_bins, )\n",
    "\n",
    "\t\t# _long_short_decoding_comparison_df = pd.DataFrame({'t': curr_time_bins,\n",
    "\t\t# \t'x_bin_long': curr_long_most_likely_position_indicies, 'x_bin_long_confidence': curr_long_most_likely_position_confidence,\n",
    "\t\t# \t'x_bin_short': curr_short_most_likely_position_indicies, 'x_bin_short_confidence': curr_short_most_likely_position_confidence}) # , 'x': curr_most_likely_positions\n",
    "\n",
    "\t\tviewer.add_image(curr_long_epoch_p_x_given_n.astype(float), **(dict(name=f'long_p_x_given_n[{decoded_epoch_idx}]', blending='additive', colormap='red')))\n",
    "\t\tviewer.add_image(curr_short_epoch_p_x_given_n.astype(float), **(dict(name=f'short_p_x_given_n[{decoded_epoch_idx}]', blending='additive', colormap='bop blue')))\n",
    "\n",
    "\t# np.shape(curr_long_epoch_p_x_given_n)\n",
    "\t# _long_short_decoding_comparison_df.plot(y=['x_bin_long', 'x_bin_short'], color=['r','g'], ax=ax)\n",
    "\n",
    "# _long_short_decoding_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e173de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max([np.shape(a_long_decoder_result.p_x_given_n_list[decoded_epoch_idx]) for decoded_epoch_idx in np.arange(a_long_decoder_result.num_filter_epochs)], axis=0)\n",
    "# np.max([np.shape(a_short_decoder_result.p_x_given_n_list[decoded_epoch_idx]) for decoded_epoch_idx in np.arange(a_short_decoder_result.num_filter_epochs)], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de2edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_long_decoder_result.p_x_given_n_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_decoder_result.p_x_given_n_list[decoded_epoch_idx]\n",
    "# a_decoder_result.most_likely_position_indicies_list\n",
    "\n",
    "\n",
    "# curr_most_likely_positions\n",
    "\n",
    "_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c62e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_time_bins.shape\n",
    "curr_most_likely_positions.shape\n",
    "curr_most_likely_position_indicies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoder_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd9f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for decoded_epoch_idx in np.arange(a_decoder_result.num_filter_epochs):\n",
    "\tcurr_epoch_time_bin_container = a_decoder_result.time_bin_containers[decoded_epoch_idx]\n",
    "\tcurr_cell_decoded_epoch_time_bins.append(curr_epoch_time_bin_container)\n",
    "\tcurr_time_bins = curr_epoch_time_bin_container.centers\n",
    "\tcurr_epoch_p_x_given_n = a_decoder_result.p_x_given_n_list[decoded_epoch_idx] # .shape: (239, 5) - (n_x_bins, n_epoch_time_bins)\n",
    "\tassert curr_epoch_p_x_given_n.shape[0] == curr_cell_pf_curve.shape[0]\n",
    "\t\n",
    "\t## Need to exclude estimates from bins that didn't have any spikes in them (in general these glitch around):\n",
    "\tcurr_total_spike_counts_per_window = np.sum(a_decoder_result.spkcount[decoded_epoch_idx], axis=0) # left_out_decoder_result.spkcount[i].shape # (69, 222) - (nCells, nTimeWindowCenters)\n",
    "\tcurr_is_time_bin_non_firing = (curr_total_spike_counts_per_window == 0) # this would mean that no cells fired in this time bin\n",
    "\tcurr_most_likely_position_indicies = a_decoder_result.most_likely_position_indicies_list[decoded_epoch_idx] # (n_epoch_time_bins, ) one position for each time bin in the replay\n",
    "\t\n",
    "\t# From the firing map of the placefields for this neuron (`decoder_1D.F.T[left_out_neuron_IDX]`) get the value for each position bin index in the epoch\n",
    "\tcurr_epoch_expected_fr = np.squeeze(a_decoder_1D.F.T[left_out_neuron_IDX][curr_most_likely_position_indicies])\n",
    "\t# expected_num_spikes = curr_epoch_expected_fr * decoder_result.decoding_time_bin_size\n",
    "\n",
    "\t# Eqn 1:\n",
    "\t# p_n_given_x = lambda n: (1.0/factorial(n)) * pow(expected_num_spikes, n) * np.exp(-expected_num_spikes) # likelihood function\n",
    "\t\n",
    "\tall_cells_decoded_expected_firing_rates[left_out_aclu].append(curr_epoch_expected_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2fbcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049bf938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.neuron_identities import NeuronIdentityDataframeAccessor\n",
    "\n",
    "neuron_replay_stats_df = neuron_replay_stats_df.neuron_identity.make_neuron_indexed_df_global(curr_active_pipeline.get_session_context(), add_expanded_session_context_keys=False, add_extended_aclu_identity_columns=False)\n",
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29710ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df.neuron_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88beb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager, SessionCellExclusivityRecord\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "\n",
    "\n",
    "\n",
    "# for a_ctx, a_val in annotation_man.get_hardcoded_specific_session_override_dict().items():\n",
    "# \tannotation_man.annotations[a_ctx] = a_val\n",
    "\n",
    "# for a_ctx, a_val in UserAnnotationsManager.get_user_annotations().items():\n",
    "# \tannotation_man.annotations[a_ctx] = a_val\n",
    "\n",
    "# for a_ctx, a_val in session_cell_exclusivity_annotations.items():\n",
    "# \t# Not ideal. Adds a key 'session_cell_exclusivity' to the extant session context instead of being indexable by an entirely new context\n",
    "# \tannotation_man.annotations[a_ctx] = annotation_man.annotations.get(a_ctx, {}) | dict(session_cell_exclusivity=a_val)\n",
    "# \t# annotation_man.annotations[a_ctx.overwriting_context(user_annotation='session_cell_exclusivity')] = a_val\n",
    "\n",
    "annotation_man = UserAnnotationsManager()\n",
    "session_cell_exclusivity: SessionCellExclusivityRecord = annotation_man.annotations[curr_active_pipeline.get_session_context()].get('session_cell_exclusivity', None)\n",
    "session_cell_exclusivity.LxC\n",
    "session_cell_exclusivity.SxC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0f270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-10-03 - My metric comes from the number of laps with an active long place vs. number of laps with an active short place\n",
    "# curr_active_pipeline.sess.laps\n",
    "# active_long_spikes_df = active_spikes_df[active_spikes_df.is_included_long_pf1D]\n",
    "# active_short_spikes_df = active_spikes_df[active_spikes_df.is_included_short_pf1D]\n",
    "\n",
    "# active_spikes_df: pd.DataFrame = long_session.spikes_df.copy()\n",
    "active_spikes_df: pd.DataFrame = global_session.spikes_df.copy()\n",
    "# active_spikes_df[active_spikes_df['lap'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb48f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.neuron_identities import NeuronExtendedIdentityTuple, NeuronType\n",
    "\n",
    "\n",
    "def pho_long_short_exclusivity_index(active_spikes_df: pd.DataFrame) -> pd.DataFrame:\n",
    "\t\"\"\" 2023-10-03 - Long/Short Exclusivity Metric based off of Pho's intuition. Looks at the total number of spikes over laps. Pletny of room for improvement. \n",
    "\n",
    "\t\"\"\"\n",
    "\t# active_spikes_df['neuron_type'] = active_spikes_df.map(\n",
    "\n",
    "\t# Drop rows with missing data in columns: 'lin_pos', 't' and 8 other columns\n",
    "\tactive_spikes_df = active_spikes_df.dropna(subset=['lin_pos', 't', 't_seconds', 't_rel_seconds', 'x', 'y', 'aclu', 'maze_id', 'lap', 'maze_relative_lap'])\n",
    "\t# Filter rows based on columns: 'lap', 'maze_id'\n",
    "\tactive_spikes_df = active_spikes_df[(active_spikes_df['lap'] != -1) & (active_spikes_df['maze_id'] != -1)]\n",
    "\n",
    "\t# Convert the 'neuron_type' column of the dataframe to the categorical type if needed\n",
    "\tcat_type = NeuronType.get_pandas_categories_type()\n",
    "\tif active_spikes_df[\"neuron_type\"].dtype != cat_type:\n",
    "\t\t# If this type check ever becomes a problem and we want a more liberal constraint, All instances of CategoricalDtype compare equal to the string 'category'.\n",
    "\t\tactive_spikes_df[\"neuron_type\"] = active_spikes_df[\"neuron_type\"].apply(lambda x: x.hdfcodingClassName).astype(cat_type) # NeuronType can't seem to be cast directly to the new categorical type, it results in the column being filled with NaNs. Instead cast to string first.\n",
    "\n",
    "\tactive_spikes_df = active_spikes_df.astype({'maze_id': 'category', 'lap': 'category', 'maze_relative_lap': 'category', 'aclu': 'category'})\n",
    "\t# display(active_spikes_df)\n",
    "\n",
    "\t# Performed 5 aggregations grouped on columns: 'aclu', 'maze_id', 'lap'\n",
    "\tactive_spikes_df_agg = active_spikes_df.groupby(['aclu', 'maze_id', 'maze_relative_lap']).agg(t_count=('t', 'count'), lin_pos_mean=('lin_pos', 'mean'), lin_pos_std=('lin_pos', 'std'), lin_pos_min=('lin_pos', 'min'), lin_pos_max=('lin_pos', 'max')).reset_index()\n",
    "\n",
    "\tcurr_unique_aclus = active_spikes_df_agg['aclu'].unique()\n",
    "\tcurr_unique_maze_relative_laps = active_spikes_df_agg['maze_relative_lap'].unique()\n",
    "\tn_total_entries: int = len(active_spikes_df_agg['maze_relative_lap'].unique()) * len(active_spikes_df_agg['aclu'].unique())\n",
    "\n",
    "\t# Static lists of columns:\n",
    "\trelevant_columns_list = ['aclu', 'maze_relative_lap', 't_count', 'lin_pos_mean', 'lin_pos_std', 'lin_pos_min', 'lin_pos_max']\n",
    "\trelevant_index_column_names = ['aclu', 'maze_relative_lap']\n",
    "\tnumerical_column_names = ['t_count', 'lin_pos_mean', 'lin_pos_std', 'lin_pos_min', 'lin_pos_max']\n",
    "\n",
    "\tlong_maze_df = active_spikes_df_agg[active_spikes_df_agg['maze_id'] == 1][relevant_columns_list].reset_index()\n",
    "\tshort_maze_df = active_spikes_df_agg[active_spikes_df_agg['maze_id'] == 2][relevant_columns_list].reset_index() #.set_index(['aclu', 'maze_relative_lap'])\n",
    "\n",
    "\tn_laps = len(active_spikes_df_agg['maze_relative_lap'].unique())\n",
    "\tn_long_laps = len(long_maze_df['maze_relative_lap'].unique()) \n",
    "\tn_short_laps = len(short_maze_df['maze_relative_lap'].unique()) \n",
    "\n",
    "\tn_min_laps = min(n_long_laps, n_short_laps)\n",
    "\tsafe_lap_indicies = np.arange(n_min_laps) + 1\n",
    "\tif n_long_laps > n_min_laps:\n",
    "\t\t# truncate the long laps\n",
    "\t\tlong_maze_df = long_maze_df[np.isin(long_maze_df['maze_relative_lap'], safe_lap_indicies)]\n",
    "\tif n_short_laps > n_min_laps:\n",
    "\t\t# truncate the short laps\n",
    "\t\tshort_maze_df = short_maze_df[np.isin(short_maze_df['maze_relative_lap'], safe_lap_indicies)]\n",
    "\n",
    "\t## Compute the difference between the two\n",
    "\tlong_short_maze_diff_df = long_maze_df[numerical_column_names] - short_maze_df[numerical_column_names]\n",
    "\tlong_short_maze_diff_df[relevant_index_column_names] = long_maze_df[relevant_index_column_names].copy()\n",
    "\t# long_short_maze_diff_df = long_short_maze_diff_df.set_index(relevant_index_column_names)\n",
    "\tlong_short_maze_diff_df = long_short_maze_diff_df.groupby(['aclu']).agg(t_count_sum=('t_count', 'sum'), t_count_mean=('t_count', 'mean')).reset_index() # Aggregate across all columns to get a value for each 'aclu'\n",
    "\t# , t_count_max=('t_count', 'max')\n",
    "\t# long_short_maze_diff_df.set_index('aclu')\n",
    "\t# Sort by column: 't_count_sum' (ascending)\n",
    "\tlong_short_maze_diff_df = long_short_maze_diff_df.sort_values(['t_count_sum'], na_position='first')\n",
    "\treturn long_short_maze_diff_df\n",
    "\n",
    "\n",
    "active_spikes_df: pd.DataFrame = global_session.spikes_df.copy()\n",
    "long_short_maze_diff_df = pho_long_short_exclusivity_index(active_spikes_df=active_spikes_df)\n",
    "long_short_maze_diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b6acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import partition, safe_pandas_get_group\n",
    "from pyphocorehelpers.indexing_helpers import partition_df\n",
    "\n",
    "unique_aclu_values, aclu_group_dfs = partition_df(long_short_maze_diff_df, 'aclu')\n",
    "n_aclus = len(unique_aclu_values)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=n_aclus, ncols=1, sharex=True, sharey=False)\n",
    "\n",
    "for i, (aclu, aclu_df) in enumerate(zip(unique_aclu_values, aclu_group_dfs)):\n",
    "\taclu_df.plot(x='maze_relative_lap', y='t_count', label=f'{aclu}', ax=axes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_maze_diff_df = long_maze_df['t_count'].to_numpy() - short_maze_df['t_count'].to_numpy()\n",
    "long_short_maze_diff_df.set_index()\n",
    "long_short_maze_diff_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f086f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_spikes_df_agg.reindex([active_spikes_df_agg['aclu'].unique(), active_spikes_df_agg['maze_relative_lap'].unique()], fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import partition, safe_pandas_get_group\n",
    "\n",
    "unique_values, group_dfs = partition(active_spikes_df_agg, 'maze_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f06f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_values, group_dfs = partition(active_spikes_df_agg, 'maze_id')\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9cf0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_pandas_get_group(active_spikes_df_agg, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44579fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf8721",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values, group_dfs = partition(active_spikes_df, 'aclu')\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7770fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for aclu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06339961",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df = group_dfs[unique_values[0]]\n",
    "# type(a_df)\n",
    "a_df.shape # (4320, 8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21e3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_spikes_df_agg[active_spikes_df_agg['maze_id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0bde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_spikes_df_agg['maze_id'].eq(1).astype(int).groupby(active_spikes_df_agg['aclu']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performed 2 aggregations grouped on columns: 'aclu', 'maze_id', 'lap'\n",
    "active_spikes_df = active_spikes_df.groupby(['aclu', 'maze_id', 'lap']).agg(flat_spike_idx_count=('flat_spike_idx', 'count'), lin_pos_var=('lin_pos', 'var')).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae5e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performed 5 aggregations grouped on columns: 'aclu', 'maze_id'\n",
    "active_spikes_df = active_spikes_df.groupby(['aclu', 'maze_id']).agg(t_count=('t', 'count'), lin_pos_mean=('lin_pos', 'mean'), lin_pos_std=('lin_pos', 'std'), lin_pos_min=('lin_pos', 'min'), lin_pos_max=('lin_pos', 'max')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ee8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "'maze_id'==1\n",
    "\n",
    "active_spikes_df[active_spikes_df['lap'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2340733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f47f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ee54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_rename_dict = {'neuron_type':'neuron_type'}\n",
    "# input_df.rename(\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff2939c",
   "metadata": {},
   "source": [
    "# 2023-10-03 - Recompute `long_short_inst_spike_rate_groups`, fixing result for empty LxC/SxC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74aa3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce4dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if curr_active_pipeline.global_computation_results.computation_config is None:\n",
    "\tglobal_computation_results.computation_config = DynamicContainer(instantaneous_time_bin_size_seconds=0.01)\n",
    "else:\n",
    "\t# update the existing value\n",
    "\tcurr_active_pipeline.global_computation_results.computation_config.instantaneous_time_bin_size_seconds = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4f5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=['long_short_inst_spike_rate_groups'], include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=True, debug_print=False)\n",
    "newly_computed_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf4d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903acc7",
   "metadata": {},
   "source": [
    "## 2023-09-29 - Plot the LxC/SxC PhoJonathanPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots, BatchPhoJonathanFiguresHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5922fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## all cells, sorted by custom_frs_index:\n",
    "# fig_1c_figures_all_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df.sort_values('custom_frs_index', ascending=True, inplace=False), included_unit_neuron_IDs=None,\n",
    "# \tn_max_page_rows=20, write_vector_format=False, write_png=False,\n",
    "# \tshow_only_refined_cells=False, disable_top_row=True, split_by_short_long_shared=False)\n",
    "\n",
    "fig_1c_figures_all_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=None,\n",
    "\tn_max_page_rows=20, write_vector_format=False, write_png=True,\n",
    "\tshow_only_refined_cells=False, disable_top_row=False, split_by_short_long_shared=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad664f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba5b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1c_figures_out_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=long_exclusive.get_refined_track_exclusive_aclus(), n_max_page_rows=20, write_vector_format=False, write_png=True, show_only_refined_cells=True, disable_top_row=True)\n",
    "fig_1c_figures_out_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=short_exclusive.get_refined_track_exclusive_aclus(), n_max_page_rows=20, write_vector_format=False, write_png=True, show_only_refined_cells=True, disable_top_row=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac53d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1c_figures_out_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=save_figure, disable_top_row=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_1c_figures_out_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.get_refined_track_exclusive_aclus(), n_max_page_rows=20, write_vector_format=False, write_png=True, show_only_refined_cells=True, disable_top_row=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e290fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df.copy()\n",
    "\n",
    "np.sum(np.logical_xor(neuron_replay_stats_df['is_refined_LxC'], neuron_replay_stats_df['is_refined_SxC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941cc7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.logical_and(neuron_replay_stats_df['is_refined_LxC'], neuron_replay_stats_df['is_refined_SxC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460c6e5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# uses global's 'extended_stats' results for relative entropy (surprise) analyses:\n",
    "\n",
    "import tables as tb\n",
    "\n",
    "\n",
    "# {\n",
    "# 't': Tuple[float, float],\n",
    "# 'snapshots': Tuple[PlacefieldSnapshot, PlacefieldSnapshot],\n",
    "# 'relative_entropy_result_dict': {\n",
    "# \t\t'long_short_rel_entr_curve': np.array,\n",
    "# \t\t...\n",
    "# \t\t'jensen_shannon_distance': np.array,\n",
    "# \t} # 5 items\n",
    "# } # 3 items\n",
    "# Dict[float, PlacefieldSnapshot]\n",
    "\n",
    "def relative_entropy_to_h5(global_results, file_path='output/test_relative_entropy_numpy_arrays.h5'):\n",
    "\tprint(f'relative_entropy_to_h5(...)')\n",
    "\n",
    "\tactive_extended_stats = global_results['extended_stats']\n",
    "\tactive_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise'] # DynamicParameters\n",
    "\tpost_update_times: np.ndarray = active_relative_entropy_results['post_update_times'] # (4152,) = (n_post_update_times,)\n",
    "\tsnapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "\ttime_intervals: np.ndarray = active_relative_entropy_results['time_intervals']\n",
    "\tlong_short_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "\tshort_long_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "\tflat_relative_entropy_results: np.ndarray = active_relative_entropy_results['flat_relative_entropy_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "\tflat_jensen_shannon_distance_results: np.ndarray = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "\tflat_jensen_shannon_distance_across_all_positions: np.ndarray = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\tflat_surprise_across_all_positions: np.ndarray = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\t\n",
    "\t# Create an HDF5 file\n",
    "\twith tb.open_file(file_path, mode=\"w\") as hdf5_file:\n",
    "\t\tprint(f'trying to write to \"{file_path}\"...')\n",
    "\t\t# Create groups for organization\n",
    "\t\troot = hdf5_file.root\n",
    "\t\tgroup = hdf5_file.create_group(root, 'relative_entropy_results')\n",
    "\t\t\n",
    "\t\t# Store np.ndarrays in the HDF5 file\n",
    "\t\thdf5_file.create_array(group, 'post_update_times', post_update_times)\n",
    "\t\thdf5_file.create_array(group, 'time_intervals', time_intervals)\n",
    "\t\thdf5_file.create_array(group, 'long_short_rel_entr_curves_frames', long_short_rel_entr_curves_frames)\n",
    "\t\thdf5_file.create_array(group, 'short_long_rel_entr_curves_frames', short_long_rel_entr_curves_frames)\n",
    "\t\thdf5_file.create_array(group, 'flat_relative_entropy_results', flat_relative_entropy_results)\n",
    "\t\thdf5_file.create_array(group, 'flat_jensen_shannon_distance_results', flat_jensen_shannon_distance_results)\n",
    "\t\thdf5_file.create_array(group, 'flat_jensen_shannon_distance_across_all_positions', flat_jensen_shannon_distance_across_all_positions)\n",
    "\t\thdf5_file.create_array(group, 'flat_surprise_across_all_positions', flat_surprise_across_all_positions)\n",
    "\t\n",
    "\tprint(f'\\t done!')\n",
    "\t\n",
    "\n",
    "relative_entropy_to_h5(global_results, file_path='output/test_relative_entropy_numpy_arrays.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c6b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_differences_result_dict\n",
    "\n",
    "flat_jensen_shannon_distance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06537c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_relative_entropy_results\n",
    "# type(active_relative_entropy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd2f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "neuron_replay_stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d613474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test classifying various x-positions as belonging to outside the outside_maze, the track_endcaps, or the track_body\n",
    "from enum import Enum\n",
    "\n",
    "class TrackPositionClassification(Enum):\n",
    "    OUTSIDE_MAZE = \"outside_maze\"\n",
    "    TRACK_ENDCAPS = \"track_endcaps\"\n",
    "    TRACK_BODY = \"track_body\"\n",
    "\n",
    "\n",
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "short_pf_peak_x = neuron_replay_stats_df.short_pf_peak_x\n",
    "long_pf_peak_x = neuron_replay_stats_df.long_pf_peak_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b2a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_remapping_df[np.isin(rate_remapping_df.index, significant_distant_remapping_endcap_aclus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51571ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_spike_rate_groups_result: InstantaneousSpikeRateGroupsComputation = curr_active_pipeline.global_computation_results.computed_data.long_short_inst_spike_rate_groups\n",
    "# custom_InstSpikeRateTrends_df = inst_spike_rate_groups_result.all_incl_endPlatforms_InstSpikeRateTrends_df\n",
    "# if not hasattr(inst_spike_rate_groups_result, 'all_incl_endPlatforms_InstSpikeRateTrends_df'):\n",
    "# \tinst_spike_rate_groups_result.all_incl_endPlatforms_InstSpikeRateTrends_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c789f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2023-09-14 - Find cells outside the bounds of the short track\n",
    "# Modifies the `jonathan_firing_rate_analysis_result.neuron_replay_stats_df` in-place instead of creating a copy:\n",
    "# neuron_replay_stats_df = deepcopy(jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "# Extract the peaks of the long placefields to find ones that have peaks outside the boundaries\n",
    "# long_pf_peaks = neuron_replay_stats_df[neuron_replay_stats_df['has_long_pf']]['long_pf_peak_x'] - 150.0 # this shift of 150.0 is to center the midpoint of the track at 0. \n",
    "# # display(long_pf_peaks)\n",
    "# is_left_cap = (long_pf_peaks < -72.0)\n",
    "# is_right_cap = (long_pf_peaks > 72.0)\n",
    "# is_either_cap =  np.logical_or(is_left_cap, is_right_cap)\n",
    "\n",
    "# # Adds ['is_long_peak_left_cap', 'is_long_peak_right_cap', 'is_long_peak_either_cap'] columns: \n",
    "# neuron_replay_stats_df['is_long_peak_left_cap'] = False\n",
    "# neuron_replay_stats_df['is_long_peak_right_cap'] = False\n",
    "# neuron_replay_stats_df.loc[is_left_cap.index, 'is_long_peak_left_cap'] = is_left_cap # True\n",
    "# neuron_replay_stats_df.loc[is_right_cap.index, 'is_long_peak_right_cap'] = is_right_cap # True\n",
    "# neuron_replay_stats_df['is_long_peak_either_cap'] = np.logical_or(neuron_replay_stats_df['is_long_peak_left_cap'], neuron_replay_stats_df['is_long_peak_right_cap'])\n",
    "# adds ['LS_pf_peak_x_diff'] column\n",
    "# neuron_replay_stats_df['LS_pf_peak_x_diff'] = neuron_replay_stats_df['long_pf_peak_x'] - neuron_replay_stats_df['short_pf_peak_x']\n",
    "neuron_replay_stats_df.is_long_peak_either_cap\n",
    "\n",
    "## Extract just the endcap cells:\n",
    "cap_cells_df = neuron_replay_stats_df[np.logical_and(neuron_replay_stats_df['has_long_pf'], neuron_replay_stats_df['is_long_peak_either_cap'])]\n",
    "cap_aclus = cap_cells_df.index\n",
    "num_total_endcap_cells = len(cap_aclus)\n",
    "display(num_total_endcap_cells)\n",
    "\n",
    "# \"Disppearing\" cells fall below the 1Hz firing criteria on the short track:\n",
    "disappearing_endcap_cells_df = cap_cells_df[np.logical_not(cap_cells_df['has_short_pf'])]\n",
    "disappearing_endcap_aclus = disappearing_endcap_cells_df.index\n",
    "num_disappearing_endcap_cells = len(disappearing_endcap_aclus)\n",
    "print(f'num_disappearing_endcap_cells/num_total_endcap_cells: {num_disappearing_endcap_cells}/{num_total_endcap_cells}')\n",
    "\n",
    "non_disappearing_endcap_cells_df = cap_cells_df[cap_cells_df['has_short_pf']] # \"non_disappearing\" cells are those with a placefield on the short track as well\n",
    "num_non_disappearing_endcap_cells = len(non_disappearing_endcap_cells_df)\n",
    "print(f'num_non_disappearing_endcap_cells/num_total_endcap_cells: {num_non_disappearing_endcap_cells}/{num_total_endcap_cells}')\n",
    "\n",
    "# display(non_disappearing_endcap_cells_df)\n",
    "# non_disappearing_endcap_cells_df['LS_pf_peak_x_diff'] = non_disappearing_endcap_cells_df['long_pf_peak_x'] - non_disappearing_endcap_cells_df['short_pf_peak_x']\n",
    "# display(non_disappearing_endcap_cells_df)\n",
    "\n",
    "# Classify the non_disappearing cells into two groups:\n",
    "# 1. Those that exhibit significant remapping onto somewhere else on the track\n",
    "non_disappearing_endcap_cells_df['has_significant_distance_remapping'] = (np.abs(non_disappearing_endcap_cells_df['LS_pf_peak_x_diff']) >= 40.0) # The most a placefield could translate intwards would be (35 + (pf_width/2.0)) I think.\n",
    "num_significant_position_remappping_endcap_cells = len(non_disappearing_endcap_cells_df[non_disappearing_endcap_cells_df['has_significant_distance_remapping'] == True])\n",
    "print(f'num_significant_position_remappping_endcap_cells/num_non_disappearing_endcap_cells: {num_significant_position_remappping_endcap_cells}/{num_non_disappearing_endcap_cells}')\n",
    "\n",
    "# 2. Those that seem to remain where they were on the long track, perhaps being \"sampling-clipped\" or translated adjacent to the platform. These two subcases can be distinguished by a change in the placefield's length (truncated cells would be a fraction of the length, although might need to account for scaling with new track length)\n",
    "minorly_changed_endcap_cells_df = non_disappearing_endcap_cells_df[non_disappearing_endcap_cells_df['has_significant_distance_remapping'] == False]\n",
    "\n",
    "non_disappearing_endcap_cells_df\n",
    "# endcaps:\n",
    "significant_distant_remapping_endcap_aclus = non_disappearing_endcap_cells_df[non_disappearing_endcap_cells_df['has_significant_distance_remapping']].index.to_numpy() # Int64Index([3, 5, 7, 11, 14, 38, 41, 53, 57, 61, 62, 75, 78, 79, 82, 83, 85, 95, 98, 100, 102], dtype='int64')\n",
    "significant_distant_remapping_endcap_aclus\n",
    "minor_remapping_endcap_aclus = minorly_changed_endcap_cells_df.index.to_numpy()\n",
    "minor_remapping_endcap_aclus\n",
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_distant_remapping_endcap_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[np.isin(jonathan_firing_rate_analysis_result.neuron_replay_stats_df.index, significant_distant_remapping_endcap_aclus)]\n",
    "significant_distant_remapping_endcap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will these remapped cells be included in replays after the delta?\n",
    "num_short_replays = non_disappearing_endcap_cells_df['short_num_replays']\n",
    "short_replay_mean_fr_Hz = non_disappearing_endcap_cells_df['replay_diff']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb68efff",
   "metadata": {},
   "source": [
    "# 2023-10-11 - sanity check the Jensen-Shannon distance metric by computing for each placefield curve:\n",
    "As a sanity check, compute the Jensen-Shannon Distance between each of the distributions for the long/short curve. Expected to see that non-trivially remapping cells had a greater JS-distance than the others.\n",
    "### NO: It doesn't work, not even a little bit. Returns inf values for curves containing no infs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc7b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "# (epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "\n",
    "## long_short_endcap_analysis:\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11685400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_pf1D.ratemap.unsmoothed_tuning_maps.shape\n",
    "\n",
    "long_1DMaps = long_pf1D.get_by_id(trivially_remapping_endcap_aclus).ratemap.unsmoothed_tuning_maps # (15, 107)\n",
    "short_1DMaps = short_pf1D.get_by_id(trivially_remapping_endcap_aclus).ratemap.unsmoothed_tuning_maps # .shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: these results are NOT the same as the ones calculated in compute_snapshot_relative_entropy_surprise_differences.compute_surprise_relative_entropy_divergence, and I'm not quite sure why:\n",
    "# Jensen-Shannon distance is an average of KL divergence:\n",
    "\n",
    "from scipy.special import rel_entr\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "# 2023-10-11 - Earth mover's distance\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# def compute_surprise_relative_entropy_divergence(long_curve, short_curve):\n",
    "# \t\"\"\" Pre 2023-03-10 Refactoring:\n",
    "# \tGiven two tuning maps, computes the surprise (in terms of the KL-divergence a.k.a. relative entropy) between the two\n",
    "# \tReturns a dictionary containing the results in both directions\n",
    "\n",
    "# \tTODO 2023-03-08 02:41: - [ ] Convert naming convention from long_, short_ to lhs_, rhs_ to be general\n",
    "# \tTODO 2023-03-08 02:47: - [ ] Convert output dict to a dataclass\n",
    "\n",
    "# \tfrom pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ExtendedStats import compute_surprise_relative_entropy_divergence\n",
    "\n",
    "# \t\"\"\"\n",
    "# \tlong_short_rel_entr_curve = rel_entr(long_curve, short_curve)\n",
    "# \tlong_short_relative_entropy = sum(long_short_rel_entr_curve) \n",
    "# \tshort_long_rel_entr_curve = rel_entr(short_curve, long_curve)\n",
    "# \tshort_long_relative_entropy = sum(short_long_rel_entr_curve)\n",
    "# \t# Jensen-Shannon distance is an average of KL divergence:\n",
    "# \tmixture_distribution = 0.5 * (long_curve + short_curve)\n",
    "# \tjensen_shannon_distance = 0.5 * (sum(rel_entr(mixture_distribution, long_curve)) + sum(rel_entr(mixture_distribution, short_curve))) # is this right? I'm confused by sum(...)\n",
    "\n",
    "# \treturn dict(long_short_rel_entr_curve=long_short_rel_entr_curve, long_short_relative_entropy=long_short_relative_entropy, short_long_rel_entr_curve=short_long_rel_entr_curve, short_long_relative_entropy=short_long_relative_entropy,\n",
    "# \t\t\tjensen_shannon_distance=jensen_shannon_distance)\n",
    "\n",
    "\n",
    "\n",
    "# def JS_Distance(long_short_rel_entr_curves_frames, short_long_rel_entr_curves_frames):\n",
    "# \t\"\"\" seems incorrect. Returns a vector of Inf values for JS-Distance\"\"\"\n",
    "# \tmixture_distribution = 0.5 * (long_short_rel_entr_curves_frames + short_long_rel_entr_curves_frames)\n",
    "# \tprint(f'mixture_distribution.shape: {np.shape(mixture_distribution)}') # (nSnapshots, n_neurons, n_xbins)\n",
    "# \t# jensen_shannon_distance = 0.5 * (sum(rel_entr(mixture_distribution, long_short_rel_entr_curves_frames)) + sum(rel_entr(mixture_distribution, short_long_rel_entr_curves_frames))) # is this right? I'm confused by sum(...) # (n_neurons, n_xbins)\n",
    "# \tjensen_shannon_distance = 0.5 * (np.sum(rel_entr(mixture_distribution, long_short_rel_entr_curves_frames), axis=1) + np.sum(rel_entr(mixture_distribution, short_long_rel_entr_curves_frames), axis=1)) # alt version: (nSnapshots, n_xbins)\n",
    "# \tprint(f'jensen_shannon_distance.shape: {np.shape(jensen_shannon_distance)}') # (n_neurons, n_xbins)\n",
    "# \treturn jensen_shannon_distance, mixture_distribution\n",
    "\n",
    "\n",
    "def earth_movers_distance(long_1DMaps, short_1DMaps):\n",
    "\tn_cells = np.shape(short_1DMaps)[0]\n",
    "\t# return np.array([cdist(np.atleast_2d(np.squeeze(long_1DMaps[i,:])), np.atleast_2d(np.squeeze(short_1DMaps[i,:])), 'jensenshannon')[0,0] for i in np.arange(n_cells)])\n",
    "\treturn np.array([wasserstein_distance(np.squeeze(long_1DMaps[i,:]), np.squeeze(short_1DMaps[i,:])) for i in np.arange(n_cells)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# i = 0\n",
    "# js_result_dict = compute_surprise_relative_entropy_divergence(np.squeeze(long_1DMaps[i,:]), np.squeeze(short_1DMaps[i,:]))\n",
    "# js_result_dict\n",
    "# js_result_dict['jensen_shannon_distance']\n",
    "# js_result_dict['long_short_rel_entr_curve']\n",
    "\n",
    "# jensen_shannon_distance, mixture_distribution = JS_Distance(long_1DMaps, short_1DMaps)\n",
    "# jensen_shannon_distance\n",
    "\n",
    "# earth_movers_distance = cdist(long_1DMaps, short_1DMaps, 'jensenshannon')\n",
    "\n",
    "# n_cells = np.shape(short_1DMaps)[0]\n",
    "# earth_movers_distance = np.array([cdist(np.atleast_2d(np.squeeze(long_1DMaps[i,:])), np.atleast_2d(np.squeeze(short_1DMaps[i,:])), 'jensenshannon')[0,0] for i in np.arange(n_cells)])\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e930baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# long_1DMaps = long_pf1D.get_by_id(trivially_remapping_endcap_aclus).ratemap.unsmoothed_tuning_maps # (15, 107)\n",
    "# short_1DMaps = short_pf1D.get_by_id(trivially_remapping_endcap_aclus).ratemap.unsmoothed_tuning_maps # .shape\n",
    "\n",
    "# appearing_earth_movers_distance = earth_movers_distance(long_pf1D.get_by_id(appearing_aclus).ratemap.unsmoothed_tuning_maps, short_pf1D.get_by_id(appearing_aclus).ratemap.unsmoothed_tuning_maps)\n",
    "\n",
    "# get_curve_fn = lambda x: x.unsmoothed_tuning_maps\n",
    "get_curve_fn = lambda x: x.unsmoothed_tuning_maps\n",
    "\n",
    "trivially_remapping_endcap_earth_movers_distance = earth_movers_distance(get_curve_fn(long_pf1D.get_by_id(trivially_remapping_endcap_aclus).ratemap), get_curve_fn(short_pf1D.get_by_id(trivially_remapping_endcap_aclus).ratemap))\n",
    "significant_distant_remapping_earth_movers_distance = earth_movers_distance(get_curve_fn(long_pf1D.get_by_id(significant_distant_remapping_endcap_aclus).ratemap), get_curve_fn(short_pf1D.get_by_id(significant_distant_remapping_endcap_aclus).ratemap))\n",
    "disappearing_endcap_earth_movers_distance = earth_movers_distance(get_curve_fn(long_pf1D.get_by_id(disappearing_endcap_aclus).ratemap), get_curve_fn(short_pf1D.get_by_id(disappearing_endcap_aclus).ratemap))\n",
    "\n",
    "\n",
    "# earth_movers_distance = cdist(np.atleast_2d(np.squeeze(long_1DMaps[i,:])), np.atleast_2d(np.squeeze(short_1DMaps[i,:])), 'jensenshannon')[0]\n",
    "# trivially_remapping_endcap_earth_movers_distance\n",
    "# earth_movers_distance.shape\n",
    "\n",
    "trivially_remapping_endcap_earth_movers_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c0aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_distant_remapping_earth_movers_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65765e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(trivially_remapping_endcap_earth_movers_distance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d139cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(significant_distant_remapping_earth_movers_distance)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcb50e6",
   "metadata": {},
   "source": [
    "## 2023-09-20 - Plot the significantly remapping cells using the lower-level `plot_short_v_long_pf1D_comparison` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_short_v_long_pf1D_comparison\n",
    "from neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines, add_track_shapes\n",
    "from neuropy.plotting.ratemaps import plot_ratemap_1D\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import LongShortDisplayConfigManager\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "graphics_output_dict = {}\n",
    "active_context: IdentifyingContext = curr_active_pipeline.get_session_context()\n",
    "\n",
    "long_short_display_config_manager = LongShortDisplayConfigManager()\n",
    "long_epoch_config = long_short_display_config_manager.long_epoch_config.as_pyqtgraph_kwargs()\n",
    "short_epoch_config = long_short_display_config_manager.short_epoch_config.as_pyqtgraph_kwargs()\n",
    "\n",
    "long_epoch_matplotlib_config = long_short_display_config_manager.long_epoch_config.as_matplotlib_kwargs()\n",
    "short_epoch_matplotlib_config = long_short_display_config_manager.short_epoch_config.as_matplotlib_kwargs()\n",
    "\n",
    "shared_kwargs = dict(pad=1, cmap='hsv', active_context=curr_active_pipeline.get_session_context(), plot_zero_baselines=True, skip_figure_titles=True, use_flexitext_titles=True, flat_stack_mode=False)\n",
    "top_level_shared_kwargs = dict(should_plot_vertical_track_bounds_lines=True, sortby='peak_long')\n",
    "# top_level_shared_kwargs = dict(should_plot_vertical_track_bounds_lines=False, should_plot_linear_track_shapes=True) # Renders the linear track shape on the maze. Assumes `flat_stack_mode=True`\n",
    "\n",
    "\n",
    "# # flat_stack_mode: all placefields are stacked up (z-wise) on top of each other on a single axis with no offsets:\n",
    "# shared_kwargs = dict(pad=1, active_context=curr_active_pipeline.get_session_context(), plot_zero_baselines=True, skip_figure_titles=True, use_flexitext_titles=True, flat_stack_mode=True)\n",
    "# top_level_shared_kwargs = dict(should_plot_vertical_track_bounds_lines=False, should_plot_linear_track_shapes=True) # Renders the linear track shape on the maze. Assumes `flat_stack_mode=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec159e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-09-21 - Plot All\n",
    "graphics_output_dict = graphics_output_dict | fig_remapping_cells(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e180fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'hsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c748dd",
   "metadata": {
    "tags": [
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "long_single_cell_pfmap_processing_fn = None\n",
    "short_single_cell_pfmap_processing_fn = None\n",
    "sort_idx = None\n",
    "# sort_idx = sort_ind\n",
    "# sort_idx = sort_indicies\n",
    "# sort_idx = new_all_aclus_sort_indicies\n",
    "# sort_idx = np.flip( np.arange(len(shared_aclus_only_neuron_IDs)))\n",
    "sort_idx = 'peak_long'\n",
    "# sort_idx = 'bad'\n",
    "\n",
    "pf1d_compare_graphics = curr_active_pipeline.display('_display_short_long_pf1D_comparison', curr_active_pipeline.get_session_context(), single_figure=True, debug_print=False, fignum='Short v Long pf1D Comparison',\n",
    "\t\t\t\t\t\t\t\tlong_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': long_single_cell_pfmap_processing_fn},\n",
    "\t\t\t\t\t\t\t\tshort_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': short_single_cell_pfmap_processing_fn, 'curve_hatch_style': {'hatch':'///', 'edgecolor':'k'}},\n",
    "\t\t\t\t\t\t\t\tshared_kwargs={'cmap': 'hsv'},\n",
    "\t\t\t\t\t\t\t\tincluded_any_context_neuron_ids=shared_aclus_only_neuron_IDs,\n",
    "\t\t\t\t\t\t\t\tsave_figure=False,\n",
    "\t\t\t\t\t\t\t\tdefer_render=False\n",
    "\t\t\t\t\t\t\t\t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e4945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_aclus = [7, 38] # 95 was BAAAAD\n",
    "# # flat_stack_mode: all placefields are stacked up (z-wise) on top of each other on a single axis with no offsets:\n",
    "example_shared_kwargs = dict(pad=1, active_context=curr_active_pipeline.get_session_context(), plot_zero_baselines=True, skip_figure_titles=True, use_flexitext_titles=True, flat_stack_mode=False)\n",
    "example_top_level_shared_kwargs = dict(should_plot_vertical_track_bounds_lines=True, should_plot_linear_track_shapes=True) # Renders the linear track shape on the maze. Assumes `flat_stack_mode=True`\n",
    "\n",
    "# (fig_long_pf_1D, ax_long_pf_1D, long_sort_ind, long_neurons_colors_array), (fig_short_pf_1D, ax_short_pf_1D, short_sort_ind, short_neurons_colors_array) = plot_short_v_long_pf1D_comparison(long_results, short_results, example_aclus, reuse_axs_tuple=None, single_figure=True, title_string=\"Example Non-Neighbor Preserving Remapping Cells\", subtitle_string=f\"2 Example Cells {example_aclus}\", shared_kwargs=example_shared_kwargs, **example_top_level_shared_kwargs)\n",
    "_out = curr_active_pipeline.display('_display_short_long_pf1D_comparison', curr_active_pipeline.get_session_context(), included_any_context_neuron_ids=shared_aclus_only_neuron_IDs, reuse_axs_tuple=None, single_figure=True, title_string=\"Shared PFs Only Cells\", subtitle_string=f\"{len(shared_aclus_only_neuron_IDs)} Cells\", shared_kwargs=example_shared_kwargs, **example_top_level_shared_kwargs)\n",
    "\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c851fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bimodal_exclude_aclus = [5, 14, 46, 61, 66, 86, 88, 95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract long/short plotting data from the figure for use in other plots:\n",
    "included_any_context_neuron_ids = pf1d_compare_graphics.plot_data['included_any_context_neuron_ids']\n",
    "long_sort_ind, short_sort_ind = pf1d_compare_graphics.plot_data['sort_indicies']\n",
    "long_neurons_colors_array, short_neurons_colors_array = pf1d_compare_graphics.plot_data['colors']\n",
    "\n",
    "display(long_sort_ind)\n",
    "display(short_sort_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d8a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron_colors: .shape: (4, n_neurons)\n",
    "# long_neurons_colors_array.shape\n",
    "\n",
    "## Only get for the relevant cells:\n",
    "\n",
    "\t\n",
    "is_included_in_raster = np.isin(included_any_context_neuron_ids, active_raster_plot.neuron_ids)\n",
    "neuron_qcolors_list = DataSeriesColorHelpers.colors_NDarray_to_qColorsList(long_neurons_colors_array[:, is_included_in_raster])\n",
    "neuron_plotting_configs_dict: Dict = DataSeriesColorHelpers.build_cell_display_configs(active_raster_plot.neuron_ids, neuron_qcolors_list)\n",
    "neuron_plotting_configs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087933f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_sorted_aclus = included_any_context_neuron_ids[long_sort_ind]\n",
    "short_sorted_aclus = included_any_context_neuron_ids[short_sort_ind]\n",
    "short_sorted_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb370fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "long_sort_ind\n",
    "short_sort_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19236393",
   "metadata": {},
   "source": [
    "# SpikeRaster sorting by pf1D pf peaks on the long or the short track:\n",
    "2023-10-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3283db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import determine_long_short_pf1D_indicies_sort_by_peak\n",
    "\n",
    "## Get 2D or 3D Raster from spike_raster_window\n",
    "active_raster_plot = spike_raster_window.spike_raster_plt_2d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "if active_raster_plot is None:\n",
    "\tactive_raster_plot = spike_raster_window.spike_raster_plt_3d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "\tassert active_raster_plot is not None\n",
    "\n",
    "# Sort the neurons by their peak on the long track AND on the short track:\n",
    "included_unit_neuron_IDs = active_raster_plot.neuron_ids\n",
    "new_active_2d_plotter_aclus_LONG_PEAK_sort_indicies = determine_long_short_pf1D_indicies_sort_by_peak(curr_active_pipeline=curr_active_pipeline, curr_any_context_neurons=included_unit_neuron_IDs, sortby=[\"long_pf_peak_x\", \"short_pf_peak_x\", 'neuron_IDX']) # get the neuron_ids to be sorted from the raster plot\n",
    "new_active_2d_plotter_aclus_SHORT_PEAK_sort_indicies = determine_long_short_pf1D_indicies_sort_by_peak(curr_active_pipeline=curr_active_pipeline, curr_any_context_neurons=included_unit_neuron_IDs, sortby=[\"short_pf_peak_x\", \"long_pf_peak_x\", 'neuron_IDX']) # get the neuron_ids to be sorted from the raster plot\n",
    "\n",
    "display(new_active_2d_plotter_aclus_LONG_PEAK_sort_indicies)\n",
    "display(new_active_2d_plotter_aclus_SHORT_PEAK_sort_indicies)\n",
    "# new_active_2d_plotter_aclus_sort_indicies # array([14,  3,  1,  2,  5,  9,  0, 20, 16, 24,  7, 19, 17, 21, 11, 10, 13, 12,  4, 18, 25,  6, 15, 23, 22,  8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbbd475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the sort order on the Spike2DPlotter to align with the LONG TRACK pf1D field peaks:\n",
    "active_raster_plot.unit_sort_order = new_active_2d_plotter_aclus_LONG_PEAK_sort_indicies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7349d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the sort order on the Spike2DPlotter to align with the SHORT TRACK pf1D field peaks:\n",
    "active_raster_plot.unit_sort_order = new_active_2d_plotter_aclus_SHORT_PEAK_sort_indicies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb64f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the original sort order of Spike2DPlotter:\n",
    "original_neuron_plotter_aclus_sort_index = np.arange(len(new_active_2d_plotter_aclus_LONG_PEAK_sort_indicies))\n",
    "active_raster_plot.unit_sort_order = original_neuron_plotter_aclus_sort_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e3310e",
   "metadata": {},
   "source": [
    "# SpikeRasterND color updating\n",
    "2023-10-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ff6e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.update_neurons_color_data(neuron_plotting_configs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the raster colors from the sidebar config widget:\n",
    "neuron_widget_container = spike_raster_window.neuron_visual_config_widget_container\n",
    "spike_raster_window.update_neurons_color_data(neuron_widget_container.get_config_map_from_child_widgets())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84796538",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_neurons_colors_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d917a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "included_any_context_neuron_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfab342",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle('Translation Remapping Cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_surprise_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a009cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.active_sess_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffe8d9f",
   "metadata": {},
   "source": [
    "## pre 2023-10-11 - Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e11c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_example_nontopo_remap\n",
    "\n",
    "graphics_output_dict = fig_example_nontopo_remap(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be59d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e3b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5('output/2023_09_26_new_pipeline_test.h5')\n",
    "# ERROR: encountered exception !! 'InstantaneousSpikeRateGroupsComputation' object has no attribute 'all_incl_endPlatforms_InstSpikeRateTrends_df' ::::: (<class 'AttributeError'>, AttributeError(\"'InstantaneousSpikeRateGroupsComputation' object has no attribute 'all_incl_endPlatforms_InstSpikeRateTrends_df'\"), <traceback object at 0x000001E5A3D3D040>) while trying to build the session HDF output.\n",
    "# AttributeError: 'SpikeRateTrends' object has no attribute 'included_neuron_ids'\n",
    "# _neuron_replay_stats_df - TypeError: Cannot serialize the column [track_membership] because its data contents are not [string] but [mixed] object dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa0ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ef3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_short_long_pf1D_scalar_overlap_comparison', active_identifying_session_ctx, save_figure=False)\n",
    "# fig, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['axs'], graphics_output_dict['plot_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e146d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _display_long_short_expected_v_observed_firing_rate\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_long_short_expected_v_observed_firing_rate', curr_active_pipeline.sess.get_context(), included_neuron_IDs=significant_distant_remapping_endcap_aclus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6bc6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_temp_force_recompute=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recompute 'long_short_fr_indicies_analyses'\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_computations\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "# _temp_force_recompute=True\n",
    "_temp_force_recompute=False\n",
    "# extended_computations_include_includelist = ['_perform_time_dependent_placefield_computation', 'long_short_fr_indicies_analyses', 'pf_dt_sequential_surprise', 'short_long_pf_overlap_analyses'] # do only specifiedl\n",
    "extended_computations_include_includelist = ['jonathan_firing_rate_analysis', 'short_long_pf_overlap_analyses']\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=_temp_force_recompute, debug_print=False)\n",
    "newly_computed_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed12881",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.rdf.rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab18fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.irdf.irdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a269239",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ce6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_long_short_fr_indicies_analysis_bak = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "\n",
    "curr_long_short_fr_indicies_analysis = curr_active_pipeline.global_computation_results.computed_data.pop('long_short_fr_indicies_analysis')\n",
    "\n",
    "print(list(curr_long_short_fr_indicies_analysis.keys())) # ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays', 'long_non_replays', 'short_non_replays', 'global_non_replays', 'long_mean_non_replays_frs', 'short_mean_non_replays_frs', 'long_mean_non_replays_all_frs', 'short_mean_non_replays_all_frs', 'non_replays_frs_index', 'long_mean_non_replays_all_inst_frs', 'short_mean_non_replays_all_inst_frs', 'non_replays_inst_frs_index', 'active_context']\n",
    "\n",
    "print_keys_if_possible('curr_long_short_fr_indicies_analysis', curr_long_short_fr_indicies_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6411650",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320f02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a621ba9",
   "metadata": {},
   "source": [
    "# 2023-09-12 - Assemble all neuron-level properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.neuron_identities import NeuronIdentityDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import build_merged_neuron_firing_rate_indicies\n",
    "\n",
    "joined_neruon_fri_df = build_merged_neuron_firing_rate_indicies(curr_active_pipeline, enable_display_intermediate_results=False)\n",
    "joined_neruon_fri_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_neruon_fri_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c78c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(joined_neruon_fri_df.columns)) # ['aclu', 'lsfria_laps_frs_index', 'lsfria_laps_inst_frs_index', 'lsfria_replays_frs_index', 'lsfria_replays_inst_frs_index', 'lsfria_non_replays_frs_index', 'lsfria_non_replays_inst_frs_index', 'jfra_long_pf_peak_x', 'jfra_has_long_pf', 'jfra_short_pf_peak_x', 'jfra_has_short_pf', 'jfra_has_na', 'jfra_track_membership', 'jfra_long_non_replay_mean', 'jfra_short_non_replay_mean', 'jfra_non_replay_diff', 'jfra_long_replay_mean', 'jfra_short_replay_mean', 'jfra_replay_diff', 'jfra_long_mean', 'jfra_short_mean', 'jfra_mean_diff', 'jfra_neuron_IDX', 'jfra_num_replays', 'jfra_long_num_replays', 'jfra_short_num_replays', 'jfra_neuron_type', 'lspd_laps', 'lspd_replays', 'lspd_skew', 'lspd_max_axis_distance_from_center', 'lspd_distance_from_center', 'lspd_has_considerable_remapping']\n",
    "\n",
    "recast_columns=['track_membership','neuron_type']\n",
    "\n",
    "drop_columns=['jfra_aclu']\n",
    "joined_neuron_fri_df.drop(columns=drop_columns)\n",
    "['aclu', 'laps_frs_index', 'replays_frs_index', 'non_replays_frs_index', 'long_pf_peak_x', 'has_long_pf', 'short_pf_peak_x', 'has_short_pf', 'has_na', 'track_membership', 'long_non_replay_mean', 'short_non_replay_mean', 'non_replay_diff', 'long_replay_mean', 'short_replay_mean', 'replay_diff', 'long_mean', 'short_mean', 'mean_diff', 'neuron_IDX', 'num_replays', 'long_num_replays', 'short_num_replays', 'neuron_type', 'jfra_aclu', 'custom_frs_index', 'is_rate_extrema', 'is_refined_exclusive', 'is_refined_LxC', 'is_refined_SxC', 'laps', 'replays', 'skew', 'max_axis_distance_from_center', 'distance_from_center', 'has_considerable_remapping', 'session_uid', 'neuron_uid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bd0afa",
   "metadata": {},
   "source": [
    "# Computing consolidated `long_short_fr_indicies_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be486bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'long_short_fr_indicies_analysis'\n",
    "curr_long_short_fr_indicies_analysis = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "_curr_aclus = list(curr_long_short_fr_indicies_analysis['laps_frs_index'].keys()) # extract one set of keys for the aclus\n",
    "_curr_frs_indicies_dict = {k:v.values() for k,v in curr_long_short_fr_indicies_analysis.items() if k in ['laps_frs_index', 'laps_inst_frs_index', 'replays_frs_index', 'replays_inst_frs_index', 'non_replays_frs_index', 'non_replays_inst_frs_index']} # extract the values\n",
    "long_short_fr_indicies_df = pd.DataFrame(_curr_frs_indicies_dict, index=_curr_aclus)\n",
    "long_short_fr_indicies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_fr_indicies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca0c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d40c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_active_pipeline.perform_specific_computation('long_short_fr_indicies_analyses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62734a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = long_short_fr_indicies_df.plot.scatter(x='non_replays_inst_frs_index' , y='replays_inst_frs_index', title='Replays v. Non-replay Firing Rate Index Comparison')\n",
    "# long_short_fr_indicies_df.plot.scatter(x='laps_inst_frs_index' , y='replays_inst_frs_index', title='Replays v. Laps Firing Rate Index Comparison', ax=ax)\n",
    "\n",
    "ax = long_short_fr_indicies_df.plot.scatter(x='non_replays_frs_index' , y='replays_frs_index', title='Replays v. Non-replay Firing Rate Index Comparison')\n",
    "long_short_fr_indicies_df.plot.scatter(x='laps_frs_index' , y='replays_frs_index', title='Replays v. Laps Firing Rate Index Comparison', ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8f1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# scatter_matrix(long_short_fr_indicies_df, figsize=(10, 10))\n",
    "scatter_matrix(joined_neruon_fri_df, figsize=(10, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d02820",
   "metadata": {},
   "source": [
    "# 2023-10-11 - Assigning Replays after delta to either the Long or Short track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import TrackAssignmentState, TrackAssignmentDecision, AssigningEpochs\n",
    "\n",
    "fig, ax, assigning_epochs_obj = AssigningEpochs.main_plot_iterative_epoch_track_assignments(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assigning_epochs_obj.unassigned_epochs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assigning_epochs_obj.filter_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_assignable_by_long_exclusive_cells = np.logical_and(assigning_epochs_obj.filter_epochs_df['has_LONG_exclusive_aclu'], np.logical_not(assigning_epochs_obj.filter_epochs_df['has_SHORT_exclusive_aclu'])) # has long exclusive and no short-exclusive cells\n",
    "np.sum(is_assignable_by_long_exclusive_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0a7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_assignable_by_short_exclusive_cells = np.logical_and(assigning_epochs_obj.filter_epochs_df['has_SHORT_exclusive_aclu'], np.logical_not(assigning_epochs_obj.filter_epochs_df['has_LONG_exclusive_aclu'])) # has short exclusive and no long-exclusive cells\n",
    "np.sum(is_assignable_by_short_exclusive_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b07f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assigning_epochs_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20da51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Get the active_unique_aclus during the epoch and score them based on their rate-remapping value:\n",
    "assigning_epochs_obj.filter_epochs_df.active_unique_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74977100",
   "metadata": {},
   "outputs": [],
   "source": [
    "assigning_epochs_obj.unassigned_epochs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a9146",
   "metadata": {},
   "source": [
    "## Plots the RateRemappingFiringRateIndex Number Line Figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Extract rr_* variables from rate_remapping_df\n",
    "# rr_aclus = rate_remapping_df.index.values\n",
    "# rr_laps, rr_replays, rr_skew, rr_neuron_type = [rate_remapping_df[n].values for n in ['laps', 'replays', 'skew', 'neuron_type']]\n",
    "\n",
    "\n",
    "## Extract rr_* variables from joined_neruon_fri_df\n",
    "rr_aclus = joined_neruon_fri_df.index.values\n",
    "rr_laps, rr_replays, rr_skew, rr_neuron_type = [joined_neruon_fri_df[n].values for n in ['lspd_laps', 'lspd_replays', 'lspd_skew', 'jfra_neuron_type']]\n",
    "\n",
    "## Display:\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_rr_aclu\n",
    "n_debug_limit = 10\n",
    "fig, axs, sort_indicies = plot_rr_aclu([str(aclu) for aclu in rr_aclus[:n_debug_limit]], rr_laps=rr_laps[:n_debug_limit], rr_replays=rr_replays[:n_debug_limit], rr_neuron_types=rr_neuron_type[:n_debug_limit])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad336e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fri_index_dicts_list = [dict(x=rr_laps, marker=r'$\\theta$', markersize=10, color='black', label='rr_laps'),\n",
    "\tdict(x=rr_replays, marker='o', markersize=10, fillstyle='none', color='black', label='rr_replays'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc67e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Display Paginated multi-plot\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_rr_aclu\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import RateRemappingPaginatedFigureController\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context()\n",
    "_out_rr_pagination_controller = RateRemappingPaginatedFigureController.init_from_rr_data(rr_aclus, rr_laps, rr_replays, rr_neuron_type, max_subplots_per_page=30, a_name='TestRateRemappingPaginatedFigureController', active_context=active_identifying_session_ctx)\n",
    "a_paginator = _out_rr_pagination_controller.plots_data.paginator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6768b355",
   "metadata": {},
   "source": [
    "# 2023-09-28 - InstFrRate-based classification of LxC and SxC\n",
    "2023-09-28 10:39am: We looked at the results and determined that it was much worse than the placefield critiera I had previously. This analysis should be used as a secondary refinement for the existing placefield-based LxC/SxC exclusion critiera. It includes information about non-lap endcap activity that the other analysis omits. Can be used with a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the selected LxC/SxC cells cells on the PhoJonathan plots\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "refined_LxC_aclus = long_exclusive.get_refined_track_exclusive_aclus()\n",
    "print(f'refined_LxC_aclus: {refined_LxC_aclus}')\n",
    "if len(refined_LxC_aclus):\n",
    "\t_out_LxC = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', n_max_plot_rows=10, save_figure=False, included_unit_neuron_IDs=refined_LxC_aclus) # , included_unit_neuron_IDs=[4, 58]\n",
    "\n",
    "refined_SxC_aclus = short_exclusive.get_refined_track_exclusive_aclus()\n",
    "print(f'refined_SxC_aclus: {refined_SxC_aclus}')\n",
    "if len(refined_SxC_aclus):\n",
    "\t_out_SxC = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', n_max_plot_rows=10, save_figure=False, included_unit_neuron_IDs=refined_SxC_aclus) # , included_unit_neuron_IDs=[4, 58]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a08e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_df = pd.read_csv(Path(r'W:\\Data\\neuron_replay_stats_table_2023-09-29-GL.csv'))\n",
    "loaded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dbed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data_root_parent_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionTables\n",
    " \n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.load_all_combined_tables(override_output_parent_path=global_data_root_parent_path, output_path_suffix=f'_{BATCH_DATE_TO_USE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6aacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import _fr_index\n",
    "instantaneous_time_bin_size_seconds = 0.1\n",
    "owning_pipeline_reference = curr_active_pipeline\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(owning_pipeline_reference.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name)) for an_epoch_name in [long_epoch_name, short_epoch_name]]\n",
    "\n",
    "# non_running_periods = Epoch.from_PortionInterval(owning_pipeline_reference.sess.laps.as_epoch_obj().to_PortionInterval().complement())\n",
    "non_replay_periods: Epoch = Epoch(Epoch.from_PortionInterval(owning_pipeline_reference.sess.replay.epochs.to_PortionInterval().complement()).time_slice(t_start=long_epoch_obj.t_start, t_stop=short_epoch_obj.t_stop).to_dataframe()[:-1]) #[:-1] # any period except the replay ones, drop the infinite last entry\n",
    "long_only_non_replay_periods: Epoch  = non_replay_periods.time_slice(t_start=long_epoch_obj.t_start, t_stop=long_epoch_obj.t_stop) # any period except the replay ones\n",
    "short_only_non_replay_periods: Epoch  = non_replay_periods.time_slice(t_start=short_epoch_obj.t_start, t_stop=short_epoch_obj.t_stop) # any period except the replay ones\n",
    "\n",
    "# ~20sec computation\n",
    "long_custom_InstSpikeRateTrends: SpikeRateTrends = SpikeRateTrends.init_from_spikes_and_epochs(spikes_df=deepcopy(owning_pipeline_reference.sess.spikes_df),\n",
    "                                                                                        filter_epochs=long_only_non_replay_periods,\n",
    "                                                                                        #    included_neuron_ids=long_exclusive.track_exclusive_aclus,\n",
    "                                                                                        instantaneous_time_bin_size_seconds=instantaneous_time_bin_size_seconds)\n",
    "\n",
    "short_custom_InstSpikeRateTrends: SpikeRateTrends = SpikeRateTrends.init_from_spikes_and_epochs(spikes_df=deepcopy(owning_pipeline_reference.sess.spikes_df),\n",
    "                                                                                        filter_epochs=short_only_non_replay_periods,\n",
    "                                                                                        #    included_neuron_ids=long_exclusive.track_exclusive_aclus,\n",
    "                                                                                        instantaneous_time_bin_size_seconds=instantaneous_time_bin_size_seconds)\n",
    "\n",
    "# # Note custom_InstSpikeRateTrends is global, not really needed:\n",
    "# global_custom_InstSpikeRateTrends: SpikeRateTrends = SpikeRateTrends.init_from_spikes_and_epochs(spikes_df=deepcopy(owning_pipeline_reference.sess.spikes_df),\n",
    "#                                                                                            filter_epochs=non_replay_periods,\n",
    "#                                                                                         #    included_neuron_ids=long_exclusive.track_exclusive_aclus,\n",
    "#                                                                                            instantaneous_time_bin_size_seconds=instantaneous_time_bin_size_seconds)\n",
    "\n",
    "## Determine the included percentiles for `joined_neruon_fri_df`\n",
    "custom_InstSpikeRateTrends_df = pd.DataFrame({'aclu': long_custom_InstSpikeRateTrends.included_neuron_ids, 'long_inst_fr': long_custom_InstSpikeRateTrends.cell_agg_inst_fr_list, 'short_inst_fr': short_custom_InstSpikeRateTrends.cell_agg_inst_fr_list}) #\n",
    "# custom_InstSpikeRateTrends_df['global_inst_fr'] = global_custom_InstSpikeRateTrends.cell_agg_inst_fr_list\n",
    "\n",
    "# Compute the single-dimensional firing rate index for the custom epochs and add it as a column to the dataframe:\n",
    "custom_InstSpikeRateTrends_df['custom_frs_index'] = _fr_index(long_fr=long_custom_InstSpikeRateTrends.cell_agg_inst_fr_list, short_fr=short_custom_InstSpikeRateTrends.cell_agg_inst_fr_list)\n",
    "\n",
    "# # Calculate 10th and 90th percentiles\n",
    "# lower_bound = custom_InstSpikeRateTrends_df['custom_frs_index'].quantile(0.10)\n",
    "# upper_bound = custom_InstSpikeRateTrends_df['custom_frs_index'].quantile(0.90)\n",
    "\n",
    "# # Filter rows\n",
    "# bottom_10_percent = custom_InstSpikeRateTrends_df[custom_InstSpikeRateTrends_df['custom_frs_index'] <= lower_bound]\n",
    "# top_10_percent = custom_InstSpikeRateTrends_df[custom_InstSpikeRateTrends_df['custom_frs_index'] >= upper_bound]\n",
    "\n",
    "# # Extract the aclus from these rows:\n",
    "# LxC_10_percent_aclus = top_10_percent.aclu.to_numpy()\n",
    "# SxC_10_percent_aclus = bottom_10_percent.aclu.to_numpy()\n",
    "\n",
    "# print(f'LxC_10_percent_aclus: {LxC_10_percent_aclus}')\n",
    "# print(f'SxC_10_percent_aclus: {SxC_10_percent_aclus}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Really want to penalize for any firing on the opposite track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a867b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wanna look at the suprise metrics again please.\n",
    "\n",
    "# can align each of the sessions (across days) to the track transition point (the \"Delta\") as the zero.\n",
    "\n",
    "# print_keys_if_possible(\"global_computation_results\", curr_active_pipeline.global_computation_results, max_depth=2)\n",
    "\n",
    "# computed_data: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "# \t\t│   ├── jonathan_firing_rate_analysis: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "# \t\t│   ├── long_short_fr_indicies_analysis: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "# \t\t│   ├── long_short_leave_one_out_decoding_analysis: pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.LeaveOneOutDecodingAnalysis\n",
    "# \t\t│   ├── long_short_post_decoding: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "\n",
    "\n",
    "print_keys_if_possible(\"global_computation_results\", curr_active_pipeline.global_computation_results.computed_data, max_depth=3)\n",
    "\n",
    "# jonathan_firing_rate_analysis_result.rdf\n",
    "\n",
    "# long_short_leave_one_out_decoding_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d33a7c",
   "metadata": {
    "tags": [
     "NOW",
     "load",
     "plot"
    ]
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pyphocorehelpers.indexing_helpers import partition, safe_pandas_get_group\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor, AcrossSessionsVisualizations\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import SingleBarResult\n",
    "\n",
    "common_file_path = Path('output/active_across_session_scatter_plot_results.h5')\n",
    "print(f'common_file_path: {common_file_path}')\n",
    "\n",
    "# InstantaneousSpikeRateGroupsComputation, : pd.DataFrame\n",
    "_shell_obj, loaded_result_df = InstantaneousFiringRatesDataframeAccessor.load_and_prepare_for_plot(common_file_path)\n",
    "# Perform the actual plotting:\n",
    "AcrossSessionsVisualizations.across_sessions_bar_graphs(_shell_obj, num_sessions=13, save_figure=False, enable_tiny_point_labels=False, enable_hover_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb580a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "maximum_timedelta: timedelta = timedelta(1, 0, 0) # 1 Day maximum time\n",
    "delta_since_last_compute: timedelta = curr_active_pipeline.get_time_since_last_computation()\n",
    "print(f'delta_since_last_compute: {delta_since_last_compute}')\n",
    "needs_recompute: bool = delta_since_last_compute > maximum_timedelta\n",
    "print(f'\\tneeds_recompute: {needs_recompute}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624326b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Serialization of preprocessing parameters test\n",
    "file_path = 'output/preprocessing_parameters.h5'\n",
    "\n",
    "with h5py.File(file_path, \"w\") as f:\n",
    "\tpreprocessing_group = f.create_group(\"preprocessing_parameters\")\n",
    "\n",
    "\t# Serialize epoch_estimation_parameters\n",
    "\tepoch_estimation_group = preprocessing_group.create_group(\"epoch_estimation_parameters\")\n",
    "\n",
    "\tlaps_group = epoch_estimation_group.create_group(\"laps\")\n",
    "\tlaps_group.attrs[\"N\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"laps\"][\"N\"]\n",
    "\tlaps_group.attrs[\"should_backup_extant_laps_obj\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"laps\"][\"should_backup_extant_laps_obj\"]\n",
    "\n",
    "\tPBEs_group = epoch_estimation_group.create_group(\"PBEs\")\n",
    "\tPBEs_group.attrs[\"thresh\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"thresh\"]\n",
    "\tPBEs_group.attrs[\"min_dur\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"min_dur\"]\n",
    "\tPBEs_group.attrs[\"merge_dur\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"merge_dur\"]\n",
    "\tPBEs_group.attrs[\"max_dur\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"max_dur\"]\n",
    "\n",
    "\treplays_group = epoch_estimation_group.create_group(\"replays\")\n",
    "\treplay_data = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"replays\"]\n",
    "\t# replay_dataframe = pd.DataFrame(replay_data)\n",
    "\t# replay_data.to_hdf(f, \"/preprocessing_parameters/epoch_estimation_parameters/replays\")\n",
    "\t## TODO: add the data here using Epoch's .to_hdf\n",
    "\t\n",
    "\t# Check for \"None\" values before setting attributes\n",
    "\tdef check_and_set(key, value):\n",
    "\t\tif value is not None:\n",
    "\t\t\treplays_group.attrs[key] = value\n",
    "\n",
    "\t# Set attributes if not \"None\", otherwise skip writing\n",
    "\tcheck_and_set(\"min_epoch_included_duration\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"min_epoch_included_duration\"))\n",
    "\tcheck_and_set(\"max_epoch_included_duration\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"max_epoch_included_duration\"))\n",
    "\tcheck_and_set(\"maximum_speed_thresh\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"maximum_speed_thresh\"))\n",
    "\tcheck_and_set(\"min_inclusion_fr_active_thresh\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"min_inclusion_fr_active_thresh\"))\n",
    "\tcheck_and_set(\"min_num_unique_aclu_inclusions\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"min_num_unique_aclu_inclusions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc30a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_default_neptune_plots = False\n",
    "# enable_default_neptune_plots = True\n",
    "\n",
    "## To file only:\n",
    "with matplotlib_file_only():\n",
    "\t# Perform non-interactive Matplotlib operations with 'AGG' backend\n",
    "\tmain_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=enable_default_neptune_plots, save_figures_only=True, save_figure=True)\n",
    "\n",
    "## Clear the Programmatically open figures:\n",
    "plt.close('all') # this takes care of the matplotlib-backed figures.\n",
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44783dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_out_figures = main_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=False, save_figures_only=False, save_figure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943b8f18",
   "metadata": {},
   "source": [
    "# Common Display Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef70fb2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": [
     "plot_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# configure backend here\n",
    "matplotlib.use('Qt5Agg')\n",
    "# backend_qt5agg\n",
    "# %matplotlib qt5\n",
    "# %matplotlib qt\n",
    "# matplotlib.use('AGG') # non-interactive backend ## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# mpl.rcParams['toolbar'] = 'None' # disable toolbars\n",
    "\n",
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa82d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-11-06 - Show em the PLOWT. Indicate the best item for each epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fbf214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "# configure backend here\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "import pylustrator # call `pylustrator.start()` before creating your first figure in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530208a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pylustrator.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8eddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b490781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot The laps:\n",
    "from neuropy.utils.matplotlib_helpers import plot_position_curves_figure\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "# pylustrator.start()\n",
    "fig, out_axes_list = plot_laps_2d(global_session, legacy_plotting_mode=False, include_velocity=False, include_accel=False, figsize=(24, 10))\n",
    "out_axes_list[0].set_title('Estimated Laps')\n",
    "fig.canvas.manager.set_window_title('Estimated Laps')\n",
    "ax = out_axes_list[0]\n",
    "# ax.set_xlim((1036.242685185441, 1441.769668184419))\n",
    "\n",
    "# Hide y-axis ticklabels\n",
    "plt.tick_params(axis='y', which='both', labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.gcf()\n",
    "# ax = fig.axes[0]\n",
    "# ax\n",
    "# ax.get_xlim()\n",
    "\n",
    "\n",
    "# laps_example_region_xlims = (1036.242685185441, 1441.769668184419)\n",
    "\n",
    "fig, out_axes_list = plot_position_curves_figure(global_session.position, include_velocity=False, include_accel=False, figsize=(24, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc97408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import plot_overlapping_epoch_analysis_diagnoser\n",
    "\n",
    "\n",
    "fig, out_axes_list = plot_overlapping_epoch_analysis_diagnoser(curr_active_pipeline.sess.position, curr_active_pipeline.sess.laps.as_epoch_obj())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e144a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.position import Position\n",
    "\n",
    "position: Position = curr_active_pipeline.sess.position\n",
    "position.compute_higher_order_derivatives()\n",
    "position.compute_smoothed_position_info()\n",
    "\n",
    "type(position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0161ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_active_pipeline.sess.position.compute_higher_order_derivatives()\n",
    "curr_active_pipeline.sess.position.compute_smoothed_position_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c975e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b11e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out1 = curr_active_pipeline.display('_display_long_short_laps', include_velocity=False, include_accel=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c59882",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_decoder_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737539d",
   "metadata": {},
   "source": [
    "# 2023-09-07 - Track Graphics Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a866b1b",
   "metadata": {
    "tags": [
     "ACTIVE",
     "track_graphics"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphocorehelpers.geometry_helpers import BoundsRect, point_tuple_mid_point, map_value\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines, add_track_shapes, test_LinearTrackDimensions_2D_pyqtgraph\n",
    "from neuropy.utils.mathutil import contiguous_regions, threshPeriods, compute_grid_bin_bounds, map_value\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import test_LinearTrackDimensions_2D_Matplotlib\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackInstance\n",
    "\n",
    "grid_bin_bounds = BoundsRect.init_from_grid_bin_bounds(global_pf2D.config.grid_bin_bounds)\n",
    "display(grid_bin_bounds)\n",
    "\n",
    "# long_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(grid_bin_bounds)\n",
    "# short_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(grid_bin_bounds)\n",
    "\n",
    "long_track_dims = LinearTrackDimensions(track_length=170.0)\n",
    "short_track_dims = LinearTrackDimensions(track_length=100.0)\n",
    "\n",
    "common_1D_platform_height = 0.25\n",
    "common_1D_track_height = 0.1\n",
    "long_track_dims.minor_axis_platform_side_width = common_1D_platform_height\n",
    "long_track_dims.track_width = common_1D_track_height # (short_track_dims.minor_axis_platform_side_width\n",
    "\n",
    "short_track_dims.minor_axis_platform_side_width = common_1D_platform_height\n",
    "short_track_dims.track_width = common_1D_track_height # (short_track_dims.minor_axis_platform_side_width\n",
    "\n",
    "# instances:\n",
    "long_track = LinearTrackInstance(long_track_dims, grid_bin_bounds=grid_bin_bounds)\n",
    "short_track = LinearTrackInstance(short_track_dims, grid_bin_bounds=grid_bin_bounds)\n",
    "\n",
    "print(long_track_dims)\n",
    "print(short_track_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c12b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "# global_pf1D_dt.config.grid_bin_bounds\n",
    "\n",
    "\n",
    "def napari_add_grid_bin_bounds_rect(viewer: napari.viewer.Viewer, grid_bin_bounds):\n",
    "\t\"\"\" adds the animal's position as a track and a point layer to the napari viewer.\n",
    "\n",
    "\n",
    "\tUsage:\n",
    "\n",
    "\tfrom pyphoplacecellanalysis.GUI.Napari.napari_helpers import napari_add_animal_position\n",
    "\tnapari_add_animal_position(viewer=viewer, position_df=global_pf1D_dt.all_time_filtered_pos_df[['t','x','binned_x']], time_intervals)\n",
    "\n",
    "\n",
    "\t\"\"\"\n",
    "\t# rect = np.array([[0, 0], [3, 1]])\n",
    "\tgrid_bin_bounds_rect = grid_bin_bounds\n",
    "\tviewer.add_shapes(grid_bin_bounds_rect, shape_type='grid_bin_bounds_rect', edge_width=0.1)\n",
    "    \n",
    "napari_add_grid_bin_bounds_rect(viewer, grid_bin_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b29b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For napari need to map onto xbins axis:\n",
    "#TODO: Not working, did manual rect drawing below instead.\n",
    "\n",
    "assert len(viewer.dims.range) == 3\n",
    "t_range_tuple, neuron_id_range_tuple, xbin_range_tuple = viewer.dims.range\n",
    "# ((0.0, 3309.0, 1.0),\n",
    "#  (-0.2906298631133275, 85.0, 1.0),\n",
    "#  (-0.24635407377607876, 108.0, 1.0))\n",
    "xbin_min, xbin_max = (xbin_range_tuple[0], (xbin_range_tuple[1]-xbin_range_tuple[2])) # the max range isn't included, so we need to subtract off the step to get the real max\n",
    "xbin_width = (xbin_max - xbin_min) # total width in number of xbins\n",
    "x_to_xbins_multiplier: float = xbin_width/grid_bin_bounds.size[0] # multiply a number in normal coordinates to get the equivalent number of xbins\n",
    "x_to_xbins_multiplier\n",
    "\n",
    "map_track_coords_to_xbins_space = lambda v: map_value(v, (grid_bin_bounds.xmin, grid_bin_bounds.xmax), (xbin_min, xbin_max)) # same map\n",
    "# map_track_coords_to_ybins_space = lambda v: map_value(v, (grid_bin_bounds.ymin, grid_bin_bounds.ymax), (ybin_min, ybin_max)) # same map\n",
    "\n",
    "bin_space_grid_bin_bounds = deepcopy(grid_bin_bounds)\n",
    "bin_space_grid_bin_bounds.xmin = map_track_coords_to_xbins_space(grid_bin_bounds.xmin)\n",
    "bin_space_grid_bin_bounds.xmax = map_track_coords_to_xbins_space(grid_bin_bounds.xmax)\n",
    "\n",
    "bin_space_grid_bin_bounds.ymin = 0.0\n",
    "bin_space_grid_bin_bounds.ymax = 5.0\n",
    "\n",
    "bin_space_grid_bin_bounds\n",
    "\n",
    "# map_track_coords_to_xbins_space(grid_bin_bounds.xmin), map_track_coords_to_xbins_space(grid_bin_bounds.xmax)\n",
    "# bin_space_long_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(bin_space_grid_bin_bounds)\n",
    "# bin_space_short_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(bin_space_grid_bin_bounds)\n",
    "\n",
    "# common_1D_platform_height = 0.25\n",
    "# common_1D_track_height = 0.1\n",
    "# bin_space_long_track_dims.minor_axis_platform_side_width = common_1D_platform_height\n",
    "# bin_space_long_track_dims.track_width = common_1D_track_height # (short_track_dims.minor_axis_platform_side_width\n",
    "\n",
    "# bin_space_short_track_dims.minor_axis_platform_side_width = common_1D_platform_height\n",
    "# bin_space_short_track_dims.track_width = common_1D_track_height # (short_track_dims.minor_axis_platform_side_width\n",
    "\n",
    "bin_space_long_track_dims = deepcopy(long_track_dims)\n",
    "bin_space_short_track_dims = deepcopy(short_track_dims)\n",
    "\n",
    "bin_space_long_track_dims.axis_scale_factors = (x_to_xbins_multiplier, 1.0)\n",
    "bin_space_short_track_dims.axis_scale_factors = (x_to_xbins_multiplier, 1.0)\n",
    "\n",
    "bin_space_long_track = LinearTrackInstance(bin_space_long_track_dims, grid_bin_bounds=bin_space_grid_bin_bounds)\n",
    "bin_space_short_track = LinearTrackInstance(bin_space_short_track_dims, grid_bin_bounds=bin_space_grid_bin_bounds)\n",
    "\n",
    "bin_space_short_track\n",
    "\n",
    "t_range_tuple, neuron_id_range_tuple, xbin_range_tuple = viewer.dims.range\n",
    "t_range_tuple\n",
    "\n",
    "\n",
    "bin_space_grid_bin_bounds\n",
    "half_xbin_width = float(xbin_width)/2.0\n",
    "half_xbin_width\n",
    "bin_space_short_track.track_dimensions.scaled_total_length\n",
    "# vertices are top-left and bottom-right corners\n",
    "# [(x, 0.0, w, h) for x, y, w, h, *_unused in bin_space_short_track.rects]\n",
    "# short_track_rectangle_data = [BoundsRect.init_from_x_y_w_h_tuple((x+np.abs(x), y, w, h)).corner_points for x, y, w, h, *_unused in bin_space_short_track.rects]\n",
    "short_track_rectangle_data = [np.hstack((np.zeros((4,1)), BoundsRect.init_from_x_y_w_h_tuple((x+half_xbin_width, y, w, h)).corner_points))[:, :][:, [0, 2, 1]] for x, y, w, h, *_unused in bin_space_short_track.rects]\n",
    "long_track_rectangle_data = np.vstack([np.hstack((np.zeros((4,1)), BoundsRect.init_from_x_y_w_h_tuple((x+half_xbin_width, y, w, h)).corner_points))[:, [0, 2, 1]] for x, y, w, h, *_unused in bin_space_long_track.rects])\n",
    "\n",
    "# short_track_rectangle_data = np.vstack(short_track_rectangle_data)\n",
    "short_track_rectangle_data\n",
    "\n",
    "# array([[0, 2.375, 35], # bottom-left\n",
    "    #    [0, 2.625, 35], # bottom-right\n",
    "    #    [0, 2.375, 46.112], # top-left\n",
    "    #    [0, 2.625, 46.112], # top-right\n",
    "\n",
    "# [0,2,3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb201f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# sync_point_y = -0.750314\n",
    "sync_point_y = 0.0 # the bottom (y-axis) value of the track\n",
    "track_platform_height_y = -5.19389 # the top coordinate (y-axis) value of the platforms\n",
    "\n",
    "## Time indicies for tracks:\n",
    "time_index = 0\n",
    "long_short_change_time_index = 2097 # APPROXIMATE\n",
    "t_range_tuple, neuron_id_range_tuple, xbin_range_tuple = viewer.dims.range\n",
    "long_time_indicies = np.arange(t_range_tuple[0], long_short_change_time_index)\n",
    "short_time_indicies = np.arange(long_short_change_time_index, (t_range_tuple[1]-t_range_tuple[2]))\n",
    "\n",
    "### Long Track Shape Layer:\n",
    "# Where the platform and the track connect:\n",
    "track_platform_connect_x_min = 14.157\n",
    "track_platform_connect_x_max = 91.6898\n",
    "long_track_shapes_data = list(itertools.chain.from_iterable([\n",
    "[\n",
    "np.array([[time_index, track_platform_height_y, track_platform_connect_x_max],\n",
    "        [time_index, track_platform_height_y, 106.093],\n",
    "        [time_index, sync_point_y, 106.093],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_max]]),\n",
    " np.array([[time_index, -3.66162, 14.0037],\n",
    "        [time_index, -3.66162, track_platform_connect_x_max],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_max],\n",
    "        [time_index, sync_point_y, 14.0037]]),\n",
    " np.array([[time_index, track_platform_height_y, -0.246354],\n",
    "        [time_index, track_platform_height_y, track_platform_connect_x_min],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_min],\n",
    "        [time_index, sync_point_y, -0.246354]])\n",
    "]\n",
    "for time_index in long_time_indicies]))\n",
    "long_track_shapes_layer = viewer.add_shapes(long_track_shapes_data, shape_type='rectangle', name='long_track', edge_width=0, face_color='#aa0000ff')\n",
    "long_track_shapes_layer.editable = False\n",
    "\n",
    "\n",
    "### Short Track Shape Layer:\n",
    "# Where the platform and the track connect:\n",
    "track_platform_connect_x_min = 28.2539\n",
    "track_platform_connect_x_max = 73.7623\n",
    "\n",
    "short_track_shapes_data =  list(itertools.chain.from_iterable([\n",
    "[\n",
    "np.array([[time_index, track_platform_height_y, track_platform_connect_x_max],\n",
    "        [time_index, track_platform_height_y, 88.1655],\n",
    "        [time_index, sync_point_y, 88.1655],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_max]]),\n",
    "np.array([[time_index, -3.66162, 28.1006],\n",
    "        [time_index, -3.66162, track_platform_connect_x_max],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_max],\n",
    "        [time_index, sync_point_y, 28.1006]]),\n",
    "np.array([[time_index, track_platform_height_y, 13.8505],\n",
    "        [time_index, track_platform_height_y, track_platform_connect_x_min],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_min],\n",
    "        [time_index, sync_point_y, 13.8505]])\n",
    "]\n",
    "for time_index in short_time_indicies]))\n",
    "\n",
    "short_track_shapes_layer = viewer.add_shapes(short_track_shapes_data, shape_type='rectangle', name='short_track', edge_width=0, face_color='royalblue')\n",
    "short_track_shapes_layer.editable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b12bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_shapes_layer.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc1240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_layer = viewer.layers['short_track_rectangle_data']\n",
    "shapes_layer.data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb9ebf9",
   "metadata": {},
   "source": [
    "# Test classifying various x-positions as belonging to outside the outside_maze, the track_endcaps, or the track_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_rects_outputs, short_rects_outputs = add_track_shapes(grid_bin_bounds, ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7494b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_offset=(150.0, 0.5)\n",
    "# short_offset=(150.0, -0.5)\n",
    "\n",
    "long_offset=(grid_bin_bounds.center_point[0], 0.5)\n",
    "short_offset=(grid_bin_bounds.center_point[0], -0.5)\n",
    "\n",
    "# # Create a second y-axis sharing the same x-axis as ax\n",
    "# ax2 = ax.twinx()\n",
    "# # ax2.plot(x, y2, 'b-')\n",
    "# ax2.set_ylabel('Track data', color='b')\n",
    "# # Set the adjustable attribute to 'datalim'\n",
    "# ax.set_adjustable('datalim')\n",
    "# ax2.set_adjustable('datalim')\n",
    "# long_track_dims.plot_rects(ax2, offset=long_offset)\n",
    "# short_track_dims.plot_rects(ax2, offset=short_offset)\n",
    "\n",
    "combined_item, rect_items, rects = long_track_dims.plot_rects(ax, offset=long_offset)\n",
    "short_track_dims.plot_rects(ax, offset=short_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36198209",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1, ax2 = test_LinearTrackDimensions_2D_Matplotlib(long_track_dims, short_track_dims, long_offset=(150.0, 0.5), short_offset=(150.0, -0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find center from `grid_bin_bounds`\n",
    "# long_pf2D.bin_info\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "\n",
    "x_diff = (grid_bin_bounds[0][1] - grid_bin_bounds[0][0])\n",
    "y_diff = (grid_bin_bounds[1][1] - grid_bin_bounds[1][0])\n",
    "print(f'x_diff: {x_diff}, y_diff: {y_diff}')\n",
    "\n",
    "# Find the x, y midpoints:\n",
    "x_midpoint = grid_bin_bounds[0][0] + (x_diff/2.0)\n",
    "y_midpoint = grid_bin_bounds[1][0] + (y_diff/2.0)\n",
    "print(f'x_midpoint: {x_midpoint}, y_midpoint: {y_midpoint}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_bin_bounds_center_point = (point_tuple_mid_point(grid_bin_bounds[0]), point_tuple_mid_point(grid_bin_bounds[1])) # (145.43, 140.61)\n",
    "x_midpoint, y_midpoint = grid_bin_bounds_center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# long_track_dims.total_length # 214.0\n",
    "# short_track_dims.total_length # 144.0\n",
    "# zero_alignment_point = self.total_length/2.0\n",
    "long_notable_x_positions, _long_notable_y_positions = long_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))\n",
    "short_notable_x_positions, _short_notable_y_positions = short_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc254a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _add_vertical_track_bounds_lines(grid_bin_bounds, ax=None):\n",
    "# \t\"\"\" \n",
    "# \tCaptures: long_notable_x_positions, short_notable_x_positions\n",
    "\t\n",
    "# \tUsage:\n",
    "# \t\tgrid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "# \t\tlong_track_line_collection, short_track_line_collection = _add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=ax)\n",
    "\n",
    "# \t\"\"\"\n",
    "# \tlong_track_dims = LinearTrackDimensions(track_length=170.0)\n",
    "# \tshort_track_dims = LinearTrackDimensions(track_length=100.0)\n",
    "\n",
    "# \t# Find center from `grid_bin_bounds` using `point_tuple_mid_point`\n",
    "# \tx_midpoint, y_midpoint = (point_tuple_mid_point(grid_bin_bounds[0]), point_tuple_mid_point(grid_bin_bounds[1])) # grid_bin_bounds_center_point: (145.43, 140.61)\n",
    "\n",
    "# \tlong_notable_x_positions, _long_notable_y_positions = long_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))\n",
    "# \tshort_notable_x_positions, _short_notable_y_positions = short_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))\n",
    "\n",
    "# \t# Omit the midpoint\n",
    "# \tlong_notable_x_platform_positions = long_notable_x_positions[[0,1,3,4]]\n",
    "# \tshort_notable_x_platform_positions = short_notable_x_positions[[0,1,3,4]]\n",
    "\n",
    "# \t## Adds to current axes:\n",
    "# \tif ax is None:\n",
    "# \t\tfig = plt.gcf()\n",
    "# \t\taxs = fig.get_axes()\n",
    "# \t\tax = axs[0]\n",
    "# \tlong_track_line_collection: matplotlib.collections.LineCollection = plt.vlines(long_notable_x_platform_positions, label='long_track_x_pos_lines', ymin=ax.get_ybound()[0], ymax=ax.get_ybound()[1], colors='#0000FFAA', linestyles='dashed') # matplotlib.collections.LineCollection\n",
    "# \tshort_track_line_collection: matplotlib.collections.LineCollection = plt.vlines(short_notable_x_platform_positions, label='short_track_x_pos_lines', ymin=ax.get_ybound()[0], ymax=ax.get_ybound()[1], colors='#FF0000AA', linestyles='dashed') # matplotlib.collections.LineCollection\n",
    "# \treturn long_track_line_collection, short_track_line_collection\n",
    "\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2650ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_items, rects = long_track_dims.plot_rects(axs[0]) # , offset=(x, y) # , offset=(0.1, 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20cfaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_line_collection.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_track_line_collection.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdae8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_dims.plot_rects(ax, offset=)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a25f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "axs = fig.get_axes()\n",
    "ax = axs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a48933",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_line_collection.remove()\n",
    "short_track_line_collection.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a142c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_1D_placecell_validation\n",
    "\n",
    "_out = plot_1D_placecell_validation(long_pf1D, 0)\n",
    "\n",
    "axes = _out[1]\n",
    "ax = axes[0]\n",
    "# ax = axes[1]\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(grid_bin_bounds=grid_bin_bounds, debug_print=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1)\n",
    "\n",
    "rect_items, rects = long_track_dims.plot_rects(axs[0]) # , offset=(x, y) # , offset=(0.1, 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5cf4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# long_track_dims.plot_rects(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4064c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_grid_bin_bounds_validation', curr_active_pipeline.get_session_context(), defer_render=False, save_figure=True)\n",
    "fig = _out.figures[0]\n",
    "ax = _out.axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the bounding box coordinates and dimensions\n",
    "bbox = ax.bbox\n",
    "x, y, width, height = bbox.x0, bbox.y0, bbox.width, bbox.height\n",
    "x, y, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_empty = ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e6b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_items, rects = long_track_dims.plot_rects(ax_empty) # , offset=(x, y) # , offset=(0.1, 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "(320.0, 983.7668560462606, 901.8181818181818, 91.99628790747863)\n",
    "active_track_dims = LinearTrackDimensions(width=901.8181818181818)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6645194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.transforms import Bbox\n",
    "\n",
    "# Step 2: Define a simple vector graphic (an arrow in this case)\n",
    "def draw_arrow(ax, x, y, width, height):\n",
    "    arrow = patches.FancyArrow(x, y, width, height, width=0.2*height, color=\"red\")\n",
    "    ax.add_patch(arrow)\n",
    "\n",
    "# Step 3: Scale and draw the arrow within a bounding box\n",
    "def draw_scaled_arrow_in_bbox(ax, bbox):\n",
    "    # Extract the bounding box coordinates and dimensions\n",
    "    x, y, width, height = bbox.x0, bbox.y0, bbox.width, bbox.height\n",
    "\n",
    "    # Draw the bounding box (for visualization)\n",
    "    rect = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor='black', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    # Draw the scaled arrow within the bounding box\n",
    "    draw_arrow(ax, x, y, width, height)\n",
    "\n",
    "# Main code\n",
    "fig, ax = plt.subplots()\n",
    "bbox = Bbox.from_bounds(0.2, 0.2, 0.6, 0.6)  # Define bounding box with [x, y, width, height]\n",
    "\n",
    "draw_scaled_arrow_in_bbox(ax, bbox)\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_aspect('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b365b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8f5ab",
   "metadata": {},
   "source": [
    "# 2023-09-21 - Continuous Surprise Figure - How do I display it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dbe065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_long_short_surprise_difference_plot, plot_long_short, plot_long_short_any_values\n",
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_surprise_results\n",
    "\n",
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import LongShortDisplayConfigManager\n",
    "long_short_display_config_manager = LongShortDisplayConfigManager()\n",
    "long_epoch_config = long_short_display_config_manager.long_epoch_config.as_matplotlib_kwargs()\n",
    "short_epoch_config = long_short_display_config_manager.short_epoch_config.as_matplotlib_kwargs()\n",
    "\n",
    "graphics_outputs_list = fig_surprise_results(curr_active_pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d58220",
   "metadata": {},
   "source": [
    "### FOUND! 2023-09-21 - Found code that generated surprise plots, strangely not stored anywhere!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: nSnapshots == n_post_update_times\n",
    "active_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise']\n",
    "post_update_times = active_relative_entropy_results['post_update_times'] # (4123,) = (nSnapshots,)\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals = active_relative_entropy_results['time_intervals']\n",
    "long_short_rel_entr_curves_frames = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4123, 108, 63) = (nSnapshots, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4123, 108, 63) = (nSnapshots, n_neurons, n_xbins)\n",
    "flat_relative_entropy_results = active_relative_entropy_results['flat_relative_entropy_results'] # (4123, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_results = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (4123, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_across_all_positions = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4123,) - (nSnapshots)\n",
    "flat_surprise_across_all_positions = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4123,) - (nSnapshots)\n",
    "nSnapshots, n_neurons, n_xbins = np.shape(long_short_rel_entr_curves_frames)\n",
    "print(f'nSnapshots: {nSnapshots}, n_neurons: {n_neurons}, n_xbins: {n_xbins}') # nSnapshots: 3308, n_neurons: 85, n_xbins: 107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1200faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_update_times.shape\n",
    "# np.shape(post_update_times)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61282cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(flat_jensen_shannon_distance_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d8d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(flat_relative_entropy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a7718",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(flat_jensen_shannon_distance_across_all_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(long_short_rel_entr_curves_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303ca32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7205c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: these results are NOT the same as the ones calculated in compute_snapshot_relative_entropy_surprise_differences.compute_surprise_relative_entropy_divergence, and I'm not quite sure why:\n",
    "# Jensen-Shannon distance is an average of KL divergence:\n",
    "from scipy.special import rel_entr\n",
    "mixture_distribution = 0.5 * (long_short_rel_entr_curves_frames + short_long_rel_entr_curves_frames)\n",
    "print(f'mixture_distribution.shape: {np.shape(mixture_distribution)}') # (nSnapshots, n_neurons, n_xbins)\n",
    "# jensen_shannon_distance = 0.5 * (sum(rel_entr(mixture_distribution, long_short_rel_entr_curves_frames)) + sum(rel_entr(mixture_distribution, short_long_rel_entr_curves_frames))) # is this right? I'm confused by sum(...) # (n_neurons, n_xbins)\n",
    "jensen_shannon_distance = 0.5 * (np.sum(rel_entr(mixture_distribution, long_short_rel_entr_curves_frames), axis=1) + np.sum(rel_entr(mixture_distribution, short_long_rel_entr_curves_frames), axis=1)) # alt version: (nSnapshots, n_xbins)\n",
    "print(f'jensen_shannon_distance.shape: {np.shape(jensen_shannon_distance)}') # (n_neurons, n_xbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(flat_jensen_shannon_distance_results, jensen_shannon_distance).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1fd095",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(flat_jensen_shannon_distance_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb518301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from silx.gui.plot import Plot2D\n",
    "\n",
    "plot = Plot2D()  # Create the plot widget\n",
    "plot.addImage(flat_jensen_shannon_distance_results, legend='flat_jensen_shannon_distance_results')  # Plot the 2D data set with default colormap\n",
    "plot.setGraphTitle('flat_jensen_shannon_distance_results')\n",
    "plot.getXAxis().setLabel('Position Bin')\n",
    "plot.getYAxis().setLabel('Snapshot Timebin')\n",
    "plot.show()  # Make the plot widget visible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9eca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = Plot2D()  # Create the plot widget\n",
    "plot.addImage(jensen_shannon_distance, legend='jensen_shannon_distance')  # Plot the 2D data set with default colormap\n",
    "plot.setGraphTitle('jensen_shannon_distance')\n",
    "plot.getXAxis().setLabel('Position Bin')\n",
    "plot.getYAxis().setLabel('Snapshot Timebin')\n",
    "plot.show()  # Make the plot widget visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot = Plot2D()  # Create the plot widget\n",
    "plot.addImage(long_short_rel_entr_curves_frames, legend='image')  # Plot the 2D data set with default colormap\n",
    "plot.setGraphTitle('long_short_rel_entr_curves_frames')\n",
    "# plot.getXAxis().setLabel('Position Bin')\n",
    "# plot.getYAxis().setLabel('Snapshot Timebin')\n",
    "plot.show()  # Make the plot widget visible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from silx.gui.plot.StackView import StackViewMainWindow\n",
    "\n",
    "# synthetic data, stack of 100 images of size 200x300\n",
    "# mystack = np.fromfunction(\n",
    "#     lambda i, j, k: np.sin(i/15.) + np.cos(j/4.) + 2 * np.sin(k/6.),\n",
    "#     (100, 200, 300)\n",
    "# )\n",
    "\n",
    "sv = StackViewMainWindow()\n",
    "sv.setColormap(\"jet\", autoscale=True)\n",
    "sv.setStack(long_short_rel_entr_curves_frames)\n",
    "# (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "sv.setLabels([\"post_update_time\", \"aclu\", \"Position (xbin)\"])\n",
    "sv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa37de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(flat_jensen_shannon_distance_results, show_yticks=False, title=f\"flat_jensen_shannon_distance_results\", defer_show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa164de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(flat_jensen_shannon_distance_across_all_positions, show_yticks=False, title=f\"flat_jensen_shannon_distance_across_all_positions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2295dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "from neuropy.core.epoch import Epoch\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(post_update_times, flat_surprise_across_all_positions)\n",
    "ax.set_ylabel('Relative Entropy across all positions')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('r','cyan'), alpha=0.1, edgecolors=None, labels_kwargs={'y_offset': -0.05, 'size': 14}, defer_render=True, debug_print=False)\n",
    "laps_epochs_collection, laps_epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='r', edgecolors='black', labels_kwargs={'y_offset': -16.0, 'size':8}, defer_render=True, debug_print=False)\n",
    "# replays_epochs_collection, replays_epoch_labels = draw_epoch_regions(active_filter_epoch_obj, ax, facecolor='orange', edgecolors=None, labels_kwargs=None, defer_render=False, debug_print=False)\n",
    "fig.suptitle('flat_surprise_across_all_positions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(post_update_times, flat_jensen_shannon_distance_across_all_positions, label='JS_Distance')\n",
    "ax.set_ylabel('J-S Distance across all positions')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), alpha=0.1, edgecolors=None, labels_kwargs={'y_offset': -0.05, 'size': 14}, defer_render=True, debug_print=False)\n",
    "laps_epochs_collection, laps_epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='red', edgecolors='black', labels_kwargs={'y_offset': -16.0, 'size':8}, defer_render=True, debug_print=False)\n",
    "# replays_epochs_collection, replays_epoch_labels = draw_epoch_regions(active_filter_epoch_obj, ax, facecolor='orange', edgecolors=None, labels_kwargs=None, defer_render=False, debug_print=False)\n",
    "fig.suptitle('flat_jensen_shannon_distance_across_all_positions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df587d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic relative entropy vs. time plot:\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(post_update_times, flat_relative_entropy_results)\n",
    "ax.set_ylabel('Relative Entropy')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), alpha=0.1, edgecolors=None, labels_kwargs={'y_offset': -0.05, 'size': 14}, defer_render=False, debug_print=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ffda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "win, plots = plot_long_short_surprise_difference_plot(curr_active_pipeline, long_results_obj, short_results_obj, long_epoch_name, short_epoch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "win, (ax_long, ax_short), legend = plot_long_short(long_results_obj, short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fn = lambda a_results_obj: a_results_obj.all_epochs_decoded_epoch_time_bins_mean[:,0]\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_scrambled_pf_surprises_mean\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "y_fn = lambda a_results_obj: a_results_obj.all_epochs_computed_one_left_out_posterior_to_pf_surprises\n",
    "\n",
    "# (time_bins, neurons), (epochs, neurons), (epochs)\n",
    "# all_epochs_computed_one_left_out_posterior_to_pf_surprises, all_epochs_computed_cell_one_left_out_posterior_to_pf_surprises_mean, all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "win, plots_tuple, legend = plot_long_short_any_values(long_results_obj, short_results_obj, x=x_fn, y=y_fn) #  limit_aclus=[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO 2023-09-21 16:19: - [ ] Does not work due to QCode issue\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions import _context_nested_docks\n",
    "\n",
    "\n",
    "# active_display_output = {}\n",
    "# active_identifying_filtered_session_ctx = global_epoch_context\n",
    "# display_output = active_display_output | curr_active_pipeline.display('_display_context_nested_docks', active_identifying_filtered_session_ctx, enable_gui=False, debug_print=False) # returns {'master_dock_win': master_dock_win, 'app': app, 'out_items': out_items}\n",
    "# master_dock_win = display_output['master_dock_win']\n",
    "# app = display_output['app']\n",
    "# out_items = display_output['out_items']\n",
    "\n",
    "include_includelist = curr_active_pipeline.active_completed_computation_result_names # ['maze', 'sprinkle']\n",
    "\n",
    "out_items = {}\n",
    "master_dock_win, app, out_items = _context_nested_docks(curr_active_pipeline, active_config_names=include_includelist, **{'enable_gui': True, 'debug_print': False})\n",
    "master_dock_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7326d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "short_pf_peak_x = neuron_replay_stats_df.short_pf_peak_x.values\n",
    "long_pf_peak_x = neuron_replay_stats_df.long_pf_peak_x.values\n",
    "\n",
    "# long_pf_peak_x_maze_classification = [classify_x_position(test_x, long_rects) for test_x in long_pf_peak_x.values]\n",
    "# short_pf_peak_x_maze_classification = [classify_x_position(test_x, short_rects) for test_x in short_pf_peak_x.values]\n",
    "# [classify_x_position(test_x, short_rects) for test_x in long_pf_peak_x.values]\n",
    "\n",
    "long_track.is_on_maze(long_pf_peak_x)\n",
    "# long_track.is_on_endcap(long_pf_peak_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bc1b6",
   "metadata": {},
   "source": [
    "## NOW TODO 2023-09-20 22:33: - [ ] Need to fix tests and determing why some peaks are falling outside the bounds (as assessed by the is_on_maze function to see if implementation is valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# assert short_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))].all(), f\"all valid short peaks should be located on the short track\" # should all be true yeah?\n",
    "assert long_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))].all(), f\"all valid short peaks should be located on the long track\"\n",
    "assert long_track.is_on_maze(long_pf_peak_x)[np.logical_not(np.isnan(long_pf_peak_x))].all(), f\"all valid long peaks should be located on the long track. {long_track.is_on_maze(long_pf_peak_x)[np.logical_not(np.isnan(long_pf_peak_x))]}\" # not working\n",
    "assert short_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))].all(), f\"all valid short peaks should be located on the short track. {short_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))]}\" # not working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec27b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track.is_on_endcap(long_pf_peak_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1bc2ae",
   "metadata": {},
   "source": [
    "## Debug Plots for `LinearTrackDimensions` and `LinearTrackInstance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ece7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, w, cw, (long_track_dims, long_rect_items, long_rects), (short_track_dims, short_rect_items, short_rects) = test_LinearTrackDimensions_2D_pyqtgraph(long_track_dims, short_track_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cdcb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "axs = fig.get_axes()\n",
    "ax = axs[0]\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d49be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "## Adds a new subplot to an existing (fig, ax) without requiring modifications in the original code!\n",
    "\n",
    "# Get the current gridspec from ax\n",
    "gs = ax.get_subplotspec().get_gridspec()\n",
    "\n",
    "# Create a new gridspec with an additional column\n",
    "gs_new = gridspec.GridSpec(1, 2, width_ratios=[1, 0.5]) # new column is half the width of the current one\n",
    "\n",
    "# Reposition the existing ax using the new gridspec\n",
    "ax.set_position(gs_new[0, 0].get_position(fig))\n",
    "\n",
    "# Add a new subplot in the new column\n",
    "ax2 = fig.add_subplot(gs_new[0, 1])\n",
    "\n",
    "\n",
    "ax2.plot(np.cos(np.linspace(0, 10, 100)))\n",
    "# ax2.cla()\n",
    "# long_track_dims.plot_rects(ax2)\n",
    "\n",
    "# long_track_dims.plot_rects(ax2, offset=(0.1, 0.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out2 = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', included_unit_neuron_IDs=[2], n_max_plot_rows=2, save_figure=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_example_handpicked_pho_jonathan_active_set_cells\n",
    "\n",
    "_LxC_out, _SxC_out = fig_example_handpicked_pho_jonathan_active_set_cells(curr_active_pipeline, save_figure=True, included_LxC_example_neuron_IDs=[4, 58], included_SxC_example_neuron_IDs=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6907963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuropy.analyses.placefields import PfnDMixin, plotRaw_v_time\n",
    "from neuropy.analyses.placefields import PfnDMixin\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out3 = long_pf1D.plotRaw_v_time(0, should_include_trajectory=True, should_include_spikes=False, should_include_labels=True, use_filtered_positions=True, use_pandas_plotting=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a88a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out4 = long_pf1D.plotRaw_v_time(0, should_include_trajectory=True, should_include_spikes=False, should_include_labels=True, use_filtered_positions=False, use_pandas_plotting=False)\n",
    "# _out4 = long_pf1D.plotRaw_v_time(0, should_include_trajectory=True, should_include_spikes=False, should_include_labels=True, use_filtered_positions=False, use_pandas_plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff3397",
   "metadata": {},
   "source": [
    "# PhoKamran2023Paper Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e59bdb",
   "metadata": {},
   "source": [
    "## Figure 1) pf1D Ratemaps, Active set, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77377ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_1_add_replay_epoch_rasters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics, fig_1c_figures_out_dict = PAPER_FIGURE_figure_1_full(curr_active_pipeline) # did not display the pf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05664e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = jonathan_firing_rate_analysis_result.rdf.rdf\n",
    "rdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b2335",
   "metadata": {},
   "source": [
    "## Figure 2) `PaperFigureTwo`: LxC/SxC Analyses\n",
    "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63d9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo\n",
    "\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # 10ms\n",
    "_out_fig_2.compute(curr_active_pipeline=curr_active_pipeline)\n",
    "_out_fig_2.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403e5c60",
   "metadata": {},
   "source": [
    "## Figure 3) `PAPER_FIGURE_figure_3`: Firing Rate Index and Long/Short Firing Rate Replays v. Laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6932845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import FormattedFigureText\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _plot_long_short_firing_rate_indicies\n",
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out, _out2 = PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9796ffb1",
   "metadata": {},
   "source": [
    "## Other Paper-related explorations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90dda8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out2.figures\n",
    "_out.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "['start']\n",
    "\n",
    "\n",
    "# Any change in duration over the recording session duration?\n",
    "rdf['duration']\n",
    "\n",
    "# rdf.plot.scatter('start', 'duration')\n",
    "\n",
    "# rdf.plot.scatter('duration', 'num_neuron_participating') # strong positive trend\n",
    "\n",
    "# rdf.plot.scatter('start', 'num_neuron_participating') # num neurons participating seems to increase over time, especially after the short track is introduced. Contrary to my hypothesis.\n",
    "\n",
    "rdf.plot.scatter('start', 'num_short_only_neuron_participating')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ['num_neuron_participating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "a_plot_obj = curr_active_pipeline.plot\n",
    "a_plot_obj._display_spike_rasters_pyqtplot_2D()\n",
    "# '_display_spike_rasters_pyqtplot_2D': ' Plots a standalone 2D raster plot\\n        ',\n",
    "# '_display_spike_rasters_pyqtplot_3D': ' Plots a standalone 3D raster plot with independent/standalone controls built-in\\n        ',\n",
    "# '_display_spike_rasters_pyqtplot_3D_with_2D_controls': ' Plots a standalone 3D raster plot (via pyqtgraph) with a separate 2D raster plot as the window with which you can adjust the viewed window. \\n        ',\n",
    "# '_display_spike_rasters_vedo_3D': ' Plots a standalone 3D raster plot with independent/standalone controls built-in\\n        ',\n",
    "# '_display_spike_rasters_vedo_3D_with_2D_controls': ' Plots a standalone 3D raster plot (via Vedo) with a separate 2D raster plot as the window with which you can adjust the viewed window. \\n        ',\n",
    "# '_display_spike_rasters_window': ' Displays a Spike3DRasterWindowWidget with a configurable set of raster widgets and controls in it.\\n        ',type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3877d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1d_compare_fig_L, pf1d_compare_fig_S = pf1d_compare_graphics.figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ffa57",
   "metadata": {
    "tags": [
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import build_shared_sorted_neuronIDs\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph\n",
    "\n",
    "ratemap = long_pf1D.ratemap\n",
    "included_unit_neuron_IDs = EITHER_subset.track_exclusive_aclus\n",
    "rediculous_final_sorted_all_included_neuron_ID, rediculous_final_sorted_all_included_pfmap = build_shared_sorted_neuronIDs(ratemap, included_unit_neuron_IDs, sort_ind=new_all_aclus_sort_indicies.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(rediculous_final_sorted_all_included_pfmap, show_yticks=False, title=f\"pf1D Sorted Visualization\", defer_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66369f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7261b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_curves_sorted = long_pf1D.ratemap.normalized_tuning_curves[is_included][included_new_all_aclus_sort_indicies]\n",
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(active_curves_sorted, show_yticks=False, title=f\"pf1D Sorted Visualization\", defer_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f0066",
   "metadata": {
    "tags": [
     "unwrap_figure_output",
     "interactive"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a588ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "## Stacked Epoch Plot\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defb05a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController # `plot_decoded_epoch_slices_paginated`\n",
    "from neuropy.utils.matplotlib_helpers import add_inner_title # plot_decoded_epoch_slices_paginated\n",
    "\n",
    "if display_context is None:\n",
    "\tdisplay_context = IdentifyingContext(display_fn_name='DecodedEpochSlices')\n",
    "\t\n",
    "\n",
    "max_subplots_per_page = kwargs.pop('max_subplots_per_page', 200)\n",
    "controller_name = kwargs.pop('name', 'TestDecodedEpochSlicesPaginationController')\n",
    "\t\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "    \n",
    "\n",
    "\n",
    "_out_pagination_controller = DecodedEpochSlicesPaginatedFigureController.init_from_decoder_data(curr_results_obj.active_filter_epochs, curr_results_obj.all_included_filter_epochs_decoder_result, \n",
    "        xbin=curr_results_obj.original_1D_decoder.xbin, global_pos_df=global_session.position.df, a_name=controller_name, active_context=display_context,  max_subplots_per_page=max_subplots_per_page, included_epoch_indicies=included_epoch_indicies) # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_results_obj.flat_all_epochs_decoded_epoch_time_bins\n",
    "fig, curr_ax = plot_1D_most_likely_position_comparsions(curr_active_pipeline.sess.position.to_dataframe(), time_window_centers=short_updated_time_bin_containers, xbin=long_results_obj.original_1D_decoder.xbin.copy(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tposterior=short_updated_timebins_p_x_given_n,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tactive_most_likely_positions_1D=None,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tenable_flat_line_drawing=False, debug_print=False, ax=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252638b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_filter_epochs\n",
    "## Get the previously created matplotlib_view_widget figure/ax:\n",
    "\n",
    "# measured_position_df, time_window_centers, xbin, ax=None, posterior=None, active_most_likely_positions_1D=None, enable_flat_line_drawing=False, variable_name = 'x', debug_print=False\n",
    "# fig, curr_ax = plot_1D_most_likely_position_comparsions(curr_active_pipeline.sess.position.to_dataframe(), time_window_centers=flat_time_bin_centers, xbin=long_results_obj.original_1D_decoder.xbin.copy(),\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tposterior=timebins_p_x_given_n,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tactive_most_likely_positions_1D=None,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tenable_flat_line_drawing=False, debug_print=False)\n",
    "\n",
    "fig, curr_ax = plot_1D_most_likely_position_comparsions(curr_active_pipeline.sess.position.to_dataframe(), time_window_centers=updated_time_bin_containers, xbin=long_results_obj.original_1D_decoder.xbin.copy(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tposterior=updated_timebins_p_x_given_n,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tactive_most_likely_positions_1D=None,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tenable_flat_line_drawing=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e417d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, curr_ax = plot_1D_most_likely_position_comparsions(curr_active_pipeline.sess.position.to_dataframe(), time_window_centers=updated_time_bin_containers, xbin=long_results_obj.original_1D_decoder.xbin.copy(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tposterior=updated_timebins_p_x_given_n,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tactive_most_likely_positions_1D=None,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tenable_flat_line_drawing=False, debug_print=False, ax=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe67720",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a04bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_time_bin_containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af732746",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a masked array:\n",
    "np.ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96caba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_results_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dce6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params, plots_data, plots, ui = plot_decoded_epoch_slices(deepcopy(active_filter_epochs), deepcopy(filter_epochs_decoder_result), global_pos_df=global_pos_df, variable_name='lin_pos', xbin=xbin, included_epoch_indicies=included_epoch_indicies,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tname=a_name, debug_print=False, debug_test_max_num_slices=max_subplots_per_page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1033c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination_controller_L, pagination_controller_S = example_stacked_epoch_graphics.plot_data['controllers']\n",
    "ax_L, ax_S = example_stacked_epoch_graphics.axes\n",
    "final_figure_context_L, final_context_S = example_stacked_epoch_graphics.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cbb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## After launching the interactive Stacked Epoch Plots for user epoch selection, try to update the selection with previously added annotations:\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.GUI.Qt.Mixins.PaginationMixins import SelectionsObject\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "user_annotation_man = UserAnnotationsManager()\n",
    "user_annotations = user_annotation_man.get_user_annotations()\n",
    "\n",
    "final_context_L = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj')\n",
    "final_context_S = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj')\n",
    "# _out_pagination_controller.params.active_identifying_figure_ctx.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_L = final_context_L.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_S = final_context_S.adding_context(None,  user_annotation=\"selections\")\n",
    "\n",
    "saved_selection_L: SelectionsObject = pagination_controller_L.save_selection()\n",
    "saved_selection_S: SelectionsObject = pagination_controller_S.save_selection()\n",
    "# saved_selection_L = user_annotation_man.update_selections_from_annotations(saved_selection_L, user_annotations)\n",
    "# saved_selection_S = user_annotation_man.update_selections_from_annotations(saved_selection_S, user_annotations)\n",
    "\n",
    "saved_selection_L = saved_selection_L.update_selections_from_annotations(user_annotations, debug_print=False)\n",
    "saved_selection_S = saved_selection_S.update_selections_from_annotations(user_annotations, debug_print=False)\n",
    "\n",
    "## re-apply the selections:\n",
    "pagination_controller_L.restore_selections(saved_selection_L, defer_render=True)\n",
    "pagination_controller_S.restore_selections(saved_selection_S, defer_render=True)\n",
    "\n",
    "ax_L[0].figure.canvas.draw()  # .figures.canvas.draw()\n",
    "ax_S[0].figure.canvas.draw()  # .figures.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b2f39d",
   "metadata": {
    "tags": [
     "TODO"
    ]
   },
   "source": [
    "# 2023-09-06 - Plot the decoded positions for each replay on the track:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592c55f",
   "metadata": {
    "tags": [
     "TODO"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions\n",
    "\n",
    "\n",
    "long_track_dims = LinearTrackDimensions(track_length=100.0)\n",
    "short_track_dims = LinearTrackDimensions(track_length=70.0)\n",
    "\n",
    "\n",
    "# long_track_dims.plot_rects(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import _test_LinearTrackDimensions_2D\n",
    "\n",
    "app, w, cw, (long_track_dims, long_rect_items, long_rects), (short_track_dims, short_rect_items, short_rects) = _test_LinearTrackDimensions_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48faca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_3_a, _out_fig_3_b = PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = _out_fig_3_a.axes[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c872e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_dims.plot_rects(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination_controller_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the symbol properties\n",
    "# symbol = pg.mkPen('w', width=1)  # Pen for the lines\n",
    "size = 1.0  # Fixed x-width\n",
    "symbol_brush = None  # No brush for the symbol (transparent fill)\n",
    "\n",
    "# override_scatter_plot_kwargs = dict(pxMode=False, symbol='|', size=size, pen={'color': 'w', 'width': 1.0}) # , brush=symbol_brush\n",
    "\n",
    "# override_scatter_plot_kwargs = dict(pxMode=False, symbol='arrow_up', size=1.0, pen={'color': 'w', 'width': 1.0}, hoverable=True) #\n",
    "\n",
    "# override_scatter_plot_kwargs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bb530",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epoch_spikes_df_L.spikes.rebuild_fragile_linear_neuron_IDXs();\n",
    "filter_epoch_spikes_df_S.spikes.rebuild_fragile_linear_neuron_IDXs();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d46002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import DataSeriesColorHelpers\n",
    "\n",
    "# unit_colors_list = neuron_qcolors_list.copy()\n",
    "\n",
    "n_neurons = len(EITHER_subset.track_exclusive_aclus)\n",
    "EITHER_subset_neuron_qcolors_list, EITHER_subset_neuron_colors_ndarray = DataSeriesColorHelpers.build_cell_colors(n_neurons, colormap_name='PAL-relaxed_bright', colormap_source=None)\n",
    "\n",
    "unit_colors_list = EITHER_subset_neuron_colors_ndarray.copy()\n",
    "unit_colors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "render_epochs_df = epochs_df_L.iloc[0:1]\n",
    "app_L, win_L, plots_L, plots_data_L = plot_multiple_raster_plot(render_epochs_df, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "\t\t\t\t\t\t\t\t\t\tepoch_id_key_name='replay_epoch_id', scatter_app_name=\"Long Decoded Example Replays\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_L, win_L, plots_L, plots_data_L = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "\t\t\t\t\t\t\t\t\t\tepoch_id_key_name='replay_epoch_id', scatter_app_name=\"Long Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee132b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_S, win_S, plots_S, plots_data_S = plot_multiple_raster_plot(epochs_df_S, filter_epoch_spikes_df_S, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                 epoch_id_key_name='replay_epoch_id', scatter_app_name=\"Short Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26dd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single `plot_raster_plot` calls\n",
    "an_epoch = list(epochs_df_L.itertuples())[0]\n",
    "an_epoch_spikes_df = filter_epoch_spikes_df_L[filter_epoch_spikes_df_L['replay_epoch_id'] == an_epoch.Index]\n",
    "\n",
    "override_scatter_plot_kwargs = dict(pxMode=True, size=10.0, pen={'color': 'w', 'width': 1.0}) # , symbol='arrow_up,\n",
    "\n",
    "_out_single_raster_plot = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test1\")\n",
    "_out_single_raster_plot2 = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc499c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e7707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a132a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d915bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720e380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c144cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f0558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c32519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b67ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6071c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_alt, win_alt, plots_alt, plots_data_alt = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                         epoch_id_key_name='replay_epoch_id', scatter_app_name=\"ALT Long Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d20407c",
   "metadata": {},
   "source": [
    "### Testing `plot_kourosh_activity_style_figure` for debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69512447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import plot_kourosh_activity_style_figure\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.helpers import _helper_make_scatterplot_clickable\n",
    "\n",
    "plot_aclus = EITHER_subset.track_exclusive_aclus.copy()\n",
    "# plot_aclus = EITHER_subset.track_exclusive_aclus[new_all_aclus_sort_indicies].copy()\n",
    "_out_A = plot_kourosh_activity_style_figure(long_results_obj, long_session, plot_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_idx=13, callout_epoch_IDXs=None, skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, plots, plots_data = _out_A\n",
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d4092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 2023-06-27 10:42: - [ ] Desperitely need a class that \"explodes\" the important variables and their types out of a DynamicParameters (dict-like) or other object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_n = plot_kourosh_activity_style_figure(long_results_obj, long_session, EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_idx=49, callout_epoch_IDXs=np.arange(6), skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af748f5c",
   "metadata": {},
   "source": [
    "# 2023-07-14 - LxC and SxC PhoJonathanSession plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_display_BatchPhoJonathanFiguresHelper_PlusPDF_20.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\n",
    "# print(f'active_out_figures_dict: {active_out_figures_dict}')\n",
    "\n",
    "# BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset\n",
    "active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=EITHER_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\n",
    "print(f'active_out_figures_dict: {active_out_figures_dict}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e072b346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec1c4bb",
   "metadata": {
    "tags": [
     "ACTIVE_2023-09-07"
    ]
   },
   "outputs": [],
   "source": [
    "# 2023-09-07 - Build Example LxC/SxC cells from handpicked examples: aclus = [4, 58]\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import build_extra_cell_info_label_string\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out2 = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', n_max_plot_rows=2, save_figure=False, included_unit_neuron_IDs=[4, 58]) # , included_unit_neuron_IDs=[4, 58]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.display(display_function='_display_2d_placefield_result_plot_ratemaps_2D', active_session_configuration_context=long_epoch_context)\n",
    "\n",
    "\n",
    "# curr_active_pipeline.display(display_function='_display_placemaps_pyqtplot_2D', active_session_configuration_context=long_epoch_context)\n",
    "curr_active_pipeline.display(display_function='_display_1d_placefields', active_session_configuration_context=long_epoch_context)\n",
    "# curr_active_pipeline.display(display_function='_display_2d_placefield_occupancy', active_session_configuration_context=long_epoch_context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_occupancy', active_session_configuration_context=long_epoch_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be309d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_occupancy', active_session_configuration_context=short_epoch_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_result_plot_ratemaps_2D', active_session_configuration_context=short_epoch_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5115fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_result_plot_ratemaps_2D', active_session_configuration_context=long_epoch_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d12ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() # new figure to hold the result\n",
    "# can show the figures by looping through and calling\n",
    "for a_ctxt, a_fig in active_out_figures_dict.items():\n",
    "    print(f'showing: {a_ctxt}')\n",
    "    a_fig.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edea79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]] # only uses global_session\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a731f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d085cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ab296",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exclusive.track_exclusive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exclusive.track_exclusive_df['lap_delta_minus_inst_fr'] = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n",
    "long_exclusive.track_exclusive_df['lap_delta_plus_inst_fr'] = LxC_ThetaDeltaPlus.cell_agg_inst_fr_list # (n_cells, )\n",
    "long_exclusive.track_exclusive_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3077438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = LxC_ThetaDeltaMinus.epoch_agg_inst_fr_list # (n_epochs, n_cells)\n",
    "# d = d[:,1]\n",
    "d = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n",
    "d\n",
    "long_exclusive.track_exclusive_df['lap_delta_minus_inst_fr'] = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop out the very low (inactive) Epochs... I guess? But we want it to be influenced by the inactive epochs.\n",
    "curr_active_pipeline.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(LxC_ThetaDeltaMinus.inst_fr_signals_list) # n_epochs\n",
    "d = LxC_ThetaDeltaMinus.inst_fr_df_list\n",
    "d[0]\n",
    "# (n_epochs, n_cells)\n",
    "# print(f'{d.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b2901",
   "metadata": {},
   "source": [
    "## NOW: 2023-07-11 - Testing Batch-computed inst_firing_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "\n",
    "## Load the saved across-session results:\n",
    "inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=0) # some global context across all of the sessions, not sure what to put here.\n",
    "\n",
    "# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\n",
    "\n",
    "## Display the aggregate across sessions:\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn't save this info\n",
    "_out_fig_2.computation_result = across_session_inst_fr_computation\n",
    "_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\n",
    "# Set callback, the only self-specific property\n",
    "_out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f71cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\n",
    "\t\n",
    "_out_fig_2.perform_save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed322ee",
   "metadata": {},
   "source": [
    "# `active_pf_nD`, `active_pf_nD_dt` visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8606b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedOccupancyPlotter import TimeSynchronizedOccupancyPlotter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d478ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_sync_occupancy_plotter = TimeSynchronizedOccupancyPlotter(global_pf2D_dt)\n",
    "curr_sync_occupancy_plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14388eec",
   "metadata": {},
   "source": [
    "# 2023-07-07 - `batch_extended_programmatic_figures` Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "neptuner = batch_perform_all_plots(curr_active_pipeline, enable_neptune=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126028b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb off\n",
    "%load_ext viztracer\n",
    "from viztracer import VizTracer\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a065e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-batch_extended_programmatic_figures.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    batch_extended_programmatic_figures(curr_active_pipeline, write_vector_format=False, write_png=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9f9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_extended_programmatic_figures(curr_active_pipeline, write_vector_format=False, write_png=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.logical_or(neuron_replay_stats_df['is_refined_LxC'], neuron_replay_stats_df['is_refined_SxC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a49741",
   "metadata": {},
   "outputs": [],
   "source": [
    "JonathanFiringRateAnalysisResult = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc366f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "\n",
    "jonathan_firing_rate_analysis_result.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0710f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b9ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CreateNewStackedDecodedEpochSlicesPlotCommand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681ac70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_render_config_widgets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28604a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Update function to call after success:\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(epochs_update_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc81e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "laps_display_config: EpochDisplayConfig = epoch_display_configs['Laps']\n",
    "laps_display_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = deepcopy(laps_display_config) # EpochDisplayConfig()\n",
    "widget = EpochRenderConfigWidget(config=test_config)\n",
    "# widget = EpochRenderConfigWidget()\n",
    "widget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25433137",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget.update_from_config(test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf483c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_config = widget.config_from_state()\n",
    "a_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8170bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_to_pyqt_binding_dict = ParamToPyQtBinding.param_to_pyqt_binding_dict()\n",
    "ui_element_list = widget.get_ui_element_list()\n",
    "bound_config_value_list = widget.get_bound_config_value_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d25a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_config_property, a_widget in zip(bound_config_value_list, ui_element_list):\n",
    "\ta_widget_type = type(a_widget)\n",
    "\t# print(f'a_widget_type: {a_widget_type.__name__}')\n",
    "\t# found_binding = param_to_pyqt_binding_dict.get(type(a_widget), None)\n",
    "\tfound_binding = param_to_pyqt_binding_dict.get(type(a_widget).__name__, None)\n",
    "\tif found_binding is not None:\n",
    "\t\tprint(f'found_binding: {found_binding}')\n",
    "\t\tdesired_value = a_config_property(widget.config)\n",
    "\t\tprint(f'\\t{desired_value}')\n",
    "\t\tcurr_value = found_binding.get_value(a_widget)\n",
    "\t\tprint(f'\\t{curr_value}')\n",
    "\t\tfound_binding.set_value(a_widget, desired_value)\n",
    "\telse:\n",
    "\t\tprint(f'no binding for {a_widget} of type: {type(a_widget)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daefe59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_widget_hierarchy(widget)\n",
    "# widget.ui.btnTitle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fdbeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_display_config.param.height # param.parameterized.Parameters\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac4bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_display_config.brush_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b33c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force New:\n",
    "active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D().values() # included_neuron_ids=EITHER_subset.track_exclusive_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3798b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.EpochRenderingMixin import EpochRenderingMixin, RenderedEpochsItemsContainer\n",
    "\n",
    "interval_info = active_2d_plot.list_all_rendered_intervals()\n",
    "interval_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfabc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_default_renderables(active_2d_plot):\n",
    "    \"\"\" adds the typical Epochs and Position curves to the RasterWindow on startup \n",
    "    \n",
    "    \"\"\"\n",
    "    active_2d_plot_renderable_menus = active_2d_plot.ui.menus.custom_context_menus.add_renderables\n",
    "    widget_2d_menu = active_2d_plot_renderable_menus[0]\n",
    "    menuAdd_Renderable = widget_2d_menu.ui.menuAdd_Renderable\n",
    "    programmatic_actions_dict = widget_2d_menu.programmatic_actions_dict\n",
    "\n",
    "    # add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "    # menu_commands = ['AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.Session.Epochs', 'AddTimeIntervals.Bursts']\n",
    "    # \n",
    "    menu_commands = ['AddTimeIntervals.SessionEpochs', 'AddTimeIntervals.Laps', 'AddTimeIntervals.PBEs','AddTimeIntervals.Replays']\n",
    "    for a_command in menu_commands:\n",
    "        programmatic_actions_dict[a_command].trigger()\n",
    "        \n",
    "    # AddMatplotlibPlot: ['AddMatplotlibPlot.DecodedPosition', 'AddMatplotlibPlot.Custom']\n",
    "    # menu_commands = ['AddTimeCurves.Position', 'AddTimeCurves.Velocity','AddTimeCurves.Random','AddTimeCurves.RelativeEntropySurprise', 'AddTimeCurves.Custom']\n",
    "    menu_commands = ['AddTimeCurves.Position']\n",
    "    for a_command in menu_commands:\n",
    "        programmatic_actions_dict[a_command].trigger()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d3fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot_renderable_menus = active_2d_plot.ui.menus.custom_context_menus.add_renderables\n",
    "widget_2d_menu = active_2d_plot_renderable_menus[0]\n",
    "menuAdd_Renderable = widget_2d_menu.ui.menuAdd_Renderable\n",
    "programmatic_actions_dict = widget_2d_menu.programmatic_actions_dict\n",
    "programmatic_actions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.dynamicPropertyNames()\n",
    "\n",
    "# active_2d_plot.params.time_curves_datasource\n",
    "active_2d_plot.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f760906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.update_rendered_intervals_visualization_properties()\n",
    "interval_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d429a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.clear_all_rendered_intervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd58501",
   "metadata": {},
   "outputs": [],
   "source": [
    "_a_saved_state = active_2d_plot.save_state_active_renderables()\n",
    "_a_saved_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57680498",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EITHER_subset.track_exclusive_aclus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e39b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbde0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.debug_print=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.\n",
    "\n",
    "EITHER_subset.track_exclusive_aclus\n",
    "# , neuron_colors=neuron_colors, neuron_sort_order=neuron_sort_order, application_name=application_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846e84b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.general_helpers import CodeConversion, inspect_callable_arguments\n",
    "from pyphocorehelpers.print_helpers import document_active_variables, print_keys_if_possible, DocumentationFilePrinter\n",
    "\n",
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\DEVELOPER_NOTES\\DataStructureDocumentation'), doc_name='spike_raster_plt_2d.params.config_items')\n",
    "doc_printer.save_documentation('spike_raster_plt_2d.params.config_items', spike_raster_window.spike_raster_plt_2d.params.config_items, non_expanded_item_keys=['_reverse_cellID_index_map', 'pf_listed_colormap', 'computation_results', 'active_configs', 'logger']) # 'Logger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2703e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('spike_raster_plt_2d.params.config_items', spike_raster_window.spike_raster_plt_2d.params.config_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ce291",
   "metadata": {},
   "source": [
    "## Updating SpikeRasterWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2011a",
   "metadata": {
    "tags": [
     "spike_raster_window_defaults"
    ]
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "@define(repr=False)\n",
    "class UpdateRenderState:\n",
    "\t\"\"\" describes specific updates to the rendering.\n",
    "\t\n",
    "\tRepresents a particular set of visual configurations or changes to visual configurations.\n",
    "\t\"\"\"\n",
    "\ton_apply_state: Callable = field() # can be called to update the rendering of the widget.\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a59fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038949a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_active_variables(spike_raster_window.spike_raster_plt_2d.params.config_items, enable_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85802f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "\n",
    "active_pf_2D = global_pf2D\n",
    "## Example 1: De-emphasize spikes excluded from the placefield calculations:\n",
    "is_spike_included_in_pf = np.isin(spike_raster_window.spike_raster_plt_2d.spikes_df.index, active_pf_2D.filtered_spikes_df.index)\n",
    "spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not(is_spike_included_in_pf), SpikeEmphasisState.Deemphasized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84069402",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Toggle Different Emphasis State Settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30524af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnownSpikeEmphasisModes:\n",
    "\tdef deemph_non_placefield_neurons():\n",
    "\t\tactive_pf_2D = global_pf2D\n",
    "\t\t## Example 1: De-emphasize spikes excluded from the placefield calculations:\n",
    "\t\tis_spike_included_in_pf = np.isin(spike_raster_window.spike_raster_plt_2d.spikes_df.index, active_pf_2D.filtered_spikes_df.index)\n",
    "\t\tspike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not(is_spike_included_in_pf), SpikeEmphasisState.Deemphasized)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.EpochRenderingMixin import EpochRenderingMixin\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, Ripples_2DRenderTimeEpochs, inline_mkColor\n",
    "\n",
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.Session.Epochs']\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26350f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interval_info = active_2d_plot.list_all_rendered_intervals() ## get the existing intervals\n",
    "rendered_interval_keys = list(interval_info.keys())\n",
    "desired_interval_height_ratios = [2.0, 2.0, 1.0, 0.1, 1.0, 1.0, 1.0] # ratio of heights to each interval\n",
    "required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout(desired_interval_height_ratios, epoch_render_stack_height=20.0, interval_stack_location='below')\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(rendered_interval_keys, required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(stacked_epoch_layout_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a0f86",
   "metadata": {},
   "source": [
    "# 2023-07-19 - Validation with 3D tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecde32c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "display_output = {}\n",
    "# active_config_name = long_epoch_name\n",
    "active_config_name = global_epoch_name\n",
    "active_config = curr_active_pipeline.active_configs[active_config_name]\n",
    "active_config.plotting_config.should_use_linear_track_geometry = True # indicate that it's a linear track so the better geometry can be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80672dec",
   "metadata": {},
   "source": [
    "# 3D Plotters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f0e7a",
   "metadata": {},
   "source": [
    "## 📣 Programmatically adding several epoch rectangles by calling the addRenderable context menu functions all at once for SpikeRaster2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb05977",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict # {'AddTimeIntervals': {'Laps': <PyQt5.QtWidgets.QAction object at 0x0000015199440160>, 'PBEs': <PyQt5.QtWidgets.QAction object at 0x0000015199440940>, 'SessionEpochs': <PyQt5.QtWidgets.QAction object at 0x0000015199440B80>, 'Ripples': <PyQt5.QtWidgets.QAction object at 0x00000151973D4430>, 'Replays': <PyQt5.QtWidgets.QAction object at 0x00000151973D4280>, 'Bursts': <PyQt5.QtWidgets.QAction object at 0x000001532D179EE0>, 'Custom': <PyQt5.QtWidgets.QAction object at 0x0000015199440F70>}, 'AddTimeCurves': {'Position': <PyQt5.QtWidgets.QAction object at 0x0000015199440DC0>, 'Velocity': <PyQt5.QtWidgets.QAction object at 0x000001532D179040>, 'Random': <PyQt5.QtWidgets.QAction object at 0x00000151994403A0>, 'RelativeEntropySurprise': <PyQt5.QtWidgets.QAction object at 0x000001532D179310>, 'Custom': <PyQt5.QtWidgets.QAction object at 0x0000015199440C10>}, 'AddMatplotlibPlot': {'DecodedPosition': <PyQt5.QtWidgets.QAction object at 0x00000151973D4EE0>, 'Custom': <PyQt5.QtWidgets.QAction object at 0x00000151973D4B80>}, 'Clear': {'all': {'Time': {'Curves': <PyQt5.QtWidgets.QAction object at 0x0000015199440310>, 'Intervals': <PyQt5.QtWidgets.QAction object at 0x00000151973D4700>}, 'Matplotlib': {'Plots': <PyQt5.QtWidgets.QAction object at 0x00000151973D44C0>}, 'Renderables': <PyQt5.QtWidgets.QAction object at 0x00000151973D4790>}}}\n",
    "add_renderables_menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce852133",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(add_renderables_menu.keys()) # ['AddTimeIntervals', 'AddTimeCurves', 'AddMatplotlibPlot', 'Clear']\n",
    "list(add_renderables_menu['AddTimeIntervals'].keys()) # ['Laps', 'PBEs', 'SessionEpochs', 'Ripples', 'Replays', 'Bursts', 'Custom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_commands = ['AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.Session.Epochs', 'AddTimeIntervals.Bursts']\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, Ripples_2DRenderTimeEpochs, inline_mkColor\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.epochs_plotting_mixins import EpochDisplayConfig\n",
    "\n",
    "# interval_info = active_2d_plot.list_all_rendered_intervals() ## get the existing intervals\n",
    "\n",
    "## Inline Concise: Position Replays, PBEs, and Ripples all below the scatter:\n",
    "# active_2d_plot.interval_datasources.Replays.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-10.0, height=7.5, pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5), **kwargs)) ## Fully inline\n",
    "# active_2d_plot.interval_datasources.PBEs.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-2.0, height=1.5, pen_color=inline_mkColor('pink', 0.8), brush_color=inline_mkColor('pink', 0.5), **kwargs)) ## Fully inline\n",
    "# active_2d_plot.interval_datasources.Ripples.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5), **kwargs)) ## Fully inline\n",
    "# active_2d_plot.interval_datasources.SessionEpochs .update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5), **kwargs)) ## Fully inline\n",
    "# epochs_update_dict = {\n",
    "#     'Replays':dict(y_location=-10.0, height=7.5, pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5)),\n",
    "#     'PBEs':dict(y_location=-2.0, height=1.5, pen_color=inline_mkColor('pink', 0.8), brush_color=inline_mkColor('pink', 0.5)),\n",
    "#     'Ripples':dict(y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5)),\n",
    "#     'SessionEpochs':dict(y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5)),\n",
    "# }\n",
    "# epochs_update_dict = {k:EpochDisplayConfig.init_from_config_dict(name=k, config_dict=v) for k,v in epochs_update_dict.items()}\n",
    "# epochs_update_dict\n",
    "\n",
    "\n",
    "epochs_update_dict = {\n",
    "\t# 'SessionEpochs': EpochDisplayConfig(brush_color='#00ffff', brush_opacity=0.5, name='SessionEpochs', pen_color='#00ffff', pen_opacity=0.8, height=1.5, y_location=-12.0),\n",
    "\t'Laps': EpochDisplayConfig(brush_color='#ff0000', brush_opacity=0.5, name='Laps', pen_color='#ff0000', pen_opacity=0.8, height=0.9, y_location=-2.0),\t\n",
    "\t'PBEs': EpochDisplayConfig(brush_color='#ffc0cb', brush_opacity=0.5, name='PBEs', pen_color='#ffc0cb', pen_opacity=0.8, height=1.5, y_location=-2.0),\n",
    "\t'Ripples': EpochDisplayConfig(brush_color='#6e00f5', brush_opacity=0.5, name='Ripples', pen_color='#6e00f5', pen_opacity=0.8, height=1.5, y_location=-12.0),\n",
    "\t'Replays': EpochDisplayConfig(brush_color='#ffa500', brush_opacity=0.5, name='Replays', pen_color='#ffa500', pen_opacity=0.8, height=7.5, y_location=-10.0), \n",
    "}\n",
    "\n",
    "epochs_update_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad2ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike_raster_window\n",
    "epochs_list = active_2d_plot.list_all_rendered_intervals()\n",
    "epochs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd240080",
   "metadata": {},
   "source": [
    "## 🪟 ipcDataExplorer - 3D Interactive Tuning Curves Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5568d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict\n",
    "\n",
    "'_display_3d_image_plotter'\n",
    "'_display_long_short_laps'\n",
    "'_display_3d_interactive_custom_data_explorer'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveDataExplorerBase import InteractiveDataExplorerBase\n",
    "# from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer # TypeError: super(type, obj): obj must be an instance or subtype of type\n",
    "\n",
    "active_config_name = global_epoch_context\n",
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "# _out = curr_active_pipeline.display('_display_3d_interactive_custom_data_explorer', long_epoch_name) # long_epoch_context\n",
    "display_dict = curr_active_pipeline.display('_display_3d_interactive_custom_data_explorer', active_config_name) # does not work, missing color info?\n",
    "iplapsDataExplorer = display_dict['iplapsDataExplorer']\n",
    "# plotter is available at\n",
    "p = display_dict['plotter']\n",
    "iplapsDataExplorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ac39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "# df = pd.DataFrame([curr_active_pipeline.registered_display_function_docs_dict])\n",
    "# df = curr_active_pipeline.registered_display_function_docs_dict\n",
    "df = pd.DataFrame.from_dict(curr_active_pipeline.registered_display_function_docs_dict, orient='index', columns=['Value'])\n",
    "display_widget = widgets.Output()\n",
    "with display_widget:\n",
    "\tdisplay(df)\n",
    "display_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import plot_position_curves_figure\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_long_short_laps', active_identifying_session_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# _out3 = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', included_epoch_indicies=None, save_figure=False)\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=False, included_epoch_indicies=selection_idxs_L[:50], enable_radon_transform_info=False, max_subplots_per_page=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_stacked_epoch_graphics.figures[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b3d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination_controller_L, pagination_controller_S = example_stacked_epoch_graphics.plot_data['controllers']\n",
    "ax_L, ax_S = example_stacked_epoch_graphics.axes\n",
    "final_figure_context_L, final_context_S = example_stacked_epoch_graphics.context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_3d\n",
    "# ## single_combined_plot == True mode (mode 1.):\n",
    "# p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=True)\n",
    "# p.show()\n",
    "\n",
    "## single_combined_plot == False mode (mode 2.):        \n",
    "p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=False, curr_num_subplots=len(curr_active_pipeline.sess.laps.lap_id), active_page_index=0)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ec90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_2d\n",
    "\n",
    "p_laps_2D, axs_laps_2D, laps_2D_pages = plot_lap_trajectories_2d(curr_active_pipeline.sess, curr_num_subplots=5, active_page_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ddaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_laps_2D.suptitle('plot_lap_trajectories_2d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c4da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = axs_laps_2D[0,0]\n",
    "ax_empty = axs_laps_2D[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_position_offset = 1.0 * long_track_dims.compute_position_offset(grid_bin_bounds=grid_bin_bounds) # array([49.43, 140.61])\n",
    "long_track_position_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_bin_bounds_center_point = (point_tuple_mid_point(grid_bin_bounds[0]), point_tuple_mid_point(grid_bin_bounds[1])) # (145.43, 140.61)\n",
    "print(f'grid_bin_bounds_center_point: {grid_bin_bounds_center_point}')\n",
    "x_midpoint, y_midpoint = grid_bin_bounds_center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77188bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_annotation_man = UserAnnotationsManager()\n",
    "user_annotations = user_annotation_man.annotations # .get_user_annotations()\n",
    "\n",
    "allow_interactive_selection = False\n",
    "\n",
    "final_context_L = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj')\n",
    "final_context_S = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj')\n",
    "# _out_pagination_controller.params.active_identifying_figure_ctx.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_L = final_context_L.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_S = final_context_S.adding_context(None,  user_annotation=\"selections\")\n",
    "\n",
    "## try to get the user annotations for this session:\n",
    "try:\n",
    "\tselection_idxs_L = user_annotations[selections_context_L]\n",
    "\tselection_idxs_S = user_annotations[selections_context_S]\n",
    "except KeyError as e:\n",
    "\tif allow_interactive_selection:\n",
    "\t\tprint(f'user annotations <good replay selections> are not found. Creating them interactively...')\n",
    "\t\tuser_annotations = interactive_good_epoch_selections(annotations_man=user_annotation_man, curr_active_pipeline=curr_active_pipeline)  # perform interactive selection. Should block here.\n",
    "\t\tselection_idxs_L = user_annotations[selections_context_L]\n",
    "\t\tselection_idxs_S = user_annotations[selections_context_S]\n",
    "\telse:\n",
    "\t\tprint(f'interactive annotation is not permitted. Failing.')\n",
    "\t\traise e\n",
    "except Exception as e:\n",
    "\tprint('Unhandled exception: {e}')\n",
    "\traise\n",
    "\n",
    "\n",
    "(selection_idxs_L, selection_idxs_S)\n",
    "# # for updating the filter_epochs_df (`filter_epochs_df`) from the selections:\n",
    "# self.filter_epochs_df['long_is_user_included'] = np.isin(self.filter_epochs_df.index, selection_idxs_L)\n",
    "# self.filter_epochs_df['short_is_user_included'] = np.isin(self.filter_epochs_df.index, selection_idxs_S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices_paginated, plot_decoded_epoch_slices, _subfn_update_decoded_epoch_slices\n",
    "\n",
    "\n",
    "## Stacked Epoch Plot\n",
    "defer_render=False\n",
    "save_figure=False\n",
    "included_epoch_indicies=selection_idxs_L[:50]\n",
    "enable_radon_transform_info=False\n",
    "max_subplots_per_page=25\n",
    "kwargs = {}\n",
    "\n",
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "## Extract variables from results object:\n",
    "long_results_obj, short_results_obj = curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "pagination_controller_L, active_out_figure_paths_L, final_context_L = plot_decoded_epoch_slices_paginated(curr_active_pipeline, long_results_obj, curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj'), included_epoch_indicies=included_epoch_indicies, save_figure=save_figure, **kwargs)\n",
    "fig_L = pagination_controller_L.plots.fig\n",
    "ax_L = fig_L.get_axes()\n",
    "if defer_render:\n",
    "\twidget_L = pagination_controller_L.ui.mw # MatplotlibTimeSynchronizedWidget\n",
    "\twidget_L.close()\n",
    "\tpagination_controller_L = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b89982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _subfn_update_decoded_epoch_slices(params, plots_data, plots, ui, debug_print=False):\n",
    "    \"\"\" attempts to update existing plots created by:\n",
    "    \n",
    "       params, plots_data, plots, ui = stacked_epoch_slices_matplotlib_build_view(epoch_slices, epoch_labels=epoch_labels, name=name, plot_function_name=plot_function_name, debug_test_max_num_slices=debug_test_max_num_slices, debug_print=debug_print)\n",
    "\n",
    "       Requires: `plots_data.filter_epochs_decoder_result`\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, curr_ax in enumerate(plots.axs):\n",
    "        curr_time_bin_container = plots_data.filter_epochs_decoder_result.time_bin_containers[i]\n",
    "        curr_time_bins = curr_time_bin_container.centers\n",
    "        curr_posterior_container = plots_data.filter_epochs_decoder_result.marginal_x_list[i]\n",
    "        curr_posterior = curr_posterior_container.p_x_given_n\n",
    "        curr_most_likely_positions = curr_posterior_container.most_likely_positions_1D\n",
    "        \n",
    "        params, plots_data, plots, ui = _helper_update_decoded_single_epoch_slice_plot(curr_ax, params, plots_data, plots, ui, i, curr_time_bins, curr_posterior, curr_most_likely_positions, debug_print=debug_print)\n",
    "        on_render_page_callbacks = params.get('on_render_page_callbacks', {})\n",
    "        for a_callback_name, a_callback in on_render_page_callbacks.items():\n",
    "            try:\n",
    "                params, plots_data, plots, ui = a_callback(curr_ax, params, plots_data, plots, ui, i, curr_time_bins, curr_posterior, curr_most_likely_positions, debug_print=debug_print)\n",
    "            except Exception as e:\n",
    "                print(f'\\t encountered exception in callback: {e}')\n",
    "                pass            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0190db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pagination_controller_S, active_out_figure_paths_S, final_context_S = plot_decoded_epoch_slices_paginated(curr_active_pipeline, short_results_obj, curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj'), included_epoch_indicies=included_epoch_indicies, save_figure=save_figure, **kwargs)\n",
    "fig_S = pagination_controller_S.plots.fig\n",
    "ax_S = fig_S.get_axes()\n",
    "if defer_render:\n",
    "\twidget_S = pagination_controller_S.ui.mw # MatplotlibTimeSynchronizedWidget\n",
    "\twidget_S.close()\n",
    "\tpagination_controller_S = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a222ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from neuropy.utils.mixins.binning_helpers import transition_matrix\n",
    "\n",
    "### 1D Transition Matrix:\n",
    "\n",
    "def _compute_position_transition_matrix(xbin_labels, binned_x: np.ndarray, n_powers:int=3):\n",
    "\t\"\"\"  1D Transition Matrix from binned positions (e.g. 'binned_x')\n",
    "\n",
    "\t\tpf1D.xbin_labels # array([  1,   2,   3,   4,  ...)\n",
    "\t\tpf1D.filtered_pos_df['binned_x'].to_numpy() # array([116, 115, 115, ...,  93,  93,  93], dtype=int64)\n",
    "\t\"\"\"\n",
    "\tnum_position_states = len(xbin_labels)\n",
    "\t# binned_x = pos_1D.to_numpy()\n",
    "\tbinned_x_indicies = binned_x - 1\n",
    "\tbinned_x_transition_matrix = transition_matrix(deepcopy(binned_x_indicies), markov_order=1, max_state_index=num_position_states)\n",
    "\t# binned_x_transition_matrix_higher_order_list = [binned_x_transition_matrix, transition_matrix(deepcopy(binned_x_indicies), markov_order=2, max_state_index=num_position_states), transition_matrix(deepcopy(binned_x_indicies), markov_order=3, max_state_index=num_position_states)]\n",
    "\n",
    "\tbinned_x_transition_matrix[np.isnan(binned_x_transition_matrix)] = 0.0\n",
    "\tbinned_x_transition_matrix_higher_order_list = [binned_x_transition_matrix] + [np.linalg.matrix_power(binned_x_transition_matrix, n) for n in np.arange(2, n_powers+1)]\n",
    "\t# , np.linalg.matrix_power(binned_x_transition_matrix, 2), np.linalg.matrix_power(binned_x_transition_matrix, 3)\n",
    "\t# binned_x_transition_matrix.shape # (64, 64)\n",
    "\treturn binned_x_transition_matrix_higher_order_list\n",
    "\n",
    "def _build_decoded_positions_transition_matrix(active_one_step_decoder):\n",
    "\t\"\"\" Compute the transition_matrix from the decoded positions \n",
    "\n",
    "\tTODO: make sure that separate events (e.g. separate replays) are not truncated creating erronious transitions\n",
    "\n",
    "\t\"\"\"\n",
    "\t# active_time_window_variable = active_one_step_decoder.time_window_centers # get time window centers (n_time_window_centers,) # (4060,)\n",
    "\t# active_most_likely_positions = active_one_step_decoder.most_likely_positions.T # (4060, 2) NOTE: the most_likely_positions for the active_one_step_decoder are tranposed compared to the active_two_step_decoder\n",
    "\t# active_most_likely_positions = active_two_step_decoder.most_likely_positions # (2, 4060)\n",
    "\tactive_one_step_decoder.most_likely_position_flat_indicies\n",
    "\t# active_most_likely_positions = active_one_step_decoder.revised_most_likely_positions.T\n",
    "\t# active_most_likely_positions #.shape # (36246,)\n",
    "\n",
    "\tmost_likely_position_indicies = np.squeeze(np.array(np.unravel_index(active_one_step_decoder.most_likely_position_flat_indicies, active_one_step_decoder.original_position_data_shape))) # convert back to an array\n",
    "\tmost_likely_position_xbins = most_likely_position_indicies + 1 # add 1 to convert back to a bin label from an index\n",
    "\t# most_likely_position_indicies # (1, 36246)\n",
    "\n",
    "\txbin_labels = np.arange(active_one_step_decoder.original_position_data_shape[0]) + 1\n",
    "\n",
    "\tdecoded_binned_x_transition_matrix_higher_order_list = _compute_position_transition_matrix(xbin_labels, most_likely_position_indicies)\n",
    "\treturn decoded_binned_x_transition_matrix_higher_order_list, xbin_labels\n",
    "\n",
    "\n",
    "# pf1D = deepcopy(curr_active_pipeline.computation_results['maze1'].computed_data['pf1D'])\n",
    "pf1D = deepcopy(global_pf1D)\n",
    "# pf1D = deepcopy(short_pf1D)\n",
    "# pf1D = deepcopy(long_pf1D)\n",
    "binned_x_transition_matrix_higher_order_list = _compute_position_transition_matrix(pf1D.xbin_labels, pf1D.filtered_pos_df['binned_x'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1D.filtered_pos_df.plot(x='t',y='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb355dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization ______________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "out = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[0], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix', title=\"Transition Matrix for binned x (from, to)\", variable_label='Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n",
    "# out.add_data(row=1, col=0, matrix=active_eloy_analysis.pf_overlapDensity_2D, xbins=active_pf_2D_dt.xbin_labels, ybins=active_pf_2D_dt.ybin_labels, name='pf_overlapDensity', title='pf overlapDensity metric', variable_label='pf overlapDensity')\n",
    "\n",
    "# out.add_data(row=1, col=0, matrix=binned_x_transition_matrix_higher_order_list[1], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^2', title='2nd Order Transition Matrix for binned x (from, to)', variable_label='2nd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n",
    "# out.add_data(row=2, col=0, matrix=binned_x_transition_matrix_higher_order_list[2], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^3', title='3rd Order Transition Matrix for binned x (from, to)', variable_label='3rd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n",
    "\n",
    "# Separate Windows for each:\n",
    "# out2 = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[1], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix^2', title=\"2nd Order Transition Matrix for binned x (from, to)\", variable_label='2nd Order Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n",
    "# out3 = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[2], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix^3', title=\"3rd Order Transition Matrix for binned x (from, to)\", variable_label='3rd Order Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e5f54",
   "metadata": {},
   "source": [
    "# 1. Compute the transition_matrix from the decoded positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e5db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayesianPlacemapPositionDecoder\n",
    "# active_one_step_decoder = deepcopy(long_one_step_decoder_1D) # long_results_obj.original_1D_decoder\n",
    "long_decoded_binned_x_transition_matrix_higher_order_list, long_xbin_labels = _build_decoded_positions_transition_matrix(active_one_step_decoder=deepcopy(long_one_step_decoder_1D))\n",
    "short_decoded_binned_x_transition_matrix_higher_order_list, short_xbin_labels = _build_decoded_positions_transition_matrix(active_one_step_decoder=deepcopy(short_one_step_decoder_1D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcddd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_decoded = BasicBinnedImageRenderingWindow(decoded_binned_x_transition_matrix_higher_order_list[0], active_one_step_decoder.xbin_centers, active_one_step_decoder.xbin_centers, name='decoded_binned_x_transition_matrix', title=\"DECODED Transition Matrix for binned x (from, to)\", variable_label='Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea34522",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "out = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[i], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix', title=\"Transition Matrix for binned x (from, to)\", variable_label='Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n",
    "out.add_data(row=1, col=0, matrix=long_decoded_binned_x_transition_matrix_higher_order_list[i], xbins=long_xbin_labels, ybins=long_xbin_labels, name='long_decoded_binned_x_transition_matrix', title='Long DECODED Transition Matrix', variable_label='long decoded')\n",
    "out.add_data(row=2, col=0, matrix=short_decoded_binned_x_transition_matrix_higher_order_list[i], xbins=short_xbin_labels, ybins=short_xbin_labels, name='short_decoded_binned_x_transition_matrix', title='Short DECODED Transition Matrix', variable_label='short decoded')\n",
    "# out.add_data(row=1, col=0, matrix=binned_x_transition_matrix_higher_order_list[1], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^2', title='2nd Order Transition Matrix for binned x (from, to)', variable_label='2nd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n",
    "# out.add_data(row=2, col=0, matrix=binned_x_transition_matrix_higher_order_list[2], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^3', title='3rd Order Transition Matrix for binned x (from, to)', variable_label='3rd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.most_likely_position_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 2. Use the position transition matrix to determine how likely each decoded position's transition is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87cd169",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_binned_instantaneous_unit_specific_spike_rate = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.time_binned_instantaneous_unit_specific_spike_rate\n",
    "timestamps = time_binned_instantaneous_unit_specific_spike_rate.time_bins\n",
    "\n",
    "value_df = time_binned_instantaneous_unit_specific_spike_rate.instantaneous_unit_specific_spike_rate_values\n",
    "value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0807be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of spikes version:\n",
    "time_binned_unit_specific_spike_rate = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.time_binned_unit_specific_spike_rate\n",
    "timestamps = time_binned_unit_specific_spike_rate.time_bins\n",
    "value_df = time_binned_unit_specific_spike_rate.time_binned_unit_specific_binned_spike_rate\n",
    "value_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7320ac",
   "metadata": {},
   "source": [
    "# LauncherWidget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph import QtWidgets, QtCore, QtGui\n",
    "from pyphocorehelpers.gui.Qt.ExceptionPrintingSlot import pyqtExceptionPrintingSlot\n",
    "from pyphoplacecellanalysis.GUI.Qt.MainApplicationWindows.LauncherWidget.LauncherWidget import LauncherWidget\n",
    "\n",
    "widget = LauncherWidget()\n",
    "treeWidget = widget.mainTreeWidget # QTreeWidget\n",
    "widget.build_for_pipeline(curr_active_pipeline=curr_active_pipeline)\n",
    "widget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefa4d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_obj = curr_active_pipeline.plot\n",
    "plot_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c288ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_obj._display_spike_rasters_pyqtplot_2D('maze_any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_context = curr_active_pipeline.filtered_contexts['maze_any']\n",
    "found_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ad0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_active_pipeline.computation_results[found_context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e432510",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(curr_active_pipeline.computation_results.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b14556",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(curr_active_pipeline.active_configs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e754ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(curr_active_pipeline.filtered_epochs.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(curr_active_pipeline.filtered_sessions.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5974c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(curr_active_pipeline.display_output.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f7cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20370a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_fcn_items_dict = widget.get_display_function_items()\n",
    "display_fcn_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f1f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "{a_fn_name:a_fn.is_global for a_fn_name, a_fn in curr_active_pipeline.registered_display_function_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_contexts['maze_any']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e27a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b231bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.active_config_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b319c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "curr_active_pipeline.display('_display_spike_rasters_pyqtplot_2D', curr_active_pipeline.filtered_contexts['maze_any'])\n",
    "# curr_active_pipeline.display('_display_spike_rasters_pyqtplot_2D', 'maze_any') # AssertionError: ERROR: The display function with the name _display_spike_rasters_pyqtplot_2D  could not be found! Is it registered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec410ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('spike_rasters_pyqtplot_2D') # AssertionError: ERROR: The display function with the name _display_spike_rasters_pyqtplot_2D  could not be found! Is it registered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3663c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_display_output = display_function(self.computation_results[active_session_configuration_name], self.active_configs[active_session_configuration_name], owning_pipeline=self, active_config_name=active_session_configuration_name, **kwargs)\n",
    "# TypeError: _display_context_nested_docks() missing 2 required positional arguments: 'computation_results' and 'active_configs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_1d_placefields', 'maze1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9914d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_obj.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee39c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_obj._display_grid_bin_bounds_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d29dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_obj._display_1d_placefields()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3693c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_obj._display_2d_placefield_result_plot_ratemaps_2D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c439ff5f",
   "metadata": {},
   "source": [
    "# 2023-10-19 - Home - Widget Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a73238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import stacked_epoch_slices_matplotlib_build_view \n",
    "## TODO: stacked_epoch_slices_matplotlib_build_view should be replaced with plot_decoded_epoch_slices:\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices\n",
    "\n",
    "### Two Step Decoder Plotting:\n",
    "plot_function_name = 'Stacked Epoch Slices View - MATPLOTLIB subplots Version'\n",
    "active_two_step_containers = stacked_epoch_slices_matplotlib_build_view(epoch_slices, name='Two Step Stacked Epoch Slices View (MATPLOTLIB)', plot_function_name=plot_function_name, debug_test_max_num_slices=debug_test_max_num_slices, debug_print=False)\n",
    "# Unpack:\n",
    "active_two_step_params, active_two_step_plots_data, active_two_step_plots, active_two_step_ui = active_two_step_containers\n",
    "# active_two_step_containers.axs\n",
    "\n",
    "## Test Plotting just a single dimension of the 2D posterior:\n",
    "pho_active_two_step_custom_decoder = active_two_step_decoder\n",
    "active_two_step_posterior = pho_active_two_step_custom_decoder.p_x_given_n_and_x_prev\n",
    "# Collapse the 2D position posterior into two separate 1D (X & Y) marginal posteriors. Be sure to re-normalize each marginal after summing\n",
    "active_two_step_marginal_posterior_x = np.squeeze(np.sum(active_two_step_posterior, 1)) # sum over all y. Result should be [x_bins x time_bins]\n",
    "active_two_step_marginal_posterior_x = active_two_step_marginal_posterior_x / np.sum(active_two_step_marginal_posterior_x, axis=0) # sum over all positions for each time_bin (so there's a normalized distribution at each timestep)\n",
    "for i, curr_ax in enumerate(active_two_step_plots.axs):\n",
    "    active_two_step_plots.fig, curr_ax = plot_1D_most_likely_position_comparsions(sess.position.to_dataframe(), ax=curr_ax, time_window_centers=pho_custom_decoder.active_time_window_centers, xbin=pho_custom_decoder.xbin,\n",
    "                                                       posterior=active_two_step_marginal_posterior_x,\n",
    "                                                       active_most_likely_positions_1D=active_two_step_decoder.most_likely_positions.T[:,0].T,\n",
    "                                                       enable_flat_line_drawing=enable_flat_line_drawing, debug_print=False)\n",
    "    curr_ax.set_xlim(*active_two_step_plots_data.epoch_slices[i,:])\n",
    "    curr_ax.set_title('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d308f559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deee69d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.IdentifyingContextSelector.IdentifyingContextSelectorWidget import IdentifyingContextSelectorWidget\n",
    "\n",
    "widget = IdentifyingContextSelectorWidget(owning_pipeline=curr_active_pipeline, enable_multi_context_select=False)\n",
    "widget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# widget.all_filtered_session_context_descriptions\n",
    "widget.updateUi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f520b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_filtered_session_context_descriptions = [a_context.get_description() for a_context in curr_active_pipeline.filtered_contexts.values()] \n",
    "all_filtered_session_context_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb4d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PendingNotebookCode import display_all_eloy_pf_density_measures_results\n",
    "    \n",
    "\n",
    "out_all_eloy_pf_density_fig = display_all_eloy_pf_density_measures_results(global_pf2D, active_eloy_analysis, active_simpler_pf_densities_analysis, active_peak_prominence_2d_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345871dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_aclus_only_neuron_IDs\n",
    "\n",
    "plot = curr_active_pipeline.plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_active_pipeline.registered_display_function_docs_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db5fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-10-18 - This surprisingly works!\n",
    "curr_display_function_name = '_display_pf_peak_prominence2d_plots'\n",
    "figure, ax = curr_active_pipeline.display(curr_display_function_name, active_config_name, neuron_id=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_2d\n",
    "# Complete Version:\n",
    "fig, axs, laps_pages = plot_lap_trajectories_2d(curr_active_pipeline.sess, curr_num_subplots=len(curr_active_pipeline.sess.laps.lap_id), active_page_index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af09d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_display_function_name = '_display_pf_peak_prominence2d_plots'\n",
    "figure, ax = curr_active_pipeline.display(curr_display_function_name, active_config_name, neuron_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f894c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pActiveTuningCurvesPlotter = None\n",
    "display_output = display_output | curr_active_pipeline.display('_display_3d_interactive_tuning_curves_plotter', active_config_name, extant_plotter=display_output.get('pActiveTuningCurvesPlotter', None), panel_controls_mode='Qt', should_nan_non_visited_elements=False, zScalingFactor=2000.0) # Works now!\n",
    "ipcDataExplorer = display_output['ipcDataExplorer']\n",
    "display_output['pActiveTuningCurvesPlotter'] = display_output.pop('plotter') # rename the key from the generic \"plotter\" to \"pActiveSpikesBehaviorPlotter\" to avoid collisions with others\n",
    "pActiveTuningCurvesPlotter = display_output['pActiveTuningCurvesPlotter']\n",
    "root_dockAreaWindow, placefieldControlsContainerWidget, pf_widgets = display_output['pane'] # for Qt mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd0a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho3D.PyVista.peak_prominences import render_all_neuron_peak_prominence_2d_results_on_pyvista_plotter\n",
    "\n",
    "active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "render_all_neuron_peak_prominence_2d_results_on_pyvista_plotter(ipcDataExplorer, active_peak_prominence_2d_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da3df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.widget_positioning_helpers import WidgetPositioningHelpers\n",
    "\n",
    "WidgetPositioningHelpers.move_widget_to_top_left_corner(placefieldControlsContainerWidget, screen_index=None, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9bae07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
