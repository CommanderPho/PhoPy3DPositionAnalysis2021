{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84413466-6942-4870-a5ac-559ccc21d51e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24458397-c844-41ed-85de-034ed4b87e72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.output_area pre {white-space: pre;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      \n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.0.min.js\", \"https://unpkg.com/@holoviz/panel@0.12.4/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.12.4/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.12.4/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.12.4/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.12.4/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.12.4/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.12.4/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.12.4/dist/css/widgets.css\"];\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\")\\n    }\\n    \");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, js_modules, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      \n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.0.min.js\", \"https://unpkg.com/@holoviz/panel@0.12.4/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.12.4/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.12.4/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.12.4/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.12.4/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.12.4/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.12.4/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.12.4/dist/css/widgets.css\"];\n  var inline_js = [\n    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\")\\n    }\\n    \");\n    },\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: pho\n",
    "\"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import importlib\n",
    "from threading import Thread\n",
    "import time # for time.sleep\n",
    "from ipygany import PolyMesh, Scene, IsoColor, WarpByScalar\n",
    "import pyvista as pv\n",
    "# from pyvista import _vtk\n",
    "import pyvistaqt as pvqt\n",
    "import colorcet as cc # Colormaps:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import hdf5storage # conda install hdf5storage\n",
    "from pathlib import Path\n",
    "import bqplot.scales\n",
    "import seaborn as sns\n",
    "\n",
    "#interactive plotting in separate window\n",
    "# %matplotlib qt\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "# %matplotlib widget\n",
    "# %matplotlib qt\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "# %matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize, to_rgba_array\n",
    "from matplotlib.figure import Figure\n",
    "# import mplcursors\n",
    "import math # For color map generation\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.cm import hsv\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import ipywidgets as widgets\n",
    "# from PyQt5 import QtWidgets, uic\n",
    "from pyvistaqt import QtInteractor, MainWindow\n",
    "# from pyqt6 import QApplication\n",
    "from IPython.external.qt_for_kernel import QtGui\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_area pre {white-space: pre;}</style>\"))\n",
    "from IPython.lib.pretty import pretty, pprint\n",
    "# from pretty import pprint\n",
    "\n",
    "# Pandas display options\n",
    "# pd.set_option('display.max_columns', None)  # or 1000\n",
    "# pd.set_option('display.max_rows', None)  # or 1000\n",
    "# pd.set_option('display.max_colwidth', -1)  # or 199\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "import rich as rich\n",
    "# from rich import inspect\n",
    "# from rich import print\n",
    "# from rich import pretty\n",
    "\n",
    "from PyQt5.QtWidgets import QApplication\n",
    "import datetime as dt\n",
    "\n",
    "import panel as pn\n",
    "from panel.interact import interact, interactive, fixed, interact_manual\n",
    "from panel import widgets\n",
    "pn.extension()\n",
    "# pn.extension('tabulator')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7773a93a-d1a0-4403-93dd-755468f86751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuropy module not found, adding directory to sys.path. \n",
      " >> Updated sys.path.\n"
     ]
    }
   ],
   "source": [
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "try:\n",
    "    from neuropy import core\n",
    "    importlib.reload(core)\n",
    "except ImportError:\n",
    "    sys.path.append(r'C:\\Users\\Pho\\repos\\NeuroPy') # Windows\n",
    "    # sys.path.append('/home/pho/repo/BapunAnalysis2021/NeuroPy') # Linux\n",
    "    # sys.path.append(r'/Users/pho/repo/Python Projects/NeuroPy') # MacOS\n",
    "    print('neuropy module not found, adding directory to sys.path. \\n >> Updated sys.path.')\n",
    "    from neuropy import core\n",
    "# from neuropy.core.session.dataSession import SessionConfig, DataSessionLoader, DataSession, processDataSssion\n",
    "\n",
    "# import neuropy.core as core\n",
    "from neuropy.core.session.data_session_loader import DataSessionLoader\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.core.epoch import Epoch\n",
    "from neuropy.core.epoch import NamedTimerange\n",
    "from neuropy.core import Laps\n",
    "from neuropy.core import Position\n",
    "from neuropy.core import FlattenedSpiketrains\n",
    "from neuropy.core import Neurons\n",
    "from neuropy.utils.misc import print_seconds_human_readable\n",
    "from neuropy.plotting import plot_raster\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.analyses.laps import estimate_laps, compute_laps_spike_indicies\n",
    "from neuropy.analyses.pho_custom_placefields import PfND\n",
    "from neuropy.plotting.placemaps import plot_all_placefields\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c9bf0a-6bd0-4ec2-b11a-7c510c05cdce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'perform_compute_placefields' from 'neuropy.analyses' (C:\\Users\\Pho\\repos\\NeuroPy\\neuropy\\analyses\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12540/388247069.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPhoPositionalData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteractive_placeCell_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_subsession_neuron_differences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mPendingNotebookCode\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdebug_print_spike_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_placefields_as_needed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_configs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_units_colormap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_placefield_multiplotter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess_by_good_placefields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimation_session_laps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\repos\\PhoPy3DPositionAnalysis2021\\PendingNotebookCode.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mneuropy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLaps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mneuropy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyses\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mperform_compute_placefields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mneuropy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplacefields\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPlacefieldComputationParameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mneuropy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaps\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimate_laps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_laps_spike_indicies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'perform_compute_placefields' from 'neuropy.analyses' (C:\\Users\\Pho\\repos\\NeuroPy\\neuropy\\analyses\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# import PhoPositionalData as pdp\n",
    "# from PhoPositionalData import load_exported, process_data\n",
    "from PhoPositionalData.load_exported import *\n",
    "# from PhoPositionalData.process_data import process_positionalAnalysis_data, gen_2d_histrogram, get_heatmap_color_vectors, process_chunk_equal_poritions_data, extract_spike_timeseries\n",
    "from PhoPositionalData.process_data import *\n",
    "from PhoPositionalData.plot_data import *\n",
    "from PhoPositionalData.plotting.animations import * # make_mp4_from_plotter\n",
    "from PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "from PhoPositionalData.import_data import * # build_spike_positions_list, build_cellID_reverse_lookup_map\n",
    "from PhoPositionalData.analysis.interactive_placeCell_config import InteractivePlaceCellConfig, VideoOutputModeConfig, PlottingConfig\n",
    "from PhoPositionalData.analysis.interactive_placeCell_config import print_subsession_neuron_differences\n",
    "\n",
    "from PendingNotebookCode import debug_print_spike_counts, compute_placefields_as_needed, build_configs, build_units_colormap, build_placefield_multiplotter, process_by_good_placefields, estimation_session_laps, partition\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a916f3f-99e0-478d-9d7f-69277134ab48",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Session Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf0e92-3d50-44b8-97b8-eaf34490af9d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KDiba Old Format:\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "# R:\\data\\KDIBA\\gor01\\one\\IIDataMat_Export_ToPython_2021_11_23.m\n",
    "# From pre-computed .mat files:\n",
    "# 07: \n",
    "basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53'\n",
    "# # ## 08:\n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15'\n",
    "sess = DataSessionLoader.kdiba_old_format_session(basedir)\n",
    "active_sess_config = sess.config\n",
    "session_name = sess.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a19d4c-9b1f-4508-9650-5e4dc212aa5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sess.spikes_df.size # (1014937, 18)\n",
    "# np.sum(sess.neurons.n_spikes) # 1014937\n",
    "print('session dataframe spikes: {}\\nsession.neurons.n_spikes summed: {}\\n'.format(sess.spikes_df.shape, np.sum(sess.neurons.n_spikes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de3d37-775b-485b-9f59-44f687c7731b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Estimate the Session's Laps data using my algorithm from the loaded position data.\n",
    "sess = estimation_session_laps(sess)\n",
    "# plot_laps_2d(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114dd37e-24e6-4369-8c40-58d01765141b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "debug"
    ]
   },
   "source": [
    "### Lap Specific Session Debugging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553ba0ab-e4bd-4afb-903b-7be256fd1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_specific_epochs = sess.laps.as_epoch_obj()\n",
    "# lap_specific_epochs.to_dataframe()\n",
    "any_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(len(sess.laps.lap_id))])\n",
    "even_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(0, len(sess.laps.lap_id), 2)])\n",
    "odd_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(1, len(sess.laps.lap_id), 2)])\n",
    "\n",
    "# rich.inspect(lap_specific_epochs)\n",
    "# even_lap_specific_epochs\n",
    "# lap_specific_epochs\n",
    "# pretty(lap_specific_epochs)\n",
    "# pprint(lap_specific_epochs)\n",
    "# pretty(lap_specific_epochs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7aeaa7-ec07-4f3d-b665-2874cd4a589f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Filter Session by Epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2582c6eb-bf20-4c7d-ad47-f551fc352471",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.epochs.t_start = 22.26 # exclude the first short period where the animal isn't on the maze yet\n",
    "# sess.epochs.to_dataframe()\n",
    "# active_epoch = sess.epochs.get_named_timerange('maze1')\n",
    "# print('active_epoch: {}'.format(active_epoch))\n",
    "# active_epoch = sess.epochs.get_named_timerange('maze2')\n",
    "active_epoch = NamedTimerange(name='maze', start_end_times=[sess.epochs['maze1'][0], sess.epochs['maze2'][1]])\n",
    "active_subplots_shape = (1,1) # Single subplot\n",
    "# active_subplots_shape = '1|2' # 1 subplot on left, two on right\n",
    "active_config = build_configs(active_sess_config, active_epoch, active_subplots_shape = active_subplots_shape)\n",
    "\n",
    "## All Spikes:\n",
    "active_epoch_session = sess.filtered_by_neuron_type('pyramidal').filtered_by_epoch(active_epoch)\n",
    "print_subsession_neuron_differences(sess.neurons, active_epoch_session.neurons)\n",
    "# print(sess.neurons.n_spikes)\n",
    "\n",
    "# # ## Lap_specific Spikes Only:\n",
    "# active_lap_specific_epoch_session = lap_specific_session.filtered_by_neuron_type('pyramidal').filtered_by_epoch(active_epoch)\n",
    "# print_subsession_neuron_differences(lap_specific_session.neurons, active_lap_specific_epoch_session.neurons)\n",
    "# # print(active_lap_specific_epoch_session.neurons.n_spikes)\n",
    "\n",
    "## Configure Placefield Calc:\n",
    "should_display_2D_plots = False\n",
    "\n",
    "# active_config.computation_config = PlacefieldComputationParameters(speed_thresh=1, grid_bin=2, smooth=0.5, frate_thresh=2.0)\n",
    "# active_config.computation_config = PlacefieldComputationParameters(speed_thresh=1, grid_bin=10, smooth=0.5, frate_thresh=2.0) # works well\n",
    "# active_config.computation_config = PlacefieldComputationParameters(speed_thresh=1, grid_bin=2.5, smooth=1.5, frate_thresh=2.0)\n",
    "# active_config.computation_config = PlacefieldComputationParameters(speed_thresh=1, grid_bin=(10, 3), smooth=(0.5, 0.5), frate_thresh=0.0)\n",
    "# active_config.computation_config = PlacefieldComputationParameters(speed_thresh=0.0, grid_bin=(3, 4), smooth=(2, 1), frate_thresh=2.0)\n",
    "# active_config.computation_config = PlacefieldComputationParameters(speed_thresh=1, grid_bin=(10, 10), smooth=(0.5, 0.5), frate_thresh=2.0) ## Works well for 2D Placemaps\n",
    "# height: 20.0\n",
    "# width: 250.0\n",
    "# active_config.computation_config = PlacefieldComputationParameters(speed_thresh=0, grid_bin=(2.0, 0.2), smooth=(0.5, 0.5), frate_thresh=2.0) ## Extremely Slow\n",
    "# active_config.computation_config = PlacefieldComputationParameters(speed_thresh=0, grid_bin=(2.0, 1.0), smooth=(0.5, 0.5), frate_thresh=2.0) ## Very slow, doesn't work\n",
    "\n",
    "# active_config.computation_config = PlacefieldComputationParameters(speed_thresh=1, grid_bin=(10, 3), smooth=(0.0, 0.0), frate_thresh=2.0)\n",
    "# active_config.computation_config = PlacefieldComputationParameters(speed_thresh=1, grid_bin=(10, 3), smooth=(0.1, 0.1), frate_thresh=2.0)\n",
    "# active_config.computation_config = PlacefieldComputationParameters(speed_thresh=1, grid_bin=(10, 3), smooth=(1.0, 10.0), frate_thresh=2.0)\n",
    "\n",
    "# active_config.computation_config = PlacefieldComputationParameters(speed_thresh=0.0, grid_bin=(25, 9), smooth=(0.0, 0.0), frate_thresh=2.0)\n",
    "active_config.computation_config = PlacefieldComputationParameters(speed_thresh=0.0, grid_bin=(5, 3), smooth=(0.0, 0.0), frate_thresh=2.0)\n",
    "\n",
    "\n",
    "# active_config.computation_config.frate_thresh = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74b3c32-24c2-4ca8-908e-1b270affffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## position binning with _bin_pos_nD testing and validation:\n",
    "from neuropy.analyses.pho_custom_placefields import _bin_pos_nD\n",
    "# from neuropy.analyses.placefields import _bin_pos_nD\n",
    "\n",
    "test_pos_x = active_epoch_session.position.x\n",
    "test_pos_y = active_epoch_session.position.y\n",
    "\n",
    "# test_bin_size = (5, 3)\n",
    "test_bin_size = active_config.computation_config.grid_bin\n",
    "\n",
    "test_xbin, test_ybin, test_bin_info = _bin_pos_nD(x=test_pos_x, y=test_pos_y, num_bins=None, bin_size=test_bin_size)\n",
    "print(f'for bin_size: {test_bin_size} computed pos bins: {test_bin_info}') # for bin_size: (25, 9) computed pos bins: {'mode': 'bin_size', 'xstep': 25, 'xnum_bins': 11, 'ystep': 9, 'ynum_bins': 5}\n",
    "# for bin_size: (5, 9) computed pos bins: {'mode': 'bin_size', 'xstep': 5, 'xnum_bins': 49, 'ystep': 9, 'ynum_bins': 5}\n",
    "# for bin_size: (5, 3) computed pos bins: {'mode': 'bin_size', 'xstep': 5, 'xnum_bins': 49, 'ystep': 3, 'ynum_bins': 11}\n",
    "\n",
    "assert test_bin_size[0] == test_bin_info['xstep'], \"xstep calculation failure!\"\n",
    "assert test_bin_size[1] == test_bin_info['ystep'], \"ystep calculation failure!\"\n",
    "\n",
    "# assert test_bin_size[0] == np.shape(test_xbin), \"xstep calculation failure!\"\n",
    "# assert test_bin_size[1] == np.shape(test_ybin), \"xstep calculation failure!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212608eb-26af-425d-92c0-a3309bf4727d",
   "metadata": {},
   "source": [
    "## Compute Placefields if needed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6742e705-6578-4b58-bdba-20cb5c4e870a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute the placefields for lap-only filtered Session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ec706f-196c-4e36-917b-0c7b3f266a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def debug_print_ratemap(ratemap):\n",
    "    # Get the cell IDs that have a good place field mapping:\n",
    "    good_placefield_neuronIDs = np.array(ratemap.neuron_ids) # in order of ascending ID\n",
    "    print('good_placefield_neuronIDs: {}; ({} good)'.format(good_placefield_neuronIDs, len(good_placefield_neuronIDs)))\n",
    "    \n",
    "def debug_print_placefield(active_epoch_placefield, short=True):\n",
    "    # Get the cell IDs that have a good place field mapping:\n",
    "    good_placefield_neuronIDs = np.array(active_epoch_placefield.ratemap.neuron_ids) # in order of ascending ID\n",
    "    num_spikes_per_spiketrain = np.array([np.shape(a_spk_train)[0] for a_spk_train in active_epoch_placefield.spk_t])\n",
    "    if short:\n",
    "        print('good_placefield_neuronIDs: ({} good)'.format(len(good_placefield_neuronIDs)), end='\\n')\n",
    "        print('num_spikes: ({} total spikes)'.format(np.sum(num_spikes_per_spiketrain)), end='\\n')\n",
    "    else:\n",
    "        print('good_placefield_neuronIDs: {}; ({} good)'.format(good_placefield_neuronIDs, len(good_placefield_neuronIDs)), end='\\n')\n",
    "        print('num_spikes: {}; ({} total spikes)'.format(num_spikes_per_spiketrain, np.sum(num_spikes_per_spiketrain)), end='\\n')\n",
    "    return pd.DataFrame({'neuronID':good_placefield_neuronIDs, 'num_spikes':num_spikes_per_spiketrain}).T\n",
    "\n",
    "\n",
    "def compute_placefields_masked_by_epochs(sess, active_config, included_epochs=None, should_display_2D_plots=False):\n",
    "    active_session = deepcopy(sess)\n",
    "    active_epoch_placefields1D, active_epoch_placefields2D = compute_placefields_as_needed(active_session, active_config.computation_config, active_config, None, None, included_epochs=included_epochs, should_force_recompute_placefields=True, should_display_2D_plots=should_display_2D_plots)\n",
    "    # Focus on the 2D placefields:\n",
    "    # active_epoch_placefields = active_epoch_placefields2D\n",
    "    # Get the updated session using the units that have good placefields\n",
    "    # active_session, active_config, good_placefield_neuronIDs = process_by_good_placefields(active_session, active_config, active_epoch_placefields)\n",
    "    # debug_print_spike_counts(active_session)\n",
    "    return active_epoch_placefields1D, active_epoch_placefields2D\n",
    "\n",
    "\n",
    "active_epoch_placefields1D, active_epoch_placefields2D = compute_placefields_masked_by_epochs(active_epoch_session, active_config, included_epochs=None, should_display_2D_plots=should_display_2D_plots)\n",
    "even_lap_specific_placefields1D, even_lap_specific_placefields2D = compute_placefields_masked_by_epochs(active_epoch_session, active_config, included_epochs=even_lap_specific_epochs, should_display_2D_plots=should_display_2D_plots)\n",
    "odd_lap_specific_placefields1D, odd_lap_specific_placefields2D = compute_placefields_masked_by_epochs(active_epoch_session, active_config, included_epochs=odd_lap_specific_epochs, should_display_2D_plots=should_display_2D_plots)\n",
    "any_lap_specific_placefields1D, any_lap_specific_placefields2D = compute_placefields_masked_by_epochs(active_epoch_session, active_config, included_epochs=any_lap_specific_epochs, should_display_2D_plots=should_display_2D_plots)\n",
    "# Compare the results\n",
    "# debug_print_ratemap(active_epoch_placefields1D.ratemap)\n",
    "# num_spikes_per_spiketrain = np.array([np.shape(a_spk_train)[0] for a_spk_train in active_epoch_placefields1D.spk_t])\n",
    "# num_spikes_per_spiketrain\n",
    "# print('placefield_neuronID_spikes: {}; ({} total spikes)'.format(num_spikes_per_spiketrain, np.sum(num_spikes_per_spiketrain)))\n",
    "debug_print_placefield(active_epoch_placefields1D)\n",
    "debug_print_placefield(any_lap_specific_placefields1D)\n",
    "debug_print_placefield(even_lap_specific_placefields1D)\n",
    "debug_print_placefield(odd_lap_specific_placefields1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db6d73-595c-4cd0-a988-4b63d00e0e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "active_epoch_placefields2D\n",
    "# active_binwidths = (active_epoch_placefields2D.config.grid_bin[0], active_epoch_placefields2D.config.grid_bin[1]) # e.g. (2, .5)\n",
    "\n",
    "print(active_epoch_placefields1D.config)\n",
    "print(np.shape(active_epoch_placefields1D.occupancy)) # the 1D occupancy map is (48,) units wide\n",
    "\n",
    "print(np.shape(active_epoch_placefields2D.occupancy)) # the 1D occupancy map is (48, 10). The Width is 10\n",
    "# print(active_epoch_placefields2D.config)\n",
    "\n",
    "active_epoch_placefields2D.occupancy[0,:] # occupancy appears to by 4 columns wide, and 10 rows tall. The value I passed in though was (25, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c8bf1-7e9a-4574-ad6c-ddda2437cecc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.image import NonUniformImage\n",
    "import seaborn as sns\n",
    "# sns.set_theme(style=\"dark\")\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "active_ratemap = any_lap_specific_placefields2D.ratemap\n",
    "curr_unit_idx = 3\n",
    "\n",
    "def test_plot_ratemap(curr_unit_idx = 3):\n",
    "    fig = Figure(figsize=(10, 6))\n",
    "    \n",
    "    plot_mode = 5\n",
    "    active_binwidths = (any_lap_specific_placefields2D.config.grid_bin[0], any_lap_specific_placefields2D.config.grid_bin[1]) # e.g. (2, .5)\n",
    "    \n",
    "    print(f'active_binwidths: {active_binwidths}')\n",
    "    pfmap = active_ratemap.tuning_curves[curr_unit_idx]\n",
    "    curr_pfmap = np.array(pfmap)\n",
    "    if plot_mode == 0:\n",
    "        # ax = fig.subplots()\n",
    "        ax = fig.add_subplot(111, title='pcolormesh test', aspect='equal')\n",
    "        mesh_X, mesh_Y = np.meshgrid(active_ratemap.xbin, active_ratemap.ybin)\n",
    "        curr_pfmap = np.rot90(np.fliplr(curr_pfmap)) / np.nanmax(curr_pfmap)\n",
    "        ax.pcolormesh(mesh_X, mesh_Y, curr_pfmap, cmap='jet', vmin=0);\n",
    "    \n",
    "    \n",
    "    elif plot_mode == 1:\n",
    "        xedges = active_ratemap.xbin\n",
    "        yedges = active_ratemap.ybin\n",
    "        ax = fig.add_subplot(111, title='NonUniformImage Test', aspect='equal', xlim=xedges[[0, -1]], ylim=yedges[[0, -1]])\n",
    "        # print(f'curr_pfmap: {np.shape(curr_pfmap)}') # (6, 74)\n",
    "        # print(f'curr_pfmap: {np.shape(curr_pfmap)}') # (6, 74)\n",
    "        # print(f'curr_pfmap: {np.shape(curr_pfmap)}') # (6, 74)\n",
    "        \n",
    "        # rich.inspect(active_ratemap.xbin_centers) # xbin: (75,), ybin: (7,), xbin_centers: (74,), ybin_centers: (6,)\n",
    "        im = NonUniformImage(ax, interpolation='bilinear') # interpolation='bilinear'\n",
    "        xcenters = (xedges[:-1] + xedges[1:]) / 2\n",
    "        ycenters = (yedges[:-1] + yedges[1:]) / 2\n",
    "        im.set_data(xcenters, ycenters, curr_pfmap.T)\n",
    "        # im.set_data(active_ratemap.xbin_centers, active_ratemap.ybin_centers, curr_pfmap.T)\n",
    "        ax.images.append(im)\n",
    "        \n",
    "    elif plot_mode == 2:\n",
    "        # g = sns.jointplot(\"s_zscore\",\"p_zscore\",s=2, data=scatter_all, kind=\"kde\")\n",
    "        scatter_all = np.array(any_lap_specific_placefields2D.spk_pos[curr_unit_idx]) # (2, 825)\n",
    "        # any_lap_specific_placefields2D.occupancy\n",
    "        scatter_all_df = pd.DataFrame({'x':scatter_all[0,:], 'y':scatter_all[1,:]})\n",
    "        # g = sns.jointplot(x='x', y='y', data=scatter_all_df, kind=\"kde\", marginal_ticks=True)\n",
    "        # g = sns.jointplot(x='x', y='y', data=scatter_all_df)\n",
    "        # g = sns.jointplot(x='x', y='y', data=scatter_all_df, kind=\"hex\", marginal_ticks=True)\n",
    "        # g = sns.jointplot(x='x', y='y', data=scatter_all_df, kind=\"hist\", marginal_ticks=True)\n",
    "        \n",
    "        ax = plt.gca()\n",
    "        sns.heatmap(curr_pfmap, annot=True, linewidths=.5, ax=ax)\n",
    "        # sns.heatmap(curr_pfmap, annot=True, fmt=\"d\", linewidths=.5, ax=ax)\n",
    "        # , hue=\"species\"\n",
    "        \n",
    "        # marker=\"+\", s=100, marginal_kws=dict(bins=25)\n",
    "    elif plot_mode == 3:\n",
    "        scatter_all = np.array(any_lap_specific_placefields2D.spk_pos[curr_unit_idx]) # (2, 825)\n",
    "        # any_lap_specific_placefields2D.occupancy\n",
    "        scatter_all_df = pd.DataFrame({'x':scatter_all[0,:], 'y':scatter_all[1,:]})\n",
    "        \n",
    "        sns.scatterplot(x=scatter_all_df.x, y=scatter_all_df.y, s=5, color=\".15\")\n",
    "        sns.histplot(x=scatter_all_df.x, y=scatter_all_df.y, bins=10, pthresh=.1, cmap=\"mako\")\n",
    "        sns.kdeplot(x=scatter_all_df.x, y=scatter_all_df.y, levels=5, color=\"w\", linewidths=1)\n",
    "    elif plot_mode == 4:\n",
    "        \"\"\" Especially good-looking heatmap plot \"\"\"\n",
    "        scatter_all = np.array(any_lap_specific_placefields2D.spk_pos[curr_unit_idx]) # (2, 825)\n",
    "        scatter_all_df = pd.DataFrame({'x':scatter_all[0,:], 'y':scatter_all[1,:]})\n",
    "        \n",
    "        # g = sns.scatterplot(x=scatter_all_df.x, y=scatter_all_df.y, s=5, color=\".15\")\n",
    "        g = sns.JointGrid(data=scatter_all_df, x=\"x\", y=\"y\", space=0)\n",
    "        g.plot_joint(sns.kdeplot, fill=True, thresh=0, levels=100, cmap=\"rocket\")\n",
    "        \n",
    "        \n",
    "        g.plot_joint(sns.histplot, binwidth=binwidths, cbar=True)\n",
    "        \n",
    "        # g.scatterplot(x=scatter_all_df.x, y=scatter_all_df.y, s=5, color=\".15\")\n",
    "        # g.plot_joint(sns.kdeplot,\n",
    "        #              fill=True, clip=((2200, 6800), (10, 25)),\n",
    "        #              thresh=0, levels=100, cmap=\"rocket\")\n",
    "        # g.plot_marginals(sns.histplot, color=\"#03051A\", alpha=0.75, bins=25)\n",
    "        g.plot_marginals(sns.histplot, color=\"#03051A\", alpha=0.75, binwidth=active_binwidths)\n",
    "        \n",
    "    elif plot_mode == 5:\n",
    "        scatter_all = np.array(any_lap_specific_placefields2D.spk_pos[curr_unit_idx]) # (2, 825)\n",
    "        scatter_all_df = pd.DataFrame({'x':scatter_all[0,:], 'y':scatter_all[1,:]})\n",
    "        sns.displot(scatter_all_df, x=\"x\", y=\"y\", binwidth=active_binwidths, cbar=True)\n",
    "\n",
    "        \n",
    "    ax = plt.gca()\n",
    "    ax.set_title(f'TuningCurve[{curr_unit_idx}]')\n",
    "    # pn.pane.Matplotlib(fig)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "test_plot_ratemap(9)\n",
    "# pn.interact(plot_ratemap, curr_unit_idx=3)\n",
    "# pn.interact(test_plot_ratemap, curr_unit_idx=widgets.IntSlider(start=0,end=active_ratemap.n_neurons,step=1,value=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac13a0b-c6a0-4bbb-b19d-7688a9e42789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax_pf_1D, occupancy_fig, active_pf_2D_figures = plot_all_placefields(active_epoch_placefields1D, active_epoch_placefields2D, active_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ffc1d0-5eb1-49d5-8fb8-f3cac3d8e9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from neuropy.plotting.placemaps import plot_occupancy_custom\n",
    "\n",
    "# plot_occupancy_1D(even_lap_specific_placefields1D, True)\n",
    "# plot_occupancy_1D(even_lap_specific_placefields1D, False)\n",
    "# plot_placefield_occupancy(even_lap_specific_placefields2D)\n",
    "\n",
    "occupancy_fig = plt.Figure(figsize=(10,6))\n",
    "occupancy_fig, occupancy_ax = plot_occupancy_custom(even_lap_specific_placefields2D.occupancy, even_lap_specific_placefields2D.ratemap.xbin_centers, even_lap_specific_placefields2D.ratemap.ybin_centers, max_normalized=True, fig=occupancy_fig)\n",
    "occupancy_ax.scatter(even_lap_specific_placefields2D.x, even_lap_specific_placefields2D.y, s=5, c='red', alpha=0.1)\n",
    "occupancy_fig\n",
    "\n",
    "# # fig = plt.Figure()\n",
    "# fig, axs = plt.subplots(3, 1, figsize=(7, 15))\n",
    "\n",
    "# # even_lap_specific_placefields1D.occupancy.\n",
    "# # even_lap_specific_placefields1D.ratemap.xbin_centers\n",
    "# # np.shape(even_lap_specific_placefields1D.ratemap.xbin) # (214,)\n",
    "# # even_lap_specific_placefields1D.config.grid_bin_1D # 1\n",
    "# # np.shape(even_lap_specific_placefields1D.ratemap.xbin_centers) # 213\n",
    "\n",
    "# even_lap_specific_ax_pf_1D, even_lap_specific_occupancy_fig, even_lap_specific_active_pf_2D_figures = plot_all_placefields(even_lap_specific_placefields1D, even_lap_specific_placefields2D, active_config)\n",
    "\n",
    "# even_lap_specific_placefields1D.plot_ratemaps();\n",
    "# even_lap_specific_placefields1D.plot_ratemaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ee93b-1815-4a67-98d2-da2f743205fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "odd_lap_specific_ax_pf_1D, odd_lap_specific_occupancy_fig, odd_lap_specific_active_pf_2D_figures = plot_all_placefields(odd_lap_specific_placefields1D, odd_lap_specific_placefields2D, active_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871db3f4-cc71-44ca-a0a0-fbf92ec2a687",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Pho Custom Placefield2D Implementation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcd9213-11cc-4776-a73b-ecdc713b22dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.placefields import _bin_pos, plot_placefield_occupancy, plot_occupancy_custom, _filter_by_frate, Pf2D, _normalized_occupancy\n",
    "\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "\n",
    "# First, interested in answering the question \"where did the animal spend its time on the track\" to assess the relative frequency of events that occur in a given region. If the animal spends a lot of time in a certain region,\n",
    "# it's more likely that any cell, not just the ones that hold it as a valid place field, will fire there.\n",
    "    # this can be done by either binning (lumping close position points together based on a standardized grid), neighborhooding, or continuous smearing. \n",
    "\n",
    "def build_customPf2D_fromConfig(active_epoch_session, custom_computation_config):\n",
    "    # num_bins = (10, 10)\n",
    "    fig = Figure(figsize=(10, 6))\n",
    "    ax = fig.subplots(2, 1)\n",
    "    \n",
    "    should_plot_multiple_occupancy_curves = False\n",
    "    \n",
    "    pos_df = active_epoch_session.position.to_dataframe().copy()\n",
    "    laps_df = active_epoch_session.laps.to_dataframe().copy()\n",
    "    spk_df = active_epoch_session.spikes_df.copy()\n",
    "\n",
    "    ## Binning with Fixed Number of Bins:    \n",
    "    xbin, ybin, bin_info = _bin_pos(pos_df.x.to_numpy(), pos_df.y.to_numpy(), bin_size=custom_computation_config.grid_bin) # bin_size mode\n",
    "    # print(bin_info)\n",
    "    ## Binning with Fixed Bin Sizes:\n",
    "    # xbin, ybin, bin_info = _bin_pos(pos_df.x.to_numpy(), pos_df.y.to_numpy(), num_bins=num_bins) # num_bins mode\n",
    "    # print(bin_info)\n",
    "\n",
    "    # print('xbin: {}'.format(xbin))\n",
    "    # print('ybin: {}'.format(ybin))\n",
    "\n",
    "    # # Laps plotting:\n",
    "    # # pos_df.lin_pos.plot();\n",
    "    # curr_lap_id = 3\n",
    "    # plt.plot(pos_df.t, pos_df.lin_pos, '*');\n",
    "    # plt.xlim([laps_df.start[curr_lap_id], laps_df.stop[curr_lap_id]])\n",
    "    # # pos_df.describe()\n",
    "    # # pos_df.boxplot()\n",
    "\n",
    "    raw_occupancy, xedges, yedges = Pf2D._compute_occupancy(pos_df.x.to_numpy(), pos_df.y.to_numpy(), xbin, ybin, active_epoch_session.position.sampling_rate, custom_computation_config.smooth, should_return_raw_occupancy=True)\n",
    "    seconds_occupancy, normalized_occupancy = _normalized_occupancy(raw_occupancy, position_srate=active_epoch_session.position.sampling_rate)\n",
    "    occupancy = seconds_occupancy\n",
    "    # print(np.shape(occupancy))\n",
    "    # print(occupancy)\n",
    "    # plot_occupancy(occupancy)\n",
    "    # plot_occupancy_custom(active_epoch_placefields2D)\n",
    "\n",
    "    if should_plot_multiple_occupancy_curves:\n",
    "        fig, ax = plot_occupancy_custom(raw_occupancy, xedges, yedges, max_normalized=False)\n",
    "        ax.set_title('Custom Occupancy: Raw')\n",
    "        fig, ax = plot_occupancy_custom(normalized_occupancy, xedges, yedges, max_normalized=False)\n",
    "        ax.set_title('Custom Occupancy: Normalized')\n",
    "        fig, ax = plot_occupancy_custom(seconds_occupancy, xedges, yedges, max_normalized=False)\n",
    "        ax.set_title('Custom Occupancy: Seconds')\n",
    "\n",
    "    # pos_df.groupby('lap').plas.hist(alpha=0.4)\n",
    "\n",
    "    # Given a cell's last several seconds of its instantaneous firing rate at a given point in time, what's like likelihood that it's at a given position.\n",
    "        # continuous position used.\n",
    "\n",
    "    # spk_df_filtered_speed_thresh = spk_df[spk_df['speed'] >= custom_computation_config.speed_thresh].copy() # filter out the spikes below the speed_threshold\n",
    "    # spk_x = spk_df_filtered_speed_thresh['x'].to_numpy()\n",
    "    # spk_y = spk_df_filtered_speed_thresh['y'].to_numpy()\n",
    "\n",
    "    spk_x = spk_df['x'].to_numpy()\n",
    "    spk_y = spk_df['y'].to_numpy()\n",
    "    num_spike_counts_map = Pf2D._compute_tuning_map(spk_x, spk_y, xbin, ybin, occupancy, custom_computation_config.smooth, should_return_raw_tuning_map=True)\n",
    "    fig, ax[0] = plot_occupancy_custom(num_spike_counts_map, xbin, ybin, max_normalized=False, fig=fig, ax=ax[0])\n",
    "    ax[0].set_title('Custom num_spike_counts_map: All Neurons')\n",
    "\n",
    "    mpl_pane = pn.pane.Matplotlib(fig, dpi=144, height=800)\n",
    "    tabs = pn.Tabs(('num_spike_counts_map', fig))\n",
    "    ## This seems to be wrong, the highest spike rate is like 0.1 (in Hz)\n",
    "    spike_rate_Hz_map = num_spike_counts_map / seconds_occupancy\n",
    "    fig, ax[1] = plot_occupancy_custom(spike_rate_Hz_map, xbin, ybin, max_normalized=False, fig=fig, ax=ax[1])\n",
    "    ax[1].set_title('Custom spike_rate_Hz_map [Hz]: All Neurons, Occupancy Divided')\n",
    "    # Add a tab\n",
    "    tabs.append(('spike_rate_Hz_map', fig))\n",
    "\n",
    "    # # Add a tab\n",
    "    # tabs.append(('Slider', pn.widgets.FloatSlider()))\n",
    "\n",
    "    neuron_split_spike_dfs = [spk_df.groupby('aclu').get_group(neuron_id)[['t','x','y','lin_pos']] for neuron_id in active_epoch_session.neuron_ids] # dataframes split for each ID:\n",
    "    raw_tuning_maps = np.asarray([Pf2D._compute_tuning_map(neuron_split_spike_dfs[i].x.to_numpy(), neuron_split_spike_dfs[i].y.to_numpy(), xbin, ybin, occupancy, custom_computation_config.smooth, should_return_raw_tuning_map=True) for i in np.arange(len(neuron_split_spike_dfs))]) # dataframes split for each ID:\n",
    "    tuning_maps = np.asarray([raw_tuning_maps[i] / occupancy for i in np.arange(len(raw_tuning_maps))])\n",
    "    ratemap = Ratemap(tuning_maps, xbin=xbin, ybin=ybin, neuron_ids=active_epoch_session.neuron_ids)\n",
    "\n",
    "    # fig, ax = plot_occupancy_custom(raw_tuning_maps[0], xedges, yedges, max_normalized=False)\n",
    "    # ax.set_title('Custom raw_tuning_maps: Seconds')\n",
    "    firing_spike_counts_max = np.asarray([np.nanmax(raw_tuning_maps[i]) for i in np.arange(len(neuron_split_spike_dfs))]) # dataframes split for each ID:\n",
    "    # print('firing_spike_counts_max: {}'.format(firing_spike_counts_max))\n",
    "    firing_rate_max = np.asarray([np.nanmax(tuning_maps[i]) for i in np.arange(len(neuron_split_spike_dfs))]) # dataframes split for each ID:\n",
    "    # print('firing_rate_max: {}'.format(firing_rate_max))\n",
    "\n",
    "    filtered_tuning_maps, filter_function = _filter_by_frate(tuning_maps.copy(), custom_computation_config.frate_thresh)\n",
    "    filtered_ratemap = Ratemap(filtered_tuning_maps, xbin=xbin, ybin=ybin, neuron_ids=filter_function(ratemap.neuron_ids))\n",
    "    \n",
    "    # outputs: filtered_ratemap, filtered_ratemap\n",
    "    \n",
    "    # plt.fastcolor(active_epoch_placefields1D.occupancy)\n",
    "    # Convolve the location data\n",
    "\n",
    "    # plot_occupancy(active_epoch_placefields2D)\n",
    "    # pn.pane.Matplotlib(fig)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def build_customPf2D(active_epoch_session, speed_thresh=1, grid_bin=(10, 3), smooth=(0.0, 0.0), frate_thresh=0.0):\n",
    "    # custom_active_config = active_config\n",
    "    # note the second smoothing paramter affects the horizontal axis on the occupancy plot:\n",
    "    # custom_computation_config = PlacefieldComputationParameters(speed_thresh=1, grid_bin=(10, 3), smooth=(2, 0.1), frate_thresh=0.0)\n",
    "    # custom_computation_config = PlacefieldComputationParameters(speed_thresh=1, grid_bin=(10, 3), smooth=(0.0, 0.0), frate_thresh=0.0)\n",
    "    custom_computation_config = PlacefieldComputationParameters(speed_thresh=speed_thresh, grid_bin=grid_bin, smooth=smooth, frate_thresh=frate_thresh)\n",
    "    return build_customPf2D_fromConfig(active_epoch_session, custom_computation_config)\n",
    "\n",
    "def build_customPf2D_separate(active_epoch_session, speed_thresh=1, grid_bin_x=10, grid_bin_y=3, smooth_x=0.0, smooth_y=0.0, frate_thresh=0.0):\n",
    "    return build_customPf2D(active_epoch_session, speed_thresh=speed_thresh, grid_bin=(grid_bin_x, grid_bin_y), smooth=(smooth_x, smooth_y), frate_thresh=frate_thresh)\n",
    "\n",
    "\n",
    "# build_customPf2D(active_epoch_session, speed_thresh=1, grid_bin=10, smooth=0.0, frate_thresh=0.0)\n",
    "# pn.interact(build_customPf2D, active_epoch_session=fixed(active_epoch_session), speed_thresh=1, grid_bin=(10, 3), smooth=(0.0, 0.0), frate_thresh=2.0)\n",
    "pn.interact(build_customPf2D_separate, active_epoch_session=fixed(active_epoch_session), speed_thresh=(0.0, 20.0, 1.0), grid_bin_x=(0.10, 20.0, 0.5), grid_bin_y=(0.10, 20.0, 0.5), smooth_x=(0.0, 20.0, 0.25), smooth_y=(0.0, 20.0, 0.25), frate_thresh=(0.0, 20.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206d32f8-c809-4bf8-bd95-995a062fb5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.unique(spk_df['aclu']))\n",
    "# print(np.unique(spk_df['unit_id']))\n",
    "\n",
    "curr_unit_idx = 3\n",
    "def plot_ratemap(curr_unit_idx = 3):\n",
    "    fig = Figure(figsize=(10, 6))\n",
    "    ax = fig.subplots()\n",
    "    mesh_X, mesh_Y = np.meshgrid(ratemap.xbin, ratemap.ybin)\n",
    "    pfmap = ratemap.tuning_curves[curr_unit_idx]\n",
    "    curr_pfmap = np.array(pfmap)\n",
    "    curr_pfmap = np.rot90(np.fliplr(curr_pfmap)) / np.nanmax(curr_pfmap)\n",
    "    ax.pcolormesh(mesh_X, mesh_Y, curr_pfmap, cmap='jet', vmin=0);\n",
    "    ax.set_title(f'TuningCurve[{curr_unit_idx}]')\n",
    "    pn.pane.Matplotlib(fig)\n",
    "    return fig\n",
    "\n",
    "# plot_ratemap(5)\n",
    "# pn.interact(plot_ratemap, curr_unit_idx=3)\n",
    "pn.interact(plot_ratemap, curr_unit_idx=widgets.IntSlider(start=0,end=ratemap.n_neurons,step=1,value=10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bca1e4-77d4-4a42-9883-57f0ff6431d4",
   "metadata": {
    "tags": [
     "plotting"
    ]
   },
   "source": [
    "## Main Spike/Placemap plotting:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf894fae-cd96-472f-baa4-9701643f046b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2D Lap Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d958ca-37e6-4ee8-844d-8d9badb4e4d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2D Lap Trajectories Visualization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52715ea-4f27-4f41-9052-6957324f9699",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2D Placefield Plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b890dda3-9d7a-4c8a-b78d-d6bd924f0986",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib as mpl\n",
    "# mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "from PhoPositionalData.plotting.placefield import plot_1d_placecell_validations\n",
    "# out_figures_list = plot_1d_placecell_validations(active_epoch_placefields1D, active_config.plotting_config, should_save=True, save_mode='pdf')\n",
    "out_figures_list = plot_1d_placecell_validations(active_epoch_placefields1D, active_config.plotting_config, should_save=True, save_mode='separate_files')\n",
    "# plot_1d_placecell_validations(active_epoch_placefields1D, active_config.plotting_config, modifier_string='lap_only', should_save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66530e8-b2f1-4794-9d92-9b208e4d4fde",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_figures_list = plot_1d_placecell_validations(even_lap_specific_placefields1D, active_config.plotting_config, should_save=False, save_mode='separate_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b263b33-6e6d-400d-a446-22a4a4c71fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# active_epoch_placefields2D.plotRaw()\n",
    "curr_cell_id = 1\n",
    "fig, ax = active_epoch_placefields2D.plotRaw_v_time(curr_cell_id)\n",
    "# ax[0].plot(t_both, x_both, 'k', alpha=0.8, linewidth=5)\n",
    "ax[0].plot(t_even, x_even, 'g', alpha=0.3, linewidth=3)\n",
    "ax[0].plot(t_odd, x_odd, 'r', alpha=0.3, linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf188118-9bfc-4959-9df5-317231f73c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "position_obj = sess.position\n",
    "# position_obj.dt\n",
    "position_obj.compute_higher_order_derivatives()\n",
    "pos_df = position_obj.compute_smoothed_position_info(N=20) ## Smooth the velocity curve to apply meaningful logic to it\n",
    "pos_df = position_obj.to_dataframe()\n",
    "pos_df\n",
    "\n",
    "\n",
    "custom_test_laps = deepcopy(sess.laps)\n",
    "# custom_test_laps.to_dataframe()\n",
    "\n",
    "spikes_df = deepcopy(sess.spikes_df)\n",
    "spikes_df\n",
    "\n",
    "# any_position_columns = position_obj.dim_columns + position_obj.dim_computed_columns # ['x', 'y', 'velocity_x', 'acceleration_x', 'velocity_y', 'acceleration_y']\n",
    "# # any_position_columns.append(position_obj.dim_computed_columns)\n",
    "# any_position_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d24f1-eef6-44bb-80db-c0f510cbc156",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Uses Diba-computed Lap information that was loaded from file.\n",
    "\n",
    "# For Gradient Line Plotting:\n",
    "# import matplotlib.collections as mcoll\n",
    "from PhoPositionalData.plotting.laps import _plot_helper_add_span_where_ranges\n",
    "from PhoPositionalData.plotting.laps import plot_position_curves_figure, _plot_helper_render_laps\n",
    "\n",
    "## non-pre-filtered version, also doesn't create a duplicate dataframe:\n",
    "pos_df_is_nonNaN_lap = np.logical_not(np.isnan(pos_df.lap))\n",
    "pos_df_is_even_lap = np.logical_and(pos_df_is_nonNaN_lap, (np.remainder(pos_df.lap, 2) == 0))\n",
    "pos_df_is_odd_lap = np.logical_and(pos_df_is_nonNaN_lap, (np.remainder(pos_df.lap, 2) != 0))\n",
    "\n",
    "\n",
    "## pre-filtered copy version:\n",
    "# pos_df should already have the 'lap' column, so this should be easy:\n",
    "good_pos_df = pos_df[pos_df_is_nonNaN_lap] # pre-filter for non-NaN laps. Throws an error otherwise.\n",
    "unique_lap_values, lap_grouped_pos_dfs = partition(good_pos_df, 'lap') # split position dataframe based on its lap number\n",
    "# lap_num_points = [np.shape(a_df) for a_df in lap_grouped_pos_dfs]\n",
    "# lap_points = [a_df[curr_lap_i][['t','x']].to_numpy() for a_df in lap_grouped_pos_dfs]\n",
    "is_even_lap = np.remainder(unique_lap_values, 2) == 0\n",
    "is_odd_lap = np.logical_not(is_even_lap)\n",
    "\n",
    "\n",
    "# Easy way to get the even/odd a.k.a forward/reverse direction laps:\n",
    "unique_lap_dir_values, lap_dir_grouped_pos_dfs = partition(good_pos_df, 'lap_dir') # split position dataframe based on its lap number\n",
    "unique_lap_dir_values\n",
    "\n",
    "## equivalence testing:\n",
    "# np.shape(pos_df[pos_df_is_even_lap]) # (41331, 12)\n",
    "# np.shape(pd.concat(lap_grouped_pos_dfs[is_even_lap])) # (41331, 12)\n",
    "assert (np.shape(pos_df[pos_df_is_even_lap]) == np.shape(pd.concat(lap_grouped_pos_dfs[is_even_lap]))), 'Must be same size'\n",
    "\n",
    "# np.shape(pos_df[pos_df_is_odd_lap]) # (16023, 12)\n",
    "assert (np.shape(pos_df[pos_df_is_odd_lap]) == np.shape(pd.concat(lap_grouped_pos_dfs[is_odd_lap]))), 'Must be same size'\n",
    "\n",
    "\n",
    "# pos_df[pos_df_is_odd_lap]\n",
    "# lap_points = [a_df[curr_lap_i][['t','x']].to_numpy() for a_df in lap_grouped_pos_dfs]\n",
    "# curr_lap_num_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b342d8-b0c5-4f64-99d1-d163a24c1418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plot Extant Laps Variable:\n",
    "fig, out_axes_list = plot_position_curves_figure(position_obj, include_velocity=True, include_accel=False, figsize=(24, 10))\n",
    "\n",
    "## lap_grouped_pos_dfs concatenation-based version:\n",
    "curr_even_lap_dir_points = pos_df[pos_df_is_even_lap][['t','x']].to_numpy()\n",
    "out_axes_list[0].scatter(curr_even_lap_dir_points[:,0], curr_even_lap_dir_points[:,1], s=0.5, c='g')\n",
    "\n",
    "curr_odd_lap_dir_points = pos_df[pos_df_is_odd_lap][['t','x']].to_numpy()\n",
    "out_axes_list[0].scatter(curr_odd_lap_dir_points[:,0], curr_odd_lap_dir_points[:,1], s=0.5, c='r')\n",
    "\n",
    "\n",
    "## Span_where implementation:\n",
    "# Draws colored spans indicating the lap that is active during a given time interval.\n",
    "\n",
    "# _add_span_where_ranges(pos_df.t.to_numpy(), pos_df_is_even_lap, pos_df_is_odd_lap, ax0)\n",
    "# _add_span_where_ranges(pos_df.t.to_numpy(), pos_df_is_even_lap, pos_df_is_odd_lap, ax1)\n",
    "# _add_span_where_ranges(pos_df.t.to_numpy(), pos_df_is_even_lap, pos_df_is_odd_lap, ax2)\n",
    "\n",
    "\n",
    "## Constain to a specific lap:\n",
    "# curr_lap_times = sess.laps.get_lap_times(2)\n",
    "# out_axes_list[0].set_xlim([curr_lap_times[0], curr_lap_times[-1]])\n",
    "# out_axes_list[0].set_xlim([250.0, 300.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd113213-0176-4288-b6a6-23b6309c6991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now try a velocity threshold based lap detection mechanism:\n",
    "import matplotlib.collections as mcoll\n",
    "\n",
    "    \n",
    "    \n",
    "# plateaus:\n",
    "\n",
    "# ## Platform[0]:\n",
    "# collection = mcoll.BrokenBarHCollection.span_where(pos_df.t.to_numpy(), ymin=curr_span_ymin, ymax=curr_span_ymax, where=(pos_df['x'] < 63.5), facecolor='red', alpha=0.25)\n",
    "# curr_ax.add_collection(collection)\n",
    "# ## Platform[1]:\n",
    "# collection = mcoll.BrokenBarHCollection.span_where(pos_df.t.to_numpy(), ymin=curr_span_ymin, ymax=curr_span_ymax, where=(pos_df['x'] > 223.9), facecolor='orange', alpha=0.25)\n",
    "# curr_ax.add_collection(collection)\n",
    "\n",
    "# fig, out_axes_list = plot_position_curves_figure(position_obj, include_velocity=True, include_accel=False)\n",
    "\n",
    "desc_crossing_beginings, desc_crossing_midpoints, desc_crossing_endings, asc_crossing_beginings, asc_crossing_midpoints, asc_crossing_endings = estimate_laps(pos_df)\n",
    "custom_test_laps_obj = Laps.from_estimated_laps(pos_df['t'].to_numpy(), desc_crossing_beginings, desc_crossing_endings, asc_crossing_beginings, asc_crossing_endings)\n",
    "## Determine the spikes included with each computed lap:\n",
    "custom_test_laps_obj = compute_laps_spike_indicies(custom_test_laps_obj, spikes_df)\n",
    "\n",
    "\n",
    "# backup the extant laps object to prepare for the new one:\n",
    "sess.old_laps_obj = deepcopy(sess.laps)\n",
    "# sess.old_laps_obj\n",
    "sess.laps = deepcopy(custom_test_laps_obj) # replace the laps obj\n",
    "sess.laps.to_dataframe()\n",
    "\n",
    "# plot_laps_2d(sess, legacy_plotting_mode=True)\n",
    "plot_laps_2d(sess, legacy_plotting_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9181c-0a5b-4775-b80d-d5bd17cbe41a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def _plot_helper_render_estimated_laps(desc_crossing_beginings, desc_crossing_midpoints, desc_crossing_endings, asc_crossing_beginings, asc_crossing_midpoints, asc_crossing_endings):\n",
    "\n",
    "## Working Midpoint Detection:\n",
    "# Plots the midpoints as red and green dots on the pos_x curve\n",
    "fig, out_axes_list = plot_position_curves_figure(position_obj, include_velocity=False, include_accel=False)\n",
    "out_axes_list[0].set_ylim([np.nanmin(position_obj.x), np.nanmax(position_obj.x)])\n",
    "_plot_helper_render_lap(pos_df['t'].to_numpy(), pos_df['x'].to_numpy(), desc_crossing_beginings, desc_crossing_midpoints, desc_crossing_endings, color='r', ax=out_axes_list[0])\n",
    "_plot_helper_render_lap(pos_df['t'].to_numpy(), pos_df['x'].to_numpy(), asc_crossing_beginings, asc_crossing_midpoints, asc_crossing_endings, color='g', ax=out_axes_list[0])\n",
    "# ax0.set_xlim([240.0, 500.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd21e418-e33a-4824-a68a-ad98c77a69f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "active_epoch_placefields2D.plotMap(figsize=(12,20), enable_spike_overlay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907077d1-2a16-4fda-9fae-ab1f586cdb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PhoPositionalData.plotting.laps import plot_lap_trajectories_2d\n",
    "fig, axs, laps_pages = plot_lap_trajectories_2d(sess, curr_num_subplots=len(sess.laps.lap_id), active_page_index=0)\n",
    "fig.suptitle('Lap Trajectories 2D', fontsize=22)\n",
    "# fig_out_path = active_config.plotting_config.get_figure_save_path('lap_trajectories_2D').with_suffix('.png')\n",
    "# fig.savefig(fig_out_path)\n",
    "plt.show()\n",
    "\n",
    "# p, axs, laps_pages = plot_lap_trajectories_2d(sess, curr_num_subplots=22, active_page_index=0)\n",
    "# p, axs, laps_pages = plot_lap_trajectories_2d(sess, curr_num_subplots=22, active_page_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad08080-abb6-4373-b426-520cb0ac95f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3D Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa48d74c-8e7a-4678-bea5-9415b270b1db",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3D Lap Trajectories Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f4fe6-7848-4f62-b2c2-e20e4eb426d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PhoPositionalData.plotting.laps import plot_lap_trajectories_3d\n",
    "p, laps_pages = plot_lap_trajectories_3d(sess, curr_num_subplots=10, active_page_index=1)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd9ebb1-1e31-44e1-8600-339b06db84a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tuning Curves 3D Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59a148-4799-48e5-ba8a-69516a44ec4c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PhoGui.InteractivePlotter.InteractivePlaceCellTuningCurvesDataExplorer import InteractivePlaceCellTuningCurvesDataExplorer\n",
    "try: pActiveTuningCurvesPlotter\n",
    "except NameError: pActiveTuningCurvesPlotter = None # Checks variable p's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "ipcDataExplorer = InteractivePlaceCellTuningCurvesDataExplorer(active_config, active_epoch_session, active_epoch_placefields, active_config.plotting_config.pf_colors, extant_plotter=pActiveTuningCurvesPlotter)\n",
    "pActiveTuningCurvesPlotter = ipcDataExplorer.plot(pActiveTuningCurvesPlotter) # [2, 17449]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3a1442-b113-483e-94ab-880bf8e694fc",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "debug",
     "testing",
     "unfinished"
    ]
   },
   "source": [
    "### Tuning-Curve Height Spikes Plot Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68b8fa4-a6c7-4863-8eb5-8497543b1985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.collections import EventCollection\n",
    "from scipy.interpolate import RectBivariateSpline # for 2D spline interpolation\n",
    "\n",
    "## Getting the proper z-position for the tuning curve:\n",
    "# Create source to ray trace\n",
    "sphere = pv.Sphere(radius=0.85)\n",
    "\n",
    "# Define a list of origin points and a list of direction vectors for each ray\n",
    "# vectors = [ [cos(radians(x)), sin(radians(x)), 0] for x in range(0, 360, 5)]\n",
    "\n",
    "# origins = [[0, 0, 0]] * len(active_lap_specific_epoch_session.spikes_df['x'])\n",
    "# origins = np.hstack(active_lap_specific_epoch_session.spikes_df[['x','y']].to_numpy().T, np.full_like(active_lap_specific_epoch_session.spikes_df['x'].to_numpy(), 0.0))\n",
    "# origins[0,:]\n",
    "# spike_series_identities = active_flattened_spike_identities # currently unused\n",
    "\n",
    "active_epoch_placefields2D\n",
    "\n",
    "\n",
    "active_epoch_placefields1D.ratemap_spiketrains # times where the spikes occured.\n",
    "active_epoch_placefields1D.ratemap_spiketrains_pos # position where the spikes occured.\n",
    "\n",
    "## This is the correct 1D interpolation! It gets the y-values on the curve where the spikes could be plot!\n",
    "spike_pf_heights_1D = [np.interp(active_epoch_placefields1D.spk_pos[i], active_epoch_placefields1D.ratemap.xbin_centers, active_epoch_placefields1D.ratemap.normalized_tuning_curves[i]) for i in np.arange(active_epoch_placefields1D.ratemap.n_neurons)] # the appropriately interpolated values for where the spikes should be on the tuning_curve\n",
    "\n",
    "## Potentially successfully implemented the z-interpolation!!!: 2D interpolation where the (x,y) point of each spike is evaluated to determine the Z-position it would correspond to on the pf map.\n",
    "_spike_pf_heights_2D_splineAproximator = [RectBivariateSpline(active_epoch_placefields2D.ratemap.xbin_centers, active_epoch_placefields2D.ratemap.ybin_centers, active_epoch_placefields2D.ratemap.normalized_tuning_curves[i]) for i in np.arange(active_epoch_placefields2D.ratemap.n_neurons)] \n",
    "spike_pf_heights_2D = [spike_pf_heights_2D_splineAproximator[i](active_epoch_placefields2D.spk_pos[i][0], active_epoch_placefields2D.spk_pos[i][1], grid=False) for i in np.arange(active_epoch_placefields1D.ratemap.n_neurons)] # the appropriately interpolated values for where the spikes should be on the tuning_curve\n",
    "print(f'np.shape(spike_pf_heights_2D): {np.shape(spike_pf_heights_2D[i])}') # (809,)\n",
    "\n",
    "#spike_pf_heights_1D is (814,) and the values range between 0.0 and 1.0\n",
    "\n",
    "fig = plt.Figure()\n",
    "axes = fig.subplots(3, 1, sharex=True)\n",
    "axes[0].plot(active_epoch_placefields1D.ratemap.xbin_centers, active_epoch_placefields1D.ratemap.normalized_tuning_curves[i])\n",
    "axes[0].set_ylabel('norm_tuning_curve')\n",
    "# axes[0].plot(active_epoch_placefields1D.ratemap.xbin_centers, active_epoch_placefields1D.ratemap.normalized_tuning_curves[i])\n",
    "# plt.plot(active_epoch_placefields1D.spk_pos[i])\n",
    "# plt.plot(active_epoch_placefields1D.spk_t[i], spike_pf_heights_1D[i])\n",
    "\n",
    "axes[1].scatter(active_epoch_placefields1D.spk_pos[i], spike_pf_heights_1D[i])\n",
    "axes[1].set_ylabel('spike_pf_heights')\n",
    "\n",
    "# # create the events marking the x data points\n",
    "# xevents1 = EventCollection(xdata1, color='tab:blue', linelength=0.05)\n",
    "# xevents2 = EventCollection(xdata2, color='tab:orange', linelength=0.05)\n",
    "\n",
    "# # create the events marking the y data points\n",
    "# yevents1 = EventCollection(ydata1, color='tab:blue', linelength=0.05,\n",
    "#                            orientation='vertical')\n",
    "# yevents2 = EventCollection(ydata2, color='tab:orange', linelength=0.05,\n",
    "#                            orientation='vertical')\n",
    "\n",
    "# # add the events to the axis\n",
    "# ax.add_collection(xevents1)\n",
    "# ax.add_collection(xevents2)\n",
    "# ax.add_collection(yevents1)\n",
    "# ax.add_collection(yevents2)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be7929-fe2c-4f0f-9660-4bb23f6dbec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "active_epoch_session.position\n",
    "\n",
    "vectors = [[0, 0, 10.0]] * len(active_lap_specific_epoch_session.spikes_df['x']) # just up in the z-direction\n",
    "spike_series_positions = active_lap_specific_epoch_session.spikes_df[['x','y']].to_numpy().T    \n",
    "z_fixed = np.full_like(spike_series_positions[0,:], 1.1) # Offset a little bit in the z-direction so we can see it\n",
    "origins = np.vstack((spike_series_positions[0,:], spike_series_positions[1,:], z_fixed)).T\n",
    "# origins\n",
    "\n",
    "# Perform ray trace\n",
    "# Define line segment\n",
    "# start = [0, 0, 0]\n",
    "# stop = [0.25, 1, 0.5]\n",
    "\n",
    "curr_idx = 0\n",
    "curr_tuning_curve_mesh = ipcDataExplorer.plots['tuningCurvePlotActors'][curr_idx]\n",
    "start = origins[curr_idx]\n",
    "stop = start + vectors[curr_idx]\n",
    "\n",
    "# Perform ray trace\n",
    "# points, ind = sphere.ray_trace(start, stop)\n",
    "points, ind = curr_tuning_curve_mesh.ray_trace(start, stop)\n",
    "pActiveTuningCurvesPlotter.add_mesh(ray, color=\"blue\", line_width=5, name='test_ray', label=\"Ray Segment\")\n",
    "pActiveTuningCurvesPlotter.add_mesh(intersection, color=\"maroon\",\n",
    "           point_size=25, label=\"Intersection Points\", name='test_ray_intersection')\n",
    "# points, ind_ray, ind_tri = sphere.multi_ray_trace(origins, vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57076118-8e5f-496e-b06f-d1be2491d590",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "## Interactive 3D Spike and Behavior Browser: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14318f45-b618-43a5-9f77-201cfac02b9d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import PhoGui\n",
    "from PhoGui.InteractivePlotter.PhoInteractivePlotter import PhoInteractivePlotter\n",
    "from PhoGui.InteractivePlotter.shared_helpers import InteractivePyvistaPlotterBuildIfNeededMixin\n",
    "from PhoGui.InteractivePlotter.InteractivePlaceCellDataExplorer import InteractivePlaceCellDataExplorer\n",
    "\n",
    "active_config.plotting_config.show_legend = True\n",
    "\n",
    "try: pActiveInteractivePlaceSpikesPlotter\n",
    "except NameError: pActiveInteractivePlaceSpikesPlotter = None # Checks variable p's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "ipspikesDataExplorer = InteractivePlaceCellDataExplorer(active_config, active_epoch_session, extant_plotter=pActiveInteractivePlaceSpikesPlotter)\n",
    "pActiveInteractivePlaceSpikesPlotter = ipspikesDataExplorer.plot(pActivePlotter=pActiveInteractivePlaceSpikesPlotter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bdbf90-b7c6-44c9-8e6e-5bfba6563ebe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CustomDataExplorer 3D Plotter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dee0cf-211e-43ea-89a6-9a41a24d814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PhoGui.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer\n",
    "active_laps_config = InteractivePlaceCellConfig(active_session_config=sess.config, active_epochs=None, video_output_config=None, plotting_config=None) # '3|1    \n",
    "active_laps_config.plotting_config = PlottingConfig(output_subplots_shape='1|5', output_parent_dir=Path('output', sess.config.session_name, 'custom_laps'))\n",
    "\n",
    "try: pActiveInteractiveLapsPlotter\n",
    "except NameError: pActiveInteractiveLapsPlotter = None # Checks variable p's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "iplapsDataExplorer = InteractiveCustomDataExplorer(active_laps_config, sess, extant_plotter=pActiveInteractiveLapsPlotter)\n",
    "pActiveInteractiveLapsPlotter = iplapsDataExplorer.plot(pActivePlotter=pActiveInteractiveLapsPlotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e91d7b6-7aa1-4372-802f-9931e3988356",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sess.laps.lap_id) # 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876756ea-69ee-4cbc-bbd4-ff37050899f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(len(sess.laps.lap_id)):\n",
    "    curr_lap_id = sess.laps.lap_id[i]\n",
    "    curr_lap_t_start, curr_lap_t_stop = sess.laps.get_lap_times(i)\n",
    "    curr_lap_position_traces = laps_position_traces[i]\n",
    "    plot_lap_trajectory_path_spline(iplapsDataExplorer, curr_lap_position_traces, curr_lap_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86277544-9199-4b81-b85b-169fa1307a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = pv.Plotter(shape=(5, 1), border=True)\n",
    "p = pActiveInteractiveLapsPlotter\n",
    "num_laps_to_show = len(sess.laps.lap_id)\n",
    "num_laps_to_show = 5\n",
    "flat_lap_id_index = np.arange(len(sess.laps.lap_id))\n",
    "# subplot_lap_id_index = np.reshape([4,11])\n",
    "for i in np.arange(num_laps_to_show):\n",
    "    curr_lap_id = sess.laps.lap_id[i]\n",
    "    p.subplot(i, 0)\n",
    "    # curr_lap_t_start, curr_lap_t_stop = sess.laps.get_lap_times(i)\n",
    "    plot_lap_trajectory_path_spline(iplapsDataExplorer, laps_position_traces[i], curr_lap_id)\n",
    "    \n",
    "p.link_views()  # link all the views\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646febe2-b13c-4657-846c-779aa7c05fff",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def plot_placefields2D(pTuningCurves, active_placefields, pf_colors: np.ndarray, zScalingFactor=10.0, show_legend=False):\n",
    "\n",
    "#     # .threshold().elevation()\n",
    "\n",
    "#     curr_tuning_curves = active_placefields.ratemap.normalized_tuning_curves\n",
    "#     # curr_tuning_curves[curr_tuning_curves < 0.1] = np.nan\n",
    "#     curr_tuning_curves = curr_tuning_curves * zScalingFactor\n",
    "\n",
    "#     num_curr_tuning_curves = len(curr_tuning_curves)\n",
    "#     # Get the cell IDs that have a good place field mapping:\n",
    "#     good_placefield_neuronIDs = np.array(active_placefields.ratemap.neuron_ids) # in order of ascending ID\n",
    "#     tuningCurvePlot_x, tuningCurvePlot_y = np.meshgrid(active_placefields.ratemap.xbin_centers, active_placefields.ratemap.ybin_centers)\n",
    "\n",
    "#     pdata_currActiveNeuronTuningCurve = pv.StructuredGrid(tuningCurvePlot_x, tuningCurvePlot_y, curr_active_neuron_tuning_Curve)\n",
    "#     pdata_currActiveNeuronTuningCurve[\"Elevation\"] = curr_active_neuron_tuning_Curve.ravel(order=\"F\")\n",
    "        \n",
    "#     return pTuningCurves\n",
    "\n",
    "# plot_placefields2D(pTuningCurves, active_epoch_placefields\n",
    "\n",
    "# ipcDataExplorer.plots['spikes_pf_active']['cellID']\n",
    "\n",
    "# only_active_colormap = ipcDataExplorer.active_config.plotting_config.active_cells_listed_colormap.copy()\n",
    "# only_active_colormap\n",
    "test_full_pc_data = ipcDataExplorer.plots_data['spikes_pf_active']['historical_spikes_pc']\n",
    "\n",
    "# test_subset = test_full_pc_data.GetCellGhostArray()\n",
    "# test_subset = test_full_pc_data.GetCellData() # vtkmodules.vtkCommonDataModel.vtkCellData\n",
    "# test_subset = test_full_pc_data[test_full_pc_data['cellID'] == 55] # vtkmodules.vtkCommonDataModel.vtkCellData\n",
    "\n",
    "# test_subset = test_full_pc_data.GetGhostArray() # [test_full_pc_data['cellID'] == 55] # vtkmodules.vtkCommonDataModel.vtkCellData\n",
    "\n",
    "\n",
    "unique_ids = np.unique(test_full_pc_data['cellID']) # array([ 0,  1,  2,  3,  5,  7,  9, 10, 15, 16, 19, 20, 21, 22, 25, 26, 27, 31, 32, 36, 37, 40, 42, 43, 44, 45, 46, 51, 53, 55, 56])\n",
    "# count_arr = np.bincount(test_full_pc_data['cellID'])\n",
    "count_arr\n",
    "# array([ 3591,  3311,   231,  4410,     0,   910,     0,  4417,     0,\n",
    "#         1050,  2443,     0,     0,     0,     0,  2156,  6664,     0,\n",
    "#            0, 10052,  6286,  2394,  1561,     0,     0,  8827,  4788,\n",
    "#         6412,     0,     0,     0,   959,  2051,     0,     0,     0,\n",
    "#         4809,  2758,     0,     0,  1575,     0,  3465, 14861,  2212,\n",
    "#          777,  2772,     0,     0,     0,     0,  3206,     0,  4032,\n",
    "#            0,  6489,  2674], dtype=int64)\n",
    "\n",
    "# good_placefield_neuronIDs: [  5   8  10  13  14  16  19  21  23  25  28  31  32  33  36  37  41  49\n",
    "#   52  53  54  55  57  59  60  61  62  63  64  66  68  69  74  75  76  78\n",
    "#   83  86  88  89  90  92  96  98 105 108]; (46 good)\n",
    "\n",
    "# 1, 4, 6, 7, 8, 11, 18, 19, 21 ## CONCLUSION: the ones that work are indeed the non-zero entries, but the checkboxes work in reverse order to this array that's printed. Meaning you start at the end and work back.\n",
    "# len(count_arr) # 107\n",
    "print(unique_ids) # [  3   6   8  11  12  14  17  19  21  23  26  29  30  31  34  35  39  47\n",
    "  # 50  51  52  53  55  57  58  59  60  61  62  64  66  67  72  73  74  76\n",
    "  # 81  84  86  87  88  90  94  96 103 106]\n",
    "\n",
    "\n",
    "# uniques, indicies, inverse_indicies, count_arr = np.unique(active_epoch_session.spikes_df['aclu'].values, return_index=True, return_inverse=True, return_counts=True)\n",
    "# # count_arr = np.bincount(active_epoch_session.spikes_df['aclu'].values)\n",
    "# print('active_epoch_session.spikes_df unique aclu values: {}'.format(uniques))\n",
    "# print('active_epoch_session.spikes_df unique aclu value counts: {}'.format(count_arr))\n",
    "# print(len(uniques)) # 46 \n",
    "# uniques, indicies, inverse_indicies, count_arr = np.unique(active_epoch_session.spikes_df['unit_id'].values, return_index=True, return_inverse=True, return_counts=True)\n",
    "# # count_arr = np.bincount(active_epoch_session.spikes_df['unit_id'].values)\n",
    "# print('active_epoch_session.spikes_df unique unit_id values: {}'.format(uniques))\n",
    "# print('active_epoch_session.spikes_df unique unit_id value counts: {}'.format(count_arr))\n",
    "# print(len(uniques)) # 46 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53837d28-4831-4655-8db6-f6b104ab0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pActiveTuningCurvesPlotter.export_obj('export.obj')\n",
    "# pActiveTuningCurvesPlotter.export_gltf('export.gltf')\n",
    "\n",
    "ipcDataExplorer.update_placefield_spike_visibility([38], True) # seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b25f57-c2f7-424d-8ba2-95d15deb3522",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcDataExplorer.update_placefield_spike_visibility([53], True) # seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ac6e02-fee8-4c30-811f-4d29de766b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcDataExplorer.update_placefield_spike_visibility([44, 53], True) # seems to work\n",
    "\n",
    "# test_subset\n",
    "# test_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc26f9e-d03b-42c0-90e0-dfe4dfd3b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcDataExplorer.update_placefield_spike_visibility([53, 44], False) # seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1bdbd9-9d3a-4c55-8b22-417adb733cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcDataExplorer.gui['tuningCurveSpikeVisibilityCallbacks'][1](False)\n",
    "# ipcDataExplorer.get_cell_index([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00b059-3073-45fb-94df-3b0c7b818d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = ipcDataExplorer.plots_data['spikes_pf_active']['historical_spikes_pc'].cast_to_unstructured_grid()\n",
    "# mesh.n_cells\n",
    "mesh_unique_ids = np.unique(mesh['cellID'])\n",
    "print('n_cells: {}'.format(mesh.n_cells)) # 122143\n",
    "print('cellIDs of mesh: {}'.format(mesh_unique_ids))\n",
    "# np.unique(mesh['cellID']) # array([ 0,  1,  2,  3,  5,  7,  9, 10, 15, 16, 19, 20, 21, 22, 25, 26, 27, 31, 32, 36, 37, 40, 42, 43, 44, 45, 46, 51, 53, 55, 56])\n",
    "# ipcDataExplorer.hide_placefield_spikes([0,1,2,3], should_invert=True)\n",
    "# ipcDataExplorer.hide_placefield_spikes([23,2,34], should_invert=True)\n",
    "\n",
    "# ipcDataExplorer.hide_placefield_spikes([34], should_invert=True)\n",
    "ipcDataExplorer.hide_placefield_spikes([38], should_invert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a1565-0a1f-423a-900f-c97e9cbbbb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list of spike times that occured for this cell:\n",
    "i = 2\n",
    "active_epoch_session.neurons.neuron_ids[i]\n",
    "active_epoch_session.neurons.spiketrains[i]\n",
    "\n",
    "# spikes_df = FlattenedSpiketrains.build_spike_dataframe(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b2bd34-f09b-4c72-b02c-3650eea21f6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Timestamp Fixing:\n",
    "def tt(position_timestamps, t_begin, SampleRate):\n",
    "    return ((position_timestamps - t_begin) / (1e6 * SampleRate))\n",
    "\n",
    "# sess.laps.lap_start_stop_flat_idx\n",
    "\n",
    "sess.recinfo.dat_sampling_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239326ba-1294-4655-9f34-10f25316b656",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Programmatically change the animal position trail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9a0b7-fcf2-442c-a36d-d72e89a73a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_lap_id = int_input.value\n",
    "\n",
    "# plot_lap_trajectory_path(ipspikesDataExplorer, curr_lap_position_traces)\n",
    "plot_lap_trajectory_path_spline(ipspikesDataExplorer, curr_lap_position_traces)\n",
    "# curr_lap_t_start\n",
    "## TODO: enable showding/hiding the spikes for this data range programmatically in InteractivePlaceCellDataExplorer. \n",
    "# ipspikesDataExplorer.\n",
    "# curr_lap_spike_t_seconds\n",
    "# curr_lap_spike_indicies\n",
    "# active_epoch_session.flattened_spiketrains.spikes_df.t_seconds.values[curr_lap_spike_indicies] # index 145937 is out of bounds for axis 0 with size 19647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c721731e-4a61-4656-adcf-da1386aee30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the laps and position dataframe, extract which lap every position belongs to:\n",
    "\n",
    "# curr_lap_position_df_is_included = curr_position_df['t'].between(laps_df['start'], laps_df['stop'], inclusive=True) # returns a boolean array indicating inclusion in teh current lap\n",
    "# curr_lap_position_df = curr_position_df[curr_lap_position_df_is_included] \n",
    "# curr_position_df['lap'] = np.NaN\n",
    "\n",
    "curr_position_df = sess.compute_position_laps()\n",
    "# curr_position_df.groupby('lap').groups[1] # returns the Int64Index\n",
    "# curr_position_df.groupby('lap').get_group(2)[['t','x','y','lin_pos']]\n",
    "\n",
    "lap_specific_position_dfs = [curr_position_df.groupby('lap').get_group(i)[['t','x','y','lin_pos']] for i in sess.laps.lap_id]\n",
    "lap_specific_position_dfs\n",
    "curr_lap_position_traces = [lap_pos_df[['x','y']].to_numpy().T for lap_pos_df in lap_specific_position_dfs]\n",
    "curr_lap_position_traces\n",
    "curr_lap_time_range = [[lap_pos_df[['t']].to_numpy()[0].item(), lap_pos_df[['t']].to_numpy()[-1].item()] for lap_pos_df in lap_specific_position_dfs]\n",
    "curr_lap_time_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90554b89-1a4f-43c0-a888-920d262d9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .GetPosition() returns the actor's position, which is usually (0.0, 0.0, 0.0), and does not relate to the actor's data points\n",
    "# curr_animal_point = ipspikesDataExplorer.animal_location_trail.GetPosition()\n",
    "# curr_animal_point = ipspikesDataExplorer.animal_location_trail.GetXRange() # (44.23604202270508, 245.9059600830078)\n",
    "# print(curr_animal_point)\n",
    "# curr_animal_point = ipspikesDataExplorer.animal_location_trail.GetYRange() # (135.27638244628906, 145.448974609375)\n",
    "# print(curr_animal_point)\n",
    "# curr_animal_point = ipspikesDataExplorer.animal_location_trail.GetZRange() # (1.100000023841858, 1.100000023841858)\n",
    "\n",
    "curr_animal_point = np.array(ipspikesDataExplorer.animal_location_trail.GetCenter()) # (206.27755737304688, 140.15452575683594, 1.100000023841858)\n",
    "print('curr_animal_point: {}'.format(curr_animal_point))\n",
    "curr_animal_point # curr_animal_point\n",
    "\n",
    "# curr_animal_point = np.array([0, 0, 0])\n",
    "\n",
    "# curr_animal_point = np.column_stack((self.x[active_window_sample_indicies], self.y[active_window_sample_indicies], self.z_fixed))\n",
    "# ipspikesDataExplorer.on_programmatic_data_update(curr_animal_point=curr_animal_point)\n",
    "\n",
    "curr_debug_point = np.array(ipspikesDataExplorer.animal_location_trail.GetCenter()) # (206.27755737304688, 140.15452575683594, 1.100000023841858)\n",
    "ipspikesDataExplorer.perform_plot_location_point('debug_point_plot', curr_animal_point, color='r')\n",
    "\n",
    "curr_animal_point = np.array(ipspikesDataExplorer.animal_location_trail.GetCenter()) # not updated\n",
    "print('new curr_animal_point: {}'.format(curr_animal_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ac6391-89e5-4452-bbdb-12338332da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipspikesDataExplorer.flattened_spike_positions_list\n",
    "\n",
    "active_epoch_session.flattened_spiketrains.time_slice(curr_lap_spike_t_seconds.values[0], curr_lap_spike_t_seconds.values[-1]).spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ffb93-dd70-4eae-86dc-4498d39f7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_lap_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a1bec-6aa9-4942-b590-5b9e407106ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epoch_session.time_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9639c15-312d-4bbb-938a-0bc8a0d51a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b81d4e-b4ff-4e2f-bb2b-dc753c1a0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding interaction highlighters:\n",
    "pActiveInteractivePlaceSpikesPlotter."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "fde6e68fa8f5f4f0920a88ee99edd8d4121f14a57a7800ceb19ed197f25c05dc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
