{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed23d389-0bd6-4c9b-9a11-ee200ce372b0",
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import traceback # for stack trace formatting\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from benedict import benedict\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# # os.environ[\"MODIN_ENGINE\"] = \"ray\"  # Modin will use Ray\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"dask\"  # Modin will use Dask\n",
    "# # os.environ[\"MODIN_ENGINE\"] = \"unidist\" # Modin will use Unidist\n",
    "# # os.environ[\"UNIDIST_BACKEND\"] = \"mpi\" # Unidist will use MPI backend\n",
    "# import modin.pandas as pd # alternative to pandas which is much faster\n",
    "# # Installed with `poetry add modin[all]`\n",
    "\n",
    "# from pandas_profiling import ProfileReport ## for dataframe viewing\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from benedict import benedict # https://github.com/fabiocaccamo/python-benedict#usage\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import CodeConversion\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible, print_value_overview_only, document_active_variables, objsize, print_object_memory_usage, debug_dump_object_member_shapes, TypePrintMode\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "\n",
    "# from PendingNotebookCode import _perform_batch_plot, _build_batch_plot_kwargs\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import batch_load_session, batch_extended_computations, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "session_batch_status = {}\n",
    "session_batch_errors = {}\n",
    "enable_saving_to_disk = False\n",
    "\n",
    "global_data_root_parent_path = Path(r'W:\\Data') # Windows Apogee\n",
    "# global_data_root_parent_path = Path(r'/media/MAX/Data') # Diba Lab Workstation Linux\n",
    "# global_data_root_parent_path = Path(r'/Volumes/MoverNew/data') # rMBP\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "tags": [
     "load"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_session_names_list: ['2006-6-07_11-26-53', '2006-6-08_14-26-15', '2006-6-09_1-22-43', '2006-6-09_3-23-37', '2006-6-12_15-55-31', '2006-6-13_14-42-6']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-07_11-26-53'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_3-23-37'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-13_14-42-6'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "#     neuropy/data_session_pre_processing_scripts/KDIBA/IIDataMat_Export_ToPython_2022_08_01.m\n",
    "# From pre-computed .mat files:\n",
    "\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "## Animal `gor01`:\n",
    "local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='one') # IdentifyingContext<('kdiba', 'gor01', 'one')>\n",
    "local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # 'gor01', 'one'\n",
    "local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['PhoHelpers', 'Spike3D-Minimal-Test', 'Unused'])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "### Animal `vvp01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# ### Animal `pin01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='pin01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # no exper_name ('one' or 'two') folders for this animal.\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['redundant','showclus','sleep','tmaze'])\n",
    "\n",
    "## Build session contexts list:\n",
    "local_session_contexts_list = [local_session_parent_context.adding_context(collision_prefix='sess', session_name=a_name) for a_name in local_session_names_list] # [IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-07_11-26-53')>, ..., IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-13_14-42-6')>]\n",
    "\n",
    "## Initialize `session_batch_status` with the NOT_STARTED status if it doesn't already have a different status\n",
    "for curr_session_basedir in local_session_paths_list:\n",
    "    curr_session_status = session_batch_status.get(curr_session_basedir, None)\n",
    "    if curr_session_status is None:\n",
    "        session_batch_status[curr_session_basedir] = SessionBatchProgress.NOT_STARTED # set to not started if not present\n",
    "        # session_batch_status[curr_session_basedir] = SessionBatchProgress.COMPLETED # set to not started if not present\n",
    "\n",
    "session_batch_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a52bab20-baf7-4510-b90a-a55696b962b4",
   "metadata": {
    "tags": [
     "load",
     "single_session"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl.\n",
      "property already present in pickled version. No need to save.\n",
      "using provided computation_functions_name_whitelist: ['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_two_step_position_decoding_computation']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# %%viztracer\n",
    "basedir = local_session_paths_list[1] # NOT 3\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# epoch_name_whitelist = ['maze']\n",
    "epoch_name_whitelist = None\n",
    "active_computation_functions_name_whitelist=['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        # '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        # '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding'\n",
    "                                    ]\n",
    "curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_whitelist=epoch_name_whitelist,\n",
    "                                          computation_functions_name_whitelist=active_computation_functions_name_whitelist,\n",
    "                                          saving_mode=PipelineSavingScheme.SKIP_SAVING, force_reload=False, skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d77d8-811b-4402-a37d-dcd82efa8fc9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "lines_to_next_cell": 2,
    "tags": [
     "decoder"
    ]
   },
   "source": [
    "# 2023-02-24 Decoders \n",
    "- [ ] where are cells chosen for inclusion in the input of the decoder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5cf00e-cd16-40ab-a8f9-7b0b2c4c36ed",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "decoder"
    ]
   },
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "\n",
    "recalculate_anyway = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17793403-7842-4c6c-ade7-2a0c487f777d",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "decoder"
    ]
   },
   "outputs": [],
   "source": [
    "# Make the 1D Placefields and Decoders conform between the long and the short epochs:\n",
    "long_pf1D = long_results.pf1D\n",
    "short_pf1D = short_results.pf1D\n",
    "global_pf1D = global_results.pf1D\n",
    "\n",
    "# short_pf1D, did_update_bins = short_pf1D.conform_to_position_bins(long_pf1D, force_recompute=True) # not needed because it's done in one_step_decoder_1D.conform_to_position_bins(...)\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D  = [results_data.get('pf1D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "short_one_step_decoder_1D, did_recompute = short_one_step_decoder_1D.conform_to_position_bins(long_one_step_decoder_1D, force_recompute=True)\n",
    "\n",
    "## Build or get the two-step decoders for both the long and short:\n",
    "long_two_step_decoder_1D, short_two_step_decoder_1D  = [results_data.get('pf1D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "if recalculate_anyway or did_recompute or (long_two_step_decoder_1D is None) or (short_two_step_decoder_1D is None):\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_two_step_position_decoding_computation'], computation_kwargs_list=[dict(ndim=1)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "    long_two_step_decoder_1D, short_two_step_decoder_1D  = [results_data.get('pf1D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "    assert (long_two_step_decoder_1D is not None and short_two_step_decoder_1D is not None)\n",
    "\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "# decoding_time_bin_size = 0.03 # 0.03333333333333333\n",
    "print(f'decoding_time_bin_size: {decoding_time_bin_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361fc6cd-84b9-405f-bf53-6b66a6c32525",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "decoder"
    ]
   },
   "source": [
    "#### Get 2D Decoders for validation and comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b9806-923f-42fd-921f-1f75bdddc5cb",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "decoder"
    ]
   },
   "outputs": [],
   "source": [
    "# Make the 2D Placefields and Decoders conform between the long and the short epochs:\n",
    "long_pf2D = long_results.pf2D\n",
    "short_pf2D = short_results.pf2D\n",
    "global_pf2D = global_results.pf2D\n",
    "\n",
    "# long_one_step_decoder_2D, short_one_step_decoder_2D  = [results_data.get('pf2D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "# long_two_step_decoder_2D, short_two_step_decoder_2D  = [results_data.get('pf2D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "\n",
    "# short_pf2D, did_update_bins = short_pf2D.conform_to_position_bins(long_pf2D)\n",
    "long_one_step_decoder_2D, short_one_step_decoder_2D  = [results_data.get('pf2D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "short_one_step_decoder_2D, did_recompute = short_one_step_decoder_2D.conform_to_position_bins(long_one_step_decoder_2D)\n",
    "\n",
    "## Build or get the two-step decoders for both the long and short:\n",
    "long_two_step_decoder_2D, short_two_step_decoder_2D  = [results_data.get('pf2D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "if recalculate_anyway or did_recompute or (long_two_step_decoder_2D is None) or (short_two_step_decoder_2D is None):\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_two_step_position_decoding_computation'], computation_kwargs_list=[dict(ndim=1)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "    long_two_step_decoder_2D, short_two_step_decoder_2D  = [results_data.get('pf2D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "    assert (long_two_step_decoder_2D is not None and short_two_step_decoder_2D is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43499e87-0693-4d11-9d33-100a987737ac",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "decoder"
    ]
   },
   "outputs": [],
   "source": [
    "# Sums are similar:\n",
    "print(f'{np.sum(long_one_step_decoder_2D.marginal.x.p_x_given_n) =},\\t {np.sum(long_one_step_decoder_1D.p_x_given_n) = }') # 31181.999999999996 vs 31181.99999999999\n",
    "\n",
    "## Validate:\n",
    "assert long_one_step_decoder_2D.marginal.x.p_x_given_n.shape == long_one_step_decoder_1D.p_x_given_n.shape, f\"Must equal but: {long_one_step_decoder_2D.marginal.x.p_x_given_n.shape =} and {long_one_step_decoder_1D.p_x_given_n.shape =}\"\n",
    "assert long_one_step_decoder_2D.marginal.x.most_likely_positions_1D.shape == long_one_step_decoder_1D.most_likely_positions.shape, f\"Must equal but: {long_one_step_decoder_2D.marginal.x.most_likely_positions_1D.shape =} and {long_one_step_decoder_1D.most_likely_positions.shape =}\"\n",
    "\n",
    "## validate values:\n",
    "assert np.allclose(long_one_step_decoder_2D.marginal.x.p_x_given_n, long_one_step_decoder_1D.p_x_given_n), f\"1D Decoder should have an x-posterior equal to its own posterior\"\n",
    "assert np.allclose(curr_epoch_result['marginal_x']['most_likely_positions_1D'], curr_epoch_result['most_likely_positions']), f\"1D Decoder should have an x-posterior with most_likely_positions_1D equal to its own most_likely_positions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7372d125-bca4-4dba-a4bc-ca1fd83d918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gate the spikes that are coming in to build the decoder... those are from the placefields actually.\n",
    "    # so it'll be gating the placefield cells.\n",
    "    \n",
    "active_config_name = 'maze1'\n",
    "active_pf_1D = long_pf1D\n",
    "# curr_active_pipeline.computation_results['maze']."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275c444-2439-4d16-bbf3-35d8b777d93c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Testing Placefields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c086de63-62f8-4226-8d74-9930580b30ff",
   "metadata": {
    "tags": [
     "required_imports"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "from neuropy.utils.misc import split_list_of_dicts\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.analyses.placefields import PfND\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_subsession_neuron_differences, debug_print_ratemap, debug_print_spike_counts, debug_plot_2d_binning, print_aligned_columns\n",
    "from neuropy.utils.debug_helpers import parameter_sweeps, _plot_parameter_sweep, compare_placefields_info\n",
    "from PendingNotebookCode import _compute_parameter_sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afab4d0e-0df1-42c4-9d4a-7f3596217965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - [ ] Test that changing the position bins post-hoc is equivalent to initially computing with those position bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a7f8f-6f12-4539-be0a-9bc9f7aa07ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get testing variables from `curr_active_pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ec24bfe-191c-4244-890d-5183053a61f5",
   "metadata": {
    "tags": [
     "curr_active_pipeline"
    ]
   },
   "outputs": [],
   "source": [
    "sess = curr_active_pipeline.filtered_sessions['maze']\n",
    "spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "pyramidal_only_spikes_df = deepcopy(spikes_df).spikes.sliced_by_neuron_type('pyramidal') ## get only the pyramidal spikes\n",
    "active_pos = curr_active_pipeline.sess.position\n",
    "active_pos_df = active_pos.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4583150b-eb31-4ebf-a5bb-b35444c450b3",
   "metadata": {
    "tags": [
     "curr_active_pipeline"
    ]
   },
   "outputs": [],
   "source": [
    "## Save for NeuroPy testing:\n",
    "finalized_output_cache_file='../NeuroPy/tests/neuropy_pf_testing.h5'\n",
    "sess_identifier_key='sess'\n",
    "spikes_df.to_hdf(finalized_output_cache_file, key=f'{sess_identifier_key}/spikes_df')\n",
    "active_pos.to_dataframe().to_hdf(finalized_output_cache_file, key=f'{sess_identifier_key}/pos_df', format='table')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa9344-c10b-488a-855f-b5547a324393",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load testing variables from file 'NeuroPy/tests/neuropy_pf_testing.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03923ef5-5e66-4ee8-84a0-eaee7622222f",
   "metadata": {
    "tags": [
     "load",
     "independent"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\" Corresponding load for Neuropy Testing file 'NeuroPy/tests/neuropy_pf_testing.h5': \n",
    "    ## Save for NeuroPy testing:\n",
    "    finalized_output_cache_file='../NeuroPy/tests/neuropy_pf_testing.h5'\n",
    "    sess_identifier_key='sess'\n",
    "    spikes_df.to_hdf(finalized_output_cache_file, key=f'{sess_identifier_key}/spikes_df')\n",
    "    active_pos.to_dataframe().to_hdf(finalized_output_cache_file, key=f'{sess_identifier_key}/pos_df', format='table')\n",
    "\"\"\"\n",
    "finalized_output_cache_file='../NeuroPy/tests/neuropy_pf_testing.h5'\n",
    "sess_identifier_key='sess'\n",
    "# Load the saved .h5 spikes_df and active_pos dataframes for testing:\n",
    "spikes_df = pd.read_hdf(finalized_output_cache_file, key=f'{sess_identifier_key}/spikes_df')\n",
    "pyramidal_only_spikes_df = deepcopy(spikes_df).spikes.sliced_by_neuron_type('pyramidal') ## get only the pyramidal spikes\n",
    "\n",
    "active_pos_df = pd.read_hdf(finalized_output_cache_file, key=f'{sess_identifier_key}/pos_df')\n",
    "active_pos = active_pos_df.position.to_Position_obj() # convert back to a full position object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d54730-06da-4290-8d62-c619dbc82ad8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Conduct Parameter Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21053b39-214b-49be-905c-da33146f27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth_options = [(None, None), (0.5, 0.5), (1.0, 1.0), (2.0, 2.0), (5.0, 5.0)]\n",
    "# grid_bin_options = [(1,1),(5,5),(10,10)]\n",
    "# grid_bin_options = [(5,5)]\n",
    "# param_sweep_option_n_values = dict(smooth=len(smooth_options), grid_bin=len(grid_bin_options)) \n",
    "\n",
    "smooth_options = [(None, None), (0.5, 0.5), (1.0, 1.0)]\n",
    "grid_bin_options = [(0.5, 0.5), (1.0, 1.0), (2.0, 2.0), (5.0, 5.0)]\n",
    "all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(smooth=smooth_options, grid_bin=grid_bin_options)\n",
    "output_pfs = _compute_parameter_sweep(spikes_df, active_pos, all_param_sweep_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da3cfbc-5fff-41da-ba7e-a6ca1ffc9e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_thresh_options = [0.0, 1.0, 25.0, 50.0, 100.0, 200.0]\n",
    "all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(speed_thresh=speed_thresh_options)\n",
    "output_pfs = _compute_parameter_sweep(spikes_df, active_pos, all_param_sweep_options)\n",
    "print_aligned_columns(['speed_thresh', 'num_good_neurons', 'num_total_spikes'], [speed_thresh_options, num_good_placefield_neurons_list, num_total_spikes_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf913cb9-3cc4-4289-ab0c-39ee28167ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "frate_thresh_options = [0.0, 0.1, 1.0, 5.0, 10.0, 100.0]\n",
    "all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(frate_thresh=frate_thresh_options)\n",
    "output_pfs = _compute_parameter_sweep(spikes_df, active_pos, all_param_sweep_options)\n",
    "print_aligned_columns(['frate_thresh', 'num_good_neurons', 'num_total_spikes'], [frate_thresh_options, num_good_placefield_neurons_list, num_total_spikes_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f999df69-49b9-49f1-9698-1c7ee62afe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = _plot_parameter_sweep(output_pfs, param_sweep_option_n_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337434e7-eb87-48e4-8de6-8245a51c9b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_config.computation_config = PlacefieldComputationParameters(speed_thresh=0.0, grid_bin=(5, 3), smooth=(0.0, 0.0), frate_thresh=0.1) # TODO: FIXME: BUG: when frate_thresh=0.0, there are 0 good placefield_neuronIDs for all computations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06062812-4281-4f78-89e1-7c17614c340b",
   "metadata": {},
   "source": [
    "### PfND_TimeDependent Parameter Sweeps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb234b7-7215-4189-818a-2687a6977aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "\n",
    "# PfND_TimeDependent\n",
    "orginal_pf1D_dt = PfND_TimeDependent(deepcopy(spikes_df).spikes.sliced_by_neuron_type('pyramidal'), deepcopy(active_pos.linear_pos_obj), frate_thresh=0.0)\n",
    "orginal_pf1D_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a54e573-d047-4f17-a080-23e656fa26b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2023-03-03 - Decoder Testing\n",
    "Useful Decoder-related plotting and visuzliation classes:\n",
    "```python\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5645b541-4830-46ad-b7b2-087b7d3c16e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext viztracer\n",
    "from viztracer import VizTracer\n",
    "\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BayesianPlacemapPositionDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e250e4a6-df77-4617-8a99-dd91618be259",
   "metadata": {},
   "outputs": [],
   "source": [
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-build_new_PfND.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    ## Build placefield for the decoder to use:\n",
    "    original_pf1D = PfND(deepcopy(pyramidal_only_spikes_df), deepcopy(active_pos.linear_pos_obj), frate_thresh=0.0) # all other settings default\n",
    "\n",
    "    new_decoder_pf_params = deepcopy(original_pf1D.config) # should be a PlacefieldComputationParameters\n",
    "    # override some settings before computation:\n",
    "    new_decoder_pf_params.time_bin_size = 0.1\n",
    "\n",
    "    ## 1D Decoder\n",
    "    new_decoder_pf1D = original_pf1D\n",
    "    new_1D_decoder_spikes_df = new_decoder_pf1D.filtered_spikes_df.copy()\n",
    "\n",
    "    # Why would it need both the pf1D and the spikes? Doesn't the pf1D include the spikes (and determine the placefields, which are all that are used)???\n",
    "    new_1D_decoder = BayesianPlacemapPositionDecoder(new_decoder_pf_params.time_bin_size, new_decoder_pf1D, new_1D_decoder_spikes_df, debug_print=False)\n",
    "    new_1D_decoder.compute_all()\n",
    "\n",
    "    print(f'done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca005c14-bd80-451f-b691-7000f72e764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_1D_decoder.time_bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c84ece5-564f-4e0a-b806-ebdb1e94d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_decoder = new_1D_decoder # strangely this makes original_pf.included_neuron_IDs wrapped in an extra list!\n",
    "original_neuron_ids = np.array(original_decoder.pf.ratemap.neuron_ids) # original_pf.included_neuron_IDs\n",
    "subset_included_neuron_IDXs = np.arange(10) # only get the first 10 neuron_ids\n",
    "subset_included_neuron_ids = original_neuron_ids[subset_included_neuron_IDXs] # only get the first 10 neuron_ids\n",
    "print(f'{original_neuron_ids = }\\n{subset_included_neuron_ids = }')\n",
    "neuron_sliced_1D_decoder = original_decoder.get_by_id(subset_included_neuron_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d14c5-2b64-4f19-bae4-64910c68b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_sliced_1D_decoder.neuron_IDXs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e48db7-800a-403a-bf3d-63c91d73647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PfND\n",
    "get_by_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae1ac0-b7f4-40df-957d-c42ad74ee704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffc90d44-7231-40e4-851c-a276a810434b",
   "metadata": {},
   "source": [
    "## Specific Epoch Decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f5acd-f070-4242-a528-18cf5956e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e3a8c5-944e-402a-b1c2-177821d70019",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lap-Epochs Decoding:\n",
    "sess = curr_active_pipeline.filtered_sessions['maze']\n",
    "active_decoder = new_1D_decoder\n",
    "decoding_time_bin_size = 0.02\n",
    "global_pos_df = sess.position.to_dataframe()\n",
    "\n",
    "laps_copy = deepcopy(sess.laps)\n",
    "laps_filter_epochs = laps_copy.filtered_by_lap_flat_index(np.arange(6)).as_epoch_obj() # epoch object\n",
    "laps_filter_epochs_decoder_result = active_decoder.decode_specific_epochs(sess.spikes_df, filter_epochs=laps_filter_epochs, decoding_time_bin_size=decoding_time_bin_size, debug_print=False)\n",
    "laps_filter_epochs_decoder_result.epoch_description_list = [f'lap[{epoch_tuple.lap_id}]' for epoch_tuple in laps_filter_epochs.to_dataframe()[['lap_id']].itertuples()] # Short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333e2be-bf03-4c34-8342-00dfaa0cd396",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_plot_tuple = plot_decoded_epoch_slices(laps_filter_epochs, laps_filter_epochs_decoder_result, global_pos_df=global_pos_df, variable_name='lin_pos', xbin=active_decoder.xbin,\n",
    "                                                        name='stacked_epoch_slices_matplotlib_subplots_LAPS', debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5cf84-156a-4fbe-8102-2ede8e114138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create legend object and add to figure\n",
    "last_axes = list(laps_plot_tuple[2].axs)[-1]\n",
    "last_axes.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51317ae-2c9c-4064-aa30-0f1fe2e0e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_plot_tuple[2].fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a7d6a9-daa9-4cc6-a289-33a9f7adc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_legend = laps_plot_tuple[2].fig.legend(handles=list(laps_plot_tuple[2].axs), labels=[p.get_label() for p in list(laps_plot_tuple[2].axs)], loc='lower center', ncol=4) #\n",
    "out_legend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6684d5-5162-4ce0-b563-bf9754c3191b",
   "metadata": {},
   "source": [
    "## \"Leave-one-out\" decoding:\n",
    "\n",
    "2023-03-09 - IDEA - 9/10 - \"Each Decoded time-bin's Neuronal Contribution\" - In addition to the performance be measured for the whole decoded epoch (mean squared error across all decoded time bins in an epoch) we could also look at it for each time bin at a time.\n",
    "That means at a given time bin we'd have a vector that reflects how much error is introduced by leaving out a certain cell. Since the animal is at a fixed place in each time bin (approximately) we expect most cells to contribute little to the decoding of that bin and a few cells (the ones with that place field) to contribute a lot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f24e6f-7724-4e65-85b1-96f1f8038edf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BayesianPlacemapPositionDecoder\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import perform_leave_one_aclu_out_decoding_analysis\n",
    "\n",
    "## Lap-Epochs Decoding:\n",
    "sess = curr_active_pipeline.sess\n",
    "# decoding_time_bin_size = 0.02\n",
    "decoding_time_bin_size = 0.5\n",
    "\n",
    "# Common for all decoders:\n",
    "laps_copy = deepcopy(sess.laps)\n",
    "active_filter_epochs = laps_copy.filtered_by_lap_flat_index(np.arange(20)).as_epoch_obj() # epoch object\n",
    "filter_epoch_description_list = [f'lap[{epoch_tuple.lap_id}]' for epoch_tuple in active_filter_epochs.to_dataframe()[['lap_id']].itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f20a24-17c4-4a20-b1f9-1552a61edd9a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_1D_decoder, one_left_out_decoder_dict, one_left_out_filter_epochs_decoder_result_dict, one_left_out_omitted_aclu_distance_df, most_contributing_aclus = perform_leave_one_aclu_out_decoding_analysis(pyramidal_only_spikes_df, active_pos_df, active_filter_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b5bc3-aa60-4012-85dd-1b5bd172c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(one_left_out_filter_epochs_decoder_result_dict[2].most_likely_positions_list) # len(...): 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f681f7e-6e8f-4046-b91c-7a116074d28f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# one_left_out_filter_epochs_decoder_result_dict[aclu].most_likely_positions_list[epoch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e83b9-1782-4431-88e3-ebb436e5871c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plotting leave-one-out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4ee8c7-be9e-45b1-b421-a3aca5f4c86d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "laps_plot_tuple = plot_decoded_epoch_slices(active_filter_epochs,  one_left_out_filter_epochs_decoder_result_dict[2], global_pos_df=active_pos_df, variable_name='lin_pos', xbin=original_1D_decoder.xbin,\n",
    "                                                        name='stacked_epoch_slices_matplotlib_subplots_LAPS_leave_one_out', debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36951b80-958d-43d2-a7c7-0d93bae0bd85",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    " one_left_out_filter_epochs_decoder_result_dict[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f03895-8253-47a4-b992-1f790c5b7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_left_out_omitted_aclu_distance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a706e595-b36e-4b16-b775-60712d9923e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Get time-binned spikes during each epoch event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37c882a-187e-4ae9-8242-de2cef285b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Determine the probability of that observed neural sequence given the placefields.\n",
    "    # - [ ] Issue: this probability only accounts for the cells that are firing, not the ones that aren't firing, right?\n",
    "    Consider two cells (A and B) that highly correlated (effectively redundant) in a particular environment.\n",
    "        - IF we observe activity of A without activity B, that is highly suggestive that we are not representing this environment where they are correlated, right? But our likelihood doesn't measure this quanity.\n",
    "    # - [ ] Issue: The typical conditional probability assumes all cells are independent, which is specifically NOT the case, and especially not for replays.\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341a967f-500b-4261-b31d-9d8a34256ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a03b0e-9977-4af9-98a4-93021f804a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59608c2b-3b75-468c-989f-ae87449feb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_contributing_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff74922-f2d4-4998-84d5-2b99d3f1cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEBUG: Get just one of the decoders using a left-out cell:\n",
    "# left_out_aclu, curr_aclu_omitted_decoder = list(one_left_out_decoder_dict.items())[0]\n",
    "# left_out_aclu, curr_aclu_omitted_decoder = list(one_left_out_decoder_dict.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc051fc3-9af7-46d0-beae-eb1951970472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a simple plot for comparison:\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(curr_time_bins, window_center_measured_pos_x, label='measured')\n",
    "# ax.plot(curr_time_bins, curr_most_likely_positions, label=f'omit_{left_out_aclu}')\n",
    "ax.plot(curr_time_bins, curr_most_likely_valid_positions, label=f'valid only omit_{left_out_aclu}')\n",
    "plt.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c06b78f-f51b-41d0-b6e6-c1431c2df912",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(pos_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aae5aa-965e-4940-96a3-9f82b103105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_pos_df.resample(\n",
    "    time_binned_position_df\n",
    "    interpolate\n",
    "    \n",
    "time_binned_position_df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3ef89-e5da-4712-b675-02404eee8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_out_aclu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011f8ffa-0e1c-4e71-be0f-e35b54084c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_decoder.decode_specific_epochs("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa8904a-c517-4d64-8528-c776c76819c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95390cc6-4b60-4a98-a479-8a6c06cdace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_filter_epochs_decoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c46e5-655a-4cae-a920-1c0b26405eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_1D_decoder.compute_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e0f93-237b-441c-8667-3977e6c2ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import print_object_memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54771eca-b5dd-4250-a621-39a496c4ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_object_memory_usage(original_1D_decoder) # original_1D_decoder - object size: 90.199349 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a5dd56-1eee-4434-ade5-1c6a187b2ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_object_memory_usage(one_left_out_laps_filter_epochs_decoder_result_dict) # one_left_out_laps_filter_epochs_decoder_result_dict - object size: 403.150110 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e916ab-2baf-4a0d-91d2-33e51a33e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(one_left_out_decoder_dict) # 70\n",
    "print_object_memory_usage(one_left_out_decoder_dict) # object size: 12696.855616 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21ea59-269c-48df-a06c-30559680df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_decoder = list(one_left_out_decoder_dict.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b7111-5625-485e-8fa5-60b3ffb26042",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_decoder.decode_specific_epochs(spikes_df="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad59ae-10a3-4405-9d67-353196a1227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_decoder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30c2d58-c848-4cd1-b9a8-7a97374d1664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _perform_specific_epochs_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f58cc0-386a-4231-b9e4-1fee71f9fbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c86fd8ca-655e-4395-8020-42b37ff97106",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2023-02-27 - Test whether conform to active position works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8788d1-134b-4351-93bb-b142a4608b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Placefields with varying bin-sizes:\n",
    "### Here we use frate_thresh=0.0 which ensures that differently binned ratemaps don't have different numbers of spikes or cells.\n",
    "smooth_options = [(None, None)]\n",
    "grid_bin_options = [(0.5, 0.5), (1.0, 1.0), (2.0, 2.0), (5.0, 5.0)]\n",
    "all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(grid_bin=grid_bin_options, smooth=smooth_options, frate_thresh=[0.0])\n",
    "output_pfs = _compute_parameter_sweep(spikes_df, active_pos, all_param_sweep_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d501f7-0ac3-4cae-ad9e-9f655389bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_good_placefield_neurons_list, num_total_spikes_list, num_spikes_per_spiketrain_list = compare_placefields_info(output_pfs)\n",
    "print_aligned_columns(['grid_bin x smooth', 'num_good_neurons', 'num_total_spikes'], \n",
    "                     [all_param_sweep_options, num_good_placefield_neurons_list, num_total_spikes_list], enable_checking_all_values_width=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd76742-2059-41d3-8038-6cb4fcb5bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = _plot_parameter_sweep(output_pfs, param_sweep_option_n_values, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf605a2-24f2-4574-9520-81c0706f45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14fdbc-6a86-4de8-ad5c-0ce86fab500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sweep_option_n_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cbea74-64cb-4df0-bd35-fe621395a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_binned_pf = list(output_pfs.values())[0]\n",
    "coarse_binned_pf = list(output_pfs.values())[-1]\n",
    "\n",
    "print(f'{coarse_binned_pf.bin_info = }\\n{fine_binned_pf.bin_info = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51689e35-11d0-40c0-97c4-56daa9120748",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_binned_pf.bin_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c0b738-ad5f-46ac-914f-731a497c6ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_binned_pf.bin_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe5a9bc-3ec1-4d75-b257-3a039be88bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rebinned_fine_binned_pf = deepcopy(fine_binned_pf)\n",
    "rebinned_fine_binned_pf.conform_to_position_bins(target_pf1D=coarse_binned_pf, force_recompute=True)\n",
    "assert rebinned_fine_binned_pf.bin_info == coarse_binned_pf.bin_info # the bins must be equal after conforming\n",
    "\n",
    "num_good_placefield_neurons_list, num_total_spikes_list, num_spikes_per_spiketrain_list = compare_placefields_info(dict(zip(['coarse', 'original', 'rebinned'],[coarse_binned_pf, fine_binned_pf, rebinned_fine_binned_pf])))\n",
    "print_aligned_columns(['pf', 'num_good_neurons', 'num_total_spikes'], [['coarse', 'original', 'rebinned'], num_good_placefield_neurons_list, num_total_spikes_list], enable_checking_all_values_width=True)\n",
    "\n",
    "assert num_good_placefield_neurons_list[0] == num_good_placefield_neurons_list[-1] # require the rebinned pf to have the same number of good neurons as the one that it conformed to\n",
    "assert num_total_spikes_list[0] == num_total_spikes_list[-1] # require the rebinned pf to have the same number of total spikes as the one that it conformed to\n",
    "# assert num_spikes_per_spiketrain_list[0] == num_spikes_per_spiketrain_list[-1] # require the rebinned pf to have the same number of spikes in each spiketrain as the one that it conformed to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c6b01-b0eb-4dd6-b820-f0019b85420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO 2023-03-02: plot the three placefields next to each other horizontally (as a single row for comparison):\n",
    "fig, axs = _plot_parameter_sweep(dict(zip([frozenset({'pf':'coarse'}), frozenset({'pf':'original'}), frozenset({'pf':'rebinned'})],[coarse_binned_pf, fine_binned_pf, rebinned_fine_binned_pf])), {'pf':3}, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ddf44-053c-43df-9855-ab5b2d8ee8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test excluding certain neurons from the placefield\n",
    "original_pf = fine_binned_pf\n",
    "original_pf_neuron_ids = original_pf.included_neuron_IDs.copy()\n",
    "subset_included_neuron_IDXs = np.arange(10) # only get the first 10 neuron_ids\n",
    "subset_included_neuron_ids = original_pf_neuron_ids[subset_included_neuron_IDXs] # only get the first 10 neuron_ids\n",
    "print(f'{original_pf_neuron_ids = }\\n{subset_included_neuron_ids = }')\n",
    "neuron_sliced_pf = deepcopy(fine_binned_pf)\n",
    "neuron_sliced_pf = neuron_sliced_pf.get_by_id(subset_included_neuron_ids)\n",
    "neuron_sliced_pf_neuron_ids = neuron_sliced_pf.included_neuron_IDs\n",
    "print(f'{neuron_sliced_pf_neuron_ids = }')\n",
    "\n",
    "assert np.all(neuron_sliced_pf_neuron_ids == subset_included_neuron_ids) # ensure that the returned neuron ids actually equal the desired subset\n",
    "assert np.all(np.array(neuron_sliced_pf.ratemap.neuron_ids) == subset_included_neuron_ids) # ensure that the ratemap neuron ids actually equal the desired subset\n",
    "assert len(neuron_sliced_pf.ratemap.tuning_curves) == len(subset_included_neuron_ids) # ensure one output tuning curve for each neuron_id\n",
    "np.all(np.isclose(neuron_sliced_pf.ratemap.tuning_curves, [original_pf.ratemap.tuning_curves[idx] for idx in subset_included_neuron_IDXs])) # ensure that the tuning curves built for the neuron_slided_pf are the same as those subset as retrieved from the  original_pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e3c6ea-8629-499b-8233-33107a246504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron_sliced_pf.cell_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf2c25-b755-4407-a65c-23175d6493f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_sliced_pf.ratemap.tuning_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306cf13f-521f-4daa-9f92-0cc330ccaeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_pf.plot_ratemaps_1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd846fe-a582-48b1-982b-b0df6cec3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_sliced_pf.plot_ratemaps_1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c1ce59-7b74-4b58-81c7-679c5df50a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test selecting non-existant neuron_ids for inclusion:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c9faa1-307c-46a4-90f8-0021dc72f400",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2023-03-06 - Test Plotting Decoder leave-one-out paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064887c-1f93-4059-a857-41428e380ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation: `_perform_time_dependent_pf_sequential_surprise_computation`\n",
    "_perform_relative_entropy_analyses\n",
    "\"\"\" NOTE: 2022-12-14 - this mirrors the non-global version at `pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ExtendedStats.ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation` that I just modified except it only uses the global epoch.\n",
    "class TimeDependentPlacefieldSurpriseMode(ExtendedEnum):\n",
    "    \"\"\"for _perform_relative_entropy_analyses \"\"\"\n",
    "    STATIC_METHOD_ONLY = \"static_method_only\"\n",
    "    USING_EXTANT = \"using_extant\"\n",
    "    BUILD_NEW = \"build_new\"\n",
    "    \n",
    "\n",
    "\n",
    "_perform_time_dependent_pf_sequential_surprise_computation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57342a6b-80fc-4f24-ae35-2830736b51cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2023-03-07 - Look at scISIs for simple expectation violation in replays/laps given decoders\n",
    "Would like to build a distribution (potentially poisson) that models the temporal relation between two spikes of each unit (e.g. cell_i and cell_j). This allows us to assess how likely it is that any two spikes (spike_i_t, spike_j_t+1) are to be sampled from this distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ad2a9-844a-4868-b6aa-1549c586c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_df.spikes.add_same_cell_ISI_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b00fd-02ab-4443-a152-f496de3b6647",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_timestamp_column_name=self.time_variable_name # 't_rel_seconds'\n",
    "self._obj['scISI'] = -1 # initialize the 'scISI' column (same-cell Intra-spike-interval) to -1\n",
    "\n",
    "for (i, a_cell_id) in enumerate(self._obj.spikes.neuron_ids):\n",
    "    # loop through the cell_ids\n",
    "    curr_df = safe_pandas_get_group(self._obj.groupby('aclu'), a_cell_id)\n",
    "    curr_series_differences = curr_df[spike_timestamp_column_name].diff() # These are the ISIs\n",
    "    #set the properties for the points in question:\n",
    "    self._obj.loc[curr_df.index,'scISI'] = curr_series_differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c7a593-8ea0-454f-b2f0-dd76cd5782ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2023-03-07 - Look at firing_rate_trends and previous surprise metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326ffb34-1183-45e0-bb0d-591c18c3de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "computation_result = curr_active_pipeline.computation_results['maze1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d547a8b-217c-422e-9255-07d4044634d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the time-binning from `firing_rate_trends`:\n",
    "active_firing_rate_trends = computation_result.computed_data['firing_rate_trends']\n",
    "time_bin_size_seconds, pf_included_spikes_only = active_firing_rate_trends['time_bin_size_seconds'], active_firing_rate_trends['pf_included_spikes_only']\n",
    "\n",
    "active_time_binning_container, active_time_binned_unit_specific_binned_spike_counts = pf_included_spikes_only['time_binning_container'], pf_included_spikes_only['time_binned_unit_specific_binned_spike_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e674097-476b-43aa-bbfd-7199c2d67b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_time_dependent_pf_sequential_surprise_computation'], enabled_filter_names=['maze'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5f6acab-cb75-49cf-bcc6-2e5a0eabac09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"computation_result.computed_data['extended_stats']['time_binned_positioned_resampler']\",\n",
       " \"computation_result.computed_data['extended_stats']['time_binned_position_df']\",\n",
       " \"computation_result.computed_data['extended_stats']['time_binned_position_mean']\",\n",
       " \"computation_result.computed_data['extended_stats']['time_binned_position_covariance']\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.registered_computation_function_dict['_perform_time_dependent_pf_sequential_surprise_computation'].output_provides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61627f8f-cad5-43fc-b3e1-ebaf466b6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_extended_stats = curr_active_pipeline.computation_results['maze'].computed_data['extended_stats']\n",
    "active_relative_entropy_results = active_extended_stats['relative_entropy_analyses']\n",
    "post_update_times = active_relative_entropy_results['post_update_times']\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals = active_relative_entropy_results['time_intervals']\n",
    "long_short_rel_entr_curves_frames = active_relative_entropy_results['long_short_rel_entr_curves_frames']\n",
    "short_long_rel_entr_curves_frames = active_relative_entropy_results['short_long_rel_entr_curves_frames']\n",
    "flat_relative_entropy_results = active_relative_entropy_results['flat_relative_entropy_results']\n",
    "flat_jensen_shannon_distance_results = active_relative_entropy_results['flat_jensen_shannon_distance_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c10eccf1-f355-4a06-a8de-c76b72891cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_relative_entropy_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39dbb326-c64a-40a1-9f53-45e6eadcbc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4152,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_flat_relative_entropy_results = np.sum(flat_relative_entropy_results, axis=1)\n",
    "summed_flat_relative_entropy_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20548cac-954f-4d9f-9fd7-78e7680eff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "\n",
    "# Show basic relative entropy vs. time plot:\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "# ax.plot(post_update_times, flat_relative_entropy_results)\n",
    "ax.plot(post_update_times, summed_flat_relative_entropy_results)\n",
    "ax.set_ylabel('Relative Entropy')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, defer_render=False, debug_print=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab6fff45-bec6-4691-91b0-ca09208ce738",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# ax.plot(post_update_times, flat_relative_entropy_results)\n",
    "extents = (post_update_times[0], post_update_times[-1], active_pf_1D_dt.xbin[0], active_pf_1D_dt.xbin[-1]) # (left, right, bottom, top)\n",
    "ax.imshow(flat_relative_entropy_results.T, extent=extents)\n",
    "ax.set_ylabel('Relative Entropy')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "fig.suptitle('flat_relative_entropy_results.T')\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, defer_render=False, debug_print=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb2632af-4b50-4d48-af2b-13f435f95aa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'active_pf_1D_dt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# ax.plot(post_update_times, flat_relative_entropy_results)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m extents \u001b[38;5;241m=\u001b[39m (post_update_times[\u001b[38;5;241m0\u001b[39m], post_update_times[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[43mactive_pf_1D_dt\u001b[49m\u001b[38;5;241m.\u001b[39mxbin[\u001b[38;5;241m0\u001b[39m], active_pf_1D_dt\u001b[38;5;241m.\u001b[39mxbin[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;66;03m# (left, right, bottom, top)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m ax\u001b[38;5;241m.\u001b[39mimshow(flat_relative_entropy_results\u001b[38;5;241m.\u001b[39mT, extent\u001b[38;5;241m=\u001b[39mextents)\n\u001b[0;32m      5\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelative Entropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'active_pf_1D_dt' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60169818-f1c9-4499-b890-01e04ef65de2",
   "metadata": {},
   "source": [
    "# 2023-03-07 - Similar to previous surprise metrics: build time-dependent placefield for each the long and short"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6861a9fa-7765-4357-8f6b-311d874e006b",
   "metadata": {},
   "source": [
    "## can compute the surprise of a given epoch by taking the pf_dt computed up to epoch_start, computing the snapshot up to epoch_end, and then computing the surprise between them\n",
    "    ### LIMITATION: this surprise is still cell-spiketrain specific, not combined across cells\n",
    "    ### CLAIM: this surprise (for a given cell) indicates how much this series of spikes observed for this cell matches expectation *for this measured position*.\n",
    "    ### LIMITATION: I believe this surprise misses absent but expected spikes (missing spikes aren't surprising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f380c213-5097-417a-acc4-564355b65b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute snapshots (historical_snapshots_dict) for each Epoch:\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ExtendedStats import compute_snapshot_relative_entropy_surprise_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e368496-8704-4b8c-bc86-179bb3f323f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "included_epochs = None\n",
    "active_pf_1D_dt = PfND_TimeDependent(deepcopy(pyramidal_only_spikes_df), deepcopy(active_pos.linear_pos_obj), epochs=included_epochs)\n",
    "active_time_dependent_placefields2D = PfND_TimeDependent(deepcopy(pyramidal_only_spikes_df), deepcopy(active_pos), epochs=included_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fbc574b-8043-42b3-8208-9744b54e650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get laps as epochs to compute the surprise for:\n",
    "laps_copy = deepcopy(sess.laps)\n",
    "active_filter_epochs = laps_copy.filtered_by_lap_flat_index(np.arange(20)).as_epoch_obj() # epoch object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4d468e0-b144-4a2f-b9cf-cedcb6ebd473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_filter_epochs.n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "006ede4d-da85-4403-bcff-9c11b78bd775",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (304904623.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[18], line 13\u001b[1;36m\u001b[0m\n\u001b[1;33m    active_time_dependent_placefields2D.\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def _build_historical_snapshots(active_time_dependent_placefields2D, active_filter_epochs, debug_print=False):\n",
    "    active_time_dependent_placefields2D.reset() # reset dropping all snapshots\n",
    "\n",
    "    # out_pair_indicies = build_pairwise_indicies(np.arange(active_time_binning_container.edge_info.num_bins))\n",
    "    # time_intervals = active_time_binning_container.edges[out_pair_indicies] # .shape # (4153, 2)\n",
    "\n",
    "    for a_start, an_end in active_filter_epochs.as_array():\n",
    "        if debug_print:\n",
    "            print(f'{a_start = }, {an_end =}')\n",
    "        active_time_dependent_placefields2D.update(t=a_start, should_snapshot=True) # update the decoder to the start of the epoch\n",
    "        active_time_dependent_placefields2D.update(t=an_end, should_snapshot=True) # update the decoder to the start of the epoch\n",
    "        \n",
    "        active_time_dependent_placefields2D.\n",
    "        \n",
    "    historical_snapshots = active_time_dependent_placefields2D.historical_snapshots\n",
    "    return historical_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb4f999-028b-474b-b665-eef34fddd55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_snapshots_1D = _build_historical_snapshots(active_pf_1D_dt, active_filter_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d757d4d1-9626-4575-bc56-85a61bb2c2d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_build_historical_snapshots' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m historical_snapshots_2D \u001b[38;5;241m=\u001b[39m \u001b[43m_build_historical_snapshots\u001b[49m(active_time_dependent_placefields2D, active_filter_epochs)\n",
      "\u001b[1;31mNameError\u001b[0m: name '_build_historical_snapshots' is not defined"
     ]
    }
   ],
   "source": [
    "historical_snapshots_2D = _build_historical_snapshots(active_time_dependent_placefields2D, active_filter_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf38865-5cbf-4279-bfff-f355e14f0d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7078cba-bf6b-4564-86cf-52ccbe9a4b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_snapshots_1D.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da100c1a-2b57-4e2d-b2bb-161bc71e13ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_weighted_tuning_maps_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bac0058-29ed-4902-8f6a-60581b68eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_snapshots_1D[8.806375011103228].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda075ea-0b63-49b2-856b-8c3c7dc5bd87",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Wasserstein distance\n",
    "https://stackoverflow.com/questions/60529232/reference-for-wasserstein-distance-function-in-python\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wasserstein_distance.html\n",
    "https://blogs.rstudio.com/ai/posts/2020-02-19-kl-divergence/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f034b75e-ac10-45f2-bc57-2395fccfb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# 2023-03-10 TODO - [ ] Implement wasserstein_distance for each cell to collapse over the 1D space variable\n",
    "# stats.wasserstein_distance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1816f0e7-49e0-4cb1-a0d6-91b701b6c1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import build_pairwise_indicies\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ExtendedStats import compute_surprise_relative_entropy_divergence\n",
    "\n",
    "\"\"\"\n",
    "- snapshot_differences_result_dict[i]: dict\n",
    "\t- t: tuple - (2,)\n",
    "\t- snapshots: tuple - (2,)\n",
    "\t- relative_entropy_result_dict: dict\n",
    "\t\t- long_short_rel_entr_curve: ndarray - (108, 239, 102)\n",
    "\t\t- long_short_relative_entropy: ndarray - (239, 102)\n",
    "\t\t- short_long_rel_entr_curve: ndarray - (108, 239, 102)\n",
    "\t\t- short_long_relative_entropy: ndarray - (239, 102)\n",
    "\t\t- jensen_shannon_distance: ndarray - (239, 102)\n",
    "        \n",
    "\"\"\"\n",
    "# post_update_times, snapshot_differences_result_dict, flat_relative_entropy_results, flat_jensen_shannon_distance_results = compute_snapshot_relative_entropy_surprise_differences(historical_snapshots)\n",
    "## Extraction of `pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ExtendedStats.compute_snapshot_relative_entropy_surprise_differences`\n",
    "historical_snapshots_dict = historical_snapshots_1D\n",
    "# historical_snapshots_dict = historical_snapshots_2D\n",
    "# Lists with one entry per snapshot in historical_snapshots_dict\n",
    "snapshot_differences_result_dict = []\n",
    "flat_relative_entropy_results = []\n",
    "flat_jensen_shannon_distance_results = []\n",
    "\n",
    "n_snapshots = len(historical_snapshots_dict)\n",
    "snapshot_times = list(historical_snapshots_dict.keys())\n",
    "snapshots = list(historical_snapshots_dict.values())\n",
    "snapshot_indicies = np.arange(n_snapshots) # [0, 1, 2, 3, 4]\n",
    "\n",
    "post_update_times = snapshot_times[1:] # all but the first snapshot\n",
    "\n",
    "snapshot_pair_indicies = build_pairwise_indicies(snapshot_indicies) # [(0, 1), (1, 2), (2, 3), ... , (146, 147), (147, 148), (148, 149)]\n",
    "# snapshot_included_pair_indicies = snapshot_pair_indicies # include all pairs\n",
    "\n",
    "epoch_pair_indicies = snapshot_pair_indicies[::2] # get every other element: [(0, 1), (2, 3), (4, 5), (6, 7), ..., (36, 37), (38, 39)]\n",
    "between_epochs_pair_indicies = snapshot_pair_indicies[1::2] # the indicies corresponding to between the epochs: [(1, 2), (3, 4), (5, 6), (7, 8), ..., (35, 36), (37, 38)]\n",
    "snapshot_included_pair_indicies = epoch_pair_indicies # include only the epoch (start, end) snapshots, and not the ones between epochs\n",
    "\n",
    "for earlier_snapshot_idx, later_snapshot_idx in snapshot_included_pair_indicies:\n",
    "    ## Extract the two sequential snapshots for this period:\n",
    "    earlier_snapshot, later_snapshot = snapshots[earlier_snapshot_idx], snapshots[later_snapshot_idx]\n",
    "    earlier_snapshot_t, later_snapshot_t = snapshot_times[earlier_snapshot_idx], snapshot_times[later_snapshot_idx]\n",
    "\n",
    "    ## Proof of concept, comute surprise between the two snapshots:\n",
    "    # relative_entropy_overlap_dict, relative_entropy_overlap_scalars_df = compute_relative_entropy_divergence_overlap(earlier_snapshot, later_snapshot, debug_print=False)\n",
    "    # print(earlier_snapshot['occupancy_weighted_tuning_maps_matrix'].shape) # (108, 63)\n",
    "    # print(later_snapshot['occupancy_weighted_tuning_maps_matrix'].shape) # (108, 63)\n",
    "    # relative_entropy_result_dict = compute_surprise_relative_entropy_divergence(earlier_snapshot['occupancy_weighted_tuning_maps_matrix'], later_snapshot['occupancy_weighted_tuning_maps_matrix'])\n",
    "    relative_entropy_result_dict = compute_surprise_relative_entropy_divergence(earlier_snapshot.occupancy_weighted_tuning_maps_matrix, later_snapshot.occupancy_weighted_tuning_maps_matrix)\n",
    "    # aclu_keys = [k for k,v in relative_entropy_result_dict.items() if v is not None] # len(aclu_keys) # 101\n",
    "    # short_long_rel_entr_curves = np.vstack([v['short_long_rel_entr_curve'] for k,v in relative_entropy_result_dict.items() if v is not None])\n",
    "    # short_long_rel_entr_curves # .shape # (101, 63)\n",
    "    # print(f\"{relative_entropy_result_dict['short_long_rel_entr_curve'].shape}\") # (108, 63)\n",
    "    # print(f\"{relative_entropy_result_dict['short_long_relative_entropy'].shape}\") # (63,)\n",
    "    flat_relative_entropy_results.append(relative_entropy_result_dict['short_long_relative_entropy'])\n",
    "    flat_jensen_shannon_distance_results.append(relative_entropy_result_dict['jensen_shannon_distance'])\n",
    "    snapshot_differences_result_dict.append({'t': (earlier_snapshot_t, later_snapshot_t),\n",
    "                               'snapshots': (earlier_snapshot, later_snapshot),\n",
    "                               'relative_entropy_result_dict': relative_entropy_result_dict,   \n",
    "    })\n",
    "\n",
    "# flatten the relevent results:\n",
    "post_update_times = np.array(post_update_times)\n",
    "flat_jensen_shannon_distance_results = np.vstack(flat_jensen_shannon_distance_results) # flatten the list (20, 239) = (n_post_update_times, n_xbins)\n",
    "flat_relative_entropy_results = np.vstack(flat_relative_entropy_results) # flatten the list (20, 239) = (n_post_update_times, n_xbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db22b1a-d559-4c22-bda6-3a452dcd6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_jensen_shannon_distance_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12e389a-ebb9-4a73-96b4-46ad8826ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf_1D_dt.dims_coord_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a013e-33eb-4bae-a75b-748466ab5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_relative_entropy_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e1680a-9e3b-4f63-afc2-dc09b954ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(snapshot_differences_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b66e2-1960-499b-8a1e-7306e3223c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8983df-202e-4646-8cd1-95e6ab02b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pf_overlap_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c5abf-0ea5-4d6a-ab9f-f3495fa13a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Keep track of the \"dimensions\" for the returned arrays and such so they don't have to be reverse engineered later\n",
    "\n",
    "long_short_rel_entr_curves_list = [a_val_dict['long_short_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list] # [0].shape # (108, 63) = (n_neurons, n_xbins)\n",
    "long_short_rel_entr_curves_frames = np.stack([a_val_dict['long_short_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list]) # build a 3D array (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ('length_term_name', 'index_item_name')\n",
    "('n_snapshots','snapshot_idx'),\n",
    "('n_post_update_times', 'post_update_time_idx'),\n",
    "('n_neurons', 'neuron_IDX'),\n",
    "('n_xbins', 'xbin_idx'),\n",
    "('n_ybins', 'ybin_idx'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd259b-10ba-45d1-b344-a8aa526f4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    " dims_coord_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b49552b-8dbf-4b00-bf8f-2f347afc897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_entropy_result_dicts_list = [a_val_dict['relative_entropy_result_dict'] for a_val_dict in snapshot_differences_result_dict]\n",
    "long_short_rel_entr_curves_list = [a_val_dict['long_short_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list] # [0].shape # (108, 63) = (n_neurons, n_xbins) || 2D: (70, 239, 102) = (n_neurons, n_xbins, n_ybins)\n",
    "short_long_rel_entr_curves_list = [a_val_dict['short_long_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list]\n",
    "long_short_rel_entr_curves_frames = np.stack([a_val_dict['long_short_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list]) # build a 3D array (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins) || 2D: (20, 70, 239, 102) = (n_post_update_times, n_neurons, n_xbins, n_ybins)\n",
    "short_long_rel_entr_curves_frames = np.stack([a_val_dict['short_long_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list]) # build a 3D array (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins) || 2D: (20, 70, 239, 102) = (n_post_update_times, n_neurons, n_xbins, n_ybins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c942a07-bfb5-4cb1-9186-901e9a0a726c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90666e0b-3aba-40fd-b124-966ba75f78bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e267a-84f4-4db7-96c3-322394994cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb09cc3b-7780-4b28-9fb4-337ef666bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_rel_entr_curves_frames.shape # build a 4D array (20, 70, 239, 102) = (n_post_update_times, n_neurons, n_xbins, n_ybins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12956de-2a9e-4527-9b84-12f97f2e65b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a specific lap i, extract the set of suprises \n",
    "epoch_idx = 0\n",
    "long_short_rel_entr_curves_frames[epoch_idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf634a-0219-4954-bd29-e40ab02a42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the surprise for each cell similar to how the 2D heatmaps are plotted\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "\n",
    "figure_format_config = {}\n",
    "out_all_pf_2D_pyqtgraph_binned_image_fig = display_all_pf_2D_pyqtgraph_binned_image_rendering(long_short_rel_entr_curves_frames[epoch_idx], figure_format_config) # output is BasicBinnedImageRenderingWindow\n",
    "# Set the window title from the context\n",
    "out_all_pf_2D_pyqtgraph_binned_image_fig.setWindowTitle(f'long_short_rel_entr_curves_frames[epoch_idx: {epoch_idx}]')\n",
    "out_all_pf_2D_pyqtgraph_binned_image_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7846c2d-ebba-4ac9-ad84-197e6d816952",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to use the more general `pyqtplot_plot_image_array`\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array\n",
    "\n",
    "epoch_idx = 19\n",
    "app, parent_root_widget, root_render_widget, plot_array, img_item_array, other_components_array = pyqtplot_plot_image_array(active_time_dependent_placefields2D.xbin, active_time_dependent_placefields2D.ybin, long_short_rel_entr_curves_frames[epoch_idx], active_time_dependent_placefields2D.occupancy)\n",
    "parent_root_widget.setWindowTitle(f'long_short_rel_entr_curves_frames[epoch_idx: {epoch_idx}]')\n",
    "parent_root_widget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20447908-2fc0-4857-9816-b888edafa518",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_jensen_shannon_distance_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c2e7a1-379e-43cf-8e94-7151275b7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for 1D results, add a singleton dimension on for y_bins:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b518c-af58-49ab-92b6-7795a844dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "curr_1D_padded_occupancy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ce15d-1340-49c4-b10a-d691ad02e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to use the more general `pyqtplot_plot_image_array`\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array\n",
    "\n",
    "curr_1D_padded_result = flat_jensen_shannon_distance_results.reshape(*flat_jensen_shannon_distance_results.shape, 1)\n",
    "curr_1D_padded_occupancy = active_pf_1D_dt.occupancy.reshape(*active_pf_1D_dt.occupancy.shape, 1)\n",
    "app, parent_root_widget, root_render_widget, plot_array, img_item_array, other_components_array = pyqtplot_plot_image_array(active_pf_1D_dt.xbin, [0.0, 1.0], curr_1D_padded_result, curr_1D_padded_occupancy)\n",
    "parent_root_widget.setWindowTitle(f'1D long_short_rel_entr_curves_frames[epoch_idx: {epoch_idx}]')\n",
    "parent_root_widget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1b557-15d9-41f6-86ec-3f93bd5f17da",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_rel_entr_curves_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2da41c6-8adb-44df-ad35-18f79a7b341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'mode': 'bin_size',\n",
    " 'xstep': 1,\n",
    " 'xnum_bins': 240,\n",
    " 'ystep': 1,\n",
    " 'ynum_bins': 103}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba375eb7-4996-453f-8e10-dc8300ba14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_rel_entr_curves_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bbb928-a242-4657-80ad-28263082db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_rel_entr_curves_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc88ce2-6003-47fa-91bb-d170a33cca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_long_short_rel_entr_curves_frames = long_short_rel_entr_curves_frames[::2] # get only the ones corresponding to the epochs\n",
    "epoch_long_short_rel_entr_curves_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3011b-ff4e-4368-b859-6e79fa64ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_long_short_rel_entr_curves_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95619249-71f8-4ca1-90c5-388bc9941155",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(long_short_rel_entr_curves_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1b42d-dd9b-4411-b1fd-aae8636ecacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_rel_entr_curves_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd8ba0a-b0e5-45a9-a973-6566b70765b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_relative_entropy_results.shape # (9321, 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95309be2-effe-4f03-8ac1-0ec2ec9e26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_update_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47484740-d4cd-4d6d-b211-0136f1b7633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(108, 63) = (n_neurons, n_xbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72909169-8ca0-476c-be9d-547c7b0e51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "\n",
    "# PfND version:\n",
    "curr_sync_placefield_plotter = TimeSynchronizedPlacefieldsPlotter(active_time_dependent_placefields2D)\n",
    "curr_sync_placefield_plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b51579d-2559-4f25-a8f1-2399cc4f3bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's look at the original surprise curves for each cell, but instead of plotting them on top of each other plot them in a separate strip for each cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a978b2a-edbe-41ed-934e-fdb9c52a3114",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2023-03-08 - Build Transition Matrix for each position bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ba836-549c-45dc-b050-57d94db396d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.binning_helpers import transition_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789cfdf0-ebe3-4466-b7ba-201a8e1230a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1D Transition Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fdf50b-f477-4fa5-9cde-939c9a9b53c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1D = deepcopy(curr_active_pipeline.computation_results['maze1'].computed_data['pf1D'])\n",
    "pf1D.bin_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade8081d-e4c1-4ca4-aad7-c97ca0a56c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_position_states = len(pf1D.xbin_labels)\n",
    "binned_x = pf1D.filtered_pos_df['binned_x'].to_numpy()\n",
    "binned_x_indicies = binned_x - 1\n",
    "binned_x_transition_matrix = transition_matrix(deepcopy(binned_x_indicies), markov_order=1, max_state_index=num_position_states)\n",
    "# binned_x_transition_matrix_higher_order_list = [binned_x_transition_matrix, transition_matrix(deepcopy(binned_x_indicies), markov_order=2, max_state_index=num_position_states), transition_matrix(deepcopy(binned_x_indicies), markov_order=3, max_state_index=num_position_states)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4023346-0c45-4ae0-9ab9-5cb9f62b41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_x_transition_matrix[np.isnan(binned_x_transition_matrix)] = 0.0\n",
    "binned_x_transition_matrix_higher_order_list = [binned_x_transition_matrix, np.linalg.matrix_power(binned_x_transition_matrix, 2), np.linalg.matrix_power(binned_x_transition_matrix, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44051920-194f-4de0-a250-a006e9d36a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_x_transition_matrix.shape # (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3e7ac-bcc7-42d4-87eb-fb4768c75176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "out = BasicBinnedImageRenderingWindow(binned_x_transition_matrix, pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix', title=\"Transition Matrix for binned x (from, to)\", variable_label='Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n",
    "# out.add_data(row=1, col=0, matrix=active_eloy_analysis.pf_overlapDensity_2D, xbins=active_pf_2D_dt.xbin_labels, ybins=active_pf_2D_dt.ybin_labels, name='pf_overlapDensity', title='pf overlapDensity metric', variable_label='pf overlapDensity')\n",
    "\n",
    "out.add_data(row=1, col=0, matrix=binned_x_transition_matrix_higher_order_list[1], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^2', title='2nd Order Transition Matrix for binned x (from, to)', variable_label='2nd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n",
    "out.add_data(row=2, col=0, matrix=binned_x_transition_matrix_higher_order_list[2], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^3', title='3rd Order Transition Matrix for binned x (from, to)', variable_label='3rd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63158f9d-47ca-4c9c-91e7-d7c36ff5625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[1], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix^2', title=\"2nd Order Transition Matrix for binned x (from, to)\", variable_label='2nd Order Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115df375-c43c-4792-9d89-493c4797ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out3 = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[2], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix^3', title=\"3rd Order Transition Matrix for binned x (from, to)\", variable_label='3rd Order Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96d7fac-b1f7-45aa-8046-ad60880a0e3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2023-03-09 - Extract the probability of spiking given position (whether that's the measured position or the previous decoded position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3cb7a3-c7d8-4351-93af-0987e7dadd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1D = deepcopy(curr_active_pipeline.computation_results['maze1'].computed_data['pf1D'])\n",
    "pf1D.bin_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373700b5-9d54-474b-885c-37931e4dc621",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1D.ratemap.unsmoothed_tuning_maps # .shape (104, 63)\n",
    "pf1D.ratemap.dims_coord_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4563cb0-53d7-489a-b66f-545cc2d8c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_idx = 0\n",
    "# curr_position_firing_rates_Hz = [a_peak_firing_rate*a_tuning_curve[x_idx] for a_peak_firing_rate, a_tuning_curve in zip(pf1D.ratemap.tuning_curve_unsmoothed_peak_firing_rates, pf1D.ratemap.pdf_normalized_tuning_curves)]\n",
    "curr_position_firing_rates_Hz = [an_unsmoothed_tuning_map[x_idx] for an_unsmoothed_tuning_map in pf1D.ratemap.unsmoothed_tuning_maps]\n",
    "curr_position_firing_rates_Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0314f0a8-39c0-437c-9af6-40c5fb06e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1D.ratemap.tuning_curve_unsmoothed_peak_firing_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae41182-e0f9-4caa-adf9-09dad17418fd",
   "metadata": {},
   "source": [
    "# 2023-03-10 - End of Day - Get conceptual surprise distance confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed438e7-1fc7-4584-b041-9e3aaced29cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf reflecting the expected firing rate for a given cell\n",
    "pdf = [2, 4, 2, 1, 0, 0]\n",
    "# two spike sequences for a given cell, across every <position>\n",
    "spike_seqs = [[0,4,0,0,0,0], [0,2,0,0,0,0], [0,0,0,0,2,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52638b19-2ab4-4902-89fd-b3b978d4671f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Wasserstein distance\n",
    "https://stackoverflow.com/questions/60529232/reference-for-wasserstein-distance-function-in-python\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wasserstein_distance.html\n",
    "https://blogs.rstudio.com/ai/posts/2020-02-19-kl-divergence/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a631e8-ebbd-4e92-b284-ef06e386f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# 2023-03-10 TODO - [ ] Implement wasserstein_distance for each cell to collapse over the 1D space variable\n",
    "# stats.wasserstein_distance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d967948-067f-4094-a3cd-e6812ec0122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[stats.wasserstein_distance(pdf, a_spike_seq) for a_spike_seq in spike_seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25360995-e9db-4f0e-9930-42a3a19e86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_fns = [stats.bayes_mvs\n",
    "# stats.mvsdist\n",
    "# stats.entropy\n",
    "# stats.differential_entropy\n",
    "# stats.median_abs_deviation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd979425-bda8-4b14-9ee2-fb3afabce09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[stats.entropy(pdf, a_spike_seq) for a_spike_seq in spike_seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d1a651-05e6-45f6-9383-fb0cefd2e7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a8c7c69-5918-4924-b831-e24e3029405c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Overflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfea00a-e8c3-436f-b7a7-3cf023ba68d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the entries in the transition matrix:\n",
    "for row in binned_x_transition_matrix: print(' '.join(f'{x:.2f}' for x in row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcb1473-77c2-4b0b-8334-44939abfbd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all spikes:\n",
    "active_epoch_placefields1Da = PfND(deepcopy(spikes_df), deepcopy(active_pos.linear_pos_obj), grid_bin=(1,1)) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74209eda-e41f-46e2-95d6-869a225c3108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyramidal spikes only:\n",
    "active_epoch_placefields1Db = PfND(deepcopy(spikes_df).spikes.sliced_by_neuron_type('pyramidal'), deepcopy(active_pos.linear_pos_obj), grid_bin=(1,1)) # grid_bin=, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4371c415-2621-489f-9428-65e399da7c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PlacefieldComputationParameters\n",
    "# Parameter sweeps:\n",
    "\n",
    "# grid_bin = [(1.0, 1.0)]\n",
    "\n",
    "# 10.0\n",
    "cls.compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6119a5e5-8f01-40fa-a15a-98b1ac7b13ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ansi2html import Ansi2HTMLConverter # used by DocumentationFilePrinter to build html document from ansi-color coded version\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter\n",
    "\n",
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=Path('C:/Users/pho/repos/IsolatedSpike3DEnv/Spike3D/EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation'), doc_name='snapshot_differences_result_dict')\n",
    "doc_printer.save_documentation('snapshot_differences_result_dict[i]', snapshot_differences_result_dict[0], non_expanded_item_keys=['_reverse_cellID_index_map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d70c397-8d25-46c6-9bc5-f171aaedf9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import define, field\n",
    "\n",
    "@define\n",
    "class Coordinates:\n",
    "    x: int\n",
    "    y: int\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff57ca3-5f59-4599-880c-c2b205afde31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2023-03-07: Test Launching GUIs in background to prevent crashing main kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f44eb65-18f5-4290-88f6-2fd6311ba65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd11e7-6731-441a-a305-933db52f1410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow\n",
    "\n",
    "def run_gui():\n",
    "    app = QApplication([])\n",
    "    # Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "    active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D.values()\n",
    "    spike_raster_window.show()\n",
    "    app.exec_()\n",
    "\n",
    "p = multiprocessing.Process(target=run_gui)\n",
    "p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe314b1-5700-4bdf-ad62-0147bc91f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow\n",
    "\n",
    "def run_gui():\n",
    "    app = QApplication([])\n",
    "    window = QMainWindow()\n",
    "    window.show()\n",
    "    app.exec_()\n",
    "\n",
    "p = multiprocessing.Process(target=run_gui)\n",
    "p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599db22-2d43-41e1-a044-378b8c7554a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph import QtWidgets, Qt, QtCore, QtGui\n",
    "\n",
    "def mythread():\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    # win = MainWindow()\n",
    "    # win.show()\n",
    "    # Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "    active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D.values()\n",
    "    spike_raster_window.show()\n",
    "    app.exec_()\n",
    "\n",
    "def show():\n",
    "    import threading\n",
    "    t = threading.Thread(target = mythread)\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app = QtWidgets.QApplication(sys.argv)\n",
    "#     win = MainWindow()\n",
    "#     win.show()\n",
    "#     sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c6dd6a-05e9-4986-83b6-0ce0bff55d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdf9ee2-5e95-48fd-ad8f-5ee885cd7417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbeb730-da97-48bf-b4b8-345dde427af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = QtWidgets.QApplication(sys.argv)\n",
    "active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D.values()\n",
    "spike_raster_window.show()\n",
    "sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb60d574-67b3-4bed-bd55-0abdd7387b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike3d-poetry",
   "language": "python",
   "name": "spike3d-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
