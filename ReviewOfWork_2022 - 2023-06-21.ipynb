{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import neptune # for logging progress and results\n",
    "from pyphoplacecellanalysis.General.Batch.NeptuneAiHelpers import set_environment_variables, neptune_output_figures\n",
    "neptune_kwargs = {'project':\"commander.pho/PhoDibaLongShort2023\",\n",
    "'api_token':\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGIxODU2My1lZTNhLTQ2ZWMtOTkzNS02ZTRmNzM5YmNjNjIifQ==\"}\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from attrs import define, field, fields, Factory\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import CodeConversion\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible, print_value_overview_only, document_active_variables, objsize, print_object_memory_usage, debug_dump_object_member_shapes, TypePrintMode\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "\n",
    "from pyphocorehelpers.print_helpers import generate_html_string\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot, create_daily_programmatic_display_function_testing_folder_if_needed, session_context_to_relative_path\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import build_pyqtgraph_epoch_indicator_regions # Add session indicators to pyqtgraph plot\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _helper_add_long_short_session_indicator_regions\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "# 'time_bin_indices': valid_time_bin_indicies, 'posterior_to_pf_mean_surprise': one_left_out_posterior_to_pf_surprises_mean, 'posterior_to_scrambled_pf_mean_surprise': one_left_out_posterior_to_scrambled_pf_surprises_mean}\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_long_short_expected_vs_observed_firing_rates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_long_short_surprise_difference_plot\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import _update_pipeline_missing_preprocessing_parameters\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "\n",
    "from scripts.run_BatchAnalysis import post_compute_validate, _on_complete_success_execution_session\n",
    "\n",
    "session_batch_status = {}\n",
    "session_batch_errors = {}\n",
    "enable_saving_to_disk = False\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle.pkl.\n",
      "property already present in pickled version. No need to save.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\output\\global_computation_results.pkl... done.\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "#     neuropy/data_session_pre_processing_scripts/KDIBA/IIDataMat_Export_ToPython_2022_08_01.m\n",
    "# From pre-computed .mat files:\n",
    "\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # DONE. Very good. Many good Pfs, many good replays.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays!\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3') # DONE, Good Pfs, no good epochs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # BAD, Good Pfs strangely despite horrible map, no good epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # DONE\n",
    "\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "\n",
    "\n",
    "    # ==================================================================================================================== #\n",
    "    # Load Pipeline                                                                                                        #\n",
    "    # ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=[#'_perform_estimated_epochs_computation',  # AL:WAYS OFF\n",
    "                                            '_perform_baseline_placefield_computation',\n",
    "                                        # '_perform_time_dependent_placefield_computation', # AL:WAYS OFF\n",
    "                                        '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        # '_perform_time_dependent_pf_sequential_surprise_computation' # AL:WAYS OFF\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding' # AL:WAYS OFF\n",
    "                                    ]\n",
    "# active_computation_functions_name_includelist=['_perform_baseline_placefield_computation']\n",
    "\n",
    "curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        curr_active_pipeline.load_pickled_global_computation_results()\n",
    "    except Exception as e:\n",
    "        print(f'cannot load global results: {e}')\n",
    "\n",
    "# 6m 1.1s\n",
    "# 12m 15.6s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8aab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "from neuropy.utils.matplotlib_helpers import interactive_select_grid_bin_bounds_2D\n",
    "# fig, ax, rect_selector, set_extents = interactive_select_grid_bin_bounds_2D(curr_active_pipeline, epoch_name='maze', should_block_for_input=True)\n",
    "\n",
    "grid_bin_bounds = interactive_select_grid_bin_bounds_2D(curr_active_pipeline, epoch_name='maze', should_block_for_input=True, should_apply_updates_to_pipeline=False)\n",
    "print(f'grid_bin_bounds: {grid_bin_bounds}')\n",
    "print(f\"Add this to `specific_session_override_dict`:\\n\\n{curr_active_pipeline.get_session_context().get_initialization_code_string()}:dict(grid_bin_bounds=({(grid_bin_bounds[0], grid_bin_bounds[1]), (grid_bin_bounds[2], grid_bin_bounds[3])})),\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a29b890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis already computed.\n",
      "long_short_fr_indicies_analyses already computed.\n",
      "long_short_decoding_analyses already computed.\n",
      "long_short_post_decoding already computed.\n",
      "done with all batch_extended_computations(...).\n",
      "no changes in global results.\n"
     ]
    }
   ],
   "source": [
    "## Post Compute Validate 2023-05-16:\n",
    "from scripts.run_BatchAnalysis import post_compute_validate\n",
    "post_compute_validate(curr_active_pipeline)\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "extended_computations_include_includelist=['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'] # do only specifiedl , 'long_short_rate_remapping'\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "# extended_computations_include_includelist=['long_short_post_decoding'] # do only specifiedl\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=force_recompute_global, debug_print=False)\n",
    "if len(newly_computed_values) > 0:\n",
    "\tprint(f'newly_computed_values: {newly_computed_values}. Saving global results...')\n",
    "\ttry:\n",
    "\t\t# curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "\t\t# Try to write out the global computation function results:\n",
    "\t\tcurr_active_pipeline.save_global_computation_results()\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "\t\tprint(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "\tprint(f'no changes in global results.')\n",
    "# 10m 29.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "neptuner = batch_perform_all_plots(curr_active_pipeline, enable_neptune=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e7106ef",
   "metadata": {},
   "source": [
    "### Pipeline Loading/Saving [Optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f3fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE) # AttributeError: 'PfND_TimeDependent' object has no attribute '_included_thresh_neurons_indx'\n",
    "# TypeError: cannot pickle 'MplMultiTab' object\n",
    "# PicklingError: Can't pickle .set_closure_cell at 0x000002BF248F50D0>: it's not found as attr._compat.make_set_closure_cell..set_closure_cell\n",
    "# TypeError: cannot pickle 'PyQt5.QtCore.pyqtSignal' object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c2afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results() # PicklingError: Can't pickle .set_closure_cell at 0x000002BF248F50D0>: it's not found as attr._compat.make_set_closure_cell..set_closure_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.load_pickled_global_computation_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241dc49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba716fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c850782f",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda48261",
   "metadata": {
    "tags": [
     "load",
     "ACTIVE"
    ]
   },
   "outputs": [],
   "source": [
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "## Extract variables from results object:\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global\n",
    "\n",
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result['Flat_epoch_time_bins_mean'], expected_v_observed_result['Flat_decoder_time_bin_centers'], expected_v_observed_result['num_neurons'], expected_v_observed_result['num_timebins_in_epoch'], expected_v_observed_result['num_total_flat_timebins'], expected_v_observed_result['is_short_track_epoch'], expected_v_observed_result['is_long_track_epoch'], expected_v_observed_result['short_short_diff'], expected_v_observed_result['long_long_diff']\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9e59bdb",
   "metadata": {},
   "source": [
    "# ***NOW*** TODO 2023-06-20 22:01: - [ ] OONE FACTORING OUT `PAPER_FIGURE_figure_1_add_replay_epoch_rasters` and got plots to show up.\n",
    "# - Just get both `plot_multiple_raster_plot` calls (long and short) to show up simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63af0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PendingNotebookCode import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import determine_long_short_pf1D_indicies_sort_by_peak\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.helpers import _helper_make_scatterplot_clickable\n",
    "from neuropy.utils.mixins.enum_helpers import StringLiteralComparableEnum\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f77377ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: new_all_aclus_sort_indicies: [ 5 22 36 10  6 30 29 34 28 16 14 27 17  0 21 35  4 15 32 25  2 12 31  7\n",
      "  1 33 18 19  3 26 11 13 20 37 24 23 38  9  8]\n",
      "scatter_plot_kwargs: {'pxMode': True, 'symbol': <PyQt5.QtGui.QPainterPath object at 0x000002B4AC5739E0>, 'size': 6, 'pen': {'color': 'white', 'width': 1}}\n",
      "scatter_plot_kwargs: {'pxMode': True, 'symbol': <PyQt5.QtGui.QPainterPath object at 0x000002B4AC5739E0>, 'size': 6, 'pen': {'color': 'white', 'width': 1}}\n"
     ]
    }
   ],
   "source": [
    "pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics = PAPER_FIGURE_figure_1_full(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9174642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8403ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common for all rasters:\n",
    "new_all_aclus_sort_indicies = determine_long_short_pf1D_indicies_sort_by_peak(curr_active_pipeline=curr_active_pipeline, curr_any_context_neurons=EITHER_subset.track_exclusive_aclus)\n",
    "new_all_aclus_sort_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e128b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unit_colors_list = None # default rainbow of colors for the raster plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron_qcolors_list = [pg.mkColor('black') for aclu in EITHER_subset.track_exclusive_aclus] # solid black for all\n",
    "neuron_qcolors_list = [pg.mkColor('green') for aclu in EITHER_subset.track_exclusive_aclus] # solid black\n",
    "unit_colors_list = DataSeriesColorHelpers.qColorsList_to_NDarray(neuron_qcolors_list, is_255_array=True)\n",
    "unit_colors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8858abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_left_exclusive = np.isin(EITHER_subset.track_exclusive_aclus, long_exclusive.track_exclusive_aclus) # get left exclusive\n",
    "unit_colors_list[0, is_left_exclusive] = 255 # [1.0, 0.0, 0.0, 1.0]\n",
    "unit_colors_list[1, is_left_exclusive] = 0.0\n",
    "unit_colors_list[2, is_left_exclusive] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9291091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Common Tick Label\n",
    "vtick = pg.QtGui.QPainterPath()\n",
    "\n",
    "# Thicker Tick Label:\n",
    "tick_width = 0.25\n",
    "# tick_width = 10.0\n",
    "half_tick_width = 0.5 * tick_width\n",
    "vtick.moveTo(-half_tick_width, -0.5)\n",
    "vtick.addRect(-half_tick_width, -0.5, tick_width, 1.0) # x, y, width, height\n",
    "\n",
    "pen = {'color': 'red', 'width': 1}\n",
    "# pen = None\n",
    "override_scatter_plot_kwargs = dict(pxMode=True, symbol=vtick, size=10, pen=pen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bb530",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epoch_spikes_df_L.spikes.rebuild_fragile_linear_neuron_IDXs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a1109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import plot_kourosh_activity_style_figure\n",
    "\n",
    "plot_aclus = EITHER_subset.track_exclusive_aclus.copy()\n",
    "# plot_aclus = EITHER_subset.track_exclusive_aclus[new_all_aclus_sort_indicies].copy()\n",
    "\n",
    "_out_A = plot_kourosh_activity_style_figure(long_results_obj, long_session, plot_aclus, epoch_idx=15, callout_epoch_IDXs=np.arange(5), skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4915ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_n = plot_kourosh_activity_style_figure(long_results_obj, long_session, EITHER_subset.track_exclusive_aclus, epoch_idx=49, callout_epoch_IDXs=np.arange(6), skip_rendering_callouts=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a231332",
   "metadata": {},
   "source": [
    "## Raster Plot Data Manager Reconceptualization\n",
    "\n",
    "Colors = Unit Identity -- purpose is to make them easier to visually trace across time within the same plot and relate these units to other figures (by color coding)\n",
    "Vertical Position = Unit Identity -- units can be sorted to convey information (such as a sweep across sorted units over time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26dd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single `plot_raster_plot` calls\n",
    "an_epoch = list(epochs_df_L.itertuples())[0]\n",
    "an_epoch_spikes_df = filter_epoch_spikes_df_L[filter_epoch_spikes_df_L['replay_epoch_id'] == an_epoch.Index]\n",
    "\n",
    "_out_single_raster_plot = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_app_name=\"test1\")\n",
    "_out_single_raster_plot2 = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_app_name=\"test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_L, win_L, plots_L, plots_data_L = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "\t\t\t\t\t\t\t\t\t\tepoch_id_key_name='replay_epoch_id', scatter_app_name=\"Long Decoded Example Replays\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee132b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_S, win_S, plots_S, plots_data_S = plot_multiple_raster_plot(epochs_df_S, filter_epoch_spikes_df_S, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                 epoch_id_key_name='replay_epoch_id', scatter_app_name=\"Short Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4dba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_aclus_sort_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6071c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_alt, win_alt, plots_alt, plots_data_alt = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                         epoch_id_key_name='replay_epoch_id', scatter_app_name=\"ALT Long Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e7d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting plot window background color to white\n",
    "win_L.setBackground('w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c69ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_plot_manager = plots_data_L.raster_plot_manager\n",
    "unit_sort_manager = plots_data_L.unit_sort_manager\n",
    "all_spots_dict = plots_data_L.all_spots_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_sort_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_plot_manager\n",
    "raster_plot_manager.config_fragile_linear_neuron_IDX_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb46eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.helpers import _helper_make_scatterplot_clickable\n",
    "\n",
    "# each output is: lastClicked, clickedPen, (main_scatter_hovered_connection, main_scatter_clicked_connection)\n",
    "clicked_objects = {}\n",
    "for an_epoch_idx, a_plot in plots_L.scatter_plots.items():\n",
    "\tclicked_objects[an_epoch_idx] = _helper_make_scatterplot_clickable(a_plot, enable_hover=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ca981",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raster_plot_manager.params\n",
    "# neuron_colors_hex, neuron_qcolors_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9322ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.helpers import RectangleRenderTupleHelpers, QPenTuple, QBrushTuple\n",
    "\n",
    "\n",
    "# a_pen = plots_data_L.all_spots_dict[15][0]['pen']\n",
    "# RectangleRenderTupleHelpers.QPen_to_tuple(a_pen)\n",
    "\n",
    "\n",
    "[RectangleRenderTupleHelpers.QPen_to_tuple(a_spot['pen'])  for a_spot in all_spots_dict[15]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8de2e3da",
   "metadata": {},
   "source": [
    "# 2023-05-19 - Testing S-only emergence, L-only replays in S, peak position remappings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d082385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership, SetPartition\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import TrackExclusivePartitionSubset\n",
    "\n",
    "# Four distinct subgroups are formed:  pf on neither, pf on both, pf on only long, pf on only short\n",
    "# L_only_aclus, S_only_aclus\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd91c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _prepare_spikes_df_from_filter_epochs, _find_example_epochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership, SetPartition\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import TrackExclusivePartitionSubset\n",
    "# approach copied from `pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations._epoch_unit_avg_firing_rates`\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions()\n",
    "\n",
    "# included_neuron_ids = deepcopy(exclusive_aclus)\n",
    "# included_neuron_ids = None\n",
    "included_neuron_ids = EITHER_subset.track_exclusive_aclus\n",
    "spikes_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.spikes_df).spikes.sliced_by_neuron_type('pyr')\n",
    "# filter_epochs = deepcopy(curr_active_pipeline.sess.replay)\n",
    "# spikes_df = deepcopy(long_results_obj.spikes_df) # LeaveOneOutDecodingAnalysisResult\n",
    "# spikes_df[np.isin(spikes_df.aclu, included_neuron_ids)]\n",
    "filter_epochs = deepcopy(long_results_obj.active_filter_epochs)\n",
    "\n",
    "filter_epoch_spikes_df, filter_epochs_df = _find_example_epochs(spikes_df, filter_epochs, EITHER_subset.track_exclusive_aclus, included_neuron_ids=included_neuron_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fce367",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 24 cells, 133 Epochs, 789 Total Timebins\n",
    "# Other\n",
    "\t\n",
    "\t- is_non_firing_time_bin: numpy.ndarray - (24, 789)\n",
    "\t- all_epochs_num_epoch_time_bins: numpy.ndarray - (133,)\n",
    "\t\n",
    "    ## Indexing Helpers:\n",
    "\t\t- all_epochs_reverse_flat_epoch_indicies_array: numpy.ndarray - (789,)\n",
    "\t\t- split_by_epoch_reverse_flattened_time_bin_indicies: list - (133,)\n",
    "    \n",
    "\t- original_1D_decoder: pyphoplacecellanalysis.Analysis.Decoder.reconstruction.BasePositionDecoder\n",
    "\t\t- pf: neuropy.analyses.placefields.PfND\n",
    "\t\t- neuron_IDXs: numpy.ndarray - (24,)\n",
    "\t\t- neuron_IDs: numpy.ndarray - (24,)\n",
    "\t\t- F: numpy.ndarray - (119, 24)\n",
    "\t\t- P_x: numpy.ndarray - (119, 1)\n",
    "        \n",
    "\t- flat_all_epochs_decoded_epoch_time_bins: numpy.ndarray - (24, 789)\n",
    "\n",
    "# Measured\n",
    "\t- flat_all_epochs_measured_cell_spike_counts: numpy.ndarray - (24, 789)\n",
    "\t- flat_all_epochs_measured_cell_firing_rates: numpy.ndarray - (24, 789)\n",
    "\n",
    "\n",
    "# Expected\n",
    "\t- flat_all_epochs_computed_expected_cell_firing_rates: numpy.ndarray - (24, 789)\n",
    "\t- flat_all_epochs_difference_from_expected_cell_spike_counts: numpy.ndarray - (24, 789)\n",
    "\t- flat_all_epochs_difference_from_expected_cell_firing_rates: numpy.ndarray - (24, 789)\n",
    "    \n",
    "    \n",
    "    \n",
    "## Epoch-based\n",
    "\t- all_epochs_decoded_epoch_time_bins_mean: numpy.ndarray - (133, 24)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "- flat_all_epochs_measured_cell_firing_rates: numpy.ndarray - .shape: (24, 789) \n",
    "- flat_all_epochs_computed_expected_cell_firing_rates: numpy.ndarray - .shape: (24, 789)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fe80559",
   "metadata": {},
   "source": [
    "# 2023-04-13 - Find Good looking epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9a519",
   "metadata": {
    "tags": [
     "ACTIVE_NOW"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "curr_results_obj = long_results_obj\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context()\n",
    "_out_pagination_controller = DecodedEpochSlicesPaginatedFigureController.init_from_decoder_data(curr_results_obj.active_filter_epochs, curr_results_obj.all_included_filter_epochs_decoder_result, \n",
    "\txbin=curr_results_obj.original_1D_decoder.xbin, global_pos_df=global_session.position.df, a_name='TestDecodedEpochSlicesPaginationController', active_context=active_identifying_session_ctx,  max_subplots_per_page=200) # 10\n",
    "# _out_pagination_controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5280cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b05b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _display_long_and_short_stacked_epoch_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting selections out of DecoedEpochSlicesPaginationController\n",
    "curr_active_pipeline.display_output_history_list\n",
    "# Ideally could search like: '_display_long_and_short_stacked_epoch_slices'\n",
    "active_result_backup = curr_active_pipeline.last_added_display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f7829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(active_result_backup.keys()) # ['name', 'context', 'figures', 'axes', 'plot_data']\n",
    "\n",
    "active_result_backup['context'] # (IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-08_14-26-15', 'DecodedEpochSlices', 'replays', 'long_results_obj')>,\n",
    "\t\t\t\t\t\t\t\t#  IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-08_14-26-15', 'DecodedEpochSlices', 'replays', 'short_results_obj')>)\n",
    "\n",
    "pagination_controllers = active_result_backup.plot_data['controllers']\n",
    "long_controller = pagination_controllers[0]\n",
    "short_controller = pagination_controllers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e85d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_controller.selected_indicies # np.array([ 13,  14,  15,  25,  27,  28,  31,  37,  42,  45,  48,  57,  61,  62,  63,  76,  79,  82,  89,  90, 111, 112, 113, 115])\n",
    "\n",
    "# np.array([5,  13,  15,  17,  20,  21,  24,  31,  33,  43,  44,  49,  63, 64,  66,  68,  70,  71,  74,  76,  77,  78,  84,  90,  94,  95, 104, 105, 122, 123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_controller.selected_indicies # np.array([  9,  11,  13,  14,  15,  20,  22,  25,  37,  40,  45,  48,  61, 62,  76,  79,  84,  89,  90,  93,  94, 111, 112, 113, 115, 121])\n",
    "\n",
    "# np.array([ 12,  13,  15,  17,  20,  24,  30,  31,  32,  33,  41,  43,  49, 54,  55,  68,  70,  71,  73,  76,  77,  78,  84,  89,  94, 100, 104, 105, 111, 114, 115, 117, 118, 122, 123, 131])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5bcc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_context_L = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj')\n",
    "final_context_S = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj')\n",
    "# _out_pagination_controller.params.active_identifying_figure_ctx.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_L = final_context_L.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_S = final_context_S.adding_context(None,  user_annotation=\"selections\")\n",
    "\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='long_results_obj',user_annotation='selections')\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='short_results_obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd249e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the `long_results_obj.active_filter_epochs` and `short_results_obj.active_filter_epochs` objects with the selection information\n",
    "assert long_controller.is_selected.shape[0] == long_results_obj.active_filter_epochs.n_epochs\n",
    "assert short_controller.is_selected.shape[0] == short_results_obj.active_filter_epochs.n_epochs\n",
    "# for some reason the active_filter_epochs on both the long and the short objects contain properties about the other one as well, so keep with tradition and add them to both as well\n",
    "long_results_obj.active_filter_epochs._df['long_is_user_included'] = long_controller.is_selected\n",
    "long_results_obj.active_filter_epochs._df['short_is_user_included'] = short_controller.is_selected\n",
    "short_results_obj.active_filter_epochs._df['long_is_user_included'] = long_controller.is_selected\n",
    "short_results_obj.active_filter_epochs._df['short_is_user_included'] = short_controller.is_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636184b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(long_controller.params.keys())) # ['name', 'window_title', 'num_slices', '_debug_test_max_num_slices', 'active_num_slices', 'global_epoch_start_t', 'global_epoch_end_t', 'single_plot_fixed_height', 'all_plots_height', 'epoch_labels', 'variable_name', 'xbin', 'enable_flat_line_drawing', 'debug_print', 'active_identifying_figure_ctx', 'flat_all_data_indicies', 'is_selected', 'callback_id', 'on_render_page_callbacks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d5dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_controller.selected_epoch_times\n",
    "# array([[ 292.62367098,  292.80826736],\n",
    "#        [ 528.48329294,  528.68561475],\n",
    "#        [ 572.24842637,  572.44236163],\n",
    "#        [ 677.99306343,  678.25522777],\n",
    "#        [ 802.91157867,  803.11436129],\n",
    "#        [ 831.70962856,  831.90743454],\n",
    "#        [ 888.22678107,  888.46492239],\n",
    "#        [ 945.48035303,  945.68543965],\n",
    "#        [ 954.00517939,  954.2546871 ],\n",
    "#        [1033.05203044, 1033.22639707],\n",
    "#        [1061.35727035, 1061.5943979 ],\n",
    "#        [1214.61082388, 1214.834834  ],\n",
    "#        [1722.78022002, 1722.95406441],\n",
    "#        [1741.58530479, 1741.79413924],\n",
    "#        [1743.25171034, 1743.53445707]])\n",
    "short_controller.selected_epoch_times\n",
    "# array([[ 489.42507549,  489.65575186],\n",
    "#        [ 528.48329294,  528.68561475],\n",
    "#        [ 572.24842637,  572.44236163],\n",
    "#        [ 677.99306343,  678.25522777],\n",
    "#        [ 802.91157867,  803.11436129],\n",
    "#        [ 888.22678107,  888.46492239],\n",
    "#        [ 931.21227202,  931.45262518],\n",
    "#        [ 945.48035303,  945.68543965],\n",
    "#        [ 950.18327543,  950.44046313],\n",
    "#        [ 954.00517939,  954.2546871 ],\n",
    "#        [1024.83173129, 1025.10320379],\n",
    "#        [1033.05203044, 1033.22639707],\n",
    "#        [1214.61082388, 1214.834834  ],\n",
    "#        [1326.54476977, 1326.76506278],\n",
    "#        [1329.84606216, 1330.0684134 ],\n",
    "#        [1732.09310613, 1732.29060491],\n",
    "#        [1741.58530479, 1741.79413924],\n",
    "#        [1743.25171034, 1743.53445707],\n",
    "#        [1751.03108555, 1751.22059714],\n",
    "#        [1769.90424581, 1770.10497019],\n",
    "#        [1776.56793264, 1776.78871716],\n",
    "#        [1871.00426701, 1871.21629634],\n",
    "#        [1917.09385877, 1917.2703758 ],\n",
    "#        [1994.07242543, 1994.2525367 ],\n",
    "#        [2038.53127755, 2038.70899266],\n",
    "#        [2064.36693792, 2064.54016792],\n",
    "#        [2111.52742834, 2111.80120484],\n",
    "#        [2125.54830564, 2125.73772506]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab793819",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_results_obj.active_filter_epochs.n_epochs # 122"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eacd1d90",
   "metadata": {},
   "source": [
    "# TODO 2023-06-19 14:31: - [ ] Come up with system for storing user-annotations:\n",
    " Need to store user-annotations and labeled selections for Epochs:\n",
    "\n",
    "\tdate_annotated: datetime - the date the annotations were made\n",
    "\tannotation_author: str - the person who made the annotations\n",
    "\tannotation_content: Any - the content of the annotation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf36a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All epochs are shown for both decoders. So the result should be an epochs table with separate columns for the inclusion in each decoder.\n",
    "@define(slots=False, eq=False)\n",
    "class EpochSelectionSet:\n",
    "    selected_indicies: np.ndarray # a list of the selected inidices\n",
    "\n",
    "long_selection = EpochSelectionSet(selected_indicies=np.array([5,  13,  15,  17,  20,  21,  24,  31,  33,  43,  44,  49,  63, 64,  66,  68,  70,  71,  74,  76,  77,  78,  84,  90,  94,  95, 104, 105, 122, 123]))\n",
    "short_selection = EpochSelectionSet(selected_indicies=np.array([ 12,  13,  15,  17,  20,  24,  30,  31,  32,  33,  41,  43,  49, 54,  55,  68,  70,  71,  73,  76,  77,  78,  84,  89,  94, 100, 104, 105, 111, 114, 115, 117, 118, 122, 123, 131]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f58d5",
   "metadata": {
    "tags": [
     "LEGACY"
    ]
   },
   "outputs": [],
   "source": [
    "# For updating the controller from the selected indicies:\n",
    "for a_selected_index in selection_idxs_L:\n",
    "\t_out_pagination_controller.params.is_selected[a_selected_index] = True\n",
    "\n",
    "_out_pagination_controller.perform_update_selections(defer_render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c7348",
   "metadata": {
    "tags": [
     "user_annotations",
     "active",
     "SERIALIZE"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Mixins.PaginationMixins import SelectionsObject\n",
    "import cattrs\n",
    "\n",
    "user_annotations = {}\n",
    "\n",
    "## IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15')\n",
    "user_annotations[IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='long_results_obj',user_annotation='selections')] = np.array([ 13,  14,  15,  25,  27,  28,  31,  37,  42,  45,  48,  57,  61,  62,  63,  76,  79,  82,  89,  90, 111, 112, 113, 115])\n",
    "user_annotations[IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='short_results_obj',user_annotation='selections')] = np.array([  9,  11,  13,  14,  15,  20,  22,  25,  37,  40,  45,  48,  61, 62,  76,  79,  84,  89,  90,  93,  94, 111, 112, 113, 115, 121])\n",
    "\n",
    "## IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19')\n",
    "user_annotations[IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='long_results_obj',user_annotation='selections')] = np.array([5,  13,  15,  17,  20,  21,  24,  31,  33,  43,  44,  49,  63, 64,  66,  68,  70,  71,  74,  76,  77,  78,  84,  90,  94,  95, 104, 105, 122, 123])\n",
    "user_annotations[IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='short_results_obj',user_annotation='selections')] = np.array([ 12,  13,  15,  17,  20,  24,  30,  31,  32,  33,  41,  43,  49, 54,  55,  68,  70,  71,  73,  76,  77,  78,  84,  89,  94, 100, 104, 105, 111, 114, 115, 117, 118, 122, 123, 131])\n",
    "\n",
    "\n",
    "## try to get the user annotations for this session:\n",
    "selection_idxs_L = user_annotations[selections_context_L]\n",
    "selection_idxs_S = user_annotations[selections_context_S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9773a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cattrs.unstructure(user_annotations)\n",
    "# cattrs.unstructure(selection_idxs_S)\n",
    "cattrs.unstructure(selections_context_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "selections_context_L.as_tuple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aff36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for updating the filter_epochs_df (`filter_epochs_df`) from the selections:\n",
    "filter_epochs_df['long_is_user_included'] = np.isin(filter_epochs_df.index, selection_idxs_L)\n",
    "filter_epochs_df['short_is_user_included'] = np.isin(filter_epochs_df.index, selection_idxs_S)\n",
    "\n",
    "## Finally filter to find the potential example epochs:\n",
    "\n",
    "# only include those with one or more exclusive aclu:\n",
    "considered_filter_epochs_df = filter_epochs_df[filter_epochs_df.contains_one_exclusive_aclu].copy()\n",
    "# require inclusion for long or short:\n",
    "considered_filter_epochs_df = considered_filter_epochs_df[np.logical_xor(filter_epochs_df['long_is_user_included'], filter_epochs_df['short_is_user_included'])]\n",
    "considered_filter_epochs_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0409e08",
   "metadata": {},
   "source": [
    "# Other Programmatic Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe831b56",
   "metadata": {
    "tags": [
     "ACTIVE"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "\n",
    "## Builds proper sort indicies for '_display_short_long_pf1D_comparison'\n",
    "long_ratemap = long_pf1D.ratemap\n",
    "short_ratemap = short_pf1D.ratemap\n",
    "\n",
    "curr_any_context_neurons = _find_any_context_neurons(*[k.neuron_ids for k in [long_ratemap, short_ratemap]])\n",
    "curr_any_context_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402834bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.plotting.ratemaps import plot_ratemap_1D\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_short_v_long_pf1D_comparison, LongShortTrackComparingDisplayFunctions\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "long_single_cell_pfmap_processing_fn = None\n",
    "short_single_cell_pfmap_processing_fn = None\n",
    "# sort_idx = None\n",
    "# sort_idx = sort_ind\n",
    "# sort_idx = sort_indicies\n",
    "# sort_idx = new_all_aclus_sort_indicies\n",
    "sort_idx = 'peak_long'\n",
    "# sort_idx = 'bad'\n",
    "\n",
    "# out = curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_identifying_session_ctx, single_figure=False, debug_print=True, fignum='Short v Long pf1D Comparison',\n",
    "#                                    long_kwargs={'included_unit_neuron_IDs': curr_any_context_neurons, 'included_unit_indicies': None, 'sortby': sort_idx, 'single_cell_pfmap_processing_fn': long_single_cell_pfmap_processing_fn},\n",
    "#                                    short_kwargs={'included_unit_neuron_IDs': curr_any_context_neurons, 'included_unit_indicies': None,'sortby': sort_idx, 'single_cell_pfmap_processing_fn': short_single_cell_pfmap_processing_fn, 'curve_hatch_style': {'hatch':'///', 'edgecolor':'k'}},\n",
    "#                                   )\n",
    "\n",
    "out = curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_identifying_session_ctx, single_figure=False, debug_print=False, fignum='Short v Long pf1D Comparison',\n",
    "                                   long_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': long_single_cell_pfmap_processing_fn},\n",
    "                                   short_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': short_single_cell_pfmap_processing_fn, 'curve_hatch_style': {'hatch':'///', 'edgecolor':'k'}},\n",
    "                                  )\n",
    "                                  \n",
    "\n",
    "# ax = out.axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5653100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_short_long_pf1D_comparison', single_figure=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1906e5a",
   "metadata": {},
   "source": [
    "# 2023-06-01 - Testing new metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3fb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "## Extract variables from results object:\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result['Flat_epoch_time_bins_mean'], expected_v_observed_result['Flat_decoder_time_bin_centers'], expected_v_observed_result['num_neurons'], expected_v_observed_result['num_timebins_in_epoch'], expected_v_observed_result['num_total_flat_timebins'], expected_v_observed_result['is_short_track_epoch'], expected_v_observed_result['is_long_track_epoch'], expected_v_observed_result['short_short_diff'], expected_v_observed_result['long_long_diff']\n",
    "\n",
    "print(f'long_test: {np.mean(long_long_diff)}')\n",
    "print(f'short_test: {np.mean(short_short_diff)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e65f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_results_obj.original_1D_decoder\n",
    "replay_result_df = deepcopy(long_results_obj.active_filter_epochs.to_dataframe())\n",
    "replay_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67e3b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_results_obj.active_filter_epochs.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59838cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at lap speed over time - doesn't look like there's a difference between the long and the short track speeds\n",
    "global_session.position.compute_higher_order_derivatives()\n",
    "running_pos_df = global_session.position.to_dataframe()\n",
    "ax = running_pos_df.plot(x='t', y=['lin_pos','speed'], title='Running Speed over Time')\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627282a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "fig, ax = plot_lines(replay_result_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39e5020d",
   "metadata": {},
   "source": [
    "# 2023-06-13 11:01: - [ ] New display function testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6008da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# from pyphoplacecellanalysis.General.Mixins.ExportHelpers import create_daily_programmatic_display_function_testing_folder_if_needed, session_context_to_relative_path, programmatic_display_to_PDF\n",
    "# from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_pdf_metadata_from_display_context # newer version of build_pdf_export_metadata\n",
    "from neuropy.core.neuron_identities import PlotStringBrevityModeEnum\n",
    "from neuropy.plotting.ratemaps import BackgroundRenderingOptions\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# mpl.rcParams['toolbar'] = 'None' # disable toolbars\n",
    "# matplotlib.use('AGG') # non-interactive backend ## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import programmatic_render_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f47ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap, visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_raster_plot # used in `plot_kourosh_activity_style_figure`\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg # used in `plot_kourosh_activity_style_figure`\n",
    "\n",
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(long_pf1D.ratemap.normalized_tuning_curves, title=f\"pf1D Visualization\")\n",
    "# Apply the colormap\n",
    "# heatmap_pf1D_img.setLookupTable(lut)\n",
    "heatmap_pf1D_win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbecb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _prepare_spikes_df_from_filter_epochs\n",
    "\n",
    "long_ratemap = long_pf1D.ratemap\n",
    "short_ratemap = short_pf1D.ratemap\n",
    "curr_any_context_neurons = _find_any_context_neurons(*[k.neuron_ids for k in [long_ratemap, short_ratemap]])\n",
    "\n",
    "# filter_epochs = deepcopy(long_replays)\n",
    "\n",
    "filter_epochs = deepcopy(long_results_obj.active_filter_epochs.to_dataframe())\n",
    "filter_epoch_spikes_df = _prepare_spikes_df_from_filter_epochs(long_session.spikes_df, filter_epochs=filter_epochs, included_neuron_ids=curr_any_context_neurons, epoch_id_key_name='replay_epoch_id', debug_print=False) # replay_epoch_id\n",
    "filter_epoch_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde77360",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, plots, plots_data = plot_multiple_raster_plot(filter_epochs_df, filter_epoch_spikes_df, included_neuron_ids=shared_aclus, epoch_id_key_name='replay_epoch_id', scatter_app_name=\"Pho Stacked Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df49394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import determine_long_short_pf1D_indicies_sort_by_peak\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _prepare_spikes_df_from_filter_epochs, _find_example_epochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "# approach copied from `pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations._epoch_unit_avg_firing_rates`\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions()\n",
    "\n",
    "# included_neuron_ids = deepcopy(exclusive_aclus)\n",
    "# included_neuron_ids = None\n",
    "included_neuron_ids = EITHER_subset.track_exclusive_aclus\n",
    "spikes_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.spikes_df).spikes.sliced_by_neuron_type('pyr')\n",
    "# filter_epochs = deepcopy(curr_active_pipeline.sess.replay)\n",
    "# spikes_df = deepcopy(long_results_obj.spikes_df) # LeaveOneOutDecodingAnalysisResult\n",
    "# spikes_df[np.isin(spikes_df.aclu, included_neuron_ids)]\n",
    "filter_epochs_df = deepcopy(long_results_obj.active_filter_epochs.to_dataframe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filter_epoch_spikes_df, filter_epochs_df = _find_example_epochs(spikes_df, filter_epochs_df, EITHER_subset.track_exclusive_aclus, included_neuron_ids=included_neuron_ids) # adds 'active_unique_aclus'\n",
    "# epoch_contains_any_exclusive_aclus.append(np.isin(epoch_spikes_unique_aclus, exclusive_aclus).any())\n",
    "filter_epochs_df['has_SHORT_exclusive_aclu'] = [np.isin(epoch_spikes_unique_aclus, short_exclusive.track_exclusive_aclus).any() for epoch_spikes_unique_aclus in filter_epochs_df['active_unique_aclus']]\n",
    "filter_epochs_df['has_LONG_exclusive_aclu'] = [np.isin(epoch_spikes_unique_aclus, long_exclusive.track_exclusive_aclus).any() for epoch_spikes_unique_aclus in filter_epochs_df['active_unique_aclus']]\n",
    "\n",
    "# requires selection_idxs_L, selection_idxs_S\n",
    "\n",
    "# for updating the filter_epochs_df (`filter_epochs_df`) from the selections:\n",
    "filter_epochs_df['long_is_user_included'] = np.isin(filter_epochs_df.index, selection_idxs_L)\n",
    "filter_epochs_df['short_is_user_included'] = np.isin(filter_epochs_df.index, selection_idxs_S)\n",
    "\n",
    "# Finally, get only the epochs that meet the criteria:\n",
    "\n",
    "\n",
    "# # only include those with one or more exclusive aclu:\n",
    "# considered_filter_epochs_df = filter_epochs_df[filter_epochs_df.contains_one_exclusive_aclu].copy()\n",
    "# # require inclusion for long or short:\n",
    "# considered_filter_epochs_df = considered_filter_epochs_df[np.logical_xor(filter_epochs_df['long_is_user_included'], filter_epochs_df['short_is_user_included'])]\n",
    "\n",
    "# Get separate long-side/short-side canidate replays:\n",
    "# considered_long_side_epochs_df = filter_epochs_df[(filter_epochs_df['has_LONG_exclusive_aclu'] & ~filter_epochs_df['short_is_user_included'] & filter_epochs_df['long_is_user_included'])].copy() # replay not considered good by user for short decoding, but it is for long decoding. Finally, has at least one LONG exclusive ACLU.\n",
    "considered_long_side_epochs_df = filter_epochs_df[(filter_epochs_df['has_LONG_exclusive_aclu'] & filter_epochs_df['long_is_user_included'])].copy() # replay not considered good by user for short decoding, but it is for long decoding. Finally, has at least one LONG exclusive ACLU.\n",
    "# considered_long_side_epochs_df\n",
    "# considered_short_side_epochs_df = filter_epochs_df[(filter_epochs_df['has_SHORT_exclusive_aclu'] & filter_epochs_df['short_is_user_included'] & ~filter_epochs_df['long_is_user_included'])].copy()  # replay not considered good by user for long decoding, but it is for short decoding. Finally, has at least one SHORT exclusive ACLU.\n",
    "considered_short_side_epochs_df = filter_epochs_df[(filter_epochs_df['has_SHORT_exclusive_aclu'] & filter_epochs_df['short_is_user_included'])].copy()  # replay not considered good by user for long decoding, but it is for short decoding. Finally, has at least one SHORT exclusive ACLU.\n",
    "# considered_short_side_epochs_df\n",
    "\n",
    "\n",
    "# Common for all rasters:\n",
    "new_all_aclus_sort_indicies = determine_long_short_pf1D_indicies_sort_by_peak(curr_active_pipeline=curr_active_pipeline, curr_any_context_neurons=EITHER_subset.track_exclusive_aclus)\n",
    "\n",
    "# considered_filter_epochs_df = deepcopy(considered_long_side_epochs_df)\n",
    "considered_filter_epochs_df = deepcopy(considered_short_side_epochs_df)\n",
    "# considered_filter_epochs_df = deepcopy(filter_epochs_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6da56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filter_epoch_spikes_df = _prepare_spikes_df_from_filter_epochs(filter_epoch_spikes_df, filter_epochs=considered_filter_epochs_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, epoch_id_key_name='replay_epoch_id', debug_print=True) # replay_epoch_id\n",
    "app, win, plots, plots_data = plot_multiple_raster_plot(considered_filter_epochs_df, filter_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_id_key_name='replay_epoch_id', scatter_app_name=\"Pho Custom Selected Stacked Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48451ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_filter_epochs = deepcopy(considered_short_side_epochs_df)\n",
    "filter_epoch_spikes_df = _prepare_spikes_df_from_filter_epochs(filter_epoch_spikes_df, filter_epochs=active_filter_epochs, included_neuron_ids=EITHER_subset.track_exclusive_aclus, epoch_id_key_name='replay_epoch_id', debug_print=True) # replay_epoch_id\n",
    "app, win, plots, plots_data = plot_multiple_raster_plot(active_filter_epochs, filter_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_id_key_name='replay_epoch_id', scatter_app_name=\"Pho Custom Selected Stacked Replays - Short Side\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec7dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_filter_epochs = deepcopy(considered_long_side_epochs_df)\n",
    "filter_epoch_spikes_df = _prepare_spikes_df_from_filter_epochs(filter_epoch_spikes_df, filter_epochs=active_filter_epochs, included_neuron_ids=EITHER_subset.track_exclusive_aclus, epoch_id_key_name='replay_epoch_id', debug_print=True) # replay_epoch_id\n",
    "app, win, plots, plots_data = plot_multiple_raster_plot(active_filter_epochs, filter_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_id_key_name='replay_epoch_id', scatter_app_name=\"Pho Custom Selected Stacked Replays - LONG Side\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab1452",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_short_side_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc278ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_long_side_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23fd55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_short_side_epochs_df = filter_epochs_df[ (filter_epochs_df['has_SHORT_exclusive_aclu'] & filter_epochs_df['short_is_user_included'] & ~filter_epochs_df['long_is_user_included']) ]  # replay not considered good by user for long decoding, but it is for short decoding. Finally, has at least one SHORT exclusive ACLU.\n",
    "considered_short_side_epochs_df\n",
    "\n",
    "considered_long_side_epochs_df = filter_epochs_df[ (filter_epochs_df['has_LONG_exclusive_aclu'] & ~filter_epochs_df['short_is_user_included'] & filter_epochs_df['long_is_user_included']) ] # replay not considered good by user for short decoding, but it is for long decoding. Finally, has at least one LONG exclusive ACLU.\n",
    "considered_long_side_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9ef48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
