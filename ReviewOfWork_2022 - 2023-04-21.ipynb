{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from benedict import benedict\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from benedict import benedict # https://github.com/fabiocaccamo/python-benedict#usage\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import CodeConversion\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible, print_value_overview_only, document_active_variables, objsize, print_object_memory_usage, debug_dump_object_member_shapes, TypePrintMode\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import batch_load_session, batch_extended_computations, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "\n",
    "# from PendingNotebookCode import _perform_batch_plot, _build_batch_plot_kwargs\n",
    "\n",
    "session_batch_status = {}\n",
    "session_batch_errors = {}\n",
    "enable_saving_to_disk = False\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "#     neuropy/data_session_pre_processing_scripts/KDIBA/IIDataMat_Export_ToPython_2022_08_01.m\n",
    "# From pre-computed .mat files:\n",
    "\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# Animal `gor01`:\n",
    "local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='one') # IdentifyingContext<('kdiba', 'gor01', 'one')>\n",
    "local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # 'gor01', 'one'\n",
    "local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['PhoHelpers', 'Spike3D-Minimal-Test', 'Unused'])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# ## Animal `vvp01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# ### Animal `pin01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='pin01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # no exper_name ('one' or 'two') folders for this animal.\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['redundant','showclus','sleep','tmaze'])\n",
    "\n",
    "## Build session contexts list:\n",
    "local_session_contexts_list = [local_session_parent_context.adding_context(collision_prefix='sess', session_name=a_name) for a_name in local_session_names_list] # [IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-07_11-26-53')>, ..., IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-13_14-42-6')>]\n",
    "\n",
    "## Initialize `session_batch_status` with the NOT_STARTED status if it doesn't already have a different status\n",
    "for curr_session_basedir in local_session_paths_list:\n",
    "    curr_session_status = session_batch_status.get(curr_session_basedir, None)\n",
    "    if curr_session_status is None:\n",
    "        session_batch_status[curr_session_basedir] = SessionBatchProgress.NOT_STARTED # set to not started if not present\n",
    "        # session_batch_status[curr_session_basedir] = SessionBatchProgress.COMPLETED # set to not started if not present\n",
    "\n",
    "session_batch_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e68b4-03e0-4388-a35c-87a352a6e6b3",
   "metadata": {
    "tags": [
     "load",
     "single_session",
     "REQUIRED"
    ]
   },
   "outputs": [],
   "source": [
    "%pdb off\n",
    "# %%viztracer\n",
    "basedir = local_session_paths_list[1] # NOT 3\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# epoch_name_whitelist = ['maze']\n",
    "epoch_name_whitelist = None\n",
    "active_computation_functions_name_whitelist=['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        # '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding'\n",
    "                                    ]\n",
    "curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_whitelist=epoch_name_whitelist,\n",
    "                                          computation_functions_name_whitelist=active_computation_functions_name_whitelist,\n",
    "                                          saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                          skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e403d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.placefields import PfND\n",
    "from PendingNotebookCode import constrain_to_laps\n",
    "from PendingNotebookCode import compute_short_long_constrained_decoders\n",
    "\n",
    "curr_active_pipeline = constrain_to_laps(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda48261",
   "metadata": {},
   "outputs": [],
   "source": [
    "(long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "# 3m 40.3s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a896c17",
   "metadata": {},
   "source": [
    "# Fix pipeline persistance issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d8ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_time_dependent_placefield_computation'], enabled_filter_names=[long_epoch_name, short_epoch_name, global_epoch_name], fail_on_exception=False, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04466ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_drop_computed_result(computed_data_keys_to_drop=['_perform_time_dependent_placefield_computation'], config_names_whitelist=[long_epoch_name, short_epoch_name, global_epoch_name], debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183508e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE) # AttributeError: 'PfND_TimeDependent' object has no attribute '_included_thresh_neurons_indx'\n",
    "# TypeError: cannot pickle 'MplMultiTab' object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2112c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a1877",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline._persistance_state\n",
    "curr_active_pipeline.pipeline_compare_dict\n",
    "curr_active_pipeline.persistance_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a92c8",
   "metadata": {},
   "source": [
    "# 2023-03-16 - Explore passing in long/short decoders specifically to `perform_full_session_leave_one_out_decoding_analysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26804fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder, BayesianPlacemapPositionDecoder\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import perform_full_session_leave_one_out_decoding_analysis\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import SurpriseAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import build_neurons_color_map # for plot_short_v_long_pf1D_comparison\n",
    "\n",
    "# Get existing long/short decoders from the cell under \"# 2023-02-24 Decoders\"\n",
    "long_decoder, short_decoder = deepcopy(long_one_step_decoder_1D), deepcopy(short_one_step_decoder_1D)\n",
    "assert np.all(long_decoder.xbin == short_decoder.xbin)\n",
    "\n",
    "# Backup and replace loaded replays with computed ones:\n",
    "long_replays, short_replays, global_replays = [a_session.replace_session_replays_with_estimates(require_intersecting_epoch=None, debug_print=False) for a_session in [long_session, short_session, global_session]]\n",
    "\n",
    "### Need to prune to only the cells active in both epochs ahead of time:\n",
    "# Prune to the shared aclus in both epochs (short/long):\n",
    "long_shared_aclus_only_decoder, short_shared_aclus_only_decoder = [BasePositionDecoder.init_from_stateful_decoder(a_decoder) for a_decoder in (long_decoder, short_decoder)]\n",
    "shared_aclus, (long_shared_aclus_only_decoder, short_shared_aclus_only_decoder), long_short_pf_neurons_diff = BasePositionDecoder.prune_to_shared_aclus_only(long_shared_aclus_only_decoder, short_shared_aclus_only_decoder)\n",
    "n_neurons = len(shared_aclus)\n",
    "# for plotting purposes, build colors only for the common (present in both, the intersection) neurons:\n",
    "neurons_colors_array = build_neurons_color_map(n_neurons, sortby=None, cmap=None)\n",
    "print(f'{n_neurons = }, {neurons_colors_array.shape =}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b360bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from viztracer import VizTracer\n",
    "\n",
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "\tlong_results_obj = perform_full_session_leave_one_out_decoding_analysis(global_session, original_1D_decoder=long_shared_aclus_only_decoder, decoding_time_bin_size = 0.025, cache_suffix = '_long', perform_cache_load=False) # , perform_cache_load=False\n",
    "\tshort_results_obj = perform_full_session_leave_one_out_decoding_analysis(global_session, original_1D_decoder=short_shared_aclus_only_decoder, decoding_time_bin_size = 0.025, cache_suffix = '_short', perform_cache_load=False) # , perform_cache_load=False\n",
    "\n",
    "# 4m 22.4s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69eed8a",
   "metadata": {},
   "source": [
    "## 2023-04-13 - Shuffled Surprise\n",
    "\"\"\" \n",
    "Relevant Functions:\n",
    "`perform_full_session_leave_one_out_decoding_analysis`:\n",
    "\t`perform_leave_one_aclu_out_decoding_analysis`:\tfrom pyphoplacecellanalysis.Analysis.Decoder.decoder_result import perform_leave_one_aclu_out_decoding_analysis\n",
    "\t`_analyze_leave_one_out_decoding_results`: from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.DefaultComputationFunctions import _analyze_leave_one_out_decoding_results\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac42d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PendingNotebookCode import _new_compute_surprise, TimebinnedNeuronActivity\n",
    "# Distance metrics used by `_new_compute_surprise`\n",
    "# from scipy.spatial import distance # for Jensen-Shannon distance in `_subfn_compute_leave_one_out_analysis`\n",
    "# import random # for random.choice(mylist)\n",
    "# # from PendingNotebookCode import _scramble_curve\n",
    "# from scipy.stats import wasserstein_distance\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# def _compute_multi_surprise_metric(pf, p_x_given_n):\n",
    "# \treturn {'correlation': distance.correlation(pf, p_x_given_n),\n",
    "# \t\t'JSD': distance.jensenshannon(pf, p_x_given_n)}\n",
    "\n",
    "# active_surprise_metric_fn = lambda pf, p_x_given_n: distance.jensenshannon(pf, p_x_given_n)\n",
    "# active_surprise_metric_fn = lambda pf, p_x_given_n: distance.correlation(pf, p_x_given_n)\n",
    "# active_surprise_metric_fn = lambda pf, p_x_given_n: distance.sqeuclidean(pf, p_x_given_n)\n",
    "# active_surprise_metric_fn = lambda pf, p_x_given_n: wasserstein_distance(pf, p_x_given_n) # Figure out the correct function for this, it's in my old notebooks\n",
    "# active_surprise_metric_fn = lambda pf, p_x_given_n: pearsonr(pf, p_x_given_n)[0] # this returns just the correlation coefficient (R), not the p-value due to the [0]\n",
    "# active_surprise_metric_fn = _compute_multi_surprise_metric\n",
    "# long_results_obj, result, result_df, result_df_grouped = _new_compute_surprise(long_results_obj, active_surprise_metric_fn=active_surprise_metric_fn)\n",
    "\n",
    "# 2023-04-18 - Refactored into decoder_result\n",
    "result, result_df, result_df_grouped = long_results_obj.result, long_results_obj.result_df, long_results_obj.result_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478b7530",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c61634",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe57a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b860dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import loadData, saveData\n",
    "\n",
    "### Build a folder to store the temporary outputs:\n",
    "output_data_folder = sess.get_output_path()\n",
    "\n",
    "cache_suffix = '_long'\n",
    "leave_one_out_result_pickle_path = output_data_folder.joinpath(f'leave_one_out_surprise_results{cache_suffix}.pkl').resolve()\n",
    "print(f'leave_one_out_result_pickle_path: {leave_one_out_result_pickle_path}')\n",
    "saveData(leave_one_out_result_pickle_path, (long_results_obj))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936d766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c107570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import DiagnosticDistanceMetricFigure\n",
    "\n",
    "## Render the internactive slider that allows selecting the timebin index to debug\n",
    "n_timebins = np.sum(long_results_obj.all_epochs_num_epoch_time_bins)\n",
    "timebinned_neuron_info = long_results_obj.timebinned_neuron_info\n",
    "result = long_results_obj.new_result\n",
    "active_fig_obj, update_function = DiagnosticDistanceMetricFigure.build_interactive_diagnostic_distance_metric_figure(long_results_obj, timebinned_neuron_info, result)\n",
    "active_fig_obj.integer_slider(n_timebins=n_timebins, update_func=update_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Get set of cells active in a given time bin, for each compute the surprise of its placefield with the leave-one-out decoded posterior.\n",
    "\n",
    "# 2. From the remainder of cells (those not active), randomly choose one to grab the placefield of and compute the surprise with that and the same posterior.\n",
    "\n",
    "\n",
    "# Expectation: The cells that are included in the time bin are expected to have a lower surprise (be less correlated with) the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff50bc",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import build_pyqtgraph_epoch_indicator_regions # Add session indicators to pyqtgraph plot\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions import _helper_add_long_short_session_indicator_regions\n",
    "\n",
    "from pyphocorehelpers.print_helpers import generate_html_string\n",
    "# Long Short\n",
    "# TODO 2023-04-18 - Can Refactor in terms of `plot_long_short_any_values`?\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "# 'time_bin_indices': valid_time_bin_indicies, 'posterior_to_pf_mean_surprise': one_left_out_posterior_to_pf_surprises_mean, 'posterior_to_scrambled_pf_mean_surprise': one_left_out_posterior_to_scrambled_pf_surprises_mean}\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions import plot_long_short_expected_vs_observed_firing_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae2e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "win, plots_tuple, legend = plot_long_short_expected_vs_observed_firing_rates(long_results_obj, short_results_obj)\n",
    "long_epoch_indicator_region_items, short_epoch_indicator_region_items = _helper_add_long_short_session_indicator_regions(win, long_epoch=curr_active_pipeline.filtered_epochs[long_epoch_name], short_epoch=curr_active_pipeline.filtered_epochs[short_epoch_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4efa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_long_short_surprise_difference_plot(long_results_obj, short_results_obj):\n",
    "\t\"\"\" captures `curr_active_pipeline` \"\"\"\n",
    "\t# Private Subfunctions _______________________________________________________________________________________________ #\n",
    "\tdef _subfn_add_difference_plot_series(win, plots, result_df_grouped, series_suffix, **kwargs):\n",
    "\t\t\"\"\" captures nothing\n",
    "\t\tmodifies `plots` \"\"\"\n",
    "\t\tx=result_df_grouped.time_bin_centers.to_numpy()\n",
    "\t\ty=result_df_grouped['surprise_diff'].to_numpy()\n",
    "\t\tseries_id_str = f'difference_{series_suffix}'\n",
    "\t\tplots[series_id_str] = win.plot(x=x, y=y, name=series_id_str, alpha=0.5, **kwargs) #  symbolBrush=pg.intColor(i,6,maxValue=128) , symbol=curr_symbol, symbolBrush=cell_color_symbol_brush[unit_IDX]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t# BEGIN FUNCTION BODY ________________________________________________________________________________________________ #\n",
    "\n",
    "\t# make a separate symbol_brush color for each cell:\n",
    "\t# cell_color_symbol_brush = [pg.intColor(i,hues=9, values=3, alpha=180) for i, aclu in enumerate(long_results_obj.original_1D_decoder.neuron_IDs)] # maxValue=128\n",
    "\t# All properties in common:\n",
    "\twin = pg.plot() # PlotWidget\n",
    "\twin.setWindowTitle('Long Sanity Check - Leave-one-out Custom Surprise Plot')\n",
    "\t# legend_size = (80,60) # fixed size legend\n",
    "\tlegend_size = None # auto-sizing legend to contents\n",
    "\tlegend = pg.LegendItem(legend_size, offset=(-1,0)) # do this instead of # .addLegend\n",
    "\tlegend.setParentItem(win.graphicsItem())\n",
    "\n",
    "\tplots = {}\n",
    "\tlabel_prefix_list = ['normal', 'scrambled']\n",
    "\tlong_short_symbol_list = ['t', 'o'] # note: 's' is a square. 'o', 't1': triangle pointing upwards0\n",
    "\n",
    "\t# Use mean time_bin and surprise for each epoch\n",
    "\t# plots['normal'] = win.plot(x=valid_time_bin_indicies, y=one_left_out_posterior_to_pf_surprises_mean, pen=None, symbol='t', symbolBrush=pg.intColor(1,6,maxValue=128), name=f'normal', alpha=0.5) #  symbolBrush=pg.intColor(i,6,maxValue=128) , symbol=curr_symbol, symbolBrush=cell_color_symbol_brush[unit_IDX]\n",
    "\t# plots['scrambled'] = win.plot(x=valid_time_bin_indicies, y=one_left_out_posterior_to_scrambled_pf_surprises_mean, pen=None, symbol='t', symbolBrush=pg.intColor(2,6,maxValue=128), name=f'scrambled', alpha=0.5) #  symbolBrush=pg.intColor(i,6,maxValue=128) , symbol=curr_symbol, symbolBrush=cell_color_symbol_brush[unit_IDX]\n",
    "\n",
    "\t# curr_surprise_difference = one_left_out_posterior_to_scrambled_pf_surprises_mean - one_left_out_posterior_to_pf_surprises_mean\n",
    "\n",
    "\t# x=valid_time_bin_indicies\n",
    "\t# y=curr_surprise_difference\n",
    "\t# x=result_df_grouped.time_bin_indices.to_numpy()\n",
    "\n",
    "\t\n",
    "\t_subfn_add_difference_plot_series(win, plots, long_results_obj.result_df_grouped, series_suffix='_long', **dict(pen=None, symbol='t', symbolBrush=pg.intColor(2,6,maxValue=128), clickable=True, hoverable=True, hoverSize=7))\n",
    "\n",
    "\t_subfn_add_difference_plot_series(win, plots, short_results_obj.result_df_grouped, series_suffix='_short', **dict(pen=None, symbol='o', symbolBrush=pg.intColor(3,6,maxValue=128), clickable=True))\n",
    "\n",
    "\t# dict(pen=None, symbol='t', symbolBrush=pg.intColor(2,6,maxValue=128))\n",
    "\n",
    "\n",
    "\t# x=result_df_grouped.time_bin_centers.to_numpy()\n",
    "\t# y=result_df_grouped['surprise_diff'].to_numpy()\n",
    "\t# plots['difference'] = win.plot(x=x, y=y, pen=None, symbol='t', symbolBrush=pg.intColor(2,6,maxValue=128), name=f'difference', alpha=0.5) #  symbolBrush=pg.intColor(i,6,maxValue=128) , symbol=curr_symbol, symbolBrush=cell_color_symbol_brush[unit_IDX]\n",
    "\n",
    "\t# long_results_obj.result, long_results_obj.result_df, long_results_obj.result_df_grouped\n",
    "\n",
    "\t# short_results_obj.result, short_results_obj.result_df, short_results_obj.result_df_grouped\n",
    "\n",
    "\n",
    "\tfor k, v in plots.items():\n",
    "\t\tlegend.addItem(v, f'{k}')\n",
    "\n",
    "\twin.graphicsItem().setLabel(axis='left', text='Normal v. Random - Surprise (Custom)')\n",
    "\twin.graphicsItem().setLabel(axis='bottom', text='time')\n",
    "\n",
    "\twin.showGrid(True, True)  # Show grid for reference\n",
    "\n",
    "\t# Emphasize the y=0 crossing by drawing a horizontal line at y=0\n",
    "\tvline = pg.InfiniteLine(pos=0, angle=0, movable=False, pen=pg.mkPen(color='w', width=2, style=pg.QtCore.Qt.DashLine))\n",
    "\twin.addItem(vline)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t# Add session indicators to pyqtgraph plot\n",
    "\tlong_epoch = curr_active_pipeline.filtered_epochs[long_epoch_name]\n",
    "\tshort_epoch = curr_active_pipeline.filtered_epochs[short_epoch_name]\n",
    "\tlong_epoch_indicator_region_items, short_epoch_indicator_region_items = _helper_add_long_short_session_indicator_regions(win, long_epoch, short_epoch)\n",
    "\n",
    "\t# epoch_linear_region, epoch_region_label = build_pyqtgraph_epoch_indicator_regions(win, t_start=curr_active_pipeline.filtered_epochs[long_epoch_name].t_start, t_stop=curr_active_pipeline.filtered_epochs[long_epoch_name].t_stop, epoch_label='long', **dict(pen=pg.mkPen('#0b0049'), brush=pg.mkBrush('#0099ff42'), hoverBrush=pg.mkBrush('#fff400'), hoverPen=pg.mkPen('#00ff00')))\n",
    "\t# epoch_linear_region, epoch_region_label = build_pyqtgraph_epoch_indicator_regions(win, t_start=curr_active_pipeline.filtered_epochs[short_epoch_name].t_start, t_stop=curr_active_pipeline.filtered_epochs[short_epoch_name].t_stop, epoch_label='short', **dict(pen=pg.mkPen('#490000'), brush=pg.mkBrush('#f5161659'), hoverBrush=pg.mkBrush('#fff400'), hoverPen=pg.mkPen('#00ff00')))\n",
    "\n",
    "\ti_str = generate_html_string('i', color='white', bold=True)\n",
    "\tj_str = generate_html_string('j', color='red', bold=True)\n",
    "\ttitle_str = generate_html_string(f'JSD(p_x_given_n, pf[{i_str}]) - JSD(p_x_given_n, pf[{j_str}]) where {j_str} non-firing')\n",
    "\twin.setTitle(title_str)\n",
    "\n",
    "\twin.setWindowTitle('Long Sanity Check - Leave-one-out Custom Surprise Plot - JSD')\n",
    "\n",
    "\treturn win, plots\n",
    "\n",
    "win, plots = plot_long_short_surprise_difference_plot(long_results_obj, short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d937f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _helper_make_scatterplot_clickable(main_scatter_plot, enable_hover:bool=False):\n",
    "\t# Highlights the hovered spikes white:\n",
    "\t# main_scatter_plot.addPoints(hoverable=True,\n",
    "\t# \t# hoverSymbol=vtick, # hoverSymbol='s',\n",
    "\t# \thoverSize=7, # default is 5\n",
    "\t# \t)\n",
    "\n",
    "\n",
    "\t## Clickable/Selectable Spikes:\n",
    "\t# Will make all plots clickable\n",
    "\tclickedPen = pg.mkPen('#DDD', width=2)\n",
    "\tlastClicked = []\n",
    "\tdef _test_scatter_plot_clicked(plot, points):\n",
    "\t\tglobal lastClicked\n",
    "\t\tfor p in lastClicked:\n",
    "\t\t\tp.resetPen()\n",
    "\t\tprint(\"clicked points\", points)\n",
    "\t\tfor p in points:\n",
    "\t\t\tp.setPen(clickedPen)\n",
    "\t\tlastClicked = points\n",
    "\n",
    "\tmain_scatter_clicked_connection = main_scatter_plot.sigClicked.connect(_test_scatter_plot_clicked)\n",
    "\n",
    "\t## Hoverable Spikes:\n",
    "\tif enable_hover:\n",
    "\t\tdef _test_scatter_plot_hovered(plt, points, ev):\n",
    "\t\t\t# sigHovered(self, points, ev)\n",
    "\t\t\tprint(f'_test_scatter_plot_hovered(plt: {plt}, points: {points}, ev: {ev})')\n",
    "\t\t\tif (len(points) > 0):\n",
    "\t\t\t\tcurr_point = points[0]\n",
    "\t\t\t\t# self.\n",
    "\t\t\t\t# curr_point.index\n",
    "\t\tmain_scatter_hovered_connection = main_scatter_plot.sigHovered.connect(_test_scatter_plot_hovered)\n",
    "\telse:\n",
    "\t\tmain_scatter_hovered_connection = None\n",
    "\n",
    "\treturn lastClicked, clickedPen, (main_scatter_hovered_connection, main_scatter_clicked_connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a84888",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plot = plots['difference__long']  # PlotDataItem \n",
    "a_curve = a_plot.curve # PlotCurveItem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e78da",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plot.sigPointsClicked\n",
    "# a_plot.sigPointsHovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe350d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve.curve.setClickable(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will make all plots clickable\n",
    "clickedPen = pg.mkPen('#DDD', width=2)\n",
    "lastClicked = []\n",
    "def _test_scatter_plot_clicked(plot, points):\n",
    "\tglobal lastClicked\n",
    "\tfor p in lastClicked:\n",
    "\t\tp.resetPen()\n",
    "\tprint(\"clicked points\", points)\n",
    "\tfor p in points:\n",
    "\t\tp.setPen(clickedPen)\n",
    "\tlastClicked = points\n",
    "\n",
    "main_scatter_clicked_connection = a_plot.sigClicked.connect(_test_scatter_plot_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastClicked, clickedPen, (main_scatter_hovered_connection, main_scatter_clicked_connection) = _helper_make_scatterplot_clickable(a_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d54370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to map from time_bin_indicies to times\n",
    "a_plot = plots['difference'] # PlotDataItem \n",
    "# a_plot.setLa\n",
    "# win.graphicsItem().setLabel(axis='left', text='Normal v. Random - Surprise (Custom)')\n",
    "\n",
    "# # Set the plot title with a LaTeX formula\n",
    "# title = pg.LabelItem(justify='center')\n",
    "# title.setText(r'<font size=\"4\">JSD Surprise Diff: $\\fn{JSD}{\\matr{pf}_{i}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}} - \\fn{JSD}{\\matr{pf}_{j}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}}$</font>')\n",
    "# win.addItem(title)\n",
    "\n",
    "# win.graphicsItem().setLabel(axis='top', text=r'$\\fn{JSD}{\\matr{pf}_{i}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}} - \\fn{JSD}{\\matr{pf}_{j}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot # works pretty well seemingly\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "export_pyqtgraph_plot(win)\n",
    "# pg.setConfigOption('leftTitle', 'MathText')\n",
    "# win.setTitle(r'JSD(p_x_given_n, pf[<font size=\"4\"><b><span style=\"color:red;\">i</span></b></font>]) - JSD(p_x_given_n, pf[<font size=\"4\"><b>j</b></font>]) where <font size=\"4\"><b>j</b></font> non-firing')\n",
    "\n",
    "\n",
    "# win.setTitle(generate_html_string(f'JSD(p_x_given_n, pf[{i_str}]) - JSD(p_x_given_n, pf[{j_str}]) where {j_str} non-firing', font_size=8))\n",
    "\n",
    "# r'$\\fn{JSD}{\\matr{pf}_{i}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}} - \\fn{JSD}{\\matr{pf}_{j}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}}$'\n",
    "# title_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d68ce1",
   "metadata": {},
   "source": [
    "$\\fn{JSD}{\\matr{pf}_{i}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}} - \\fn{JSD}{\\matr{pf}_{j}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c015652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "win.setBackground\n",
    "win.setWindowTitle\n",
    "win.setBackgroundBrush\n",
    "win.setXRange\n",
    "win.setYRange\n",
    "\n",
    "\"Show X Grid\"\n",
    "\"Show Y Grid\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d0cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_config = dict(pen=pg.mkPen('#fff'), brush=pg.mkBrush('#f004'), hoverBrush=pg.mkBrush('#fff4'), hoverPen=pg.mkPen('#f00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e586e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_epochs[short_epoch_name].t_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_epochs[long_epoch_name].start_end_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f996fd9",
   "metadata": {},
   "source": [
    "## Pre 2023-04-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea08f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Fresh (don't load from cache)\n",
    "long_results_obj = perform_full_session_leave_one_out_decoding_analysis(global_session, original_1D_decoder=long_shared_aclus_only_decoder, decoding_time_bin_size = 0.025, cache_suffix = '_long', perform_cache_load=False, skip_cache_save=False)\n",
    "short_results_obj = perform_full_session_leave_one_out_decoding_analysis(global_session, original_1D_decoder=short_shared_aclus_only_decoder, decoding_time_bin_size = 0.025, cache_suffix = '_short', perform_cache_load=False, skip_cache_save=False)\n",
    "# # (time_bins, neurons), (epochs, neurons), (epochs)\n",
    "# all_epochs_computed_one_left_out_posterior_to_pf_surprises, all_epochs_computed_cell_one_left_out_posterior_to_pf_surprises_mean, all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b6ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import plot_kourosh_activity_style_figure\n",
    "\n",
    "from neuropy.core.neurons import NeuronType\n",
    "# # Include only pyramidal aclus:\n",
    "# print(f'all shared_aclus: {len(shared_aclus)}\\nshared_aclus: {shared_aclus}')\n",
    "# shared_aclu_neuron_type = long_session.neurons.neuron_type[np.isin(long_session.neurons.neuron_ids, shared_aclus)]\n",
    "# assert len(shared_aclu_neuron_type) == len(shared_aclus)\n",
    "# # Find only the aclus that are pyramidal:\n",
    "# is_shared_aclu_pyramidal = (shared_aclu_neuron_type == NeuronType.PYRAMIDAL)\n",
    "# pyramidal_only_shared_aclus = shared_aclus[is_shared_aclu_pyramidal]\n",
    "# print(f'num pyramidal_only_shared_aclus: {len(pyramidal_only_shared_aclus)}\\npyramidal_only_shared_aclus: {pyramidal_only_shared_aclus}')\n",
    "\n",
    "\n",
    "## Drop Pyramidal but don't use only shared aclus:\n",
    "all_aclus = deepcopy(long_session.neurons.neuron_ids)\n",
    "neuron_type = long_session.neurons.neuron_type\n",
    "assert len(neuron_type) == len(all_aclus)\n",
    "# Find only the aclus that are pyramidal:\n",
    "is_aclu_pyramidal = (neuron_type == NeuronType.PYRAMIDAL)\n",
    "pyramidal_only_all_aclus = all_aclus[is_aclu_pyramidal]\n",
    "print(f'num pyramidal_only_all_aclus: {len(pyramidal_only_all_aclus)}\\npyramidal_only_all_aclus: {pyramidal_only_all_aclus}')\n",
    "\n",
    "# app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, shared_aclus, epoch_idx=5, callout_epoch_IDXs=[0,1,2,3], skip_rendering_callouts=True)\n",
    "# app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_shared_aclus, epoch_idx=2, callout_epoch_IDXs=[0,4], skip_rendering_callouts=False)\n",
    "app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_all_aclus, epoch_idx=3, callout_epoch_IDXs=[2,4,6], skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea983fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_all_aclus, epoch_idx=11, callout_epoch_IDXs=[0,1,2, 3, 4, 5], skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519e392",
   "metadata": {},
   "source": [
    "# 2023-04-13 Show Surprise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b417bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions import plot_long_short, plot_long_short_any_values, plot_long_short_expected_vs_observed_firing_rates, _helper_add_long_short_session_indicator_regions\n",
    "# plot_long_short(long_results_obj, short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd6593",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_long_short_any_values(long_results_obj=long_results_obj, short_results_obj=short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_long_short_expected_vs_observed_firing_rates(long_results_obj=long_results_obj, short_results_obj=short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fn = lambda a_results_obj: a_results_obj.all_epochs_decoded_epoch_time_bins_mean[:,0]\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_scrambled_pf_surprises_mean\n",
    "y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_computed_one_left_out_posterior_to_pf_surprises\n",
    "\n",
    "# (time_bins, neurons), (epochs, neurons), (epochs)\n",
    "# all_epochs_computed_one_left_out_posterior_to_pf_surprises, all_epochs_computed_cell_one_left_out_posterior_to_pf_surprises_mean, all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "win, plots_tuple, legend = plot_long_short_any_values(long_results_obj, short_results_obj, x=x_fn, y=y_fn, limit_aclus=[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe80559",
   "metadata": {},
   "source": [
    "# 2023-04-13 - Find Good looking epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb6dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices\n",
    "\n",
    "laps_plot_tuple = plot_decoded_epoch_slices(long_results_obj.active_filter_epochs, long_results_obj.all_included_filter_epochs_decoder_result, global_pos_df=global_session.position.df, variable_name='lin_pos', xbin=long_results_obj.original_1D_decoder.xbin,\n",
    "                                                        name='stacked_epoch_slices_long_results_obj', debug_print=True, debug_test_max_num_slices=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed0656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [23, 27, 29, ]\n",
    "[16, 17, 18, 20, 21, 22, 23, 25, 26, 29]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pagination support for `plot_decoded_epoch_slices`\n",
    "from pyphocorehelpers.indexing_helpers import compute_paginated_grid_config\n",
    "\n",
    "n_epochs = long_results_obj.active_filter_epochs.n_epochs\n",
    "subplot_no_pagination_configuration, included_combined_indicies_pages, page_grid_sizes = compute_paginated_grid_config(n_epochs, max_num_columns=1, max_subplots_per_page=32, data_indicies=result_df_grouped.index.to_numpy(), last_figure_subplots_same_layout=True)\n",
    "num_pages = len(included_combined_indicies_pages)\n",
    "num_pages\n",
    "included_epoch_indicies_pages = [[curr_included_epoch_index for (a_linear_index, curr_row, curr_col, curr_included_epoch_index) in v] for page_idx, v in enumerate(included_combined_indicies_pages)] # a list of length `num_pages` containing up to 10 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bdb485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf9f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import batch_extended_computations\n",
    "\n",
    "batch_extended_computations(curr_active_pipeline, include_whitelist=[], include_global_functions=False, fail_on_exception=True, progress_print=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a65b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.session_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e6526e9",
   "metadata": {},
   "source": [
    "# 2023-03-28 - Playing around with older computations/visualizations from the `_display_short_long_firing_rate_index_comparison` era:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d2e9eb6",
   "metadata": {},
   "source": [
    "\n",
    "2023-04-20 - Encountered issue with the replays in session '2006-6-08_14-26-15' where they are duplicated exactly twice, like the first half of the rows are legitimate entries and the second half are directly repeated versions of the first with the only difference appearing to be the 'epoch_id' column changes from 1 to 2. 'rel_id' column seems incorrect but different for some reason. It must be how the MATLAB script exports the values.\n",
    "\n",
    "Also when I'm looking at only the `short_session.replay` there are many non-2 'epoch_id' values, which is strange. \n",
    "\n",
    "TODO: It could have something to do with Jonathan's code maybe? Because the 'replay_r' and 'replay_p' columns he added are different. SEEMS FALSE. It's this way even without running Jonathan's code, although the values might have been saved later?\n",
    "\tAlso flat_replay_idx jumps from 689 to 1087 at the transition from epoch_id 1 to 2\n",
    "\n",
    "UPDATE: the 'replay_r' and 'replay_p' columns aren't from Joanthan, they're in the original .replay_info.mat that's imported!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd397788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import create_daily_programmatic_display_function_testing_folder_if_needed, session_context_to_relative_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61605d54",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/NonInteractiveWrapper.py:498\u001b[0m, in \u001b[0;36mbatch_extended_computations\u001b[0;34m(curr_active_pipeline, include_whitelist, include_global_functions, fail_on_exception, progress_print, debug_print)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    497\u001b[0m     \u001b[39m## Get global `long_short_fr_indicies_analysis` results:\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m     long_short_fr_indicies_analysis_results \u001b[39m=\u001b[39m curr_active_pipeline\u001b[39m.\u001b[39;49mglobal_computation_results\u001b[39m.\u001b[39;49mcomputed_data[\u001b[39m'\u001b[39;49m\u001b[39mlong_short_fr_indicies_analysis\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m    499\u001b[0m     x_frs_index, y_frs_index \u001b[39m=\u001b[39m long_short_fr_indicies_analysis_results[\u001b[39m'\u001b[39m\u001b[39mx_frs_index\u001b[39m\u001b[39m'\u001b[39m], long_short_fr_indicies_analysis_results[\u001b[39m'\u001b[39m\u001b[39my_frs_index\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m# use the all_results_dict as the computed data value\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/pyPhoCoreHelpers/src/pyphocorehelpers/DataStructure/dynamic_parameters.py:34\u001b[0m, in \u001b[0;36mDynamicParameters.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDynamicParameters.__getitem__(self, key): key \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mapping[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'long_short_fr_indicies_analysis'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 2023-01-* - Call extended computations to build `_display_short_long_firing_rate_index_comparison` figures:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m extended_computations_include_whitelist\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mlong_short_fr_indicies_analyses\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mjonathan_firing_rate_analysis\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m# do only specifiedl\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m newly_computed_values \u001b[39m=\u001b[39m batch_extended_computations(curr_active_pipeline, include_whitelist\u001b[39m=\u001b[39;49mextended_computations_include_whitelist, include_global_functions\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, fail_on_exception\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, progress_print\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, debug_print\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      4\u001b[0m newly_computed_values\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/NonInteractiveWrapper.py:510\u001b[0m, in \u001b[0;36mbatch_extended_computations\u001b[0;34m(curr_active_pipeline, include_whitelist, include_global_functions, fail_on_exception, progress_print, debug_print)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m progress_print \u001b[39mor\u001b[39;00m debug_print:\n\u001b[1;32m    509\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m Recomputing \u001b[39m\u001b[39m{\u001b[39;00m_comp_name\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 510\u001b[0m curr_active_pipeline\u001b[39m.\u001b[39;49mperform_specific_computation(computation_functions_name_whitelist\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39m_perform_short_long_firing_rate_analyses\u001b[39;49m\u001b[39m'\u001b[39;49m], fail_on_exception\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, debug_print\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \u001b[39m# fail_on_exception MUST be True or error handling is all messed up \u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m done.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    512\u001b[0m long_short_fr_indicies_analysis_results \u001b[39m=\u001b[39m curr_active_pipeline\u001b[39m.\u001b[39mglobal_computation_results\u001b[39m.\u001b[39mcomputed_data[\u001b[39m'\u001b[39m\u001b[39mlong_short_fr_indicies_analysis\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py:796\u001b[0m, in \u001b[0;36mPipelineWithComputedPipelineStageMixin.perform_specific_computation\u001b[0;34m(self, active_computation_params, enabled_filter_names, computation_functions_name_whitelist, computation_kwargs_list, fail_on_exception, debug_print)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" perform a specific computation (specified in computation_functions_name_whitelist) in a minimally destructive manner using the previously recomputed results:\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[39mPassthrough wrapper to self.stage.perform_specific_computation(...) with the same arguments.\u001b[39;00m\n\u001b[1;32m    791\u001b[0m \n\u001b[1;32m    792\u001b[0m \u001b[39mUpdates:\u001b[39;00m\n\u001b[1;32m    793\u001b[0m \u001b[39m    curr_active_pipeline.computation_results\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[39m# self.stage is of type ComputedPipelineStage\u001b[39;00m\n\u001b[0;32m--> 796\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstage\u001b[39m.\u001b[39;49mperform_specific_computation(active_computation_params\u001b[39m=\u001b[39;49mactive_computation_params, enabled_filter_names\u001b[39m=\u001b[39;49menabled_filter_names, computation_functions_name_whitelist\u001b[39m=\u001b[39;49mcomputation_functions_name_whitelist, computation_kwargs_list\u001b[39m=\u001b[39;49mcomputation_kwargs_list, fail_on_exception\u001b[39m=\u001b[39;49mfail_on_exception, debug_print\u001b[39m=\u001b[39;49mdebug_print)\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py:466\u001b[0m, in \u001b[0;36mComputedPipelineStage.perform_specific_computation\u001b[0;34m(self, active_computation_params, enabled_filter_names, computation_functions_name_whitelist, computation_kwargs_list, fail_on_exception, debug_print)\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[39m## TODO: ERROR: `owning_pipeline_reference=self` is not CORRECT as self is of type `ComputedPipelineStage` (or `DisplayPipelineStage`) and not `NeuropyPipeline`\u001b[39;00m\n\u001b[1;32m    463\u001b[0m         \u001b[39m# this has been fine for all the global functions so far because the majority of the properties are defined on the stage anyway, but any pipeline properties will be missing! \u001b[39;00m\n\u001b[1;32m    464\u001b[0m     global_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(owning_pipeline_reference\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, global_computation_results\u001b[39m=\u001b[39mprevious_computation_result, computation_results\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomputation_results, active_configs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactive_configs, include_whitelist\u001b[39m=\u001b[39menabled_filter_names, debug_print\u001b[39m=\u001b[39mdebug_print)\n\u001b[0;32m--> 466\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_computation_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_specific_computations_single_context(global_kwargs, computation_functions_name_whitelist\u001b[39m=\u001b[39;49mcomputation_functions_name_whitelist, are_global\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, fail_on_exception\u001b[39m=\u001b[39;49mfail_on_exception, debug_print\u001b[39m=\u001b[39;49mdebug_print)\n\u001b[1;32m    467\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m     \u001b[39m# Non-global functions:\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[39mfor\u001b[39;00m a_select_config_name, a_filtered_session \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiltered_sessions\u001b[39m.\u001b[39mitems():                \n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py:251\u001b[0m, in \u001b[0;36mComputedPipelineStage.run_specific_computations_single_context\u001b[0;34m(self, previous_computation_result, computation_functions_name_whitelist, computation_kwargs_list, fail_on_exception, progress_logger_callback, are_global, debug_print)\u001b[0m\n\u001b[1;32m    249\u001b[0m     progress_logger_callback(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrun_specific_computations_single_context(including only \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(active_computation_functions)\u001b[39m}\u001b[39;00m\u001b[39m out of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregistered_computation_function_names)\u001b[39m}\u001b[39;00m\u001b[39m registered computation functions): active_computation_functions: \u001b[39m\u001b[39m{\u001b[39;00mactive_computation_functions\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    250\u001b[0m \u001b[39m# Perform the computations:\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[39mreturn\u001b[39;00m ComputedPipelineStage\u001b[39m.\u001b[39;49m_execute_computation_functions(active_computation_functions, previous_computation_result\u001b[39m=\u001b[39;49mprevious_computation_result, computation_kwargs_list\u001b[39m=\u001b[39;49mcomputation_kwargs_list, fail_on_exception\u001b[39m=\u001b[39;49mfail_on_exception, progress_logger_callback\u001b[39m=\u001b[39;49mprogress_logger_callback, are_global\u001b[39m=\u001b[39;49mare_global, debug_print\u001b[39m=\u001b[39;49mdebug_print)\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py:533\u001b[0m, in \u001b[0;36mComputedPipelineStage._execute_computation_functions\u001b[0;34m(active_computation_functions, previous_computation_result, computation_kwargs_list, fail_on_exception, progress_logger_callback, are_global, debug_print)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[39mif\u001b[39;00m progress_logger_callback \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m         progress_logger_callback(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mExecuting [\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mtotal_num_funcs\u001b[39m}\u001b[39;00m\u001b[39m]: \u001b[39m\u001b[39m{\u001b[39;00mf\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 533\u001b[0m     previous_computation_result \u001b[39m=\u001b[39m f(previous_computation_result, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomputation_kwargs_list[i])\n\u001b[1;32m    535\u001b[0m \u001b[39m# Since there's no error handling, gettin ghere means that there were no accumulated errors\u001b[39;00m\n\u001b[1;32m    536\u001b[0m accumulated_errors \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/MultiContextComputationFunctions.py:52\u001b[0m, in \u001b[0;36m_wrap_multi_context_computation_function.<locals>._\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(x):\n\u001b[1;32m     51\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(x) \u001b[39m>\u001b[39m \u001b[39m4\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 52\u001b[0m     x[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m global_comp_fcn(\u001b[39m*\u001b[39;49mx) \u001b[39m# update global_computation_results\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/MultiContextComputationFunctions.py:314\u001b[0m, in \u001b[0;36mMultiContextComputationFunctions._perform_short_long_firing_rate_analyses\u001b[0;34m(owning_pipeline_reference, global_computation_results, computation_results, active_configs, include_whitelist, debug_print)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" \u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[39mRequires:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39m# New unified `pipeline_complete_compute_long_short_fr_indicies(...)` method for entire pipeline:\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m x_frs_index, y_frs_index, active_context, all_results_dict \u001b[39m=\u001b[39m pipeline_complete_compute_long_short_fr_indicies(owning_pipeline_reference) \u001b[39m# use the all_results_dict as the computed data value\u001b[39;00m\n\u001b[1;32m    315\u001b[0m global_computation_results\u001b[39m.\u001b[39mcomputed_data[\u001b[39m'\u001b[39m\u001b[39mlong_short_fr_indicies_analysis\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m DynamicParameters\u001b[39m.\u001b[39minit_from_dict({\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mall_results_dict, \u001b[39m'\u001b[39m\u001b[39mactive_context\u001b[39m\u001b[39m'\u001b[39m: active_context})\n\u001b[1;32m    316\u001b[0m \u001b[39mreturn\u001b[39;00m global_computation_results\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/MultiContextComputationFunctions.py:1357\u001b[0m, in \u001b[0;36mpipeline_complete_compute_long_short_fr_indicies\u001b[0;34m(curr_active_pipeline, temp_save_filename)\u001b[0m\n\u001b[1;32m   1334\u001b[0m \u001b[39m# TODO 2023-04-11 - Note this doesn't assign these filtered laps objects to the session or anything yet, it just returns them.\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m \n\u001b[1;32m   1336\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[39m#     return Epoch(active_filter_epochs)\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m \u001b[39m# long_replays, short_replays, global_replays = [process_existing_replays_from_session(curr_active_pipeline.filtered_sessions[an_epoch_name], minimum_valid_replay_duration=(5.0 * decoding_time_bin_size)) for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]] # NOTE: this includes a few overlapping   epochs since the function to remove overlapping ones seems to be broken\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1356\u001b[0m     \u001b[39m# long_replays, short_replays, global_replays = [Epoch(curr_active_pipeline.filtered_sessions[an_epoch_name].replay.epochs.get_valid_df()) for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]] # NOTE: this includes a few overlapping   epochs since the function to remove overlapping ones seems to be broken\u001b[39;00m\n\u001b[0;32m-> 1357\u001b[0m     long_replays, short_replays, global_replays \u001b[39m=\u001b[39m [DataSession\u001b[39m.\u001b[39mfilter_replay_epochs(curr_active_pipeline\u001b[39m.\u001b[39mfiltered_sessions[an_epoch_name]\u001b[39m.\u001b[39mreplay, pos_df\u001b[39m=\u001b[39mcurr_active_pipeline\u001b[39m.\u001b[39mfiltered_sessions[an_epoch_name]\u001b[39m.\u001b[39mposition\u001b[39m.\u001b[39mto_dataframe(), spikes_df\u001b[39m=\u001b[39mcurr_active_pipeline\u001b[39m.\u001b[39mfiltered_sessions[an_epoch_name]\u001b[39m.\u001b[39mspikes_df) \u001b[39mfor\u001b[39;00m an_epoch_name \u001b[39min\u001b[39;00m [long_epoch_name, short_epoch_name, global_epoch_name]] \u001b[39m# NOTE: this includes a few overlapping   epochs since the function to remove overlapping ones seems to be broken\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mKeyError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1360\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mReplays missing, need to compute new ones... e: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/MultiContextComputationFunctions.py:1357\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1334\u001b[0m \u001b[39m# TODO 2023-04-11 - Note this doesn't assign these filtered laps objects to the session or anything yet, it just returns them.\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m \n\u001b[1;32m   1336\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[39m#     return Epoch(active_filter_epochs)\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m \u001b[39m# long_replays, short_replays, global_replays = [process_existing_replays_from_session(curr_active_pipeline.filtered_sessions[an_epoch_name], minimum_valid_replay_duration=(5.0 * decoding_time_bin_size)) for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]] # NOTE: this includes a few overlapping   epochs since the function to remove overlapping ones seems to be broken\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1356\u001b[0m     \u001b[39m# long_replays, short_replays, global_replays = [Epoch(curr_active_pipeline.filtered_sessions[an_epoch_name].replay.epochs.get_valid_df()) for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]] # NOTE: this includes a few overlapping   epochs since the function to remove overlapping ones seems to be broken\u001b[39;00m\n\u001b[0;32m-> 1357\u001b[0m     long_replays, short_replays, global_replays \u001b[39m=\u001b[39m [DataSession\u001b[39m.\u001b[39;49mfilter_replay_epochs(curr_active_pipeline\u001b[39m.\u001b[39;49mfiltered_sessions[an_epoch_name]\u001b[39m.\u001b[39;49mreplay, pos_df\u001b[39m=\u001b[39;49mcurr_active_pipeline\u001b[39m.\u001b[39;49mfiltered_sessions[an_epoch_name]\u001b[39m.\u001b[39;49mposition\u001b[39m.\u001b[39;49mto_dataframe(), spikes_df\u001b[39m=\u001b[39;49mcurr_active_pipeline\u001b[39m.\u001b[39;49mfiltered_sessions[an_epoch_name]\u001b[39m.\u001b[39;49mspikes_df) \u001b[39mfor\u001b[39;00m an_epoch_name \u001b[39min\u001b[39;00m [long_epoch_name, short_epoch_name, global_epoch_name]] \u001b[39m# NOTE: this includes a few overlapping   epochs since the function to remove overlapping ones seems to be broken\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mKeyError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1360\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mReplays missing, need to compute new ones... e: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/repos/NeuroPy/neuropy/core/session/dataSession.py:480\u001b[0m, in \u001b[0;36mDataSession.filter_replay_epochs\u001b[0;34m(cls, curr_replays, pos_df, spikes_df, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"filters the provided replay epochs by specified constraints.\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \n\u001b[1;32m    463\u001b[0m \u001b[39m# require_intersecting_epoch:Epoch=None, min_epoch_included_duration=0.06, max_epoch_included_duration=0.6, maximum_speed_thresh=2.0, min_inclusion_fr_active_thresh=2.0, min_num_unique_aclu_inclusions=3, save_on_compute=False, debug_print=False\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    477\u001b[0m \n\u001b[1;32m    478\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mneuropy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mepoch\u001b[39;00m \u001b[39mimport\u001b[39;00m Epoch\n\u001b[0;32m--> 480\u001b[0m \u001b[39mreturn\u001b[39;00m Epoch\u001b[39m.\u001b[39;49mfilter_epochs(curr_epochs\u001b[39m=\u001b[39;49mcurr_replays, pos_df\u001b[39m=\u001b[39;49mpos_df, spikes_df\u001b[39m=\u001b[39;49mspikes_df, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/repos/NeuroPy/neuropy/core/epoch.py:399\u001b[0m, in \u001b[0;36mEpoch.filter_epochs\u001b[0;34m(cls, curr_epochs, pos_df, spikes_df, require_intersecting_epoch, min_epoch_included_duration, max_epoch_included_duration, maximum_speed_thresh, min_inclusion_fr_active_thresh, min_num_unique_aclu_inclusions, debug_print)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39mif\u001b[39;00m (min_inclusion_fr_active_thresh \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m (min_num_unique_aclu_inclusions \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    398\u001b[0m     \u001b[39massert\u001b[39;00m spikes_df \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mmust provide spikes_df if filtering by active units\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 399\u001b[0m     active_spikes_df \u001b[39m=\u001b[39m spikes_df\u001b[39m.\u001b[39;49mspikes\u001b[39m.\u001b[39;49msliced_by_neuron_type(\u001b[39m'\u001b[39;49m\u001b[39mpyr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m# trim based on pyramidal cell activity only\u001b[39;00m\n\u001b[1;32m    400\u001b[0m     \u001b[39mif\u001b[39;00m curr_epochs\u001b[39m.\u001b[39mn_epochs \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    401\u001b[0m         spike_trimmed_active_epochs, epoch_split_spike_dfs, all_aclus, dense_epoch_split_frs_mat, is_cell_active_in_epoch_mat \u001b[39m=\u001b[39m filter_epochs_by_num_active_units(active_spikes_df, curr_epochs, min_inclusion_fr_active_thresh\u001b[39m=\u001b[39mmin_inclusion_fr_active_thresh, min_num_unique_aclu_inclusions\u001b[39m=\u001b[39mmin_num_unique_aclu_inclusions) \u001b[39m# TODO: seems wasteful considering we compute all these spikes_df metrics and refinements and then don't return them.\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/NeuroPy/neuropy/core/flattened_spiketrains.py:121\u001b[0m, in \u001b[0;36mSpikesAccessor.sliced_by_neuron_type\u001b[0;34m(self, query_neuron_type)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    120\u001b[0m \u001b[39m# Compare via .shortClassName for both query_neuron_type and self._obj.cell_type\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m inclusion_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misin(np\u001b[39m.\u001b[39marray([a_type\u001b[39m.\u001b[39mshortClassName \u001b[39mfor\u001b[39;00m a_type \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj\u001b[39m.\u001b[39mcell_type]), [query_neuron_type\u001b[39m.\u001b[39mshortClassName])\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj\u001b[39m.\u001b[39mloc[inclusion_mask, :]\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/repos/NeuroPy/neuropy/core/flattened_spiketrains.py:121\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    120\u001b[0m \u001b[39m# Compare via .shortClassName for both query_neuron_type and self._obj.cell_type\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m inclusion_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misin(np\u001b[39m.\u001b[39marray([a_type\u001b[39m.\u001b[39;49mshortClassName \u001b[39mfor\u001b[39;00m a_type \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj\u001b[39m.\u001b[39mcell_type]), [query_neuron_type\u001b[39m.\u001b[39mshortClassName])\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj\u001b[39m.\u001b[39mloc[inclusion_mask, :]\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/repos/NeuroPy/neuropy/core/neurons.py:42\u001b[0m, in \u001b[0;36mNeuronType.shortClassName\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshortClassName\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m NeuronType\u001b[39m.\u001b[39;49mshortClassNames()[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue]\n",
      "File \u001b[0;32m~/repos/NeuroPy/neuropy/core/neurons.py:57\u001b[0m, in \u001b[0;36mNeuronType.shortClassNames\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlongClassNames\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([\u001b[39m'\u001b[39m\u001b[39mpyramidal\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcontaminated\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39minterneurons\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 57\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshortClassNames\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[1;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([\u001b[39m'\u001b[39m\u001b[39mpyr\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcont\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mintr\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     61\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbapunNpyFileStyleShortClassNames\u001b[39m(\u001b[39mcls\u001b[39m):\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1758\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.ThreadTracer.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spike3d-xhKu_1Lg-py3.9/lib64/python3.9/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/pydev_is_thread_alive.py:9\u001b[0m, in \u001b[0;36mis_thread_alive\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      6\u001b[0m _temp \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mThread()\n\u001b[1;32m      7\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_temp, \u001b[39m'\u001b[39m\u001b[39m_is_stopped\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# Python 3.x has this\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mis_thread_alive\u001b[39m(t):\n\u001b[1;32m     10\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39m_is_stopped\n\u001b[1;32m     12\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_temp, \u001b[39m'\u001b[39m\u001b[39m_Thread__stopped\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# Python 2.x has this\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 2023-01-* - Call extended computations to build `_display_short_long_firing_rate_index_comparison` figures:\n",
    "extended_computations_include_whitelist=['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis'] # do only specifiedl\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_whitelist=extended_computations_include_whitelist, include_global_functions=True, fail_on_exception=True, progress_print=True, debug_print=False)\n",
    "newly_computed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3e6ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'long_short_fr_indicies_analyses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_short_long_firing_rate_analyses'], fail_on_exception=True, debug_print=False) # fail_on_exception MUST be True or error handling is all messed up \n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_index, y_frs_index = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']\n",
    "long_short_fr_indicies_analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09070ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_frs_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a13cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot long|short firing rate index:\n",
    "# fig_save_parent_path = Path(r'E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Results from 2023-01-20 - LongShort Firing Rate Indicies')\n",
    "## Get the output path (active_session_figures_out_path) for this session (and all of its filtered_contexts as well):\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "figures_parent_out_path = create_daily_programmatic_display_function_testing_folder_if_needed()\n",
    "active_session_figures_out_path = session_context_to_relative_path(figures_parent_out_path, active_identifying_session_ctx)\n",
    "print(f'curr_session_parent_out_path: {active_session_figures_out_path}')\n",
    "active_session_figures_out_path.mkdir(parents=True, exist_ok=True) # make folder if needed\n",
    "curr_active_pipeline.display('_display_short_long_firing_rate_index_comparison', curr_active_pipeline.sess.get_context(), fig_save_parent_path=active_session_figures_out_path)\n",
    "# plt.close() # closes the current figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecc42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_extended_programmatic_figures(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4289a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_programmatic_figures(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the 2D placefields for my presentation\n",
    "from neuropy.core.neuron_identities import PlotStringBrevityModeEnum\n",
    "from neuropy.plotting.ratemaps import BackgroundRenderingOptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# '_display_2d_placefield_result_plot_ratemaps_2D'\n",
    "# %matplotlib inline\n",
    "%matplotlib qt\n",
    "# curr_active_pipeline.display('_display_2d_placefield_result_plot_ratemaps_2D', long_epoch_context) # MatplotlibRenderPlots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48029c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# long_pf2D.plot_occupancy()\n",
    "_out = short_one_step_decoder_2D.pf.plot_ratemaps_2D(included_unit_neuron_IDs=[2,4,5], bg_rendering_mode=BackgroundRenderingOptions.EMPTY, use_special_overlayed_title=False, missing_aclu_string_formatter=None, debug_print=False, brev_mode=PlotStringBrevityModeEnum.NONE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
