{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "\n",
    "# from PendingNotebookCode import _perform_batch_plot, _build_batch_plot_kwargs\n",
    "# from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "# from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import run_diba_batch\n",
    "\n",
    "from scripts.run_BatchAnalysis import post_compute_validate, _on_complete_success_execution_session\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "\n",
    "\n",
    "active_global_batch_result_filename='global_batch_result_2023-06-08.pkl'\n",
    "debug_print=True\n",
    "enable_neptune = False\n",
    "\n",
    "if enable_neptune:\n",
    "    import neptune # for logging progress and results\n",
    "    from neptune.types import File\n",
    "    from pyphoplacecellanalysis.General.Batch.NeptuneAiHelpers import set_environment_variables, neptune_output_figures\n",
    "    neptune_kwargs = {'project':\"commander.pho/PhoDibaLongShort2023\",\n",
    "    'api_token':\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGIxODU2My1lZTNhLTQ2ZWMtOTkzNS02ZTRmNzM5YmNjNjIifQ==\"}\n",
    "    set_environment_variables(neptune_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde1acc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalized_loaded_global_batch_result_pickle_path: W:\\Data\\global_batch_result_2023-06-08.pkl\n",
      "Loading loaded session pickle file results : W:\\Data\\global_batch_result_2023-06-08.pkl... done.\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Memo value not found at index 631",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Loading.py:44\u001b[0m, in \u001b[0;36mloadData\u001b[1;34m(pkl_path, debug_print, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m     db \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(dbfile, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:373\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, ignore, **kwds)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39mUnpickle an object from a file.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \n\u001b[0;32m    371\u001b[0m \u001b[39mSee :func:`loads` for keyword arguments.\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 373\u001b[0m \u001b[39mreturn\u001b[39;00m Unpickler(file, ignore\u001b[39m=\u001b[39;49mignore, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\u001b[39m.\u001b[39;49mload()\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:646\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m): \u001b[39m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[1;32m--> 646\u001b[0m     obj \u001b[39m=\u001b[39m StockUnpickler\u001b[39m.\u001b[39;49mload(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    647\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(obj)\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39mgetattr\u001b[39m(_main_module, \u001b[39m'\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pathlib.py:1084\u001b[0m, in \u001b[0;36mPath.__new__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1083\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flavour\u001b[39m.\u001b[39mis_supported:\n\u001b[1;32m-> 1084\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot instantiate \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m on your system\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1085\u001b[0m                               \u001b[39m%\u001b[39m (\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m,))\n\u001b[0;32m   1086\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init()\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: cannot instantiate 'PosixPath' on your system",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m \trun[\u001b[39m\"\u001b[39m\u001b[39mdataset/latest\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mtrack_files(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfile://\u001b[39m\u001b[39m{\u001b[39;00mglobal_batch_result_file_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39m# \"s3://datasets/images\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39m# try to load an existing batch result:\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m global_batch_run \u001b[39m=\u001b[39m BatchRun\u001b[39m.\u001b[39;49mtry_init_from_file(global_data_root_parent_path, active_global_batch_result_filename\u001b[39m=\u001b[39;49mactive_global_batch_result_filename, debug_print\u001b[39m=\u001b[39;49mdebug_print) \u001b[39m# on_needs_create_callback_fn=run_diba_batch\u001b[39;00m\n\u001b[0;32m     27\u001b[0m batch_progress_df \u001b[39m=\u001b[39m global_batch_run\u001b[39m.\u001b[39mto_dataframe(expand_context\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, good_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m# all\u001b[39;00m\n\u001b[0;32m     28\u001b[0m good_only_batch_progress_df \u001b[39m=\u001b[39m global_batch_run\u001b[39m.\u001b[39mto_dataframe(expand_context\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, good_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\runBatch.py:82\u001b[0m, in \u001b[0;36mBatchRun.try_init_from_file\u001b[1;34m(cls, global_data_root_parent_path, active_global_batch_result_filename, debug_print)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m global_batch_run\n\u001b[0;32m     80\u001b[0m \u001b[39m##\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m global_batch_run \u001b[39m=\u001b[39m _try_load_global_batch_result()\n\u001b[0;32m     83\u001b[0m \u001b[39mif\u001b[39;00m global_batch_run \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m     \u001b[39m# One was loaded from file, meaning it has the potential to have the wrong paths. Check.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     global_batch_run\u001b[39m.\u001b[39mchange_global_root_path(global_data_root_parent_path) \u001b[39m# Convert the paths to work on the new system:\u001b[39;00m\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\runBatch.py:62\u001b[0m, in \u001b[0;36mBatchRun.try_init_from_file.<locals>._try_load_global_batch_result\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39m# try to load an existing batch result:\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 62\u001b[0m     global_batch_run \u001b[39m=\u001b[39m loadData(finalized_loaded_global_batch_result_pickle_path, debug_print\u001b[39m=\u001b[39;49mdebug_print)\n\u001b[0;32m     64\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39m# Fixes issue with pickled POSIX_PATH on windows for path.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     posix_backup \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPosixPath \u001b[39m# backup the PosixPath definition\u001b[39;00m\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Loading.py:62\u001b[0m, in \u001b[0;36mloadData\u001b[1;34m(pkl_path, debug_print, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     pathlib\u001b[39m.\u001b[39mPosixPath \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPurePosixPath\n\u001b[1;32m---> 62\u001b[0m     db \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(dbfile, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m# Fails this time if it still throws an error\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     pathlib\u001b[39m.\u001b[39mPosixPath \u001b[39m=\u001b[39m posix_backup \u001b[39m# restore the backup posix path definition\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:373\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, ignore, **kwds)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(file, ignore\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[0;32m    368\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m    Unpickle an object from a file.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \n\u001b[0;32m    371\u001b[0m \u001b[39m    See :func:`loads` for keyword arguments.\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 373\u001b[0m     \u001b[39mreturn\u001b[39;00m Unpickler(file, ignore\u001b[39m=\u001b[39;49mignore, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\u001b[39m.\u001b[39;49mload()\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:646\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m): \u001b[39m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[1;32m--> 646\u001b[0m     obj \u001b[39m=\u001b[39m StockUnpickler\u001b[39m.\u001b[39;49mload(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    647\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(obj)\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39mgetattr\u001b[39m(_main_module, \u001b[39m'\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    648\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ignore:\n\u001b[0;32m    649\u001b[0m             \u001b[39m# point obj class to main\u001b[39;00m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: Memo value not found at index 631"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import main, BatchRun, run_diba_batch, run_specific_batch\n",
    "\n",
    "\"\"\"\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "\n",
    "## NEPTUNE:\n",
    "if enable_neptune:\n",
    "\tproject = neptune.init_project(**neptune_kwargs)\n",
    "\tproject[\"general/global_batch_result_filename\"] = active_global_batch_result_filename\n",
    "\tproject[\"general/global_data_root_parent_path\"] = global_data_root_parent_path.as_posix()\n",
    "\n",
    "## TODO: load the batch result initially:\n",
    "\n",
    "## Build Pickle Path:\n",
    "global_batch_result_file_path = Path(global_data_root_parent_path).joinpath(active_global_batch_result_filename).resolve() # Use Default\n",
    "\n",
    "if enable_neptune:\n",
    "\trun = neptune.init_run() # rember to run.stop()\n",
    "\trun['parameters/global_batch_result_file_path'] = global_batch_result_file_path.as_posix()\n",
    "\t# project[\"general/data_analysis\"].upload(\"data_analysis.ipynb\")\n",
    "\trun[\"dataset/latest\"].track_files(f\"file://{global_batch_result_file_path}\") # \"s3://datasets/images\"\n",
    "\n",
    "# try to load an existing batch result:\n",
    "global_batch_run = BatchRun.try_init_from_file(global_data_root_parent_path, active_global_batch_result_filename=active_global_batch_result_filename, debug_print=debug_print) # on_needs_create_callback_fn=run_diba_batch\n",
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "\n",
    "if enable_neptune:\n",
    "\trun[\"dataset/global_batch_run_progress_df\"].upload(File.as_html(batch_progress_df)) # \"path/to/test_preds.csv\"\n",
    "\trun[\"dataset/global_batch_run_good_only_df\"].upload(File.as_html(good_only_batch_progress_df)) # \"path/to/test_preds.csv\"\n",
    "\t\n",
    "batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba250bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_df = pd.read_hdf(finalized_output_cache_file, key=desired_spikes_df_key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c12f42b4",
   "metadata": {},
   "source": [
    "# Build `global_batch_run` pre-loading results (before execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496a7c6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# global_batch_result = loadData('global_batch_result.pkl')\n",
    "global_batch_run = run_diba_batch(global_data_root_parent_path, execute_all=False, extant_batch_run=global_batch_run, debug_print=False)\n",
    "# print(f'global_batch_result: {global_batch_run}')\n",
    "global_batch_run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab824348",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Batch Executions/Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d043e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## I got it doing the bare-minimum loading and computations, so it should be ready to update the laps and constraint the placefields to those. Then we should be able to set up the replays at the same time.\n",
    "# finally, we then finish by computing.\n",
    "# force_reload = True\n",
    "force_reload = False\n",
    "\n",
    "## Execute with the custom arguments.\n",
    "active_computation_functions_name_includelist=['_perform_baseline_placefield_computation',\n",
    "                                        # '_perform_time_dependent_placefield_computation',\n",
    "                                        '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        # '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding'\n",
    "                                    ]\n",
    "# active_computation_functions_name_includelist=['_perform_baseline_placefield_computation']\n",
    "global_batch_run.execute_all(force_reload=force_reload, skip_extended_batch_computations=True, post_run_callback_fn=_on_complete_success_execution_session, **{'computation_functions_name_includelist': active_computation_functions_name_includelist, 'active_session_computation_configs': None}) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 4m 39.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45172b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last completed:\n",
    "r'W:\\Data\\KDIBA\\pin01\\one\\11-03_12-3-25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d2321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to file:\n",
    "saveData(global_batch_result_file_path, global_batch_run) # Update the global batch run dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c0e3f6-5c37-42e1-b06d-7a8028cb9512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get output files:\n",
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8f1582-93ba-4f7d-bab9-a566a6c3462d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Build a list of the output files for the good sessions:\n",
    "session_result_paths = [str(v.joinpath(f'loadedSessPickle.pkl').resolve()) for v in list(good_only_batch_progress_df.basedirs.values)]\n",
    "global_computation_result_paths = [str(v.joinpath(f'output/global_computation_results.pkl').resolve()) for v in list(good_only_batch_progress_df.basedirs.values)]\n",
    "\n",
    "# Write out a GreatlakesOutputs.txt file:\n",
    "with open('GreatlakesOutputs.txt','w') as f:\n",
    "    f.write('\\n'.join(session_result_paths + global_computation_result_paths))\n",
    "    # f.write('\\n'.join())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad98850-4eb5-4623-91e3-c84f3cc75632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=False, good_only=True)\n",
    "# good_only_batch_progress_df\n",
    "\n",
    "[v.get('outputs', None) for v in list(global_batch_run.session_batch_outputs.values()) if v is not None]\n",
    "# v = list(global_batch_run.session_batch_outputs.values())[0]\n",
    "# v.get('outputs', None)\n",
    "  \n",
    "\n",
    "# [{'local': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-07_11-26-53/loadedSessPickle.pkl'),\n",
    "#   'global': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-07_11-26-53/output/global_computation_results.pkl')},\n",
    "#  {'local': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl'),\n",
    "#   'global': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl')},\n",
    "#  ...\n",
    "# ]\n",
    "    \n",
    "\n",
    "\n",
    "# outputs': {'local': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle.pkl'),\n",
    "#    'global': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results.pkl')}}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32781c8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Single Session testing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_out = global_batch_run.execute_session(session_context=curr_sess_context, force_reload=True, skip_extended_batch_computations=True, computation_functions_name_includelist =['_perform_baseline_placefield_computation'], active_session_computation_configs=None) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "_test_out\n",
    "\n",
    "# global_batch_run.execute_session(session_context=curr_sess_context, force_reload=True, skip_extended_batch_computations=True, **{'computation_functions_name_includelist': ['_perform_baseline_placefield_computation'], 'active_session_computation_configs': None}) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 23.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf2bb67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "full_good_dirs = [k for k, v in global_batch_run.session_batch_errors.items() if v is None]\n",
    "bad_dirs = [k for k, v in global_batch_run.session_batch_errors.items() if v is not None]\n",
    "full_good_dirs\n",
    "bad_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f73f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_batch_run.session_batch_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcad70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_run.session_batch_status\n",
    "global_batch_run.session_batch_errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15faf2bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get good sessions for use in the specific session processing notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed516134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf02efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get the list of sessions that are completely ready to process:\n",
    "full_good_ready_to_process_sessions = list(good_only_batch_progress_df['context'].to_numpy())\n",
    "full_good_ready_to_process_sessions\n",
    "# Get good sessions for use in the specific session processing notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ad809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run[\"good_sessions_list\"].extend(full_good_ready_to_process_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636e3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.stop()\n",
    "project.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf1322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\",\\n\".join([ctx.get_initialization_code_string() for ctx in full_good_ready_to_process_sessions])) # List definitions\n",
    "\n",
    "# [IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "# IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a4bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\ncurr_context = \".join([ctx.get_initialization_code_string() for ctx in full_good_ready_to_process_sessions])) # Line definitions\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5689d1d-6400-4f87-be0e-a184a1d5bee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82aedf-b024-4f07-b1a9-350730b4db8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "save_time = datetime.now()\n",
    " \n",
    "print(\"save_time =\", save_time)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = save_time.strftime(\"%Y-%m-%d_%I-%M%p\")\n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7bc6bd-5b34-41d0-b906-b0ad9927b08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get output file paths:\n",
    "completed_pipeline_filename = 'loadedSessPickle.pkl'\n",
    "completed_global_computations_filename = 'outputs/global_computation_results.pkl'\n",
    "\n",
    "full_good_ready_to_process_session_paths = list(good_only_batch_progress_df['basedirs'].to_numpy())\n",
    "session_paths_output_folders = [sess_path.joinpath('outputs').resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "\n",
    "\n",
    "\n",
    "completed_pipeline_file_paths = [sess_path.joinpath(completed_pipeline_filename).resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "completed_global_computations_file_paths = [sess_path.joinpath(completed_global_computations_filename).resolve() for sess_path in full_good_ready_to_process_session_paths]\n",
    "completed_global_computations_file_paths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
