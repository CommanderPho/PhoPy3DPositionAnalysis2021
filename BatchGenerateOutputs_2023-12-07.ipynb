{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from typing import List, Dict, Optional, Union, Callable\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables as tb\n",
    "from copy import deepcopy\n",
    "from datetime import datetime, timedelta\n",
    "from attrs import define, field, Factory\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import CapturedException\n",
    "\n",
    "# Jupyter interactivity:\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.gui.Jupyter.JupyterButtonRowWidget import JupyterButtonRowWidget\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core import Epoch\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "import pyphoplacecellanalysis.General.Batch.runBatch\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun, BatchResultDataframeAccessor, run_diba_batch, BatchComputationProcessOptions, BatchSessionCompletionHandler, SavingOptions\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import SessionBatchProgress\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults, AcrossSessionTables, AcrossSessionsVisualizations\n",
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "\n",
    "from pyphocorehelpers.print_helpers import CapturedException\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult, BatchSessionCompletionHandler\n",
    "\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_file_metadata\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file, save_copydict_to_text_file, read_copydict_from_text_file, invert_filedict\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import get_file_str_if_file_exists\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import check_output_h5_files, copy_files_in_filelist_to_dest\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import ConcreteSessionFolder, BackupMethods\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots, BatchPhoJonathanFiguresHelper\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "\n",
    "from neuropy.core.neuron_identities import NeuronIdentityDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import build_merged_neuron_firing_rate_indicies\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsHelpers\n",
    "\n",
    "# BATCH_DATE_TO_USE = '2023-10-20' # used for filenames throught the notebook\n",
    "# BATCH_DATE_TO_USE = '2023-10-18_Apogee' # used for filenames throught the notebook\n",
    "BATCH_DATE_TO_USE = '2023-12-07_GL' # used for filenames throught the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5938c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "active_global_batch_result_filename=f'global_batch_result_{BATCH_DATE_TO_USE}.pkl'\n",
    "\n",
    "debug_print = False\n",
    "known_global_data_root_parent_paths = [Path(r'/media/MAX/Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/Volumes/MoverNew/data')] # , Path(r'/home/halechr/FastData'), Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'/home/halechr/turbo/Data'), Path(r'W:\\Data')\n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "## Build Pickle Path:\n",
    "global_batch_result_file_path = Path(global_data_root_parent_path).joinpath(active_global_batch_result_filename).resolve() # Use Default\n",
    "\n",
    "# try to load an existing batch result:\n",
    "global_batch_run = BatchRun.try_init_from_file(global_data_root_parent_path, active_global_batch_result_filename=active_global_batch_result_filename,\n",
    "\t\t\t\t\t\tskip_root_path_conversion=False, debug_print=debug_print) # on_needs_create_callback_fn=run_diba_batch\n",
    "\n",
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "batch_progress_df.batch_results.build_all_columns()\n",
    "good_only_batch_progress_df.batch_results.build_all_columns()\n",
    "batch_progress_df\n",
    "with pd.option_context('display.max_rows', 10, 'display.max_columns', None):  # more options can be specified also\n",
    "    # display(batch_progress_df)\n",
    "    # display(good_only_batch_progress_df)\n",
    "    display(batch_progress_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab824348",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Batch Executions/Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019afbbd-70d2-4e75-9548-b6f22d2e31ca",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hardcoded included_session_contexts:\n",
    "included_session_contexts = [\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'), # prev completed\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'), # prev completed\n",
    "]\n",
    "\n",
    "good_session_concrete_folders = ConcreteSessionFolder.build_concrete_session_folders(global_data_root_parent_path, included_session_contexts)\n",
    "good_session_concrete_folders\n",
    "\n",
    "# from pyphoplacecellanalysis.General.Batch.pythonScriptTemplating import generate_batch_single_session_scripts\n",
    "\n",
    "# ## Build Slurm Scripts:\n",
    "# session_basedirs_dict: Dict[IdentifyingContext, Path] = {a_session_folder.context:a_session_folder.path for a_session_folder in good_session_concrete_folders}\n",
    "# included_session_contexts, output_python_scripts, output_slurm_scripts = generate_batch_single_session_scripts(global_data_root_parent_path, session_batch_basedirs=session_basedirs_dict, included_session_contexts=included_session_contexts, output_directory=Path('output/generated_slurm_scripts/').resolve(), use_separate_run_directories=True, should_perform_figure_generation_to_file=True)\n",
    "# display(output_python_scripts)\n",
    "\n",
    "included_session_batch_progress_df = batch_progress_df[np.isin(batch_progress_df['context'].values, included_session_contexts)]\n",
    "with pd.option_context('display.max_rows', 10, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(included_session_batch_progress_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71584edc",
   "metadata": {},
   "source": [
    "# Execute Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ae279",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.8910155507790067\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:420: UserWarning: n_contours is 0 for level: 0.4950086393216704\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-17:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/queues.py\", line 366, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/SpecificComputationValidation.py\", line 71, in _perform_try_computation_if_needed\n",
      "    comp_specifier.validate_computation_test(curr_active_pipeline, computation_filter_name=computation_filter_name)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/SpecificComputationValidation.py\", line 71, in _perform_try_computation_if_needed\n",
      "    comp_specifier.validate_computation_test(curr_active_pipeline, computation_filter_name=computation_filter_name)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/SpecificComputationValidation.py\", line 71, in _perform_try_computation_if_needed\n",
      "    comp_specifier.validate_computation_test(curr_active_pipeline, computation_filter_name=computation_filter_name)\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py\", line 356, in <lambda>\n",
      "    validate_computation_test=lambda curr_active_pipeline, computation_filter_name='maze': (curr_active_pipeline.computation_results[computation_filter_name].computed_data['RatemapPeaksAnalysis'], curr_active_pipeline.computation_results[computation_filter_name].computed_data['RatemapPeaksAnalysis']['PeakProminence2D']), is_global=False)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py\", line 356, in <lambda>\n",
      "    validate_computation_test=lambda curr_active_pipeline, computation_filter_name='maze': (curr_active_pipeline.computation_results[computation_filter_name].computed_data['RatemapPeaksAnalysis'], curr_active_pipeline.computation_results[computation_filter_name].computed_data['RatemapPeaksAnalysis']['PeakProminence2D']), is_global=False)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py\", line 356, in <lambda>\n",
      "    validate_computation_test=lambda curr_active_pipeline, computation_filter_name='maze': (curr_active_pipeline.computation_results[computation_filter_name].computed_data['RatemapPeaksAnalysis'], curr_active_pipeline.computation_results[computation_filter_name].computed_data['RatemapPeaksAnalysis']['PeakProminence2D']), is_global=False)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/SpecificComputationValidation.py\", line 71, in _perform_try_computation_if_needed\n",
      "    comp_specifier.validate_computation_test(curr_active_pipeline, computation_filter_name=computation_filter_name)\n",
      "  File \"/home/halechr/repos/pyPhoCoreHelpers/src/pyphocorehelpers/DataStructure/dynamic_parameters.py\", line 33, in __getitem__\n",
      "    return self._mapping[key] #@IgnoreException\n",
      "KeyError: 'RatemapPeaksAnalysis'\n",
      "  File \"/home/halechr/repos/pyPhoCoreHelpers/src/pyphocorehelpers/DataStructure/dynamic_parameters.py\", line 33, in __getitem__\n",
      "    return self._mapping[key] #@IgnoreException\n",
      "  File \"/home/halechr/repos/pyPhoCoreHelpers/src/pyphocorehelpers/DataStructure/dynamic_parameters.py\", line 33, in __getitem__\n",
      "    return self._mapping[key] #@IgnoreException\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py\", line 356, in <lambda>\n",
      "    validate_computation_test=lambda curr_active_pipeline, computation_filter_name='maze': (curr_active_pipeline.computation_results[computation_filter_name].computed_data['RatemapPeaksAnalysis'], curr_active_pipeline.computation_results[computation_filter_name].computed_data['RatemapPeaksAnalysis']['PeakProminence2D']), is_global=False)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "KeyError: 'RatemapPeaksAnalysis'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/runBatch.py\", line 1176, in run_specific_batch\n",
      "    post_run_callback_fn_output = post_run_callback_fn(global_data_root_parent_path, curr_session_context, curr_session_basedir, curr_active_pipeline)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/BatchJobCompletion/BatchCompletionHandler.py\", line 580, in on_complete_success_execution_session\n",
      "    newly_computed_values = self.try_compute_global_computations_if_needed(curr_active_pipeline, curr_session_context=curr_session_context)\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/BatchJobCompletion/BatchCompletionHandler.py\", line 427, in try_compute_global_computations_if_needed\n",
      "    newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=self.extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=self.force_global_recompute, debug_print=False)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/runBatch.py\", line 1176, in run_specific_batch\n",
      "    post_run_callback_fn_output = post_run_callback_fn(global_data_root_parent_path, curr_session_context, curr_session_basedir, curr_active_pipeline)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/NonInteractiveProcessing.py\", line 343, in batch_extended_computations\n",
      "    newly_computed_values += _comp_specifier.try_computation_if_needed(curr_active_pipeline, computation_filter_name=a_computation_filter_name, on_already_computed_fn=_subfn_on_already_computed, fail_on_exception=fail_on_exception, progress_print=progress_print, debug_print=debug_print, force_recompute=force_recompute)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/BatchJobCompletion/BatchCompletionHandler.py\", line 580, in on_complete_success_execution_session\n",
      "    newly_computed_values = self.try_compute_global_computations_if_needed(curr_active_pipeline, curr_session_context=curr_session_context)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/SpecificComputationValidation.py\", line 71, in _perform_try_computation_if_needed\n",
      "    comp_specifier.validate_computation_test(curr_active_pipeline, computation_filter_name=computation_filter_name)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/BatchJobCompletion/BatchCompletionHandler.py\", line 427, in try_compute_global_computations_if_needed\n",
      "    newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=self.extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=self.force_global_recompute, debug_print=False)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/NonInteractiveProcessing.py\", line 343, in batch_extended_computations\n",
      "    newly_computed_values += _comp_specifier.try_computation_if_needed(curr_active_pipeline, computation_filter_name=a_computation_filter_name, on_already_computed_fn=_subfn_on_already_computed, fail_on_exception=fail_on_exception, progress_print=progress_print, debug_print=debug_print, force_recompute=force_recompute)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/SpecificComputationValidation.py\", line 55, in try_computation_if_needed\n",
      "    return self._perform_try_computation_if_needed(self, curr_active_pipeline, **kwargs)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py\", line 356, in <lambda>\n",
      "    validate_computation_test=lambda curr_active_pipeline, computation_filter_name='maze': (curr_active_pipeline.computation_results[computation_filter_name].computed_data['RatemapPeaksAnalysis'], curr_active_pipeline.computation_results[computation_filter_name].computed_data['RatemapPeaksAnalysis']['PeakProminence2D']), is_global=False)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/SpecificComputationValidation.py\", line 85, in _perform_try_computation_if_needed\n",
      "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=[comp_specifier.computation_fn_name], computation_kwargs_list=[comp_specifier.computation_fn_kwargs], fail_on_exception=True, debug_print=False) # fail_on_exception MUST be True or error handling is all messed up\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 1074, in perform_specific_computation\n",
      "    return self.stage.perform_specific_computation(active_computation_params=active_computation_params, enabled_filter_names=enabled_filter_names, computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=computation_kwargs_list, fail_on_exception=fail_on_exception, debug_print=debug_print)\n",
      "  File \"/home/halechr/repos/pyPhoCoreHelpers/src/pyphocorehelpers/DataStructure/dynamic_parameters.py\", line 33, in __getitem__\n",
      "    return self._mapping[key] #@IgnoreException\n",
      "KeyError: 'RatemapPeaksAnalysis'\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 681, in perform_specific_computation\n",
      "    self.computation_results[a_select_config_name] = self.run_specific_computations_single_context(previous_computation_result, computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=computation_kwargs_list, are_global=False, fail_on_exception=fail_on_exception, debug_print=debug_print)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 330, in run_specific_computations_single_context\n",
      "    return ComputedPipelineStage._execute_computation_functions(active_computation_functions, previous_computation_result=previous_computation_result, computation_kwargs_list=computation_kwargs_list, fail_on_exception=fail_on_exception, progress_logger_callback=progress_logger_callback, are_global=are_global, debug_print=debug_print)\n",
      "KeyError: 'RatemapPeaksAnalysis'\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/SpecificComputationValidation.py\", line 55, in try_computation_if_needed\n",
      "    return self._perform_try_computation_if_needed(self, curr_active_pipeline, **kwargs)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/home/halechr/repos/pyPhoCoreHelpers/src/pyphocorehelpers/DataStructure/dynamic_parameters.py\", line 33, in __getitem__\n",
      "    return self._mapping[key] #@IgnoreException\n",
      "Exception in thread Exception in threading.excepthook:\n",
      "Exception ignored in thread started by: <bound method Thread._bootstrap of <Thread(Thread-7, stopped daemon 22481483491072)>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/threading.py\", line 975, in _bootstrap_inner\n",
      "    self._invoke_excepthook(self)\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/threading.py\", line 1257, in invoke_excepthook\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/SpecificComputationValidation.py\", line 85, in _perform_try_computation_if_needed\n",
      "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=[comp_specifier.computation_fn_name], computation_kwargs_list=[comp_specifier.computation_fn_kwargs], fail_on_exception=True, debug_print=False) # fail_on_exception MUST be True or error handling is all messed up\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 771, in _execute_computation_functions\n",
      "    previous_computation_result = f(previous_computation_result, **computation_kwargs_list[i])\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 1074, in perform_specific_computation\n",
      "    return self.stage.perform_specific_computation(active_computation_params=active_computation_params, enabled_filter_names=enabled_filter_names, computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=computation_kwargs_list, fail_on_exception=fail_on_exception, debug_print=debug_print)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py\", line 697, in _perform_pf_find_ratemap_peaks_peak_prominence2d_computation\n",
      "    _, _, slab, cell_peaks_dict, id_map, prominence_map, parent_map = compute_prominence_contours(xbin_centers=active_pf_2D.xbin_centers, ybin_centers=active_pf_2D.ybin_centers, slab=slab, step=step, min_area=None, min_depth=0.2, include_edge=True, verbose=False)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 681, in perform_specific_computation\n",
      "    self.computation_results[a_select_config_name] = self.run_specific_computations_single_context(previous_computation_result, computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=computation_kwargs_list, are_global=False, fail_on_exception=fail_on_exception, debug_print=debug_print)\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "      File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "KeyError: 'RatemapPeaksAnalysis'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 330, in run_specific_computations_single_context\n",
      "    return ComputedPipelineStage._execute_computation_functions(active_computation_functions, previous_computation_result=previous_computation_result, computation_kwargs_list=computation_kwargs_list, fail_on_exception=fail_on_exception, progress_logger_callback=progress_logger_callback, are_global=are_global, debug_print=debug_print)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/External/peak_prominence2d.py\", line 515, in compute_prominence_contours\n",
      "    peaks_dict, id_map, prominence_map, parent_map = getProminence(slab, step, ybin_centers=ybin_centers, xbin_centers=xbin_centers, min_area=min_area, min_depth=min_depth, include_edge=include_edge, verbose=verbose, **kwargs)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/External/peak_prominence2d.py\", line 283, in getProminence\n",
      "    ax.cla()\n",
      "Traceback (most recent call last):\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/runBatch.py\", line 1176, in run_specific_batch\n",
      "    post_run_callback_fn_output = post_run_callback_fn(global_data_root_parent_path, curr_session_context, curr_session_basedir, curr_active_pipeline)\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/runBatch.py\", line 1176, in run_specific_batch\n",
      "    post_run_callback_fn_output = post_run_callback_fn(global_data_root_parent_path, curr_session_context, curr_session_basedir, curr_active_pipeline)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/BatchJobCompletion/BatchCompletionHandler.py\", line 580, in on_complete_success_execution_session\n",
      "    newly_computed_values = self.try_compute_global_computations_if_needed(curr_active_pipeline, curr_session_context=curr_session_context)\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/BatchJobCompletion/BatchCompletionHandler.py\", line 427, in try_compute_global_computations_if_needed\n",
      "    newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=self.extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=self.force_global_recompute, debug_print=False)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/BatchJobCompletion/BatchCompletionHandler.py\", line 580, in on_complete_success_execution_session\n",
      "    newly_computed_values = self.try_compute_global_computations_if_needed(curr_active_pipeline, curr_session_context=curr_session_context)\n",
      "  File \"/sw/pkgs/arc/python/3.9.12/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/NonInteractiveProcessing.py\", line 343, in batch_extended_computations\n",
      "    newly_computed_values += _comp_specifier.try_computation_if_needed(curr_active_pipeline, computation_filter_name=a_computation_filter_name, on_already_computed_fn=_subfn_on_already_computed, fail_on_exception=fail_on_exception, progress_print=progress_print, debug_print=debug_print, force_recompute=force_recompute)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/BatchJobCompletion/BatchCompletionHandler.py\", line 427, in try_compute_global_computations_if_needed\n",
      "    newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=self.extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=self.force_global_recompute, debug_print=False)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/runBatch.py\", line 1176, in run_specific_batch\n",
      "    post_run_callback_fn_output = post_run_callback_fn(global_data_root_parent_path, curr_session_context, curr_session_basedir, curr_active_pipeline)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/SpecificComputationValidation.py\", line 55, in try_computation_if_needed\n",
      "    return self._perform_try_computation_if_needed(self, curr_active_pipeline, **kwargs)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/NonInteractiveProcessing.py\", line 343, in batch_extended_computations\n",
      "    newly_computed_values += _comp_specifier.try_computation_if_needed(curr_active_pipeline, computation_filter_name=a_computation_filter_name, on_already_computed_fn=_subfn_on_already_computed, fail_on_exception=fail_on_exception, progress_print=progress_print, debug_print=debug_print, force_recompute=force_recompute)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/BatchJobCompletion/BatchCompletionHandler.py\", line 580, in on_complete_success_execution_session\n",
      "    newly_computed_values = self.try_compute_global_computations_if_needed(curr_active_pipeline, curr_session_context=curr_session_context)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/SpecificComputationValidation.py\", line 85, in _perform_try_computation_if_needed\n",
      "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=[comp_specifier.computation_fn_name], computation_kwargs_list=[comp_specifier.computation_fn_kwargs], fail_on_exception=True, debug_print=False) # fail_on_exception MUST be True or error handling is all messed up\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/SpecificComputationValidation.py\", line 55, in try_computation_if_needed\n",
      "    return self._perform_try_computation_if_needed(self, curr_active_pipeline, **kwargs)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/BatchJobCompletion/BatchCompletionHandler.py\", line 427, in try_compute_global_computations_if_needed\n",
      "    newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=self.extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=self.force_global_recompute, debug_print=False)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 1074, in perform_specific_computation\n",
      "    return self.stage.perform_specific_computation(active_computation_params=active_computation_params, enabled_filter_names=enabled_filter_names, computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=computation_kwargs_list, fail_on_exception=fail_on_exception, debug_print=debug_print)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/SpecificComputationValidation.py\", line 85, in _perform_try_computation_if_needed\n",
      "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=[comp_specifier.computation_fn_name], computation_kwargs_list=[comp_specifier.computation_fn_kwargs], fail_on_exception=True, debug_print=False) # fail_on_exception MUST be True or error handling is all messed up\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 681, in perform_specific_computation\n",
      "    self.computation_results[a_select_config_name] = self.run_specific_computations_single_context(previous_computation_result, computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=computation_kwargs_list, are_global=False, fail_on_exception=fail_on_exception, debug_print=debug_print)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/NonInteractiveProcessing.py\", line 343, in batch_extended_computations\n",
      "    newly_computed_values += _comp_specifier.try_computation_if_needed(curr_active_pipeline, computation_filter_name=a_computation_filter_name, on_already_computed_fn=_subfn_on_already_computed, fail_on_exception=fail_on_exception, progress_print=progress_print, debug_print=debug_print, force_recompute=force_recompute)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 1074, in perform_specific_computation\n",
      "    return self.stage.perform_specific_computation(active_computation_params=active_computation_params, enabled_filter_names=enabled_filter_names, computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=computation_kwargs_list, fail_on_exception=fail_on_exception, debug_print=debug_print)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 330, in run_specific_computations_single_context\n",
      "    return ComputedPipelineStage._execute_computation_functions(active_computation_functions, previous_computation_result=previous_computation_result, computation_kwargs_list=computation_kwargs_list, fail_on_exception=fail_on_exception, progress_logger_callback=progress_logger_callback, are_global=are_global, debug_print=debug_print)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/SpecificComputationValidation.py\", line 55, in try_computation_if_needed\n",
      "    return self._perform_try_computation_if_needed(self, curr_active_pipeline, **kwargs)\n",
      "      File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 681, in perform_specific_computation\n",
      "    self.computation_results[a_select_config_name] = self.run_specific_computations_single_context(previous_computation_result, computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=computation_kwargs_list, are_global=False, fail_on_exception=fail_on_exception, debug_print=debug_print)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/SpecificComputationValidation.py\", line 85, in _perform_try_computation_if_needed\n",
      "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=[comp_specifier.computation_fn_name], computation_kwargs_list=[comp_specifier.computation_fn_kwargs], fail_on_exception=True, debug_print=False) # fail_on_exception MUST be True or error handling is all messed up\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 771, in _execute_computation_functions\n",
      "    previous_computation_result = f(previous_computation_result, **computation_kwargs_list[i])\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 330, in run_specific_computations_single_context\n",
      "    return ComputedPipelineStage._execute_computation_functions(active_computation_functions, previous_computation_result=previous_computation_result, computation_kwargs_list=computation_kwargs_list, fail_on_exception=fail_on_exception, progress_logger_callback=progress_logger_callback, are_global=are_global, debug_print=debug_print)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 1074, in perform_specific_computation\n",
      "    return self.stage.perform_specific_computation(active_computation_params=active_computation_params, enabled_filter_names=enabled_filter_names, computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=computation_kwargs_list, fail_on_exception=fail_on_exception, debug_print=debug_print)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py\", line 697, in _perform_pf_find_ratemap_peaks_peak_prominence2d_computation\n",
      "    _, _, slab, cell_peaks_dict, id_map, prominence_map, parent_map = compute_prominence_contours(xbin_centers=active_pf_2D.xbin_centers, ybin_centers=active_pf_2D.ybin_centers, slab=slab, step=step, min_area=None, min_depth=0.2, include_edge=True, verbose=False)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 771, in _execute_computation_functions\n",
      "    previous_computation_result = f(previous_computation_result, **computation_kwargs_list[i])\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 681, in perform_specific_computation\n",
      "    self.computation_results[a_select_config_name] = self.run_specific_computations_single_context(previous_computation_result, computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=computation_kwargs_list, are_global=False, fail_on_exception=fail_on_exception, debug_print=debug_print)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/External/peak_prominence2d.py\", line 515, in compute_prominence_contours\n",
      "    peaks_dict, id_map, prominence_map, parent_map = getProminence(slab, step, ybin_centers=ybin_centers, xbin_centers=xbin_centers, min_area=min_area, min_depth=min_depth, include_edge=include_edge, verbose=verbose, **kwargs)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py\", line 697, in _perform_pf_find_ratemap_peaks_peak_prominence2d_computation\n",
      "    _, _, slab, cell_peaks_dict, id_map, prominence_map, parent_map = compute_prominence_contours(xbin_centers=active_pf_2D.xbin_centers, ybin_centers=active_pf_2D.ybin_centers, slab=slab, step=step, min_area=None, min_depth=0.2, include_edge=True, verbose=False)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/External/peak_prominence2d.py\", line 283, in getProminence\n",
      "    ax.cla()\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/External/peak_prominence2d.py\", line 515, in compute_prominence_contours\n",
      "    peaks_dict, id_map, prominence_map, parent_map = getProminence(slab, step, ybin_centers=ybin_centers, xbin_centers=xbin_centers, min_area=min_area, min_depth=min_depth, include_edge=include_edge, verbose=verbose, **kwargs)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 330, in run_specific_computations_single_context\n",
      "    return ComputedPipelineStage._execute_computation_functions(active_computation_functions, previous_computation_result=previous_computation_result, computation_kwargs_list=computation_kwargs_list, fail_on_exception=fail_on_exception, progress_logger_callback=progress_logger_callback, are_global=are_global, debug_print=debug_print)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 771, in _execute_computation_functions\n",
      "    previous_computation_result = f(previous_computation_result, **computation_kwargs_list[i])\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/External/peak_prominence2d.py\", line 283, in getProminence\n",
      "    ax.cla()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py\", line 1397, in cla\n",
      "    self.clear()\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/Computation.py\", line 771, in _execute_computation_functions\n",
      "    previous_computation_result = f(previous_computation_result, **computation_kwargs_list[i])\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py\", line 1397, in cla\n",
      "    self.clear()\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py\", line 697, in _perform_pf_find_ratemap_peaks_peak_prominence2d_computation\n",
      "    _, _, slab, cell_peaks_dict, id_map, prominence_map, parent_map = compute_prominence_contours(xbin_centers=active_pf_2D.xbin_centers, ybin_centers=active_pf_2D.ybin_centers, slab=slab, step=step, min_area=None, min_depth=0.2, include_edge=True, verbose=False)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py\", line 1388, in clear\n",
      "    self.__clear()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py\", line 1388, in clear\n",
      "    self.__clear()\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py\", line 697, in _perform_pf_find_ratemap_peaks_peak_prominence2d_computation\n",
      "    _, _, slab, cell_peaks_dict, id_map, prominence_map, parent_map = compute_prominence_contours(xbin_centers=active_pf_2D.xbin_centers, ybin_centers=active_pf_2D.ybin_centers, slab=slab, step=step, min_area=None, min_depth=0.2, include_edge=True, verbose=False)\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/External/peak_prominence2d.py\", line 515, in compute_prominence_contours\n",
      "    peaks_dict, id_map, prominence_map, parent_map = getProminence(slab, step, ybin_centers=ybin_centers, xbin_centers=xbin_centers, min_area=min_area, min_depth=min_depth, include_edge=include_edge, verbose=verbose, **kwargs)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py\", line 1271, in __clear\n",
      "    axis.clear()  # Also resets the scale to linear.\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py\", line 1271, in __clear\n",
      "    axis.clear()  # Also resets the scale to linear.\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/External/peak_prominence2d.py\", line 283, in getProminence\n",
      "    ax.cla()\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/External/peak_prominence2d.py\", line 515, in compute_prominence_contours\n",
      "    peaks_dict, id_map, prominence_map, parent_map = getProminence(slab, step, ybin_centers=ybin_centers, xbin_centers=xbin_centers, min_area=min_area, min_depth=min_depth, include_edge=include_edge, verbose=verbose, **kwargs)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 918, in clear\n",
      "    self.reset_ticks()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 918, in clear\n",
      "    self.reset_ticks()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py\", line 1397, in cla\n",
      "    self.clear()\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/External/peak_prominence2d.py\", line 281, in getProminence\n",
      "    csii=ax.contourf(xbin_centers,ybin_centers,var,[levii,vmax+step]) ## Heavy-lifting code here. levii is the level\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 940, in reset_ticks\n",
      "    self.set_clip_path(self.axes.patch)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 940, in reset_ticks\n",
      "    self.set_clip_path(self.axes.patch)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/__init__.py\", line 1465, in inner\n",
      "    return func(ax, *map(sanitize_sequence, args), **kwargs)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/_api/deprecation.py\", line 297, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py\", line 1388, in clear\n",
      "    self.__clear()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/_api/deprecation.py\", line 297, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_axes.py\", line 6533, in contourf\n",
      "    contours = mcontour.QuadContourSet(self, *args, **kwargs)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py\", line 1271, in __clear\n",
      "    axis.clear()  # Also resets the scale to linear.\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 1110, in set_clip_path\n",
      "    super().set_clip_path(path, transform)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 1111, in set_clip_path\n",
      "    for child in self.majorTicks + self.minorTicks:\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 918, in clear\n",
      "    self.reset_ticks()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/contour.py\", line 940, in __init__\n",
      "    self.changed()  # set the colors\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 586, in __get__\n",
      "    tick = instance._get_tick(major=True)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/artist.py\", line 821, in set_clip_path\n",
      "    elif isinstance(path, TransformedPath):\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 940, in reset_ticks\n",
      "    self.set_clip_path(self.axes.patch)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/contour.py\", line 1164, in changed\n",
      "    self.set_array(self.cvalues)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 1562, in _get_tick\n",
      "    return self._tick_class(self.axes, 0, major=major, **tick_kw)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/_api/deprecation.py\", line 297, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 417, in __init__\n",
      "    data=([0], [0]), transform=ax.get_xaxis_transform(\"tick1\"))\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/cm.py\", line 533, in set_array\n",
      "    A = cbook.safe_masked_invalid(A, copy=True)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 1111, in set_clip_path\n",
      "    for child in self.majorTicks + self.minorTicks:\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py\", line 930, in get_xaxis_transform\n",
      "    return self.spines.bottom.get_spine_transform()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 586, in __get__\n",
      "    tick = instance._get_tick(major=True)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/cbook.py\", line 740, in safe_masked_invalid\n",
      "    xm = np.ma.masked_where(~(np.isfinite(x)), x, copy=False)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/spines.py\", line 341, in get_spine_transform\n",
      "    self._ensure_position_is_set()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/numpy/ma/core.py\", line 1933, in masked_where\n",
      "    result = a.view(cls)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 1562, in _get_tick\n",
      "    return self._tick_class(self.axes, 0, major=major, **tick_kw)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/spines.py\", line 206, in _ensure_position_is_set\n",
      "    self.set_position(self._position)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/numpy/ma/core.py\", line 2978, in __array_finalize__\n",
      "    self._update_from(obj)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/spines.py\", line 331, in set_position\n",
      "    self.axis.reset_ticks()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 417, in __init__\n",
      "    data=([0], [0]), transform=ax.get_xaxis_transform(\"tick1\"))\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/numpy/ma/core.py\", line 2965, in _update_from\n",
      "    _baseclass=getattr(obj, '_baseclass', _baseclass),\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py\", line 930, in get_xaxis_transform\n",
      "    return self.spines.bottom.get_spine_transform()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 940, in reset_ticks\n",
      "    self.set_clip_path(self.axes.patch)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/_api/deprecation.py\", line 297, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 1111, in set_clip_path\n",
      "    for child in self.majorTicks + self.minorTicks:\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 586, in __get__\n",
      "    tick = instance._get_tick(major=True)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 1562, in _get_tick\n",
      "    return self._tick_class(self.axes, 0, major=major, **tick_kw)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py\", line 1397, in cla\n",
      "    self.clear()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 413, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/spines.py\", line 341, in get_spine_transform\n",
      "    self._ensure_position_is_set()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/spines.py\", line 206, in _ensure_position_is_set\n",
      "    self.set_position(self._position)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/spines.py\", line 331, in set_position\n",
      "    self.axis.reset_ticks()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py\", line 1388, in clear\n",
      "    self.__clear()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 940, in reset_ticks\n",
      "    self.set_clip_path(self.axes.patch)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/_api/deprecation.py\", line 297, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 1111, in set_clip_path\n",
      "    for child in self.majorTicks + self.minorTicks:\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 187, in __init__\n",
      "    self._apply_tickdir(tickdir)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 586, in __get__\n",
      "    tick = instance._get_tick(major=True)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py\", line 933, in get_xaxis_transform\n",
      "    return self.spines.top.get_spine_transform()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 1562, in _get_tick\n",
      "    return self._tick_class(self.axes, 0, major=major, **tick_kw)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 445, in _apply_tickdir\n",
      "    self.tick2line.set_marker(mark2)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 419, in __init__\n",
      "    data=([0], [1]), transform=ax.get_xaxis_transform(\"tick2\"))\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/lines.py\", line 1194, in set_marker\n",
      "    self._marker = MarkerStyle(marker, self._marker.get_fillstyle())\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/markers.py\", line 255, in __init__\n",
      "    self._set_marker(marker)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/spines.py\", line 341, in get_spine_transform\n",
      "    self._ensure_position_is_set()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/markers.py\", line 319, in _set_marker\n",
      "    if isinstance(marker, str) and cbook.is_math_text(marker):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/spines.py\", line 206, in _ensure_position_is_set\n",
      "    self.set_position(self._position)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py\", line 1271, in __clear\n",
      "    axis.clear()  # Also resets the scale to linear.\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/spines.py\", line 331, in set_position\n",
      "    self.axis.reset_ticks()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/_api/deprecation.py\", line 297, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 918, in clear\n",
      "    self.reset_ticks()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 940, in reset_ticks\n",
      "    self.set_clip_path(self.axes.patch)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 1112, in set_clip_path\n",
      "    child.set_clip_path(path, transform)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/_api/deprecation.py\", line 297, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/axis.py\", line 240, in set_clip_path\n",
      "    super().set_clip_path(path, transform)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/artist.py\", line 803, in set_clip_path\n",
      "    path.get_transform())\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/patches.py\", line 261, in get_transform\n",
      "    return self.get_patch_transform() + artist.Artist.get_transform(self)\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/patches.py\", line 751, in get_patch_transform\n",
      "    bbox = self.get_bbox()\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/patches.py\", line 882, in get_bbox\n",
      "    return transforms.Bbox.from_extents(*self._convert_units())\n",
      "  File \"/home/halechr/repos/Spike3D/.venv/lib/python3.9/site-packages/matplotlib/patches.py\", line 742, in _convert_units\n",
      "    x1 = self.convert_xunits(self._x0 + self._width)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# %pdb on\n",
    "\n",
    "# multiprocessing_kwargs = dict(use_multiprocessing=False, num_processes=1)\n",
    "multiprocessing_kwargs = dict(use_multiprocessing=True, num_processes=10)\n",
    "\n",
    "# Whether to output figures:\n",
    "should_perform_figure_generation_to_file=False\n",
    "# should_perform_figure_generation_to_file=True\n",
    "\n",
    "## Included Session Contexts:\n",
    "# included_session_contexts = batch_progress_df[np.logical_and(batch_progress_df['has_user_replay_annotations'], batch_progress_df['is_ready'])]['context'].to_numpy().tolist()\n",
    "\n",
    "# Only require sessions to have replay annotations:\n",
    "# included_session_contexts = batch_progress_df[batch_progress_df['has_user_replay_annotations']]['context'].to_numpy().tolist()\n",
    "\n",
    "# included_session_contexts = batch_progress_df['context'].to_numpy().tolist()[:4] # Only get the first 6\n",
    "# Limit the contexts to run to the last N:\n",
    "# included_session_contexts = included_session_contexts[3:5]\n",
    "\n",
    "# included_session_contexts = [included_session_contexts[3]]\n",
    "\n",
    "# ALL\n",
    "included_session_contexts = included_session_contexts\n",
    "\n",
    "# ## No filtering the sessions:\n",
    "# included_session_contexts = None\n",
    "\n",
    "if included_session_contexts is not None:\n",
    "    print(f'len(included_session_contexts): {len(included_session_contexts)}')\n",
    "else:\n",
    "    print(f'included_session_contexts is None so all session contexts will be included.')\n",
    "\n",
    "# included_session_contexts\n",
    "\n",
    "# # No recomputing at all:\n",
    "# result_handler = BatchSessionCompletionHandler(force_reload_all=False,\n",
    "#                                                 session_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=False, should_save=SavingOptions.NEVER), # , override_file=\n",
    "#                                                 global_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=False, should_save=SavingOptions.NEVER),\n",
    "#                                                 should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, should_generate_all_plots=True, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_global_recompute=False,\n",
    "#                                                 **multiprocessing_kwargs)\n",
    "\n",
    "# No Reloading\n",
    "result_handler = BatchSessionCompletionHandler(force_reload_all=False,\n",
    "                                                session_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=True, should_save=SavingOptions.IF_CHANGED),\n",
    "                                                global_computations_options=BatchComputationProcessOptions(should_load=True, should_compute=True, should_save=SavingOptions.IF_CHANGED),\n",
    "                                                should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, should_generate_all_plots=True, saving_mode=PipelineSavingScheme.SKIP_SAVING, force_global_recompute=False,\n",
    "                                                **multiprocessing_kwargs)\n",
    "\n",
    "\n",
    "# # Forced Reloading:\n",
    "# result_handler = BatchSessionCompletionHandler(force_reload_all=True,\n",
    "#                                                 session_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=SavingOptions.ALWAYS),\n",
    "#                                                 global_computations_options=BatchComputationProcessOptions(should_load=False, should_compute=True, should_save=SavingOptions.ALWAYS),\n",
    "#                                                 should_perform_figure_generation_to_file=should_perform_figure_generation_to_file, saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE, force_global_recompute=True,\n",
    "#                                                 **multiprocessing_kwargs)\n",
    "\n",
    "\n",
    "active_post_run_callback_fn = result_handler.on_complete_success_execution_session\n",
    "# active_post_run_callback_fn = _temp_on_complete_success_execution_session\n",
    "\n",
    "\n",
    "def a_test_completion_function(self, global_data_root_parent_path, curr_session_context, curr_session_basedir, curr_active_pipeline, across_session_results_extended_dict: dict) -> dict:\n",
    "    # print(f'>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "    print(f'<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "    print(f'a_test_completion_function(curr_session_context: {curr_session_context}, curr_session_basedir: {str(curr_session_basedir)}, ...,across_session_results_extended_dict: {across_session_results_extended_dict})')\n",
    "    long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "\n",
    "    # 2023-11-27 - I'd like to be able to save/load single results a time, (meaning specific to their parameters):\n",
    "\n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData\n",
    "\n",
    "    # list = ['2Hz', '12Hz']\n",
    "    directional_laps_output_path = curr_active_pipeline.get_output_path().joinpath(f'DirectionalLaps_2Hz_new_{BATCH_DATE_TO_USE}.pkl').resolve()\n",
    "    saveData(directional_laps_output_path, (curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'], curr_active_pipeline.global_computation_results.computed_data['RankOrder']))\n",
    "\n",
    "    print(f'>>\\t done with {curr_session_context}')\n",
    "    print(f'>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "    print(f'>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "\n",
    "    return across_session_results_extended_dict\n",
    "\n",
    "\n",
    "result_handler.completion_functions.append(a_test_completion_function)\n",
    "\n",
    "## Specific Setup for 2023-09-28 Changes to LxC/SxC \"refinements\"\n",
    "result_handler.extended_computations_include_includelist = ['pf_computation', 'pfdt_computation', 'firing_rate_trends',\n",
    "                                                # 'pf_dt_sequential_surprise',\n",
    "                                                # 'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                # 'position_decoding_two_step',\n",
    "                                                'extended_stats',\n",
    "                                                'long_short_decoding_analyses',\n",
    "                                                'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', #, 'long_short_rate_remapping',\n",
    "                                                'long_short_inst_spike_rate_groups',\n",
    "                                                'long_short_endcap_analysis',\n",
    "                                                # 'spike_burst_detection',\n",
    "                                                'split_to_directional_laps',\n",
    "                                                'rank_order_shuffle_analysis'\n",
    "                                                ]\n",
    "\n",
    "\n",
    "basic_local_computations = ['pf_computation', 'pfdt_computation', 'firing_rate_trends',\n",
    "#                                                 'pf_dt_sequential_surprise',\n",
    "                                                # 'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                #'position_decoding_two_step', \n",
    "                                                ]\n",
    " \n",
    "\n",
    "# basic_local_computations = [] # set to empty so we don't overwrite these computations\n",
    "# result_handler.extended_computations_include_includelist = ['split_to_directional_laps', 'rank_order_shuffle_analysis'] # OVERRIDE with specific computations to do\n",
    "\n",
    "\n",
    "result_handler.enable_hdf5_output = True # output the HDF5 when done.\n",
    "# result_handler.override_existing_frs_index_values = True\n",
    "# result_handler.frs_index_inclusion_magnitude = 0.1\n",
    "\n",
    "# result_handler.enable_hdf5_output = False\n",
    "result_handler.override_existing_frs_index_values = False\n",
    "\n",
    "\n",
    "## Execute with the custom arguments.\n",
    "global_batch_run.execute_all(force_reload=result_handler.force_reload_all, saving_mode=result_handler.saving_mode, skip_extended_batch_computations=True, post_run_callback_fn=active_post_run_callback_fn,\n",
    "                             fail_on_exception=False, included_session_contexts=included_session_contexts,\n",
    "                                                                                        **{'computation_functions_name_includelist': basic_local_computations,\n",
    "                                                                                            'active_session_computation_configs': None,\n",
    "                                                                                            'allow_processing_previously_completed': True}, **multiprocessing_kwargs) # can override `active_session_computation_configs` if we want to set custom ones like only the laps.)\n",
    "\n",
    "# 4m 39.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f130e5c9",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Save to pickle:\n",
    "saveData(global_batch_result_file_path, global_batch_run) # Update the global batch run dictionary\n",
    "\n",
    "# Save to HDF5\n",
    "suffix = f'{BATCH_DATE_TO_USE}'\n",
    "## Build Pickle Path:\n",
    "file_path = global_data_root_parent_path.joinpath(f'global_batch_output_{suffix}.h5').resolve()\n",
    "global_batch_run.to_hdf(file_path,'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0981cde1",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=False) # all\n",
    "good_only_batch_progress_df = global_batch_run.to_dataframe(expand_context=True, good_only=True)\n",
    "batch_progress_df.batch_results.build_all_columns()\n",
    "good_only_batch_progress_df.batch_results.build_all_columns()\n",
    "good_only_batch_progress_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f140f",
   "metadata": {},
   "source": [
    "# Across Sessions After Batching Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dce885b-5b99-4a7a-9f72-2eed2e45ae18",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_batch_progress_df = included_session_batch_progress_df.copy()\n",
    "\n",
    "good_session_concrete_folders = [ConcreteSessionFolder(a_context, a_basedir) for a_context, a_basedir in zip(list(a_batch_progress_df.context.values), list(a_batch_progress_df.basedirs.values))]\n",
    "\n",
    "# good_only_batch_progress_df.batch_results\n",
    "# included_h5_paths = [get_file_str_if_file_exists(v.joinpath('output','pipeline_results.h5').resolve()) for v in list(good_only_batch_progress_df.basedirs.values)]\n",
    "# included_h5_paths = [a_dir.joinpath('output','pipeline_results.h5').resolve() for a_dir in included_session_batch_progress_df['basedirs']]\n",
    "included_h5_paths = [get_file_str_if_file_exists(v.pipeline_results_h5) for v in good_session_concrete_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39738fa-f8f3-46d2-a937-0fb08c0ccb43",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# target_dir = Path('output/across_session_results/2023-09-29').resolve()\n",
    "# target_dir = Path('/home/halechr/cloud/turbo/Pho/Output/across_session_results/2023-09-29').resolve()\n",
    "# target_dir = Path('/home/halechr/cloud/turbo/Pho/Output/across_session_results/2023-10-03').resolve()\n",
    "# copy_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, target_dir=target_dir)\n",
    "# copy_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, backup_mode=BackupMethods.RenameInSourceDirectory, rename_backup_suffix='2023-10-05', only_include_file_types=['local_pkl', 'global_pkl','h5'])\n",
    "copy_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, backup_mode=BackupMethods.RenameInSourceDirectory, rename_backup_suffix=BATCH_DATE_TO_USE, only_include_file_types=['local_pkl', 'global_pkl'])\n",
    "# copy_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, backup_mode=BackupMethods.RenameInSourceDirectory, rename_backup_suffix='2023-10-07', only_include_file_types=['local_pkl', 'global_pkl','h5'])\n",
    "copy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135cb2d8-65b3-405b-a41b-22b2fa7cb28e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "moved_files_dict_h5_files = copy_movedict(copy_dict)\n",
    "moved_files_dict_h5_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e3954-15a4-449c-b927-56d5d79153c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "moved_files_copydict_output_filename=f'backed_up_files_copydict_{BATCH_DATE_TO_USE}.csv'\n",
    "moved_files_copydict_file_path = Path(global_data_root_parent_path).joinpath(moved_files_copydict_output_filename).resolve() # Use Default\n",
    "print(f'moved_files_copydict_file_path: {moved_files_copydict_file_path}')\n",
    "\n",
    "_out_string, filedict_out_path = save_copydict_to_text_file(moved_files_dict_h5_files, moved_files_copydict_file_path, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab869730",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_moved_files_dict_files = read_copydict_from_text_file(moved_files_copydict_file_path, debug_print=False)\n",
    "read_moved_files_dict_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4671e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_moved_files_dict_files\n",
    "restore_moved_files_dict_files = invert_filedict(read_moved_files_dict_files)\n",
    "restore_moved_files_dict_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d067d8f2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "check_output_h5_files(included_h5_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb0953",
   "metadata": {},
   "source": [
    "## Extract `across_sessions_instantaneous_fr_dict` from the computation outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39691fe2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Somewhere in there there are `InstantaneousSpikeRateGroupsComputation` results to extract\n",
    "across_sessions_instantaneous_fr_dict = {} # InstantaneousSpikeRateGroupsComputation\n",
    "across_sessions_recomputed_instantaneous_fr_dict = {}\n",
    "\n",
    "# Get only the sessions with non-None results\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "good_session_batch_outputs = {a_ctxt:a_result for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None}\n",
    "\n",
    "for a_ctxt, a_result in good_session_batch_outputs.items():\n",
    "    if a_result is not None:\n",
    "        # a_good_result = a_result.__dict__.get('across_sessions_batch_results', {}).get('inst_fr_comps', None)\n",
    "        a_good_result = a_result.across_session_results.get('inst_fr_comps', None)\n",
    "        if a_good_result is not None:\n",
    "            across_sessions_instantaneous_fr_dict[a_ctxt] = a_good_result\n",
    "            # print(a_result['across_sessions_batch_results']['inst_fr_comps'])\n",
    "        a_good_recomp_result = a_result.across_session_results.get('recomputed_inst_fr_comps', None)\n",
    "        if a_good_recomp_result is not None:\n",
    "            across_sessions_recomputed_instantaneous_fr_dict[a_ctxt] = a_good_recomp_result\n",
    "            \n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "\n",
    "\n",
    "## Outputs: across_sessions_instantaneous_fr_dict, across_sessions_recomputed_instantaneous_fr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb9efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "across_sessions_recomputed_instantaneous_fr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09136799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When done, `result_handler.across_sessions_instantaneous_fr_dict` is now equivalent to what it would have been before. It can be saved using the normal `.save_across_sessions_data(...)`\n",
    "\n",
    "## Save the instantaneous firing rate results dict: (# Dict[IdentifyingContext] = InstantaneousSpikeRateGroupsComputation)\n",
    "# AcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_instantaneous_fr_dict, global_data_root_parent_path=global_data_root_parent_path,\n",
    "#                                                  inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl')\n",
    "\n",
    "across_session_result_long_short_recomputed_inst_firing_rate_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "\n",
    "AcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_recomputed_instantaneous_fr_dict, global_data_root_parent_path=global_data_root_parent_path,\n",
    "                                                 inst_fr_output_filename=across_session_result_long_short_recomputed_inst_firing_rate_filename)\n",
    "\n",
    "\n",
    "\n",
    "# ## Save pickle:\n",
    "# inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "# global_batch_result_inst_fr_file_path = Path(global_data_root_parent_path).joinpath(inst_fr_output_filename).resolve() # Use Default\n",
    "# print(f'global_batch_result_inst_fr_file_path: {global_batch_result_inst_fr_file_path}')\n",
    "# # Save the all sessions instantaneous firing rate dict to the path:\n",
    "# saveData(global_batch_result_inst_fr_file_path, across_sessions_instantaneous_fr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c123baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    "\n",
    "# neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_all_known_tables(included_session_contexts, included_h5_paths, should_restore_native_column_types=True, )\n",
    "\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_and_save_all_combined_tables(included_session_contexts, included_h5_paths, override_output_parent_path=global_data_root_parent_path, output_path_suffix=f'{BATCH_DATE_TO_USE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a859bff-8cdb-4281-a64f-251d24db7cb9",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    "\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_all_known_tables(included_session_contexts, included_h5_paths, should_restore_native_column_types=True)\n",
    "# neuron_replay_stats_table['is_refined_LxC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b2430-c9ec-4adb-81a8-1ffbf8a0cb3c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "long_short_fr_indicies_analysis_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95013ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_identities_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ced5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(neuron_replay_stats_table['is_refined_LxC'])\n",
    "# np.isnan(neuron_replay_stats_table['is_refined_LxC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8615ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "session_identifier_key: str = 'session_name'\n",
    "# session_identifier_key: str = 'session_datetime'\n",
    "\n",
    "## !IMPORTANT! Count of the fields of interest using .value_counts(...) and converting to an explicit pd.DataFrame:\n",
    "# _out_value_counts_df: pd.DataFrame = neuron_replay_stats_table.value_counts(subset=['format_name', 'animal', 'session_name', 'session_datetime','track_membership'], normalize=False, sort=False, ascending=True, dropna=True).reset_index()\n",
    "# _out_value_counts_df.columns = ['format_name', 'animal', 'session_name', 'session_datetime', 'track_membership', 'count']\n",
    "_out_value_counts_df: pd.DataFrame = neuron_replay_stats_table.value_counts(subset=['format_name', 'animal', 'session_name', 'session_datetime','track_membership','is_refined_LxC', 'is_refined_SxC'], normalize=False, sort=False, ascending=True, dropna=True).reset_index()\n",
    "_out_value_counts_df.columns = ['format_name', 'animal', 'session_name', 'session_datetime', 'track_membership', 'is_refined_LxC', 'is_refined_SxC', 'count']\n",
    "_out_value_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af57298",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the time of the first session for each animal:\n",
    "first_session_time  = _out_value_counts_df.groupby(['animal']).agg(session_datetime_first=('session_datetime', 'first')).reset_index()\n",
    "\n",
    "## Subtract this initial time from all of the 'session_datetime' entries for each animal:\n",
    "# Merge the first session time back into the original DataFrame\n",
    "merged_df = pd.merge(_out_value_counts_df, first_session_time, on='animal')\n",
    "\n",
    "# Subtract this initial time from all of the 'session_datetime' entries for each animal\n",
    "merged_df['time_since_first_session'] = merged_df['session_datetime'] - merged_df['session_datetime_first']\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25bb1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "point_size = 8\n",
    "df = _out_value_counts_df.copy()\n",
    "animals = df['animal'].unique()\n",
    "track_memberships = df['track_membership'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(animals), figsize=(15, 5))\n",
    "\n",
    "for i, animal in enumerate(animals):\n",
    "\tax = axes[i]\n",
    "\tsubset_df = df[df['animal'] == animal]\n",
    "\t\n",
    "\tfor track_membership in track_memberships:\n",
    "\t\ttrack_subset_df = subset_df[subset_df['track_membership'] == track_membership]\n",
    "\t\tax.plot(track_subset_df['session_datetime'], track_subset_df['count'], label=f'Track: {track_membership}')\n",
    "\t\tax.scatter(track_subset_df['session_datetime'], track_subset_df['count'], s=point_size)\n",
    "\t\t\n",
    "\tax.set_title(f'Animal: {animal}')\n",
    "\tax.set_xlabel('Session Datetime')\n",
    "\tax.set_ylabel('Count')\n",
    "\tax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94408ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_value_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784fcc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## See if the number of cells decreases over re-exposures to the track\n",
    "df = _out_value_counts_df[_out_value_counts_df['animal'] == 'gor01']\n",
    "# df = _out_value_counts_df[_out_value_counts_df['animal'] == 'pin01']\n",
    "# df = _out_value_counts_df[_out_value_counts_df['animal'] == 'vvp01']\n",
    "\n",
    "# Sort by column: 'session_datetime' (ascending)\n",
    "df = df.sort_values(['session_datetime'])\n",
    "\n",
    "'LEFT_ONLY'\n",
    "\n",
    "# df.to_clipboard(index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a502f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the number of cells in each session of the animal:\n",
    "num_LxCs = df[df['track_membership'] == 'LEFT_ONLY']['count'].to_numpy()\n",
    "num_Shared = df[df['track_membership'] == 'SHARED']['count'].to_numpy()\n",
    "num_SxCs = df[df['track_membership'] == 'RIGHT_ONLY']['count'].to_numpy()\n",
    "\n",
    "num_TotalCs = num_LxCs + num_Shared + num_SxCs\n",
    "num_TotalCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The only safe point to align each session to is the switchpoint (the delta):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046bbce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each session can be expressed in terms of time from the start of the first session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f99ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "\n",
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=num_sessions, save_figure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc1ac7-5771-4cd5-94c6-7a6244eb8217",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "source": [
    "## Extract output files from all completed sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb0cd9-3e60-4425-9351-dfc903f3f067",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphocorehelpers.Filesystem.path_helpers import convert_filelist_to_new_parent\n",
    "\n",
    "def save_filelist_to_text_file(hdf5_output_paths, filelist_path: Path):\n",
    "    _out_string = '\\n'.join([str(a_file) for a_file in hdf5_output_paths])\n",
    "    print(f'{_out_string}')\n",
    "    print(f'saving out to \"{filelist_path}\"...')\n",
    "    with open(filelist_path, 'w') as f:\n",
    "        f.write(_out_string)\n",
    "    return _out_string, filelist_path\n",
    "\n",
    "# Save output filelist:\n",
    "\n",
    "# '/nfs/turbo/umms-kdiba/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/pipeline_results.h5'\n",
    "\n",
    "# kdiba_vvp01_two_2006-4-10_12-58-3\n",
    "# \toutputs_local ={'pkl': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/loadedSessPickle.pkl')}\n",
    "# \toutputs_global ={'pkl': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/global_computation_results.pkl'), 'hdf5': PosixPath('/nfs/turbo/umms-kdiba/Data/KDIBA/vvp01/two/2006-4-10_12-58-3/output/pipeline_results.h5')}\n",
    "session_identifiers, pkl_output_paths, hdf5_output_paths = global_batch_run.build_output_files_lists()\n",
    "\n",
    "h5_filelist_path = global_data_root_parent_path.joinpath(f'fileList_Greatlakes_HDF5_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, src_filelist_HDF5_savepath = save_filelist_to_text_file(hdf5_output_paths, h5_filelist_path)\n",
    "\n",
    "pkls_filelist_path = global_data_root_parent_path.joinpath(f'fileList_Greatlakes_pkls_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, src_filelist_pkls_savepath = save_filelist_to_text_file(pkl_output_paths, pkls_filelist_path)\n",
    "\n",
    "# source_parent_path = Path(r'/media/MAX/cloud/turbo/Data')\n",
    "source_parent_path = Path(r'/nfs/turbo/umms-kdiba/Data')\n",
    "dest_parent_path = Path(r'/~/W/Data/')\n",
    "# # Build the destination filelist from the source_filelist and the two paths:\n",
    "filelist_source = hdf5_output_paths\n",
    "filelist_dest_paths = convert_filelist_to_new_parent(filelist_source, original_parent_path=source_parent_path, dest_parent_path=dest_parent_path)\n",
    "filelist_dest_paths\n",
    "\n",
    "dest_Apogee_h5_filelist_path = global_data_root_parent_path.joinpath(f'dest_fileList_Apogee_{BATCH_DATE_TO_USE}.txt').resolve()\n",
    "_out_string, dest_filelist_savepath = save_filelist_to_text_file(filelist_dest_paths, dest_Apogee_h5_filelist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e69a3",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult\n",
    "from neuropy.core.epoch import Epoch\n",
    "\n",
    "# Save to HDF5\n",
    "suffix = f'{BATCH_DATE_TO_USE}'\n",
    "## Build Pickle Path:\n",
    "file_path = global_data_root_parent_path.joinpath(f'global_batch_output_{suffix}.h5').resolve()\n",
    "file_path\n",
    "global_batch_run.to_hdf(file_path,'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ce774-98fb-4e69-a7e2-e94cbff1b0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get only the sessions with non-None results\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "\n",
    "# list(global_batch_run.session_batch_outputs.keys())\n",
    "\n",
    "# Somewhere in there there are `InstantaneousSpikeRateGroupsComputation` results to extract\n",
    "across_sessions_instantaneous_fr_dict = {} # InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "# good_session_batch_outputs = global_batch_run.session_batch_outputs\n",
    "\n",
    "sessions_with_results = [a_ctxt for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None]\n",
    "good_session_batch_outputs = {a_ctxt:a_result for a_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None}\n",
    "\n",
    "for a_ctxt, a_result in good_session_batch_outputs.items():\n",
    "    if a_result is not None:\n",
    "        # a_good_result = a_result.__dict__.get('across_sessions_batch_results', {}).get('inst_fr_comps', None)\n",
    "        a_good_result = a_result.across_session_results.get('inst_fr_comps', None)\n",
    "        if a_good_result is not None:\n",
    "            across_sessions_instantaneous_fr_dict[a_ctxt] = a_good_result\n",
    "            # print(a_result['across_sessions_batch_results']['inst_fr_comps'])\n",
    "            \n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "\n",
    "# When done, `result_handler.across_sessions_instantaneous_fr_dict` is now equivalent to what it would have been before. It can be saved using the normal `.save_across_sessions_data(...)`\n",
    "\n",
    "## Save the instantaneous firing rate results dict: (# Dict[IdentifyingContext] = InstantaneousSpikeRateGroupsComputation)\n",
    "AcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_instantaneous_fr_dict, global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl')\n",
    "\n",
    "# ## Save pickle:\n",
    "# inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "# global_batch_result_inst_fr_file_path = Path(global_data_root_parent_path).joinpath(inst_fr_output_filename).resolve() # Use Default\n",
    "# print(f'global_batch_result_inst_fr_file_path: {global_batch_result_inst_fr_file_path}')\n",
    "# # Save the all sessions instantaneous firing rate dict to the path:\n",
    "# saveData(global_batch_result_inst_fr_file_path, across_sessions_instantaneous_fr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d19a7-5a89-43f1-aa33-3a7450d1f965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "across_sessions_instantaneous_fr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e178426c-54df-47ac-8103-a66f114c77e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[a_ctxt.get_initialization_code_string() for a_ctxt in sessions_with_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28828512",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056d9a7",
   "metadata": {},
   "source": [
    "# 2023-10-06 - `joined_neruon_fri_df` loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_DATE_TO_USE = '2023-10-05_NewParameters'\n",
    "BATCH_DATE_TO_USE = '2023-10-07'\n",
    "all_sessions_joined_neruon_fri_df, out_path = build_and_merge_all_sessions_joined_neruon_fri_df(global_data_root_parent_path, BATCH_DATE_TO_USE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb893bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joined_neruon_fri_df_basename = f'{BATCH_DATE_TO_USE}_{output_file_prefix}_joined_neruon_fri_df'\n",
    "AcrossSessionTables.write_table_to_files(joined_neruon_fri_df, global_data_root_parent_path=global_data_root_parent_path, output_basename=joined_neruon_fri_df_basename, include_csv=False)\n",
    "print(f'>>\\t done with {output_file_prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c4c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be651cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2023-10-04 - Load Saved across-sessions-data and testing Batch-computed inst_firing_rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "# from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "# from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import list_of_dicts_to_dict_of_lists\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34549c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the saved across-session results:\n",
    "# inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "# inst_fr_output_filename = 'across_session_result_long_short_inst_firing_rate.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-07-21.pkl'\n",
    "# inst_fr_output_filename=f'across_session_result_handler_{BATCH_DATE_TO_USE}.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-08-09_Test.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-10-04-GL.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_recomputed_inst_firing_rate_2023-10-04-GL-Recomp.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_recomputed_inst_firing_rate_2023-10-07.pkl'\n",
    "inst_fr_output_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abea5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    " \n",
    "## Load all across-session tables from the pickles:\n",
    "# output_path_suffix: str = f'2023-10-07'\n",
    "output_path_suffix: str = f'{BATCH_DATE_TO_USE}'\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.load_all_combined_tables(override_output_parent_path=global_data_root_parent_path, output_path_suffix=output_path_suffix) # output_path_suffix=f'2023-10-04-GL-Recomp'\n",
    "num_sessions = len(neuron_replay_stats_table.session_uid.unique().to_numpy())\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ef2a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ac006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager, SessionCellExclusivityRecord\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "\n",
    "annotation_man = UserAnnotationsManager()\n",
    "\n",
    "LxC_uids = []\n",
    "SxC_uids = []\n",
    "\n",
    "for a_ctxt in included_session_contexts:\n",
    "\tsession_uid = a_ctxt.get_description(separator=\"|\", include_property_names=False)\n",
    "\tsession_uid\n",
    "\tsession_cell_exclusivity: SessionCellExclusivityRecord = annotation_man.annotations[a_ctxt].get('session_cell_exclusivity', None)\n",
    "\tLxC_uids.extend([f\"{session_uid}|{aclu}\" for aclu in session_cell_exclusivity.LxC])\n",
    "\tSxC_uids.extend([f\"{session_uid}|{aclu}\" for aclu in session_cell_exclusivity.SxC])\n",
    "\t\n",
    "# [a_ctxt.get_description(separator=\"|\", include_property_names=False) for a_ctxt in included_session_contexts]\n",
    "\n",
    "long_short_fr_indicies_analysis_table['XxC_status'] = 'Shared'\n",
    "long_short_fr_indicies_analysis_table.loc[np.isin(long_short_fr_indicies_analysis_table.neuron_uid, LxC_uids), 'XxC_status'] = 'LxC'\n",
    "long_short_fr_indicies_analysis_table.loc[np.isin(long_short_fr_indicies_analysis_table.neuron_uid, SxC_uids), 'XxC_status'] = 'SxC'\n",
    "\n",
    "long_short_fr_indicies_analysis_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df97ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-10-11 - Get the long peak location\n",
    "\n",
    "long_short_fr_indicies_analysis_table['long_pf_peak_x'] = neuron_replay_stats_table['long_pf_peak_x']\n",
    "long_short_fr_indicies_analysis_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1641aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "long_short_fr_indicies_analysis_table.plot.scatter(x='long_pf_peak_x', y='x_frs_index', title='Pf Peak position vs. LapsFRI', ylabel='Lap FRI')\n",
    "\n",
    "long_short_fr_indicies_analysis_table.plot.scatter(x='long_pf_peak_x', y='y_frs_index', title='Pf Peak position vs. ReplayFRI', ylabel='Replay FRI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9987dc",
   "metadata": {},
   "source": [
    " #TODO 2023-10-05 11:40: - [ ] Extract the \"contrarian cells\", the ones that have a strong exclusivity on the laps but the opposite tendency on the replays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_short_fr_indicies_analysis_table_filename = 'output/2023-10-07_long_short_fr_indicies_analysis_table.csv'\n",
    "long_short_fr_indicies_analysis_table_filename: str = 'output/{BATCH_DATE_TO_USE}_long_short_fr_indicies_analysis_table.csv'\n",
    "long_short_fr_indicies_analysis_table.to_csv(long_short_fr_indicies_analysis_table_filename)\n",
    "print(f'saved: {long_short_fr_indicies_analysis_table_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1427597f",
   "metadata": {},
   "source": [
    "# 2023-10-10 - Statistics for `across_sessions_bar_graphs`, analysing `across_session_inst_fr_computation` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33422d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import pho_stats_perform_diagonal_line_binomial_test, pho_stats_bar_graph_t_tests\n",
    "\n",
    "binom_test_chance_result = pho_stats_perform_diagonal_line_binomial_test(long_short_fr_indicies_analysis_table)\n",
    "print(f'binom_test_chance_result: {binom_test_chance_result}')\n",
    "\n",
    "LxC_Laps_T_result, SxC_Laps_T_result, LxC_Replay_T_result, SxC_Replay_T_result = pho_stats_bar_graph_t_tests(across_session_inst_fr_computation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24ea5a5",
   "metadata": {},
   "source": [
    "## 2023-10-04 - Run `AcrossSessionsVisualizations` corresponding to the PhoDibaPaper2023 figures for all sessions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1152c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Hacks the `PaperFigureTwo` and `InstantaneousSpikeRateGroupsComputation` \n",
    "global_multi_session_context, _out_aggregate_fig_2 = AcrossSessionsVisualizations.across_sessions_bar_graphs(across_session_inst_fr_computation, num_sessions, enable_tiny_point_labels=False, enable_hover_labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c437e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "\n",
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=num_sessions, save_figure=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_long_and_short_firing_rate_replays_v_laps_figure(neuron_replay_stats_table=neuron_replay_stats_table, num_sessions=num_sessions, save_figure=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_man = UserAnnotationsManager()\n",
    "included_annotations = {ctxt:ann_man.annotations[ctxt].get('session_cell_exclusivity', None) for ctxt in included_session_contexts}\n",
    "\n",
    "all_LxCs = []\n",
    "all_SxCs = []\n",
    "\n",
    "for ctxt, an_ann in included_annotations.items():\n",
    "\tsession_ctxt_key:str = ctxt.get_description(separator='|', subset_includelist=IdentifyingContext._get_session_context_keys())\n",
    "\tall_LxCs.extend([f\"{session_ctxt_key}|{aclu}\" for aclu in an_ann.LxC])\n",
    "\tall_SxCs.extend([f\"{session_ctxt_key}|{aclu}\" for aclu in an_ann.SxC])\n",
    "\t\n",
    "all_LxCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1222a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_SxCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381fcf5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "across_session_inst_fr_computation.LxC_scatter_props\n",
    "across_session_inst_fr_computation.SxC_scatter_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63258151",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=num_sessions) # some global context across all of the sessions, not sure what to put here.\n",
    "\n",
    "# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\n",
    "\n",
    "## Display the aggregate across sessions:\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn't save this info\n",
    "_out_fig_2.computation_result = across_session_inst_fr_computation # the result loaded from the file\n",
    "_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\n",
    "# Set callback, the only self-specific property\n",
    "# _out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)\n",
    "_out_fig_2.scatter_props_fn = _return_scatter_props_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LxC_aclus = _out_fig_2.computation_result.LxC_aclus\n",
    "SxC_aclus = _out_fig_2.computation_result.SxC_aclus\n",
    "\n",
    "LxC_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c498f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureOutputManager, FigureOutputLocation, ContextToPathMode\n",
    "\n",
    "registered_output_files = {}\n",
    "\n",
    "def output_figure(final_context: IdentifyingContext, fig, write_vector_format:bool=False, write_png:bool=True, debug_print=True):\n",
    "    \"\"\" outputs the figure using the provided context. \"\"\"\n",
    "    from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_and_write_to_file\n",
    "    def register_output_file(output_path, output_metadata=None):\n",
    "        \"\"\" registers a new output file for the pipeline \"\"\"\n",
    "        print(f'register_output_file(output_path: {output_path}, ...)')\n",
    "        registered_output_files[output_path] = output_metadata or {}\n",
    "\n",
    "    fig_out_man = FigureOutputManager(figure_output_location=FigureOutputLocation.DAILY_PROGRAMMATIC_OUTPUT_FOLDER, context_to_path_mode=ContextToPathMode.HIERARCHY_UNIQUE)\n",
    "    active_out_figure_paths = build_and_write_to_file(fig, final_context, fig_out_man, write_vector_format=write_vector_format, write_png=write_png, register_output_file_fn=register_output_file)\n",
    "    return active_out_figure_paths, final_context\n",
    "\n",
    "\n",
    "# Set callback, the only self-specific property\n",
    "_out_fig_2._pipeline_file_callback_fn = output_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_2.computation_result.Fig2_Laps_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\n",
    "\t\n",
    "_out_fig_2.perform_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96ed659",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-10-11 - Surprise Shuffling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d829b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a87449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
